1:f81a91d: /*
1:f81a91d:  * Licensed to the Apache Software Foundation (ASF) under one
1:f81a91d:  * or more contributor license agreements.  See the NOTICE file
1:f81a91d:  * distributed with this work for additional information
1:f81a91d:  * regarding copyright ownership.  The ASF licenses this file
1:f81a91d:  * to you under the Apache License, Version 2.0 (the
1:f81a91d:  * "License"); you may not use this file except in compliance
1:f81a91d:  * with the License.  You may obtain a copy of the License at
1:f81a91d:  *
1:f81a91d:  *     http://www.apache.org/licenses/LICENSE-2.0
1:f81a91d:  *
1:f81a91d:  * Unless required by applicable law or agreed to in writing, software
1:f81a91d:  * distributed under the License is distributed on an "AS IS" BASIS,
1:f81a91d:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:f81a91d:  * See the License for the specific language governing permissions and
1:f81a91d:  * limitations under the License.
1:f81a91d:  */
1:f81a91d: package org.apache.cassandra.io.sstable.format;
1:f81a91d: 
1:f81a91d: import java.io.File;
1:f81a91d: import java.io.IOException;
1:f81a91d: import java.nio.ByteBuffer;
1:f81a91d: import java.util.Arrays;
1:f81a91d: import java.util.Collection;
1:f81a91d: import java.util.Collections;
1:f81a91d: import java.util.Iterator;
1:f81a91d: 
1:f81a91d: import org.apache.cassandra.config.CFMetaData;
1:f81a91d: import org.apache.cassandra.config.ColumnDefinition;
1:f81a91d: import org.apache.cassandra.config.DatabaseDescriptor;
1:f81a91d: import org.apache.cassandra.db.Clustering;
1:f81a91d: import org.apache.cassandra.db.DecoratedKey;
1:f81a91d: import org.apache.cassandra.db.DeletionTime;
1:f81a91d: import org.apache.cassandra.db.SerializationHeader;
1:f81a91d: import org.apache.cassandra.db.compaction.OperationType;
1:f81a91d: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1:f81a91d: import org.apache.cassandra.db.marshal.Int32Type;
1:f81a91d: import org.apache.cassandra.db.marshal.LongType;
1:f81a91d: import org.apache.cassandra.db.marshal.UTF8Type;
1:f81a91d: import org.apache.cassandra.db.rows.*;
1:f81a91d: import org.apache.cassandra.io.FSReadError;
1:f81a91d: import org.apache.cassandra.io.FSWriteError;
1:f81a91d: import org.apache.cassandra.io.sstable.Descriptor;
1:f81a91d: import org.apache.cassandra.io.sstable.format.big.BigTableWriter;
1:f81a91d: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
1:f81a91d: import org.apache.cassandra.io.util.FileDataInput;
1:f81a91d: import org.apache.cassandra.io.util.FileUtils;
1:f81a91d: import org.apache.cassandra.utils.ByteBufferUtil;
1:f81a91d: import org.apache.cassandra.utils.Pair;
1:f81a91d: 
1:f81a91d: import com.google.common.collect.ArrayListMultimap;
1:f81a91d: import com.google.common.collect.Multimap;
1:f81a91d: 
1:f81a91d: import junit.framework.Assert;
1:9797511: 
1:9797511: import org.junit.BeforeClass;
1:f81a91d: import org.junit.Test;
1:f81a91d: 
1:f81a91d: public class SSTableFlushObserverTest
1:f81a91d: {
1:9797511:     @BeforeClass
1:9797511:     public static void initDD()
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:9797511:     }
1:9797511: 
1:f81a91d:     private static final String KS_NAME = "test";
1:f81a91d:     private static final String CF_NAME = "flush_observer";
1:f81a91d: 
1:f81a91d:     @Test
1:f81a91d:     public void testFlushObserver()
1:f81a91d:     {
1:f81a91d:         CFMetaData cfm = CFMetaData.Builder.create(KS_NAME, CF_NAME)
1:f81a91d:                                            .addPartitionKey("id", UTF8Type.instance)
1:f81a91d:                                            .addRegularColumn("first_name", UTF8Type.instance)
1:f81a91d:                                            .addRegularColumn("age", Int32Type.instance)
1:f81a91d:                                            .addRegularColumn("height", LongType.instance)
1:f81a91d:                                            .build();
1:f81a91d: 
1:f81a91d:         LifecycleTransaction transaction = LifecycleTransaction.offline(OperationType.COMPACTION);
1:f81a91d:         FlushObserver observer = new FlushObserver();
1:f81a91d: 
1:f81a91d:         String sstableDirectory = DatabaseDescriptor.getAllDataFileLocations()[0];
1:f81a91d:         File directory = new File(sstableDirectory + File.pathSeparator + KS_NAME + File.pathSeparator + CF_NAME);
1:f81a91d:         directory.deleteOnExit();
1:f81a91d: 
1:f81a91d:         if (!directory.exists() && !directory.mkdirs())
1:f81a91d:             throw new FSWriteError(new IOException("failed to create tmp directory"), directory.getAbsolutePath());
1:f81a91d: 
1:9797511:         SSTableFormat.Type sstableFormat = SSTableFormat.Type.current();
1:f81a91d: 
1:f81a91d:         BigTableWriter writer = new BigTableWriter(new Descriptor(sstableFormat.info.getLatestVersion().version,
1:f81a91d:                                                                   directory,
1:f81a91d:                                                                   KS_NAME, CF_NAME,
1:f81a91d:                                                                   0,
1:f81a91d:                                                                   sstableFormat),
1:f81a91d:                                                    10L, 0L, cfm,
1:f81a91d:                                                    new MetadataCollector(cfm.comparator).sstableLevel(0),
1:f81a91d:                                                    new SerializationHeader(true, cfm, cfm.partitionColumns(), EncodingStats.NO_STATS),
1:f81a91d:                                                    Collections.singletonList(observer),
1:f81a91d:                                                    transaction);
1:f81a91d: 
1:f81a91d:         SSTableReader reader = null;
1:f81a91d:         Multimap<ByteBuffer, Cell> expected = ArrayListMultimap.create();
1:f81a91d: 
1:f81a91d:         try
1:f81a91d:         {
1:f81a91d:             final long now = System.currentTimeMillis();
1:f81a91d: 
1:f81a91d:             ByteBuffer key = UTF8Type.instance.fromString("key1");
1:cb0d1ca:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(27)),
1:cb0d1ca:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jack")),
1:e017f94:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(183L))));
1:f81a91d: 
1:f81a91d:             writer.append(new RowIterator(cfm, key.duplicate(), Collections.singletonList(buildRow(expected.get(key)))));
1:f81a91d: 
1:f81a91d:             key = UTF8Type.instance.fromString("key2");
1:cb0d1ca:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:cb0d1ca:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jim")),
1:e017f94:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(180L))));
1:f81a91d: 
1:f81a91d:             writer.append(new RowIterator(cfm, key, Collections.singletonList(buildRow(expected.get(key)))));
1:f81a91d: 
1:f81a91d:             key = UTF8Type.instance.fromString("key3");
1:cb0d1ca:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:cb0d1ca:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("ken")),
1:e017f94:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(178L))));
1:f81a91d: 
1:f81a91d:             writer.append(new RowIterator(cfm, key, Collections.singletonList(buildRow(expected.get(key)))));
1:f81a91d: 
1:f81a91d:             reader = writer.finish(true);
1:f81a91d:         }
1:f81a91d:         finally
1:f81a91d:         {
1:f81a91d:             FileUtils.closeQuietly(writer);
1:f81a91d:         }
1:f81a91d: 
1:f81a91d:         Assert.assertTrue(observer.isComplete);
1:f81a91d:         Assert.assertEquals(expected.size(), observer.rows.size());
1:f81a91d: 
1:f81a91d:         for (Pair<ByteBuffer, Long> e : observer.rows.keySet())
1:f81a91d:         {
1:f81a91d:             ByteBuffer key = e.left;
1:f81a91d:             Long indexPosition = e.right;
1:f81a91d: 
1:f81a91d:             try (FileDataInput index = reader.ifile.createReader(indexPosition))
1:f81a91d:             {
1:f81a91d:                 ByteBuffer indexKey = ByteBufferUtil.readWithShortLength(index);
1:f81a91d:                 Assert.assertEquals(0, UTF8Type.instance.compare(key, indexKey));
1:f81a91d:             }
1:f81a91d:             catch (IOException ex)
1:f81a91d:             {
1:f81a91d:                 throw new FSReadError(ex, reader.getIndexFilename());
1:f81a91d:             }
1:f81a91d: 
1:f81a91d:             Assert.assertEquals(expected.get(key), observer.rows.get(e));
1:f81a91d:         }
1:f81a91d:     }
1:f81a91d: 
1:f81a91d:     private static class RowIterator extends AbstractUnfilteredRowIterator
1:f81a91d:     {
1:f81a91d:         private final Iterator<Unfiltered> rows;
1:f81a91d: 
1:f81a91d:         public RowIterator(CFMetaData cfm, ByteBuffer key, Collection<Unfiltered> content)
1:f81a91d:         {
1:f81a91d:             super(cfm,
1:f81a91d:                   DatabaseDescriptor.getPartitioner().decorateKey(key),
1:f81a91d:                   DeletionTime.LIVE,
1:f81a91d:                   cfm.partitionColumns(),
1:f81a91d:                   BTreeRow.emptyRow(Clustering.STATIC_CLUSTERING),
1:f81a91d:                   false,
1:f81a91d:                   EncodingStats.NO_STATS);
1:f81a91d: 
1:f81a91d:             rows = content.iterator();
1:f81a91d:         }
1:f81a91d: 
1:f81a91d:         @Override
1:f81a91d:         protected Unfiltered computeNext()
1:f81a91d:         {
1:f81a91d:             return rows.hasNext() ? rows.next() : endOfData();
1:f81a91d:         }
1:f81a91d:     }
1:f81a91d: 
1:f81a91d:     private static class FlushObserver implements SSTableFlushObserver
1:f81a91d:     {
1:f81a91d:         private final Multimap<Pair<ByteBuffer, Long>, Cell> rows = ArrayListMultimap.create();
1:f81a91d:         private Pair<ByteBuffer, Long> currentKey;
1:f81a91d:         private boolean isComplete;
1:f81a91d: 
1:f81a91d:         @Override
1:f81a91d:         public void begin()
1:f81a91d:         {}
1:f81a91d: 
1:f81a91d:         @Override
1:f81a91d:         public void startPartition(DecoratedKey key, long indexPosition)
1:f81a91d:         {
1:f81a91d:             currentKey = Pair.create(key.getKey(), indexPosition);
1:f81a91d:         }
1:f81a91d: 
1:f81a91d:         @Override
1:72790dc:         public void nextUnfilteredCluster(Unfiltered row)
1:f81a91d:         {
1:72790dc:             if (row.isRow())
1:72790dc:                 ((Row) row).forEach((c) -> rows.put(currentKey, (Cell) c));
1:f81a91d:         }
1:f81a91d: 
1:f81a91d:         @Override
1:f81a91d:         public void complete()
1:f81a91d:         {
1:f81a91d:             isComplete = true;
1:f81a91d:         }
1:f81a91d:     }
1:f81a91d: 
1:f81a91d:     private static Row buildRow(Collection<Cell> cells)
1:f81a91d:     {
1:f81a91d:         Row.Builder rowBuilder = BTreeRow.sortedBuilder();
1:f81a91d:         rowBuilder.newRow(Clustering.EMPTY);
1:f81a91d:         cells.forEach(rowBuilder::addCell);
1:f81a91d:         return rowBuilder.build();
1:f81a91d:     }
1:f81a91d: 
1:f81a91d:     private static ColumnDefinition getColumn(CFMetaData cfm, String name)
1:f81a91d:     {
1:f81a91d:         return cfm.getColumnDefinition(UTF8Type.instance.fromString(name));
1:f81a91d:     }
1:f81a91d: }
============================================================================
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.junit.BeforeClass;
1:     @BeforeClass
1:     public static void initDD()
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:         SSTableFormat.Type sstableFormat = SSTableFormat.Type.current();
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:cb0d1ca
/////////////////////////////////////////////////////////////////////////
1:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(27)),
1:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jack")),
1:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jim")),
1:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:                                                BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("ken")),
author:Benjamin Lerer
-------------------------------------------------------------------------------
commit:e017f94
/////////////////////////////////////////////////////////////////////////
0:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jack")),
0:                                                BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(27)),
1:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(183L))));
0:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jim")),
0:                                                BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(180L))));
0:             expected.putAll(key, Arrays.asList(BufferCell.live(getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("ken")),
0:                                                BufferCell.live(getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
1:                                                BufferCell.live(getColumn(cfm, "height"), now, LongType.instance.decompose(178L))));
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:72790dc
/////////////////////////////////////////////////////////////////////////
1:         public void nextUnfilteredCluster(Unfiltered row)
1:             if (row.isRow())
1:                 ((Row) row).forEach((c) -> rows.put(currentKey, (Cell) c));
commit:f81a91d
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.io.sstable.format;
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.util.Arrays;
1: import java.util.Collection;
1: import java.util.Collections;
1: import java.util.Iterator;
1: 
1: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.config.ColumnDefinition;
1: import org.apache.cassandra.config.DatabaseDescriptor;
1: import org.apache.cassandra.db.Clustering;
1: import org.apache.cassandra.db.DecoratedKey;
1: import org.apache.cassandra.db.DeletionTime;
1: import org.apache.cassandra.db.SerializationHeader;
1: import org.apache.cassandra.db.compaction.OperationType;
1: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1: import org.apache.cassandra.db.marshal.Int32Type;
1: import org.apache.cassandra.db.marshal.LongType;
1: import org.apache.cassandra.db.marshal.UTF8Type;
1: import org.apache.cassandra.db.rows.*;
1: import org.apache.cassandra.io.FSReadError;
1: import org.apache.cassandra.io.FSWriteError;
1: import org.apache.cassandra.io.sstable.Descriptor;
1: import org.apache.cassandra.io.sstable.format.big.BigTableWriter;
1: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
1: import org.apache.cassandra.io.util.FileDataInput;
1: import org.apache.cassandra.io.util.FileUtils;
1: import org.apache.cassandra.utils.ByteBufferUtil;
1: import org.apache.cassandra.utils.Pair;
1: 
1: import com.google.common.collect.ArrayListMultimap;
1: import com.google.common.collect.Multimap;
1: 
1: import junit.framework.Assert;
1: import org.junit.Test;
1: 
1: public class SSTableFlushObserverTest
1: {
1:     private static final String KS_NAME = "test";
1:     private static final String CF_NAME = "flush_observer";
1: 
1:     @Test
1:     public void testFlushObserver()
1:     {
1:         CFMetaData cfm = CFMetaData.Builder.create(KS_NAME, CF_NAME)
1:                                            .addPartitionKey("id", UTF8Type.instance)
1:                                            .addRegularColumn("first_name", UTF8Type.instance)
1:                                            .addRegularColumn("age", Int32Type.instance)
1:                                            .addRegularColumn("height", LongType.instance)
1:                                            .build();
1: 
1:         LifecycleTransaction transaction = LifecycleTransaction.offline(OperationType.COMPACTION);
1:         FlushObserver observer = new FlushObserver();
1: 
1:         String sstableDirectory = DatabaseDescriptor.getAllDataFileLocations()[0];
1:         File directory = new File(sstableDirectory + File.pathSeparator + KS_NAME + File.pathSeparator + CF_NAME);
1:         directory.deleteOnExit();
1: 
1:         if (!directory.exists() && !directory.mkdirs())
1:             throw new FSWriteError(new IOException("failed to create tmp directory"), directory.getAbsolutePath());
1: 
0:         SSTableFormat.Type sstableFormat = DatabaseDescriptor.getSSTableFormat();
1: 
1:         BigTableWriter writer = new BigTableWriter(new Descriptor(sstableFormat.info.getLatestVersion().version,
1:                                                                   directory,
1:                                                                   KS_NAME, CF_NAME,
1:                                                                   0,
1:                                                                   sstableFormat),
1:                                                    10L, 0L, cfm,
1:                                                    new MetadataCollector(cfm.comparator).sstableLevel(0),
1:                                                    new SerializationHeader(true, cfm, cfm.partitionColumns(), EncodingStats.NO_STATS),
1:                                                    Collections.singletonList(observer),
1:                                                    transaction);
1: 
1:         SSTableReader reader = null;
1:         Multimap<ByteBuffer, Cell> expected = ArrayListMultimap.create();
1: 
1:         try
1:         {
1:             final long now = System.currentTimeMillis();
1: 
1:             ByteBuffer key = UTF8Type.instance.fromString("key1");
0:             expected.putAll(key, Arrays.asList(BufferCell.live(cfm, getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jack")),
0:                                                BufferCell.live(cfm, getColumn(cfm, "age"), now, Int32Type.instance.decompose(27)),
0:                                                BufferCell.live(cfm, getColumn(cfm, "height"), now, LongType.instance.decompose(183L))));
1: 
1:             writer.append(new RowIterator(cfm, key.duplicate(), Collections.singletonList(buildRow(expected.get(key)))));
1: 
1:             key = UTF8Type.instance.fromString("key2");
0:             expected.putAll(key, Arrays.asList(BufferCell.live(cfm, getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("jim")),
0:                                                BufferCell.live(cfm, getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
0:                                                BufferCell.live(cfm, getColumn(cfm, "height"), now, LongType.instance.decompose(180L))));
1: 
1:             writer.append(new RowIterator(cfm, key, Collections.singletonList(buildRow(expected.get(key)))));
1: 
1:             key = UTF8Type.instance.fromString("key3");
0:             expected.putAll(key, Arrays.asList(BufferCell.live(cfm, getColumn(cfm, "first_name"), now,UTF8Type.instance.fromString("ken")),
0:                                                BufferCell.live(cfm, getColumn(cfm, "age"), now, Int32Type.instance.decompose(30)),
0:                                                BufferCell.live(cfm, getColumn(cfm, "height"), now, LongType.instance.decompose(178L))));
1: 
1:             writer.append(new RowIterator(cfm, key, Collections.singletonList(buildRow(expected.get(key)))));
1: 
1:             reader = writer.finish(true);
1:         }
1:         finally
1:         {
1:             FileUtils.closeQuietly(writer);
1:         }
1: 
1:         Assert.assertTrue(observer.isComplete);
1:         Assert.assertEquals(expected.size(), observer.rows.size());
1: 
1:         for (Pair<ByteBuffer, Long> e : observer.rows.keySet())
1:         {
1:             ByteBuffer key = e.left;
1:             Long indexPosition = e.right;
1: 
1:             try (FileDataInput index = reader.ifile.createReader(indexPosition))
1:             {
1:                 ByteBuffer indexKey = ByteBufferUtil.readWithShortLength(index);
1:                 Assert.assertEquals(0, UTF8Type.instance.compare(key, indexKey));
1:             }
1:             catch (IOException ex)
1:             {
1:                 throw new FSReadError(ex, reader.getIndexFilename());
1:             }
1: 
1:             Assert.assertEquals(expected.get(key), observer.rows.get(e));
1:         }
1:     }
1: 
1:     private static class RowIterator extends AbstractUnfilteredRowIterator
1:     {
1:         private final Iterator<Unfiltered> rows;
1: 
1:         public RowIterator(CFMetaData cfm, ByteBuffer key, Collection<Unfiltered> content)
1:         {
1:             super(cfm,
1:                   DatabaseDescriptor.getPartitioner().decorateKey(key),
1:                   DeletionTime.LIVE,
1:                   cfm.partitionColumns(),
1:                   BTreeRow.emptyRow(Clustering.STATIC_CLUSTERING),
1:                   false,
1:                   EncodingStats.NO_STATS);
1: 
1:             rows = content.iterator();
1:         }
1: 
1:         @Override
1:         protected Unfiltered computeNext()
1:         {
1:             return rows.hasNext() ? rows.next() : endOfData();
1:         }
1:     }
1: 
1:     private static class FlushObserver implements SSTableFlushObserver
1:     {
1:         private final Multimap<Pair<ByteBuffer, Long>, Cell> rows = ArrayListMultimap.create();
1:         private Pair<ByteBuffer, Long> currentKey;
1:         private boolean isComplete;
1: 
1:         @Override
1:         public void begin()
1:         {}
1: 
1:         @Override
1:         public void startPartition(DecoratedKey key, long indexPosition)
1:         {
1:             currentKey = Pair.create(key.getKey(), indexPosition);
1:         }
1: 
1:         @Override
0:         public void nextCell(ColumnData cell)
1:         {
0:             rows.put(currentKey, (Cell) cell);
1:         }
1: 
1:         @Override
1:         public void complete()
1:         {
1:             isComplete = true;
1:         }
1:     }
1: 
1:     private static Row buildRow(Collection<Cell> cells)
1:     {
1:         Row.Builder rowBuilder = BTreeRow.sortedBuilder();
1:         rowBuilder.newRow(Clustering.EMPTY);
1:         cells.forEach(rowBuilder::addCell);
1:         return rowBuilder.build();
1:     }
1: 
1:     private static ColumnDefinition getColumn(CFMetaData cfm, String name)
1:     {
1:         return cfm.getColumnDefinition(UTF8Type.instance.fromString(name));
1:     }
1: }
============================================================================
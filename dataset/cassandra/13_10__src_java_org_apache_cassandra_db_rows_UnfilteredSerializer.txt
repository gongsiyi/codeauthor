1:a991b64: /*
1:a991b64:  * Licensed to the Apache Software Foundation (ASF) under one
1:a991b64:  * or more contributor license agreements.  See the NOTICE file
1:a991b64:  * distributed with this work for additional information
1:a991b64:  * regarding copyright ownership.  The ASF licenses this file
1:a991b64:  * to you under the Apache License, Version 2.0 (the
1:a991b64:  * "License"); you may not use this file except in compliance
1:a991b64:  * with the License.  You may obtain a copy of the License at
3:a991b64:  *
1:a991b64:  *     http://www.apache.org/licenses/LICENSE-2.0
1:a991b64:  *
1:a991b64:  * Unless required by applicable law or agreed to in writing, software
1:a991b64:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a991b64:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a991b64:  * See the License for the specific language governing permissions and
1:a991b64:  * limitations under the License.
1:a991b64:  */
1:a991b64: package org.apache.cassandra.db.rows;
71:a991b64: 
1:a991b64: import java.io.IOException;
1:a991b64: 
1:0d74c3e: import com.google.common.collect.Collections2;
1:a991b64: 
1:1e92ce4: import net.nicoulaj.compilecommand.annotations.Inline;
1:a991b64: import org.apache.cassandra.config.ColumnDefinition;
1:a991b64: import org.apache.cassandra.db.*;
1:d40ac78: import org.apache.cassandra.db.rows.Row.Deletion;
1:2457599: import org.apache.cassandra.io.util.DataInputPlus;
1:1e92ce4: import org.apache.cassandra.io.util.DataOutputBuffer;
1:a991b64: import org.apache.cassandra.io.util.DataOutputPlus;
1:d40ac78: import org.apache.cassandra.io.util.FileDataInput;
1:e4c344c: import org.apache.cassandra.utils.SearchIterator;
1:dc9ed46: import org.apache.cassandra.utils.WrappedException;
1:a991b64: 
1:a991b64: /**
1:2457599:  * Serialize/deserialize a single Unfiltered (both on-wire and on-disk).
1:aefa580:  * <p>
1:a991b64:  *
1:aefa580:  * The encoded format for an unfiltered is {@code <flags>(<row>|<marker>)} where:
1:aefa580:  * <ul>
1:aefa580:  *   <li>
1:aefa580:  *     {@code <flags>} is a byte (or two) whose bits are flags used by the rest
1:aefa580:  *     of the serialization. Each flag is defined/explained below as the
1:aefa580:  *     "Unfiltered flags" constants. One of those flags is an extension flag,
1:aefa580:  *     and if present, indicates the presence of a 2ndbyte that contains more
1:aefa580:  *     flags. If the extension is not set, defaults are assumed for the flags
1:aefa580:  *     of that 2nd byte.
1:aefa580:  *   </li>
1:aefa580:  *   <li>
1:aefa580:  *     {@code <row>} is
1:aefa580:  *        {@code <clustering><sizes>[<pkliveness>][<deletion>][<columns>]<columns_data>}
1:aefa580:  *     where:
1:aefa580:  *     <ul>
1:aefa580:  *       <li>{@code <clustering>} is the row clustering as serialized by
1:79c5bc3:  *           {@link org.apache.cassandra.db.Clustering.Serializer} (note that static row are an
1:aefa580:  *           exception and don't have this). </li>
1:aefa580:  *       <li>{@code <sizes>} are the sizes of the whole unfiltered on disk and
1:aefa580:  *           of the previous unfiltered. This is only present for sstables and
1:aefa580:  *           is used to efficiently skip rows (both forward and backward).</li>
1:aefa580:  *       <li>{@code <pkliveness>} is the row primary key liveness infos, and it
1:aefa580:  *           contains the timestamp, ttl and local deletion time of that info,
1:aefa580:  *           though some/all of those can be absent based on the flags. </li>
1:aefa580:  *       <li>{@code deletion} is the row deletion. It's presence is determined
1:aefa580:  *           by the flags and if present, it conists of both the deletion
1:aefa580:  *           timestamp and local deletion time.</li>
1:aefa580:  *       <li>{@code <columns>} are the columns present in the row  encoded by
1:79c5bc3:  *           {@link org.apache.cassandra.db.Columns.Serializer#serializeSubset}. It is absent if the row
1:aefa580:  *           contains all the columns of the {@code SerializationHeader} (which
1:aefa580:  *           is then indicated by a flag). </li>
1:aefa580:  *       <li>{@code <columns_data>} is the data for each of the column present
1:aefa580:  *           in the row. The encoding of each data depends on whether the data
1:aefa580:  *           is for a simple or complex column:
1:aefa580:  *           <ul>
1:aefa580:  *              <li>Simple columns are simply encoded as one {@code <cell>}</li>
1:aefa580:  *              <li>Complex columns are encoded as {@code [<delTime>]<n><cell1>...<celln>}
1:aefa580:  *                  where {@code <delTime>} is the deletion for this complex
1:aefa580:  *                  column (if flags indicates its presence), {@code <n>} is the
1:aefa580:  *                  vint encoded value of n, i.e. {@code <celln>}'s 1-based
1:aefa580:  *                  inde and {@code <celli>} are the {@code <cell>} for this
1:aefa580:  *                  complex column</li>
1:aefa580:  *           </ul>
1:aefa580:  *       </li>
1:aefa580:  *     </ul>
1:aefa580:  *   </li>
1:aefa580:  *   <li>
1:aefa580:  *     {@code <marker>} is {@code <bound><deletion>} where {@code <bound>} is
1:79c5bc3:  *     the marker bound as serialized by {@link org.apache.cassandra.db.ClusteringBoundOrBoundary.Serializer}
1:aefa580:  *     and {@code <deletion>} is the marker deletion time.
1:aefa580:  *   </li>
1:aefa580:  * </ul>
1:aefa580:  * <p>
1:aefa580:  * The serialization of a {@code <cell>} is defined by {@link Cell.Serializer}.
1:a991b64:  */
1:a991b64: public class UnfilteredSerializer
32:a991b64: {
1:a991b64:     public static final UnfilteredSerializer serializer = new UnfilteredSerializer();
1:a991b64: 
1:2457599:     /*
1:2457599:      * Unfiltered flags constants.
1:2457599:      */
1:2457599:     private final static int END_OF_PARTITION     = 0x01; // Signal the end of the partition. Nothing follows a <flags> field with that flag.
1:2457599:     private final static int IS_MARKER            = 0x02; // Whether the encoded unfiltered is a marker or a row. All following markers applies only to rows.
1:665f747:     private final static int HAS_TIMESTAMP        = 0x04; // Whether the encoded row has a timestamp (i.e. if row.partitionKeyLivenessInfo().hasTimestamp() == true).
1:665f747:     private final static int HAS_TTL              = 0x08; // Whether the encoded row has some expiration info (i.e. if row.partitionKeyLivenessInfo().hasTTL() == true).
1:665f747:     private final static int HAS_DELETION         = 0x10; // Whether the encoded row has some deletion info.
1:665f747:     private final static int HAS_ALL_COLUMNS      = 0x20; // Whether the encoded row has all of the columns from the header present.
1:2457599:     private final static int HAS_COMPLEX_DELETION = 0x40; // Whether the encoded row has some complex deletion for at least one of its columns.
1:665f747:     private final static int EXTENSION_FLAG       = 0x80; // If present, another byte is read containing the "extended flags" above.
1:665f747: 
1:665f747:     /*
1:665f747:      * Extended flags
1:665f747:      */
1:665f747:     private final static int IS_STATIC               = 0x01; // Whether the encoded row is a static. If there is no extended flag, the row is assumed not static.
1:665f747:     private final static int HAS_SHADOWABLE_DELETION = 0x02; // Whether the row deletion is shadowable. If there is no extended flag (or no row deletion), the deletion is assumed not shadowable.
1:a991b64: 
1:a991b64:     public void serialize(Unfiltered unfiltered, SerializationHeader header, DataOutputPlus out, int version)
6:a991b64:     throws IOException
1:a991b64:     {
1:6584331:         assert !header.isForSSTable();
1:6584331:         serialize(unfiltered, header, out, 0, version);
1:6584331:     }
1:6584331: 
1:6584331:     public void serialize(Unfiltered unfiltered, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
1:6584331:     throws IOException
1:d40ac78:     {
1:a991b64:         if (unfiltered.kind() == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:6584331:         {
1:6584331:             serialize((RangeTombstoneMarker) unfiltered, header, out, previousUnfilteredSize, version);
1:2457599:         }
9:a991b64:         else
1:2457599:         {
1:6584331:             serialize((Row) unfiltered, header, out, previousUnfilteredSize, version);
1:2457599:         }
31:a991b64:     }
1:2457599: 
1:6584331:     public void serializeStaticRow(Row row, SerializationHeader header, DataOutputPlus out, int version)
1:6584331:     throws IOException
1:6584331:     {
1:6584331:         assert row.isStatic();
1:6584331:         serialize(row, header, out, 0, version);
1:6584331:     }
1:6584331: 
1:6584331:     private void serialize(Row row, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
1:2457599:     throws IOException
1:2457599:     {
1:a991b64:         int flags = 0;
1:665f747:         int extendedFlags = 0;
1:2457599: 
1:665f747:         boolean isStatic = row.isStatic();
1:0d74c3e:         Columns headerColumns = header.columns(isStatic);
1:a991b64:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
1:665f747:         Row.Deletion deletion = row.deletion();
1:a991b64:         boolean hasComplexDeletion = row.hasComplexDeletion();
1:0d74c3e:         boolean hasAllColumns = (row.size() == headerColumns.size());
1:6584331:         boolean hasExtendedFlags = hasExtendedFlags(row);
1:665f747: 
1:a991b64:         if (isStatic)
1:665f747:             extendedFlags |= IS_STATIC;
1:665f747: 
1:2457599:         if (!pkLiveness.isEmpty())
1:a991b64:             flags |= HAS_TIMESTAMP;
1:2457599:         if (pkLiveness.isExpiring())
1:a991b64:             flags |= HAS_TTL;
1:a991b64:         if (!deletion.isLive())
1:665f747:         {
1:a991b64:             flags |= HAS_DELETION;
1:665f747:             if (deletion.isShadowable())
1:665f747:                 extendedFlags |= HAS_SHADOWABLE_DELETION;
1:665f747:         }
1:2457599:         if (hasComplexDeletion)
1:a991b64:             flags |= HAS_COMPLEX_DELETION;
1:0d74c3e:         if (hasAllColumns)
1:0d74c3e:             flags |= HAS_ALL_COLUMNS;
1:a991b64: 
1:665f747:         if (hasExtendedFlags)
1:665f747:             flags |= EXTENSION_FLAG;
1:665f747: 
2:a991b64:         out.writeByte((byte)flags);
1:665f747:         if (hasExtendedFlags)
1:665f747:             out.writeByte((byte)extendedFlags);
1:665f747: 
2:a991b64:         if (!isStatic)
1:a991b64:             Clustering.serializer.serialize(row.clustering(), out, version, header.clusteringTypes());
1:a991b64: 
1:6584331:         if (header.isForSSTable())
1:1e92ce4:         {
1:05660a5:             try (DataOutputBuffer dob = DataOutputBuffer.scratchBuffer.get())
1:6584331:             {
1:1e92ce4:                 serializeRowBody(row, flags, header, dob);
1:1e92ce4: 
1:1e92ce4:                 out.writeUnsignedVInt(dob.position() + TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize));
1:1e92ce4:                 // We write the size of the previous unfiltered to make reverse queries more efficient (and simpler).
1:1e92ce4:                 // This is currently not used however and using it is tbd.
1:1e92ce4:                 out.writeUnsignedVInt(previousUnfilteredSize);
1:dc9ed46:                 out.write(dob.getData(), 0, dob.getLength());
1:1e92ce4:             }
1:1e92ce4:         }
1:1e92ce4:         else
1:1e92ce4:         {
1:1e92ce4:             serializeRowBody(row, flags, header, out);
1:1e92ce4:         }
1:1e92ce4:     }
1:1e92ce4: 
1:1e92ce4:     @Inline
1:1e92ce4:     private void serializeRowBody(Row row, int flags, SerializationHeader header, DataOutputPlus out)
1:1e92ce4:     throws IOException
1:1e92ce4:     {
1:1e92ce4:         boolean isStatic = row.isStatic();
1:1e92ce4: 
1:1e92ce4:         Columns headerColumns = header.columns(isStatic);
1:1e92ce4:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
1:1e92ce4:         Row.Deletion deletion = row.deletion();
1:6584331: 
1:a991b64:         if ((flags & HAS_TIMESTAMP) != 0)
1:c055ab9:             header.writeTimestamp(pkLiveness.timestamp(), out);
1:a991b64:         if ((flags & HAS_TTL) != 0)
1:6584331:         {
1:c055ab9:             header.writeTTL(pkLiveness.ttl(), out);
1:c055ab9:             header.writeLocalDeletionTime(pkLiveness.localExpirationTime(), out);
1:6584331:         }
1:a991b64:         if ((flags & HAS_DELETION) != 0)
1:665f747:             header.writeDeletionTime(deletion.time(), out);
1:a991b64: 
1:1e92ce4:         if ((flags & HAS_ALL_COLUMNS) == 0)
1:0d74c3e:             Columns.serializer.serializeSubset(Collections2.transform(row, ColumnData::column), headerColumns, out);
1:a991b64: 
1:e4c344c:         SearchIterator<ColumnDefinition, ColumnDefinition> si = headerColumns.iterator();
1:a991b64: 
1:dc9ed46:         try
1:dc9ed46:         {
1:dc9ed46:             row.apply(cd -> {
1:dc9ed46:                 // We can obtain the column for data directly from data.column(). However, if the cell/complex data
1:dc9ed46:                 // originates from a sstable, the column we'll get will have the type used when the sstable was serialized,
1:dc9ed46:                 // and if that type have been recently altered, that may not be the type we want to serialize the column
1:dc9ed46:                 // with. So we use the ColumnDefinition from the "header" which is "current". Also see #11810 for what
1:dc9ed46:                 // happens if we don't do that.
1:dc9ed46:                 ColumnDefinition column = si.next(cd.column());
1:dc9ed46:                 assert column != null : cd.column.toString();
1:dc9ed46: 
1:dc9ed46:                 try
1:dc9ed46:                 {
1:dc9ed46:                     if (cd.column.isSimple())
1:dc9ed46:                         Cell.serializer.serialize((Cell) cd, column, out, pkLiveness, header);
1:dc9ed46:                     else
1:dc9ed46:                         writeComplexColumn((ComplexColumnData) cd, column, (flags & HAS_COMPLEX_DELETION) != 0, pkLiveness, header, out);
1:dc9ed46:                 }
1:dc9ed46:                 catch (IOException e)
1:dc9ed46:                 {
1:dc9ed46:                     throw new WrappedException(e);
1:dc9ed46:                 }
1:dc9ed46:             }, false);
1:dc9ed46:         }
1:dc9ed46:         catch (WrappedException e)
1:dc9ed46:         {
1:dc9ed46:             if (e.getCause() instanceof IOException)
1:dc9ed46:                 throw (IOException) e.getCause();
1:dc9ed46: 
1:dc9ed46:             throw e;
1:665f747:         }
1:665f747:     }
1:a991b64: 
1:e4c344c:     private void writeComplexColumn(ComplexColumnData data, ColumnDefinition column, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header, DataOutputPlus out)
1:a991b64:     throws IOException
1:1e92ce4:     {
2:a991b64:         if (hasComplexDeletion)
1:80a141c:             header.writeDeletionTime(data.complexDeletion(), out);
1:a991b64: 
1:0d74c3e:         out.writeUnsignedVInt(data.cellsCount());
1:2457599:         for (Cell cell : data)
1:e4c344c:             Cell.serializer.serialize(cell, column, out, rowLiveness, header);
1:2457599:     }
1:a991b64: 
1:6584331:     private void serialize(RangeTombstoneMarker marker, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
1:a991b64:     throws IOException
1:665f747:     {
1:a991b64:         out.writeByte((byte)IS_MARKER);
1:2cc26eb:         ClusteringBoundOrBoundary.serializer.serialize(marker.clustering(), out, version, header.clusteringTypes());
1:a991b64: 
1:6584331:         if (header.isForSSTable())
1:6584331:         {
1:6584331:             out.writeUnsignedVInt(serializedMarkerBodySize(marker, header, previousUnfilteredSize, version));
1:6584331:             out.writeUnsignedVInt(previousUnfilteredSize);
1:6584331:         }
1:6584331: 
1:a991b64:         if (marker.isBoundary())
1:665f747:         {
1:a991b64:             RangeTombstoneBoundaryMarker bm = (RangeTombstoneBoundaryMarker)marker;
1:c055ab9:             header.writeDeletionTime(bm.endDeletionTime(), out);
1:c055ab9:             header.writeDeletionTime(bm.startDeletionTime(), out);
1:a991b64:         }
1:a991b64:         else
1:2457599:         {
1:c055ab9:             header.writeDeletionTime(((RangeTombstoneBoundMarker)marker).deletionTime(), out);
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:03f72ac:     public long serializedSize(Unfiltered unfiltered, SerializationHeader header, int version)
1:2457599:     {
1:6584331:         assert !header.isForSSTable();
1:6584331:         return serializedSize(unfiltered, header, 0, version);
1:a991b64:     }
1:a991b64: 
1:6584331:     public long serializedSize(Unfiltered unfiltered, SerializationHeader header, long previousUnfilteredSize,int version)
1:6584331:     {
1:6584331:         return unfiltered.kind() == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER
1:6584331:              ? serializedSize((RangeTombstoneMarker) unfiltered, header, previousUnfilteredSize, version)
1:6584331:              : serializedSize((Row) unfiltered, header, previousUnfilteredSize, version);
1:6584331:     }
1:6584331: 
1:6584331:     private long serializedSize(Row row, SerializationHeader header, long previousUnfilteredSize, int version)
1:a991b64:     {
2:a991b64:         long size = 1; // flags
1:a991b64: 
1:6584331:         if (hasExtendedFlags(row))
1:6584331:             size += 1; // extended flags
1:6584331: 
1:6584331:         if (!row.isStatic())
1:6584331:             size += Clustering.serializer.serializedSize(row.clustering(), version, header.clusteringTypes());
1:6584331: 
1:6584331:         return size + serializedRowBodySize(row, header, previousUnfilteredSize, version);
1:6584331:     }
1:6584331: 
1:6584331:     private long serializedRowBodySize(Row row, SerializationHeader header, long previousUnfilteredSize, int version)
1:6584331:     {
1:6584331:         long size = 0;
1:6584331: 
1:6584331:         if (header.isForSSTable())
1:6584331:             size += TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize);
1:6584331: 
2:a991b64:         boolean isStatic = row.isStatic();
1:0d74c3e:         Columns headerColumns = header.columns(isStatic);
1:a991b64:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
1:665f747:         Row.Deletion deletion = row.deletion();
1:a991b64:         boolean hasComplexDeletion = row.hasComplexDeletion();
1:0d74c3e:         boolean hasAllColumns = (row.size() == headerColumns.size());
1:a991b64: 
1:2457599:         if (!pkLiveness.isEmpty())
1:c055ab9:             size += header.timestampSerializedSize(pkLiveness.timestamp());
1:2457599:         if (pkLiveness.isExpiring())
1:a991b64:         {
1:c055ab9:             size += header.ttlSerializedSize(pkLiveness.ttl());
1:c055ab9:             size += header.localDeletionTimeSerializedSize(pkLiveness.localExpirationTime());
1:a991b64:         }
1:a991b64:         if (!deletion.isLive())
1:665f747:             size += header.deletionTimeSerializedSize(deletion.time());
1:a991b64: 
1:0d74c3e:         if (!hasAllColumns)
1:0d74c3e:             size += Columns.serializer.serializedSubsetSize(Collections2.transform(row, ColumnData::column), header.columns(isStatic));
1:e4c344c: 
1:e4c344c:         SearchIterator<ColumnDefinition, ColumnDefinition> si = headerColumns.iterator();
1:0d74c3e:         for (ColumnData data : row)
1:a991b64:         {
1:e4c344c:             ColumnDefinition column = si.next(data.column());
1:e4c344c:             assert column != null;
1:e4c344c: 
1:0d74c3e:             if (data.column.isSimple())
1:e4c344c:                 size += Cell.serializer.serializedSize((Cell) data, column, pkLiveness, header);
1:a991b64:             else
1:e4c344c:                 size += sizeOfComplexColumn((ComplexColumnData) data, column, hasComplexDeletion, pkLiveness, header);
1:a991b64:         }
1:a991b64: 
5:a991b64:         return size;
1:2457599:     }
1:2457599: 
1:e4c344c:     private long sizeOfComplexColumn(ComplexColumnData data, ColumnDefinition column, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header)
1:2457599:     {
1:2457599:         long size = 0;
1:2457599: 
1:a991b64:         if (hasComplexDeletion)
1:80a141c:             size += header.deletionTimeSerializedSize(data.complexDeletion());
1:a991b64: 
1:0d74c3e:         size += TypeSizes.sizeofUnsignedVInt(data.cellsCount());
1:2457599:         for (Cell cell : data)
1:e4c344c:             size += Cell.serializer.serializedSize(cell, column, rowLiveness, header);
1:a991b64: 
1:2457599:         return size;
1:2457599:     }
1:a991b64: 
1:6584331:     private long serializedSize(RangeTombstoneMarker marker, SerializationHeader header, long previousUnfilteredSize, int version)
1:2457599:     {
1:6584331:         assert !header.isForSSTable();
1:6584331:         return 1 // flags
1:2cc26eb:              + ClusteringBoundOrBoundary.serializer.serializedSize(marker.clustering(), version, header.clusteringTypes())
1:6584331:              + serializedMarkerBodySize(marker, header, previousUnfilteredSize, version);
1:6584331:     }
1:6584331: 
1:6584331:     private long serializedMarkerBodySize(RangeTombstoneMarker marker, SerializationHeader header, long previousUnfilteredSize, int version)
1:6584331:     {
1:6584331:         long size = 0;
1:6584331:         if (header.isForSSTable())
1:6584331:             size += TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize);
1:a991b64: 
1:a991b64:         if (marker.isBoundary())
1:a991b64:         {
1:a991b64:             RangeTombstoneBoundaryMarker bm = (RangeTombstoneBoundaryMarker)marker;
1:c055ab9:             size += header.deletionTimeSerializedSize(bm.endDeletionTime());
1:c055ab9:             size += header.deletionTimeSerializedSize(bm.startDeletionTime());
1:a991b64:         }
1:a991b64:         else
1:a991b64:         {
1:c055ab9:            size += header.deletionTimeSerializedSize(((RangeTombstoneBoundMarker)marker).deletionTime());
1:a991b64:         }
1:a991b64:         return size;
1:a991b64:     }
1:a991b64: 
1:a991b64:     public void writeEndOfPartition(DataOutputPlus out) throws IOException
1:a991b64:     {
1:a991b64:         out.writeByte((byte)1);
1:a991b64:     }
1:a991b64: 
1:03f72ac:     public long serializedSizeEndOfPartition()
1:a991b64:     {
1:a991b64:         return 1;
1:a991b64:     }
1:a991b64: 
1:2457599:     public Unfiltered deserialize(DataInputPlus in, SerializationHeader header, SerializationHelper helper, Row.Builder builder)
1:a991b64:     throws IOException
1:a991b64:     {
1:2457599:         // It wouldn't be wrong per-se to use an unsorted builder, but it would be inefficient so make sure we don't do it by mistake
1:2457599:         assert builder.isSorted();
1:2457599: 
1:2457599:         int flags = in.readUnsignedByte();
1:a991b64:         if (isEndOfPartition(flags))
1:a991b64:             return null;
1:665f747: 
1:6584331:         int extendedFlags = readExtendedFlags(in, flags);
1:2457599: 
1:a991b64:         if (kind(flags) == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:2457599:         {
1:2cc26eb:             ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:2457599:             return deserializeMarkerBody(in, header, bound);
1:2457599:         }
1:2457599:         else
1:2457599:         {
1:85cc390:             // deserializeStaticRow should be used for that.
1:85cc390:             if (isStatic(extendedFlags))
1:85cc390:                 throw new IOException("Corrupt flags value for unfiltered partition (isStatic flag set): " + flags);
1:a991b64: 
1:2457599:             builder.newRow(Clustering.serializer.deserialize(in, helper.version, header.clusteringTypes()));
1:85cc390:             Row row = deserializeRowBody(in, header, helper, flags, extendedFlags, builder);
1:85cc390:             // we do not write empty rows because Rows.collectStats(), called by BTW.applyToRow(), asserts that rows are not empty
1:85cc390:             // if we don't throw here, then later the very same assertion in Rows.collectStats() will fail compactions
1:85cc390:             // see BlackListingCompactionsTest and CASSANDRA-9530 for details
1:85cc390:             if (row.isEmpty())
1:85cc390:                 throw new IOException("Corrupt empty row found in unfiltered partition");
1:85cc390:             return row;
1:2457599:         }
1:a991b64:     }
1:a991b64: 
1:d40ac78:     public Unfiltered deserializeTombstonesOnly(FileDataInput in, SerializationHeader header, SerializationHelper helper)
1:d40ac78:     throws IOException
1:d40ac78:     {
1:d40ac78:         while (true)
1:d40ac78:         {
1:d40ac78:             int flags = in.readUnsignedByte();
1:d40ac78:             if (isEndOfPartition(flags))
1:d40ac78:                 return null;
1:d40ac78: 
1:d40ac78:             int extendedFlags = readExtendedFlags(in, flags);
1:d40ac78: 
1:d40ac78:             if (kind(flags) == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:d40ac78:             {
1:d40ac78:                 ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:d40ac78:                 return deserializeMarkerBody(in, header, bound);
1:d40ac78:             }
1:d40ac78:             else
1:a991b64:             {
1:d40ac78:                 assert !isStatic(extendedFlags); // deserializeStaticRow should be used for that.
1:d40ac78:                 if ((flags & HAS_DELETION) != 0)
1:d40ac78:                 {
1:d40ac78:                     assert header.isForSSTable();
1:d40ac78:                     boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
1:d40ac78:                     boolean hasTTL = (flags & HAS_TTL) != 0;
1:d40ac78:                     boolean deletionIsShadowable = (extendedFlags & HAS_SHADOWABLE_DELETION) != 0;
1:d40ac78:                     Clustering clustering = Clustering.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:d40ac78:                     long nextPosition = in.readUnsignedVInt() + in.getFilePointer();
1:d40ac78:                     in.readUnsignedVInt(); // skip previous unfiltered size
1:d40ac78:                     if (hasTimestamp)
1:d40ac78:                     {
1:d40ac78:                         header.readTimestamp(in);
1:d40ac78:                         if (hasTTL)
1:d40ac78:                         {
1:d40ac78:                             header.readTTL(in);
1:d40ac78:                             header.readLocalDeletionTime(in);
1:d40ac78:                         }
1:d40ac78:                     }
1:d40ac78: 
1:d40ac78:                     Deletion deletion = new Row.Deletion(header.readDeletionTime(in), deletionIsShadowable);
1:d40ac78:                     in.seek(nextPosition);
1:d40ac78:                     return BTreeRow.emptyDeletedRow(clustering, deletion);
1:d40ac78:                 }
1:d40ac78:                 else
1:d40ac78:                 {
1:d40ac78:                     Clustering.serializer.skip(in, helper.version, header.clusteringTypes());
1:d40ac78:                     skipRowBody(in);
1:d40ac78:                     // Continue with next item.
1:d40ac78:                 }
1:d40ac78:             }
1:d40ac78:         }
1:d40ac78:     }
1:d40ac78: 
1:2457599:     public Row deserializeStaticRow(DataInputPlus in, SerializationHeader header, SerializationHelper helper)
1:a991b64:     throws IOException
1:a991b64:     {
4:a991b64:         int flags = in.readUnsignedByte();
1:665f747:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isExtended(flags) : flags;
1:665f747:         int extendedFlags = in.readUnsignedByte();
1:aa57626:         Row.Builder builder = BTreeRow.sortedBuilder();
1:2457599:         builder.newRow(Clustering.STATIC_CLUSTERING);
1:665f747:         return deserializeRowBody(in, header, helper, flags, extendedFlags, builder);
1:a991b64:     }
1:a991b64: 
1:2cc26eb:     public RangeTombstoneMarker deserializeMarkerBody(DataInputPlus in, SerializationHeader header, ClusteringBoundOrBoundary bound)
1:a991b64:     throws IOException
1:a991b64:     {
1:6584331:         if (header.isForSSTable())
1:a991b64:         {
1:6584331:             in.readUnsignedVInt(); // marker size
1:6584331:             in.readUnsignedVInt(); // previous unfiltered size
1:6584331:         }
1:6584331: 
1:2457599:         if (bound.isBoundary())
1:2cc26eb:             return new RangeTombstoneBoundaryMarker((ClusteringBoundary) bound, header.readDeletionTime(in), header.readDeletionTime(in));
1:2457599:         else
1:2cc26eb:             return new RangeTombstoneBoundMarker((ClusteringBound) bound, header.readDeletionTime(in));
1:a991b64:     }
1:2457599: 
1:2457599:     public Row deserializeRowBody(DataInputPlus in,
1:2457599:                                   SerializationHeader header,
1:2457599:                                   SerializationHelper helper,
1:2457599:                                   int flags,
1:665f747:                                   int extendedFlags,
1:2457599:                                   Row.Builder builder)
1:a991b64:     throws IOException
1:a991b64:     {
1:1e92ce4:         try
1:a991b64:         {
1:665f747:             boolean isStatic = isStatic(extendedFlags);
1:2457599:             boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
1:2457599:             boolean hasTTL = (flags & HAS_TTL) != 0;
1:2457599:             boolean hasDeletion = (flags & HAS_DELETION) != 0;
1:665f747:             boolean deletionIsShadowable = (extendedFlags & HAS_SHADOWABLE_DELETION) != 0;
1:2457599:             boolean hasComplexDeletion = (flags & HAS_COMPLEX_DELETION) != 0;
1:0d74c3e:             boolean hasAllColumns = (flags & HAS_ALL_COLUMNS) != 0;
1:0d74c3e:             Columns headerColumns = header.columns(isStatic);
1:2457599: 
1:6584331:             if (header.isForSSTable())
1:6584331:             {
1:6584331:                 in.readUnsignedVInt(); // Skip row size
1:6584331:                 in.readUnsignedVInt(); // previous unfiltered size
1:6584331:             }
1:6584331: 
1:2457599:             LivenessInfo rowLiveness = LivenessInfo.EMPTY;
1:2457599:             if (hasTimestamp)
1:2457599:             {
1:c055ab9:                 long timestamp = header.readTimestamp(in);
1:c055ab9:                 int ttl = hasTTL ? header.readTTL(in) : LivenessInfo.NO_TTL;
1:c055ab9:                 int localDeletionTime = hasTTL ? header.readLocalDeletionTime(in) : LivenessInfo.NO_EXPIRATION_TIME;
1:e017f94:                 rowLiveness = LivenessInfo.withExpirationTime(timestamp, ttl, localDeletionTime);
1:2457599:             }
1:2457599: 
1:2457599:             builder.addPrimaryKeyLivenessInfo(rowLiveness);
1:665f747:             builder.addRowDeletion(hasDeletion ? new Row.Deletion(header.readDeletionTime(in), deletionIsShadowable) : Row.Deletion.LIVE);
1:2457599: 
1:0d74c3e:             Columns columns = hasAllColumns ? headerColumns : Columns.serializer.deserializeSubset(headerColumns, in);
1:dc9ed46: 
1:dc9ed46:             final LivenessInfo livenessInfo = rowLiveness;
1:dc9ed46: 
1:dc9ed46:             try
1:2457599:             {
1:dc9ed46:                 columns.apply(column -> {
1:dc9ed46:                     try
1:dc9ed46:                     {
1:dc9ed46:                         if (column.isSimple())
1:dc9ed46:                             readSimpleColumn(column, in, header, helper, builder, livenessInfo);
1:dc9ed46:                         else
1:dc9ed46:                             readComplexColumn(column, in, header, helper, hasComplexDeletion, builder, livenessInfo);
1:dc9ed46:                     }
1:dc9ed46:                     catch (IOException e)
1:dc9ed46:                     {
1:dc9ed46:                         throw new WrappedException(e);
1:dc9ed46:                     }
1:dc9ed46:                 }, false);
1:dc9ed46:             }
1:dc9ed46:             catch (WrappedException e)
1:dc9ed46:             {
1:dc9ed46:                 if (e.getCause() instanceof IOException)
1:dc9ed46:                     throw (IOException) e.getCause();
1:dc9ed46: 
1:dc9ed46:                 throw e;
1:2457599:             }
1:2457599: 
1:2457599:             return builder.build();
1:2457599:         }
1:2457599:         catch (RuntimeException | AssertionError e)
1:2457599:         {
1:2457599:             // Corrupted data could be such that it triggers an assertion in the row Builder, or break one of its assumption.
1:2457599:             // Of course, a bug in said builder could also trigger this, but it's impossible a priori to always make the distinction
1:2457599:             // between a real bug and data corrupted in just the bad way. Besides, re-throwing as an IOException doesn't hide the
1:2457599:             // exception, it just make we catch it properly and mark the sstable as corrupted.
1:2457599:             throw new IOException("Error building row with data deserialized from " + in, e);
1:a991b64:         }
1:a991b64:     }
1:2457599: 
1:2457599:     private void readSimpleColumn(ColumnDefinition column, DataInputPlus in, SerializationHeader header, SerializationHelper helper, Row.Builder builder, LivenessInfo rowLiveness)
1:a991b64:     throws IOException
1:a991b64:     {
1:a991b64:         if (helper.includes(column))
1:2457599:         {
1:2457599:             Cell cell = Cell.serializer.deserialize(in, rowLiveness, column, header, helper);
1:fd74a03:             if (helper.includes(cell, rowLiveness) && !helper.isDropped(cell, false))
1:2457599:                 builder.addCell(cell);
1:2457599:         }
1:2457599:         else
1:2457599:         {
1:2457599:             Cell.serializer.skip(in, column, header);
1:2457599:         }
1:a991b64:     }
1:a991b64: 
1:2457599:     private void readComplexColumn(ColumnDefinition column, DataInputPlus in, SerializationHeader header, SerializationHelper helper, boolean hasComplexDeletion, Row.Builder builder, LivenessInfo rowLiveness)
1:a991b64:     throws IOException
1:a991b64:     {
1:a991b64:         if (helper.includes(column))
1:a991b64:         {
1:a991b64:             helper.startOfComplexColumn(column);
1:a991b64:             if (hasComplexDeletion)
1:2457599:             {
1:c055ab9:                 DeletionTime complexDeletion = header.readDeletionTime(in);
1:2457599:                 if (!helper.isDroppedComplexDeletion(complexDeletion))
1:2457599:                     builder.addComplexDeletion(column, complexDeletion);
1:2457599:             }
1:a991b64: 
1:0d74c3e:             int count = (int) in.readUnsignedVInt();
1:0d74c3e:             while (--count >= 0)
1:2457599:             {
1:0d74c3e:                 Cell cell = Cell.serializer.deserialize(in, rowLiveness, column, header, helper);
1:fd74a03:                 if (helper.includes(cell, rowLiveness) && !helper.isDropped(cell, true))
1:2457599:                     builder.addCell(cell);
1:2457599:             }
1:a991b64: 
1:2457599:             helper.endOfComplexColumn();
1:a991b64:         }
1:a991b64:         else
1:a991b64:         {
1:2457599:             skipComplexColumn(in, column, header, hasComplexDeletion);
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:6584331:     public void skipRowBody(DataInputPlus in) throws IOException
1:a991b64:     {
1:6584331:         int rowSize = (int)in.readUnsignedVInt();
1:6584331:         in.skipBytesFully(rowSize);
1:a991b64:     }
1:a991b64: 
1:2457599:     public void skipStaticRow(DataInputPlus in, SerializationHeader header, SerializationHelper helper) throws IOException
1:2457599:     {
1:a991b64:         int flags = in.readUnsignedByte();
1:665f747:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isExtended(flags) : "Flags is " + flags;
1:665f747:         int extendedFlags = in.readUnsignedByte();
1:665f747:         assert isStatic(extendedFlags);
1:6584331:         skipRowBody(in);
1:2457599:     }
1:2457599: 
1:6584331:     public void skipMarkerBody(DataInputPlus in) throws IOException
1:a991b64:     {
1:6584331:         int markerSize = (int)in.readUnsignedVInt();
1:6584331:         in.skipBytesFully(markerSize);
1:2457599:     }
1:a991b64: 
1:2457599:     private void skipComplexColumn(DataInputPlus in, ColumnDefinition column, SerializationHeader header, boolean hasComplexDeletion)
1:a991b64:     throws IOException
1:a991b64:     {
1:a991b64:         if (hasComplexDeletion)
1:c055ab9:             header.skipDeletionTime(in);
1:a991b64: 
1:0d74c3e:         int count = (int) in.readUnsignedVInt();
1:0d74c3e:         while (--count >= 0)
1:0d74c3e:             Cell.serializer.skip(in, column, header);
1:a991b64:     }
1:a991b64: 
1:a991b64:     public static boolean isEndOfPartition(int flags)
1:a991b64:     {
1:a991b64:         return (flags & END_OF_PARTITION) != 0;
1:a991b64:     }
1:a991b64: 
1:a991b64:     public static Unfiltered.Kind kind(int flags)
1:a991b64:     {
1:a991b64:         return (flags & IS_MARKER) != 0 ? Unfiltered.Kind.RANGE_TOMBSTONE_MARKER : Unfiltered.Kind.ROW;
1:a991b64:     }
1:a991b64: 
1:665f747:     public static boolean isStatic(int extendedFlags)
1:a991b64:     {
1:665f747:         return (extendedFlags & IS_STATIC) != 0;
1:665f747:     }
1:665f747: 
1:6584331:     private static boolean isExtended(int flags)
1:665f747:     {
1:665f747:         return (flags & EXTENSION_FLAG) != 0;
1:a991b64:     }
1:6584331: 
1:6584331:     public static int readExtendedFlags(DataInputPlus in, int flags) throws IOException
1:6584331:     {
1:6584331:         return isExtended(flags) ? in.readUnsignedByte() : 0;
1:6584331:     }
1:6584331: 
1:6584331:     public static boolean hasExtendedFlags(Row row)
1:6584331:     {
1:6584331:         return row.isStatic() || row.deletion().isShadowable();
1:6584331:     }
1:a991b64: }
============================================================================
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:05660a5
/////////////////////////////////////////////////////////////////////////
1:             try (DataOutputBuffer dob = DataOutputBuffer.scratchBuffer.get())
/////////////////////////////////////////////////////////////////////////
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:d40ac78
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.rows.Row.Deletion;
1: import org.apache.cassandra.io.util.FileDataInput;
/////////////////////////////////////////////////////////////////////////
1:     public Unfiltered deserializeTombstonesOnly(FileDataInput in, SerializationHeader header, SerializationHelper helper)
1:     throws IOException
1:     {
1:         while (true)
1:         {
1:             int flags = in.readUnsignedByte();
1:             if (isEndOfPartition(flags))
1:                 return null;
1: 
1:             int extendedFlags = readExtendedFlags(in, flags);
1: 
1:             if (kind(flags) == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:             {
1:                 ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:                 return deserializeMarkerBody(in, header, bound);
1:             }
1:             else
1:             {
1:                 assert !isStatic(extendedFlags); // deserializeStaticRow should be used for that.
1:                 if ((flags & HAS_DELETION) != 0)
1:                 {
1:                     assert header.isForSSTable();
1:                     boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
1:                     boolean hasTTL = (flags & HAS_TTL) != 0;
1:                     boolean deletionIsShadowable = (extendedFlags & HAS_SHADOWABLE_DELETION) != 0;
1:                     Clustering clustering = Clustering.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:                     long nextPosition = in.readUnsignedVInt() + in.getFilePointer();
1:                     in.readUnsignedVInt(); // skip previous unfiltered size
1:                     if (hasTimestamp)
1:                     {
1:                         header.readTimestamp(in);
1:                         if (hasTTL)
1:                         {
1:                             header.readTTL(in);
1:                             header.readLocalDeletionTime(in);
1:                         }
1:                     }
1: 
1:                     Deletion deletion = new Row.Deletion(header.readDeletionTime(in), deletionIsShadowable);
1:                     in.seek(nextPosition);
1:                     return BTreeRow.emptyDeletedRow(clustering, deletion);
1:                 }
1:                 else
1:                 {
1:                     Clustering.serializer.skip(in, helper.version, header.clusteringTypes());
1:                     skipRowBody(in);
1:                     // Continue with next item.
1:                 }
1:             }
1:         }
1:     }
1: 
commit:2cc26eb
/////////////////////////////////////////////////////////////////////////
0:  *       by {@code ClusteringBoundOrBoundary.serializer} and <deletion> is the marker deletion
/////////////////////////////////////////////////////////////////////////
1:         ClusteringBoundOrBoundary.serializer.serialize(marker.clustering(), out, version, header.clusteringTypes());
/////////////////////////////////////////////////////////////////////////
1:              + ClusteringBoundOrBoundary.serializer.serializedSize(marker.clustering(), version, header.clusteringTypes())
/////////////////////////////////////////////////////////////////////////
1:             ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.serializer.deserialize(in, helper.version, header.clusteringTypes());
/////////////////////////////////////////////////////////////////////////
1:     public RangeTombstoneMarker deserializeMarkerBody(DataInputPlus in, SerializationHeader header, ClusteringBoundOrBoundary bound)
/////////////////////////////////////////////////////////////////////////
1:             return new RangeTombstoneBoundaryMarker((ClusteringBoundary) bound, header.readDeletionTime(in), header.readDeletionTime(in));
1:             return new RangeTombstoneBoundMarker((ClusteringBound) bound, header.readDeletionTime(in));
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:dc9ed46
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.WrappedException;
/////////////////////////////////////////////////////////////////////////
0:             DataOutputBuffer dob = DataOutputBuffer.scratchBuffer.get();
/////////////////////////////////////////////////////////////////////////
1:                 out.write(dob.getData(), 0, dob.getLength());
/////////////////////////////////////////////////////////////////////////
1:         try
1:         {
1:             row.apply(cd -> {
1:                 // We can obtain the column for data directly from data.column(). However, if the cell/complex data
1:                 // originates from a sstable, the column we'll get will have the type used when the sstable was serialized,
1:                 // and if that type have been recently altered, that may not be the type we want to serialize the column
1:                 // with. So we use the ColumnDefinition from the "header" which is "current". Also see #11810 for what
1:                 // happens if we don't do that.
1:                 ColumnDefinition column = si.next(cd.column());
1:                 assert column != null : cd.column.toString();
1: 
1:                 try
1:                 {
1:                     if (cd.column.isSimple())
1:                         Cell.serializer.serialize((Cell) cd, column, out, pkLiveness, header);
1:                     else
1:                         writeComplexColumn((ComplexColumnData) cd, column, (flags & HAS_COMPLEX_DELETION) != 0, pkLiveness, header, out);
1:                 }
1:                 catch (IOException e)
1:                 {
1:                     throw new WrappedException(e);
1:                 }
1:             }, false);
1:         }
1:         catch (WrappedException e)
1:         {
1:             if (e.getCause() instanceof IOException)
1:                 throw (IOException) e.getCause();
1: 
1:             throw e;
/////////////////////////////////////////////////////////////////////////
1: 
1:             final LivenessInfo livenessInfo = rowLiveness;
1: 
1:             try
1:                 columns.apply(column -> {
1:                     try
1:                     {
1:                         if (column.isSimple())
1:                             readSimpleColumn(column, in, header, helper, builder, livenessInfo);
1:                         else
1:                             readComplexColumn(column, in, header, helper, hasComplexDeletion, builder, livenessInfo);
1:                     }
1:                     catch (IOException e)
1:                     {
1:                         throw new WrappedException(e);
1:                     }
1:                 }, false);
1:             }
1:             catch (WrappedException e)
1:             {
1:                 if (e.getCause() instanceof IOException)
1:                     throw (IOException) e.getCause();
1: 
1:                 throw e;
commit:1e92ce4
/////////////////////////////////////////////////////////////////////////
1: import net.nicoulaj.compilecommand.annotations.Inline;
1: import org.apache.cassandra.io.util.DataOutputBuffer;
/////////////////////////////////////////////////////////////////////////
0:             DataOutputBuffer dob = DataOutputBuffer.RECYCLER.get();
1:             try
1:             {
1:                 serializeRowBody(row, flags, header, dob);
1: 
1:                 out.writeUnsignedVInt(dob.position() + TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize));
1:                 // We write the size of the previous unfiltered to make reverse queries more efficient (and simpler).
1:                 // This is currently not used however and using it is tbd.
1:                 out.writeUnsignedVInt(previousUnfilteredSize);
0:                 out.write(dob.buffer());
1:             }
0:             finally
1:             {
0:                 dob.recycle();
1:             }
1:         else
1:         {
1:             serializeRowBody(row, flags, header, out);
1:         }
1:     }
1: 
1:     @Inline
1:     private void serializeRowBody(Row row, int flags, SerializationHeader header, DataOutputPlus out)
1:     throws IOException
1:     {
1:         boolean isStatic = row.isStatic();
1: 
1:         Columns headerColumns = header.columns(isStatic);
1:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
1:         Row.Deletion deletion = row.deletion();
/////////////////////////////////////////////////////////////////////////
1:         if ((flags & HAS_ALL_COLUMNS) == 0)
/////////////////////////////////////////////////////////////////////////
0:                 writeComplexColumn((ComplexColumnData) data, (flags & HAS_COMPLEX_DELETION) != 0, pkLiveness, header, out);
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:1f014b2
commit:e4c344c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.SearchIterator;
/////////////////////////////////////////////////////////////////////////
1:         SearchIterator<ColumnDefinition, ColumnDefinition> si = headerColumns.iterator();
0:             // We can obtain the column for data directly from data.column(). However, if the cell/complex data
0:             // originates from a sstable, the column we'll get will have the type used when the sstable was serialized,
0:             // and if that type have been recently altered, that may not be the type we want to serialize the column
0:             // with. So we use the ColumnDefinition from the "header" which is "current". Also see #11810 for what
0:             // happens if we don't do that.
1:             ColumnDefinition column = si.next(data.column());
1:             assert column != null;
1: 
0:                 Cell.serializer.serialize((Cell) data, column, out, pkLiveness, header);
0:                 writeComplexColumn((ComplexColumnData) data, column, hasComplexDeletion, pkLiveness, header, out);
1:     private void writeComplexColumn(ComplexColumnData data, ColumnDefinition column, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header, DataOutputPlus out)
/////////////////////////////////////////////////////////////////////////
1:             Cell.serializer.serialize(cell, column, out, rowLiveness, header);
/////////////////////////////////////////////////////////////////////////
1:         SearchIterator<ColumnDefinition, ColumnDefinition> si = headerColumns.iterator();
0:             ColumnDefinition column = si.next(data.column());
0:             assert column != null;
1: 
1:                 size += Cell.serializer.serializedSize((Cell) data, column, pkLiveness, header);
1:                 size += sizeOfComplexColumn((ComplexColumnData) data, column, hasComplexDeletion, pkLiveness, header);
1:     private long sizeOfComplexColumn(ComplexColumnData data, ColumnDefinition column, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header)
/////////////////////////////////////////////////////////////////////////
1:             size += Cell.serializer.serializedSize(cell, column, rowLiveness, header);
commit:fd74a03
/////////////////////////////////////////////////////////////////////////
1:             if (helper.includes(cell, rowLiveness) && !helper.isDropped(cell, false))
/////////////////////////////////////////////////////////////////////////
1:                 if (helper.includes(cell, rowLiveness) && !helper.isDropped(cell, true))
commit:6584331
/////////////////////////////////////////////////////////////////////////
0:  *   <row> is <clustering><size>[<timestamp>][<ttl>][<deletion>]<sc1>...<sci><cc1>...<ccj> where
0:  *       <clustering> is the row clustering as serialized by {@code Clustering.serializer} (note
0:  *       that static row are an exception and don't have this).
0:  *       <size> is the size of the whole unfiltered on disk (it's only used for sstables and is
0:  *       used to efficiently skip rows).
0:  *       <timestamp>, <ttl> and <deletion> are the row timestamp, ttl and deletion
/////////////////////////////////////////////////////////////////////////
1:         assert !header.isForSSTable();
1:         serialize(unfiltered, header, out, 0, version);
1:     }
1: 
1:     public void serialize(Unfiltered unfiltered, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
1:     throws IOException
1:     {
1:             serialize((RangeTombstoneMarker) unfiltered, header, out, previousUnfilteredSize, version);
1:             serialize((Row) unfiltered, header, out, previousUnfilteredSize, version);
1:     public void serializeStaticRow(Row row, SerializationHeader header, DataOutputPlus out, int version)
1:     throws IOException
1:     {
1:         assert row.isStatic();
1:         serialize(row, header, out, 0, version);
1:     }
1: 
1:     private void serialize(Row row, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
/////////////////////////////////////////////////////////////////////////
1:         boolean hasExtendedFlags = hasExtendedFlags(row);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         if (header.isForSSTable())
1:         {
0:             out.writeUnsignedVInt(serializedRowBodySize(row, header, previousUnfilteredSize, version));
1:             out.writeUnsignedVInt(previousUnfilteredSize);
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:     private void serialize(RangeTombstoneMarker marker, SerializationHeader header, DataOutputPlus out, long previousUnfilteredSize, int version)
1:         if (header.isForSSTable())
1:         {
1:             out.writeUnsignedVInt(serializedMarkerBodySize(marker, header, previousUnfilteredSize, version));
0:             out.writeUnsignedVInt(previousUnfilteredSize);
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:         assert !header.isForSSTable();
1:         return serializedSize(unfiltered, header, 0, version);
1:     public long serializedSize(Unfiltered unfiltered, SerializationHeader header, long previousUnfilteredSize,int version)
1:     {
1:         return unfiltered.kind() == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER
1:              ? serializedSize((RangeTombstoneMarker) unfiltered, header, previousUnfilteredSize, version)
1:              : serializedSize((Row) unfiltered, header, previousUnfilteredSize, version);
1:     }
1: 
1:     private long serializedSize(Row row, SerializationHeader header, long previousUnfilteredSize, int version)
1:         if (hasExtendedFlags(row))
1:             size += 1; // extended flags
1: 
1:         if (!row.isStatic())
1:             size += Clustering.serializer.serializedSize(row.clustering(), version, header.clusteringTypes());
1: 
1:         return size + serializedRowBodySize(row, header, previousUnfilteredSize, version);
1:     }
1: 
1:     private long serializedRowBodySize(Row row, SerializationHeader header, long previousUnfilteredSize, int version)
1:     {
1:         long size = 0;
1: 
1:         if (header.isForSSTable())
1:             size += TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize);
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     private long serializedSize(RangeTombstoneMarker marker, SerializationHeader header, long previousUnfilteredSize, int version)
1:         assert !header.isForSSTable();
1:         return 1 // flags
0:              + RangeTombstone.Bound.serializer.serializedSize(marker.clustering(), version, header.clusteringTypes())
1:              + serializedMarkerBodySize(marker, header, previousUnfilteredSize, version);
1:     }
1: 
1:     private long serializedMarkerBodySize(RangeTombstoneMarker marker, SerializationHeader header, long previousUnfilteredSize, int version)
1:     {
1:         long size = 0;
1:         if (header.isForSSTable())
1:             size += TypeSizes.sizeofUnsignedVInt(previousUnfilteredSize);
/////////////////////////////////////////////////////////////////////////
1:         int extendedFlags = readExtendedFlags(in, flags);
/////////////////////////////////////////////////////////////////////////
1:         if (header.isForSSTable())
1:         {
1:             in.readUnsignedVInt(); // marker size
1:             in.readUnsignedVInt(); // previous unfiltered size
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:             if (header.isForSSTable())
1:             {
1:                 in.readUnsignedVInt(); // Skip row size
1:                 in.readUnsignedVInt(); // previous unfiltered size
1:             }
1: 
/////////////////////////////////////////////////////////////////////////
1:     public void skipRowBody(DataInputPlus in) throws IOException
1:         int rowSize = (int)in.readUnsignedVInt();
1:         in.skipBytesFully(rowSize);
/////////////////////////////////////////////////////////////////////////
1:         skipRowBody(in);
1:     public void skipMarkerBody(DataInputPlus in) throws IOException
1:         int markerSize = (int)in.readUnsignedVInt();
1:         in.skipBytesFully(markerSize);
/////////////////////////////////////////////////////////////////////////
1:     private static boolean isExtended(int flags)
1: 
1:     public static int readExtendedFlags(DataInputPlus in, int flags) throws IOException
1:     {
1:         return isExtended(flags) ? in.readUnsignedByte() : 0;
1:     }
1: 
1:     public static boolean hasExtendedFlags(Row row)
1:     {
1:         return row.isStatic() || row.deletion().isShadowable();
1:     }
commit:665f747
/////////////////////////////////////////////////////////////////////////
0:  *   <flags> is a byte (or two) whose bits are flags used by the rest of the serialization. Each
0:  *       flag is defined/explained below as the "Unfiltered flags" constants. One of those flags
0:  *       is an extension flag, and if present, trigger the rid of another byte that contains more
0:  *       flags. If the extension is not set, defaults are assumed for the flags of that 2nd byte.
/////////////////////////////////////////////////////////////////////////
1:     private final static int HAS_TIMESTAMP        = 0x04; // Whether the encoded row has a timestamp (i.e. if row.partitionKeyLivenessInfo().hasTimestamp() == true).
1:     private final static int HAS_TTL              = 0x08; // Whether the encoded row has some expiration info (i.e. if row.partitionKeyLivenessInfo().hasTTL() == true).
1:     private final static int HAS_DELETION         = 0x10; // Whether the encoded row has some deletion info.
1:     private final static int HAS_ALL_COLUMNS      = 0x20; // Whether the encoded row has all of the columns from the header present.
1:     private final static int EXTENSION_FLAG       = 0x80; // If present, another byte is read containing the "extended flags" above.
1: 
1:     /*
1:      * Extended flags
1:      */
1:     private final static int IS_STATIC               = 0x01; // Whether the encoded row is a static. If there is no extended flag, the row is assumed not static.
1:     private final static int HAS_SHADOWABLE_DELETION = 0x02; // Whether the row deletion is shadowable. If there is no extended flag (or no row deletion), the deletion is assumed not shadowable.
/////////////////////////////////////////////////////////////////////////
1:         int extendedFlags = 0;
0:         boolean hasExtendedFlags = false;
1:         boolean isStatic = row.isStatic();
1:         Row.Deletion deletion = row.deletion();
1:         {
0:             hasExtendedFlags = true;
1:             extendedFlags |= IS_STATIC;
1:         }
1: 
1:         {
1:             if (deletion.isShadowable())
1:             {
0:                 hasExtendedFlags = true;
1:                 extendedFlags |= HAS_SHADOWABLE_DELETION;
1:             }
1:         }
1:         if (hasExtendedFlags)
1:             flags |= EXTENSION_FLAG;
1: 
1:         if (hasExtendedFlags)
1:             out.writeByte((byte)extendedFlags);
1: 
/////////////////////////////////////////////////////////////////////////
1:             header.writeDeletionTime(deletion.time(), out);
/////////////////////////////////////////////////////////////////////////
1:         Row.Deletion deletion = row.deletion();
0:         if (isStatic || deletion.isShadowable())
0:             size += 1; // extended flags
1: 
/////////////////////////////////////////////////////////////////////////
1:             size += header.deletionTimeSerializedSize(deletion.time());
/////////////////////////////////////////////////////////////////////////
0:         int extendedFlags = isExtended(flags) ? in.readUnsignedByte() : 0;
1: 
/////////////////////////////////////////////////////////////////////////
0:             assert !isStatic(extendedFlags); // deserializeStaticRow should be used for that.
1:             return deserializeRowBody(in, header, helper, flags, extendedFlags, builder);
/////////////////////////////////////////////////////////////////////////
1:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isExtended(flags) : flags;
1:         int extendedFlags = in.readUnsignedByte();
0:         return deserializeRowBody(in, header, helper, flags, extendedFlags, builder);
/////////////////////////////////////////////////////////////////////////
1:                                   int extendedFlags,
1:             boolean isStatic = isStatic(extendedFlags);
1:             boolean deletionIsShadowable = (extendedFlags & HAS_SHADOWABLE_DELETION) != 0;
/////////////////////////////////////////////////////////////////////////
1:             builder.addRowDeletion(hasDeletion ? new Row.Deletion(header.readDeletionTime(in), deletionIsShadowable) : Row.Deletion.LIVE);
/////////////////////////////////////////////////////////////////////////
0:     public void skipRowBody(DataInputPlus in, SerializationHeader header, int flags, int extendedFlags) throws IOException
0:         boolean isStatic = isStatic(extendedFlags);
/////////////////////////////////////////////////////////////////////////
1:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isExtended(flags) : "Flags is " + flags;
1:         int extendedFlags = in.readUnsignedByte();
1:         assert isStatic(extendedFlags);
0:         skipRowBody(in, header, flags, extendedFlags);
/////////////////////////////////////////////////////////////////////////
1:     public static boolean isStatic(int extendedFlags)
1:         return (extendedFlags & IS_STATIC) != 0;
1:     }
1: 
0:     public static boolean isExtended(int flags)
1:     {
1:         return (flags & EXTENSION_FLAG) != 0;
commit:a59be26
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(-1);
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(-1);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:                 while ((i = (int)in.readVInt()) >= 0)
/////////////////////////////////////////////////////////////////////////
0:             while ((i = (int)in.readVInt()) >= 0)
commit:c055ab9
/////////////////////////////////////////////////////////////////////////
1:             header.writeTimestamp(pkLiveness.timestamp(), out);
1:             header.writeTTL(pkLiveness.ttl(), out);
1:             header.writeLocalDeletionTime(pkLiveness.localExpirationTime(), out);
0:             header.writeDeletionTime(deletion, out);
/////////////////////////////////////////////////////////////////////////
0:             header.writeDeletionTime(data == null ? DeletionTime.LIVE : data.complexDeletion(), out);
/////////////////////////////////////////////////////////////////////////
1:             header.writeDeletionTime(bm.endDeletionTime(), out);
1:             header.writeDeletionTime(bm.startDeletionTime(), out);
1:             header.writeDeletionTime(((RangeTombstoneBoundMarker)marker).deletionTime(), out);
/////////////////////////////////////////////////////////////////////////
1:             size += header.timestampSerializedSize(pkLiveness.timestamp());
1:             size += header.ttlSerializedSize(pkLiveness.ttl());
1:             size += header.localDeletionTimeSerializedSize(pkLiveness.localExpirationTime());
0:             size += header.deletionTimeSerializedSize(deletion);
/////////////////////////////////////////////////////////////////////////
0:             size += header.deletionTimeSerializedSize(data == null ? DeletionTime.LIVE : data.complexDeletion());
/////////////////////////////////////////////////////////////////////////
1:             size += header.deletionTimeSerializedSize(bm.endDeletionTime());
1:             size += header.deletionTimeSerializedSize(bm.startDeletionTime());
1:            size += header.deletionTimeSerializedSize(((RangeTombstoneBoundMarker)marker).deletionTime());
/////////////////////////////////////////////////////////////////////////
0:             return new RangeTombstoneBoundaryMarker(bound, header.readDeletionTime(in), header.readDeletionTime(in));
0:             return new RangeTombstoneBoundMarker(bound, header.readDeletionTime(in));
/////////////////////////////////////////////////////////////////////////
1:                 long timestamp = header.readTimestamp(in);
1:                 int ttl = hasTTL ? header.readTTL(in) : LivenessInfo.NO_TTL;
1:                 int localDeletionTime = hasTTL ? header.readLocalDeletionTime(in) : LivenessInfo.NO_EXPIRATION_TIME;
0:             builder.addRowDeletion(hasDeletion ? header.readDeletionTime(in) : DeletionTime.LIVE);
/////////////////////////////////////////////////////////////////////////
1:                 DeletionTime complexDeletion = header.readDeletionTime(in);
/////////////////////////////////////////////////////////////////////////
0:             header.skipTimestamp(in);
0:             header.skipLocalDeletionTime(in);
0:             header.skipTTL(in);
1:             header.skipDeletionTime(in);
/////////////////////////////////////////////////////////////////////////
0:             header.skipDeletionTime(in);
0:             header.skipDeletionTime(in);
0:             header.skipDeletionTime(in);
/////////////////////////////////////////////////////////////////////////
0:             header.skipDeletionTime(in);
commit:2457599
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus;
1:  * Serialize/deserialize a single Unfiltered (both on-wire and on-disk).
0:  * The encoded format for an unfiltered is <flags>(<row>|<marker>) where:
0:  *   <flags> is a byte whose bits are flags used by the rest of the serialization. Each
0:  *       flag is defined/explained below as the "Unfiltered flags" constants.
/////////////////////////////////////////////////////////////////////////
0:  *       header and more precisely of {@link SerializationHeader#useSparseColumnLayout(boolean)}:
/////////////////////////////////////////////////////////////////////////
1:     /*
1:      * Unfiltered flags constants.
1:      */
1:     private final static int END_OF_PARTITION     = 0x01; // Signal the end of the partition. Nothing follows a <flags> field with that flag.
1:     private final static int IS_MARKER            = 0x02; // Whether the encoded unfiltered is a marker or a row. All following markers applies only to rows.
0:     private final static int IS_STATIC            = 0x04; // Whether the encoded row is a static.
0:     private final static int HAS_TIMESTAMP        = 0x08; // Whether the encoded row has a timestamp (i.e. if row.partitionKeyLivenessInfo().hasTimestamp() == true).
0:     private final static int HAS_TTL              = 0x10; // Whether the encoded row has some expiration info (i.e. if row.partitionKeyLivenessInfo().hasTTL() == true).
0:     private final static int HAS_DELETION         = 0x20; // Whether the encoded row has some deletion info.
1:     private final static int HAS_COMPLEX_DELETION = 0x40; // Whether the encoded row has some complex deletion for at least one of its columns.
/////////////////////////////////////////////////////////////////////////
1:         if (!pkLiveness.isEmpty())
1:         if (pkLiveness.isExpiring())
/////////////////////////////////////////////////////////////////////////
0:             out.writeInt(header.encodeDeletionTime(pkLiveness.localExpirationTime()));
/////////////////////////////////////////////////////////////////////////
0:             writeSimpleColumn(i, (Cell)cells.next(columns.getSimple(i)), pkLiveness, header, out, useSparse);
0:             writeComplexColumn(i, (ComplexColumnData)cells.next(columns.getComplex(i - simpleCount)), hasComplexDeletion, pkLiveness, header, out, useSparse);
0:     private void writeSimpleColumn(int idx, Cell cell, LivenessInfo rowLiveness, SerializationHeader header, DataOutputPlus out, boolean useSparse)
1:     throws IOException
1:     {
0:         if (useSparse)
1:         {
0:             if (cell == null)
0:                 return;
1: 
0:             out.writeShort(idx);
1:         }
0:         Cell.serializer.serialize(cell, out, rowLiveness, header);
1:     }
1: 
0:     private void writeComplexColumn(int idx, ComplexColumnData data, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header, DataOutputPlus out, boolean useSparse)
/////////////////////////////////////////////////////////////////////////
1:         if (hasComplexDeletion)
0:             UnfilteredRowIteratorSerializer.writeDelTime(data == null ? DeletionTime.LIVE : data.complexDeletion(), header, out);
0:         if (data != null)
1:             for (Cell cell : data)
0:                 Cell.serializer.serialize(cell, out, rowLiveness, header);
0:         Cell.serializer.serialize(null, out, rowLiveness, header);
/////////////////////////////////////////////////////////////////////////
1:         if (!pkLiveness.isEmpty())
1:         if (pkLiveness.isExpiring())
0:             size += TypeSizes.sizeof(header.encodeDeletionTime(pkLiveness.localExpirationTime()));
/////////////////////////////////////////////////////////////////////////
0:             size += sizeOfSimpleColumn(i, (Cell)cells.next(columns.getSimple(i)), pkLiveness, header, useSparse);
0:             size += sizeOfComplexColumn(i, (ComplexColumnData)cells.next(columns.getComplex(i - simpleCount)), hasComplexDeletion, pkLiveness, header, useSparse);
/////////////////////////////////////////////////////////////////////////
0:     private long sizeOfSimpleColumn(int idx, Cell cell, LivenessInfo rowLiveness, SerializationHeader header, boolean useSparse)
1:     {
1:         long size = 0;
0:         if (useSparse)
1:         {
0:             if (cell == null)
1:                 return size;
1: 
0:             size += TypeSizes.sizeof((short)idx);
1:         }
0:         return size + Cell.serializer.serializedSize(cell, rowLiveness, header);
1:     }
1: 
0:     private long sizeOfComplexColumn(int idx, ComplexColumnData data, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header, boolean useSparse)
/////////////////////////////////////////////////////////////////////////
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(data == null ? DeletionTime.LIVE : data.complexDeletion(), header);
0:         if (data != null)
1:         {
1:             for (Cell cell : data)
0:                 size += Cell.serializer.serializedSize(cell, rowLiveness, header);
1:         }
0:         return size + Cell.serializer.serializedSize(null, rowLiveness, header);
/////////////////////////////////////////////////////////////////////////
1:     public Unfiltered deserialize(DataInputPlus in, SerializationHeader header, SerializationHelper helper, Row.Builder builder)
1:         // It wouldn't be wrong per-se to use an unsorted builder, but it would be inefficient so make sure we don't do it by mistake
1:         assert builder.isSorted();
1: 
0:             RangeTombstone.Bound bound = RangeTombstone.Bound.serializer.deserialize(in, helper.version, header.clusteringTypes());
1:             return deserializeMarkerBody(in, header, bound);
1:             builder.newRow(Clustering.serializer.deserialize(in, helper.version, header.clusteringTypes()));
0:             return deserializeRowBody(in, header, helper, flags, builder);
1:     public Row deserializeStaticRow(DataInputPlus in, SerializationHeader header, SerializationHelper helper)
0:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isStatic(flags) : flags;
0:         Row.Builder builder = ArrayBackedRow.sortedBuilder(helper.fetchedStaticColumns(header));
1:         builder.newRow(Clustering.STATIC_CLUSTERING);
0:         return deserializeRowBody(in, header, helper, flags, builder);
0:     public RangeTombstoneMarker deserializeMarkerBody(DataInputPlus in, SerializationHeader header, RangeTombstone.Bound bound)
1:         if (bound.isBoundary())
0:             return new RangeTombstoneBoundaryMarker(bound, UnfilteredRowIteratorSerializer.readDelTime(in, header), UnfilteredRowIteratorSerializer.readDelTime(in, header));
0:             return new RangeTombstoneBoundMarker(bound, UnfilteredRowIteratorSerializer.readDelTime(in, header));
1:     public Row deserializeRowBody(DataInputPlus in,
1:                                   SerializationHeader header,
1:                                   SerializationHelper helper,
1:                                   int flags,
1:                                   Row.Builder builder)
0:         try
0:             boolean isStatic = isStatic(flags);
1:             boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
1:             boolean hasTTL = (flags & HAS_TTL) != 0;
1:             boolean hasDeletion = (flags & HAS_DELETION) != 0;
1:             boolean hasComplexDeletion = (flags & HAS_COMPLEX_DELETION) != 0;
1: 
1:             LivenessInfo rowLiveness = LivenessInfo.EMPTY;
1:             if (hasTimestamp)
0:                 long timestamp = header.decodeTimestamp(in.readLong());
0:                 int ttl = hasTTL ? header.decodeTTL(in.readInt()) : LivenessInfo.NO_TTL;
0:                 int localDeletionTime = hasTTL ? header.decodeDeletionTime(in.readInt()) : LivenessInfo.NO_EXPIRATION_TIME;
0:                 rowLiveness = LivenessInfo.create(timestamp, ttl, localDeletionTime);
1: 
1:             builder.addPrimaryKeyLivenessInfo(rowLiveness);
0:             builder.addRowDeletion(hasDeletion ? UnfilteredRowIteratorSerializer.readDelTime(in, header) : DeletionTime.LIVE);
1: 
0:             Columns columns = header.columns(isStatic);
0:             if (header.useSparseColumnLayout(isStatic))
1:             {
0:                 int count = columns.columnCount();
0:                 int simpleCount = columns.simpleColumnCount();
0:                 int i;
0:                 while ((i = in.readShort()) >= 0)
1:                 {
0:                     if (i > count)
0:                         throw new IOException(String.format("Impossible column index %d, the header has only %d columns defined", i, count));
1: 
0:                     if (i < simpleCount)
0:                         readSimpleColumn(columns.getSimple(i), in, header, helper, builder, rowLiveness);
1:                     else
0:                         readComplexColumn(columns.getComplex(i - simpleCount), in, header, helper, hasComplexDeletion, builder, rowLiveness);
1:                 }
1:             }
1:             else
1:             {
0:                 for (int i = 0; i < columns.simpleColumnCount(); i++)
0:                     readSimpleColumn(columns.getSimple(i), in, header, helper, builder, rowLiveness);
1: 
0:                 for (int i = 0; i < columns.complexColumnCount(); i++)
0:                     readComplexColumn(columns.getComplex(i), in, header, helper, hasComplexDeletion, builder, rowLiveness);
1:             }
1: 
1:                 return builder.build();
1:         catch (RuntimeException | AssertionError e)
1:             // Corrupted data could be such that it triggers an assertion in the row Builder, or break one of its assumption.
1:             // Of course, a bug in said builder could also trigger this, but it's impossible a priori to always make the distinction
1:             // between a real bug and data corrupted in just the bad way. Besides, re-throwing as an IOException doesn't hide the
1:             // exception, it just make we catch it properly and mark the sstable as corrupted.
1:             throw new IOException("Error building row with data deserialized from " + in, e);
1:     private void readSimpleColumn(ColumnDefinition column, DataInputPlus in, SerializationHeader header, SerializationHelper helper, Row.Builder builder, LivenessInfo rowLiveness)
1:         {
1:             Cell cell = Cell.serializer.deserialize(in, rowLiveness, column, header, helper);
0:             if (cell != null && !helper.isDropped(cell, false))
1:                 builder.addCell(cell);
1:         }
1:         {
1:             Cell.serializer.skip(in, column, header);
1:         }
1:     private void readComplexColumn(ColumnDefinition column, DataInputPlus in, SerializationHeader header, SerializationHelper helper, boolean hasComplexDeletion, Row.Builder builder, LivenessInfo rowLiveness)
1:             {
0:                 DeletionTime complexDeletion = UnfilteredRowIteratorSerializer.readDelTime(in, header);
1:                 if (!helper.isDroppedComplexDeletion(complexDeletion))
1:                     builder.addComplexDeletion(column, complexDeletion);
1:             }
0:             Cell cell;
0:             while ((cell = Cell.serializer.deserialize(in, rowLiveness, column, header, helper)) != null)
1:             {
0:                 if (helper.includes(cell.path()) && !helper.isDropped(cell, true))
1:                     builder.addCell(cell);
1:             }
1:             helper.endOfComplexColumn();
1:             skipComplexColumn(in, column, header, hasComplexDeletion);
0:     public void skipRowBody(DataInputPlus in, SerializationHeader header, int flags) throws IOException
/////////////////////////////////////////////////////////////////////////
0:                     Cell.serializer.skip(in, columns.getSimple(i), header);
0:                     skipComplexColumn(in, columns.getComplex(i - simpleCount), header, hasComplexDeletion);
0:                 Cell.serializer.skip(in, columns.getSimple(i), header);
0:                 skipComplexColumn(in, columns.getComplex(i), header, hasComplexDeletion);
1:     public void skipStaticRow(DataInputPlus in, SerializationHeader header, SerializationHelper helper) throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
0:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isStatic(flags) : "Flags is " + flags;
0:         skipRowBody(in, header, flags);
1:     }
1: 
0:     public void skipMarkerBody(DataInputPlus in, SerializationHeader header, boolean isBoundary) throws IOException
1:     {
0:         if (isBoundary)
1:         {
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1:         }
1:         else
1:         {
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1:         }
1:     }
1: 
1:     private void skipComplexColumn(DataInputPlus in, ColumnDefinition column, SerializationHeader header, boolean hasComplexDeletion)
0:         while (Cell.serializer.skip(in, column, header));
/////////////////////////////////////////////////////////////////////////
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.db.rows;
1: 
0: import java.io.DataInput;
1: import java.io.IOException;
0: import java.nio.ByteBuffer;
0: import java.util.*;
1: 
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
1: 
1: import org.apache.cassandra.config.ColumnDefinition;
1: import org.apache.cassandra.db.*;
1: import org.apache.cassandra.io.util.DataOutputPlus;
0: import org.apache.cassandra.utils.ByteBufferUtil;
0: import org.apache.cassandra.utils.SearchIterator;
1: 
1: /**
0:  * Serialize/deserialize a single Unfiltered for the intra-node protocol.
1:  *
0:  * The encode format for an unfiltered is <flags>(<row>|<marker>) where:
1:  *
0:  *   <flags> is a byte whose bits are flags. The rightmost 1st bit is only
0:  *       set to indicate the end of the partition. The 2nd bit indicates
0:  *       whether the reminder is a range tombstone marker (otherwise it's a row).
0:  *       If it's a row then the 3rd bit indicates if it's static, the 4th bit
0:  *       indicates the presence of a row timestamp, the 5th the presence of a row
0:  *       ttl, the 6th the presence of row deletion and the 7th indicates the
0:  *       presence of complex deletion times.
0:  *   <row> is <clustering>[<timestamp>][<ttl>][<deletion>]<sc1>...<sci><cc1>...<ccj> where
0:  *       <clustering> is the row clustering as serialized by
0:  *       {@code Clustering.serializer}. Note that static row are an exception and
0:  *       don't have this. <timestamp>, <ttl> and <deletion> are the row timestamp, ttl and deletion
0:  *       whose presence is determined by the flags. <sci> is the simple columns of the row and <ccj> the
0:  *       complex ones.  There is actually 2 slightly different possible layout for those
0:  *       cell: a dense one and a sparse one. Which one is used depends on the serialization
0:  *       header and more precisely of {@link SerializationHeader.useSparseColumnLayout()}:
0:  *         1) in the dense layout, there will be as many <sci> and <ccj> as there is columns
0:  *            in the serialization header. *Each simple column <sci> will simply be a <cell>
0:  *            (which might have no value, see below), while each <ccj> will be
0:  *             [<delTime>]<cell1>...<celln><emptyCell> where <delTime> is the deletion for
0:  *             this complex column (if flags indicates it present), <celln> are the <cell>
0:  *             for this complex column and <emptyCell> is a last cell that will have no value
0:  *             to indicate the end of this column.
0:  *         2) in the sparse layout, there won't be "empty" cells, i.e. only the column that
0:  *            actually have a cell are represented. For that, each <sci> and <ccj> start
0:  *            by a 2 byte index that points to the column in the header it belongs to. After
0:  *            that, each <sci> and <ccj> is the same than for the dense layout. But contrarily
0:  *            to the dense layout we won't know how many elements are serialized so a 2 byte
0:  *            marker with a value of -1 will indicates the end of the row.
0:  *   <marker> is <bound><deletion> where <bound> is the marker bound as serialized
0:  *       by {@code Slice.Bound.serializer} and <deletion> is the marker deletion
0:  *       time.
1:  *
0:  *   <cell> A cell start with a 1 byte <flag>. Thre rightmost 1st bit indicates
0:  *       if there is actually a value for this cell. If this flag is unset,
0:  *       nothing more follows for the cell. The 2nd and third flag indicates if
0:  *       it's a deleted or expiring cell. The 4th flag indicates if the value
0:  *       is empty or not. The 5th and 6th indicates if the timestamp and ttl/
0:  *       localDeletionTime for the cell are the same than the row one (if that
0:  *       is the case, those are not repeated for the cell).Follows the <value>
0:  *       (unless it's marked empty in the flag) and a delta-encoded long <timestamp>
0:  *       (unless the flag tells to use the row level one).
0:  *       Then if it's a deleted or expiring cell a delta-encoded int <localDelTime>
0:  *       and if it's expiring a delta-encoded int <ttl> (unless it's an expiring cell
0:  *       and the ttl and localDeletionTime are indicated by the flags to be the same
0:  *       than the row ones, in which case none of those appears).
1:  */
1: public class UnfilteredSerializer
1: {
0:     private static final Logger logger = LoggerFactory.getLogger(UnfilteredSerializer.class);
1: 
1:     public static final UnfilteredSerializer serializer = new UnfilteredSerializer();
1: 
0:     // Unfiltered flags
0:     private final static int END_OF_PARTITION     = 0x01;
0:     private final static int IS_MARKER            = 0x02;
0:     // For rows
0:     private final static int IS_STATIC            = 0x04;
0:     private final static int HAS_TIMESTAMP        = 0x08;
0:     private final static int HAS_TTL              = 0x10;
0:     private final static int HAS_DELETION         = 0x20;
0:     private final static int HAS_COMPLEX_DELETION = 0x40;
1: 
0:     // Cell flags
0:     private final static int PRESENCE_MASK     = 0x01;
0:     private final static int DELETION_MASK     = 0x02;
0:     private final static int EXPIRATION_MASK   = 0x04;
0:     private final static int EMPTY_VALUE_MASK  = 0x08;
0:     private final static int USE_ROW_TIMESTAMP = 0x10;
0:     private final static int USE_ROW_TTL       = 0x20;
1: 
1:     public void serialize(Unfiltered unfiltered, SerializationHeader header, DataOutputPlus out, int version)
1:     throws IOException
1:     {
1:         if (unfiltered.kind() == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:         {
0:             serialize((RangeTombstoneMarker) unfiltered, header, out, version);
1:         }
1:         else
1:         {
0:             serialize((Row) unfiltered, header, out, version);
1:         }
1:     }
1: 
0:     public void serialize(Row row, SerializationHeader header, DataOutputPlus out, int version)
1:     throws IOException
1:     {
1:         int flags = 0;
1:         boolean isStatic = row.isStatic();
1: 
1:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
0:         DeletionTime deletion = row.deletion();
1:         boolean hasComplexDeletion = row.hasComplexDeletion();
1: 
1:         if (isStatic)
0:             flags |= IS_STATIC;
0:         if (pkLiveness.hasTimestamp())
1:             flags |= HAS_TIMESTAMP;
0:         if (pkLiveness.hasTTL())
1:             flags |= HAS_TTL;
1:         if (!deletion.isLive())
1:             flags |= HAS_DELETION;
1:         if (hasComplexDeletion)
1:             flags |= HAS_COMPLEX_DELETION;
1: 
1:         out.writeByte((byte)flags);
1:         if (!isStatic)
1:             Clustering.serializer.serialize(row.clustering(), out, version, header.clusteringTypes());
1: 
1:         if ((flags & HAS_TIMESTAMP) != 0)
0:             out.writeLong(header.encodeTimestamp(pkLiveness.timestamp()));
1:         if ((flags & HAS_TTL) != 0)
1:         {
0:             out.writeInt(header.encodeTTL(pkLiveness.ttl()));
0:             out.writeInt(header.encodeDeletionTime(pkLiveness.localDeletionTime()));
1:         }
1:         if ((flags & HAS_DELETION) != 0)
0:             UnfilteredRowIteratorSerializer.writeDelTime(deletion, header, out);
1: 
0:         Columns columns = header.columns(isStatic);
0:         int simpleCount = columns.simpleColumnCount();
0:         boolean useSparse = header.useSparseColumnLayout(isStatic);
0:         SearchIterator<ColumnDefinition, ColumnData> cells = row.searchIterator();
1: 
0:         for (int i = 0; i < simpleCount; i++)
0:             writeSimpleColumn(i, cells.next(columns.getSimple(i)), header, out, pkLiveness, useSparse);
1: 
0:         for (int i = simpleCount; i < columns.columnCount(); i++)
0:             writeComplexColumn(i, cells.next(columns.getComplex(i - simpleCount)), hasComplexDeletion, header, out, pkLiveness, useSparse);
1: 
0:         if (useSparse)
0:             out.writeShort(-1);
1:     }
1: 
0:     private void writeSimpleColumn(int idx, ColumnData data, SerializationHeader header, DataOutputPlus out, LivenessInfo rowLiveness, boolean useSparse)
1:     throws IOException
1:     {
0:         if (useSparse)
1:         {
0:             if (data == null)
0:                 return;
1: 
0:             out.writeShort(idx);
1:         }
1: 
0:         writeCell(data == null ? null : data.cell(), header, out, rowLiveness);
1:     }
1: 
0:     private void writeComplexColumn(int idx, ColumnData data, boolean hasComplexDeletion, SerializationHeader header, DataOutputPlus out, LivenessInfo rowLiveness, boolean useSparse)
1:     throws IOException
1:     {
0:         Iterator<Cell> cells = data == null ? null : data.cells();
0:         DeletionTime deletion = data == null ? DeletionTime.LIVE : data.complexDeletion();
1: 
0:         if (useSparse)
1:         {
0:             assert hasComplexDeletion || deletion.isLive();
0:             if (cells == null && deletion.isLive())
0:                 return;
1: 
0:             out.writeShort(idx);
1:         }
1: 
1:         if (hasComplexDeletion)
0:             UnfilteredRowIteratorSerializer.writeDelTime(deletion, header, out);
1: 
0:         if (cells != null)
0:             while (cells.hasNext())
0:                 writeCell(cells.next(), header, out, rowLiveness);
1: 
0:         writeCell(null, header, out, rowLiveness);
1:     }
1: 
0:     public void serialize(RangeTombstoneMarker marker, SerializationHeader header, DataOutputPlus out, int version)
1:     throws IOException
1:     {
1:         out.writeByte((byte)IS_MARKER);
0:         RangeTombstone.Bound.serializer.serialize(marker.clustering(), out, version, header.clusteringTypes());
1: 
1:         if (marker.isBoundary())
1:         {
1:             RangeTombstoneBoundaryMarker bm = (RangeTombstoneBoundaryMarker)marker;
0:             UnfilteredRowIteratorSerializer.writeDelTime(bm.endDeletionTime(), header, out);
0:             UnfilteredRowIteratorSerializer.writeDelTime(bm.startDeletionTime(), header, out);
1:         }
1:         else
1:         {
0:             UnfilteredRowIteratorSerializer.writeDelTime(((RangeTombstoneBoundMarker)marker).deletionTime(), header, out);
1:         }
1:     }
1: 
0:     public long serializedSize(Unfiltered unfiltered, SerializationHeader header, int version, TypeSizes sizes)
1:     {
0:         return unfiltered.kind() == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER
0:              ? serializedSize((RangeTombstoneMarker) unfiltered, header, version, sizes)
0:              : serializedSize((Row) unfiltered, header, version, sizes);
1:     }
1: 
0:     public long serializedSize(Row row, SerializationHeader header, int version, TypeSizes sizes)
1:     {
1:         long size = 1; // flags
1: 
1:         boolean isStatic = row.isStatic();
1:         LivenessInfo pkLiveness = row.primaryKeyLivenessInfo();
0:         DeletionTime deletion = row.deletion();
1:         boolean hasComplexDeletion = row.hasComplexDeletion();
1: 
1:         if (!isStatic)
0:             size += Clustering.serializer.serializedSize(row.clustering(), version, header.clusteringTypes(), sizes);
1: 
0:         if (pkLiveness.hasTimestamp())
0:             size += sizes.sizeof(header.encodeTimestamp(pkLiveness.timestamp()));
0:         if (pkLiveness.hasTTL())
1:         {
0:             size += sizes.sizeof(header.encodeTTL(pkLiveness.ttl()));
0:             size += sizes.sizeof(header.encodeDeletionTime(pkLiveness.localDeletionTime()));
1:         }
1:         if (!deletion.isLive())
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(deletion, header, sizes);
1: 
0:         Columns columns = header.columns(isStatic);
0:         int simpleCount = columns.simpleColumnCount();
0:         boolean useSparse = header.useSparseColumnLayout(isStatic);
0:         SearchIterator<ColumnDefinition, ColumnData> cells = row.searchIterator();
1: 
0:         for (int i = 0; i < simpleCount; i++)
0:             size += sizeOfSimpleColumn(i, cells.next(columns.getSimple(i)), header, sizes, pkLiveness, useSparse);
1: 
0:         for (int i = simpleCount; i < columns.columnCount(); i++)
0:             size += sizeOfComplexColumn(i, cells.next(columns.getComplex(i - simpleCount)), hasComplexDeletion, header, sizes, pkLiveness, useSparse);
1: 
0:         if (useSparse)
0:             size += sizes.sizeof((short)-1);
1: 
1:         return size;
1:     }
1: 
0:     private long sizeOfSimpleColumn(int idx, ColumnData data, SerializationHeader header, TypeSizes sizes, LivenessInfo rowLiveness, boolean useSparse)
1:     {
0:         long size = 0;
0:         if (useSparse)
1:         {
0:             if (data == null)
1:                 return size;
1: 
0:             size += sizes.sizeof((short)idx);
1:         }
0:         return size + sizeOfCell(data == null ? null : data.cell(), header, sizes, rowLiveness);
1:     }
1: 
0:     private long sizeOfComplexColumn(int idx, ColumnData data, boolean hasComplexDeletion, SerializationHeader header, TypeSizes sizes, LivenessInfo rowLiveness, boolean useSparse)
1:     {
0:         long size = 0;
0:         Iterator<Cell> cells = data == null ? null : data.cells();
0:         DeletionTime deletion = data == null ? DeletionTime.LIVE : data.complexDeletion();
0:         if (useSparse)
1:         {
0:             assert hasComplexDeletion || deletion.isLive();
0:             if (cells == null && deletion.isLive())
1:                 return size;
1: 
0:             size += sizes.sizeof((short)idx);
1:         }
1: 
1:         if (hasComplexDeletion)
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(deletion, header, sizes);
1: 
0:         if (cells != null)
0:             while (cells.hasNext())
0:                 size += sizeOfCell(cells.next(), header, sizes, rowLiveness);
1: 
0:         return size + sizeOfCell(null, header, sizes, rowLiveness);
1:     }
1: 
0:     public long serializedSize(RangeTombstoneMarker marker, SerializationHeader header, int version, TypeSizes sizes)
1:     {
0:         long size = 1 // flags
0:                   + RangeTombstone.Bound.serializer.serializedSize(marker.clustering(), version, header.clusteringTypes(), sizes);
1: 
1:         if (marker.isBoundary())
1:         {
1:             RangeTombstoneBoundaryMarker bm = (RangeTombstoneBoundaryMarker)marker;
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(bm.endDeletionTime(), header, sizes);
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(bm.startDeletionTime(), header, sizes);
1:         }
1:         else
1:         {
0:            size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(((RangeTombstoneBoundMarker)marker).deletionTime(), header, sizes);
1:         }
1:         return size;
1:     }
1: 
1:     public void writeEndOfPartition(DataOutputPlus out) throws IOException
1:     {
1:         out.writeByte((byte)1);
1:     }
1: 
0:     public long serializedSizeEndOfPartition(TypeSizes sizes)
1:     {
1:         return 1;
1:     }
1: 
0:     public Unfiltered.Kind deserialize(DataInput in,
0:                                  SerializationHeader header,
0:                                  SerializationHelper helper,
0:                                  Row.Writer rowWriter,
0:                                  RangeTombstoneMarker.Writer markerWriter)
1:     throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
1:         if (isEndOfPartition(flags))
1:             return null;
1: 
1:         if (kind(flags) == Unfiltered.Kind.RANGE_TOMBSTONE_MARKER)
1:         {
0:             RangeTombstone.Bound.Kind kind = RangeTombstone.Bound.serializer.deserialize(in, helper.version, header.clusteringTypes(), markerWriter);
0:             deserializeMarkerBody(in, header, kind.isBoundary(), markerWriter);
0:             return Unfiltered.Kind.RANGE_TOMBSTONE_MARKER;
1:         }
1:         else
1:         {
0:             assert !isStatic(flags); // deserializeStaticRow should be used for that.
0:             Clustering.serializer.deserialize(in, helper.version, header.clusteringTypes(), rowWriter);
0:             deserializeRowBody(in, header, helper, flags, rowWriter);
0:             return Unfiltered.Kind.ROW;
1:         }
1:     }
1: 
0:     public Row deserializeStaticRow(DataInput in, SerializationHeader header, SerializationHelper helper)
1:     throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
0:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isStatic(flags);
0:         StaticRow.Builder builder = StaticRow.builder(header.columns().statics, true, header.columns().statics.hasCounters());
0:         deserializeRowBody(in, header, helper, flags, builder);
0:         return builder.build();
1:     }
1: 
0:     public void skipStaticRow(DataInput in, SerializationHeader header, SerializationHelper helper) throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
0:         assert !isEndOfPartition(flags) && kind(flags) == Unfiltered.Kind.ROW && isStatic(flags) : "Flags is " + flags;
0:         skipRowBody(in, header, helper, flags);
1:     }
1: 
0:     public void deserializeMarkerBody(DataInput in,
0:                                       SerializationHeader header,
0:                                       boolean isBoundary,
0:                                       RangeTombstoneMarker.Writer writer)
1:     throws IOException
1:     {
0:         if (isBoundary)
0:             writer.writeBoundaryDeletion(UnfilteredRowIteratorSerializer.readDelTime(in, header), UnfilteredRowIteratorSerializer.readDelTime(in, header));
1:         else
0:             writer.writeBoundDeletion(UnfilteredRowIteratorSerializer.readDelTime(in, header));
0:         writer.endOfMarker();
1:     }
1: 
0:     public void skipMarkerBody(DataInput in, SerializationHeader header, boolean isBoundary) throws IOException
1:     {
0:         if (isBoundary)
1:         {
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1:         }
1:         else
1:         {
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1:         }
1:     }
1: 
0:     public void deserializeRowBody(DataInput in,
0:                                    SerializationHeader header,
0:                                    SerializationHelper helper,
0:                                    int flags,
0:                                    Row.Writer writer)
1:     throws IOException
1:     {
0:         boolean isStatic = isStatic(flags);
0:         boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
0:         boolean hasTTL = (flags & HAS_TTL) != 0;
0:         boolean hasDeletion = (flags & HAS_DELETION) != 0;
0:         boolean hasComplexDeletion = (flags & HAS_COMPLEX_DELETION) != 0;
1: 
0:         long timestamp = hasTimestamp ? header.decodeTimestamp(in.readLong()) : LivenessInfo.NO_TIMESTAMP;
0:         int ttl = hasTTL ? header.decodeTTL(in.readInt()) : LivenessInfo.NO_TTL;
0:         int localDeletionTime = hasTTL ? header.decodeDeletionTime(in.readInt()) : LivenessInfo.NO_DELETION_TIME;
0:         DeletionTime deletion = hasDeletion ? UnfilteredRowIteratorSerializer.readDelTime(in, header) : DeletionTime.LIVE;
1: 
0:         helper.writePartitionKeyLivenessInfo(writer, timestamp, ttl, localDeletionTime);
0:         writer.writeRowDeletion(deletion);
1: 
0:         Columns columns = header.columns(isStatic);
0:         if (header.useSparseColumnLayout(isStatic))
1:         {
0:             int count = columns.columnCount();
0:             int simpleCount = columns.simpleColumnCount();
0:             int i;
0:             while ((i = in.readShort()) >= 0)
1:             {
0:                 if (i > count)
0:                     throw new IOException(String.format("Impossible column index %d, the header has only %d columns defined", i, count));
1: 
0:                 if (i < simpleCount)
0:                     readSimpleColumn(columns.getSimple(i), in, header, helper, writer);
1:                 else
0:                     readComplexColumn(columns.getComplex(i - simpleCount), in, header, helper, hasComplexDeletion, writer);
1:             }
1:         }
1:         else
1:         {
0:             for (int i = 0; i < columns.simpleColumnCount(); i++)
0:                 readSimpleColumn(columns.getSimple(i), in, header, helper, writer);
1: 
0:             for (int i = 0; i < columns.complexColumnCount(); i++)
0:                 readComplexColumn(columns.getComplex(i), in, header, helper, hasComplexDeletion, writer);
1:         }
1: 
0:         writer.endOfRow();
1:     }
1: 
0:     private void readSimpleColumn(ColumnDefinition column, DataInput in, SerializationHeader header, SerializationHelper helper, Row.Writer writer)
1:     throws IOException
1:     {
1:         if (helper.includes(column))
0:             readCell(column, in, header, helper, writer);
1:         else
0:             skipCell(column, in, header);
1:     }
1: 
0:     private void readComplexColumn(ColumnDefinition column, DataInput in, SerializationHeader header, SerializationHelper helper, boolean hasComplexDeletion, Row.Writer writer)
1:     throws IOException
1:     {
1:         if (helper.includes(column))
1:         {
1:             helper.startOfComplexColumn(column);
1: 
1:             if (hasComplexDeletion)
0:                 writer.writeComplexDeletion(column, UnfilteredRowIteratorSerializer.readDelTime(in, header));
1: 
0:             while (readCell(column, in, header, helper, writer));
1: 
0:             helper.endOfComplexColumn(column);
1:         }
1:         else
1:         {
0:             skipComplexColumn(column, in, header, helper, hasComplexDeletion);
1:         }
1:     }
1: 
0:     public void skipRowBody(DataInput in, SerializationHeader header, SerializationHelper helper, int flags) throws IOException
1:     {
0:         boolean isStatic = isStatic(flags);
0:         boolean hasTimestamp = (flags & HAS_TIMESTAMP) != 0;
0:         boolean hasTTL = (flags & HAS_TTL) != 0;
0:         boolean hasDeletion = (flags & HAS_DELETION) != 0;
0:         boolean hasComplexDeletion = (flags & HAS_COMPLEX_DELETION) != 0;
1: 
0:         // Note that we don't want want to use FileUtils.skipBytesFully for anything that may not have
0:         // the size we think due to VINT encoding
0:         if (hasTimestamp)
0:             in.readLong();
0:         if (hasTTL)
1:         {
0:             // ttl and localDeletionTime
0:             in.readInt();
0:             in.readInt();
1:         }
0:         if (hasDeletion)
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1: 
0:         Columns columns = header.columns(isStatic);
0:         if (header.useSparseColumnLayout(isStatic))
1:         {
0:             int count = columns.columnCount();
0:             int simpleCount = columns.simpleColumnCount();
0:             int i;
0:             while ((i = in.readShort()) >= 0)
1:             {
0:                 if (i > count)
0:                     throw new IOException(String.format("Impossible column index %d, the header has only %d columns defined", i, count));
1: 
0:                 if (i < simpleCount)
0:                     skipCell(columns.getSimple(i), in, header);
1:                 else
0:                     skipComplexColumn(columns.getComplex(i - simpleCount), in, header, helper, hasComplexDeletion);
1:             }
1:         }
1:         else
1:         {
0:             for (int i = 0; i < columns.simpleColumnCount(); i++)
0:                 skipCell(columns.getSimple(i), in, header);
1: 
0:             for (int i = 0; i < columns.complexColumnCount(); i++)
0:                 skipComplexColumn(columns.getComplex(i), in, header, helper, hasComplexDeletion);
1:         }
1:     }
1: 
0:     private void skipComplexColumn(ColumnDefinition column, DataInput in, SerializationHeader header, SerializationHelper helper, boolean hasComplexDeletion)
1:     throws IOException
1:     {
1:         if (hasComplexDeletion)
0:             UnfilteredRowIteratorSerializer.skipDelTime(in, header);
1: 
0:         while (skipCell(column, in, header));
1:     }
1: 
1:     public static boolean isEndOfPartition(int flags)
1:     {
1:         return (flags & END_OF_PARTITION) != 0;
1:     }
1: 
1:     public static Unfiltered.Kind kind(int flags)
1:     {
1:         return (flags & IS_MARKER) != 0 ? Unfiltered.Kind.RANGE_TOMBSTONE_MARKER : Unfiltered.Kind.ROW;
1:     }
1: 
0:     public static boolean isStatic(int flags)
1:     {
0:         return (flags & IS_MARKER) == 0 && (flags & IS_STATIC) != 0;
1:     }
1: 
0:     private void writeCell(Cell cell, SerializationHeader header, DataOutputPlus out, LivenessInfo rowLiveness)
1:     throws IOException
1:     {
0:         if (cell == null)
1:         {
0:             out.writeByte((byte)0);
0:             return;
1:         }
1: 
0:         boolean hasValue = cell.value().hasRemaining();
0:         boolean isDeleted = cell.isTombstone();
0:         boolean isExpiring = cell.isExpiring();
0:         boolean useRowTimestamp = rowLiveness.hasTimestamp() && cell.livenessInfo().timestamp() == rowLiveness.timestamp();
0:         boolean useRowTTL = isExpiring && rowLiveness.hasTTL() && cell.livenessInfo().ttl() == rowLiveness.ttl() && cell.livenessInfo().localDeletionTime() == rowLiveness.localDeletionTime();
0:         int flags = PRESENCE_MASK;
0:         if (!hasValue)
0:             flags |= EMPTY_VALUE_MASK;
1: 
0:         if (isDeleted)
0:             flags |= DELETION_MASK;
0:         else if (isExpiring)
0:             flags |= EXPIRATION_MASK;
1: 
0:         if (useRowTimestamp)
0:             flags |= USE_ROW_TIMESTAMP;
0:         if (useRowTTL)
0:             flags |= USE_ROW_TTL;
1: 
1:         out.writeByte((byte)flags);
1: 
0:         if (hasValue)
0:             header.getType(cell.column()).writeValue(cell.value(), out);
1: 
0:         if (!useRowTimestamp)
0:             out.writeLong(header.encodeTimestamp(cell.livenessInfo().timestamp()));
1: 
0:         if ((isDeleted || isExpiring) && !useRowTTL)
0:             out.writeInt(header.encodeDeletionTime(cell.livenessInfo().localDeletionTime()));
0:         if (isExpiring && !useRowTTL)
0:             out.writeInt(header.encodeTTL(cell.livenessInfo().ttl()));
1: 
0:         if (cell.column().isComplex())
0:             cell.column().cellPathSerializer().serialize(cell.path(), out);
1:     }
1: 
0:     private long sizeOfCell(Cell cell, SerializationHeader header, TypeSizes sizes, LivenessInfo rowLiveness)
1:     {
1:         long size = 1; // flags
1: 
0:         if (cell == null)
1:             return size;
1: 
0:         boolean hasValue = cell.value().hasRemaining();
0:         boolean isDeleted = cell.isTombstone();
0:         boolean isExpiring = cell.isExpiring();
0:         boolean useRowTimestamp = rowLiveness.hasTimestamp() && cell.livenessInfo().timestamp() == rowLiveness.timestamp();
0:         boolean useRowTTL = isExpiring && rowLiveness.hasTTL() && cell.livenessInfo().ttl() == rowLiveness.ttl() && cell.livenessInfo().localDeletionTime() == rowLiveness.localDeletionTime();
1: 
0:         if (hasValue)
0:             size += header.getType(cell.column()).writtenLength(cell.value(), sizes);
1: 
0:         if (!useRowTimestamp)
0:             size += sizes.sizeof(header.encodeTimestamp(cell.livenessInfo().timestamp()));
1: 
0:         if ((isDeleted || isExpiring) && !useRowTTL)
0:             size += sizes.sizeof(header.encodeDeletionTime(cell.livenessInfo().localDeletionTime()));
0:         if (isExpiring && !useRowTTL)
0:             size += sizes.sizeof(header.encodeTTL(cell.livenessInfo().ttl()));
1: 
0:         if (cell.column().isComplex())
0:             size += cell.column().cellPathSerializer().serializedSize(cell.path(), sizes);
1: 
1:         return size;
1:     }
1: 
0:     private boolean readCell(ColumnDefinition column, DataInput in, SerializationHeader header, SerializationHelper helper, Row.Writer writer)
1:     throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
0:         if ((flags & PRESENCE_MASK) == 0)
0:             return false;
1: 
0:         boolean hasValue = (flags & EMPTY_VALUE_MASK) == 0;
0:         boolean isDeleted = (flags & DELETION_MASK) != 0;
0:         boolean isExpiring = (flags & EXPIRATION_MASK) != 0;
0:         boolean useRowTimestamp = (flags & USE_ROW_TIMESTAMP) != 0;
0:         boolean useRowTTL = (flags & USE_ROW_TTL) != 0;
1: 
0:         ByteBuffer value = ByteBufferUtil.EMPTY_BYTE_BUFFER;
0:         if (hasValue)
1:         {
0:             if (helper.canSkipValue(column))
0:                 header.getType(column).skipValue(in);
1:             else
0:                 value = header.getType(column).readValue(in);
1:         }
1: 
0:         long timestamp = useRowTimestamp ? helper.getRowTimestamp() : header.decodeTimestamp(in.readLong());
1: 
0:         int localDelTime = useRowTTL
0:                          ? helper.getRowLocalDeletionTime()
0:                          : (isDeleted || isExpiring ? header.decodeDeletionTime(in.readInt()) : LivenessInfo.NO_DELETION_TIME);
1: 
0:         int ttl = useRowTTL
0:                 ? helper.getRowTTL()
0:                 : (isExpiring ? header.decodeTTL(in.readInt()) : LivenessInfo.NO_TTL);
1: 
0:         CellPath path = column.isComplex()
0:                       ? column.cellPathSerializer().deserialize(in)
0:                       : null;
1: 
0:         helper.writeCell(writer, column, false, value, timestamp, localDelTime, ttl, path);
1: 
0:         return true;
1:     }
1: 
0:     private boolean skipCell(ColumnDefinition column, DataInput in, SerializationHeader header)
1:     throws IOException
1:     {
1:         int flags = in.readUnsignedByte();
0:         if ((flags & PRESENCE_MASK) == 0)
0:             return false;
1: 
0:         boolean hasValue = (flags & EMPTY_VALUE_MASK) == 0;
0:         boolean isDeleted = (flags & DELETION_MASK) != 0;
0:         boolean isExpiring = (flags & EXPIRATION_MASK) != 0;
0:         boolean useRowTimestamp = (flags & USE_ROW_TIMESTAMP) != 0;
0:         boolean useRowTTL = (flags & USE_ROW_TTL) != 0;
1: 
0:         if (hasValue)
0:             header.getType(column).skipValue(in);
1: 
0:         if (!useRowTimestamp)
0:             in.readLong();
1: 
0:         if (!useRowTTL && (isDeleted || isExpiring))
0:             in.readInt();
1: 
0:         if (!useRowTTL && isExpiring)
0:             in.readInt();
1: 
0:         if (column.isComplex())
0:             column.cellPathSerializer().skip(in);
1: 
0:         return true;
1:     }
1: }
author:Dave Brosius
-------------------------------------------------------------------------------
commit:79c5bc3
/////////////////////////////////////////////////////////////////////////
1:  *           {@link org.apache.cassandra.db.Clustering.Serializer} (note that static row are an
/////////////////////////////////////////////////////////////////////////
1:  *           {@link org.apache.cassandra.db.Columns.Serializer#serializeSubset}. It is absent if the row
/////////////////////////////////////////////////////////////////////////
1:  *     the marker bound as serialized by {@link org.apache.cassandra.db.ClusteringBoundOrBoundary.Serializer}
commit:6b7db8a
/////////////////////////////////////////////////////////////////////////
0:  * {@code
/////////////////////////////////////////////////////////////////////////
0:  * }
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:81902ba
commit:68d20ed
author:Alex Petrov
-------------------------------------------------------------------------------
commit:85cc390
/////////////////////////////////////////////////////////////////////////
1:             // deserializeStaticRow should be used for that.
1:             if (isStatic(extendedFlags))
1:                 throw new IOException("Corrupt flags value for unfiltered partition (isStatic flag set): " + flags);
0: 
1:             Row row = deserializeRowBody(in, header, helper, flags, extendedFlags, builder);
1:             // we do not write empty rows because Rows.collectStats(), called by BTW.applyToRow(), asserts that rows are not empty
1:             // if we don't throw here, then later the very same assertion in Rows.collectStats() will fail compactions
1:             // see BlackListingCompactionsTest and CASSANDRA-9530 for details
1:             if (row.isEmpty())
1:                 throw new IOException("Corrupt empty row found in unfiltered partition");
1:             return row;
author:Wei Deng
-------------------------------------------------------------------------------
commit:aefa580
/////////////////////////////////////////////////////////////////////////
1:  * <p>
1:  * The encoded format for an unfiltered is {@code <flags>(<row>|<marker>)} where:
1:  * <ul>
1:  *   <li>
1:  *     {@code <flags>} is a byte (or two) whose bits are flags used by the rest
1:  *     of the serialization. Each flag is defined/explained below as the
1:  *     "Unfiltered flags" constants. One of those flags is an extension flag,
1:  *     and if present, indicates the presence of a 2ndbyte that contains more
1:  *     flags. If the extension is not set, defaults are assumed for the flags
1:  *     of that 2nd byte.
1:  *   </li>
1:  *   <li>
1:  *     {@code <row>} is
1:  *        {@code <clustering><sizes>[<pkliveness>][<deletion>][<columns>]<columns_data>}
1:  *     where:
1:  *     <ul>
1:  *       <li>{@code <clustering>} is the row clustering as serialized by
0:  *           {@link Clustering.serializer} (note that static row are an
1:  *           exception and don't have this). </li>
1:  *       <li>{@code <sizes>} are the sizes of the whole unfiltered on disk and
1:  *           of the previous unfiltered. This is only present for sstables and
1:  *           is used to efficiently skip rows (both forward and backward).</li>
1:  *       <li>{@code <pkliveness>} is the row primary key liveness infos, and it
1:  *           contains the timestamp, ttl and local deletion time of that info,
1:  *           though some/all of those can be absent based on the flags. </li>
1:  *       <li>{@code deletion} is the row deletion. It's presence is determined
1:  *           by the flags and if present, it conists of both the deletion
1:  *           timestamp and local deletion time.</li>
1:  *       <li>{@code <columns>} are the columns present in the row  encoded by
0:  *           {@link Columns.serializer#serializeSubset}. It is absent if the row
1:  *           contains all the columns of the {@code SerializationHeader} (which
1:  *           is then indicated by a flag). </li>
1:  *       <li>{@code <columns_data>} is the data for each of the column present
1:  *           in the row. The encoding of each data depends on whether the data
1:  *           is for a simple or complex column:
1:  *           <ul>
1:  *              <li>Simple columns are simply encoded as one {@code <cell>}</li>
1:  *              <li>Complex columns are encoded as {@code [<delTime>]<n><cell1>...<celln>}
1:  *                  where {@code <delTime>} is the deletion for this complex
1:  *                  column (if flags indicates its presence), {@code <n>} is the
1:  *                  vint encoded value of n, i.e. {@code <celln>}'s 1-based
1:  *                  inde and {@code <celli>} are the {@code <cell>} for this
1:  *                  complex column</li>
1:  *           </ul>
1:  *       </li>
1:  *     </ul>
1:  *   </li>
1:  *   <li>
1:  *     {@code <marker>} is {@code <bound><deletion>} where {@code <bound>} is
0:  *     the marker bound as serialized by {@link ClusteringBoundOrBoundary.serializer}
1:  *     and {@code <deletion>} is the marker deletion time.
1:  *   </li>
1:  * </ul>
1:  * <p>
1:  * The serialization of a {@code <cell>} is defined by {@link Cell.Serializer}.
/////////////////////////////////////////////////////////////////////////
0:             // We write the size of the previous unfiltered to make reverse queries more efficient (and simpler).
0:             // This is currently not used however and using it is tbd.
author:Benjamin Lerer
-------------------------------------------------------------------------------
commit:e017f94
/////////////////////////////////////////////////////////////////////////
1:                 rowLiveness = LivenessInfo.withExpirationTime(timestamp, ttl, localDeletionTime);
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:aa57626
/////////////////////////////////////////////////////////////////////////
1:         Row.Builder builder = BTreeRow.sortedBuilder();
commit:80a141c
/////////////////////////////////////////////////////////////////////////
1:             header.writeDeletionTime(data.complexDeletion(), out);
/////////////////////////////////////////////////////////////////////////
1:             size += header.deletionTimeSerializedSize(data.complexDeletion());
commit:0d74c3e
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.Collections2;
0: 
/////////////////////////////////////////////////////////////////////////
0:  *       complex ones.
0:  *       The columns for the row are then serialized if they differ from those in the header,
0:  *       and each cell then follows:
0:  *         * Each simple column <sci> will simply be a <cell>
0:  *           (which might have no value, see below),
0:  *         * Each <ccj> will be [<delTime>]<n><cell1>...<celln> where <delTime>
0:  *           is the deletion for this complex column (if flags indicates it present), <n>
0:  *           is the vint encoded value of n, i.e. <celln>'s 1-based index, <celli>
0:  *           are the <cell> for this complex column
0:  *   <cell> A cell start with a 1 byte <flag>. The 2nd and third flag bits indicate if
/////////////////////////////////////////////////////////////////////////
0:     private final static int HAS_ALL_COLUMNS      = 0x80; // Whether the encoded row has all of the columns from the header present
/////////////////////////////////////////////////////////////////////////
1:         Columns headerColumns = header.columns(isStatic);
1:         boolean hasAllColumns = (row.size() == headerColumns.size());
/////////////////////////////////////////////////////////////////////////
1:         if (hasAllColumns)
1:             flags |= HAS_ALL_COLUMNS;
/////////////////////////////////////////////////////////////////////////
1:         if (!hasAllColumns)
1:             Columns.serializer.serializeSubset(Collections2.transform(row, ColumnData::column), headerColumns, out);
1:         for (ColumnData data : row)
0:         {
1:             if (data.column.isSimple())
0:                 Cell.serializer.serialize((Cell) data, out, pkLiveness, header);
0:             else
0:                 writeComplexColumn((ComplexColumnData) data, hasComplexDeletion, pkLiveness, header, out);
0:         }
0:     private void writeComplexColumn(ComplexColumnData data, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header, DataOutputPlus out)
1:         out.writeUnsignedVInt(data.cellsCount());
0:         for (Cell cell : data)
0:             Cell.serializer.serialize(cell, out, rowLiveness, header);
/////////////////////////////////////////////////////////////////////////
1:         Columns headerColumns = header.columns(isStatic);
1:         boolean hasAllColumns = (row.size() == headerColumns.size());
/////////////////////////////////////////////////////////////////////////
0:         if (!hasAllColumns)
1:             size += Columns.serializer.serializedSubsetSize(Collections2.transform(row, ColumnData::column), header.columns(isStatic));
0:         for (ColumnData data : row)
0:         {
0:             if (data.column.isSimple())
0:                 size += Cell.serializer.serializedSize((Cell) data, pkLiveness, header);
0:             else
0:                 size += sizeOfComplexColumn((ComplexColumnData) data, hasComplexDeletion, pkLiveness, header);
0:         }
0:     private long sizeOfComplexColumn(ComplexColumnData data, boolean hasComplexDeletion, LivenessInfo rowLiveness, SerializationHeader header)
1:         size += TypeSizes.sizeofUnsignedVInt(data.cellsCount());
0:         for (Cell cell : data)
0:             size += Cell.serializer.serializedSize(cell, rowLiveness, header);
0:         return size;
/////////////////////////////////////////////////////////////////////////
1:             boolean hasAllColumns = (flags & HAS_ALL_COLUMNS) != 0;
1:             Columns headerColumns = header.columns(isStatic);
/////////////////////////////////////////////////////////////////////////
1:             Columns columns = hasAllColumns ? headerColumns : Columns.serializer.deserializeSubset(headerColumns, in);
0:             for (ColumnDefinition column : columns)
0:                 if (column.isSimple())
0:                     readSimpleColumn(column, in, header, helper, builder, rowLiveness);
0:                 else
0:                     readComplexColumn(column, in, header, helper, hasComplexDeletion, builder, rowLiveness);
0:             return builder.build();
/////////////////////////////////////////////////////////////////////////
0:             if (!helper.isDropped(cell, false))
/////////////////////////////////////////////////////////////////////////
1:             int count = (int) in.readUnsignedVInt();
1:             while (--count >= 0)
1:                 Cell cell = Cell.serializer.deserialize(in, rowLiveness, column, header, helper);
/////////////////////////////////////////////////////////////////////////
0:         boolean hasAllColumns = (flags & HAS_ALL_COLUMNS) != 0;
0:         Columns headerColumns = header.columns(isStatic);
/////////////////////////////////////////////////////////////////////////
0:         Columns columns = hasAllColumns ? headerColumns : Columns.serializer.deserializeSubset(headerColumns, in);
0:         for (ColumnDefinition column : columns)
0:             if (column.isSimple())
1:                 Cell.serializer.skip(in, column, header);
0:             else
0:                 skipComplexColumn(in, column, header, hasComplexDeletion);
/////////////////////////////////////////////////////////////////////////
1:         int count = (int) in.readUnsignedVInt();
1:         while (--count >= 0)
0:             Cell.serializer.skip(in, column, header);
commit:e51f83b
/////////////////////////////////////////////////////////////////////////
0:         Row.Builder builder = BTreeRow.sortedBuilder(helper.fetchedStaticColumns(header));
commit:639d4b2
/////////////////////////////////////////////////////////////////////////
0:         Row.Builder builder = BTreeBackedRow.sortedBuilder(helper.fetchedStaticColumns(header));
commit:5786b32
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.DataOutputPlus;
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:2fea59d
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(-1);
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             out.writeVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(-1);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeofVInt(idx);
/////////////////////////////////////////////////////////////////////////
0:                 while ((i = (int)in.readVInt()) >= 0)
/////////////////////////////////////////////////////////////////////////
0:             while ((i = (int)in.readVInt()) >= 0)
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:59a2861
/////////////////////////////////////////////////////////////////////////
0:             out.writeShort(-1);
/////////////////////////////////////////////////////////////////////////
0:             out.writeShort(idx);
/////////////////////////////////////////////////////////////////////////
0:             out.writeShort(idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeof((short)-1);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeof((short)idx);
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeof((short)idx);
/////////////////////////////////////////////////////////////////////////
0:                 while ((i = in.readShort()) >= 0)
/////////////////////////////////////////////////////////////////////////
0:             while ((i = in.readShort()) >= 0)
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
1:     public long serializedSize(Unfiltered unfiltered, SerializationHeader header, int version)
0:              ? serializedSize((RangeTombstoneMarker) unfiltered, header, version)
0:              : serializedSize((Row) unfiltered, header, version);
0:     public long serializedSize(Row row, SerializationHeader header, int version)
/////////////////////////////////////////////////////////////////////////
0:             size += Clustering.serializer.serializedSize(row.clustering(), version, header.clusteringTypes());
0:             size += TypeSizes.sizeof(header.encodeTimestamp(pkLiveness.timestamp()));
0:             size += TypeSizes.sizeof(header.encodeTTL(pkLiveness.ttl()));
0:             size += TypeSizes.sizeof(header.encodeDeletionTime(pkLiveness.localDeletionTime()));
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(deletion, header);
/////////////////////////////////////////////////////////////////////////
0:             size += sizeOfSimpleColumn(i, cells.next(columns.getSimple(i)), header, pkLiveness, useSparse);
0:             size += sizeOfComplexColumn(i, cells.next(columns.getComplex(i - simpleCount)), hasComplexDeletion, header, pkLiveness, useSparse);
0:             size += TypeSizes.sizeof((short)-1);
0:     private long sizeOfSimpleColumn(int idx, ColumnData data, SerializationHeader header, LivenessInfo rowLiveness, boolean useSparse)
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeof((short)idx);
0:         return size + sizeOfCell(data == null ? null : data.cell(), header, rowLiveness);
0:     private long sizeOfComplexColumn(int idx, ColumnData data, boolean hasComplexDeletion, SerializationHeader header, LivenessInfo rowLiveness, boolean useSparse)
/////////////////////////////////////////////////////////////////////////
0:             size += TypeSizes.sizeof((short)idx);
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(deletion, header);
0:                 size += sizeOfCell(cells.next(), header, rowLiveness);
0:         return size + sizeOfCell(null, header, rowLiveness);
0:     public long serializedSize(RangeTombstoneMarker marker, SerializationHeader header, int version)
0:                   + RangeTombstone.Bound.serializer.serializedSize(marker.clustering(), version, header.clusteringTypes());
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(bm.endDeletionTime(), header);
0:             size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(bm.startDeletionTime(), header);
0:            size += UnfilteredRowIteratorSerializer.delTimeSerializedSize(((RangeTombstoneBoundMarker)marker).deletionTime(), header);
/////////////////////////////////////////////////////////////////////////
1:     public long serializedSizeEndOfPartition()
/////////////////////////////////////////////////////////////////////////
0:     private long sizeOfCell(Cell cell, SerializationHeader header, LivenessInfo rowLiveness)
/////////////////////////////////////////////////////////////////////////
0:             size += header.getType(cell.column()).writtenLength(cell.value());
0:             size += TypeSizes.sizeof(header.encodeTimestamp(cell.livenessInfo().timestamp()));
0:             size += TypeSizes.sizeof(header.encodeDeletionTime(cell.livenessInfo().localDeletionTime()));
0:             size += TypeSizes.sizeof(header.encodeTTL(cell.livenessInfo().ttl()));
0:             size += cell.column().cellPathSerializer().serializedSize(cell.path());
============================================================================
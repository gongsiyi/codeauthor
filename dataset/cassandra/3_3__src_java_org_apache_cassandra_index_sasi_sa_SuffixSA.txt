1:72790dc: /*
1:72790dc:  * Licensed to the Apache Software Foundation (ASF) under one
1:72790dc:  * or more contributor license agreements.  See the NOTICE file
1:72790dc:  * distributed with this work for additional information
1:72790dc:  * regarding copyright ownership.  The ASF licenses this file
1:72790dc:  * to you under the Apache License, Version 2.0 (the
1:72790dc:  * "License"); you may not use this file except in compliance
1:72790dc:  * with the License.  You may obtain a copy of the License at
1:72790dc:  *
1:72790dc:  *     http://www.apache.org/licenses/LICENSE-2.0
1:72790dc:  *
1:72790dc:  * Unless required by applicable law or agreed to in writing, software
1:72790dc:  * distributed under the License is distributed on an "AS IS" BASIS,
1:72790dc:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:72790dc:  * See the License for the specific language governing permissions and
1:72790dc:  * limitations under the License.
1:72790dc:  */
1:72790dc: package org.apache.cassandra.index.sasi.sa;
1:72790dc: 
1:72790dc: import java.nio.ByteBuffer;
1:72790dc: import java.nio.CharBuffer;
1:72790dc: 
1:5c4d5c7: import org.apache.cassandra.index.sasi.disk.DynamicTokenTreeBuilder;
1:72790dc: import org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder;
1:72790dc: import org.apache.cassandra.index.sasi.disk.TokenTreeBuilder;
1:72790dc: import org.apache.cassandra.db.marshal.AbstractType;
1:8f0d5a2: import org.apache.cassandra.utils.LongTimSort;
1:72790dc: import org.apache.cassandra.utils.Pair;
1:72790dc: 
1:72790dc: import com.google.common.base.Charsets;
1:72790dc: 
1:72790dc: public class SuffixSA extends SA<CharBuffer>
1:72790dc: {
1:72790dc:     public SuffixSA(AbstractType<?> comparator, OnDiskIndexBuilder.Mode mode)
1:72790dc:     {
1:72790dc:         super(comparator, mode);
1:72790dc:     }
1:72790dc: 
1:72790dc:     protected Term<CharBuffer> getTerm(ByteBuffer termValue, TokenTreeBuilder tokens)
1:72790dc:     {
1:72790dc:         return new CharTerm(charCount, Charsets.UTF_8.decode(termValue.duplicate()), tokens);
1:72790dc:     }
1:72790dc: 
1:72790dc:     public TermIterator finish()
1:72790dc:     {
1:72790dc:         return new SASuffixIterator();
1:72790dc:     }
1:72790dc: 
1:72790dc:     private class SASuffixIterator extends TermIterator
1:72790dc:     {
1:2ca2fff: 
1:2ca2fff:         private static final int COMPLETE_BIT = 31;
1:2ca2fff: 
1:72790dc:         private final long[] suffixes;
1:72790dc: 
1:72790dc:         private int current = 0;
1:2ca2fff:         private IndexedTerm lastProcessedSuffix;
1:72790dc:         private TokenTreeBuilder container;
1:72790dc: 
1:72790dc:         public SASuffixIterator()
1:72790dc:         {
1:72790dc:             // each element has term index and char position encoded as two 32-bit integers
1:72790dc:             // to avoid binary search per suffix while sorting suffix array.
1:72790dc:             suffixes = new long[charCount];
1:72790dc: 
1:72790dc:             long termIndex = -1, currentTermLength = -1;
1:2ca2fff:             boolean isComplete = false;
1:72790dc:             for (int i = 0; i < charCount; i++)
1:72790dc:             {
1:72790dc:                 if (i >= currentTermLength || currentTermLength == -1)
1:72790dc:                 {
1:72790dc:                     Term currentTerm = terms.get((int) ++termIndex);
1:72790dc:                     currentTermLength = currentTerm.getPosition() + currentTerm.length();
1:2ca2fff:                     isComplete = true;
1:72790dc:                 }
1:72790dc: 
1:72790dc:                 suffixes[i] = (termIndex << 32) | i;
1:2ca2fff:                 if (isComplete)
1:2ca2fff:                     suffixes[i] |= (1L << COMPLETE_BIT);
1:2ca2fff: 
1:2ca2fff:                 isComplete = false;
1:72790dc:             }
1:72790dc: 
1:8f0d5a2:             LongTimSort.sort(suffixes, (a, b) -> {
1:72790dc:                 Term aTerm = terms.get((int) (a >>> 32));
1:72790dc:                 Term bTerm = terms.get((int) (b >>> 32));
1:2ca2fff:                 return comparator.compare(aTerm.getSuffix(clearCompleteBit(a) - aTerm.getPosition()),
1:2ca2fff:                                           bTerm.getSuffix(clearCompleteBit(b) - bTerm.getPosition()));
1:72790dc:             });
1:72790dc:         }
1:72790dc: 
1:2ca2fff:         private int clearCompleteBit(long value)
1:2ca2fff:         {
1:2ca2fff:             return (int) (value & ~(1L << COMPLETE_BIT));
1:2ca2fff:         }
1:2ca2fff: 
1:2ca2fff:         private Pair<IndexedTerm, TokenTreeBuilder> suffixAt(int position)
1:72790dc:         {
1:72790dc:             long index = suffixes[position];
1:72790dc:             Term term = terms.get((int) (index >>> 32));
1:2ca2fff:             boolean isPartitial = (index & ((long) 1 << 31)) == 0;
1:2ca2fff:             return Pair.create(new IndexedTerm(term.getSuffix(clearCompleteBit(index) - term.getPosition()), isPartitial), term.getTokens());
1:72790dc:         }
1:72790dc: 
1:72790dc:         public ByteBuffer minTerm()
1:72790dc:         {
1:2ca2fff:             return suffixAt(0).left.getBytes();
1:72790dc:         }
1:72790dc: 
1:72790dc:         public ByteBuffer maxTerm()
1:72790dc:         {
1:2ca2fff:             return suffixAt(suffixes.length - 1).left.getBytes();
1:72790dc:         }
1:72790dc: 
1:2ca2fff:         protected Pair<IndexedTerm, TokenTreeBuilder> computeNext()
1:72790dc:         {
1:72790dc:             while (true)
1:72790dc:             {
1:72790dc:                 if (current >= suffixes.length)
1:72790dc:                 {
1:72790dc:                     if (lastProcessedSuffix == null)
1:72790dc:                         return endOfData();
1:72790dc: 
1:2ca2fff:                     Pair<IndexedTerm, TokenTreeBuilder> result = finishSuffix();
1:72790dc: 
1:72790dc:                     lastProcessedSuffix = null;
1:72790dc:                     return result;
1:72790dc:                 }
1:72790dc: 
1:2ca2fff:                 Pair<IndexedTerm, TokenTreeBuilder> suffix = suffixAt(current++);
1:72790dc: 
1:72790dc:                 if (lastProcessedSuffix == null)
1:72790dc:                 {
1:72790dc:                     lastProcessedSuffix = suffix.left;
1:5c4d5c7:                     container = new DynamicTokenTreeBuilder(suffix.right);
1:72790dc:                 }
1:2ca2fff:                 else if (comparator.compare(lastProcessedSuffix.getBytes(), suffix.left.getBytes()) == 0)
1:72790dc:                 {
1:72790dc:                     lastProcessedSuffix = suffix.left;
1:5c4d5c7:                     container.add(suffix.right);
1:72790dc:                 }
1:72790dc:                 else
1:72790dc:                 {
1:2ca2fff:                     Pair<IndexedTerm, TokenTreeBuilder> result = finishSuffix();
1:72790dc: 
1:72790dc:                     lastProcessedSuffix = suffix.left;
1:5c4d5c7:                     container = new DynamicTokenTreeBuilder(suffix.right);
1:72790dc: 
1:72790dc:                     return result;
1:72790dc:                 }
1:72790dc:             }
1:72790dc:         }
1:72790dc: 
1:2ca2fff:         private Pair<IndexedTerm, TokenTreeBuilder> finishSuffix()
1:72790dc:         {
1:72790dc:             return Pair.create(lastProcessedSuffix, container.finish());
1:72790dc:         }
1:72790dc:     }
1:72790dc: }
============================================================================
author:Robert Stupp
-------------------------------------------------------------------------------
commit:8f0d5a2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.LongTimSort;
/////////////////////////////////////////////////////////////////////////
1:             LongTimSort.sort(suffixes, (a, b) -> {
author:Jordan West
-------------------------------------------------------------------------------
commit:2ca2fff
/////////////////////////////////////////////////////////////////////////
1: 
1:         private static final int COMPLETE_BIT = 31;
1: 
1:         private IndexedTerm lastProcessedSuffix;
/////////////////////////////////////////////////////////////////////////
1:             boolean isComplete = false;
1:                     isComplete = true;
1:                 if (isComplete)
1:                     suffixes[i] |= (1L << COMPLETE_BIT);
1: 
1:                 isComplete = false;
1:                 return comparator.compare(aTerm.getSuffix(clearCompleteBit(a) - aTerm.getPosition()),
1:                                           bTerm.getSuffix(clearCompleteBit(b) - bTerm.getPosition()));
1:         private int clearCompleteBit(long value)
1:         {
1:             return (int) (value & ~(1L << COMPLETE_BIT));
1:         }
1: 
1:         private Pair<IndexedTerm, TokenTreeBuilder> suffixAt(int position)
1:             boolean isPartitial = (index & ((long) 1 << 31)) == 0;
1:             return Pair.create(new IndexedTerm(term.getSuffix(clearCompleteBit(index) - term.getPosition()), isPartitial), term.getTokens());
1:             return suffixAt(0).left.getBytes();
1:             return suffixAt(suffixes.length - 1).left.getBytes();
1:         protected Pair<IndexedTerm, TokenTreeBuilder> computeNext()
/////////////////////////////////////////////////////////////////////////
1:                     Pair<IndexedTerm, TokenTreeBuilder> result = finishSuffix();
1:                 Pair<IndexedTerm, TokenTreeBuilder> suffix = suffixAt(current++);
1:                 else if (comparator.compare(lastProcessedSuffix.getBytes(), suffix.left.getBytes()) == 0)
1:                     Pair<IndexedTerm, TokenTreeBuilder> result = finishSuffix();
/////////////////////////////////////////////////////////////////////////
1:         private Pair<IndexedTerm, TokenTreeBuilder> finishSuffix()
commit:5c4d5c7
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.index.sasi.disk.DynamicTokenTreeBuilder;
/////////////////////////////////////////////////////////////////////////
1:                     container = new DynamicTokenTreeBuilder(suffix.right);
1:                     container.add(suffix.right);
1:                     container = new DynamicTokenTreeBuilder(suffix.right);
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:72790dc
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.index.sasi.sa;
1: 
1: import java.nio.ByteBuffer;
1: import java.nio.CharBuffer;
1: 
1: import org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder;
1: import org.apache.cassandra.index.sasi.disk.TokenTreeBuilder;
1: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.utils.Pair;
1: 
1: import com.google.common.base.Charsets;
0: import net.mintern.primitive.Primitive;
1: 
1: public class SuffixSA extends SA<CharBuffer>
1: {
1:     public SuffixSA(AbstractType<?> comparator, OnDiskIndexBuilder.Mode mode)
1:     {
1:         super(comparator, mode);
1:     }
1: 
1:     protected Term<CharBuffer> getTerm(ByteBuffer termValue, TokenTreeBuilder tokens)
1:     {
1:         return new CharTerm(charCount, Charsets.UTF_8.decode(termValue.duplicate()), tokens);
1:     }
1: 
1:     public TermIterator finish()
1:     {
1:         return new SASuffixIterator();
1:     }
1: 
1:     private class SASuffixIterator extends TermIterator
1:     {
1:         private final long[] suffixes;
1: 
1:         private int current = 0;
0:         private ByteBuffer lastProcessedSuffix;
1:         private TokenTreeBuilder container;
1: 
1:         public SASuffixIterator()
1:         {
1:             // each element has term index and char position encoded as two 32-bit integers
1:             // to avoid binary search per suffix while sorting suffix array.
1:             suffixes = new long[charCount];
1: 
1:             long termIndex = -1, currentTermLength = -1;
1:             for (int i = 0; i < charCount; i++)
1:             {
1:                 if (i >= currentTermLength || currentTermLength == -1)
1:                 {
1:                     Term currentTerm = terms.get((int) ++termIndex);
1:                     currentTermLength = currentTerm.getPosition() + currentTerm.length();
1:                 }
1: 
1:                 suffixes[i] = (termIndex << 32) | i;
1:             }
1: 
0:             Primitive.sort(suffixes, (a, b) -> {
1:                 Term aTerm = terms.get((int) (a >>> 32));
1:                 Term bTerm = terms.get((int) (b >>> 32));
0:                 return comparator.compare(aTerm.getSuffix(((int) a) - aTerm.getPosition()),
0:                                           bTerm.getSuffix(((int) b) - bTerm.getPosition()));
1:             });
1:         }
1: 
0:         private Pair<ByteBuffer, TokenTreeBuilder> suffixAt(int position)
1:         {
1:             long index = suffixes[position];
1:             Term term = terms.get((int) (index >>> 32));
0:             return Pair.create(term.getSuffix(((int) index) - term.getPosition()), term.getTokens());
1:         }
1: 
1:         public ByteBuffer minTerm()
1:         {
0:             return suffixAt(0).left;
1:         }
1: 
1:         public ByteBuffer maxTerm()
1:         {
0:             return suffixAt(suffixes.length - 1).left;
1:         }
1: 
0:         protected Pair<ByteBuffer, TokenTreeBuilder> computeNext()
1:         {
1:             while (true)
1:             {
1:                 if (current >= suffixes.length)
1:                 {
1:                     if (lastProcessedSuffix == null)
1:                         return endOfData();
1: 
0:                     Pair<ByteBuffer, TokenTreeBuilder> result = finishSuffix();
1: 
1:                     lastProcessedSuffix = null;
1:                     return result;
1:                 }
1: 
0:                 Pair<ByteBuffer, TokenTreeBuilder> suffix = suffixAt(current++);
1: 
1:                 if (lastProcessedSuffix == null)
1:                 {
1:                     lastProcessedSuffix = suffix.left;
0:                     container = new TokenTreeBuilder(suffix.right.getTokens());
1:                 }
0:                 else if (comparator.compare(lastProcessedSuffix, suffix.left) == 0)
1:                 {
1:                     lastProcessedSuffix = suffix.left;
0:                     container.add(suffix.right.getTokens());
1:                 }
1:                 else
1:                 {
0:                     Pair<ByteBuffer, TokenTreeBuilder> result = finishSuffix();
1: 
1:                     lastProcessedSuffix = suffix.left;
0:                     container = new TokenTreeBuilder(suffix.right.getTokens());
1: 
1:                     return result;
1:                 }
1:             }
1:         }
1: 
0:         private Pair<ByteBuffer, TokenTreeBuilder> finishSuffix()
1:         {
1:             return Pair.create(lastProcessedSuffix, container.finish());
1:         }
1:     }
1: }
============================================================================
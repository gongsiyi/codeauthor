1:d40ac78: /*
1:d40ac78:  * Licensed to the Apache Software Foundation (ASF) under one
1:d40ac78:  * or more contributor license agreements.  See the NOTICE file
1:d40ac78:  * distributed with this work for additional information
1:d40ac78:  * regarding copyright ownership.  The ASF licenses this file
1:d40ac78:  * to you under the Apache License, Version 2.0 (the
1:d40ac78:  * "License"); you may not use this file except in compliance
1:d40ac78:  * with the License.  You may obtain a copy of the License at
1:d40ac78:  *
1:d40ac78:  *     http://www.apache.org/licenses/LICENSE-2.0
1:d40ac78:  *
1:d40ac78:  * Unless required by applicable law or agreed to in writing, software
1:d40ac78:  * distributed under the License is distributed on an "AS IS" BASIS,
1:d40ac78:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:d40ac78:  * See the License for the specific language governing permissions and
1:d40ac78:  * limitations under the License.
1:d40ac78:  */
1:d40ac78: 
1:d40ac78: package org.apache.cassandra.cql3;
1:d40ac78: 
1:d40ac78: import java.util.ArrayList;
1:d40ac78: import java.util.Arrays;
1:d40ac78: import java.util.List;
1:d40ac78: import java.util.Random;
1:d40ac78: import java.util.concurrent.ExecutorService;
1:d40ac78: import java.util.concurrent.Executors;
1:d40ac78: import java.util.concurrent.Future;
1:d40ac78: import java.util.concurrent.atomic.AtomicLong;
1:d40ac78: import java.util.function.Predicate;
1:d40ac78: 
1:d40ac78: import com.google.common.collect.Iterables;
1:d40ac78: import org.junit.Before;
1:d40ac78: import org.junit.BeforeClass;
1:d40ac78: import org.junit.Test;
1:d40ac78: 
1:d40ac78: import junit.framework.Assert;
1:d40ac78: import org.apache.cassandra.config.Config.CommitLogSync;
1:d40ac78: import org.apache.cassandra.config.DatabaseDescriptor;
1:d40ac78: import org.apache.cassandra.db.ColumnFamilyStore;
1:d40ac78: import org.apache.cassandra.db.compaction.CompactionManager;
1:d40ac78: import org.apache.cassandra.db.rows.Row;
1:d40ac78: import org.apache.cassandra.db.rows.Unfiltered;
1:d40ac78: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
1:d40ac78: import org.apache.cassandra.io.sstable.ISSTableScanner;
1:d40ac78: import org.apache.cassandra.io.sstable.format.SSTableReader;
1:d40ac78: import org.apache.cassandra.schema.CompactionParams.TombstoneOption;
1:d40ac78: import org.apache.cassandra.utils.FBUtilities;
1:d40ac78: 
1:d40ac78: public class GcCompactionBench extends CQLTester
1:d40ac78: {
1:d40ac78:     private static final String SIZE_TIERED_STRATEGY = "SizeTieredCompactionStrategy', 'min_sstable_size' : '0";
1:d40ac78:     private static final String LEVELED_STRATEGY = "LeveledCompactionStrategy', 'sstable_size_in_mb' : '16";
1:d40ac78: 
1:d40ac78:     private static final int DEL_SECTIONS = 1000;
1:d40ac78:     private static final int FLUSH_FREQ = 10000;
1:d40ac78:     private static final int RANGE_FREQUENCY_INV = 16;
1:d40ac78:     static final int COUNT = 90000;
1:d40ac78:     static final int ITERS = 9;
1:d40ac78: 
1:d40ac78:     static final int KEY_RANGE = 10;
1:d40ac78:     static final int CLUSTERING_RANGE = 210000;
1:d40ac78: 
1:d40ac78:     static final int EXTRA_SIZE = 1025;
1:d40ac78: 
1:d40ac78:     // The name of this method is important!
1:d40ac78:     // CommitLog settings must be applied before CQLTester sets up; by using the same name as its @BeforeClass method we
1:d40ac78:     // are effectively overriding it.
1:d40ac78:     @BeforeClass
1:d40ac78:     public static void setUpClass()     // overrides CQLTester.setUpClass()
1:d40ac78:     {
1:d40ac78:         DatabaseDescriptor.setCommitLogSync(CommitLogSync.periodic);
1:d40ac78:         DatabaseDescriptor.setCommitLogSyncPeriod(100);
1:d40ac78:         CQLTester.setUpClass();
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     String hashQuery;
1:d40ac78: 
1:d40ac78:     @Before
1:d40ac78:     public void before() throws Throwable
1:d40ac78:     {
1:d40ac78:         createTable("CREATE TABLE %s(" +
1:d40ac78:                     "  key int," +
1:d40ac78:                     "  column int," +
1:d40ac78:                     "  data int," +
1:d40ac78:                     "  extra text," +
1:d40ac78:                     "  PRIMARY KEY(key, column)" +
1:d40ac78:                     ")"
1:d40ac78:                    );
1:d40ac78: 
1:d40ac78:         String hashIFunc = parseFunctionName(createFunction(KEYSPACE, "int, int",
1:d40ac78:                 " CREATE FUNCTION %s (state int, val int)" +
1:d40ac78:                 " CALLED ON NULL INPUT" +
1:d40ac78:                 " RETURNS int" +
1:d40ac78:                 " LANGUAGE java" +
1:d40ac78:                 " AS 'return val != null ? state * 17 + val : state;'")).name;
1:d40ac78:         String hashTFunc = parseFunctionName(createFunction(KEYSPACE, "int, text",
1:d40ac78:                 " CREATE FUNCTION %s (state int, val text)" +
1:d40ac78:                 " CALLED ON NULL INPUT" +
1:d40ac78:                 " RETURNS int" +
1:d40ac78:                 " LANGUAGE java" +
1:d40ac78:                 " AS 'return val != null ? state * 17 + val.hashCode() : state;'")).name;
1:d40ac78: 
1:d40ac78:         String hashInt = createAggregate(KEYSPACE, "int",
1:d40ac78:                 " CREATE AGGREGATE %s (int)" +
1:d40ac78:                 " SFUNC " + hashIFunc +
1:d40ac78:                 " STYPE int" +
1:d40ac78:                 " INITCOND 1");
1:d40ac78:         String hashText = createAggregate(KEYSPACE, "text",
1:d40ac78:                 " CREATE AGGREGATE %s (text)" +
1:d40ac78:                 " SFUNC " + hashTFunc +
1:d40ac78:                 " STYPE int" +
1:d40ac78:                 " INITCOND 1");
1:d40ac78: 
1:d40ac78:         hashQuery = String.format("SELECT count(column), %s(key), %s(column), %s(data), %s(extra), avg(key), avg(column), avg(data) FROM %%s",
1:d40ac78:                                   hashInt, hashInt, hashInt, hashText);
1:d40ac78:     }
1:d40ac78:     AtomicLong id = new AtomicLong();
1:d40ac78:     long compactionTimeNanos = 0;
1:d40ac78: 
1:d40ac78:     void pushData(Random rand, int count) throws Throwable
1:d40ac78:     {
1:d40ac78:         for (int i = 0; i < count; ++i)
1:d40ac78:         {
1:d40ac78:             long ii = id.incrementAndGet();
1:d40ac78:             if (ii % 1000 == 0)
1:d40ac78:                 System.out.print('.');
1:d40ac78:             int key = rand.nextInt(KEY_RANGE);
1:d40ac78:             int column = rand.nextInt(CLUSTERING_RANGE);
1:d40ac78:             execute("INSERT INTO %s (key, column, data, extra) VALUES (?, ?, ?, ?)", key, column, (int) ii, genExtra(rand));
1:d40ac78:             maybeCompact(ii);
1:d40ac78:         }
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     private String genExtra(Random rand)
1:d40ac78:     {
1:d40ac78:         StringBuilder builder = new StringBuilder(EXTRA_SIZE);
1:d40ac78:         for (int i = 0; i < EXTRA_SIZE; ++i)
1:d40ac78:             builder.append((char) ('a' + rand.nextInt('z' - 'a' + 1)));
1:d40ac78:         return builder.toString();
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     void deleteData(Random rand, int count) throws Throwable
1:d40ac78:     {
1:d40ac78:         for (int i = 0; i < count; ++i)
1:d40ac78:         {
1:d40ac78:             int key;
1:d40ac78:             UntypedResultSet res;
1:d40ac78:             long ii = id.incrementAndGet();
1:d40ac78:             if (ii % 1000 == 0)
1:d40ac78:                 System.out.print('-');
1:d40ac78:             if (rand.nextInt(RANGE_FREQUENCY_INV) != 1)
1:d40ac78:             {
1:d40ac78:                 do
1:d40ac78:                 {
1:d40ac78:                     key = rand.nextInt(KEY_RANGE);
1:d40ac78:                     long cid = rand.nextInt(DEL_SECTIONS);
1:d40ac78:                     int cstart = (int) (cid * CLUSTERING_RANGE / DEL_SECTIONS);
1:d40ac78:                     int cend = (int) ((cid + 1) * CLUSTERING_RANGE / DEL_SECTIONS);
1:d40ac78:                     res = execute("SELECT column FROM %s WHERE key = ? AND column >= ? AND column < ? LIMIT 1", key, cstart, cend);
1:d40ac78:                 } while (res.size() == 0);
1:d40ac78:                 UntypedResultSet.Row r = Iterables.get(res, rand.nextInt(res.size()));
1:d40ac78:                 int clustering = r.getInt("column");
1:d40ac78:                 execute("DELETE FROM %s WHERE key = ? AND column = ?", key, clustering);
1:d40ac78:             }
1:d40ac78:             else
1:d40ac78:             {
1:d40ac78:                 key = rand.nextInt(KEY_RANGE);
1:d40ac78:                 long cid = rand.nextInt(DEL_SECTIONS);
1:d40ac78:                 int cstart = (int) (cid * CLUSTERING_RANGE / DEL_SECTIONS);
1:d40ac78:                 int cend = (int) ((cid + 1) * CLUSTERING_RANGE / DEL_SECTIONS);
1:d40ac78:                 res = execute("DELETE FROM %s WHERE key = ? AND column >= ? AND column < ?", key, cstart, cend);
1:d40ac78:             }
1:d40ac78:             maybeCompact(ii);
1:d40ac78:         }
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     private void maybeCompact(long ii)
1:d40ac78:     {
1:d40ac78:         if (ii % FLUSH_FREQ == 0)
1:d40ac78:         {
1:d40ac78:             System.out.print("F");
1:d40ac78:             flush();
1:d40ac78:             if (ii % (FLUSH_FREQ * 10) == 0)
1:d40ac78:             {
1:d40ac78:                 System.out.println("C");
1:d40ac78:                 long startTime = System.nanoTime();
1:d40ac78:                 getCurrentColumnFamilyStore().enableAutoCompaction(true);
1:d40ac78:                 long endTime = System.nanoTime();
1:d40ac78:                 compactionTimeNanos += endTime - startTime;
1:d40ac78:                 getCurrentColumnFamilyStore().disableAutoCompaction();
1:d40ac78:             }
1:d40ac78:         }
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     public void testGcCompaction(TombstoneOption tombstoneOption, TombstoneOption backgroundTombstoneOption, String compactionClass) throws Throwable
1:d40ac78:     {
1:d40ac78:         id.set(0);
1:d40ac78:         compactionTimeNanos = 0;
1:d40ac78:         alterTable("ALTER TABLE %s WITH compaction = { 'class' :  '" + compactionClass + "', 'provide_overlapping_tombstones' : '" + backgroundTombstoneOption + "'  };");
1:d40ac78:         ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
1:d40ac78:         cfs.disableAutoCompaction();
1:d40ac78: 
1:d40ac78:         long onStartTime = System.currentTimeMillis();
1:d40ac78:         ExecutorService es = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
1:d40ac78:         List<Future<?>> tasks = new ArrayList<>();
1:d40ac78:         for (int ti = 0; ti < 1; ++ti)
1:d40ac78:         {
1:d40ac78:             Random rand = new Random(ti);
1:d40ac78:             tasks.add(es.submit(() -> 
1:d40ac78:             {
1:d40ac78:                 for (int i = 0; i < ITERS; ++i)
1:d40ac78:                     try
1:d40ac78:                     {
1:d40ac78:                         pushData(rand, COUNT);
1:d40ac78:                         deleteData(rand, COUNT / 3);
1:d40ac78:                     }
1:d40ac78:                     catch (Throwable e)
1:d40ac78:                     {
1:d40ac78:                         throw new AssertionError(e);
1:d40ac78:                     }
1:d40ac78:             }));
1:d40ac78:         }
1:d40ac78:         for (Future<?> task : tasks)
1:d40ac78:             task.get();
1:d40ac78: 
1:d40ac78:         flush();
1:d40ac78:         long onEndTime = System.currentTimeMillis();
1:d40ac78:         int startRowCount = countRows(cfs);
1:d40ac78:         int startTombCount = countTombstoneMarkers(cfs);
1:d40ac78:         int startRowDeletions = countRowDeletions(cfs);
1:d40ac78:         int startTableCount = cfs.getLiveSSTables().size();
1:d40ac78:         long startSize = SSTableReader.getTotalBytes(cfs.getLiveSSTables());
1:d40ac78:         System.out.println();
1:d40ac78: 
1:d40ac78:         String hashesBefore = getHashes();
1:d40ac78: 
1:d40ac78:         long startTime = System.currentTimeMillis();
1:d40ac78:         CompactionManager.instance.performGarbageCollection(cfs, tombstoneOption, 0);
1:d40ac78:         long endTime = System.currentTimeMillis();
1:d40ac78: 
1:d40ac78:         int endRowCount = countRows(cfs);
1:d40ac78:         int endTombCount = countTombstoneMarkers(cfs);
1:d40ac78:         int endRowDeletions = countRowDeletions(cfs);
1:d40ac78:         int endTableCount = cfs.getLiveSSTables().size();
1:d40ac78:         long endSize = SSTableReader.getTotalBytes(cfs.getLiveSSTables());
1:d40ac78: 
1:d40ac78:         System.out.println(cfs.getCompactionParametersJson());
1:d40ac78:         System.out.println(String.format("%s compactions completed in %.3fs",
1:d40ac78:                 tombstoneOption.toString(), (endTime - startTime) * 1e-3));
1:d40ac78:         System.out.println(String.format("Operations completed in %.3fs, out of which %.3f for ongoing " + backgroundTombstoneOption + " background compactions",
1:d40ac78:                 (onEndTime - onStartTime) * 1e-3, compactionTimeNanos * 1e-9));
1:d40ac78:         System.out.println(String.format("At start: %12d tables %12d bytes %12d rows %12d deleted rows %12d tombstone markers",
1:d40ac78:                 startTableCount, startSize, startRowCount, startRowDeletions, startTombCount));
1:d40ac78:         System.out.println(String.format("At end:   %12d tables %12d bytes %12d rows %12d deleted rows %12d tombstone markers",
1:d40ac78:                 endTableCount, endSize, endRowCount, endRowDeletions, endTombCount));
1:d40ac78: 
1:d40ac78:         String hashesAfter = getHashes();
1:d40ac78:         Assert.assertEquals(hashesBefore, hashesAfter);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     private String getHashes() throws Throwable
1:d40ac78:     {
1:d40ac78:         long startTime = System.currentTimeMillis();
1:d40ac78:         String hashes = Arrays.toString(getRows(execute(hashQuery))[0]);
1:d40ac78:         long endTime = System.currentTimeMillis();
1:d40ac78:         System.out.println(String.format("Hashes: %s, retrieved in %.3fs", hashes, (endTime - startTime) * 1e-3));
1:d40ac78:         return hashes;
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCellAtEnd() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, LEVELED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testRowAtEnd() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, LEVELED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCellThroughout() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.CELL, LEVELED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testRowThroughout() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.ROW, LEVELED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCopyCompaction() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.NONE, TombstoneOption.NONE, LEVELED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCellAtEndSizeTiered() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testRowAtEndSizeTiered() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCellThroughoutSizeTiered() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.CELL, SIZE_TIERED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testRowThroughoutSizeTiered() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.ROW, SIZE_TIERED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     @Test
1:d40ac78:     public void testCopyCompactionSizeTiered() throws Throwable
1:d40ac78:     {
1:d40ac78:         testGcCompaction(TombstoneOption.NONE, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     int countTombstoneMarkers(ColumnFamilyStore cfs)
1:d40ac78:     {
1:d40ac78:         return count(cfs, x -> x.isRangeTombstoneMarker());
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     int countRowDeletions(ColumnFamilyStore cfs)
1:d40ac78:     {
1:d40ac78:         return count(cfs, x -> x.isRow() && !((Row) x).deletion().isLive());
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     int countRows(ColumnFamilyStore cfs)
1:d40ac78:     {
1:d40ac78:         int nowInSec = FBUtilities.nowInSeconds();
1:d40ac78:         return count(cfs, x -> x.isRow() && ((Row) x).hasLiveData(nowInSec));
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     private int count(ColumnFamilyStore cfs, Predicate<Unfiltered> predicate)
1:d40ac78:     {
1:d40ac78:         int count = 0;
1:d40ac78:         for (SSTableReader reader : cfs.getLiveSSTables())
1:d40ac78:             count += count(reader, predicate);
1:d40ac78:         return count;
1:d40ac78:     }
1:d40ac78: 
1:d40ac78:     int count(SSTableReader reader, Predicate<Unfiltered> predicate)
1:d40ac78:     {
1:d40ac78:         int instances = 0;
1:d40ac78:         try (ISSTableScanner partitions = reader.getScanner())
1:d40ac78:         {
1:d40ac78:             while (partitions.hasNext())
1:d40ac78:             {
1:d40ac78:                 try (UnfilteredRowIterator iter = partitions.next())
1:d40ac78:                 {
1:d40ac78:                     while (iter.hasNext())
1:d40ac78:                     {
1:d40ac78:                         Unfiltered atom = iter.next();
1:d40ac78:                         if (predicate.test(atom))
1:d40ac78:                             ++instances;
1:d40ac78:                     }
1:d40ac78:                 }
1:d40ac78:             }
1:d40ac78:         }
1:d40ac78:         return instances;
1:d40ac78:     }
1:d40ac78: }
============================================================================
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:d40ac78
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.cassandra.cql3;
1: 
1: import java.util.ArrayList;
1: import java.util.Arrays;
1: import java.util.List;
1: import java.util.Random;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.Future;
1: import java.util.concurrent.atomic.AtomicLong;
1: import java.util.function.Predicate;
1: 
1: import com.google.common.collect.Iterables;
1: import org.junit.Before;
1: import org.junit.BeforeClass;
1: import org.junit.Test;
1: 
1: import junit.framework.Assert;
1: import org.apache.cassandra.config.Config.CommitLogSync;
1: import org.apache.cassandra.config.DatabaseDescriptor;
1: import org.apache.cassandra.db.ColumnFamilyStore;
1: import org.apache.cassandra.db.compaction.CompactionManager;
1: import org.apache.cassandra.db.rows.Row;
1: import org.apache.cassandra.db.rows.Unfiltered;
1: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
1: import org.apache.cassandra.io.sstable.ISSTableScanner;
1: import org.apache.cassandra.io.sstable.format.SSTableReader;
1: import org.apache.cassandra.schema.CompactionParams.TombstoneOption;
1: import org.apache.cassandra.utils.FBUtilities;
1: 
1: public class GcCompactionBench extends CQLTester
1: {
1:     private static final String SIZE_TIERED_STRATEGY = "SizeTieredCompactionStrategy', 'min_sstable_size' : '0";
1:     private static final String LEVELED_STRATEGY = "LeveledCompactionStrategy', 'sstable_size_in_mb' : '16";
1: 
1:     private static final int DEL_SECTIONS = 1000;
1:     private static final int FLUSH_FREQ = 10000;
1:     private static final int RANGE_FREQUENCY_INV = 16;
1:     static final int COUNT = 90000;
1:     static final int ITERS = 9;
1: 
1:     static final int KEY_RANGE = 10;
1:     static final int CLUSTERING_RANGE = 210000;
1: 
1:     static final int EXTRA_SIZE = 1025;
1: 
1:     // The name of this method is important!
1:     // CommitLog settings must be applied before CQLTester sets up; by using the same name as its @BeforeClass method we
1:     // are effectively overriding it.
1:     @BeforeClass
1:     public static void setUpClass()     // overrides CQLTester.setUpClass()
1:     {
1:         DatabaseDescriptor.setCommitLogSync(CommitLogSync.periodic);
1:         DatabaseDescriptor.setCommitLogSyncPeriod(100);
1:         CQLTester.setUpClass();
1:     }
1: 
1:     String hashQuery;
1: 
1:     @Before
1:     public void before() throws Throwable
1:     {
1:         createTable("CREATE TABLE %s(" +
1:                     "  key int," +
1:                     "  column int," +
1:                     "  data int," +
1:                     "  extra text," +
1:                     "  PRIMARY KEY(key, column)" +
1:                     ")"
1:                    );
1: 
1:         String hashIFunc = parseFunctionName(createFunction(KEYSPACE, "int, int",
1:                 " CREATE FUNCTION %s (state int, val int)" +
1:                 " CALLED ON NULL INPUT" +
1:                 " RETURNS int" +
1:                 " LANGUAGE java" +
1:                 " AS 'return val != null ? state * 17 + val : state;'")).name;
1:         String hashTFunc = parseFunctionName(createFunction(KEYSPACE, "int, text",
1:                 " CREATE FUNCTION %s (state int, val text)" +
1:                 " CALLED ON NULL INPUT" +
1:                 " RETURNS int" +
1:                 " LANGUAGE java" +
1:                 " AS 'return val != null ? state * 17 + val.hashCode() : state;'")).name;
1: 
1:         String hashInt = createAggregate(KEYSPACE, "int",
1:                 " CREATE AGGREGATE %s (int)" +
1:                 " SFUNC " + hashIFunc +
1:                 " STYPE int" +
1:                 " INITCOND 1");
1:         String hashText = createAggregate(KEYSPACE, "text",
1:                 " CREATE AGGREGATE %s (text)" +
1:                 " SFUNC " + hashTFunc +
1:                 " STYPE int" +
1:                 " INITCOND 1");
1: 
1:         hashQuery = String.format("SELECT count(column), %s(key), %s(column), %s(data), %s(extra), avg(key), avg(column), avg(data) FROM %%s",
1:                                   hashInt, hashInt, hashInt, hashText);
1:     }
1:     AtomicLong id = new AtomicLong();
1:     long compactionTimeNanos = 0;
1: 
1:     void pushData(Random rand, int count) throws Throwable
1:     {
1:         for (int i = 0; i < count; ++i)
1:         {
1:             long ii = id.incrementAndGet();
1:             if (ii % 1000 == 0)
1:                 System.out.print('.');
1:             int key = rand.nextInt(KEY_RANGE);
1:             int column = rand.nextInt(CLUSTERING_RANGE);
1:             execute("INSERT INTO %s (key, column, data, extra) VALUES (?, ?, ?, ?)", key, column, (int) ii, genExtra(rand));
1:             maybeCompact(ii);
1:         }
1:     }
1: 
1:     private String genExtra(Random rand)
1:     {
1:         StringBuilder builder = new StringBuilder(EXTRA_SIZE);
1:         for (int i = 0; i < EXTRA_SIZE; ++i)
1:             builder.append((char) ('a' + rand.nextInt('z' - 'a' + 1)));
1:         return builder.toString();
1:     }
1: 
1:     void deleteData(Random rand, int count) throws Throwable
1:     {
1:         for (int i = 0; i < count; ++i)
1:         {
1:             int key;
1:             UntypedResultSet res;
1:             long ii = id.incrementAndGet();
1:             if (ii % 1000 == 0)
1:                 System.out.print('-');
1:             if (rand.nextInt(RANGE_FREQUENCY_INV) != 1)
1:             {
1:                 do
1:                 {
1:                     key = rand.nextInt(KEY_RANGE);
1:                     long cid = rand.nextInt(DEL_SECTIONS);
1:                     int cstart = (int) (cid * CLUSTERING_RANGE / DEL_SECTIONS);
1:                     int cend = (int) ((cid + 1) * CLUSTERING_RANGE / DEL_SECTIONS);
1:                     res = execute("SELECT column FROM %s WHERE key = ? AND column >= ? AND column < ? LIMIT 1", key, cstart, cend);
1:                 } while (res.size() == 0);
1:                 UntypedResultSet.Row r = Iterables.get(res, rand.nextInt(res.size()));
1:                 int clustering = r.getInt("column");
1:                 execute("DELETE FROM %s WHERE key = ? AND column = ?", key, clustering);
1:             }
1:             else
1:             {
1:                 key = rand.nextInt(KEY_RANGE);
1:                 long cid = rand.nextInt(DEL_SECTIONS);
1:                 int cstart = (int) (cid * CLUSTERING_RANGE / DEL_SECTIONS);
1:                 int cend = (int) ((cid + 1) * CLUSTERING_RANGE / DEL_SECTIONS);
1:                 res = execute("DELETE FROM %s WHERE key = ? AND column >= ? AND column < ?", key, cstart, cend);
1:             }
1:             maybeCompact(ii);
1:         }
1:     }
1: 
1:     private void maybeCompact(long ii)
1:     {
1:         if (ii % FLUSH_FREQ == 0)
1:         {
1:             System.out.print("F");
1:             flush();
1:             if (ii % (FLUSH_FREQ * 10) == 0)
1:             {
1:                 System.out.println("C");
1:                 long startTime = System.nanoTime();
1:                 getCurrentColumnFamilyStore().enableAutoCompaction(true);
1:                 long endTime = System.nanoTime();
1:                 compactionTimeNanos += endTime - startTime;
1:                 getCurrentColumnFamilyStore().disableAutoCompaction();
1:             }
1:         }
1:     }
1: 
1:     public void testGcCompaction(TombstoneOption tombstoneOption, TombstoneOption backgroundTombstoneOption, String compactionClass) throws Throwable
1:     {
1:         id.set(0);
1:         compactionTimeNanos = 0;
1:         alterTable("ALTER TABLE %s WITH compaction = { 'class' :  '" + compactionClass + "', 'provide_overlapping_tombstones' : '" + backgroundTombstoneOption + "'  };");
1:         ColumnFamilyStore cfs = getCurrentColumnFamilyStore();
1:         cfs.disableAutoCompaction();
1: 
1:         long onStartTime = System.currentTimeMillis();
1:         ExecutorService es = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
1:         List<Future<?>> tasks = new ArrayList<>();
1:         for (int ti = 0; ti < 1; ++ti)
1:         {
1:             Random rand = new Random(ti);
1:             tasks.add(es.submit(() -> 
1:             {
1:                 for (int i = 0; i < ITERS; ++i)
1:                     try
1:                     {
1:                         pushData(rand, COUNT);
1:                         deleteData(rand, COUNT / 3);
1:                     }
1:                     catch (Throwable e)
1:                     {
1:                         throw new AssertionError(e);
1:                     }
1:             }));
1:         }
1:         for (Future<?> task : tasks)
1:             task.get();
1: 
1:         flush();
1:         long onEndTime = System.currentTimeMillis();
1:         int startRowCount = countRows(cfs);
1:         int startTombCount = countTombstoneMarkers(cfs);
1:         int startRowDeletions = countRowDeletions(cfs);
1:         int startTableCount = cfs.getLiveSSTables().size();
1:         long startSize = SSTableReader.getTotalBytes(cfs.getLiveSSTables());
1:         System.out.println();
1: 
1:         String hashesBefore = getHashes();
1: 
1:         long startTime = System.currentTimeMillis();
1:         CompactionManager.instance.performGarbageCollection(cfs, tombstoneOption, 0);
1:         long endTime = System.currentTimeMillis();
1: 
1:         int endRowCount = countRows(cfs);
1:         int endTombCount = countTombstoneMarkers(cfs);
1:         int endRowDeletions = countRowDeletions(cfs);
1:         int endTableCount = cfs.getLiveSSTables().size();
1:         long endSize = SSTableReader.getTotalBytes(cfs.getLiveSSTables());
1: 
1:         System.out.println(cfs.getCompactionParametersJson());
1:         System.out.println(String.format("%s compactions completed in %.3fs",
1:                 tombstoneOption.toString(), (endTime - startTime) * 1e-3));
1:         System.out.println(String.format("Operations completed in %.3fs, out of which %.3f for ongoing " + backgroundTombstoneOption + " background compactions",
1:                 (onEndTime - onStartTime) * 1e-3, compactionTimeNanos * 1e-9));
1:         System.out.println(String.format("At start: %12d tables %12d bytes %12d rows %12d deleted rows %12d tombstone markers",
1:                 startTableCount, startSize, startRowCount, startRowDeletions, startTombCount));
1:         System.out.println(String.format("At end:   %12d tables %12d bytes %12d rows %12d deleted rows %12d tombstone markers",
1:                 endTableCount, endSize, endRowCount, endRowDeletions, endTombCount));
1: 
1:         String hashesAfter = getHashes();
1:         Assert.assertEquals(hashesBefore, hashesAfter);
1:     }
1: 
1:     private String getHashes() throws Throwable
1:     {
1:         long startTime = System.currentTimeMillis();
1:         String hashes = Arrays.toString(getRows(execute(hashQuery))[0]);
1:         long endTime = System.currentTimeMillis();
1:         System.out.println(String.format("Hashes: %s, retrieved in %.3fs", hashes, (endTime - startTime) * 1e-3));
1:         return hashes;
1:     }
1: 
1:     @Test
1:     public void testCellAtEnd() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, LEVELED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testRowAtEnd() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, LEVELED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testCellThroughout() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.CELL, LEVELED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testRowThroughout() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.ROW, LEVELED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testCopyCompaction() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.NONE, TombstoneOption.NONE, LEVELED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testCellAtEndSizeTiered() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testRowAtEndSizeTiered() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testCellThroughoutSizeTiered() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.CELL, TombstoneOption.CELL, SIZE_TIERED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testRowThroughoutSizeTiered() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.ROW, TombstoneOption.ROW, SIZE_TIERED_STRATEGY);
1:     }
1: 
1:     @Test
1:     public void testCopyCompactionSizeTiered() throws Throwable
1:     {
1:         testGcCompaction(TombstoneOption.NONE, TombstoneOption.NONE, SIZE_TIERED_STRATEGY);
1:     }
1: 
1:     int countTombstoneMarkers(ColumnFamilyStore cfs)
1:     {
1:         return count(cfs, x -> x.isRangeTombstoneMarker());
1:     }
1: 
1:     int countRowDeletions(ColumnFamilyStore cfs)
1:     {
1:         return count(cfs, x -> x.isRow() && !((Row) x).deletion().isLive());
1:     }
1: 
1:     int countRows(ColumnFamilyStore cfs)
1:     {
1:         int nowInSec = FBUtilities.nowInSeconds();
1:         return count(cfs, x -> x.isRow() && ((Row) x).hasLiveData(nowInSec));
1:     }
1: 
1:     private int count(ColumnFamilyStore cfs, Predicate<Unfiltered> predicate)
1:     {
1:         int count = 0;
1:         for (SSTableReader reader : cfs.getLiveSSTables())
1:             count += count(reader, predicate);
1:         return count;
1:     }
1: 
1:     int count(SSTableReader reader, Predicate<Unfiltered> predicate)
1:     {
1:         int instances = 0;
1:         try (ISSTableScanner partitions = reader.getScanner())
1:         {
1:             while (partitions.hasNext())
1:             {
1:                 try (UnfilteredRowIterator iter = partitions.next())
1:                 {
1:                     while (iter.hasNext())
1:                     {
1:                         Unfiltered atom = iter.next();
1:                         if (predicate.test(atom))
1:                             ++instances;
1:                     }
1:                 }
1:             }
1:         }
1:         return instances;
1:     }
1: }
============================================================================
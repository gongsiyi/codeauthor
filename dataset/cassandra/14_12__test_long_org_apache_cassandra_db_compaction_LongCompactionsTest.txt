1:f92fb22: /*
1:f92fb22: * Licensed to the Apache Software Foundation (ASF) under one
1:f92fb22: * or more contributor license agreements.  See the NOTICE file
1:f92fb22: * distributed with this work for additional information
1:f92fb22: * regarding copyright ownership.  The ASF licenses this file
1:f92fb22: * to you under the Apache License, Version 2.0 (the
1:f92fb22: * "License"); you may not use this file except in compliance
1:f92fb22: * with the License.  You may obtain a copy of the License at
1:f92fb22: *
1:f92fb22: *    http://www.apache.org/licenses/LICENSE-2.0
1:f92fb22: *
1:f92fb22: * Unless required by applicable law or agreed to in writing,
1:f92fb22: * software distributed under the License is distributed on an
1:f92fb22: * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:f92fb22: * KIND, either express or implied.  See the License for the
1:f92fb22: * specific language governing permissions and limitations
1:f92fb22: * under the License.
1:f92fb22: */
1:f92fb22: package org.apache.cassandra.db.compaction;
10:f92fb22: 
1:f92fb22: import java.util.*;
1:f92fb22: import java.util.concurrent.Future;
1:1d2c122: import java.util.concurrent.TimeUnit;
1:f92fb22: 
1:d2a3827: import org.junit.BeforeClass;
1:e7d802e: import org.junit.Before;
1:f92fb22: import org.junit.Test;
1:e7d802e: 
1:a991b64: import org.apache.cassandra.UpdateBuilder;
1:f92fb22: import org.apache.cassandra.SchemaLoader;
1:e7d802e: import org.apache.cassandra.config.Schema;
1:f92fb22: import org.apache.cassandra.Util;
1:d2a3827: import org.apache.cassandra.exceptions.ConfigurationException;
1:f92fb22: import org.apache.cassandra.db.*;
1:a991b64: import org.apache.cassandra.db.partitions.*;
1:0368e97: import org.apache.cassandra.io.sstable.format.SSTableReader;
1:e5a76bd: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1:f92fb22: import org.apache.cassandra.io.sstable.SSTableUtils;
1:b31845c: import org.apache.cassandra.schema.CompactionParams;
1:31e3f61: import org.apache.cassandra.schema.KeyspaceParams;
1:f92fb22: import org.apache.cassandra.utils.ByteBufferUtil;
1:f92fb22: import org.apache.cassandra.utils.FBUtilities;
1:83a43f1: import static org.junit.Assert.assertEquals;
1:f92fb22: 
1:d2a3827: public class LongCompactionsTest
5:f92fb22: {
1:0e96e58:     public static final String KEYSPACE1 = "Keyspace1";
1:d2a3827:     public static final String CF_STANDARD = "Standard1";
1:d2a3827: 
1:d2a3827:     @BeforeClass
1:d2a3827:     public static void defineSchema() throws ConfigurationException
1:d2a3827:     {
1:b31845c:         Map<String, String> compactionOptions = Collections.singletonMap("tombstone_compaction_interval", "1");
1:d2a3827:         SchemaLoader.prepareServer();
1:d2a3827:         SchemaLoader.createKeyspace(KEYSPACE1,
1:31e3f61:                                     KeyspaceParams.simple(1),
1:d2a3827:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD)
1:b31845c:                                                 .compaction(CompactionParams.scts(compactionOptions)));
1:d2a3827:     }
1:f92fb22: 
1:e7d802e:     @Before
1:e7d802e:     public void cleanupFiles()
1:e7d802e:     {
1:e7d802e:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:e7d802e:         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore("Standard1");
1:e7d802e:         cfs.truncateBlocking();
1:e7d802e:     }
1:e7d802e: 
1:f92fb22:     /**
1:f92fb22:      * Test compaction with a very wide row.
1:f92fb22:      */
2:f92fb22:     @Test
1:f92fb22:     public void testCompactionWide() throws Exception
1:f92fb22:     {
1:f92fb22:         testCompaction(2, 1, 200000);
5:f92fb22:     }
1:f92fb22: 
1:f92fb22:     /**
1:f92fb22:      * Test compaction with lots of skinny rows.
1:f92fb22:      */
1:f92fb22:     @Test
1:f92fb22:     public void testCompactionSlim() throws Exception
1:f92fb22:     {
1:f92fb22:         testCompaction(2, 200000, 1);
1:f92fb22:     }
1:f92fb22: 
1:f92fb22:     /**
1:f92fb22:      * Test compaction with lots of small sstables.
1:f92fb22:      */
1:f92fb22:     @Test
1:f92fb22:     public void testCompactionMany() throws Exception
1:f92fb22:     {
1:f92fb22:         testCompaction(100, 800, 5);
1:f92fb22:     }
1:f92fb22: 
1:a991b64:     protected void testCompaction(int sstableCount, int partitionsPerSSTable, int rowsPerPartition) throws Exception
1:f92fb22:     {
1:f92fb22:         CompactionManager.instance.disableAutoCompaction();
1:f92fb22: 
1:0e96e58:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:0e96e58:         ColumnFamilyStore store = keyspace.getColumnFamilyStore("Standard1");
1:f92fb22: 
1:0368e97:         ArrayList<SSTableReader> sstables = new ArrayList<>();
1:f92fb22:         for (int k = 0; k < sstableCount; k++)
1:f92fb22:         {
1:a991b64:             SortedMap<String, PartitionUpdate> rows = new TreeMap<>();
1:a991b64:             for (int j = 0; j < partitionsPerSSTable; j++)
1:f92fb22:             {
1:f92fb22:                 String key = String.valueOf(j);
1:a991b64:                 // last sstable has highest timestamps
1:a991b64:                 UpdateBuilder builder = UpdateBuilder.create(store.metadata, String.valueOf(j))
1:a991b64:                                                      .withTimestamp(k);
1:a991b64:                 for (int i = 0; i < rowsPerPartition; i++)
1:a991b64:                     builder.newRow(String.valueOf(i)).add("val", String.valueOf(i));
1:a991b64:                 rows.put(key, builder.build());
1:f92fb22:             }
1:9ed2727:             Collection<SSTableReader> readers = SSTableUtils.prepare().write(rows);
1:9ed2727:             sstables.addAll(readers);
1:9ed2727:             store.addSSTables(readers);
1:f92fb22:         }
1:f92fb22: 
1:f92fb22:         // give garbage collection a bit of time to catch up
1:f92fb22:         Thread.sleep(1000);
1:f92fb22: 
1:1d2c122:         long start = System.nanoTime();
1:b31845c:         final int gcBefore = (int) (System.currentTimeMillis() / 1000) - Schema.instance.getCFMetaData(KEYSPACE1, "Standard1").params.gcGraceSeconds;
1:e5a76bd:         try (LifecycleTransaction txn = store.getTracker().tryModify(sstables, OperationType.COMPACTION))
1:e5a76bd:         {
1:e5a76bd:             assert txn != null : "Cannot markCompacting all sstables";
1:605bcdc:             new CompactionTask(store, txn, gcBefore).execute(null);
1:e5a76bd:         }
1:f92fb22:         System.out.println(String.format("%s: sstables=%d rowsper=%d colsper=%d: %d ms",
1:f92fb22:                                          this.getClass().getName(),
1:f92fb22:                                          sstableCount,
1:a991b64:                                          partitionsPerSSTable,
1:a991b64:                                          rowsPerPartition,
1:1d2c122:                                          TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start)));
1:f92fb22:     }
1:f92fb22: 
1:f92fb22:     @Test
1:c87b6a3:     public void testStandardColumnCompactions()
1:f92fb22:     {
1:f92fb22:         // this test does enough rows to force multiple block indexes to be used
1:0e96e58:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:0e96e58:         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore("Standard1");
1:8c47124:         cfs.clearUnsafe();
1:f92fb22: 
2:f92fb22:         final int ROWS_PER_SSTABLE = 10;
1:b31845c:         final int SSTABLES = cfs.metadata.params.minIndexInterval * 3 / ROWS_PER_SSTABLE;
1:f92fb22: 
1:f92fb22:         // disable compaction while flushing
2:f92fb22:         cfs.disableAutoCompaction();
1:f92fb22: 
2:f92fb22:         long maxTimestampExpected = Long.MIN_VALUE;
2:f92fb22:         Set<DecoratedKey> inserted = new HashSet<DecoratedKey>();
1:f92fb22:         for (int j = 0; j < SSTABLES; j++) {
1:f92fb22:             for (int i = 0; i < ROWS_PER_SSTABLE; i++) {
2:f92fb22:                 DecoratedKey key = Util.dk(String.valueOf(i % 2));
2:f92fb22:                 long timestamp = j * ROWS_PER_SSTABLE + i;
2:f92fb22:                 maxTimestampExpected = Math.max(timestamp, maxTimestampExpected);
1:a991b64:                 UpdateBuilder.create(cfs.metadata, key)
1:a991b64:                              .withTimestamp(timestamp)
1:a991b64:                              .newRow(String.valueOf(i / 2)).add("val", ByteBufferUtil.EMPTY_BYTE_BUFFER)
1:a991b64:                              .apply();
1:a991b64: 
2:f92fb22:                 inserted.add(key);
1:f92fb22:             }
2:f92fb22:             cfs.forceBlockingFlush();
3:f92fb22:             CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
1:a991b64: 
1:a991b64:             assertEquals(inserted.toString(), inserted.size(), Util.getAll(Util.cmd(cfs).build()).size());
1:f92fb22:         }
1:f92fb22: 
2:f92fb22:         forceCompactions(cfs);
1:a991b64:         assertEquals(inserted.toString(), inserted.size(), Util.getAll(Util.cmd(cfs).build()).size());
1:f92fb22: 
2:f92fb22:         // make sure max timestamp of compacted sstables is recorded properly after compaction.
1:f92fb22:         CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
1:d72e938:         cfs.truncateBlocking();
1:f92fb22:     }
1:f92fb22: 
1:c87b6a3:     private void forceCompactions(ColumnFamilyStore cfs)
1:f92fb22:     {
1:f92fb22:         // re-enable compaction with thresholds low enough to force a few rounds
1:f92fb22:         cfs.setCompactionThresholds(2, 4);
1:f92fb22: 
1:f92fb22:         // loop submitting parallel compactions until they all return 0
1:f92fb22:         do
1:f92fb22:         {
1:f92fb22:             ArrayList<Future<?>> compactions = new ArrayList<Future<?>>();
1:f92fb22:             for (int i = 0; i < 10; i++)
1:2a3076b:                 compactions.addAll(CompactionManager.instance.submitBackground(cfs));
1:f92fb22:             // another compaction attempt will be launched in the background by
1:f92fb22:             // each completing compaction: not much we can do to control them here
1:f92fb22:             FBUtilities.waitOnFutures(compactions);
1:f92fb22:         } while (CompactionManager.instance.getPendingTasks() > 0 || CompactionManager.instance.getActiveCompactions() > 0);
1:f92fb22: 
1:ad8cad7:         if (cfs.getLiveSSTables().size() > 1)
1:f92fb22:         {
1:910170c:             CompactionManager.instance.performMaximal(cfs, false);
1:f92fb22:         }
1:f92fb22:     }
1:f92fb22: }
============================================================================
author:Blake Eggleston
-------------------------------------------------------------------------------
commit:9ed2727
/////////////////////////////////////////////////////////////////////////
1:             Collection<SSTableReader> readers = SSTableUtils.prepare().write(rows);
1:             sstables.addAll(readers);
1:             store.addSSTables(readers);
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:605bcdc
/////////////////////////////////////////////////////////////////////////
1:             new CompactionTask(store, txn, gcBefore).execute(null);
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:b31845c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.schema.CompactionParams;
/////////////////////////////////////////////////////////////////////////
1:         Map<String, String> compactionOptions = Collections.singletonMap("tombstone_compaction_interval", "1");
1:                                                 .compaction(CompactionParams.scts(compactionOptions)));
/////////////////////////////////////////////////////////////////////////
1:         final int gcBefore = (int) (System.currentTimeMillis() / 1000) - Schema.instance.getCFMetaData(KEYSPACE1, "Standard1").params.gcGraceSeconds;
/////////////////////////////////////////////////////////////////////////
1:         final int SSTABLES = cfs.metadata.params.minIndexInterval * 3 / ROWS_PER_SSTABLE;
commit:31e3f61
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.schema.KeyspaceParams;
/////////////////////////////////////////////////////////////////////////
1:                                     KeyspaceParams.simple(1),
commit:ee477cc
/////////////////////////////////////////////////////////////////////////
0:         final int SSTABLES = cfs.metadata.getMinIndexInterval() * 3 / ROWS_PER_SSTABLE;
commit:6bbb13b
/////////////////////////////////////////////////////////////////////////
0:                 Mutation rm = new Mutation(KEYSPACE1, key.key);
commit:0e96e58
/////////////////////////////////////////////////////////////////////////
1:     public static final String KEYSPACE1 = "Keyspace1";
/////////////////////////////////////////////////////////////////////////
1:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:         ColumnFamilyStore store = keyspace.getColumnFamilyStore("Standard1");
/////////////////////////////////////////////////////////////////////////
0:         final int gcBefore = (int) (System.currentTimeMillis() / 1000) - Schema.instance.getCFMetaData(KEYSPACE1, "Standard1").getGcGraceSeconds();
/////////////////////////////////////////////////////////////////////////
1:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore("Standard1");
/////////////////////////////////////////////////////////////////////////
0:                 RowMutation rm = new RowMutation(KEYSPACE1, key.key);
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:ad8cad7
/////////////////////////////////////////////////////////////////////////
1:         if (cfs.getLiveSSTables().size() > 1)
commit:e5a76bd
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
/////////////////////////////////////////////////////////////////////////
1:         try (LifecycleTransaction txn = store.getTracker().tryModify(sstables, OperationType.COMPACTION))
1:         {
1:             assert txn != null : "Cannot markCompacting all sstables";
0:             new CompactionTask(store, txn, gcBefore, false).execute(null);
1:         }
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.UpdateBuilder;
1: import org.apache.cassandra.db.partitions.*;
/////////////////////////////////////////////////////////////////////////
1:     protected void testCompaction(int sstableCount, int partitionsPerSSTable, int rowsPerPartition) throws Exception
/////////////////////////////////////////////////////////////////////////
1:             SortedMap<String, PartitionUpdate> rows = new TreeMap<>();
1:             for (int j = 0; j < partitionsPerSSTable; j++)
1:                 // last sstable has highest timestamps
1:                 UpdateBuilder builder = UpdateBuilder.create(store.metadata, String.valueOf(j))
1:                                                      .withTimestamp(k);
1:                 for (int i = 0; i < rowsPerPartition; i++)
1:                     builder.newRow(String.valueOf(i)).add("val", String.valueOf(i));
1:                 rows.put(key, builder.build());
/////////////////////////////////////////////////////////////////////////
1:                                          partitionsPerSSTable,
1:                                          rowsPerPartition,
/////////////////////////////////////////////////////////////////////////
1:                 UpdateBuilder.create(cfs.metadata, key)
1:                              .withTimestamp(timestamp)
1:                              .newRow(String.valueOf(i / 2)).add("val", ByteBufferUtil.EMPTY_BYTE_BUFFER)
1:                              .apply();
1: 
1: 
1:             assertEquals(inserted.toString(), inserted.size(), Util.getAll(Util.cmd(cfs).build()).size());
1:         assertEquals(inserted.toString(), inserted.size(), Util.getAll(Util.cmd(cfs).build()).size());
commit:e50d6af
/////////////////////////////////////////////////////////////////////////
0:                 Cell[] cols = new Cell[colsPerRow];
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0:                 rm.add("Standard1", Util.cellname(String.valueOf(i / 2)),
commit:3a005df
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 Column[] cols = new Column[colsPerRow];
/////////////////////////////////////////////////////////////////////////
0:                 rm.add("Standard1", ByteBufferUtil.bytes(String.valueOf(i / 2)),
/////////////////////////////////////////////////////////////////////////
author:Marcus Eriksson
-------------------------------------------------------------------------------
commit:910170c
/////////////////////////////////////////////////////////////////////////
1:             CompactionManager.instance.performMaximal(cfs, false);
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:787a20f
commit:2d1e46e
commit:8c47124
/////////////////////////////////////////////////////////////////////////
1:         cfs.clearUnsafe();
commit:2a3076b
/////////////////////////////////////////////////////////////////////////
1:                 compactions.addAll(CompactionManager.instance.submitBackground(cfs));
author:Carl Yeksigian
-------------------------------------------------------------------------------
commit:e7d802e
/////////////////////////////////////////////////////////////////////////
1: import org.junit.Before;
1: 
1: import org.apache.cassandra.config.Schema;
1:     @Before
1:     public void cleanupFiles()
1:     {
1:         Keyspace keyspace = Keyspace.open(KEYSPACE1);
1:         ColumnFamilyStore cfs = keyspace.getColumnFamilyStore("Standard1");
1:         cfs.truncateBlocking();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
0:         assert store.getDataTracker().markCompacting(sstables): "Cannot markCompacting all sstables";
author:Dave Brosius
-------------------------------------------------------------------------------
commit:c87b6a3
/////////////////////////////////////////////////////////////////////////
1:     public void testStandardColumnCompactions()
/////////////////////////////////////////////////////////////////////////
1:     private void forceCompactions(ColumnFamilyStore cfs)
commit:83a43f1
/////////////////////////////////////////////////////////////////////////
1: import static org.junit.Assert.assertEquals;
author:Jake Luciani
-------------------------------------------------------------------------------
commit:0368e97
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.sstable.format.SSTableReader;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         ArrayList<SSTableReader> sstables = new ArrayList<>();
author:lyubent
-------------------------------------------------------------------------------
commit:d2a3827
/////////////////////////////////////////////////////////////////////////
1: import org.junit.BeforeClass;
0: import org.apache.cassandra.config.KSMetaData;
0: import org.apache.cassandra.config.Schema;
1: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.locator.SimpleStrategy;
1: public class LongCompactionsTest
1:     public static final String CF_STANDARD = "Standard1";
1: 
1:     @BeforeClass
1:     public static void defineSchema() throws ConfigurationException
1:     {
0:         Map<String, String> compactionOptions = new HashMap<>();
0:         compactionOptions.put("tombstone_compaction_interval", "1");
1:         SchemaLoader.prepareServer();
1:         SchemaLoader.createKeyspace(KEYSPACE1,
0:                                     SimpleStrategy.class,
0:                                     KSMetaData.optsWithRF(1),
1:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD)
0:                                                 .compactionStrategyOptions(compactionOptions));
1:     }
/////////////////////////////////////////////////////////////////////////
0:                 rows.put(key, SSTableUtils.createCF(KEYSPACE1, CF_STANDARD, Long.MIN_VALUE, Integer.MIN_VALUE, cols));
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:8541cca
/////////////////////////////////////////////////////////////////////////
0:                 Mutation rm = new Mutation(KEYSPACE1, key.getKey());
author:belliottsmith
-------------------------------------------------------------------------------
commit:4e95953
/////////////////////////////////////////////////////////////////////////
0:         new CompactionTask(store, sstables, gcBefore, false).execute(null);
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:1d2c122
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.TimeUnit;
/////////////////////////////////////////////////////////////////////////
1:         long start = System.nanoTime();
/////////////////////////////////////////////////////////////////////////
1:                                          TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start)));
commit:d72e938
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         cfs.truncateBlocking();
commit:6a5c9ed
/////////////////////////////////////////////////////////////////////////
0:         final int SSTABLES = cfs.metadata.getIndexInterval() * 3 / ROWS_PER_SSTABLE;
/////////////////////////////////////////////////////////////////////////
0:         final int SSTABLES = cfs.metadata.getIndexInterval() * 3 / ROWS_PER_SSTABLE;
commit:f92fb22
/////////////////////////////////////////////////////////////////////////
1: /*
1: * Licensed to the Apache Software Foundation (ASF) under one
1: * or more contributor license agreements.  See the NOTICE file
1: * distributed with this work for additional information
1: * regarding copyright ownership.  The ASF licenses this file
1: * to you under the Apache License, Version 2.0 (the
1: * "License"); you may not use this file except in compliance
1: * with the License.  You may obtain a copy of the License at
1: *
1: *    http://www.apache.org/licenses/LICENSE-2.0
1: *
1: * Unless required by applicable law or agreed to in writing,
1: * software distributed under the License is distributed on an
1: * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1: * KIND, either express or implied.  See the License for the
1: * specific language governing permissions and limitations
1: * under the License.
1: */
1: package org.apache.cassandra.db.compaction;
1: 
0: import java.io.IOException;
0: import java.nio.ByteBuffer;
1: import java.util.*;
0: import java.util.concurrent.ExecutionException;
1: import java.util.concurrent.Future;
1: 
0: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.config.Schema;
1: import org.junit.Test;
1: import org.apache.cassandra.SchemaLoader;
1: import org.apache.cassandra.Util;
1: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.db.filter.QueryPath;
0: import org.apache.cassandra.io.sstable.SSTableReader;
1: import org.apache.cassandra.io.sstable.SSTableUtils;
1: import org.apache.cassandra.utils.ByteBufferUtil;
1: import org.apache.cassandra.utils.FBUtilities;
1: 
0: import static junit.framework.Assert.assertEquals;
1: 
0: public class LongCompactionsTest extends SchemaLoader
1: {
0:     public static final String TABLE1 = "Keyspace1";
1: 
1:     /**
1:      * Test compaction with a very wide row.
1:      */
1:     @Test
1:     public void testCompactionWide() throws Exception
1:     {
1:         testCompaction(2, 1, 200000);
1:     }
1: 
1:     /**
1:      * Test compaction with lots of skinny rows.
1:      */
1:     @Test
1:     public void testCompactionSlim() throws Exception
1:     {
1:         testCompaction(2, 200000, 1);
1:     }
1: 
1:     /**
1:      * Test compaction with lots of small sstables.
1:      */
1:     @Test
1:     public void testCompactionMany() throws Exception
1:     {
1:         testCompaction(100, 800, 5);
1:     }
1: 
0:     protected void testCompaction(int sstableCount, int rowsPerSSTable, int colsPerRow) throws Exception
1:     {
1:         CompactionManager.instance.disableAutoCompaction();
1: 
0:         Table table = Table.open(TABLE1);
0:         ColumnFamilyStore store = table.getColumnFamilyStore("Standard1");
1: 
0:         ArrayList<SSTableReader> sstables = new ArrayList<SSTableReader>();
1:         for (int k = 0; k < sstableCount; k++)
1:         {
0:             SortedMap<String,ColumnFamily> rows = new TreeMap<String,ColumnFamily>();
0:             for (int j = 0; j < rowsPerSSTable; j++)
1:             {
1:                 String key = String.valueOf(j);
0:                 IColumn[] cols = new IColumn[colsPerRow];
0:                 for (int i = 0; i < colsPerRow; i++)
1:                 {
0:                     // last sstable has highest timestamps
0:                     cols[i] = Util.column(String.valueOf(i), String.valueOf(i), k);
1:                 }
0:                 rows.put(key, SSTableUtils.createCF(Long.MIN_VALUE, Integer.MIN_VALUE, cols));
1:             }
0:             SSTableReader sstable = SSTableUtils.prepare().write(rows);
0:             sstables.add(sstable);
0:             store.addSSTable(sstable);
1:         }
1: 
1:         // give garbage collection a bit of time to catch up
1:         Thread.sleep(1000);
1: 
0:         long start = System.currentTimeMillis();
0:         final int gcBefore = (int) (System.currentTimeMillis() / 1000) - Schema.instance.getCFMetaData(TABLE1, "Standard1").getGcGraceSeconds();
0:         new CompactionTask(store, sstables, gcBefore).execute(null);
1:         System.out.println(String.format("%s: sstables=%d rowsper=%d colsper=%d: %d ms",
1:                                          this.getClass().getName(),
1:                                          sstableCount,
0:                                          rowsPerSSTable,
0:                                          colsPerRow,
0:                                          System.currentTimeMillis() - start));
1:     }
1: 
1:     @Test
0:     public void testStandardColumnCompactions() throws IOException, ExecutionException, InterruptedException
1:     {
1:         // this test does enough rows to force multiple block indexes to be used
0:         Table table = Table.open(TABLE1);
0:         ColumnFamilyStore cfs = table.getColumnFamilyStore("Standard1");
1: 
1:         final int ROWS_PER_SSTABLE = 10;
0:         final int SSTABLES = DatabaseDescriptor.getIndexInterval() * 3 / ROWS_PER_SSTABLE;
1: 
1:         // disable compaction while flushing
1:         cfs.disableAutoCompaction();
1: 
1:         long maxTimestampExpected = Long.MIN_VALUE;
1:         Set<DecoratedKey> inserted = new HashSet<DecoratedKey>();
1:         for (int j = 0; j < SSTABLES; j++) {
1:             for (int i = 0; i < ROWS_PER_SSTABLE; i++) {
1:                 DecoratedKey key = Util.dk(String.valueOf(i % 2));
0:                 RowMutation rm = new RowMutation(TABLE1, key.key);
1:                 long timestamp = j * ROWS_PER_SSTABLE + i;
0:                 rm.add(new QueryPath("Standard1", null, ByteBufferUtil.bytes(String.valueOf(i / 2))),
0:                        ByteBufferUtil.EMPTY_BYTE_BUFFER,
0:                        timestamp);
1:                 maxTimestampExpected = Math.max(timestamp, maxTimestampExpected);
0:                 rm.apply();
1:                 inserted.add(key);
1:             }
1:             cfs.forceBlockingFlush();
1:             CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
0:             assertEquals(inserted.toString(), inserted.size(), Util.getRangeSlice(cfs).size());
1:         }
1: 
1:         forceCompactions(cfs);
1: 
0:         assertEquals(inserted.size(), Util.getRangeSlice(cfs).size());
1: 
1:         // make sure max timestamp of compacted sstables is recorded properly after compaction.
1:         CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
0:         cfs.truncate();
1:     }
1: 
1:     @Test
0:     public void testSuperColumnCompactions() throws IOException, ExecutionException, InterruptedException
1:     {
0:         Table table = Table.open(TABLE1);
0:         ColumnFamilyStore cfs = table.getColumnFamilyStore("Super1");
1: 
1:         final int ROWS_PER_SSTABLE = 10;
0:         final int SSTABLES = DatabaseDescriptor.getIndexInterval() * 3 / ROWS_PER_SSTABLE;
1: 
0:         //disable compaction while flushing
1:         cfs.disableAutoCompaction();
1: 
1:         long maxTimestampExpected = Long.MIN_VALUE;
1:         Set<DecoratedKey> inserted = new HashSet<DecoratedKey>();
0:         ByteBuffer superColumn = ByteBufferUtil.bytes("TestSuperColumn");
0:         for (int j = 0; j < SSTABLES; j++)
1:         {
0:             for (int i = 0; i < ROWS_PER_SSTABLE; i++)
1:             {
1:                 DecoratedKey key = Util.dk(String.valueOf(i % 2));
0:                 RowMutation rm = new RowMutation(TABLE1, key.key);
1:                 long timestamp = j * ROWS_PER_SSTABLE + i;
0:                 rm.add(new QueryPath("Super1", superColumn, ByteBufferUtil.bytes((long)(i / 2))),
0:                        ByteBufferUtil.EMPTY_BYTE_BUFFER,
0:                        timestamp);
1:                 maxTimestampExpected = Math.max(timestamp, maxTimestampExpected);
0:                 rm.apply();
1:                 inserted.add(key);
1:             }
1:             cfs.forceBlockingFlush();
1:             CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
0:             assertEquals(inserted.toString(), inserted.size(), Util.getRangeSlice(cfs, superColumn).size());
1:         }
1: 
1:         forceCompactions(cfs);
1: 
0:         assertEquals(inserted.size(), Util.getRangeSlice(cfs, superColumn).size());
1: 
1:         // make sure max timestamp of compacted sstables is recorded properly after compaction.
1:         CompactionsTest.assertMaxTimestamp(cfs, maxTimestampExpected);
1:     }
1: 
0:     private void forceCompactions(ColumnFamilyStore cfs) throws ExecutionException, InterruptedException
1:     {
1:         // re-enable compaction with thresholds low enough to force a few rounds
1:         cfs.setCompactionThresholds(2, 4);
1: 
1:         // loop submitting parallel compactions until they all return 0
1:         do
1:         {
1:             ArrayList<Future<?>> compactions = new ArrayList<Future<?>>();
1:             for (int i = 0; i < 10; i++)
0:                 compactions.add(CompactionManager.instance.submitBackground(cfs));
1:             // another compaction attempt will be launched in the background by
1:             // each completing compaction: not much we can do to control them here
1:             FBUtilities.waitOnFutures(compactions);
1:         } while (CompactionManager.instance.getPendingTasks() > 0 || CompactionManager.instance.getActiveCompactions() > 0);
1: 
0:         if (cfs.getSSTables().size() > 1)
1:         {
0:             CompactionManager.instance.performMaximal(cfs);
1:         }
1:     }
1: }
============================================================================
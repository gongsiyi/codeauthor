1:47d3b7e: /*
1:47d3b7e:  * Licensed to the Apache Software Foundation (ASF) under one
1:47d3b7e:  * or more contributor license agreements.  See the NOTICE file
1:47d3b7e:  * distributed with this work for additional information
1:47d3b7e:  * regarding copyright ownership.  The ASF licenses this file
1:47d3b7e:  * to you under the Apache License, Version 2.0 (the
1:47d3b7e:  * "License"); you may not use this file except in compliance
1:47d3b7e:  * with the License.  You may obtain a copy of the License at
1:47d3b7e:  *
1:47d3b7e:  *     http://www.apache.org/licenses/LICENSE-2.0
1:47d3b7e:  *
1:47d3b7e:  * Unless required by applicable law or agreed to in writing, software
1:47d3b7e:  * distributed under the License is distributed on an "AS IS" BASIS,
1:47d3b7e:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:47d3b7e:  * See the License for the specific language governing permissions and
1:47d3b7e:  * limitations under the License.
1:47d3b7e:  */
2:47d3b7e: 
1:47d3b7e: package org.apache.cassandra.stress;
1:47d3b7e: 
1:47d3b7e: import java.io.File;
1:47d3b7e: import java.io.IOError;
1:47d3b7e: import java.net.InetAddress;
1:47d3b7e: import java.net.URI;
1:47d3b7e: import java.util.*;
1:47d3b7e: import java.util.concurrent.*;
1:47d3b7e: import javax.inject.Inject;
1:47d3b7e: 
1:47d3b7e: import com.google.common.collect.Lists;
1:47d3b7e: import com.google.common.util.concurrent.Uninterruptibles;
1:47d3b7e: 
1:47d3b7e: import io.airlift.command.*;
1:47d3b7e: import org.apache.cassandra.config.DatabaseDescriptor;
1:47d3b7e: import org.apache.cassandra.cql3.statements.CreateTableStatement;
1:47d3b7e: import org.apache.cassandra.db.ColumnFamilyStore;
1:47d3b7e: import org.apache.cassandra.db.Directories;
1:47d3b7e: import org.apache.cassandra.db.SystemKeyspace;
1:47d3b7e: import org.apache.cassandra.db.compaction.CompactionManager;
1:47d3b7e: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1:47d3b7e: import org.apache.cassandra.dht.IPartitioner;
1:47d3b7e: import org.apache.cassandra.dht.Token;
1:0026e4e: import org.apache.cassandra.io.sstable.StressCQLSSTableWriter;
1:47d3b7e: import org.apache.cassandra.io.sstable.Component;
1:47d3b7e: import org.apache.cassandra.io.sstable.Descriptor;
1:47d3b7e: import org.apache.cassandra.io.sstable.format.SSTableReader;
1:47d3b7e: import org.apache.cassandra.io.util.FileUtils;
1:47d3b7e: import org.apache.cassandra.locator.TokenMetadata;
1:47d3b7e: import org.apache.cassandra.service.StorageService;
1:47d3b7e: import org.apache.cassandra.stress.generate.PartitionGenerator;
1:47d3b7e: import org.apache.cassandra.stress.generate.SeedManager;
1:47d3b7e: import org.apache.cassandra.stress.operations.userdefined.SchemaInsert;
1:47d3b7e: import org.apache.cassandra.stress.settings.StressSettings;
1:47d3b7e: import org.apache.cassandra.tools.nodetool.CompactionStats;
1:47d3b7e: import org.apache.cassandra.utils.FBUtilities;
1:47d3b7e: import org.apache.cassandra.utils.JVMStabilityInspector;
1:47d3b7e: 
1:47d3b7e: /**
1:47d3b7e:  * Tool that allows fast route to loading data for arbitrary schemas to disk
1:47d3b7e:  * and compacting them.
1:47d3b7e:  */
1:47d3b7e: public abstract class CompactionStress implements Runnable
1:47d3b7e: {
1:47d3b7e:     @Inject
1:47d3b7e:     public HelpOption helpOption;
1:47d3b7e: 
1:47d3b7e:     @Option(name = { "-p", "--profile" }, description = "Path to stress yaml file", required = true)
1:47d3b7e:     String profile;
1:47d3b7e: 
1:47d3b7e:     @Option(name = { "-d", "--datadir" }, description = "Data directory (can be used many times to specify multiple data dirs)", required = true)
1:47d3b7e:     List<String> dataDirs;
1:47d3b7e: 
1:47d3b7e:     @Option(name = {"-v", "--vnodes"}, description = "number of local tokens to generate (default 256)")
1:47d3b7e:     Integer numTokens = 256;
1:47d3b7e: 
1:0026e4e:     static
1:0026e4e:     {
1:0026e4e:         DatabaseDescriptor.toolInitialization();
1:0026e4e:     }
1:0026e4e: 
1:47d3b7e:     List<File> getDataDirectories()
1:47d3b7e:     {
1:47d3b7e:         List<File> dataDirectories = new ArrayList<>(dataDirs.size());
1:47d3b7e:         for (String dataDir : dataDirs)
1:47d3b7e:         {
1:47d3b7e:             File outputDir = new File(dataDir);
1:47d3b7e: 
1:47d3b7e:             if (!outputDir.exists())
1:47d3b7e:             {
1:47d3b7e:                 System.err.println("Invalid output dir (missing): " + outputDir);
1:47d3b7e:                 System.exit(1);
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             if (!outputDir.isDirectory())
1:47d3b7e:             {
1:47d3b7e:                 System.err.println("Invalid output dir (not a directory): " + outputDir);
1:47d3b7e:                 System.exit(2);
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             if (!outputDir.canWrite())
1:47d3b7e:             {
1:47d3b7e:                 System.err.println("Invalid output dir (no write permissions): " + outputDir);
1:47d3b7e:                 System.exit(3);
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             dataDirectories.add(outputDir);
1:47d3b7e:         }
1:47d3b7e: 
1:47d3b7e:         return dataDirectories;
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     ColumnFamilyStore initCf(StressProfile stressProfile, boolean loadSSTables)
1:47d3b7e:     {
1:47d3b7e:         generateTokens(stressProfile.seedStr, StorageService.instance.getTokenMetadata(), numTokens);
1:47d3b7e: 
1:47d3b7e:         CreateTableStatement.RawStatement createStatement = stressProfile.getCreateStatement();
1:47d3b7e:         List<File> dataDirectories = getDataDirectories();
1:47d3b7e: 
1:0026e4e:         ColumnFamilyStore cfs = StressCQLSSTableWriter.Builder.createOfflineTable(createStatement, Collections.EMPTY_LIST, dataDirectories);
1:47d3b7e: 
1:47d3b7e:         if (loadSSTables)
1:47d3b7e:         {
1:47d3b7e:             Directories.SSTableLister lister = cfs.getDirectories().sstableLister(Directories.OnTxnErr.IGNORE).skipTemporary(true);
1:47d3b7e:             List<SSTableReader> sstables = new ArrayList<>();
1:47d3b7e: 
1:47d3b7e:             //Offline open sstables
1:47d3b7e:             for (Map.Entry<Descriptor, Set<Component>> entry : lister.list().entrySet())
1:47d3b7e:             {
1:47d3b7e:                 Set<Component> components = entry.getValue();
1:47d3b7e:                 if (!components.contains(Component.DATA))
1:47d3b7e:                     continue;
1:47d3b7e: 
1:47d3b7e:                 try
1:47d3b7e:                 {
1:47d3b7e:                     SSTableReader sstable = SSTableReader.openNoValidation(entry.getKey(), components, cfs);
1:47d3b7e:                     sstables.add(sstable);
1:47d3b7e:                 }
1:47d3b7e:                 catch (Exception e)
1:47d3b7e:                 {
1:47d3b7e:                     JVMStabilityInspector.inspectThrowable(e);
1:47d3b7e:                     System.err.println(String.format("Error Loading %s: %s", entry.getKey(), e.getMessage()));
1:47d3b7e:                 }
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             cfs.disableAutoCompaction();
1:47d3b7e: 
1:47d3b7e:             //Register with cfs
1:47d3b7e:             cfs.addSSTables(sstables);
1:47d3b7e:         }
1:47d3b7e: 
1:47d3b7e:         return cfs;
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     StressProfile getStressProfile()
1:47d3b7e:     {
1:47d3b7e:         try
1:47d3b7e:         {
1:47d3b7e:             File yamlFile = new File(profile);
1:47d3b7e:             return StressProfile.load(yamlFile.exists() ? yamlFile.toURI() : URI.create(profile));
1:47d3b7e:         }
1:47d3b7e:         catch ( IOError e)
1:47d3b7e:         {
1:47d3b7e:             e.printStackTrace();
1:47d3b7e:             System.err.print("Invalid profile URI : " + profile);
1:47d3b7e:             System.exit(4);
1:47d3b7e:         }
1:47d3b7e: 
1:47d3b7e:         return null;
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     /**
1:47d3b7e:      * Populate tokenMetadata consistently across runs.
1:47d3b7e:      *
1:47d3b7e:      * We need consistency to write and compact the same data offline
1:47d3b7e:      * in the case of a range aware sstable writer.
1:47d3b7e:      */
1:47d3b7e:     private void generateTokens(String seed, TokenMetadata tokenMetadata, Integer numTokens)
1:47d3b7e:     {
1:47d3b7e:         Random random = new Random(seed.hashCode());
1:47d3b7e: 
1:47d3b7e:         IPartitioner p = tokenMetadata.partitioner;
1:47d3b7e:         tokenMetadata.clearUnsafe();
1:47d3b7e:         for (int i = 1; i <= numTokens; i++)
1:47d3b7e:         {
1:47d3b7e:             InetAddress addr = FBUtilities.getBroadcastAddress();
1:47d3b7e:             List<Token> tokens = Lists.newArrayListWithCapacity(numTokens);
1:47d3b7e:             for (int j = 0; j < numTokens; ++j)
1:47d3b7e:                 tokens.add(p.getRandomToken(random));
1:47d3b7e: 
1:47d3b7e:             tokenMetadata.updateNormalTokens(tokens, addr);
1:47d3b7e:         }
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     public abstract void run();
1:47d3b7e: 
1:47d3b7e: 
1:47d3b7e:     @Command(name = "compact", description = "Compact data in directory")
1:47d3b7e:     public static class Compaction extends CompactionStress
1:47d3b7e:     {
1:47d3b7e: 
1:47d3b7e:         @Option(name = {"-m", "--maximal"}, description = "Force maximal compaction (default true)")
1:47d3b7e:         Boolean maximal = false;
1:47d3b7e: 
1:47d3b7e:         @Option(name = {"-t", "--threads"}, description = "Number of compactor threads to use for bg compactions (default 4)")
1:47d3b7e:         Integer threads = 4;
1:47d3b7e: 
1:47d3b7e:         public void run()
1:47d3b7e:         {
1:47d3b7e:             //Setup
1:47d3b7e:             SystemKeyspace.finishStartup(); //needed for early-open
1:47d3b7e:             CompactionManager.instance.setMaximumCompactorThreads(threads);
1:47d3b7e:             CompactionManager.instance.setCoreCompactorThreads(threads);
1:47d3b7e:             CompactionManager.instance.setRate(0);
1:47d3b7e: 
1:47d3b7e:             StressProfile stressProfile = getStressProfile();
1:47d3b7e:             ColumnFamilyStore cfs = initCf(stressProfile, true);
1:47d3b7e:             cfs.getCompactionStrategyManager().compactionLogger.enable();
1:47d3b7e: 
1:47d3b7e:             List<Future<?>> futures = new ArrayList<>(threads);
1:47d3b7e:             if (maximal)
1:47d3b7e:             {
1:47d3b7e:                 futures = CompactionManager.instance.submitMaximal(cfs, FBUtilities.nowInSeconds(), false);
1:47d3b7e:             }
1:47d3b7e:             else
1:47d3b7e:             {
1:47d3b7e:                 cfs.enableAutoCompaction();
1:47d3b7e:                 cfs.getCompactionStrategyManager().enable();
1:47d3b7e:                 for (int i = 0; i < threads; i++)
1:47d3b7e:                     futures.addAll(CompactionManager.instance.submitBackground(cfs));
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             long working;
1:47d3b7e:             //Report compaction stats while working
1:47d3b7e:             while ((working = futures.stream().filter(f -> !f.isDone()).count()) > 0 || CompactionManager.instance.getActiveCompactions() > 0 || (!maximal && cfs.getCompactionStrategyManager().getEstimatedRemainingTasks() > 0))
1:47d3b7e:             {
1:47d3b7e:                 //Re-up any bg jobs
1:47d3b7e:                 if (!maximal)
1:47d3b7e:                 {
1:47d3b7e:                     for (long i = working; i < threads; i++)
1:47d3b7e:                         futures.addAll(CompactionManager.instance.submitBackground(cfs));
1:47d3b7e:                 }
1:47d3b7e: 
1:47d3b7e:                 reportCompactionStats();
1:47d3b7e:                 Uninterruptibles.sleepUninterruptibly(10, TimeUnit.SECONDS);
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             System.out.println("Finished! Shutting down...");
1:47d3b7e:             CompactionManager.instance.forceShutdown();
1:47d3b7e: 
1:47d3b7e:             //Wait for cleanup to finish before forcing
1:47d3b7e:             Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);
1:47d3b7e:             LifecycleTransaction.removeUnfinishedLeftovers(cfs);
1:47d3b7e:         }
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     void reportCompactionStats()
1:47d3b7e:     {
1:47d3b7e:         System.out.println("========");
1:47d3b7e:         System.out.println(String.format("Pending compactions: %d\n", CompactionManager.instance.getPendingTasks()));
1:47d3b7e:         CompactionStats.reportCompactionTable(CompactionManager.instance.getCompactions(), 0, true);
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e: 
1:47d3b7e:     @Command(name = "write", description = "write data directly to disk")
1:47d3b7e:     public static class DataWriter extends CompactionStress
1:47d3b7e:     {
1:47d3b7e:         private static double BYTES_IN_GB = 1024 * 1014 * 1024;
1:47d3b7e: 
1:47d3b7e:         @Option(name = { "-g", "--gbsize"}, description = "Total GB size on disk you wish to write", required = true)
1:47d3b7e:         Integer totalSizeGb;
1:47d3b7e: 
1:47d3b7e:         @Option(name = { "-t", "--threads" }, description = "Number of sstable writer threads (default 2)")
1:47d3b7e:         Integer threads = 2;
1:47d3b7e: 
1:47d3b7e:         @Option(name = { "-c", "--partition-count"}, description = "Number of partitions to loop over (default 1000000)")
1:47d3b7e:         Integer partitions = 1000000;
1:47d3b7e: 
1:47d3b7e:         @Option(name = { "-b", "--buffer-size-mb"}, description = "Buffer in MB writes before writing new sstable (default 128)")
1:47d3b7e:         Integer bufferSize = 128;
1:47d3b7e: 
1:47d3b7e:         @Option(name = { "-r", "--range-aware"}, description = "Splits the local ranges in number of data directories and makes sure we never write the same token in two different directories (default true)")
1:47d3b7e:         Boolean makeRangeAware = true;
1:47d3b7e: 
1:47d3b7e:         public void run()
1:47d3b7e:         {
1:47d3b7e:             StressProfile stressProfile = getStressProfile();
1:47d3b7e:             ColumnFamilyStore cfs = initCf(stressProfile, false);
1:47d3b7e:             Directories directories = cfs.getDirectories();
1:47d3b7e: 
1:47d3b7e:             StressSettings settings = StressSettings.parse(new String[]{ "write", "-pop seq=1.." + partitions });
1:47d3b7e:             SeedManager seedManager = new SeedManager(settings);
1:47d3b7e:             PartitionGenerator generator = stressProfile.getOfflineGenerator();
1:47d3b7e:             WorkManager workManager = new WorkManager.FixedWorkManager(Long.MAX_VALUE);
1:47d3b7e: 
1:47d3b7e:             ExecutorService executorService = Executors.newFixedThreadPool(threads);
1:47d3b7e:             CountDownLatch finished = new CountDownLatch(threads);
1:47d3b7e: 
1:47d3b7e:             for (int i = 0; i < threads; i++)
1:47d3b7e:             {
1:47d3b7e:                 //Every thread needs it's own writer
1:47d3b7e:                 final SchemaInsert insert = stressProfile.getOfflineInsert(null, generator, seedManager, settings);
1:0026e4e:                 final StressCQLSSTableWriter tableWriter = insert.createWriter(cfs, bufferSize, makeRangeAware);
1:47d3b7e:                 executorService.submit(() -> {
1:47d3b7e:                     try
1:47d3b7e:                     {
1:47d3b7e:                         insert.runOffline(tableWriter, workManager);
1:47d3b7e:                     }
1:47d3b7e:                     catch (Exception e)
1:47d3b7e:                     {
1:47d3b7e:                         e.printStackTrace();
1:47d3b7e:                     }
1:47d3b7e:                     finally
1:47d3b7e:                     {
1:47d3b7e:                         FileUtils.closeQuietly(tableWriter);
1:47d3b7e:                         finished.countDown();
1:47d3b7e:                     }
1:47d3b7e:                 });
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             double currentSizeGB;
1:47d3b7e:             while ((currentSizeGB = directories.getRawDiretoriesSize() / BYTES_IN_GB) < totalSizeGb)
1:47d3b7e:             {
1:47d3b7e:                 if (finished.getCount() == 0)
1:47d3b7e:                     break;
1:47d3b7e: 
1:47d3b7e:                 System.out.println(String.format("Written %.2fGB of %dGB", currentSizeGB, totalSizeGb));
1:47d3b7e: 
1:47d3b7e:                 Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
1:47d3b7e:             }
1:47d3b7e: 
1:47d3b7e:             workManager.stop();
1:47d3b7e:             Uninterruptibles.awaitUninterruptibly(finished);
1:47d3b7e: 
1:47d3b7e:             currentSizeGB = directories.getRawDiretoriesSize() / BYTES_IN_GB;
1:47d3b7e:             System.out.println(String.format("Finished writing %.2fGB", currentSizeGB));
1:47d3b7e:         }
1:47d3b7e:     }
1:47d3b7e: 
1:47d3b7e:     public static void main(String[] args)
1:47d3b7e:     {
1:47d3b7e:         Cli.CliBuilder<Runnable> builder = Cli.<Runnable>builder("compaction-stress")
1:47d3b7e:                                            .withDescription("benchmark for compaction")
1:47d3b7e:                                            .withDefaultCommand(Help.class)
1:47d3b7e:                                            .withCommands(Help.class, DataWriter.class, Compaction.class);
1:47d3b7e: 
1:47d3b7e:         Cli<Runnable> stress = builder.build();
1:47d3b7e: 
1:47d3b7e:         try
1:47d3b7e:         {
1:47d3b7e:             stress.parse(args).run();
1:47d3b7e:         }
1:47d3b7e:         catch (Throwable t)
1:47d3b7e:         {
1:47d3b7e:             t.printStackTrace();
1:47d3b7e:             System.exit(6);
1:47d3b7e:         }
1:47d3b7e: 
1:47d3b7e:         System.exit(0);
1:47d3b7e:     }
1:47d3b7e: }
1:47d3b7e: 
1:47d3b7e: 
============================================================================
author:Jeremiah D Jordan
-------------------------------------------------------------------------------
commit:0026e4e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.sstable.StressCQLSSTableWriter;
/////////////////////////////////////////////////////////////////////////
1:     static
1:     {
1:         DatabaseDescriptor.toolInitialization();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:         ColumnFamilyStore cfs = StressCQLSSTableWriter.Builder.createOfflineTable(createStatement, Collections.EMPTY_LIST, dataDirectories);
/////////////////////////////////////////////////////////////////////////
1:                 final StressCQLSSTableWriter tableWriter = insert.createWriter(cfs, bufferSize, makeRangeAware);
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:47d3b7e
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.cassandra.stress;
1: 
1: import java.io.File;
1: import java.io.IOError;
1: import java.net.InetAddress;
1: import java.net.URI;
1: import java.util.*;
1: import java.util.concurrent.*;
0: import java.util.stream.Collectors;
1: import javax.inject.Inject;
1: 
1: import com.google.common.collect.Lists;
1: import com.google.common.util.concurrent.Uninterruptibles;
1: 
1: import io.airlift.command.*;
0: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.config.Schema;
1: import org.apache.cassandra.cql3.statements.CreateTableStatement;
1: import org.apache.cassandra.db.ColumnFamilyStore;
1: import org.apache.cassandra.db.Directories;
0: import org.apache.cassandra.db.Keyspace;
1: import org.apache.cassandra.db.SystemKeyspace;
1: import org.apache.cassandra.db.compaction.CompactionManager;
1: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1: import org.apache.cassandra.dht.IPartitioner;
1: import org.apache.cassandra.dht.Token;
0: import org.apache.cassandra.io.sstable.CQLSSTableWriter;
1: import org.apache.cassandra.io.sstable.Component;
1: import org.apache.cassandra.io.sstable.Descriptor;
1: import org.apache.cassandra.io.sstable.format.SSTableReader;
1: import org.apache.cassandra.io.util.FileUtils;
1: import org.apache.cassandra.locator.TokenMetadata;
0: import org.apache.cassandra.schema.KeyspaceMetadata;
0: import org.apache.cassandra.schema.KeyspaceParams;
1: import org.apache.cassandra.service.StorageService;
1: import org.apache.cassandra.stress.generate.PartitionGenerator;
1: import org.apache.cassandra.stress.generate.SeedManager;
1: import org.apache.cassandra.stress.operations.userdefined.SchemaInsert;
1: import org.apache.cassandra.stress.settings.StressSettings;
0: import org.apache.cassandra.tools.Util;
1: import org.apache.cassandra.tools.nodetool.CompactionStats;
1: import org.apache.cassandra.utils.FBUtilities;
1: import org.apache.cassandra.utils.JVMStabilityInspector;
1: 
1: /**
1:  * Tool that allows fast route to loading data for arbitrary schemas to disk
1:  * and compacting them.
1:  */
1: public abstract class CompactionStress implements Runnable
1: {
1:     @Inject
1:     public HelpOption helpOption;
1: 
1:     @Option(name = { "-p", "--profile" }, description = "Path to stress yaml file", required = true)
1:     String profile;
1: 
1:     @Option(name = { "-d", "--datadir" }, description = "Data directory (can be used many times to specify multiple data dirs)", required = true)
1:     List<String> dataDirs;
1: 
1:     @Option(name = {"-v", "--vnodes"}, description = "number of local tokens to generate (default 256)")
1:     Integer numTokens = 256;
1: 
1:     List<File> getDataDirectories()
1:     {
1:         List<File> dataDirectories = new ArrayList<>(dataDirs.size());
1:         for (String dataDir : dataDirs)
1:         {
1:             File outputDir = new File(dataDir);
1: 
1:             if (!outputDir.exists())
1:             {
1:                 System.err.println("Invalid output dir (missing): " + outputDir);
1:                 System.exit(1);
1:             }
1: 
1:             if (!outputDir.isDirectory())
1:             {
1:                 System.err.println("Invalid output dir (not a directory): " + outputDir);
1:                 System.exit(2);
1:             }
1: 
1:             if (!outputDir.canWrite())
1:             {
1:                 System.err.println("Invalid output dir (no write permissions): " + outputDir);
1:                 System.exit(3);
1:             }
1: 
1:             dataDirectories.add(outputDir);
1:         }
1: 
1:         return dataDirectories;
1:     }
1: 
1:     ColumnFamilyStore initCf(StressProfile stressProfile, boolean loadSSTables)
1:     {
0:         Util.initDatabaseDescriptor();
1: 
1:         generateTokens(stressProfile.seedStr, StorageService.instance.getTokenMetadata(), numTokens);
1: 
1:         CreateTableStatement.RawStatement createStatement = stressProfile.getCreateStatement();
1:         List<File> dataDirectories = getDataDirectories();
1: 
0:         ColumnFamilyStore cfs = CQLSSTableWriter.Builder.createOfflineTable(createStatement, Collections.EMPTY_LIST, dataDirectories);
1: 
1:         if (loadSSTables)
1:         {
1:             Directories.SSTableLister lister = cfs.getDirectories().sstableLister(Directories.OnTxnErr.IGNORE).skipTemporary(true);
1:             List<SSTableReader> sstables = new ArrayList<>();
1: 
1:             //Offline open sstables
1:             for (Map.Entry<Descriptor, Set<Component>> entry : lister.list().entrySet())
1:             {
1:                 Set<Component> components = entry.getValue();
1:                 if (!components.contains(Component.DATA))
1:                     continue;
1: 
1:                 try
1:                 {
1:                     SSTableReader sstable = SSTableReader.openNoValidation(entry.getKey(), components, cfs);
1:                     sstables.add(sstable);
1:                 }
1:                 catch (Exception e)
1:                 {
1:                     JVMStabilityInspector.inspectThrowable(e);
1:                     System.err.println(String.format("Error Loading %s: %s", entry.getKey(), e.getMessage()));
1:                 }
1:             }
1: 
1:             cfs.disableAutoCompaction();
1: 
1:             //Register with cfs
1:             cfs.addSSTables(sstables);
1:         }
1: 
1:         return cfs;
1:     }
1: 
1:     StressProfile getStressProfile()
1:     {
1:         try
1:         {
1:             File yamlFile = new File(profile);
1:             return StressProfile.load(yamlFile.exists() ? yamlFile.toURI() : URI.create(profile));
1:         }
1:         catch ( IOError e)
1:         {
1:             e.printStackTrace();
1:             System.err.print("Invalid profile URI : " + profile);
1:             System.exit(4);
1:         }
1: 
1:         return null;
1:     }
1: 
1:     /**
1:      * Populate tokenMetadata consistently across runs.
1:      *
1:      * We need consistency to write and compact the same data offline
1:      * in the case of a range aware sstable writer.
1:      */
1:     private void generateTokens(String seed, TokenMetadata tokenMetadata, Integer numTokens)
1:     {
1:         Random random = new Random(seed.hashCode());
1: 
1:         IPartitioner p = tokenMetadata.partitioner;
1:         tokenMetadata.clearUnsafe();
1:         for (int i = 1; i <= numTokens; i++)
1:         {
1:             InetAddress addr = FBUtilities.getBroadcastAddress();
1:             List<Token> tokens = Lists.newArrayListWithCapacity(numTokens);
1:             for (int j = 0; j < numTokens; ++j)
1:                 tokens.add(p.getRandomToken(random));
1: 
1:             tokenMetadata.updateNormalTokens(tokens, addr);
1:         }
1:     }
1: 
1:     public abstract void run();
1: 
1: 
1:     @Command(name = "compact", description = "Compact data in directory")
1:     public static class Compaction extends CompactionStress
1:     {
1: 
1:         @Option(name = {"-m", "--maximal"}, description = "Force maximal compaction (default true)")
1:         Boolean maximal = false;
1: 
1:         @Option(name = {"-t", "--threads"}, description = "Number of compactor threads to use for bg compactions (default 4)")
1:         Integer threads = 4;
1: 
1:         public void run()
1:         {
1:             //Setup
1:             SystemKeyspace.finishStartup(); //needed for early-open
1:             CompactionManager.instance.setMaximumCompactorThreads(threads);
1:             CompactionManager.instance.setCoreCompactorThreads(threads);
1:             CompactionManager.instance.setRate(0);
1: 
1:             StressProfile stressProfile = getStressProfile();
1:             ColumnFamilyStore cfs = initCf(stressProfile, true);
1:             cfs.getCompactionStrategyManager().compactionLogger.enable();
1: 
1:             List<Future<?>> futures = new ArrayList<>(threads);
1:             if (maximal)
1:             {
1:                 futures = CompactionManager.instance.submitMaximal(cfs, FBUtilities.nowInSeconds(), false);
1:             }
1:             else
1:             {
1:                 cfs.enableAutoCompaction();
1:                 cfs.getCompactionStrategyManager().enable();
1:                 for (int i = 0; i < threads; i++)
1:                     futures.addAll(CompactionManager.instance.submitBackground(cfs));
1:             }
1: 
1:             long working;
1:             //Report compaction stats while working
1:             while ((working = futures.stream().filter(f -> !f.isDone()).count()) > 0 || CompactionManager.instance.getActiveCompactions() > 0 || (!maximal && cfs.getCompactionStrategyManager().getEstimatedRemainingTasks() > 0))
1:             {
1:                 //Re-up any bg jobs
1:                 if (!maximal)
1:                 {
1:                     for (long i = working; i < threads; i++)
1:                         futures.addAll(CompactionManager.instance.submitBackground(cfs));
1:                 }
1: 
1:                 reportCompactionStats();
1:                 Uninterruptibles.sleepUninterruptibly(10, TimeUnit.SECONDS);
1:             }
1: 
1:             System.out.println("Finished! Shutting down...");
1:             CompactionManager.instance.forceShutdown();
1: 
1:             //Wait for cleanup to finish before forcing
1:             Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);
1:             LifecycleTransaction.removeUnfinishedLeftovers(cfs);
1:         }
1:     }
1: 
1:     void reportCompactionStats()
1:     {
1:         System.out.println("========");
1:         System.out.println(String.format("Pending compactions: %d\n", CompactionManager.instance.getPendingTasks()));
1:         CompactionStats.reportCompactionTable(CompactionManager.instance.getCompactions(), 0, true);
1:     }
1: 
1: 
1:     @Command(name = "write", description = "write data directly to disk")
1:     public static class DataWriter extends CompactionStress
1:     {
1:         private static double BYTES_IN_GB = 1024 * 1014 * 1024;
1: 
1:         @Option(name = { "-g", "--gbsize"}, description = "Total GB size on disk you wish to write", required = true)
1:         Integer totalSizeGb;
1: 
1:         @Option(name = { "-t", "--threads" }, description = "Number of sstable writer threads (default 2)")
1:         Integer threads = 2;
1: 
1:         @Option(name = { "-c", "--partition-count"}, description = "Number of partitions to loop over (default 1000000)")
1:         Integer partitions = 1000000;
1: 
1:         @Option(name = { "-b", "--buffer-size-mb"}, description = "Buffer in MB writes before writing new sstable (default 128)")
1:         Integer bufferSize = 128;
1: 
1:         @Option(name = { "-r", "--range-aware"}, description = "Splits the local ranges in number of data directories and makes sure we never write the same token in two different directories (default true)")
1:         Boolean makeRangeAware = true;
1: 
1:         public void run()
1:         {
1:             StressProfile stressProfile = getStressProfile();
1:             ColumnFamilyStore cfs = initCf(stressProfile, false);
1:             Directories directories = cfs.getDirectories();
1: 
1:             StressSettings settings = StressSettings.parse(new String[]{ "write", "-pop seq=1.." + partitions });
1:             SeedManager seedManager = new SeedManager(settings);
1:             PartitionGenerator generator = stressProfile.getOfflineGenerator();
1:             WorkManager workManager = new WorkManager.FixedWorkManager(Long.MAX_VALUE);
1: 
1:             ExecutorService executorService = Executors.newFixedThreadPool(threads);
1:             CountDownLatch finished = new CountDownLatch(threads);
1: 
1:             for (int i = 0; i < threads; i++)
1:             {
1:                 //Every thread needs it's own writer
1:                 final SchemaInsert insert = stressProfile.getOfflineInsert(null, generator, seedManager, settings);
0:                 final CQLSSTableWriter tableWriter = insert.createWriter(cfs, bufferSize, makeRangeAware);
1:                 executorService.submit(() -> {
1:                     try
1:                     {
1:                         insert.runOffline(tableWriter, workManager);
1:                     }
1:                     catch (Exception e)
1:                     {
1:                         e.printStackTrace();
1:                     }
1:                     finally
1:                     {
1:                         FileUtils.closeQuietly(tableWriter);
1:                         finished.countDown();
1:                     }
1:                 });
1:             }
1: 
1:             double currentSizeGB;
1:             while ((currentSizeGB = directories.getRawDiretoriesSize() / BYTES_IN_GB) < totalSizeGb)
1:             {
1:                 if (finished.getCount() == 0)
1:                     break;
1: 
1:                 System.out.println(String.format("Written %.2fGB of %dGB", currentSizeGB, totalSizeGb));
1: 
1:                 Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
1:             }
1: 
1:             workManager.stop();
1:             Uninterruptibles.awaitUninterruptibly(finished);
1: 
1:             currentSizeGB = directories.getRawDiretoriesSize() / BYTES_IN_GB;
1:             System.out.println(String.format("Finished writing %.2fGB", currentSizeGB));
1:         }
1:     }
1: 
1:     public static void main(String[] args)
1:     {
1:         Cli.CliBuilder<Runnable> builder = Cli.<Runnable>builder("compaction-stress")
1:                                            .withDescription("benchmark for compaction")
1:                                            .withDefaultCommand(Help.class)
1:                                            .withCommands(Help.class, DataWriter.class, Compaction.class);
1: 
1:         Cli<Runnable> stress = builder.build();
1: 
1:         try
1:         {
1:             stress.parse(args).run();
1:         }
1:         catch (Throwable t)
1:         {
1:             t.printStackTrace();
1:             System.exit(6);
1:         }
1: 
1:         System.exit(0);
1:     }
1: }
1: 
1: 
============================================================================
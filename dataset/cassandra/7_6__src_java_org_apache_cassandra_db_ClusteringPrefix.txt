1:a991b64: /*
1:a991b64:  * Licensed to the Apache Software Foundation (ASF) under one
1:a991b64:  * or more contributor license agreements.  See the NOTICE file
1:a991b64:  * distributed with this work for additional information
1:a991b64:  * regarding copyright ownership.  The ASF licenses this file
1:a991b64:  * to you under the Apache License, Version 2.0 (the
1:a991b64:  * "License"); you may not use this file except in compliance
1:a991b64:  * with the License.  You may obtain a copy of the License at
2:a991b64:  *
1:a991b64:  *     http://www.apache.org/licenses/LICENSE-2.0
1:a991b64:  *
1:a991b64:  * Unless required by applicable law or agreed to in writing, software
1:a991b64:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a991b64:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a991b64:  * See the License for the specific language governing permissions and
1:a991b64:  * limitations under the License.
3:a991b64:  */
1:a991b64: package org.apache.cassandra.db;
9:a991b64: 
1:a991b64: import java.io.IOException;
1:a991b64: import java.nio.ByteBuffer;
1:a991b64: import java.security.MessageDigest;
1:a991b64: import java.util.*;
1:a991b64: 
1:a991b64: import org.apache.cassandra.cache.IMeasurableMemory;
1:57ead56: import org.apache.cassandra.config.*;
1:a991b64: import org.apache.cassandra.db.rows.*;
1:a991b64: import org.apache.cassandra.db.marshal.AbstractType;
1:2457599: import org.apache.cassandra.io.util.DataInputPlus;
1:a991b64: import org.apache.cassandra.io.util.DataOutputPlus;
1:a991b64: import org.apache.cassandra.utils.ByteBufferUtil;
1:a991b64: 
3:a991b64: /**
1:2457599:  * A clustering prefix is the unit of what a {@link ClusteringComparator} can compare.
2:a991b64:  * <p>
1:2457599:  * It holds values for the clustering columns of a table (potentially only a prefix of all of them) and has
1:a991b64:  * a "kind" that allows us to implement slices with inclusive and exclusive bounds.
1:a991b64:  * <p>
1:2457599:  * In practice, {@code ClusteringPrefix} is just the common parts to its 3 main subtype: {@link Clustering} and
1:2cc26eb:  * {@link ClusteringBound}/{@link ClusteringBoundary}, where:
1:a991b64:  *   1) {@code Clustering} represents the clustering values for a row, i.e. the values for it's clustering columns.
1:2cc26eb:  *   2) {@code ClusteringBound} represents a bound (start or end) of a slice (of rows) or a range tombstone.
1:2cc26eb:  *   3) {@code ClusteringBoundary} represents the threshold between two adjacent range tombstones.
1:a991b64:  * See those classes for more details.
1:a991b64:  */
1:2457599: public interface ClusteringPrefix extends IMeasurableMemory, Clusterable
2:a991b64: {
1:a991b64:     public static final Serializer serializer = new Serializer();
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * The kind of clustering prefix this actually is.
1:a991b64:      *
1:2457599:      * The kind {@code STATIC_CLUSTERING} is only implemented by {@link Clustering#STATIC_CLUSTERING} and {@code CLUSTERING} is
1:2cc26eb:      * implemented by the {@link Clustering} class. The rest is used by {@link ClusteringBound} and {@link ClusteringBoundary}.
1:a991b64:      */
1:a991b64:     public enum Kind
1:a991b64:     {
1:a991b64:         // WARNING: the ordering of that enum matters because we use ordinal() in the serialization
1:a991b64: 
1:7813dee:         EXCL_END_BOUND              (0, -1),
1:7813dee:         INCL_START_BOUND            (0, -1),
1:7813dee:         EXCL_END_INCL_START_BOUNDARY(0, -1),
1:7813dee:         STATIC_CLUSTERING           (1, -1),
1:7813dee:         CLUSTERING                  (2,  0),
1:7813dee:         INCL_END_EXCL_START_BOUNDARY(3,  1),
1:7813dee:         INCL_END_BOUND              (3,  1),
1:7813dee:         EXCL_START_BOUND            (3,  1);
1:a991b64: 
1:a991b64:         private final int comparison;
1:a991b64: 
1:7813dee:         /**
1:7813dee:          * Return the comparison of this kind to CLUSTERING.
1:7813dee:          * For bounds/boundaries, this basically tells us if we sort before or after our clustering values.
1:7813dee:          */
1:7813dee:         public final int comparedToClustering;
1:a991b64: 
1:2f41243:         Kind(int comparison, int comparedToClustering)
1:a991b64:         {
1:a991b64:             this.comparison = comparison;
1:7813dee:             this.comparedToClustering = comparedToClustering;
2:a991b64:         }
1:a991b64: 
1:a991b64:         /**
1:a991b64:          * Compares the 2 provided kind.
1:a991b64:          * <p>
1:a991b64:          * Note: this should be used instead of {@link #compareTo} when comparing clustering prefixes. We do
1:a991b64:          * not override that latter method because it is final for an enum.
1:a991b64:          */
1:a991b64:         public static int compare(Kind k1, Kind k2)
1:ef5bbed:         {
1:a991b64:             return Integer.compare(k1.comparison, k2.comparison);
1:a991b64:         }
1:a991b64: 
1:a991b64:         /**
1:a991b64:          * Returns the inverse of the current kind.
1:a991b64:          * <p>
1:a991b64:          * This invert both start into end (and vice-versa) and inclusive into exclusive (and vice-versa).
1:a991b64:          *
1:a991b64:          * @return the invert of this kind. For instance, if this kind is an exlusive start, this return
1:a991b64:          * an inclusive end.
1:a991b64:          */
1:a991b64:         public Kind invert()
1:a991b64:         {
1:a991b64:             switch (this)
1:a991b64:             {
1:a991b64:                 case EXCL_START_BOUND:              return INCL_END_BOUND;
1:a991b64:                 case INCL_START_BOUND:              return EXCL_END_BOUND;
1:a991b64:                 case EXCL_END_BOUND:                return INCL_START_BOUND;
1:a991b64:                 case INCL_END_BOUND:                return EXCL_START_BOUND;
1:a991b64:                 case EXCL_END_INCL_START_BOUNDARY:  return INCL_END_EXCL_START_BOUNDARY;
1:a991b64:                 case INCL_END_EXCL_START_BOUNDARY:  return EXCL_END_INCL_START_BOUNDARY;
1:a991b64:                 default:                            return this;
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isBound()
1:a991b64:         {
1:a991b64:             switch (this)
1:a991b64:             {
1:a991b64:                 case INCL_START_BOUND:
1:a991b64:                 case INCL_END_BOUND:
1:a991b64:                 case EXCL_START_BOUND:
1:a991b64:                 case EXCL_END_BOUND:
1:a991b64:                     return true;
1:2cc26eb:                 default:
1:2cc26eb:                     return false;
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isBoundary()
1:a991b64:         {
1:a991b64:             switch (this)
1:a991b64:             {
1:a991b64:                 case INCL_END_EXCL_START_BOUNDARY:
1:a991b64:                 case EXCL_END_INCL_START_BOUNDARY:
1:a991b64:                     return true;
1:2cc26eb:                 default:
1:2cc26eb:                     return false;
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isStart()
1:a991b64:         {
1:a991b64:             switch (this)
1:a991b64:             {
1:a991b64:                 case INCL_START_BOUND:
1:a991b64:                 case EXCL_END_INCL_START_BOUNDARY:
1:a991b64:                 case INCL_END_EXCL_START_BOUNDARY:
1:a991b64:                 case EXCL_START_BOUND:
1:a991b64:                     return true;
1:a991b64:                 default:
3:a991b64:                     return false;
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isEnd()
1:a991b64:         {
1:a991b64:             switch (this)
1:a991b64:             {
1:a991b64:                 case INCL_END_BOUND:
1:a991b64:                 case EXCL_END_INCL_START_BOUNDARY:
1:a991b64:                 case INCL_END_EXCL_START_BOUNDARY:
1:a991b64:                 case EXCL_END_BOUND:
1:a991b64:                     return true;
1:a991b64:                 default:
1:a991b64:                     return false;
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isOpen(boolean reversed)
1:a991b64:         {
1:2457599:             return isBoundary() || (reversed ? isEnd() : isStart());
1:a991b64:         }
1:a991b64: 
1:a991b64:         public boolean isClose(boolean reversed)
1:a991b64:         {
1:2457599:             return isBoundary() || (reversed ? isStart() : isEnd());
1:a991b64:         }
1:a991b64: 
1:a991b64:         public Kind closeBoundOfBoundary(boolean reversed)
1:a991b64:         {
1:a991b64:             assert isBoundary();
1:a991b64:             return reversed
1:a991b64:                  ? (this == INCL_END_EXCL_START_BOUNDARY ? EXCL_START_BOUND : INCL_START_BOUND)
1:a991b64:                  : (this == INCL_END_EXCL_START_BOUNDARY ? INCL_END_BOUND : EXCL_END_BOUND);
1:a991b64:         }
1:a991b64: 
1:a991b64:         public Kind openBoundOfBoundary(boolean reversed)
1:a991b64:         {
1:a991b64:             assert isBoundary();
1:a991b64:             return reversed
1:a991b64:                  ? (this == INCL_END_EXCL_START_BOUNDARY ? INCL_END_BOUND : EXCL_END_BOUND)
1:a991b64:                  : (this == INCL_END_EXCL_START_BOUNDARY ? EXCL_START_BOUND : INCL_START_BOUND);
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:a991b64:     public Kind kind();
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * The number of values in this prefix.
1:a991b64:      *
1:a991b64:      * There can't be more values that the this is a prefix of has of clustering columns.
1:a991b64:      *
1:a991b64:      * @return the number of values in this prefix.
1:a991b64:      */
1:a991b64:     public int size();
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Retrieves the ith value of this prefix.
1:a991b64:      *
1:a991b64:      * @param i the index of the value to retrieve. Must be such that {@code 0 <= i < size()}.
1:a991b64:      *
1:a991b64:      * @return the ith value of this prefix. Note that a value can be {@code null}.
1:a991b64:      */
1:a991b64:     public ByteBuffer get(int i);
1:a991b64: 
1:2457599:     /**
1:2457599:      * Adds the data of this clustering prefix to the provided digest.
1:2457599:      *
1:2457599:      * @param digest the digest to which to add this prefix.
1:2457599:      */
1:a991b64:     public void digest(MessageDigest digest);
1:a991b64: 
1:2457599:     /**
1:2457599:      * The size of the data hold by this prefix.
1:2457599:      *
1:2457599:      * @return the size of the data hold by this prefix (this is not the size of the object in memory, just
1:2457599:      * the size of the data it stores).
1:2457599:      */
1:a991b64:     public int dataSize();
1:a991b64: 
1:2457599:     /**
1:2457599:      * Generates a proper string representation of the prefix.
1:2457599:      *
1:2457599:      * @param metadata the metadata for the table the clustering prefix is of.
1:2457599:      * @return a human-readable string representation fo this prefix.
1:2457599:      */
1:a991b64:     public String toString(CFMetaData metadata);
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * The values of this prefix as an array.
1:a991b64:      * <p>
1:a991b64:      * Please note that this may or may not require an array creation. So 1) you should *not*
1:a991b64:      * modify the returned array and 2) it's more efficient to use {@link #size()} and
1:a991b64:      * {@link #get} unless you actually need an array.
1:a991b64:      *
1:a991b64:      * @return the values for this prefix as an array.
1:a991b64:      */
1:a991b64:     public ByteBuffer[] getRawValues();
1:a991b64: 
1:a991b64:     public static class Serializer
1:a991b64:     {
1:a991b64:         public void serialize(ClusteringPrefix clustering, DataOutputPlus out, int version, List<AbstractType<?>> types) throws IOException
1:a991b64:         {
1:a991b64:             // We shouldn't serialize static clusterings
1:a991b64:             assert clustering.kind() != Kind.STATIC_CLUSTERING;
1:a991b64:             if (clustering.kind() == Kind.CLUSTERING)
1:a991b64:             {
1:a991b64:                 out.writeByte(clustering.kind().ordinal());
1:a991b64:                 Clustering.serializer.serialize((Clustering)clustering, out, version, types);
1:a991b64:             }
2:a991b64:             else
1:a991b64:             {
1:2cc26eb:                 ClusteringBoundOrBoundary.serializer.serialize((ClusteringBoundOrBoundary)clustering, out, version, types);
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:ef5bbed:         public void skip(DataInputPlus in, int version, List<AbstractType<?>> types) throws IOException
1:ef5bbed:         {
1:ef5bbed:             Kind kind = Kind.values()[in.readByte()];
1:ef5bbed:             // We shouldn't serialize static clusterings
1:ef5bbed:             assert kind != Kind.STATIC_CLUSTERING;
1:ef5bbed:             if (kind == Kind.CLUSTERING)
1:ef5bbed:                 Clustering.serializer.skip(in, version, types);
1:ef5bbed:             else
1:2cc26eb:                 ClusteringBoundOrBoundary.serializer.skipValues(in, kind, version, types);
1:ef5bbed:         }
1:ef5bbed: 
1:2457599:         public ClusteringPrefix deserialize(DataInputPlus in, int version, List<AbstractType<?>> types) throws IOException
1:a991b64:         {
1:a991b64:             Kind kind = Kind.values()[in.readByte()];
1:a991b64:             // We shouldn't serialize static clusterings
1:a991b64:             assert kind != Kind.STATIC_CLUSTERING;
1:a991b64:             if (kind == Kind.CLUSTERING)
1:a991b64:                 return Clustering.serializer.deserialize(in, version, types);
1:a991b64:             else
1:2cc26eb:                 return ClusteringBoundOrBoundary.serializer.deserializeValues(in, kind, version, types);
1:a991b64:         }
1:a991b64: 
1:03f72ac:         public long serializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types)
1:a991b64:         {
1:a991b64:             // We shouldn't serialize static clusterings
1:a991b64:             assert clustering.kind() != Kind.STATIC_CLUSTERING;
1:a991b64:             if (clustering.kind() == Kind.CLUSTERING)
1:03f72ac:                 return 1 + Clustering.serializer.serializedSize((Clustering)clustering, version, types);
1:a991b64:             else
1:2cc26eb:                 return ClusteringBoundOrBoundary.serializer.serializedSize((ClusteringBoundOrBoundary)clustering, version, types);
1:a991b64:         }
1:a991b64: 
1:a991b64:         void serializeValuesWithoutSize(ClusteringPrefix clustering, DataOutputPlus out, int version, List<AbstractType<?>> types) throws IOException
1:a991b64:         {
1:5786b32:             int offset = 0;
1:5786b32:             int clusteringSize = clustering.size();
1:5786b32:             // serialize in batches of 32, to avoid garbage when deserializing headers
1:5786b32:             while (offset < clusteringSize)
1:a991b64:             {
1:5786b32:                 // we micro-batch the headers, so that we can incur fewer method calls,
1:5786b32:                 // and generate no garbage on deserialization;
1:5786b32:                 // we piggyback on vint encoding so that, typically, only 1 byte is used per 32 clustering values,
1:5786b32:                 // i.e. more than we ever expect to see
1:5786b32:                 int limit = Math.min(clusteringSize, offset + 32);
1:5786b32:                 out.writeUnsignedVInt(makeHeader(clustering, offset, limit));
1:5786b32:                 while (offset < limit)
1:a991b64:                 {
1:5786b32:                     ByteBuffer v = clustering.get(offset);
1:5786b32:                     if (v != null && v.hasRemaining())
1:5786b32:                         types.get(offset).writeValue(v, out);
1:5786b32:                     offset++;
1:a991b64:                 }
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:03f72ac:         long valuesWithoutSizeSerializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types)
1:a991b64:         {
1:5786b32:             long result = 0;
1:5786b32:             int offset = 0;
1:5786b32:             int clusteringSize = clustering.size();
1:5786b32:             while (offset < clusteringSize)
1:a991b64:             {
1:5786b32:                 int limit = Math.min(clusteringSize, offset + 32);
1:5786b32:                 result += TypeSizes.sizeofUnsignedVInt(makeHeader(clustering, offset, limit));
1:5786b32:                 offset = limit;
1:a991b64:             }
1:5786b32:             for (int i = 0; i < clusteringSize; i++)
1:a991b64:             {
1:a991b64:                 ByteBuffer v = clustering.get(i);
2:a991b64:                 if (v == null || !v.hasRemaining())
2:a991b64:                     continue; // handled in the header
1:a991b64: 
1:5786b32:                 result += types.get(i).writtenLength(v);
1:a991b64:             }
1:5786b32:             return result;
1:a991b64:         }
1:a991b64: 
1:2457599:         ByteBuffer[] deserializeValuesWithoutSize(DataInputPlus in, int size, int version, List<AbstractType<?>> types) throws IOException
1:a991b64:         {
1:2457599:             // Callers of this method should handle the case where size = 0 (in all case we want to return a special value anyway).
1:2457599:             assert size > 0;
1:2457599:             ByteBuffer[] values = new ByteBuffer[size];
1:5786b32:             int offset = 0;
1:5786b32:             while (offset < size)
1:a991b64:             {
1:5786b32:                 long header = in.readUnsignedVInt();
1:5786b32:                 int limit = Math.min(size, offset + 32);
1:5786b32:                 while (offset < limit)
1:a991b64:                 {
1:5786b32:                     values[offset] = isNull(header, offset)
1:2457599:                                 ? null
1:57ead56:                                 : (isEmpty(header, offset) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : types.get(offset).readValue(in, DatabaseDescriptor.getMaxValueSize()));
1:5786b32:                     offset++;
1:a991b64:                 }
1:a991b64:             }
1:2457599:             return values;
1:a991b64:         }
1:a991b64: 
1:ef5bbed:         void skipValuesWithoutSize(DataInputPlus in, int size, int version, List<AbstractType<?>> types) throws IOException
1:ef5bbed:         {
1:ef5bbed:             // Callers of this method should handle the case where size = 0 (in all case we want to return a special value anyway).
1:ef5bbed:             assert size > 0;
1:ef5bbed:             int offset = 0;
1:ef5bbed:             while (offset < size)
1:ef5bbed:             {
1:ef5bbed:                 long header = in.readUnsignedVInt();
1:ef5bbed:                 int limit = Math.min(size, offset + 32);
1:ef5bbed:                 while (offset < limit)
1:a991b64:                 {
1:ef5bbed:                     if (!isNull(header, offset) && !isEmpty(header, offset))
1:ef5bbed:                          types.get(offset).skipValue(in);
1:ef5bbed:                     offset++;
1:ef5bbed:                 }
1:ef5bbed:             }
1:ef5bbed:         }
1:ef5bbed: 
1:a991b64:         /**
1:a991b64:          * Whatever the type of a given clustering column is, its value can always be either empty or null. So we at least need to distinguish those
1:a991b64:          * 2 values, and because we want to be able to store fixed width values without appending their (fixed) size first, we need a way to encode
1:a991b64:          * empty values too. So for that, every clustering prefix includes a "header" that contains 2 bits per element in the prefix. For each element,
1:a991b64:          * those 2 bits encode whether the element is null, empty, or none of those.
1:a991b64:          */
1:5786b32:         private static long makeHeader(ClusteringPrefix clustering, int offset, int limit)
1:a991b64:         {
1:5786b32:             long header = 0;
1:5786b32:             for (int i = offset ; i < limit ; i++)
1:a991b64:             {
1:a991b64:                 ByteBuffer v = clustering.get(i);
1:5786b32:                 // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
1:a991b64:                 if (v == null)
1:5786b32:                     header |= (1L << (i * 2) + 1);
1:a991b64:                 else if (!v.hasRemaining())
1:5786b32:                     header |= (1L << (i * 2));
1:a991b64:             }
1:a991b64:             return header;
1:a991b64:         }
1:a991b64: 
1:5786b32:         // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
1:5786b32:         private static boolean isNull(long header, int i)
1:a991b64:         {
1:5786b32:             long mask = 1L << (i * 2) + 1;
1:5786b32:             return (header & mask) != 0;
1:a991b64:         }
1:a991b64: 
1:5786b32:         // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
1:5786b32:         private static boolean isEmpty(long header, int i)
1:a991b64:         {
1:5786b32:             long mask = 1L << (i * 2);
1:5786b32:             return (header & mask) != 0;
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Helper class that makes the deserialization of clustering prefixes faster.
1:a991b64:      * <p>
1:a991b64:      * The main reason for this is that when we deserialize rows from sstables, there is many cases where we have
1:a991b64:      * a bunch of rows to skip at the beginning of an index block because those rows are before the requested slice.
1:a991b64:      * This class make sure we can answer the question "is the next row on disk before the requested slice" with as
1:a991b64:      * little work as possible. It does that by providing a comparison method that deserialize only what is needed
1:a991b64:      * to decide of the comparison.
1:a991b64:      */
1:a991b64:     public static class Deserializer
1:a991b64:     {
1:a991b64:         private final ClusteringComparator comparator;
1:2457599:         private final DataInputPlus in;
1:a991b64:         private final SerializationHeader serializationHeader;
1:a991b64: 
1:a991b64:         private boolean nextIsRow;
1:5786b32:         private long nextHeader;
1:a991b64: 
1:a991b64:         private int nextSize;
1:a991b64:         private ClusteringPrefix.Kind nextKind;
1:a991b64:         private int deserializedSize;
1:2457599:         private ByteBuffer[] nextValues;
1:a991b64: 
1:2457599:         public Deserializer(ClusteringComparator comparator, DataInputPlus in, SerializationHeader header)
1:a991b64:         {
1:a991b64:             this.comparator = comparator;
1:a991b64:             this.in = in;
1:a991b64:             this.serializationHeader = header;
1:a991b64:         }
1:a991b64: 
1:665f747:         public void prepare(int flags, int extendedFlags) throws IOException
1:a991b64:         {
1:85cc390:             if (UnfilteredSerializer.isStatic(extendedFlags))
1:85cc390:                 throw new IOException("Corrupt flags value for clustering prefix (isStatic flag set): " + flags);
1:85cc390: 
1:a991b64:             this.nextIsRow = UnfilteredSerializer.kind(flags) == Unfiltered.Kind.ROW;
1:a991b64:             this.nextKind = nextIsRow ? Kind.CLUSTERING : ClusteringPrefix.Kind.values()[in.readByte()];
1:a991b64:             this.nextSize = nextIsRow ? comparator.size() : in.readUnsignedShort();
1:a991b64:             this.deserializedSize = 0;
1:2457599: 
1:2457599:             // The point of the deserializer is that some of the clustering prefix won't actually be used (because they are not
1:2457599:             // within the bounds of the query), and we want to reduce allocation for them. So we only reuse the values array
1:2457599:             // between elements if 1) we haven't returned the previous element (if we have, nextValues will be null) and 2)
1:2457599:             // nextValues is of the proper size. Note that the 2nd condition may not hold for range tombstone bounds, but all
1:2457599:             // rows have a fixed size clustering, so we'll still save in the common case.
1:2457599:             if (nextValues == null || nextValues.length != nextSize)
1:2457599:                 this.nextValues = new ByteBuffer[nextSize];
1:a991b64:         }
1:a991b64: 
1:2cc26eb:         public int compareNextTo(ClusteringBoundOrBoundary bound) throws IOException
1:a991b64:         {
1:2cc26eb:             if (bound == ClusteringBound.TOP)
1:a991b64:                 return -1;
1:a991b64: 
1:a991b64:             for (int i = 0; i < bound.size(); i++)
1:a991b64:             {
1:a991b64:                 if (!hasComponent(i))
1:7813dee:                     return nextKind.comparedToClustering;
1:a991b64: 
1:a991b64:                 int cmp = comparator.compareComponent(i, nextValues[i], bound.get(i));
1:a991b64:                 if (cmp != 0)
1:a991b64:                     return cmp;
1:a991b64:             }
1:a991b64: 
1:a991b64:             if (bound.size() == nextSize)
1:a991b64:                 return nextKind.compareTo(bound.kind());
1:a991b64: 
1:a991b64:             // We know that we'll have exited already if nextSize < bound.size
1:7813dee:             return -bound.kind().comparedToClustering;
1:a991b64:         }
1:a991b64: 
1:a991b64:         private boolean hasComponent(int i) throws IOException
1:a991b64:         {
1:a991b64:             if (i >= nextSize)
1:a991b64:                 return false;
1:a991b64: 
1:a991b64:             while (deserializedSize <= i)
1:a991b64:                 deserializeOne();
1:a991b64: 
1:a991b64:             return true;
1:a991b64:         }
1:a991b64: 
1:a991b64:         private boolean deserializeOne() throws IOException
1:a991b64:         {
1:a991b64:             if (deserializedSize == nextSize)
1:a991b64:                 return false;
1:a991b64: 
1:5786b32:             if ((deserializedSize % 32) == 0)
1:5786b32:                 nextHeader = in.readUnsignedVInt();
1:a991b64: 
1:a991b64:             int i = deserializedSize++;
1:2457599:             nextValues[i] = Serializer.isNull(nextHeader, i)
1:a991b64:                           ? null
1:57ead56:                           : (Serializer.isEmpty(nextHeader, i) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : serializationHeader.clusteringTypes().get(i).readValue(in, DatabaseDescriptor.getMaxValueSize()));
1:a991b64:             return true;
1:a991b64:         }
1:a991b64: 
1:a991b64:         private void deserializeAll() throws IOException
1:a991b64:         {
1:a991b64:             while (deserializeOne())
1:a991b64:                 continue;
1:a991b64:         }
1:a991b64: 
1:2cc26eb:         public ClusteringBoundOrBoundary deserializeNextBound() throws IOException
1:a991b64:         {
1:a991b64:             assert !nextIsRow;
1:a991b64:             deserializeAll();
1:2cc26eb:             ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.create(nextKind, nextValues);
1:2457599:             nextValues = null;
1:2457599:             return bound;
1:a991b64:         }
1:a991b64: 
1:2457599:         public Clustering deserializeNextClustering() throws IOException
1:a991b64:         {
1:2457599:             assert nextIsRow;
1:a991b64:             deserializeAll();
1:2f41243:             Clustering clustering = Clustering.make(nextValues);
1:2457599:             nextValues = null;
1:2457599:             return clustering;
1:a991b64:         }
1:a991b64: 
1:a991b64:         public ClusteringPrefix.Kind skipNext() throws IOException
1:a991b64:         {
1:a991b64:             for (int i = deserializedSize; i < nextSize; i++)
1:2457599:             {
1:5786b32:                 if ((i % 32) == 0)
1:5786b32:                     nextHeader = in.readUnsignedVInt();
1:2457599:                 if (!Serializer.isNull(nextHeader, i) && !Serializer.isEmpty(nextHeader, i))
1:a991b64:                     serializationHeader.clusteringTypes().get(i).skipValue(in);
1:2457599:             }
1:5786b32:             deserializedSize = nextSize;
2:a991b64:             return nextKind;
1:a991b64:         }
1:a991b64:     }
1:a991b64: }
============================================================================
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:a2b73a5
commit:68d20ed
author:Alex Petrov
-------------------------------------------------------------------------------
commit:57ead56
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.config.*;
/////////////////////////////////////////////////////////////////////////
1:                                 : (isEmpty(header, offset) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : types.get(offset).readValue(in, DatabaseDescriptor.getMaxValueSize()));
/////////////////////////////////////////////////////////////////////////
1:                           : (Serializer.isEmpty(nextHeader, i) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : serializationHeader.clusteringTypes().get(i).readValue(in, DatabaseDescriptor.getMaxValueSize()));
commit:85cc390
/////////////////////////////////////////////////////////////////////////
1:             if (UnfilteredSerializer.isStatic(extendedFlags))
1:                 throw new IOException("Corrupt flags value for clustering prefix (isStatic flag set): " + flags);
1: 
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:2cc26eb
/////////////////////////////////////////////////////////////////////////
1:  * {@link ClusteringBound}/{@link ClusteringBoundary}, where:
1:  *   2) {@code ClusteringBound} represents a bound (start or end) of a slice (of rows) or a range tombstone.
1:  *   3) {@code ClusteringBoundary} represents the threshold between two adjacent range tombstones.
/////////////////////////////////////////////////////////////////////////
1:      * implemented by the {@link Clustering} class. The rest is used by {@link ClusteringBound} and {@link ClusteringBoundary}.
/////////////////////////////////////////////////////////////////////////
1:                 default:
1:                     return false;
/////////////////////////////////////////////////////////////////////////
1:                 default:
1:                     return false;
/////////////////////////////////////////////////////////////////////////
1:                 ClusteringBoundOrBoundary.serializer.serialize((ClusteringBoundOrBoundary)clustering, out, version, types);
/////////////////////////////////////////////////////////////////////////
1:                 ClusteringBoundOrBoundary.serializer.skipValues(in, kind, version, types);
/////////////////////////////////////////////////////////////////////////
1:                 return ClusteringBoundOrBoundary.serializer.deserializeValues(in, kind, version, types);
/////////////////////////////////////////////////////////////////////////
1:                 return ClusteringBoundOrBoundary.serializer.serializedSize((ClusteringBoundOrBoundary)clustering, version, types);
/////////////////////////////////////////////////////////////////////////
1:         public int compareNextTo(ClusteringBoundOrBoundary bound) throws IOException
1:             if (bound == ClusteringBound.TOP)
/////////////////////////////////////////////////////////////////////////
1:         public ClusteringBoundOrBoundary deserializeNextBound() throws IOException
1:             ClusteringBoundOrBoundary bound = ClusteringBoundOrBoundary.create(nextKind, nextValues);
commit:fe37e06
/////////////////////////////////////////////////////////////////////////
0:                 RangeTombstone.Bound.serializer.serialize((RangeTombstone.Bound)clustering, out, version, types);
/////////////////////////////////////////////////////////////////////////
0:                 return RangeTombstone.Bound.serializer.deserializeValues(in, kind, version, types);
/////////////////////////////////////////////////////////////////////////
0:                 return RangeTombstone.Bound.serializer.serializedSize((RangeTombstone.Bound)clustering, version, types);
author:Robert Stupp
-------------------------------------------------------------------------------
commit:ef5bbed
/////////////////////////////////////////////////////////////////////////
1:         public void skip(DataInputPlus in, int version, List<AbstractType<?>> types) throws IOException
1:         {
1:             Kind kind = Kind.values()[in.readByte()];
1:             // We shouldn't serialize static clusterings
1:             assert kind != Kind.STATIC_CLUSTERING;
1:             if (kind == Kind.CLUSTERING)
1:                 Clustering.serializer.skip(in, version, types);
1:             else
0:                 RangeTombstone.Bound.serializer.skipValues(in, kind, version, types);
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:         void skipValuesWithoutSize(DataInputPlus in, int size, int version, List<AbstractType<?>> types) throws IOException
1:         {
1:             // Callers of this method should handle the case where size = 0 (in all case we want to return a special value anyway).
1:             assert size > 0;
1:             int offset = 0;
1:             while (offset < size)
1:             {
1:                 long header = in.readUnsignedVInt();
1:                 int limit = Math.min(size, offset + 32);
1:                 while (offset < limit)
1:                 {
1:                     if (!isNull(header, offset) && !isEmpty(header, offset))
1:                          types.get(offset).skipValue(in);
1:                     offset++;
1:                 }
1:             }
1:         }
1: 
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:030c775
commit:665f747
/////////////////////////////////////////////////////////////////////////
1:         public void prepare(int flags, int extendedFlags) throws IOException
0:             assert !UnfilteredSerializer.isStatic(extendedFlags) : "Flags = " + flags;
commit:2457599
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus;
1:  * A clustering prefix is the unit of what a {@link ClusteringComparator} can compare.
1:  * It holds values for the clustering columns of a table (potentially only a prefix of all of them) and has
1:  * In practice, {@code ClusteringPrefix} is just the common parts to its 3 main subtype: {@link Clustering} and
0:  * {@link Slice.Bound}/{@link RangeTombstone.Bound}, where:
0:  *   3) {@code RangeTombstoneBoundMarker.Bound} represents a range tombstone marker "bound".
1: public interface ClusteringPrefix extends IMeasurableMemory, Clusterable
1:      * The kind {@code STATIC_CLUSTERING} is only implemented by {@link Clustering#STATIC_CLUSTERING} and {@code CLUSTERING} is
/////////////////////////////////////////////////////////////////////////
1:             return isBoundary() || (reversed ? isEnd() : isStart());
1:             return isBoundary() || (reversed ? isStart() : isEnd());
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Adds the data of this clustering prefix to the provided digest.
1:      *
1:      * @param digest the digest to which to add this prefix.
1:      */
1:     /**
1:      * The size of the data hold by this prefix.
1:      *
1:      * @return the size of the data hold by this prefix (this is not the size of the object in memory, just
1:      * the size of the data it stores).
1:      */
1:     /**
1:      * Generates a proper string representation of the prefix.
1:      *
1:      * @param metadata the metadata for the table the clustering prefix is of.
1:      * @return a human-readable string representation fo this prefix.
1:      */
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         public ClusteringPrefix deserialize(DataInputPlus in, int version, List<AbstractType<?>> types) throws IOException
/////////////////////////////////////////////////////////////////////////
1:         ByteBuffer[] deserializeValuesWithoutSize(DataInputPlus in, int size, int version, List<AbstractType<?>> types) throws IOException
1:             // Callers of this method should handle the case where size = 0 (in all case we want to return a special value anyway).
1:             assert size > 0;
1:             ByteBuffer[] values = new ByteBuffer[size];
0:                 values[i] = isNull(header, i)
1:                           ? null
0:                           : (isEmpty(header, i) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : types.get(i).readValue(in));
1:             return values;
/////////////////////////////////////////////////////////////////////////
0:         private int[] readHeader(int size, DataInputPlus in) throws IOException
/////////////////////////////////////////////////////////////////////////
0:         private static boolean isNull(int[] header, int i)
0:         private static boolean isEmpty(int[] header, int i)
/////////////////////////////////////////////////////////////////////////
1:         private final DataInputPlus in;
/////////////////////////////////////////////////////////////////////////
1:         private ByteBuffer[] nextValues;
1:         public Deserializer(ClusteringComparator comparator, DataInputPlus in, SerializationHeader header)
/////////////////////////////////////////////////////////////////////////
1: 
1:             // The point of the deserializer is that some of the clustering prefix won't actually be used (because they are not
1:             // within the bounds of the query), and we want to reduce allocation for them. So we only reuse the values array
1:             // between elements if 1) we haven't returned the previous element (if we have, nextValues will be null) and 2)
1:             // nextValues is of the proper size. Note that the 2nd condition may not hold for range tombstone bounds, but all
1:             // rows have a fixed size clustering, so we'll still save in the common case.
1:             if (nextValues == null || nextValues.length != nextSize)
1:                 this.nextValues = new ByteBuffer[nextSize];
/////////////////////////////////////////////////////////////////////////
1:             nextValues[i] = Serializer.isNull(nextHeader, i)
0:                           : (Serializer.isEmpty(nextHeader, i) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : serializationHeader.clusteringTypes().get(i).readValue(in));
/////////////////////////////////////////////////////////////////////////
0:         public RangeTombstone.Bound deserializeNextBound() throws IOException
0:             RangeTombstone.Bound bound = new RangeTombstone.Bound(nextKind, nextValues);
1:             nextValues = null;
1:             return bound;
1:         public Clustering deserializeNextClustering() throws IOException
1:             assert nextIsRow;
0:             Clustering clustering = new Clustering(nextValues);
1:             nextValues = null;
1:             return clustering;
1:             {
1:                 if (!Serializer.isNull(nextHeader, i) && !Serializer.isEmpty(nextHeader, i))
1:             }
commit:7813dee
/////////////////////////////////////////////////////////////////////////
1:         EXCL_END_BOUND              (0, -1),
1:         INCL_START_BOUND            (0, -1),
1:         EXCL_END_INCL_START_BOUNDARY(0, -1),
1:         STATIC_CLUSTERING           (1, -1),
1:         CLUSTERING                  (2,  0),
1:         INCL_END_EXCL_START_BOUNDARY(3,  1),
1:         INCL_END_BOUND              (3,  1),
1:         EXCL_START_BOUND            (3,  1);
1:         /**
1:          * Return the comparison of this kind to CLUSTERING.
1:          * For bounds/boundaries, this basically tells us if we sort before or after our clustering values.
1:          */
1:         public final int comparedToClustering;
0:         private Kind(int comparison, int comparedToClustering)
1:             this.comparedToClustering = comparedToClustering;
/////////////////////////////////////////////////////////////////////////
1:                     return nextKind.comparedToClustering;
/////////////////////////////////////////////////////////////////////////
1:             return -bound.kind().comparedToClustering;
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.db;
1: 
0: import java.io.DataInput;
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.security.MessageDigest;
1: import java.util.*;
1: 
1: import org.apache.cassandra.cache.IMeasurableMemory;
0: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.db.rows.*;
1: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.io.util.DataOutputPlus;
1: import org.apache.cassandra.utils.ByteBufferUtil;
1: 
1: /**
0:  * A clustering prefix is basically the unit of what a {@link ClusteringComparator} can compare.
1:  * <p>
0:  * It holds values for the clustering columns of a table (potentially only a prefix of all of them) and it has
1:  * a "kind" that allows us to implement slices with inclusive and exclusive bounds.
1:  * <p>
0:  * In practice, {@code ClusteringPrefix} is just the common parts to its 2 main subtype: {@link Clustering} and
0:  * {@link Slice.Bound}, where:
1:  *   1) {@code Clustering} represents the clustering values for a row, i.e. the values for it's clustering columns.
0:  *   2) {@code Slice.Bound} represents a bound (start or end) of a slice (of rows).
1:  * See those classes for more details.
1:  */
0: public interface ClusteringPrefix extends Aliasable<ClusteringPrefix>, IMeasurableMemory, Clusterable
1: {
1:     public static final Serializer serializer = new Serializer();
1: 
1:     /**
1:      * The kind of clustering prefix this actually is.
1:      *
0:      * The kind {@code STATIC_CLUSTERING} is only implemented by {@link Clustering.STATIC_CLUSTERING} and {@code CLUSTERING} is
0:      * implemented by the {@link Clustering} class. The rest is used by {@link Slice.Bound} and {@link RangeTombstone.Bound}.
1:      */
1:     public enum Kind
1:     {
1:         // WARNING: the ordering of that enum matters because we use ordinal() in the serialization
1: 
0:         EXCL_END_BOUND(0, -1),
0:         INCL_START_BOUND(1, -1),
0:         EXCL_END_INCL_START_BOUNDARY(1, -1),
0:         STATIC_CLUSTERING(2, -1),
0:         CLUSTERING(3, 0),
0:         INCL_END_EXCL_START_BOUNDARY(4, -1),
0:         INCL_END_BOUND(4, 1),
0:         EXCL_START_BOUND(5, 1);
1: 
1:         private final int comparison;
1: 
0:         // If clusterable c1 has this Kind and is a strict prefix of clusterable c2, then this
0:         // is the result of compare(c1, c2). Basically, this is the same as comparing the kind of c1 to
0:         // CLUSTERING.
0:         public final int prefixComparisonResult;
1: 
0:         private Kind(int comparison, int prefixComparisonResult)
1:         {
1:             this.comparison = comparison;
0:             this.prefixComparisonResult = prefixComparisonResult;
1:         }
1: 
1:         /**
1:          * Compares the 2 provided kind.
1:          * <p>
1:          * Note: this should be used instead of {@link #compareTo} when comparing clustering prefixes. We do
1:          * not override that latter method because it is final for an enum.
1:          */
1:         public static int compare(Kind k1, Kind k2)
1:         {
1:             return Integer.compare(k1.comparison, k2.comparison);
1:         }
1: 
1:         /**
1:          * Returns the inverse of the current kind.
1:          * <p>
1:          * This invert both start into end (and vice-versa) and inclusive into exclusive (and vice-versa).
1:          *
1:          * @return the invert of this kind. For instance, if this kind is an exlusive start, this return
1:          * an inclusive end.
1:          */
1:         public Kind invert()
1:         {
1:             switch (this)
1:             {
1:                 case EXCL_START_BOUND:              return INCL_END_BOUND;
1:                 case INCL_START_BOUND:              return EXCL_END_BOUND;
1:                 case EXCL_END_BOUND:                return INCL_START_BOUND;
1:                 case INCL_END_BOUND:                return EXCL_START_BOUND;
1:                 case EXCL_END_INCL_START_BOUNDARY:  return INCL_END_EXCL_START_BOUNDARY;
1:                 case INCL_END_EXCL_START_BOUNDARY:  return EXCL_END_INCL_START_BOUNDARY;
1:                 default:                            return this;
1:             }
1:         }
1: 
1:         public boolean isBound()
1:         {
1:             switch (this)
1:             {
1:                 case INCL_START_BOUND:
1:                 case INCL_END_BOUND:
1:                 case EXCL_START_BOUND:
1:                 case EXCL_END_BOUND:
1:                     return true;
1:             }
1:             return false;
1:         }
1: 
1:         public boolean isBoundary()
1:         {
1:             switch (this)
1:             {
1:                 case INCL_END_EXCL_START_BOUNDARY:
1:                 case EXCL_END_INCL_START_BOUNDARY:
1:                     return true;
1:             }
1:             return false;
1:         }
1: 
1:         public boolean isStart()
1:         {
1:             switch (this)
1:             {
1:                 case INCL_START_BOUND:
1:                 case EXCL_END_INCL_START_BOUNDARY:
1:                 case INCL_END_EXCL_START_BOUNDARY:
1:                 case EXCL_START_BOUND:
1:                     return true;
1:                 default:
1:                     return false;
1:             }
1:         }
1: 
1:         public boolean isEnd()
1:         {
1:             switch (this)
1:             {
1:                 case INCL_END_BOUND:
1:                 case EXCL_END_INCL_START_BOUNDARY:
1:                 case INCL_END_EXCL_START_BOUNDARY:
1:                 case EXCL_END_BOUND:
1:                     return true;
1:                 default:
1:                     return false;
1:             }
1:         }
1: 
1:         public boolean isOpen(boolean reversed)
1:         {
0:             return reversed ? isEnd() : isStart();
1:         }
1: 
1:         public boolean isClose(boolean reversed)
1:         {
0:             return reversed ? isStart() : isEnd();
1:         }
1: 
1:         public Kind closeBoundOfBoundary(boolean reversed)
1:         {
1:             assert isBoundary();
1:             return reversed
1:                  ? (this == INCL_END_EXCL_START_BOUNDARY ? EXCL_START_BOUND : INCL_START_BOUND)
1:                  : (this == INCL_END_EXCL_START_BOUNDARY ? INCL_END_BOUND : EXCL_END_BOUND);
1:         }
1: 
1:         public Kind openBoundOfBoundary(boolean reversed)
1:         {
1:             assert isBoundary();
1:             return reversed
1:                  ? (this == INCL_END_EXCL_START_BOUNDARY ? INCL_END_BOUND : EXCL_END_BOUND)
1:                  : (this == INCL_END_EXCL_START_BOUNDARY ? EXCL_START_BOUND : INCL_START_BOUND);
1:         }
1:     }
1: 
1:     public Kind kind();
1: 
1:     /**
1:      * The number of values in this prefix.
1:      *
1:      * There can't be more values that the this is a prefix of has of clustering columns.
1:      *
1:      * @return the number of values in this prefix.
1:      */
1:     public int size();
1: 
1:     /**
1:      * Retrieves the ith value of this prefix.
1:      *
1:      * @param i the index of the value to retrieve. Must be such that {@code 0 <= i < size()}.
1:      *
1:      * @return the ith value of this prefix. Note that a value can be {@code null}.
1:      */
1:     public ByteBuffer get(int i);
1: 
1:     public void digest(MessageDigest digest);
1: 
0:     // Used to verify if batches goes over a given size
1:     public int dataSize();
1: 
1:     public String toString(CFMetaData metadata);
1: 
0:     public void writeTo(Writer writer);
1: 
1:     /**
1:      * The values of this prefix as an array.
1:      * <p>
1:      * Please note that this may or may not require an array creation. So 1) you should *not*
1:      * modify the returned array and 2) it's more efficient to use {@link #size()} and
1:      * {@link #get} unless you actually need an array.
1:      *
1:      * @return the values for this prefix as an array.
1:      */
1:     public ByteBuffer[] getRawValues();
1: 
1:     /**
0:      * Interface for writing a clustering prefix.
1:      * <p>
0:      * Each value for the prefix should simply be written in order.
1:      */
0:     public interface Writer
1:     {
1:         /**
0:          * Write the next value to the writer.
1:          *
0:          * @param value the value to write.
1:          */
0:         public void writeClusteringValue(ByteBuffer value);
1:     }
1: 
1:     public static class Serializer
1:     {
1:         public void serialize(ClusteringPrefix clustering, DataOutputPlus out, int version, List<AbstractType<?>> types) throws IOException
1:         {
1:             // We shouldn't serialize static clusterings
1:             assert clustering.kind() != Kind.STATIC_CLUSTERING;
1:             if (clustering.kind() == Kind.CLUSTERING)
1:             {
1:                 out.writeByte(clustering.kind().ordinal());
1:                 Clustering.serializer.serialize((Clustering)clustering, out, version, types);
1:             }
1:             else
1:             {
0:                 Slice.Bound.serializer.serialize((Slice.Bound)clustering, out, version, types);
1:             }
1:         }
1: 
0:         public ClusteringPrefix deserialize(DataInput in, int version, List<AbstractType<?>> types) throws IOException
1:         {
1:             Kind kind = Kind.values()[in.readByte()];
1:             // We shouldn't serialize static clusterings
1:             assert kind != Kind.STATIC_CLUSTERING;
1:             if (kind == Kind.CLUSTERING)
1:                 return Clustering.serializer.deserialize(in, version, types);
1:             else
0:                 return Slice.Bound.serializer.deserializeValues(in, kind, version, types);
1:         }
1: 
0:         public long serializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types, TypeSizes sizes)
1:         {
1:             // We shouldn't serialize static clusterings
1:             assert clustering.kind() != Kind.STATIC_CLUSTERING;
1:             if (clustering.kind() == Kind.CLUSTERING)
0:                 return 1 + Clustering.serializer.serializedSize((Clustering)clustering, version, types, sizes);
1:             else
0:                 return Slice.Bound.serializer.serializedSize((Slice.Bound)clustering, version, types, sizes);
1:         }
1: 
1:         void serializeValuesWithoutSize(ClusteringPrefix clustering, DataOutputPlus out, int version, List<AbstractType<?>> types) throws IOException
1:         {
0:             if (clustering.size() == 0)
0:                 return;
1: 
0:             writeHeader(clustering, out);
0:             for (int i = 0; i < clustering.size(); i++)
1:             {
1:                 ByteBuffer v = clustering.get(i);
1:                 if (v == null || !v.hasRemaining())
1:                     continue; // handled in the header
1: 
0:                 types.get(i).writeValue(v, out);
1:             }
1:         }
1: 
0:         long valuesWithoutSizeSerializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types, TypeSizes sizes)
1:         {
0:             if (clustering.size() == 0)
0:                 return 0;
1: 
0:             long size = headerBytesCount(clustering.size());
0:             for (int i = 0; i < clustering.size(); i++)
1:             {
1:                 ByteBuffer v = clustering.get(i);
1:                 if (v == null || !v.hasRemaining())
1:                     continue; // handled in the header
1: 
0:                 size += types.get(i).writtenLength(v, sizes);
1:             }
0:             return size;
1:         }
1: 
0:         void deserializeValuesWithoutSize(DataInput in, int size, int version, List<AbstractType<?>> types, ClusteringPrefix.Writer writer) throws IOException
1:         {
0:             if (size == 0)
0:                 return;
1: 
0:             int[] header = readHeader(size, in);
0:             for (int i = 0; i < size; i++)
1:             {
0:                 if (isNull(header, i))
0:                     writer.writeClusteringValue(null);
0:                 else if (isEmpty(header, i))
0:                     writer.writeClusteringValue(ByteBufferUtil.EMPTY_BYTE_BUFFER);
1:                 else
0:                     writer.writeClusteringValue(types.get(i).readValue(in));
1:             }
1:         }
1: 
0:         private int headerBytesCount(int size)
1:         {
0:             // For each component, we store 2 bit to know if the component is empty or null (or neither).
0:             // We thus handle 4 component per byte
0:             return size / 4 + (size % 4 == 0 ? 0 : 1);
1:         }
1: 
1:         /**
1:          * Whatever the type of a given clustering column is, its value can always be either empty or null. So we at least need to distinguish those
1:          * 2 values, and because we want to be able to store fixed width values without appending their (fixed) size first, we need a way to encode
1:          * empty values too. So for that, every clustering prefix includes a "header" that contains 2 bits per element in the prefix. For each element,
1:          * those 2 bits encode whether the element is null, empty, or none of those.
1:          */
0:         private void writeHeader(ClusteringPrefix clustering, DataOutputPlus out) throws IOException
1:         {
0:             int nbBytes = headerBytesCount(clustering.size());
0:             for (int i = 0; i < nbBytes; i++)
1:             {
0:                 int b = 0;
0:                 for (int j = 0; j < 4; j++)
1:                 {
0:                     int c = i * 4 + j;
0:                     if (c >= clustering.size())
0:                         break;
1: 
0:                     ByteBuffer v = clustering.get(c);
1:                     if (v == null)
0:                         b |= (1 << (j * 2) + 1);
1:                     else if (!v.hasRemaining())
0:                         b |= (1 << (j * 2));
1:                 }
0:                 out.writeByte((byte)b);
1:             }
1:         }
1: 
0:         private int[] readHeader(int size, DataInput in) throws IOException
1:         {
0:             int nbBytes = headerBytesCount(size);
0:             int[] header = new int[nbBytes];
0:             for (int i = 0; i < nbBytes; i++)
0:                 header[i] = in.readUnsignedByte();
1:             return header;
1:         }
1: 
0:         private boolean isNull(int[] header, int i)
1:         {
0:             int b = header[i / 4];
0:             int mask = 1 << ((i % 4) * 2) + 1;
0:             return (b & mask) != 0;
1:         }
1: 
0:         private boolean isEmpty(int[] header, int i)
1:         {
0:             int b = header[i / 4];
0:             int mask = 1 << ((i % 4) * 2);
0:             return (b & mask) != 0;
1:         }
1:     }
1: 
1:     /**
1:      * Helper class that makes the deserialization of clustering prefixes faster.
1:      * <p>
1:      * The main reason for this is that when we deserialize rows from sstables, there is many cases where we have
1:      * a bunch of rows to skip at the beginning of an index block because those rows are before the requested slice.
1:      * This class make sure we can answer the question "is the next row on disk before the requested slice" with as
1:      * little work as possible. It does that by providing a comparison method that deserialize only what is needed
1:      * to decide of the comparison.
1:      */
1:     public static class Deserializer
1:     {
1:         private final ClusteringComparator comparator;
0:         private final DataInput in;
1:         private final SerializationHeader serializationHeader;
1: 
1:         private boolean nextIsRow;
0:         private int[] nextHeader;
1: 
1:         private int nextSize;
1:         private ClusteringPrefix.Kind nextKind;
1:         private int deserializedSize;
0:         private final ByteBuffer[] nextValues;
1: 
0:         public Deserializer(ClusteringComparator comparator, DataInput in, SerializationHeader header)
1:         {
1:             this.comparator = comparator;
1:             this.in = in;
1:             this.serializationHeader = header;
0:             this.nextValues = new ByteBuffer[comparator.size()];
1:         }
1: 
0:         public void prepare(int flags) throws IOException
1:         {
0:             assert !UnfilteredSerializer.isStatic(flags) : "Flags = " + flags;
1:             this.nextIsRow = UnfilteredSerializer.kind(flags) == Unfiltered.Kind.ROW;
1:             this.nextKind = nextIsRow ? Kind.CLUSTERING : ClusteringPrefix.Kind.values()[in.readByte()];
1:             this.nextSize = nextIsRow ? comparator.size() : in.readUnsignedShort();
0:             this.nextHeader = serializer.readHeader(nextSize, in);
1:             this.deserializedSize = 0;
1:         }
1: 
0:         public int compareNextTo(Slice.Bound bound) throws IOException
1:         {
0:             if (bound == Slice.Bound.TOP)
1:                 return -1;
1: 
1:             for (int i = 0; i < bound.size(); i++)
1:             {
1:                 if (!hasComponent(i))
0:                     return nextKind.prefixComparisonResult;
1: 
1:                 int cmp = comparator.compareComponent(i, nextValues[i], bound.get(i));
1:                 if (cmp != 0)
1:                     return cmp;
1:             }
1: 
1:             if (bound.size() == nextSize)
1:                 return nextKind.compareTo(bound.kind());
1: 
1:             // We know that we'll have exited already if nextSize < bound.size
0:             return -bound.kind().prefixComparisonResult;
1:         }
1: 
1:         private boolean hasComponent(int i) throws IOException
1:         {
1:             if (i >= nextSize)
1:                 return false;
1: 
1:             while (deserializedSize <= i)
1:                 deserializeOne();
1: 
1:             return true;
1:         }
1: 
1:         private boolean deserializeOne() throws IOException
1:         {
1:             if (deserializedSize == nextSize)
1:                 return false;
1: 
1:             int i = deserializedSize++;
0:             nextValues[i] = serializer.isNull(nextHeader, i)
1:                           ? null
0:                           : (serializer.isEmpty(nextHeader, i) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : serializationHeader.clusteringTypes().get(i).readValue(in));
1:             return true;
1:         }
1: 
1:         private void deserializeAll() throws IOException
1:         {
1:             while (deserializeOne())
1:                 continue;
1:         }
1: 
0:         public RangeTombstone.Bound.Kind deserializeNextBound(RangeTombstone.Bound.Writer writer) throws IOException
1:         {
1:             assert !nextIsRow;
1:             deserializeAll();
0:             for (int i = 0; i < nextSize; i++)
0:                 writer.writeClusteringValue(nextValues[i]);
0:             writer.writeBoundKind(nextKind);
1:             return nextKind;
1:         }
1: 
0:         public void deserializeNextClustering(Clustering.Writer writer) throws IOException
1:         {
0:             assert nextIsRow && nextSize == nextValues.length;
1:             deserializeAll();
0:             for (int i = 0; i < nextSize; i++)
0:                 writer.writeClusteringValue(nextValues[i]);
1:         }
1: 
1:         public ClusteringPrefix.Kind skipNext() throws IOException
1:         {
1:             for (int i = deserializedSize; i < nextSize; i++)
0:                 if (!serializer.isNull(nextHeader, i) && !serializer.isEmpty(nextHeader, i))
1:                     serializationHeader.clusteringTypes().get(i).skipValue(in);
1:             return nextKind;
1:         }
1:     }
1: }
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:2f41243
/////////////////////////////////////////////////////////////////////////
1:         Kind(int comparison, int comparedToClustering)
/////////////////////////////////////////////////////////////////////////
1:             Clustering clustering = Clustering.make(nextValues);
commit:5786b32
/////////////////////////////////////////////////////////////////////////
1:             int offset = 0;
1:             int clusteringSize = clustering.size();
1:             // serialize in batches of 32, to avoid garbage when deserializing headers
1:             while (offset < clusteringSize)
1:                 // we micro-batch the headers, so that we can incur fewer method calls,
1:                 // and generate no garbage on deserialization;
1:                 // we piggyback on vint encoding so that, typically, only 1 byte is used per 32 clustering values,
1:                 // i.e. more than we ever expect to see
1:                 int limit = Math.min(clusteringSize, offset + 32);
1:                 out.writeUnsignedVInt(makeHeader(clustering, offset, limit));
1:                 while (offset < limit)
0:                 {
1:                     ByteBuffer v = clustering.get(offset);
1:                     if (v != null && v.hasRemaining())
1:                         types.get(offset).writeValue(v, out);
1:                     offset++;
0:                 }
1:             long result = 0;
1:             int offset = 0;
1:             int clusteringSize = clustering.size();
1:             while (offset < clusteringSize)
0:             {
1:                 int limit = Math.min(clusteringSize, offset + 32);
1:                 result += TypeSizes.sizeofUnsignedVInt(makeHeader(clustering, offset, limit));
1:                 offset = limit;
0:             }
1:             for (int i = 0; i < clusteringSize; i++)
1:                 result += types.get(i).writtenLength(v);
1:             return result;
1:             int offset = 0;
1:             while (offset < size)
1:                 long header = in.readUnsignedVInt();
1:                 int limit = Math.min(size, offset + 32);
1:                 while (offset < limit)
0:                 {
1:                     values[offset] = isNull(header, offset)
0:                                 ? null
0:                                 : (isEmpty(header, offset) ? ByteBufferUtil.EMPTY_BYTE_BUFFER : types.get(offset).readValue(in));
1:                     offset++;
0:                 }
1:         private static long makeHeader(ClusteringPrefix clustering, int offset, int limit)
1:             long header = 0;
1:             for (int i = offset ; i < limit ; i++)
0:                 ByteBuffer v = clustering.get(i);
1:                 // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
0:                 if (v == null)
1:                     header |= (1L << (i * 2) + 1);
0:                 else if (!v.hasRemaining())
1:                     header |= (1L << (i * 2));
1:         // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
1:         private static boolean isNull(long header, int i)
1:             long mask = 1L << (i * 2) + 1;
1:             return (header & mask) != 0;
1:         // no need to do modulo arithmetic for i, since the left-shift execute on the modulus of RH operand by definition
1:         private static boolean isEmpty(long header, int i)
1:             long mask = 1L << (i * 2);
1:             return (header & mask) != 0;
/////////////////////////////////////////////////////////////////////////
1:         private long nextHeader;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             if ((deserializedSize % 32) == 0)
1:                 nextHeader = in.readUnsignedVInt();
0: 
/////////////////////////////////////////////////////////////////////////
1:                 if ((i % 32) == 0)
1:                     nextHeader = in.readUnsignedVInt();
1:             deserializedSize = nextSize;
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
1:         public long serializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types)
1:                 return 1 + Clustering.serializer.serializedSize((Clustering)clustering, version, types);
0:                 return Slice.Bound.serializer.serializedSize((Slice.Bound)clustering, version, types);
/////////////////////////////////////////////////////////////////////////
1:         long valuesWithoutSizeSerializedSize(ClusteringPrefix clustering, int version, List<AbstractType<?>> types)
/////////////////////////////////////////////////////////////////////////
0:                 size += types.get(i).writtenLength(v);
============================================================================
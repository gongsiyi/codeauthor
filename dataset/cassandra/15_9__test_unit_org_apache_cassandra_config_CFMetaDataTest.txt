1:31e3f61: /*
1:a991b64:  * Licensed to the Apache Software Foundation (ASF) under one
1:a991b64:  * or more contributor license agreements.  See the NOTICE file
1:a991b64:  * distributed with this work for additional information
1:a991b64:  * regarding copyright ownership.  The ASF licenses this file
1:a991b64:  * to you under the Apache License, Version 2.0 (the
1:a991b64:  * "License"); you may not use this file except in compliance
1:a991b64:  * with the License.  You may obtain a copy of the License at
1:a991b64:  *
1:a991b64:  *    http://www.apache.org/licenses/LICENSE-2.0
1:a991b64:  *
1:a991b64:  * Unless required by applicable law or agreed to in writing,
1:a991b64:  * software distributed under the License is distributed on an
1:a991b64:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:a991b64:  * KIND, either express or implied.  See the License for the
1:a991b64:  * specific language governing permissions and limitations
1:a991b64:  * under the License.
1:a991b64:  */
1:a991b64: package org.apache.cassandra.config;
1:dc85238: 
1:cf365e3: import java.util.*;
5:a991b64: 
1:a991b64: import org.apache.cassandra.SchemaLoader;
1:340df43: import org.apache.cassandra.cql3.QueryProcessor;
1:340df43: import org.apache.cassandra.cql3.UntypedResultSet;
1:340df43: import org.apache.cassandra.db.ColumnFamilyStore;
1:340df43: import org.apache.cassandra.db.Keyspace;
1:340df43: import org.apache.cassandra.db.Mutation;
1:93b3aa8: import org.apache.cassandra.db.marshal.*;
1:a991b64: import org.apache.cassandra.db.partitions.PartitionUpdate;
1:340df43: import org.apache.cassandra.db.rows.UnfilteredRowIterators;
1:a991b64: import org.apache.cassandra.exceptions.ConfigurationException;
1:93b3aa8: import org.apache.cassandra.schema.*;
1:a991b64: import org.apache.cassandra.thrift.CfDef;
1:a991b64: import org.apache.cassandra.thrift.ColumnDef;
1:a991b64: import org.apache.cassandra.thrift.IndexType;
1:a94b173: import org.apache.cassandra.thrift.ThriftConversion;
1:a991b64: import org.apache.cassandra.utils.ByteBufferUtil;
1:3e9d345: import org.apache.cassandra.utils.FBUtilities;
1:3e9d345: 
1:a991b64: import org.junit.BeforeClass;
1:a991b64: import org.junit.Test;
1:a991b64: 
1:a991b64: import static org.junit.Assert.assertEquals;
1:01d26dd: import static org.junit.Assert.assertFalse;
1:01d26dd: import static org.junit.Assert.assertTrue;
1:ccb0028: 
1:a991b64: public class CFMetaDataTest
2:a991b64: {
1:a991b64:     private static final String KEYSPACE1 = "CFMetaDataTest1";
1:a991b64:     private static final String CF_STANDARD1 = "Standard1";
1:a991b64: 
1:a991b64:     private static List<ColumnDef> columnDefs = new ArrayList<ColumnDef>();
1:a991b64: 
1:a991b64:     static
1:8a1b93d:     {
1:a991b64:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col1"), AsciiType.class.getCanonicalName())
1:a991b64:                                     .setIndex_name("col1Index")
1:a991b64:                                     .setIndex_type(IndexType.KEYS));
1:a991b64: 
1:a991b64:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col2"), UTF8Type.class.getCanonicalName())
1:a991b64:                                     .setIndex_name("col2Index")
1:a991b64:                                     .setIndex_type(IndexType.KEYS));
1:cf365e3: 
1:cf365e3:         Map<String, String> customIndexOptions = new HashMap<>();
1:cf365e3:         customIndexOptions.put("option1", "value1");
1:cf365e3:         customIndexOptions.put("option2", "value2");
1:cf365e3:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col3"), Int32Type.class.getCanonicalName())
1:cf365e3:                                     .setIndex_name("col3Index")
1:cf365e3:                                     .setIndex_type(IndexType.CUSTOM)
1:cf365e3:                                     .setIndex_options(customIndexOptions));
1:8a1b93d:     }
1:8a1b93d: 
1:a991b64:     @BeforeClass
1:a991b64:     public static void defineSchema() throws ConfigurationException
1:a991b64:     {
1:a991b64:         SchemaLoader.prepareServer();
1:a991b64:         SchemaLoader.createKeyspace(KEYSPACE1,
1:31e3f61:                                     KeyspaceParams.simple(1),
1:a991b64:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD1));
2:a991b64:     }
1:a991b64: 
1:a991b64:     @Test
1:6f5d8a5:     public void testThriftConversion() throws Exception
1:a991b64:     {
1:a991b64:         CfDef cfDef = new CfDef().setDefault_validation_class(AsciiType.class.getCanonicalName())
1:a991b64:                                  .setComment("Test comment")
1:a991b64:                                  .setColumn_metadata(columnDefs)
1:a991b64:                                  .setKeyspace(KEYSPACE1)
1:a991b64:                                  .setName(CF_STANDARD1);
1:a991b64: 
1:a991b64:         // convert Thrift to CFMetaData
1:a94b173:         CFMetaData cfMetaData = ThriftConversion.fromThrift(cfDef);
1:a991b64: 
1:a991b64:         CfDef thriftCfDef = new CfDef();
1:a991b64:         thriftCfDef.keyspace = KEYSPACE1;
1:a991b64:         thriftCfDef.name = CF_STANDARD1;
1:a991b64:         thriftCfDef.default_validation_class = cfDef.default_validation_class;
1:a991b64:         thriftCfDef.comment = cfDef.comment;
1:a94b173:         thriftCfDef.column_metadata = new ArrayList<>();
1:a991b64:         for (ColumnDef columnDef : columnDefs)
1:a991b64:         {
1:a991b64:             ColumnDef c = new ColumnDef();
1:a991b64:             c.name = ByteBufferUtil.clone(columnDef.name);
1:a991b64:             c.validation_class = columnDef.getValidation_class();
1:a991b64:             c.index_name = columnDef.getIndex_name();
1:cf365e3:             c.index_type = columnDef.getIndex_type();
1:cf365e3:             if (columnDef.isSetIndex_options())
1:cf365e3:                 c.setIndex_options(columnDef.getIndex_options());
1:a991b64:             thriftCfDef.column_metadata.add(c);
1:a991b64:         }
1:a991b64: 
1:a94b173:         CfDef converted = ThriftConversion.toThrift(cfMetaData);
1:a991b64: 
1:a991b64:         assertEquals(thriftCfDef.keyspace, converted.keyspace);
1:a991b64:         assertEquals(thriftCfDef.name, converted.name);
1:a991b64:         assertEquals(thriftCfDef.default_validation_class, converted.default_validation_class);
1:a991b64:         assertEquals(thriftCfDef.comment, converted.comment);
1:a991b64:         assertEquals(new HashSet<>(thriftCfDef.column_metadata), new HashSet<>(converted.column_metadata));
1:a991b64:     }
1:a991b64: 
1:a991b64:     @Test
1:a991b64:     public void testConversionsInverses() throws Exception
1:a991b64:     {
1:0e96e58:         for (String keyspaceName : Schema.instance.getNonSystemKeyspaces())
1:a991b64:         {
1:0e96e58:             for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())
1:a991b64:             {
1:a991b64:                 CFMetaData cfm = cfs.metadata;
1:a991b64:                 if (!cfm.isThriftCompatible())
1:a991b64:                     continue;
1:a991b64: 
1:a991b64:                 checkInverses(cfm);
1:a991b64: 
1:a991b64:                 // Testing with compression to catch #3558
1:69bfca0:                 CFMetaData withCompression = cfm.copy();
1:b31845c:                 withCompression.compression(CompressionParams.snappy(32768));
1:a991b64:                 checkInverses(withCompression);
1:a991b64:             }
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:a991b64:     private void checkInverses(CFMetaData cfm) throws Exception
1:a991b64:     {
1:a89597d:         KeyspaceMetadata keyspace = Schema.instance.getKSMetaData(cfm.ksName);
1:ccb0028: 
1:a991b64:         // Test thrift conversion
1:a991b64:         CFMetaData before = cfm;
1:a94b173:         CFMetaData after = ThriftConversion.fromThriftForUpdate(ThriftConversion.toThrift(before), before);
1:a991b64:         assert before.equals(after) : String.format("%n%s%n!=%n%s", before, after);
1:a991b64: 
1:a991b64:         // Test schema conversion
1:2683806:         Mutation rm = SchemaKeyspace.makeCreateTableMutation(keyspace, cfm, FBUtilities.timestampMicros()).build();
1:9797511:         PartitionUpdate cfU = rm.getPartitionUpdate(Schema.instance.getId(SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.TABLES));
1:9797511:         PartitionUpdate cdU = rm.getPartitionUpdate(Schema.instance.getId(SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.COLUMNS));
1:a991b64: 
1:9797511:         UntypedResultSet.Row tableRow = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.TABLES),
1:340df43:                                                                  UnfilteredRowIterators.filter(cfU.unfilteredIterator(), FBUtilities.nowInSeconds()))
1:340df43:                                                       .one();
1:340df43:         TableParams params = SchemaKeyspace.createTableParamsFromRow(tableRow);
1:340df43: 
1:9797511:         UntypedResultSet columnsRows = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.COLUMNS),
1:340df43:                                                                 UnfilteredRowIterators.filter(cdU.unfilteredIterator(), FBUtilities.nowInSeconds()));
1:340df43:         Set<ColumnDefinition> columns = new HashSet<>();
1:340df43:         for (UntypedResultSet.Row row : columnsRows)
1:340df43:             columns.add(SchemaKeyspace.createColumnFromRow(row, Types.none()));
1:340df43: 
1:340df43:         assertEquals(cfm.params, params);
1:340df43:         assertEquals(new HashSet<>(cfm.allColumns()), columns);
1:a991b64:     }
1:01d26dd:     
1:01d26dd:     @Test
1:01d26dd:     public void testIsNameValidPositive()
1:01d26dd:     {
1:01d26dd:          assertTrue(CFMetaData.isNameValid("abcdefghijklmnopqrstuvwxyz"));
1:01d26dd:          assertTrue(CFMetaData.isNameValid("ABCDEFGHIJKLMNOPQRSTUVWXYZ"));
1:01d26dd:          assertTrue(CFMetaData.isNameValid("_01234567890"));
1:01d26dd:     }
1:01d26dd:     
1:01d26dd:     @Test
1:01d26dd:     public void testIsNameValidNegative()
1:01d26dd:     {
1:01d26dd:         assertFalse(CFMetaData.isNameValid(null));
1:01d26dd:         assertFalse(CFMetaData.isNameValid(""));
1:01d26dd:         assertFalse(CFMetaData.isNameValid(" "));
1:01d26dd:         assertFalse(CFMetaData.isNameValid("@"));
1:01d26dd:         assertFalse(CFMetaData.isNameValid("!"));
1:01d26dd:     }
1:93b3aa8: 
1:93b3aa8:     private static Set<String> primitiveTypes = new HashSet<String>(Arrays.asList(new String[] { "ascii", "bigint", "blob", "boolean", "date",
1:bfd57d1:                                                                                                  "duration", "decimal", "double", "float",
1:bfd57d1:                                                                                                  "inet", "int", "smallint", "text", "time",
1:bfd57d1:                                                                                                  "timestamp", "timeuuid", "tinyint", "uuid",
1:bfd57d1:                                                                                                  "varchar", "varint" }));
1:93b3aa8: 
1:93b3aa8:     @Test
1:93b3aa8:     public void typeCompatibilityTest() throws Throwable
1:93b3aa8:     {
1:93b3aa8:         Map<String, Set<String>> compatibilityMap = new HashMap<>();
1:93b3aa8:         compatibilityMap.put("bigint", new HashSet<>(Arrays.asList(new String[] {"timestamp"})));
1:bfd57d1:         compatibilityMap.put("blob", new HashSet<>(Arrays.asList(new String[] {"ascii", "bigint", "boolean", "date", "decimal", "double", "duration",
1:93b3aa8:                                                                                "float", "inet", "int", "smallint", "text", "time", "timestamp",
1:93b3aa8:                                                                                "timeuuid", "tinyint", "uuid", "varchar", "varint"})));
1:93b3aa8:         compatibilityMap.put("date", new HashSet<>(Arrays.asList(new String[] {"int"})));
1:93b3aa8:         compatibilityMap.put("time", new HashSet<>(Arrays.asList(new String[] {"bigint"})));
1:93b3aa8:         compatibilityMap.put("text", new HashSet<>(Arrays.asList(new String[] {"ascii", "varchar"})));
1:93b3aa8:         compatibilityMap.put("timestamp", new HashSet<>(Arrays.asList(new String[] {"bigint"})));
1:93b3aa8:         compatibilityMap.put("varchar", new HashSet<>(Arrays.asList(new String[] {"ascii", "text"})));
1:93b3aa8:         compatibilityMap.put("varint", new HashSet<>(Arrays.asList(new String[] {"bigint", "int", "timestamp"})));
1:93b3aa8:         compatibilityMap.put("uuid", new HashSet<>(Arrays.asList(new String[] {"timeuuid"})));
1:93b3aa8: 
1:93b3aa8:         for (String sourceTypeString: primitiveTypes)
1:93b3aa8:         {
1:93b3aa8:             AbstractType sourceType = CQLTypeParser.parse("KEYSPACE", sourceTypeString, Types.none());
1:93b3aa8:             for (String destinationTypeString: primitiveTypes)
1:93b3aa8:             {
1:93b3aa8:                 AbstractType destinationType = CQLTypeParser.parse("KEYSPACE", destinationTypeString, Types.none());
1:93b3aa8: 
1:93b3aa8:                 if (compatibilityMap.get(destinationTypeString) != null &&
1:93b3aa8:                     compatibilityMap.get(destinationTypeString).contains(sourceTypeString) ||
1:93b3aa8:                     sourceTypeString.equals(destinationTypeString))
1:93b3aa8:                 {
1:93b3aa8:                     assertTrue(sourceTypeString + " should be compatible with " + destinationTypeString,
1:93b3aa8:                                destinationType.isValueCompatibleWith(sourceType));
1:93b3aa8:                 }
1:93b3aa8:                 else
1:93b3aa8:                 {
1:93b3aa8:                     assertFalse(sourceTypeString + " should not be compatible with " + destinationTypeString,
1:93b3aa8:                                 destinationType.isValueCompatibleWith(sourceType));
1:93b3aa8:                 }
1:93b3aa8:             }
1:93b3aa8:         }
1:93b3aa8:     }
1:93b3aa8: 
1:93b3aa8:     @Test
1:93b3aa8:     public void clusteringColumnTypeCompatibilityTest() throws Throwable
1:93b3aa8:     {
1:93b3aa8:         Map<String, Set<String>> compatibilityMap = new HashMap<>();
1:93b3aa8:         compatibilityMap.put("blob", new HashSet<>(Arrays.asList(new String[] {"ascii", "text", "varchar"})));
1:93b3aa8:         compatibilityMap.put("text", new HashSet<>(Arrays.asList(new String[] {"ascii", "varchar"})));
1:93b3aa8:         compatibilityMap.put("varchar", new HashSet<>(Arrays.asList(new String[] {"ascii", "text" })));
1:93b3aa8: 
1:93b3aa8:         for (String sourceTypeString: primitiveTypes)
1:93b3aa8:         {
1:93b3aa8:             AbstractType sourceType = CQLTypeParser.parse("KEYSPACE", sourceTypeString, Types.none());
1:93b3aa8:             for (String destinationTypeString: primitiveTypes)
1:93b3aa8:             {
1:93b3aa8:                 AbstractType destinationType = CQLTypeParser.parse("KEYSPACE", destinationTypeString, Types.none());
1:93b3aa8: 
1:93b3aa8:                 if (compatibilityMap.get(destinationTypeString) != null &&
1:93b3aa8:                     compatibilityMap.get(destinationTypeString).contains(sourceTypeString) ||
1:93b3aa8:                     sourceTypeString.equals(destinationTypeString))
1:93b3aa8:                 {
1:93b3aa8:                     assertTrue(sourceTypeString + " should be compatible with " + destinationTypeString,
1:93b3aa8:                                destinationType.isCompatibleWith(sourceType));
1:93b3aa8:                 }
1:93b3aa8:                 else
1:93b3aa8:                 {
1:93b3aa8:                     assertFalse(sourceTypeString + " should not be compatible with " + destinationTypeString,
1:93b3aa8:                                 destinationType.isCompatibleWith(sourceType));
1:93b3aa8:                 }
1:93b3aa8:             }
1:93b3aa8:         }
1:93b3aa8:     }
1:a991b64: }
============================================================================
author:Benjamin Lerer
-------------------------------------------------------------------------------
commit:bfd57d1
/////////////////////////////////////////////////////////////////////////
1:                                                                                                  "duration", "decimal", "double", "float",
1:                                                                                                  "inet", "int", "smallint", "text", "time",
1:                                                                                                  "timestamp", "timeuuid", "tinyint", "uuid",
1:                                                                                                  "varchar", "varint" }));
1:         compatibilityMap.put("blob", new HashSet<>(Arrays.asList(new String[] {"ascii", "bigint", "boolean", "date", "decimal", "double", "duration",
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1:         PartitionUpdate cfU = rm.getPartitionUpdate(Schema.instance.getId(SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.TABLES));
1:         PartitionUpdate cdU = rm.getPartitionUpdate(Schema.instance.getId(SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.COLUMNS));
1:         UntypedResultSet.Row tableRow = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.TABLES),
1:         UntypedResultSet columnsRows = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaConstants.SCHEMA_KEYSPACE_NAME, SchemaKeyspace.COLUMNS),
author:Josh McKenzie
-------------------------------------------------------------------------------
commit:2683806
/////////////////////////////////////////////////////////////////////////
1:         Mutation rm = SchemaKeyspace.makeCreateTableMutation(keyspace, cfm, FBUtilities.timestampMicros()).build();
author:Alex Petrov
-------------------------------------------------------------------------------
commit:93b3aa8
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.marshal.*;
1: import org.apache.cassandra.schema.*;
/////////////////////////////////////////////////////////////////////////
1: 
1:     private static Set<String> primitiveTypes = new HashSet<String>(Arrays.asList(new String[] { "ascii", "bigint", "blob", "boolean", "date",
0:                                                                                                  "decimal", "double", "float", "inet", "int",
0:                                                                                                  "smallint", "text", "time", "timestamp",
0:                                                                                                  "timeuuid", "tinyint", "uuid", "varchar",
0:                                                                                                  "varint" }));
1: 
1:     @Test
1:     public void typeCompatibilityTest() throws Throwable
1:     {
1:         Map<String, Set<String>> compatibilityMap = new HashMap<>();
1:         compatibilityMap.put("bigint", new HashSet<>(Arrays.asList(new String[] {"timestamp"})));
0:         compatibilityMap.put("blob", new HashSet<>(Arrays.asList(new String[] {"ascii", "bigint", "boolean", "date", "decimal", "double",
1:                                                                                "float", "inet", "int", "smallint", "text", "time", "timestamp",
1:                                                                                "timeuuid", "tinyint", "uuid", "varchar", "varint"})));
1:         compatibilityMap.put("date", new HashSet<>(Arrays.asList(new String[] {"int"})));
1:         compatibilityMap.put("time", new HashSet<>(Arrays.asList(new String[] {"bigint"})));
1:         compatibilityMap.put("text", new HashSet<>(Arrays.asList(new String[] {"ascii", "varchar"})));
1:         compatibilityMap.put("timestamp", new HashSet<>(Arrays.asList(new String[] {"bigint"})));
1:         compatibilityMap.put("varchar", new HashSet<>(Arrays.asList(new String[] {"ascii", "text"})));
1:         compatibilityMap.put("varint", new HashSet<>(Arrays.asList(new String[] {"bigint", "int", "timestamp"})));
1:         compatibilityMap.put("uuid", new HashSet<>(Arrays.asList(new String[] {"timeuuid"})));
1: 
1:         for (String sourceTypeString: primitiveTypes)
1:         {
1:             AbstractType sourceType = CQLTypeParser.parse("KEYSPACE", sourceTypeString, Types.none());
1:             for (String destinationTypeString: primitiveTypes)
1:             {
1:                 AbstractType destinationType = CQLTypeParser.parse("KEYSPACE", destinationTypeString, Types.none());
1: 
1:                 if (compatibilityMap.get(destinationTypeString) != null &&
1:                     compatibilityMap.get(destinationTypeString).contains(sourceTypeString) ||
1:                     sourceTypeString.equals(destinationTypeString))
1:                 {
1:                     assertTrue(sourceTypeString + " should be compatible with " + destinationTypeString,
1:                                destinationType.isValueCompatibleWith(sourceType));
1:                 }
1:                 else
1:                 {
1:                     assertFalse(sourceTypeString + " should not be compatible with " + destinationTypeString,
1:                                 destinationType.isValueCompatibleWith(sourceType));
1:                 }
1:             }
1:         }
1:     }
1: 
1:     @Test
1:     public void clusteringColumnTypeCompatibilityTest() throws Throwable
1:     {
1:         Map<String, Set<String>> compatibilityMap = new HashMap<>();
1:         compatibilityMap.put("blob", new HashSet<>(Arrays.asList(new String[] {"ascii", "text", "varchar"})));
1:         compatibilityMap.put("text", new HashSet<>(Arrays.asList(new String[] {"ascii", "varchar"})));
1:         compatibilityMap.put("varchar", new HashSet<>(Arrays.asList(new String[] {"ascii", "text" })));
1: 
1:         for (String sourceTypeString: primitiveTypes)
1:         {
1:             AbstractType sourceType = CQLTypeParser.parse("KEYSPACE", sourceTypeString, Types.none());
1:             for (String destinationTypeString: primitiveTypes)
1:             {
1:                 AbstractType destinationType = CQLTypeParser.parse("KEYSPACE", destinationTypeString, Types.none());
1: 
1:                 if (compatibilityMap.get(destinationTypeString) != null &&
1:                     compatibilityMap.get(destinationTypeString).contains(sourceTypeString) ||
1:                     sourceTypeString.equals(destinationTypeString))
1:                 {
1:                     assertTrue(sourceTypeString + " should be compatible with " + destinationTypeString,
1:                                destinationType.isCompatibleWith(sourceType));
1:                 }
1:                 else
1:                 {
1:                     assertFalse(sourceTypeString + " should not be compatible with " + destinationTypeString,
1:                                 destinationType.isCompatibleWith(sourceType));
1:                 }
1:             }
1:         }
1:     }
author:Alexander Shopov
-------------------------------------------------------------------------------
commit:01d26dd
/////////////////////////////////////////////////////////////////////////
1: import static org.junit.Assert.assertFalse;
1: import static org.junit.Assert.assertTrue;
/////////////////////////////////////////////////////////////////////////
1:     
1:     @Test
1:     public void testIsNameValidPositive()
1:     {
1:          assertTrue(CFMetaData.isNameValid("abcdefghijklmnopqrstuvwxyz"));
1:          assertTrue(CFMetaData.isNameValid("ABCDEFGHIJKLMNOPQRSTUVWXYZ"));
1:          assertTrue(CFMetaData.isNameValid("_01234567890"));
1:     }
1:     
1:     @Test
1:     public void testIsNameValidNegative()
1:     {
1:         assertFalse(CFMetaData.isNameValid(null));
1:         assertFalse(CFMetaData.isNameValid(""));
1:         assertFalse(CFMetaData.isNameValid(" "));
1:         assertFalse(CFMetaData.isNameValid("@"));
1:         assertFalse(CFMetaData.isNameValid("!"));
1:     }
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:340df43
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.cql3.QueryProcessor;
1: import org.apache.cassandra.cql3.UntypedResultSet;
1: import org.apache.cassandra.db.ColumnFamilyStore;
1: import org.apache.cassandra.db.Keyspace;
1: import org.apache.cassandra.db.Mutation;
1: import org.apache.cassandra.db.rows.UnfilteredRowIterators;
0: import org.apache.cassandra.schema.TableParams;
0: import org.apache.cassandra.schema.Types;
/////////////////////////////////////////////////////////////////////////
0:         UntypedResultSet.Row tableRow = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaKeyspace.NAME, SchemaKeyspace.TABLES),
1:                                                                  UnfilteredRowIterators.filter(cfU.unfilteredIterator(), FBUtilities.nowInSeconds()))
1:                                                       .one();
1:         TableParams params = SchemaKeyspace.createTableParamsFromRow(tableRow);
1: 
0:         UntypedResultSet columnsRows = QueryProcessor.resultify(String.format("SELECT * FROM %s.%s", SchemaKeyspace.NAME, SchemaKeyspace.COLUMNS),
1:                                                                 UnfilteredRowIterators.filter(cdU.unfilteredIterator(), FBUtilities.nowInSeconds()));
1:         Set<ColumnDefinition> columns = new HashSet<>();
1:         for (UntypedResultSet.Row row : columnsRows)
1:             columns.add(SchemaKeyspace.createColumnFromRow(row, Types.none()));
1: 
1:         assertEquals(cfm.params, params);
1:         assertEquals(new HashSet<>(cfm.allColumns()), columns);
commit:b31845c
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.schema.CompressionParams;
/////////////////////////////////////////////////////////////////////////
1:                 withCompression.compression(CompressionParams.snappy(32768));
commit:0a08525
/////////////////////////////////////////////////////////////////////////
commit:dc85238
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
commit:7d6c876
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.schema.SchemaKeyspace;
/////////////////////////////////////////////////////////////////////////
0:         Mutation rm = SchemaKeyspace.makeCreateTableMutation(keyspace, cfm, FBUtilities.timestampMicros());
0:         PartitionUpdate cfU = rm.getPartitionUpdate(Schema.instance.getId(SchemaKeyspace.NAME, SchemaKeyspace.TABLES));
0:         PartitionUpdate cdU = rm.getPartitionUpdate(Schema.instance.getId(SchemaKeyspace.NAME, SchemaKeyspace.COLUMNS));
0:         CFMetaData newCfm = SchemaKeyspace.createTableFromTablePartitionAndColumnsPartition(
commit:a89597d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.schema.KeyspaceMetadata;
/////////////////////////////////////////////////////////////////////////
1:         KeyspaceMetadata keyspace = Schema.instance.getKSMetaData(cfm.ksName);
commit:31e3f61
/////////////////////////////////////////////////////////////////////////
1: /*
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.schema.KeyspaceParams;
/////////////////////////////////////////////////////////////////////////
1:                                     KeyspaceParams.simple(1),
commit:3e9d345
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.schema.LegacySchemaTables;
1: import org.apache.cassandra.utils.FBUtilities;
1: 
/////////////////////////////////////////////////////////////////////////
0:         KSMetaData keyspace = Schema.instance.getKSMetaData(cfm.ksName);
/////////////////////////////////////////////////////////////////////////
0:         Mutation rm = LegacySchemaTables.makeCreateTableMutation(keyspace, cfm, FBUtilities.timestampMicros());
0:         ColumnFamily serializedCf = rm.getColumnFamily(Schema.instance.getId(SystemKeyspace.NAME, LegacySchemaTables.COLUMNFAMILIES));
0:         ColumnFamily serializedCD = rm.getColumnFamily(Schema.instance.getId(SystemKeyspace.NAME, LegacySchemaTables.COLUMNS));
0:         CFMetaData newCfm = LegacySchemaTables.createTableFromTablePartitionAndColumnsPartition(new Row(k, serializedCf), new Row(k, serializedCD));
commit:611d1ba
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamily serializedCf = rm.getColumnFamily(Schema.instance.getId(SystemKeyspace.NAME, SystemKeyspace.SCHEMA_COLUMNFAMILIES_TABLE));
0:         ColumnFamily serializedCD = rm.getColumnFamily(Schema.instance.getId(SystemKeyspace.NAME, SystemKeyspace.SCHEMA_COLUMNS_TABLE));
commit:a94b173
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.thrift.ThriftConversion;
/////////////////////////////////////////////////////////////////////////
1:         CFMetaData cfMetaData = ThriftConversion.fromThrift(cfDef);
1:         thriftCfDef.column_metadata = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:         CfDef converted = ThriftConversion.toThrift(cfMetaData);
/////////////////////////////////////////////////////////////////////////
1:         CFMetaData after = ThriftConversion.fromThriftForUpdate(ThriftConversion.toThrift(before), before);
commit:69bfca0
/////////////////////////////////////////////////////////////////////////
1:                 CFMetaData withCompression = cfm.copy();
commit:6bbb13b
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         Mutation rm = cfm.toSchema(System.currentTimeMillis());
commit:a965977
/////////////////////////////////////////////////////////////////////////
0:         CFMetaData newCfm = CFMetaData.addColumnDefinitionsFromSchema(CFMetaData.fromSchemaNoColumnsNoTriggers(result), new Row(k, serializedCD));
commit:0e96e58
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.*;
/////////////////////////////////////////////////////////////////////////
1:         for (String keyspaceName : Schema.instance.getNonSystemKeyspaces())
1:             for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamily serializedCf = rm.getColumnFamily(Schema.instance.getId(Keyspace.SYSTEM_KS, SystemKeyspace.SCHEMA_COLUMNFAMILIES_CF));
0:         ColumnFamily serializedCD = rm.getColumnFamily(Schema.instance.getId(Keyspace.SYSTEM_KS, SystemKeyspace.SCHEMA_COLUMNS_CF));
commit:6f5d8a5
/////////////////////////////////////////////////////////////////////////
1:     public void testThriftConversion() throws Exception
/////////////////////////////////////////////////////////////////////////
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:cf365e3
/////////////////////////////////////////////////////////////////////////
1: import java.util.*;
0: import org.apache.cassandra.db.marshal.Int32Type;
/////////////////////////////////////////////////////////////////////////
1: 
1:         Map<String, String> customIndexOptions = new HashMap<>();
1:         customIndexOptions.put("option1", "value1");
1:         customIndexOptions.put("option2", "value2");
1:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col3"), Int32Type.class.getCanonicalName())
1:                                     .setIndex_name("col3Index")
1:                                     .setIndex_type(IndexType.CUSTOM)
1:                                     .setIndex_options(customIndexOptions));
/////////////////////////////////////////////////////////////////////////
1:             c.index_type = columnDef.getIndex_type();
1:             if (columnDef.isSetIndex_options())
1:                 c.setIndex_options(columnDef.getIndex_options());
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:a22ce89
/////////////////////////////////////////////////////////////////////////
0:         DecoratedKey k = StorageService.getPartitioner().decorateKey(ByteBufferUtil.bytes(cfm.ksName));
commit:11dfc02
commit:8a1b93d
/////////////////////////////////////////////////////////////////////////
0: import java.nio.ByteBuffer;
0: import java.util.Map;
/////////////////////////////////////////////////////////////////////////
0:         // This is a nasty hack to work around the fact that non-null componentIndex 
0:         // are only used by CQL (so far) so we don't expose them through thrift
0:         // There is a CFM with componentIndex defined in Keyspace2 which is used by 
0:         // ColumnFamilyStoreTest to verify index repair (CASSANDRA-2897)
0:         for (Map.Entry<ByteBuffer, ColumnDefinition> cMeta: cfm.column_metadata.entrySet())
1:         {
0:             // Non-null componentIndex are only used by CQL (so far) so we don't expose
0:             // them through thrift
0:             if (cMeta.getValue().componentIndex != null)
0:                 cfm.column_metadata.remove(cMeta.getKey());
1:         }
1: 
commit:5c94432
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamily serializedCf = rm.getColumnFamily(Schema.instance.getId(Table.SYSTEM_KS, SystemTable.SCHEMA_COLUMNFAMILIES_CF));
0:         ColumnFamily serializedCD = rm.getColumnFamily(Schema.instance.getId(Table.SYSTEM_KS, SystemTable.SCHEMA_COLUMNS_CF));
commit:ccb0028
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.cql3.QueryProcessor;
0: import org.apache.cassandra.cql3.UntypedResultSet;
0: import org.apache.cassandra.db.DecoratedKey;
0: import org.apache.cassandra.db.Row;
0: import org.apache.cassandra.service.StorageService;
/////////////////////////////////////////////////////////////////////////
0: import java.util.Map;
0: import java.nio.ByteBuffer;
1: 
/////////////////////////////////////////////////////////////////////////
0:         DecoratedKey k = StorageService.getPartitioner().decorateKey(ByteBufferUtil.bytes(cfm.ksName));
1: 
/////////////////////////////////////////////////////////////////////////
0:         UntypedResultSet.Row result = QueryProcessor.resultify("SELECT * FROM system.schema_columnfamilies", new Row(k, serializedCf)).one();
0:         CFMetaData newCfm = CFMetaData.addColumnDefinitionSchema(CFMetaData.fromSchemaNoColumns(result), new Row(k, serializedCD));
0:         assert cfm.equals(newCfm) : String.format("\n%s\n!=\n%s", cfm, newCfm);
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:69f77cb
/////////////////////////////////////////////////////////////////////////
author:blerer
-------------------------------------------------------------------------------
commit:056115f
/////////////////////////////////////////////////////////////////////////
0:                 withCompression.compressionParameters(CompressionParameters.snappy(32768));
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:a991b64
/////////////////////////////////////////////////////////////////////////
0: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing,
1:  * software distributed under the License is distributed on an
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:  * KIND, either express or implied.  See the License for the
1:  * specific language governing permissions and limitations
1:  * under the License.
1:  */
1: package org.apache.cassandra.config;
1: 
0: import java.util.ArrayList;
0: import java.util.List;
0: import java.util.HashMap;
0: import java.util.HashSet;
1: 
1: import org.apache.cassandra.SchemaLoader;
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.db.marshal.AsciiType;
0: import org.apache.cassandra.db.marshal.UTF8Type;
0: import org.apache.cassandra.db.rows.UnfilteredRowIterators;
1: import org.apache.cassandra.db.partitions.PartitionUpdate;
1: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.io.compress.*;
0: import org.apache.cassandra.locator.SimpleStrategy;
0: import org.apache.cassandra.schema.LegacySchemaTables;
0: import org.apache.cassandra.service.StorageService;
1: import org.apache.cassandra.thrift.CfDef;
1: import org.apache.cassandra.thrift.ColumnDef;
1: import org.apache.cassandra.thrift.IndexType;
0: import org.apache.cassandra.thrift.ThriftConversion;
1: import org.apache.cassandra.utils.ByteBufferUtil;
0: import org.apache.cassandra.utils.FBUtilities;
1: 
1: import org.junit.BeforeClass;
1: import org.junit.Test;
1: 
1: import static org.junit.Assert.assertEquals;
1: 
1: public class CFMetaDataTest
1: {
1:     private static final String KEYSPACE1 = "CFMetaDataTest1";
1:     private static final String CF_STANDARD1 = "Standard1";
1: 
1:     private static List<ColumnDef> columnDefs = new ArrayList<ColumnDef>();
1: 
1:     static
1:     {
1:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col1"), AsciiType.class.getCanonicalName())
1:                                     .setIndex_name("col1Index")
1:                                     .setIndex_type(IndexType.KEYS));
1: 
1:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col2"), UTF8Type.class.getCanonicalName())
1:                                     .setIndex_name("col2Index")
1:                                     .setIndex_type(IndexType.KEYS));
1:     }
1: 
1:     @BeforeClass
1:     public static void defineSchema() throws ConfigurationException
1:     {
1:         SchemaLoader.prepareServer();
1:         SchemaLoader.createKeyspace(KEYSPACE1,
0:                                     SimpleStrategy.class,
0:                                     KSMetaData.optsWithRF(1),
1:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD1));
1:     }
1: 
1:     @Test
0:     public void testThriftConversion() throws Exception
1:     {
1:         CfDef cfDef = new CfDef().setDefault_validation_class(AsciiType.class.getCanonicalName())
1:                                  .setComment("Test comment")
1:                                  .setColumn_metadata(columnDefs)
1:                                  .setKeyspace(KEYSPACE1)
1:                                  .setName(CF_STANDARD1);
1: 
1:         // convert Thrift to CFMetaData
0:         CFMetaData cfMetaData = ThriftConversion.fromThrift(cfDef);
1: 
1:         CfDef thriftCfDef = new CfDef();
1:         thriftCfDef.keyspace = KEYSPACE1;
1:         thriftCfDef.name = CF_STANDARD1;
1:         thriftCfDef.default_validation_class = cfDef.default_validation_class;
1:         thriftCfDef.comment = cfDef.comment;
0:         thriftCfDef.column_metadata = new ArrayList<>();
1:         for (ColumnDef columnDef : columnDefs)
1:         {
1:             ColumnDef c = new ColumnDef();
1:             c.name = ByteBufferUtil.clone(columnDef.name);
1:             c.validation_class = columnDef.getValidation_class();
1:             c.index_name = columnDef.getIndex_name();
0:             c.index_type = IndexType.KEYS;
1:             thriftCfDef.column_metadata.add(c);
1:         }
1: 
0:         CfDef converted = ThriftConversion.toThrift(cfMetaData);
1: 
1:         assertEquals(thriftCfDef.keyspace, converted.keyspace);
1:         assertEquals(thriftCfDef.name, converted.name);
1:         assertEquals(thriftCfDef.default_validation_class, converted.default_validation_class);
1:         assertEquals(thriftCfDef.comment, converted.comment);
1:         assertEquals(new HashSet<>(thriftCfDef.column_metadata), new HashSet<>(converted.column_metadata));
1:     }
1: 
1:     @Test
1:     public void testConversionsInverses() throws Exception
1:     {
0:         for (String keyspaceName : Schema.instance.getNonSystemKeyspaces())
1:         {
0:             for (ColumnFamilyStore cfs : Keyspace.open(keyspaceName).getColumnFamilyStores())
1:             {
1:                 CFMetaData cfm = cfs.metadata;
1:                 if (!cfm.isThriftCompatible())
1:                     continue;
1: 
1:                 checkInverses(cfm);
1: 
1:                 // Testing with compression to catch #3558
0:                 CFMetaData withCompression = cfm.copy();
0:                 withCompression.compressionParameters(new CompressionParameters(SnappyCompressor.instance, 32768, new HashMap<String, String>()));
1:                 checkInverses(withCompression);
1:             }
1:         }
1:     }
1: 
1:     private void checkInverses(CFMetaData cfm) throws Exception
1:     {
0:         DecoratedKey k = StorageService.getPartitioner().decorateKey(ByteBufferUtil.bytes(cfm.ksName));
0:         KSMetaData keyspace = Schema.instance.getKSMetaData(cfm.ksName);
1: 
1:         // Test thrift conversion
1:         CFMetaData before = cfm;
0:         CFMetaData after = ThriftConversion.fromThriftForUpdate(ThriftConversion.toThrift(before), before);
1:         assert before.equals(after) : String.format("%n%s%n!=%n%s", before, after);
1: 
1:         // Test schema conversion
0:         Mutation rm = LegacySchemaTables.makeCreateTableMutation(keyspace, cfm, FBUtilities.timestampMicros());
0:         PartitionUpdate cfU = rm.getPartitionUpdate(Schema.instance.getId(SystemKeyspace.NAME, LegacySchemaTables.COLUMNFAMILIES));
0:         PartitionUpdate cdU = rm.getPartitionUpdate(Schema.instance.getId(SystemKeyspace.NAME, LegacySchemaTables.COLUMNS));
0:         CFMetaData newCfm = LegacySchemaTables.createTableFromTablePartitionAndColumnsPartition(
0:                 UnfilteredRowIterators.filter(cfU.unfilteredIterator(), FBUtilities.nowInSeconds()),
0:                 UnfilteredRowIterators.filter(cdU.unfilteredIterator(), FBUtilities.nowInSeconds())
0:         );
0:         assert cfm.equals(newCfm) : String.format("%n%s%n!=%n%s", cfm, newCfm);
1:     }
1: }
commit:2269adb
commit:b433722
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0: import java.util.HashSet;
/////////////////////////////////////////////////////////////////////////
0:         assertEquals(new HashSet<>(thriftCfDef.column_metadata), new HashSet<>(converted.column_metadata));
/////////////////////////////////////////////////////////////////////////
0:                 if (!cfm.isThriftCompatible())
0:                     continue;
0: 
/////////////////////////////////////////////////////////////////////////
0:         CFMetaData before = cfm;
0:         CFMetaData after = CFMetaData.fromThrift(before.toThrift());
/////////////////////////////////////////////////////////////////////////
0:         CFMetaData newCfm = CFMetaData.fromSchemaNoTriggers(result, ColumnDefinition.resultify(new Row(k, serializedCD)));
commit:67435b5
/////////////////////////////////////////////////////////////////////////
0: import java.util.Iterator;
/////////////////////////////////////////////////////////////////////////
0:     private static CFMetaData withoutThriftIncompatible(CFMetaData cfm)
0:     {
0:         CFMetaData result = cfm.clone();
0: 
0:         // This is a nasty hack to work around the fact that in thrift we exposes:
0:         //   - neither definition with a non-nulll componentIndex
0:         //   - nor non REGULAR definitions.
0:         Iterator<ColumnDefinition> iter = result.allColumns().iterator();
0:         while (iter.hasNext())
0:         {
0:             ColumnDefinition def = iter.next();
0:             // Remove what we know is not thrift compatible
0:             if (!def.isThriftCompatible())
0:                 iter.remove();
0:         }
0:         return result;
0:     }
0: 
0:         CFMetaData before = withoutThriftIncompatible(cfm);
0:         CFMetaData after = withoutThriftIncompatible(CFMetaData.fromThrift(before.toThrift()));
0:         assert before.equals(after) : String.format("\n%s\n!=\n%s", before, after);
commit:a950b92
/////////////////////////////////////////////////////////////////////////
0:         for (ColumnDefinition def: cfm.allColumns())
0:             // Remove what we know is not thrift compatible
0:             if (!def.isThriftCompatible())
0:                 cfm.removeColumnDefinition(def);
commit:438acfc
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.SchemaLoader;
/////////////////////////////////////////////////////////////////////////
0: public class CFMetaDataTest extends SchemaLoader
commit:86637d4
/////////////////////////////////////////////////////////////////////////
0: import java.util.HashMap;
0: import org.apache.cassandra.CleanupHelper;
0: import org.apache.cassandra.config.Schema;
0: import org.apache.cassandra.db.ColumnFamilyStore;
0: import org.apache.cassandra.db.ColumnFamily;
0: import org.apache.cassandra.db.RowMutation;
0: import org.apache.cassandra.db.SystemTable;
0: import org.apache.cassandra.db.Table;
0: import org.apache.cassandra.io.compress.*;
/////////////////////////////////////////////////////////////////////////
0: public class CFMetaDataTest extends CleanupHelper
/////////////////////////////////////////////////////////////////////////
0: 
0:     @Test
0:     public void testConversionsInverses() throws Exception
0:     {
0:         for (String table : Schema.instance.getNonSystemTables())
0:         {
0:             for (ColumnFamilyStore cfs : Table.open(table).getColumnFamilyStores())
0:             {
0:                 CFMetaData cfm = cfs.metadata;
0:                 checkInverses(cfm);
0: 
0:                 // Testing with compression to catch #3558
0:                 CFMetaData withCompression = CFMetaData.rename(cfm, cfm.cfName); // basically a clone
0:                 withCompression.compressionParameters(new CompressionParameters(SnappyCompressor.instance, 32768, new HashMap<String, String>()));
0:                 checkInverses(withCompression);
0:             }
0:         }
0:     }
0: 
0:     private void checkInverses(CFMetaData cfm) throws Exception
0:     {
0:         // Test thrift conversion
0:         assert cfm.equals(CFMetaData.fromThrift(cfm.toThrift())) : String.format("\n%s\n!=\n%s", cfm, CFMetaData.fromThrift(cfm.toThrift()));
0: 
0:         // Test schema conversion
0:         RowMutation rm = cfm.toSchema(System.currentTimeMillis());
0:         ColumnFamily serializedCf = rm.getColumnFamily(Schema.instance.getId(Table.SYSTEM_TABLE, SystemTable.SCHEMA_COLUMNFAMILIES_CF));
0:         ColumnFamily serializedCD = rm.getColumnFamily(Schema.instance.getId(Table.SYSTEM_TABLE, SystemTable.SCHEMA_COLUMNS_CF));
0:         CfDef cfDef = CFMetaData.addColumnDefinitionSchema(CFMetaData.fromSchema(serializedCf), serializedCD);
0:         assert cfm.equals(CFMetaData.fromThrift(cfDef)) : String.format("\n%s\n!=\n%s", cfm, CFMetaData.fromThrift(cfDef));
0:     }
author:lyubent
-------------------------------------------------------------------------------
commit:d2a3827
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.locator.SimpleStrategy;
0: import org.junit.BeforeClass;
0: public class CFMetaDataTest
0:     private static final String KEYSPACE1 = "CFMetaDataTest1";
0:     private static final String CF_STANDARD1 = "Standard1";
/////////////////////////////////////////////////////////////////////////
0:     @BeforeClass
0:     public static void defineSchema() throws ConfigurationException
0:     {
0:         SchemaLoader.prepareServer();
0:         SchemaLoader.createKeyspace(KEYSPACE1,
0:                                     SimpleStrategy.class,
0:                                     KSMetaData.optsWithRF(1),
0:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD1));
0:     }
0: 
0:                                  .setKeyspace(KEYSPACE1)
0:                                  .setName(CF_STANDARD1);
0:         thriftCfDef.keyspace = KEYSPACE1;
0:         thriftCfDef.name = CF_STANDARD1;
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:ea565aa
/////////////////////////////////////////////////////////////////////////
0:                 CFMetaData withCompression = cfm.clone();
author:Dave Brosius
-------------------------------------------------------------------------------
commit:6609029
/////////////////////////////////////////////////////////////////////////
0:         assert before.equals(after) : String.format("%n%s%n!=%n%s", before, after);
/////////////////////////////////////////////////////////////////////////
0:         assert cfm.equals(newCfm) : String.format("%n%s%n!=%n%s", cfm, newCfm);
commit:bc6b5f4
commit:f650d3e
/////////////////////////////////////////////////////////////////////////
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:37b0793
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         CfDef thriftCfDef = new CfDef();
0:         thriftCfDef.keyspace = KEYSPACE;
0:         thriftCfDef.name = COLUMN_FAMILY;
0:         thriftCfDef.default_validation_class = cfDef.default_validation_class;
0:         thriftCfDef.comment = cfDef.comment;
0:         thriftCfDef.column_metadata = new ArrayList<ColumnDef>();
0:             ColumnDef c = new ColumnDef();
0:             c.validation_class = columnDef.getValidation_class();
0:             c.index_name = columnDef.getIndex_name();
0:             c.index_type = IndexType.KEYS;
0:             thriftCfDef.column_metadata.add(c);
0:         CfDef converted = cfMetaData.toThrift();
0:         assertEquals(thriftCfDef.keyspace, converted.keyspace);
0:         assertEquals(thriftCfDef.name, converted.name);
0:         assertEquals(thriftCfDef.default_validation_class, converted.default_validation_class);
0:         assertEquals(thriftCfDef.comment, converted.comment);
0:         assertEquals(thriftCfDef.column_metadata, converted.column_metadata);
commit:38e3e85
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
0:  *
0:  *    http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
0:  */
0: package org.apache.cassandra.config;
0: 
0: import java.util.ArrayList;
0: import java.util.List;
0: 
0: import org.apache.avro.util.Utf8;
0: import org.apache.cassandra.db.marshal.AsciiType;
0: import org.apache.cassandra.db.marshal.UTF8Type;
0: import org.apache.cassandra.thrift.CfDef;
0: import org.apache.cassandra.thrift.ColumnDef;
0: import org.apache.cassandra.thrift.IndexType;
0: import org.apache.cassandra.utils.ByteBufferUtil;
0: 
0: import org.junit.Test;
0: 
0: import static org.junit.Assert.assertEquals;
0: 
0: public class CFMetaDataTest
0: {
0:     private static String KEYSPACE = "Keyspace1";
0:     private static String COLUMN_FAMILY = "Standard1";
0: 
0:     private static List<ColumnDef> columnDefs = new ArrayList<ColumnDef>();
0: 
0:     static
0:     {
0:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col1"), AsciiType.class.getCanonicalName())
0:                                     .setIndex_name("col1Index")
0:                                     .setIndex_type(IndexType.KEYS));
0: 
0:         columnDefs.add(new ColumnDef(ByteBufferUtil.bytes("col2"), UTF8Type.class.getCanonicalName())
0:                                     .setIndex_name("col2Index")
0:                                     .setIndex_type(IndexType.KEYS));
0:     }
0: 
0:     @Test
0:     public void testThriftToAvroConversion() throws Exception
0:     {
0:         CfDef cfDef = new CfDef().setDefault_validation_class(AsciiType.class.getCanonicalName())
0:                                  .setComment("Test comment")
0:                                  .setColumn_metadata(columnDefs)
0:                                  .setKeyspace(KEYSPACE)
0:                                  .setName(COLUMN_FAMILY);
0: 
0:         // convert Thrift to CFMetaData
0:         CFMetaData cfMetaData = CFMetaData.fromThrift(cfDef);
0: 
0:         // make a correct Avro object
0:         org.apache.cassandra.db.migration.avro.CfDef avroCfDef = new org.apache.cassandra.db.migration.avro.CfDef();
0:         avroCfDef.keyspace = new Utf8(KEYSPACE);
0:         avroCfDef.name = new Utf8(COLUMN_FAMILY);
0:         avroCfDef.default_validation_class = new Utf8(cfDef.default_validation_class);
0:         avroCfDef.comment = new Utf8(cfDef.comment);
0:         avroCfDef.column_metadata = new ArrayList<org.apache.cassandra.db.migration.avro.ColumnDef>();
0:         for (ColumnDef columnDef : columnDefs)
0:         {
0:             org.apache.cassandra.db.migration.avro.ColumnDef c = new org.apache.cassandra.db.migration.avro.ColumnDef();
0:             c.name = ByteBufferUtil.clone(columnDef.name);
0:             c.validation_class = new Utf8(columnDef.getValidation_class());
0:             c.index_name = new Utf8(columnDef.getIndex_name());
0:             c.index_type = org.apache.cassandra.db.migration.avro.IndexType.KEYS;
0:             avroCfDef.column_metadata.add(c);
0:         }
0: 
0:         org.apache.cassandra.db.migration.avro.CfDef converted = cfMetaData.toAvro();
0: 
0:         assertEquals(avroCfDef.keyspace, converted.keyspace);
0:         assertEquals(avroCfDef.name, converted.name);
0:         assertEquals(avroCfDef.default_validation_class, converted.default_validation_class);
0:         assertEquals(avroCfDef.comment, converted.comment);
0:         assertEquals(avroCfDef.column_metadata, converted.column_metadata);
0:     }
0: }
============================================================================
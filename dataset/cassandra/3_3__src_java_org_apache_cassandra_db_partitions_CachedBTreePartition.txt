1:a991b64: /*
1:a991b64:  * Licensed to the Apache Software Foundation (ASF) under one
1:a991b64:  * or more contributor license agreements.  See the NOTICE file
1:a991b64:  * distributed with this work for additional information
1:a991b64:  * regarding copyright ownership.  The ASF licenses this file
1:a991b64:  * to you under the Apache License, Version 2.0 (the
1:a991b64:  * "License"); you may not use this file except in compliance
1:a991b64:  * with the License.  You may obtain a copy of the License at
1:a991b64:  *
1:a991b64:  *     http://www.apache.org/licenses/LICENSE-2.0
1:a991b64:  *
1:a991b64:  * Unless required by applicable law or agreed to in writing, software
1:a991b64:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a991b64:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a991b64:  * See the License for the specific language governing permissions and
1:a991b64:  * limitations under the License.
1:a991b64:  */
1:a991b64: package org.apache.cassandra.db.partitions;
19:a991b64: 
1:a991b64: import java.io.IOException;
1:a991b64: 
1:a991b64: import org.apache.cassandra.config.CFMetaData;
1:a991b64: import org.apache.cassandra.db.*;
1:2457599: import org.apache.cassandra.db.filter.DataLimits;
1:a991b64: import org.apache.cassandra.db.rows.*;
1:a991b64: import org.apache.cassandra.io.ISerializer;
1:03f72ac: import org.apache.cassandra.io.util.DataInputPlus;
1:a991b64: import org.apache.cassandra.io.util.DataOutputPlus;
1:a991b64: import org.apache.cassandra.net.MessagingService;
1:e51f83b: import org.apache.cassandra.utils.btree.BTree;
1:a991b64: 
1:e51f83b: public class CachedBTreePartition extends ImmutableBTreePartition implements CachedPartition
1:2457599: {
1:a991b64:     private final int createdAtInSec;
1:2457599: 
1:2457599:     private final int cachedLiveRows;
1:2457599:     private final int rowsWithNonExpiringCells;
1:a991b64: 
1:2457599:     private final int nonTombstoneCellCount;
1:2457599:     private final int nonExpiringLiveCells;
1:a991b64: 
1:e51f83b:     private CachedBTreePartition(CFMetaData metadata,
1:e51f83b:                                  DecoratedKey partitionKey,
1:e51f83b:                                  Holder holder,
1:e51f83b:                                  int createdAtInSec,
1:e51f83b:                                  int cachedLiveRows,
1:e51f83b:                                  int rowsWithNonExpiringCells,
1:e51f83b:                                  int nonTombstoneCellCount,
1:e51f83b:                                  int nonExpiringLiveCells)
12:a991b64:     {
1:c3bc856:         super(metadata, partitionKey, holder);
1:a991b64:         this.createdAtInSec = createdAtInSec;
1:2457599:         this.cachedLiveRows = cachedLiveRows;
1:2457599:         this.rowsWithNonExpiringCells = rowsWithNonExpiringCells;
1:2457599:         this.nonTombstoneCellCount = nonTombstoneCellCount;
1:2457599:         this.nonExpiringLiveCells = nonExpiringLiveCells;
12:a991b64:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Creates an {@code ArrayBackedCachedPartition} holding all the data of the provided iterator.
1:a991b64:      *
1:a991b64:      * Warning: Note that this method does not close the provided iterator and it is
1:a991b64:      * up to the caller to do so.
1:a991b64:      *
1:a991b64:      * @param iterator the iterator got gather in memory.
1:a991b64:      * @param nowInSec the time of the creation in seconds. This is the time at which {@link #cachedLiveRows} applies.
1:a991b64:      * @return the created partition.
1:a991b64:      */
1:e51f83b:     public static CachedBTreePartition create(UnfilteredRowIterator iterator, int nowInSec)
1:a991b64:     {
1:2457599:         return create(iterator, 16, nowInSec);
1:a991b64:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Creates an {@code ArrayBackedCachedPartition} holding all the data of the provided iterator.
1:a991b64:      *
1:a991b64:      * Warning: Note that this method does not close the provided iterator and it is
1:a991b64:      * up to the caller to do so.
1:a991b64:      *
1:a991b64:      * @param iterator the iterator got gather in memory.
1:a991b64:      * @param initialRowCapacity sizing hint (in rows) to use for the created partition. It should ideally
1:a991b64:      * correspond or be a good estimation of the number or rows in {@code iterator}.
1:a991b64:      * @param nowInSec the time of the creation in seconds. This is the time at which {@link #cachedLiveRows} applies.
1:a991b64:      * @return the created partition.
1:a991b64:      */
1:e51f83b:     public static CachedBTreePartition create(UnfilteredRowIterator iterator, int initialRowCapacity, int nowInSec)
1:a991b64:     {
1:e51f83b:         Holder holder = ImmutableBTreePartition.build(iterator, initialRowCapacity);
1:a991b64: 
1:2457599:         int cachedLiveRows = 0;
1:2457599:         int rowsWithNonExpiringCells = 0;
1:2457599:         int nonTombstoneCellCount = 0;
1:2457599:         int nonExpiringLiveCells = 0;
1:2457599: 
1:e51f83b:         for (Row row : BTree.<Row>iterable(holder.tree))
1:2457599:         {
1:e51f83b:             if (row.hasLiveData(nowInSec))
1:e51f83b:                 ++cachedLiveRows;
1:e51f83b: 
1:e51f83b:             int nonExpiringLiveCellsThisRow = 0;
1:e51f83b:             for (Cell cell : row.cells())
1:2457599:             {
1:e51f83b:                 if (!cell.isTombstone())
1:2457599:                 {
1:e51f83b:                     ++nonTombstoneCellCount;
1:e51f83b:                     if (!cell.isExpiring())
1:e51f83b:                         ++nonExpiringLiveCellsThisRow;
1:2457599:                 }
1:2457599:             }
1:e51f83b: 
1:e51f83b:             if (nonExpiringLiveCellsThisRow > 0)
1:2457599:             {
1:e51f83b:                 ++rowsWithNonExpiringCells;
1:e51f83b:                 nonExpiringLiveCells += nonExpiringLiveCellsThisRow;
1:2457599:             }
1:2457599:         }
1:2457599: 
1:e51f83b:         return new CachedBTreePartition(iterator.metadata(),
1:e51f83b:                                         iterator.partitionKey(),
1:e51f83b:                                         holder,
1:e51f83b:                                         nowInSec,
1:e51f83b:                                         cachedLiveRows,
1:e51f83b:                                         rowsWithNonExpiringCells,
1:e51f83b:                                         nonTombstoneCellCount,
1:e51f83b:                                         nonExpiringLiveCells);
1:2457599:     }
1:2457599: 
1:a991b64:     /**
1:a991b64:      * The number of rows that were live at the time the partition was cached.
1:a991b64:      *
1:a991b64:      * See {@link ColumnFamilyStore#isFilterFullyCoveredBy} to see why we need this.
1:a991b64:      *
1:a991b64:      * @return the number of rows in this partition that were live at the time the
1:a991b64:      * partition was cached (this can be different from the number of live rows now
1:a991b64:      * due to expiring cells).
1:a991b64:      */
1:a991b64:     public int cachedLiveRows()
1:2457599:     {
1:a991b64:         return cachedLiveRows;
1:2457599:     }
1:2457599: 
1:a991b64:     /**
1:a991b64:      * The number of rows in this cached partition that have at least one non-expiring
1:a991b64:      * non-deleted cell.
1:a991b64:      *
1:a991b64:      * Note that this is generally not a very meaningful number, but this is used by
1:a991b64:      * {@link DataLimits#hasEnoughLiveData} as an optimization.
1:a991b64:      *
1:a991b64:      * @return the number of row that have at least one non-expiring non-deleted cell.
1:a991b64:      */
1:a991b64:     public int rowsWithNonExpiringCells()
1:2457599:     {
1:a991b64:         return rowsWithNonExpiringCells;
1:a991b64:     }
1:a991b64: 
1:a991b64:     public int nonTombstoneCellCount()
1:a991b64:     {
1:a991b64:         return nonTombstoneCellCount;
1:a991b64:     }
1:a991b64: 
1:a991b64:     public int nonExpiringLiveCells()
1:a991b64:     {
1:a991b64:         return nonExpiringLiveCells;
1:a991b64:     }
1:a991b64: 
1:a991b64:     static class Serializer implements ISerializer<CachedPartition>
1:a991b64:     {
1:a991b64:         public void serialize(CachedPartition partition, DataOutputPlus out) throws IOException
1:a991b64:         {
1:8a97969:             int version = MessagingService.current_version;
1:8a97969: 
1:e51f83b:             assert partition instanceof CachedBTreePartition;
1:e51f83b:             CachedBTreePartition p = (CachedBTreePartition)partition;
1:a991b64: 
1:a991b64:             out.writeInt(p.createdAtInSec);
1:2457599:             out.writeInt(p.cachedLiveRows);
1:2457599:             out.writeInt(p.rowsWithNonExpiringCells);
1:2457599:             out.writeInt(p.nonTombstoneCellCount);
1:2457599:             out.writeInt(p.nonExpiringLiveCells);
1:8a97969:             CFMetaData.serializer.serialize(partition.metadata(), out, version);
1:e51f83b:             try (UnfilteredRowIterator iter = p.unfilteredIterator())
1:a991b64:             {
1:fe388d4:                 UnfilteredRowIteratorSerializer.serializer.serialize(iter, null, out, version, p.rowCount());
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:03f72ac:         public CachedPartition deserialize(DataInputPlus in) throws IOException
1:a991b64:         {
1:8a97969:             int version = MessagingService.current_version;
1:8a97969: 
1:a991b64:             // Note that it would be slightly simpler to just do
1:a991b64:             //   ArrayBackedCachedPiartition.create(UnfilteredRowIteratorSerializer.serializer.deserialize(...));
1:a991b64:             // However deserializing the header separatly is not a lot harder and allows us to:
1:a991b64:             //   1) get the capacity of the partition so we can size it properly directly
1:a991b64:             //   2) saves the creation of a temporary iterator: rows are directly written to the partition, which
1:a991b64:             //      is slightly faster.
1:a991b64: 
1:a991b64:             int createdAtInSec = in.readInt();
1:2457599:             int cachedLiveRows = in.readInt();
1:2457599:             int rowsWithNonExpiringCells = in.readInt();
1:2457599:             int nonTombstoneCellCount = in.readInt();
1:2457599:             int nonExpiringLiveCells = in.readInt();
1:e51f83b: 
1:a991b64: 
1:8a97969:             CFMetaData metadata = CFMetaData.serializer.deserialize(in, version);
1:fe388d4:             UnfilteredRowIteratorSerializer.Header header = UnfilteredRowIteratorSerializer.serializer.deserializeHeader(metadata, null, in, version, SerializationHelper.Flag.LOCAL);
1:2457599:             assert !header.isReversed && header.rowEstimate >= 0;
1:a991b64: 
1:e51f83b:             Holder holder;
1:8a97969:             try (UnfilteredRowIterator partition = UnfilteredRowIteratorSerializer.serializer.deserialize(in, version, metadata, SerializationHelper.Flag.LOCAL, header))
1:2457599:             {
1:e51f83b:                 holder = ImmutableBTreePartition.build(partition, header.rowEstimate);
1:2457599:             }
1:a991b64: 
1:e51f83b:             return new CachedBTreePartition(metadata,
1:2457599:                                                   header.key,
1:e51f83b:                                                   holder,
1:2457599:                                                   createdAtInSec,
1:2457599:                                                   cachedLiveRows,
1:2457599:                                                   rowsWithNonExpiringCells,
1:2457599:                                                   nonTombstoneCellCount,
1:2457599:                                                   nonExpiringLiveCells);
1:2457599: 
1:2457599:         }
1:a991b64: 
1:03f72ac:         public long serializedSize(CachedPartition partition)
1:a991b64:         {
1:8a97969:             int version = MessagingService.current_version;
1:8a97969: 
1:e51f83b:             assert partition instanceof CachedBTreePartition;
1:e51f83b:             CachedBTreePartition p = (CachedBTreePartition)partition;
1:a991b64: 
1:e51f83b:             try (UnfilteredRowIterator iter = p.unfilteredIterator())
1:a991b64:             {
1:03f72ac:                 return TypeSizes.sizeof(p.createdAtInSec)
1:2457599:                      + TypeSizes.sizeof(p.cachedLiveRows)
1:2457599:                      + TypeSizes.sizeof(p.rowsWithNonExpiringCells)
1:2457599:                      + TypeSizes.sizeof(p.nonTombstoneCellCount)
1:2457599:                      + TypeSizes.sizeof(p.nonExpiringLiveCells)
1:8a97969:                      + CFMetaData.serializer.serializedSize(partition.metadata(), version)
1:fe388d4:                      + UnfilteredRowIteratorSerializer.serializer.serializedSize(iter, null, MessagingService.current_version, p.rowCount());
1:a991b64:             }
1:a991b64:         }
1:a991b64:     }
1:a991b64: }
1:a991b64: 
============================================================================
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:c3bc856
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         super(metadata, partitionKey, holder);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:520089b
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         super(metadata, partitionKey, holder);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:e51f83b
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.btree.BTree;
1: public class CachedBTreePartition extends ImmutableBTreePartition implements CachedPartition
/////////////////////////////////////////////////////////////////////////
1:     private CachedBTreePartition(CFMetaData metadata,
1:                                  DecoratedKey partitionKey,
0:                                  PartitionColumns columns,
1:                                  Holder holder,
1:                                  int createdAtInSec,
1:                                  int cachedLiveRows,
1:                                  int rowsWithNonExpiringCells,
1:                                  int nonTombstoneCellCount,
1:                                  int nonExpiringLiveCells)
0:         super(metadata, partitionKey, columns, holder);
/////////////////////////////////////////////////////////////////////////
1:     public static CachedBTreePartition create(UnfilteredRowIterator iterator, int nowInSec)
/////////////////////////////////////////////////////////////////////////
1:     public static CachedBTreePartition create(UnfilteredRowIterator iterator, int initialRowCapacity, int nowInSec)
1:         Holder holder = ImmutableBTreePartition.build(iterator, initialRowCapacity);
1:         for (Row row : BTree.<Row>iterable(holder.tree))
1:             if (row.hasLiveData(nowInSec))
1:                 ++cachedLiveRows;
1: 
1:             int nonExpiringLiveCellsThisRow = 0;
1:             for (Cell cell : row.cells())
1:                 if (!cell.isTombstone())
1:                     ++nonTombstoneCellCount;
1:                     if (!cell.isExpiring())
1:                         ++nonExpiringLiveCellsThisRow;
1: 
1:             if (nonExpiringLiveCellsThisRow > 0)
1:                 ++rowsWithNonExpiringCells;
1:                 nonExpiringLiveCells += nonExpiringLiveCellsThisRow;
1:         return new CachedBTreePartition(iterator.metadata(),
1:                                         iterator.partitionKey(),
0:                                         iterator.columns(),
1:                                         holder,
1:                                         nowInSec,
1:                                         cachedLiveRows,
1:                                         rowsWithNonExpiringCells,
1:                                         nonTombstoneCellCount,
1:                                         nonExpiringLiveCells);
/////////////////////////////////////////////////////////////////////////
1:             assert partition instanceof CachedBTreePartition;
1:             CachedBTreePartition p = (CachedBTreePartition)partition;
/////////////////////////////////////////////////////////////////////////
1:             try (UnfilteredRowIterator iter = p.unfilteredIterator())
/////////////////////////////////////////////////////////////////////////
1: 
1:             Holder holder;
1:                 holder = ImmutableBTreePartition.build(partition, header.rowEstimate);
1:             return new CachedBTreePartition(metadata,
1:                                                   holder,
/////////////////////////////////////////////////////////////////////////
1:             assert partition instanceof CachedBTreePartition;
1:             CachedBTreePartition p = (CachedBTreePartition)partition;
1:             try (UnfilteredRowIterator iter = p.unfilteredIterator())
commit:fe388d4
/////////////////////////////////////////////////////////////////////////
1:                 UnfilteredRowIteratorSerializer.serializer.serialize(iter, null, out, version, p.rowCount());
/////////////////////////////////////////////////////////////////////////
1:             UnfilteredRowIteratorSerializer.Header header = UnfilteredRowIteratorSerializer.serializer.deserializeHeader(metadata, null, in, version, SerializationHelper.Flag.LOCAL);
/////////////////////////////////////////////////////////////////////////
1:                      + UnfilteredRowIteratorSerializer.serializer.serializedSize(iter, null, MessagingService.current_version, p.rowCount());
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:c055ab9
/////////////////////////////////////////////////////////////////////////
0:                                        EncodingStats stats,
commit:8a97969
/////////////////////////////////////////////////////////////////////////
1:             int version = MessagingService.current_version;
1: 
/////////////////////////////////////////////////////////////////////////
1:             CFMetaData.serializer.serialize(partition.metadata(), out, version);
0:                 UnfilteredRowIteratorSerializer.serializer.serialize(iter, out, version, p.rowCount());
1:             int version = MessagingService.current_version;
1: 
/////////////////////////////////////////////////////////////////////////
1:             CFMetaData metadata = CFMetaData.serializer.deserialize(in, version);
0:             UnfilteredRowIteratorSerializer.Header header = UnfilteredRowIteratorSerializer.serializer.deserializeHeader(in, version, metadata, SerializationHelper.Flag.LOCAL);
0:             MutableDeletionInfo.Builder deletionBuilder = MutableDeletionInfo.builder(header.partitionDeletion, metadata.comparator, false);
1:             try (UnfilteredRowIterator partition = UnfilteredRowIteratorSerializer.serializer.deserialize(in, version, metadata, SerializationHelper.Flag.LOCAL, header))
/////////////////////////////////////////////////////////////////////////
0:             return new ArrayBackedCachedPartition(metadata,
/////////////////////////////////////////////////////////////////////////
1:             int version = MessagingService.current_version;
1: 
/////////////////////////////////////////////////////////////////////////
1:                      + CFMetaData.serializer.serializedSize(partition.metadata(), version)
commit:2457599
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
1: import org.apache.cassandra.db.filter.DataLimits;
/////////////////////////////////////////////////////////////////////////
1:     private final int cachedLiveRows;
1:     private final int rowsWithNonExpiringCells;
1:     private final int nonTombstoneCellCount;
1:     private final int nonExpiringLiveCells;
0:                                        Row staticRow,
0:                                        List<Row> rows,
0:                                        DeletionInfo deletionInfo,
0:                                        RowStats stats,
0:                                        int createdAtInSec,
0:                                        int cachedLiveRows,
0:                                        int rowsWithNonExpiringCells,
0:                                        int nonTombstoneCellCount,
0:                                        int nonExpiringLiveCells)
0:         super(metadata, partitionKey, columns, staticRow, rows, deletionInfo, stats);
1:         this.cachedLiveRows = cachedLiveRows;
1:         this.rowsWithNonExpiringCells = rowsWithNonExpiringCells;
1:         this.nonTombstoneCellCount = nonTombstoneCellCount;
1:         this.nonExpiringLiveCells = nonExpiringLiveCells;
/////////////////////////////////////////////////////////////////////////
1:         return create(iterator, 16, nowInSec);
/////////////////////////////////////////////////////////////////////////
0:         CFMetaData metadata = iterator.metadata();
0:         boolean reversed = iterator.isReverseOrder();
0:         List<Row> rows = new ArrayList<>(initialRowCapacity);
0:         MutableDeletionInfo.Builder deletionBuilder = MutableDeletionInfo.builder(iterator.partitionLevelDeletion(), metadata.comparator, reversed);
1:         int cachedLiveRows = 0;
1:         int rowsWithNonExpiringCells = 0;
1:         int nonTombstoneCellCount = 0;
1:         int nonExpiringLiveCells = 0;
0:         while (iterator.hasNext())
1:         {
0:             Unfiltered unfiltered = iterator.next();
0:             if (unfiltered.kind() == Unfiltered.Kind.ROW)
1:             {
0:                 Row row = (Row)unfiltered;
0:                 rows.add(row);
1: 
0:                 // Collect stats
0:                 if (row.hasLiveData(nowInSec))
0:                     ++cachedLiveRows;
1: 
0:                 boolean hasNonExpiringCell = false;
0:                 for (Cell cell : row.cells())
1:                 {
0:                     if (!cell.isTombstone())
1:                     {
0:                         ++nonTombstoneCellCount;
0:                         if (!cell.isExpiring())
1:                         {
0:                             hasNonExpiringCell = true;
0:                             ++nonExpiringLiveCells;
1:                         }
1:                     }
1:                 }
1: 
0:                 if (hasNonExpiringCell)
0:                     ++rowsWithNonExpiringCells;
1:             }
0:             else
1:             {
0:                 deletionBuilder.add((RangeTombstoneMarker)unfiltered);
1:             }
1:         }
1: 
0:         if (reversed)
0:             Collections.reverse(rows);
1: 
0:         return new ArrayBackedCachedPartition(metadata,
0:                                               iterator.partitionKey(),
0:                                               iterator.columns(),
0:                                               iterator.staticRow(),
0:                                               rows,
0:                                               deletionBuilder.build(),
0:                                               iterator.stats(),
0:                                               nowInSec,
1:                                               cachedLiveRows,
1:                                               rowsWithNonExpiringCells,
1:                                               nonTombstoneCellCount,
1:                                               nonExpiringLiveCells);
0:         if (rows.isEmpty())
0:         return rows.get(rows.size() - 1);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             out.writeInt(p.cachedLiveRows);
1:             out.writeInt(p.rowsWithNonExpiringCells);
1:             out.writeInt(p.nonTombstoneCellCount);
1:             out.writeInt(p.nonExpiringLiveCells);
0:                 UnfilteredRowIteratorSerializer.serializer.serialize(iter, out, MessagingService.current_version, p.rowCount());
/////////////////////////////////////////////////////////////////////////
1:             int cachedLiveRows = in.readInt();
1:             int rowsWithNonExpiringCells = in.readInt();
1:             int nonTombstoneCellCount = in.readInt();
1:             int nonExpiringLiveCells = in.readInt();
0:             UnfilteredRowIteratorSerializer.Header header = UnfilteredRowIteratorSerializer.serializer.deserializeHeader(in, MessagingService.current_version, SerializationHelper.Flag.LOCAL);
1:             assert !header.isReversed && header.rowEstimate >= 0;
0:             MutableDeletionInfo.Builder deletionBuilder = MutableDeletionInfo.builder(header.partitionDeletion, header.metadata.comparator, false);
0:             List<Row> rows = new ArrayList<>(header.rowEstimate);
0:             try (UnfilteredRowIterator partition = UnfilteredRowIteratorSerializer.serializer.deserialize(in, MessagingService.current_version, SerializationHelper.Flag.LOCAL, header))
1:             {
0:                 while (partition.hasNext())
1:                 {
0:                     Unfiltered unfiltered = partition.next();
0:                     if (unfiltered.kind() == Unfiltered.Kind.ROW)
0:                         rows.add((Row)unfiltered);
0:                     else
0:                         deletionBuilder.add((RangeTombstoneMarker)unfiltered);
1:                 }
1:             }
0:             return new ArrayBackedCachedPartition(header.metadata,
1:                                                   header.key,
0:                                                   header.sHeader.columns(),
0:                                                   header.staticRow,
0:                                                   rows,
0:                                                   deletionBuilder.build(),
0:                                                   header.sHeader.stats(),
1:                                                   createdAtInSec,
0:                                                   cachedLiveRows,
0:                                                   rowsWithNonExpiringCells,
0:                                                   nonTombstoneCellCount,
0:                                                   nonExpiringLiveCells);
1: 
/////////////////////////////////////////////////////////////////////////
1:                      + TypeSizes.sizeof(p.cachedLiveRows)
1:                      + TypeSizes.sizeof(p.rowsWithNonExpiringCells)
1:                      + TypeSizes.sizeof(p.nonTombstoneCellCount)
1:                      + TypeSizes.sizeof(p.nonExpiringLiveCells)
0:                      + UnfilteredRowIteratorSerializer.serializer.serializedSize(iter, MessagingService.current_version, p.rowCount());
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.db.partitions;
1: 
0: import java.io.DataInput;
1: import java.io.IOException;
0: import java.nio.ByteBuffer;
1: 
1: import org.apache.cassandra.config.CFMetaData;
0: import org.apache.cassandra.config.ColumnDefinition;
1: import org.apache.cassandra.db.*;
1: import org.apache.cassandra.db.rows.*;
1: import org.apache.cassandra.io.ISerializer;
1: import org.apache.cassandra.io.util.DataOutputPlus;
1: import org.apache.cassandra.net.MessagingService;
1: 
0: public class ArrayBackedCachedPartition extends ArrayBackedPartition implements CachedPartition
1: {
1:     private final int createdAtInSec;
1: 
0:     // Note that those fields are really immutable, but we can't easily pass their values to
0:     // the ctor so they are not final.
0:     private int cachedLiveRows;
0:     private int rowsWithNonExpiringCells;
1: 
0:     private int nonTombstoneCellCount;
0:     private int nonExpiringLiveCells;
1: 
0:     private ArrayBackedCachedPartition(CFMetaData metadata,
0:                                        DecoratedKey partitionKey,
0:                                        DeletionTime deletionTime,
0:                                        PartitionColumns columns,
0:                                        int initialRowCapacity,
0:                                        boolean sortable,
0:                                        int createdAtInSec)
1:     {
0:         super(metadata, partitionKey, deletionTime, columns, initialRowCapacity, sortable);
1:         this.createdAtInSec = createdAtInSec;
1:     }
1: 
1:     /**
1:      * Creates an {@code ArrayBackedCachedPartition} holding all the data of the provided iterator.
1:      *
1:      * Warning: Note that this method does not close the provided iterator and it is
1:      * up to the caller to do so.
1:      *
1:      * @param iterator the iterator got gather in memory.
1:      * @param nowInSec the time of the creation in seconds. This is the time at which {@link #cachedLiveRows} applies.
1:      * @return the created partition.
1:      */
0:     public static ArrayBackedCachedPartition create(UnfilteredRowIterator iterator, int nowInSec)
1:     {
0:         return create(iterator, 4, nowInSec);
1:     }
1: 
1:     /**
1:      * Creates an {@code ArrayBackedCachedPartition} holding all the data of the provided iterator.
1:      *
1:      * Warning: Note that this method does not close the provided iterator and it is
1:      * up to the caller to do so.
1:      *
1:      * @param iterator the iterator got gather in memory.
1:      * @param initialRowCapacity sizing hint (in rows) to use for the created partition. It should ideally
1:      * correspond or be a good estimation of the number or rows in {@code iterator}.
1:      * @param nowInSec the time of the creation in seconds. This is the time at which {@link #cachedLiveRows} applies.
1:      * @return the created partition.
1:      */
0:     public static ArrayBackedCachedPartition create(UnfilteredRowIterator iterator, int initialRowCapacity, int nowInSec)
1:     {
0:         ArrayBackedCachedPartition partition = new ArrayBackedCachedPartition(iterator.metadata(),
0:                                                                               iterator.partitionKey(),
0:                                                                               iterator.partitionLevelDeletion(),
0:                                                                               iterator.columns(),
0:                                                                               initialRowCapacity,
0:                                                                               iterator.isReverseOrder(),
0:                                                                               nowInSec);
1: 
0:         partition.staticRow = iterator.staticRow().takeAlias();
1: 
0:         Writer writer = partition.new Writer(nowInSec);
0:         RangeTombstoneCollector markerCollector = partition.new RangeTombstoneCollector(iterator.isReverseOrder());
1: 
0:         copyAll(iterator, writer, markerCollector, partition);
1: 
0:         return partition;
1:     }
1: 
0:     public Row lastRow()
1:     {
0:         if (rows == 0)
0:             return null;
1: 
0:         return new InternalReusableRow().setTo(rows - 1);
1:     }
1: 
1:     /**
1:      * The number of rows that were live at the time the partition was cached.
1:      *
1:      * See {@link ColumnFamilyStore#isFilterFullyCoveredBy} to see why we need this.
1:      *
1:      * @return the number of rows in this partition that were live at the time the
1:      * partition was cached (this can be different from the number of live rows now
1:      * due to expiring cells).
1:      */
1:     public int cachedLiveRows()
1:     {
1:         return cachedLiveRows;
1:     }
1: 
1:     /**
1:      * The number of rows in this cached partition that have at least one non-expiring
1:      * non-deleted cell.
1:      *
1:      * Note that this is generally not a very meaningful number, but this is used by
1:      * {@link DataLimits#hasEnoughLiveData} as an optimization.
1:      *
1:      * @return the number of row that have at least one non-expiring non-deleted cell.
1:      */
1:     public int rowsWithNonExpiringCells()
1:     {
1:         return rowsWithNonExpiringCells;
1:     }
1: 
1:     public int nonTombstoneCellCount()
1:     {
1:         return nonTombstoneCellCount;
1:     }
1: 
1:     public int nonExpiringLiveCells()
1:     {
1:         return nonExpiringLiveCells;
1:     }
1: 
0:     // Writers that collect the values for 'cachedLiveRows', 'rowsWithNonExpiringCells', 'nonTombstoneCellCount'
0:     // and 'nonExpiringLiveCells'.
0:     protected class Writer extends AbstractPartitionData.Writer
1:     {
0:         private final int nowInSec;
1: 
0:         private boolean hasLiveData;
0:         private boolean hasNonExpiringCell;
1: 
0:         protected Writer(int nowInSec)
1:         {
0:             super(true);
0:             this.nowInSec = nowInSec;
1:         }
1: 
0:         @Override
0:         public void writePartitionKeyLivenessInfo(LivenessInfo info)
1:         {
0:             super.writePartitionKeyLivenessInfo(info);
0:             if (info.isLive(nowInSec))
0:                 hasLiveData = true;
1:         }
1: 
0:         @Override
0:         public void writeCell(ColumnDefinition column, boolean isCounter, ByteBuffer value, LivenessInfo info, CellPath path)
1:         {
0:             super.writeCell(column, isCounter, value, info, path);
1: 
0:             if (info.isLive(nowInSec))
1:             {
0:                 hasLiveData = true;
0:                 if (!info.hasTTL())
1:                 {
0:                     hasNonExpiringCell = true;
0:                     ++ArrayBackedCachedPartition.this.nonExpiringLiveCells;
1:                 }
1:             }
1: 
0:             if (!info.hasLocalDeletionTime() || info.hasTTL())
0:                 ++ArrayBackedCachedPartition.this.nonTombstoneCellCount;
1:         }
1: 
0:         @Override
0:         public void endOfRow()
1:         {
0:             super.endOfRow();
0:             if (hasLiveData)
0:                 ++ArrayBackedCachedPartition.this.cachedLiveRows;
0:             if (hasNonExpiringCell)
0:                 ++ArrayBackedCachedPartition.this.rowsWithNonExpiringCells;
1: 
0:             hasLiveData = false;
0:             hasNonExpiringCell = false;
1:         }
1:     }
1: 
1:     static class Serializer implements ISerializer<CachedPartition>
1:     {
1:         public void serialize(CachedPartition partition, DataOutputPlus out) throws IOException
1:         {
0:             assert partition instanceof ArrayBackedCachedPartition;
0:             ArrayBackedCachedPartition p = (ArrayBackedCachedPartition)partition;
1: 
1:             out.writeInt(p.createdAtInSec);
0:             try (UnfilteredRowIterator iter = p.sliceableUnfilteredIterator())
1:             {
0:                 UnfilteredRowIteratorSerializer.serializer.serialize(iter, out, MessagingService.current_version, p.rows);
1:             }
1:         }
1: 
0:         public CachedPartition deserialize(DataInput in) throws IOException
1:         {
1:             // Note that it would be slightly simpler to just do
1:             //   ArrayBackedCachedPiartition.create(UnfilteredRowIteratorSerializer.serializer.deserialize(...));
1:             // However deserializing the header separatly is not a lot harder and allows us to:
1:             //   1) get the capacity of the partition so we can size it properly directly
1:             //   2) saves the creation of a temporary iterator: rows are directly written to the partition, which
1:             //      is slightly faster.
1: 
1:             int createdAtInSec = in.readInt();
1: 
0:             UnfilteredRowIteratorSerializer.Header h = UnfilteredRowIteratorSerializer.serializer.deserializeHeader(in, MessagingService.current_version, SerializationHelper.Flag.LOCAL);
0:             assert !h.isReversed && h.rowEstimate >= 0;
1: 
0:             ArrayBackedCachedPartition partition = new ArrayBackedCachedPartition(h.metadata, h.key, h.partitionDeletion, h.sHeader.columns(), h.rowEstimate, false, createdAtInSec);
0:             partition.staticRow = h.staticRow;
1: 
0:             Writer writer = partition.new Writer(createdAtInSec);
0:             RangeTombstoneMarker.Writer markerWriter = partition.new RangeTombstoneCollector(false);
1: 
0:             UnfilteredRowIteratorSerializer.serializer.deserialize(in, new SerializationHelper(MessagingService.current_version, SerializationHelper.Flag.LOCAL), h.sHeader, writer, markerWriter);
0:             return partition;
1:         }
1: 
0:         public long serializedSize(CachedPartition partition, TypeSizes sizes)
1:         {
0:             assert partition instanceof ArrayBackedCachedPartition;
0:             ArrayBackedCachedPartition p = (ArrayBackedCachedPartition)partition;
1: 
0:             try (UnfilteredRowIterator iter = p.sliceableUnfilteredIterator())
1:             {
0:                 return sizes.sizeof(p.createdAtInSec)
0:                      + UnfilteredRowIteratorSerializer.serializer.serializedSize(iter, MessagingService.current_version, p.rows, sizes);
1:             }
1:         }
1:     }
1: }
1: 
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus;
/////////////////////////////////////////////////////////////////////////
1:         public CachedPartition deserialize(DataInputPlus in) throws IOException
/////////////////////////////////////////////////////////////////////////
1:         public long serializedSize(CachedPartition partition)
1:                 return TypeSizes.sizeof(p.createdAtInSec)
0:                      + UnfilteredRowIteratorSerializer.serializer.serializedSize(iter, MessagingService.current_version, p.rows);
============================================================================
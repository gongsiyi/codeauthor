1:1d74664: /*
1:1d74664:  * Licensed to the Apache Software Foundation (ASF) under one
1:1d74664:  * or more contributor license agreements.  See the NOTICE file
1:1d74664:  * distributed with this work for additional information
1:1d74664:  * regarding copyright ownership.  The ASF licenses this file
1:1d74664:  * to you under the Apache License, Version 2.0 (the
1:1d74664:  * "License"); you may not use this file except in compliance
1:1d74664:  * with the License.  You may obtain a copy of the License at
1:1d74664:  *
1:1d74664:  *     http://www.apache.org/licenses/LICENSE-2.0
1:1d74664:  *
1:1d74664:  * Unless required by applicable law or agreed to in writing, software
1:1d74664:  * distributed under the License is distributed on an "AS IS" BASIS,
1:1d74664:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:1d74664:  * See the License for the specific language governing permissions and
1:1d74664:  * limitations under the License.
1:1d74664:  */
1:1d74664: 
1:1d74664: package org.apache.cassandra.test.microbench;
1:1d74664: 
1:1d74664: 
1:1d74664: import java.io.File;
1:1d74664: import java.io.IOException;
1:1d74664: import java.nio.ByteBuffer;
1:1d74664: import java.util.Collection;
1:1d74664: import java.util.List;
1:1d74664: import java.util.concurrent.*;
1:1d74664: 
1:1d74664: import com.google.common.collect.Lists;
1:1d74664: import com.google.common.collect.Sets;
1:1d74664: import com.google.common.util.concurrent.Uninterruptibles;
1:1d74664: 
1:1d74664: import org.apache.cassandra.UpdateBuilder;
1:1d74664: import org.apache.cassandra.concurrent.StageManager;
1:1d74664: import org.apache.cassandra.config.CFMetaData;
1:1d74664: import org.apache.cassandra.config.Config;
1:1d74664: import org.apache.cassandra.config.DatabaseDescriptor;
1:1d74664: import org.apache.cassandra.config.Schema;
1:1d74664: import org.apache.cassandra.cql3.CQLTester;
1:1d74664: import org.apache.cassandra.cql3.statements.ParsedStatement;
1:1d74664: import org.apache.cassandra.db.ColumnFamilyStore;
1:1d74664: import org.apache.cassandra.db.Directories;
1:1d74664: import org.apache.cassandra.db.Keyspace;
1:1d74664: import org.apache.cassandra.db.Mutation;
1:1d74664: import org.apache.cassandra.db.compaction.CompactionManager;
1:1d74664: import org.apache.cassandra.dht.Murmur3Partitioner;
1:1d74664: import org.apache.cassandra.io.sstable.Descriptor;
1:1d74664: import org.apache.cassandra.io.util.DataInputBuffer;
1:1d74664: import org.apache.cassandra.io.util.DataOutputBuffer;
1:1d74664: import org.apache.cassandra.io.util.DataOutputBufferFixed;
1:1d74664: import org.apache.cassandra.io.util.FileUtils;
1:1d74664: import org.apache.cassandra.net.MessageIn;
1:1d74664: import org.apache.cassandra.net.MessageOut;
1:1d74664: import org.apache.cassandra.net.MessagingService;
1:1d74664: import org.apache.cassandra.schema.KeyspaceMetadata;
1:1d74664: import org.apache.cassandra.schema.KeyspaceParams;
1:1d74664: import org.apache.cassandra.service.CassandraDaemon;
1:1d74664: import org.apache.cassandra.service.StorageService;
1:1d74664: import org.apache.cassandra.transport.messages.ResultMessage;
1:1d74664: import org.apache.cassandra.utils.FBUtilities;
1:1d74664: import org.apache.hadoop.util.bloom.Key;
1:1d74664: import org.openjdk.jmh.annotations.*;
1:1d74664: import org.openjdk.jmh.profile.StackProfiler;
1:1d74664: import org.openjdk.jmh.results.Result;
1:1d74664: import org.openjdk.jmh.results.RunResult;
1:1d74664: import org.openjdk.jmh.runner.Runner;
1:1d74664: import org.openjdk.jmh.runner.options.Options;
1:1d74664: import org.openjdk.jmh.runner.options.OptionsBuilder;
1:1d74664: 
1:1d74664: @BenchmarkMode(Mode.AverageTime)
1:1d74664: @OutputTimeUnit(TimeUnit.MILLISECONDS)
1:1d74664: @Warmup(iterations = 25, time = 1, timeUnit = TimeUnit.SECONDS)
1:1d74664: @Measurement(iterations = 5, time = 2, timeUnit = TimeUnit.SECONDS)
1:1d74664: @Fork(value = 1)
1:1d74664: @Threads(1)
1:1d74664: @State(Scope.Benchmark)
1:1d74664: public class CompactionBench extends CQLTester
1:1d74664: {
1:1d74664:     static String keyspace;
1:1d74664:     String table;
1:1d74664:     String writeStatement;
1:1d74664:     String readStatement;
1:1d74664:     ColumnFamilyStore cfs;
1:1d74664:     List<File> snapshotFiles;
1:1d74664:     List<Descriptor> liveFiles;
1:1d74664: 
1:1d74664:     @Setup(Level.Trial)
1:1d74664:     public void setup() throws Throwable
1:1d74664:     {
1:1d74664:         CQLTester.prepareServer();
1:1d74664:         keyspace = createKeyspace("CREATE KEYSPACE %s with replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 } and durable_writes = false");
1:1d74664:         table = createTable(keyspace, "CREATE TABLE %s ( userid bigint, picid bigint, commentid bigint, PRIMARY KEY(userid, picid))");
1:1d74664:         execute("use "+keyspace+";");
1:1d74664:         writeStatement = "INSERT INTO "+table+"(userid,picid,commentid)VALUES(?,?,?)";
1:1d74664:         readStatement = "SELECT * from "+table+" limit 100";
1:1d74664: 
1:1d74664:         Keyspace.system().forEach(k -> k.getColumnFamilyStores().forEach(c -> c.disableAutoCompaction()));
1:1d74664: 
1:1d74664:         cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
1:1d74664:         cfs.disableAutoCompaction();
1:1d74664: 
1:1d74664:         //Warm up
1:1d74664:         System.err.println("Writing 50k");
1:1d74664:         for (long i = 0; i < 50000; i++)
1:1d74664:             execute(writeStatement, i, i, i );
1:1d74664: 
1:1d74664: 
1:1d74664:         cfs.forceBlockingFlush();
1:1d74664: 
1:1d74664:         System.err.println("Writing 50k again...");
1:1d74664:         for (long i = 0; i < 50000; i++)
1:1d74664:             execute(writeStatement, i, i, i );
1:1d74664: 
1:1d74664:         cfs.forceBlockingFlush();
1:1d74664: 
1:1d74664:         cfs.snapshot("originals");
1:1d74664: 
1:1d74664:         snapshotFiles = cfs.getDirectories().sstableLister(Directories.OnTxnErr.IGNORE).snapshots("originals").listFiles();
1:1d74664:     }
1:1d74664: 
1:1d74664:     @TearDown(Level.Trial)
1:1d74664:     public void teardown() throws IOException, ExecutionException, InterruptedException
1:1d74664:     {
1:1d74664:         int active = Thread.currentThread().getThreadGroup().activeCount();
1:1d74664:         Thread[] threads = new Thread[active];
1:1d74664:         Thread.currentThread().getThreadGroup().enumerate(threads);
1:1d74664:         for (Thread t : threads)
1:1d74664:         {
1:1d74664:             if (!t.isDaemon())
1:1d74664:                 System.err.println("Thread "+t.getName());
1:1d74664:         }
1:1d74664: 
1:1d74664:         CQLTester.cleanup();
1:1d74664:     }
1:1d74664: 
1:1d74664: 
1:1d74664:     @TearDown(Level.Invocation)
1:1d74664:     public void resetSnapshot()
1:1d74664:     {
1:1d74664:         cfs.truncateBlocking();
1:1d74664: 
1:1d74664:         List<File> directories = cfs.getDirectories().getCFDirectories();
1:1d74664: 
1:1d74664:         for (File file : directories)
1:1d74664:         {
1:1d74664:             for (File f : file.listFiles())
1:1d74664:             {
1:1d74664:                 if (f.isDirectory())
1:1d74664:                     continue;
1:1d74664: 
1:1d74664:                 FileUtils.delete(f);
1:1d74664:             }
1:1d74664:         }
1:1d74664: 
1:1d74664: 
1:1d74664:         for (File file : snapshotFiles)
1:1d74664:             FileUtils.createHardLink(file, new File(file.toPath().getParent().getParent().getParent().toFile(), file.getName()));
1:1d74664: 
1:1d74664:         cfs.loadNewSSTables();
1:1d74664:     }
1:1d74664: 
1:1d74664:     @Benchmark
1:1d74664:     public void compactTest() throws Throwable
1:1d74664:     {
1:1d74664:         cfs.forceMajorCompaction();
1:1d74664:     }
1:1d74664: }
============================================================================
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:1d74664
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.cassandra.test.microbench;
1: 
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.util.Collection;
1: import java.util.List;
1: import java.util.concurrent.*;
1: 
1: import com.google.common.collect.Lists;
1: import com.google.common.collect.Sets;
1: import com.google.common.util.concurrent.Uninterruptibles;
1: 
1: import org.apache.cassandra.UpdateBuilder;
1: import org.apache.cassandra.concurrent.StageManager;
1: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.config.Config;
1: import org.apache.cassandra.config.DatabaseDescriptor;
1: import org.apache.cassandra.config.Schema;
1: import org.apache.cassandra.cql3.CQLTester;
1: import org.apache.cassandra.cql3.statements.ParsedStatement;
1: import org.apache.cassandra.db.ColumnFamilyStore;
1: import org.apache.cassandra.db.Directories;
1: import org.apache.cassandra.db.Keyspace;
1: import org.apache.cassandra.db.Mutation;
1: import org.apache.cassandra.db.compaction.CompactionManager;
1: import org.apache.cassandra.dht.Murmur3Partitioner;
1: import org.apache.cassandra.io.sstable.Descriptor;
1: import org.apache.cassandra.io.util.DataInputBuffer;
1: import org.apache.cassandra.io.util.DataOutputBuffer;
1: import org.apache.cassandra.io.util.DataOutputBufferFixed;
1: import org.apache.cassandra.io.util.FileUtils;
1: import org.apache.cassandra.net.MessageIn;
1: import org.apache.cassandra.net.MessageOut;
1: import org.apache.cassandra.net.MessagingService;
1: import org.apache.cassandra.schema.KeyspaceMetadata;
1: import org.apache.cassandra.schema.KeyspaceParams;
1: import org.apache.cassandra.service.CassandraDaemon;
1: import org.apache.cassandra.service.StorageService;
1: import org.apache.cassandra.transport.messages.ResultMessage;
1: import org.apache.cassandra.utils.FBUtilities;
1: import org.apache.hadoop.util.bloom.Key;
1: import org.openjdk.jmh.annotations.*;
1: import org.openjdk.jmh.profile.StackProfiler;
1: import org.openjdk.jmh.results.Result;
1: import org.openjdk.jmh.results.RunResult;
1: import org.openjdk.jmh.runner.Runner;
1: import org.openjdk.jmh.runner.options.Options;
1: import org.openjdk.jmh.runner.options.OptionsBuilder;
1: 
1: @BenchmarkMode(Mode.AverageTime)
1: @OutputTimeUnit(TimeUnit.MILLISECONDS)
1: @Warmup(iterations = 25, time = 1, timeUnit = TimeUnit.SECONDS)
1: @Measurement(iterations = 5, time = 2, timeUnit = TimeUnit.SECONDS)
1: @Fork(value = 1)
1: @Threads(1)
1: @State(Scope.Benchmark)
1: public class CompactionBench extends CQLTester
1: {
1:     static String keyspace;
1:     String table;
1:     String writeStatement;
1:     String readStatement;
1:     ColumnFamilyStore cfs;
1:     List<File> snapshotFiles;
1:     List<Descriptor> liveFiles;
1: 
1:     @Setup(Level.Trial)
1:     public void setup() throws Throwable
1:     {
1:         CQLTester.prepareServer();
1:         keyspace = createKeyspace("CREATE KEYSPACE %s with replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 } and durable_writes = false");
1:         table = createTable(keyspace, "CREATE TABLE %s ( userid bigint, picid bigint, commentid bigint, PRIMARY KEY(userid, picid))");
1:         execute("use "+keyspace+";");
1:         writeStatement = "INSERT INTO "+table+"(userid,picid,commentid)VALUES(?,?,?)";
1:         readStatement = "SELECT * from "+table+" limit 100";
1: 
1:         Keyspace.system().forEach(k -> k.getColumnFamilyStores().forEach(c -> c.disableAutoCompaction()));
1: 
1:         cfs = Keyspace.open(keyspace).getColumnFamilyStore(table);
1:         cfs.disableAutoCompaction();
1: 
1:         //Warm up
1:         System.err.println("Writing 50k");
1:         for (long i = 0; i < 50000; i++)
1:             execute(writeStatement, i, i, i );
1: 
1: 
1:         cfs.forceBlockingFlush();
1: 
1:         System.err.println("Writing 50k again...");
1:         for (long i = 0; i < 50000; i++)
1:             execute(writeStatement, i, i, i );
1: 
1:         cfs.forceBlockingFlush();
1: 
1:         cfs.snapshot("originals");
1: 
1:         snapshotFiles = cfs.getDirectories().sstableLister(Directories.OnTxnErr.IGNORE).snapshots("originals").listFiles();
1:     }
1: 
1:     @TearDown(Level.Trial)
1:     public void teardown() throws IOException, ExecutionException, InterruptedException
1:     {
1:         int active = Thread.currentThread().getThreadGroup().activeCount();
1:         Thread[] threads = new Thread[active];
1:         Thread.currentThread().getThreadGroup().enumerate(threads);
1:         for (Thread t : threads)
1:         {
1:             if (!t.isDaemon())
1:                 System.err.println("Thread "+t.getName());
1:         }
1: 
1:         CQLTester.cleanup();
1:     }
1: 
1: 
1:     @TearDown(Level.Invocation)
1:     public void resetSnapshot()
1:     {
1:         cfs.truncateBlocking();
1: 
1:         List<File> directories = cfs.getDirectories().getCFDirectories();
1: 
1:         for (File file : directories)
1:         {
1:             for (File f : file.listFiles())
1:             {
1:                 if (f.isDirectory())
1:                     continue;
1: 
1:                 FileUtils.delete(f);
1:             }
1:         }
1: 
1: 
1:         for (File file : snapshotFiles)
1:             FileUtils.createHardLink(file, new File(file.toPath().getParent().getParent().getParent().toFile(), file.getName()));
1: 
1:         cfs.loadNewSSTables();
1:     }
1: 
1:     @Benchmark
1:     public void compactTest() throws Throwable
1:     {
1:         cfs.forceMajorCompaction();
1:     }
1: }
============================================================================
1:5c4d5c7: /*
1:5c4d5c7:  * Licensed to the Apache Software Foundation (ASF) under one
1:5c4d5c7:  * or more contributor license agreements.  See the NOTICE file
1:5c4d5c7:  * distributed with this work for additional information
1:5c4d5c7:  * regarding copyright ownership.  The ASF licenses this file
1:5c4d5c7:  * to you under the Apache License, Version 2.0 (the
1:5c4d5c7:  * "License"); you may not use this file except in compliance
1:5c4d5c7:  * with the License.  You may obtain a copy of the License at
1:5c4d5c7:  *
1:5c4d5c7:  *     http://www.apache.org/licenses/LICENSE-2.0
1:5c4d5c7:  *
1:5c4d5c7:  * Unless required by applicable law or agreed to in writing, software
1:5c4d5c7:  * distributed under the License is distributed on an "AS IS" BASIS,
1:5c4d5c7:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:5c4d5c7:  * See the License for the specific language governing permissions and
1:5c4d5c7:  * limitations under the License.
1:5c4d5c7:  */
14:5c4d5c7: 
1:5c4d5c7: package org.apache.cassandra.index.sasi.disk;
1:5c4d5c7: 
1:5c4d5c7: import java.io.IOException;
1:5c4d5c7: import java.nio.ByteBuffer;
1:7d857b4: import java.util.*;
1:7d857b4: import java.util.function.*;
1:5c4d5c7: 
1:7d857b4: import com.carrotsearch.hppc.LongArrayList;
1:7d857b4: import com.carrotsearch.hppc.cursors.LongCursor;
1:7d857b4: import com.carrotsearch.hppc.cursors.LongObjectCursor;
1:7d857b4: import org.apache.cassandra.dht.*;
1:5c4d5c7: import org.apache.cassandra.io.util.DataOutputPlus;
1:5c4d5c7: import org.apache.cassandra.utils.AbstractIterator;
1:5c4d5c7: import org.apache.cassandra.utils.FBUtilities;
1:5c4d5c7: import org.apache.cassandra.utils.Pair;
1:5c4d5c7: 
1:5c4d5c7: public abstract class AbstractTokenTreeBuilder implements TokenTreeBuilder
1:68d2526: {
1:5c4d5c7:     protected int numBlocks;
1:5c4d5c7:     protected Node root;
1:5c4d5c7:     protected InteriorNode rightmostParent;
1:5c4d5c7:     protected Leaf leftmostLeaf;
1:5c4d5c7:     protected Leaf rightmostLeaf;
1:5c4d5c7:     protected long tokenCount = 0;
1:5c4d5c7:     protected long treeMinToken;
1:5c4d5c7:     protected long treeMaxToken;
1:5c4d5c7: 
1:5c4d5c7:     public void add(TokenTreeBuilder other)
11:5c4d5c7:     {
1:5c4d5c7:         add(other.iterator());
11:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public TokenTreeBuilder finish()
1:5c4d5c7:     {
1:5c4d5c7:         if (root == null)
1:5c4d5c7:             constructTree();
1:5c4d5c7: 
1:5c4d5c7:         return this;
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public long getTokenCount()
1:5c4d5c7:     {
1:5c4d5c7:         return tokenCount;
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public int serializedSize()
1:5c4d5c7:     {
1:5c4d5c7:         if (numBlocks == 1)
1:7d857b4:             return BLOCK_HEADER_BYTES + ((int) tokenCount * LEAF_ENTRY_BYTES);
4:5c4d5c7:         else
1:5c4d5c7:             return numBlocks * BLOCK_BYTES;
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public void write(DataOutputPlus out) throws IOException
1:5c4d5c7:     {
1:5c4d5c7:         ByteBuffer blockBuffer = ByteBuffer.allocate(BLOCK_BYTES);
1:5c4d5c7:         Iterator<Node> levelIterator = root.levelIterator();
1:5c4d5c7:         long childBlockIndex = 1;
1:5c4d5c7: 
1:5c4d5c7:         while (levelIterator != null)
1:5c4d5c7:         {
1:5c4d5c7:             Node firstChild = null;
1:5c4d5c7:             while (levelIterator.hasNext())
1:5c4d5c7:             {
1:5c4d5c7:                 Node block = levelIterator.next();
1:5c4d5c7: 
1:5c4d5c7:                 if (firstChild == null && !block.isLeaf())
1:5c4d5c7:                     firstChild = ((InteriorNode) block).children.get(0);
1:5c4d5c7: 
1:5c4d5c7:                 if (block.isSerializable())
1:5c4d5c7:                 {
1:5c4d5c7:                     block.serialize(childBlockIndex, blockBuffer);
1:5c4d5c7:                     flushBuffer(blockBuffer, out, numBlocks != 1);
1:5c4d5c7:                 }
1:5c4d5c7: 
1:5c4d5c7:                 childBlockIndex += block.childCount();
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             levelIterator = (firstChild == null) ? null : firstChild.levelIterator();
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     protected abstract void constructTree();
1:5c4d5c7: 
1:5c4d5c7:     protected void flushBuffer(ByteBuffer buffer, DataOutputPlus o, boolean align) throws IOException
1:5c4d5c7:     {
1:5c4d5c7:         // seek to end of last block before flushing
1:5c4d5c7:         if (align)
1:5c4d5c7:             alignBuffer(buffer, BLOCK_BYTES);
1:5c4d5c7: 
1:5c4d5c7:         buffer.flip();
1:5c4d5c7:         o.write(buffer);
1:5c4d5c7:         buffer.clear();
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     /**
1:7d857b4:      * Tree node,
1:7d857b4:      *
1:7d857b4:      * B+-tree consists of root, interior nodes and leaves. Root can be either a node or a leaf.
1:7d857b4:      *
1:7d857b4:      * Depending on the concrete implementation of {@code TokenTreeBuilder}
1:7d857b4:      * leaf can be partial or static (in case of {@code StaticTokenTreeBuilder} or dynamic in case
1:7d857b4:      * of {@code DynamicTokenTreeBuilder}
1:7d857b4:      */
1:5c4d5c7:     protected abstract class Node
1:5c4d5c7:     {
1:5c4d5c7:         protected InteriorNode parent;
1:5c4d5c7:         protected Node next;
1:5c4d5c7:         protected Long nodeMinToken, nodeMaxToken;
1:5c4d5c7: 
1:5c4d5c7:         public Node(Long minToken, Long maxToken)
1:5c4d5c7:         {
1:5c4d5c7:             nodeMinToken = minToken;
1:5c4d5c7:             nodeMaxToken = maxToken;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public abstract boolean isSerializable();
1:5c4d5c7:         public abstract void serialize(long childBlockIndex, ByteBuffer buf);
1:5c4d5c7:         public abstract int childCount();
1:5c4d5c7:         public abstract int tokenCount();
1:5c4d5c7: 
1:5c4d5c7:         public Long smallestToken()
1:5c4d5c7:         {
1:5c4d5c7:             return nodeMinToken;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public Long largestToken()
1:5c4d5c7:         {
1:5c4d5c7:             return nodeMaxToken;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public Iterator<Node> levelIterator()
1:5c4d5c7:         {
1:5c4d5c7:             return new LevelIterator(this);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public boolean isLeaf()
1:5c4d5c7:         {
1:5c4d5c7:             return (this instanceof Leaf);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected boolean isLastLeaf()
1:5c4d5c7:         {
1:5c4d5c7:             return this == rightmostLeaf;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected boolean isRoot()
1:5c4d5c7:         {
1:5c4d5c7:             return this == root;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected void updateTokenRange(long token)
1:5c4d5c7:         {
1:5c4d5c7:             nodeMinToken = nodeMinToken == null ? token : Math.min(nodeMinToken, token);
1:5c4d5c7:             nodeMaxToken = nodeMaxToken == null ? token : Math.max(nodeMaxToken, token);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected void serializeHeader(ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             Header header;
1:5c4d5c7:             if (isRoot())
1:5c4d5c7:                 header = new RootHeader();
1:5c4d5c7:             else if (!isLeaf())
1:5c4d5c7:                 header = new InteriorNodeHeader();
1:5c4d5c7:             else
1:5c4d5c7:                 header = new LeafHeader();
1:5c4d5c7: 
1:5c4d5c7:             header.serialize(buf);
1:5c4d5c7:             alignBuffer(buf, BLOCK_HEADER_BYTES);
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * Shared header part, written for all node types:
1:7d857b4:          *     [  info byte  ] [  token count   ] [ min node token ] [ max node token ]
1:7d857b4:          *     [      1b     ] [    2b (short)  ] [   8b (long)    ] [    8b (long)   ]
1:7d857b4:          **/
1:5c4d5c7:         private abstract class Header
1:5c4d5c7:         {
1:7d857b4:             /**
1:7d857b4:              * Serializes the shared part of the header
1:7d857b4:              */
2:5c4d5c7:             public void serialize(ByteBuffer buf)
1:5c4d5c7:             {
1:5c4d5c7:                 buf.put(infoByte())
1:5c4d5c7:                    .putShort((short) (tokenCount()))
1:5c4d5c7:                    .putLong(nodeMinToken)
1:5c4d5c7:                    .putLong(nodeMaxToken);
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             protected abstract byte infoByte();
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * In addition to shared header part, root header stores version information,
1:7d857b4:          * overall token count and min/max tokens for the whole tree:
1:7d857b4:          *     [      magic    ] [  overall token count  ] [ min tree token ] [ max tree token ]
1:7d857b4:          *     [   2b (short)  ] [         8b (long)     ] [   8b (long)    ] [    8b (long)   ]
1:7d857b4:          */
1:5c4d5c7:         private class RootHeader extends Header
1:5c4d5c7:         {
1:5c4d5c7:             public void serialize(ByteBuffer buf)
1:5c4d5c7:             {
1:5c4d5c7:                 super.serialize(buf);
1:5c4d5c7:                 writeMagic(buf);
1:5c4d5c7:                 buf.putLong(tokenCount)
1:5c4d5c7:                    .putLong(treeMinToken)
1:5c4d5c7:                    .putLong(treeMaxToken);
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             protected byte infoByte()
1:5c4d5c7:             {
1:5c4d5c7:                 // if leaf, set leaf indicator and last leaf indicator (bits 0 & 1)
1:5c4d5c7:                 // if not leaf, clear both bits
1:7d857b4:                 return isLeaf() ? ENTRY_TYPE_MASK : 0;
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             protected void writeMagic(ByteBuffer buf)
1:5c4d5c7:             {
1:5c4d5c7:                 switch (Descriptor.CURRENT_VERSION)
1:5c4d5c7:                 {
1:7d857b4:                     case ab:
1:5c4d5c7:                         buf.putShort(AB_MAGIC);
1:5c4d5c7:                         break;
1:7d857b4:                     case ac:
1:7d857b4:                         buf.putShort(AC_MAGIC);
1:5c4d5c7:                         break;
1:7d857b4:                     default:
1:7d857b4:                         throw new RuntimeException("Unsupported version");
1:5c4d5c7:                 }
1:5c4d5c7: 
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         private class InteriorNodeHeader extends Header
1:5c4d5c7:         {
1:5c4d5c7:             // bit 0 (leaf indicator) & bit 1 (last leaf indicator) cleared
1:5c4d5c7:             protected byte infoByte()
1:5c4d5c7:             {
2:5c4d5c7:                 return 0;
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         private class LeafHeader extends Header
1:5c4d5c7:         {
1:5c4d5c7:             // bit 0 set as leaf indicator
1:5c4d5c7:             // bit 1 set if this is last leaf of data
1:5c4d5c7:             protected byte infoByte()
1:5c4d5c7:             {
1:5c4d5c7:                 byte infoByte = 1;
1:5c4d5c7:                 infoByte |= (isLastLeaf()) ? (1 << LAST_LEAF_SHIFT) : 0;
1:5c4d5c7: 
1:5c4d5c7:                 return infoByte;
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     /**
1:7d857b4:      * Leaf consists of
1:7d857b4:      *   - header (format described in {@code Header} )
1:7d857b4:      *   - data (format described in {@code LeafEntry})
1:7d857b4:      *   - overflow collision entries, that hold {@value OVERFLOW_TRAILER_CAPACITY} of {@code RowOffset}.
1:7d857b4:      */
1:5c4d5c7:     protected abstract class Leaf extends Node
1:5c4d5c7:     {
1:5c4d5c7:         protected LongArrayList overflowCollisions;
1:5c4d5c7: 
1:5c4d5c7:         public Leaf(Long minToken, Long maxToken)
1:5c4d5c7:         {
1:5c4d5c7:             super(minToken, maxToken);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public int childCount()
1:5c4d5c7:         {
1:5c4d5c7:             return 0;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected void serializeOverflowCollisions(ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             if (overflowCollisions != null)
1:5c4d5c7:                 for (LongCursor offset : overflowCollisions)
1:5c4d5c7:                     buf.putLong(offset.value);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void serialize(long childBlockIndex, ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             serializeHeader(buf);
1:5c4d5c7:             serializeData(buf);
1:5c4d5c7:             serializeOverflowCollisions(buf);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected abstract void serializeData(ByteBuffer buf);
1:5c4d5c7: 
1:7d857b4:         protected LeafEntry createEntry(final long tok, final KeyOffsets offsets)
1:5c4d5c7:         {
1:7d857b4:             LongArrayList rawOffsets = new LongArrayList(offsets.size());
1:7d857b4: 
1:7d857b4:             offsets.forEach(new Consumer<LongObjectCursor<long[]>>()
1:7d857b4:             {
1:7d857b4:                 public void accept(LongObjectCursor<long[]> cursor)
1:7d857b4:                 {
1:7d857b4:                     for (long l : cursor.value)
1:7d857b4:                     {
1:7d857b4:                         rawOffsets.add(cursor.key);
1:7d857b4:                         rawOffsets.add(l);
1:7d857b4:                     }
1:7d857b4:                 }
1:7d857b4:             });
1:7d857b4: 
1:7d857b4:             int offsetCount = rawOffsets.size();
1:5c4d5c7:             switch (offsetCount)
1:5c4d5c7:             {
1:5c4d5c7:                 case 0:
1:5c4d5c7:                     throw new AssertionError("no offsets for token " + tok);
1:5c4d5c7:                 case 2:
1:7d857b4:                     return new SimpleLeafEntry(tok, rawOffsets.get(0), rawOffsets.get(1));
2:5c4d5c7:                 default:
1:7d857b4:                     assert offsetCount % 2 == 0;
1:7d857b4:                     if (offsetCount == 4)
1:7d857b4:                     {
1:7d857b4:                         if (rawOffsets.get(0) < Integer.MAX_VALUE && rawOffsets.get(1) < Integer.MAX_VALUE &&
1:7d857b4:                             rawOffsets.get(2) < Integer.MAX_VALUE && rawOffsets.get(3) < Integer.MAX_VALUE)
1:7d857b4:                         {
1:7d857b4:                             return new PackedCollisionLeafEntry(tok, (int)rawOffsets.get(0), (int) rawOffsets.get(1),
1:7d857b4:                                                                 (int) rawOffsets.get(2), (int) rawOffsets.get(3));
1:7d857b4:                         }
1:7d857b4:                     }
1:7d857b4:                     return createOverflowEntry(tok, offsetCount, rawOffsets);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         private LeafEntry createOverflowEntry(final long tok, final int offsetCount, final LongArrayList offsets)
1:5c4d5c7:         {
1:5c4d5c7:             if (overflowCollisions == null)
1:7d857b4:                 overflowCollisions = new LongArrayList(offsetCount);
1:5c4d5c7: 
1:7d857b4:             int overflowCount = (overflowCollisions.size() + offsetCount) / 2;
1:7d857b4:             if (overflowCount >= OVERFLOW_TRAILER_CAPACITY)
1:7d857b4:                 throw new AssertionError("cannot have more than " + OVERFLOW_TRAILER_CAPACITY + " overflow collisions per leaf, but had: " + overflowCount);
1:7d857b4: 
1:7d857b4:             LeafEntry entry = new OverflowCollisionLeafEntry(tok, (short) (overflowCollisions.size() / 2), (short) (offsetCount / 2));
1:7d857b4:             overflowCollisions.addAll(offsets);
1:5c4d5c7:             return entry;
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * A leaf of the B+-Tree, that holds information about the row offset(s) for
1:7d857b4:          * the current token.
1:7d857b4:          *
1:7d857b4:          * Main 3 types of leaf entries are:
1:7d857b4:          *   1) simple leaf entry: holding just a single row offset
1:7d857b4:          *   2) packed collision leaf entry: holding two entries that would fit together into 168 bytes
1:7d857b4:          *   3) overflow entry: only holds offset in overflow trailer and amount of entries belonging to this leaf
1:7d857b4:          */
1:5c4d5c7:         protected abstract class LeafEntry
1:5c4d5c7:         {
1:5c4d5c7:             protected final long token;
1:5c4d5c7: 
1:5c4d5c7:             abstract public EntryType type();
1:5c4d5c7: 
1:5c4d5c7:             public LeafEntry(final long tok)
1:5c4d5c7:             {
1:5c4d5c7:                 token = tok;
1:5c4d5c7:             }
1:5c4d5c7: 
1:7d857b4:             public abstract void serialize(ByteBuffer buf);
1:5c4d5c7: 
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * Simple leaf, that can store a single row offset, having the following format:
1:7d857b4:          *
1:7d857b4:          *     [    type    ] [   token   ] [ partition offset ] [ row offset ]
1:7d857b4:          *     [ 2b (short) ] [ 8b (long) ] [     8b (long)    ] [  8b (long) ]
1:7d857b4:          */
1:5c4d5c7:         protected class SimpleLeafEntry extends LeafEntry
1:5c4d5c7:         {
1:7d857b4:             private final long partitionOffset;
1:7d857b4:             private final long rowOffset;
1:5c4d5c7: 
1:7d857b4:             public SimpleLeafEntry(final long tok, final long partitionOffset, final long rowOffset)
1:5c4d5c7:             {
2:5c4d5c7:                 super(tok);
1:7d857b4:                 this.partitionOffset = partitionOffset;
1:7d857b4:                 this.rowOffset = rowOffset;
1:5c4d5c7:             }
1:5c4d5c7: 
2:5c4d5c7:             public EntryType type()
1:5c4d5c7:             {
1:5c4d5c7:                 return EntryType.SIMPLE;
1:5c4d5c7:             }
1:5c4d5c7: 
1:7d857b4:             @Override
1:7d857b4:             public void serialize(ByteBuffer buf)
1:5c4d5c7:             {
1:7d857b4:                 buf.putShort((short) type().ordinal())
1:7d857b4:                    .putLong(token)
1:7d857b4:                    .putLong(partitionOffset)
1:7d857b4:                    .putLong(rowOffset);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * Packed collision entry, can store two offsets, if each one of their positions
1:7d857b4:          * fit into 4 bytes.
1:7d857b4:          *     [    type    ] [   token   ] [ partition offset 1 ] [ row offset  1] [ partition offset 1 ] [ row offset  1]
1:7d857b4:          *     [ 2b (short) ] [ 8b (long) ] [      4b (int)      ] [    4b (int)  ] [      4b (int)      ] [    4b (int)  ]
1:7d857b4:          */
1:7d857b4:         protected class PackedCollisionLeafEntry extends LeafEntry
1:5c4d5c7:         {
1:7d857b4:             private final int partitionOffset1;
1:7d857b4:             private final int rowOffset1;
1:7d857b4:             private final int partitionOffset2;
1:7d857b4:             private final int rowOffset2;
1:5c4d5c7: 
1:7d857b4:             public PackedCollisionLeafEntry(final long tok, final int partitionOffset1, final int rowOffset1,
1:7d857b4:                                             final int partitionOffset2, final int rowOffset2)
1:5c4d5c7:             {
1:5c4d5c7:                 super(tok);
1:7d857b4:                 this.partitionOffset1 = partitionOffset1;
1:7d857b4:                 this.rowOffset1 = rowOffset1;
1:7d857b4:                 this.partitionOffset2 = partitionOffset2;
1:7d857b4:                 this.rowOffset2 = rowOffset2;
1:5c4d5c7: 
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             public EntryType type()
1:5c4d5c7:             {
1:5c4d5c7:                 return EntryType.PACKED;
1:5c4d5c7:             }
1:5c4d5c7: 
1:7d857b4:             @Override
1:7d857b4:             public void serialize(ByteBuffer buf)
1:5c4d5c7:             {
1:7d857b4:                 buf.putShort((short) type().ordinal())
1:7d857b4:                    .putLong(token)
1:7d857b4:                    .putInt(partitionOffset1)
1:7d857b4:                    .putInt(rowOffset1)
1:7d857b4:                    .putInt(partitionOffset2)
1:7d857b4:                    .putInt(rowOffset2);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:7d857b4:         /**
1:7d857b4:          * Overflow collision entry, holds an entry with three or more offsets, or two offsets
1:7d857b4:          * that cannot be packed into 16 bytes.
1:7d857b4:          *     [    type    ] [   token   ] [ start index ] [    count    ]
1:7d857b4:          *     [ 2b (short) ] [ 8b (long) ] [   8b (long) ] [  8b (long)  ]
1:7d857b4:          *
1:7d857b4:          *   - [ start index ] is a position of first item belonging to this leaf entry in the overflow trailer
1:7d857b4:          *   - [ count ] is the amount of items belonging to this leaf entry that are stored in the overflow trailer
1:7d857b4:          */
1:5c4d5c7:         private class OverflowCollisionLeafEntry extends LeafEntry
1:5c4d5c7:         {
1:5c4d5c7:             private final short startIndex;
1:5c4d5c7:             private final short count;
1:5c4d5c7: 
1:5c4d5c7:             public OverflowCollisionLeafEntry(final long tok, final short collisionStartIndex, final short collisionCount)
1:5c4d5c7:             {
1:5c4d5c7:                 super(tok);
1:5c4d5c7:                 startIndex = collisionStartIndex;
1:5c4d5c7:                 count = collisionCount;
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             public EntryType type()
1:5c4d5c7:             {
1:5c4d5c7:                 return EntryType.OVERFLOW;
1:5c4d5c7:             }
1:5c4d5c7: 
1:7d857b4:             @Override
1:7d857b4:             public void serialize(ByteBuffer buf)
1:5c4d5c7:             {
1:7d857b4:                 buf.putShort((short) type().ordinal())
1:7d857b4:                    .putLong(token)
1:7d857b4:                    .putLong(startIndex)
1:7d857b4:                    .putLong(count);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     /**
1:7d857b4:      * Interior node consists of:
1:7d857b4:      *    - (interior node) header
1:7d857b4:      *    - tokens (serialized as longs, with count stored in header)
1:7d857b4:      *    - child offsets
1:7d857b4:      */
1:5c4d5c7:     protected class InteriorNode extends Node
1:5c4d5c7:     {
1:5c4d5c7:         protected List<Long> tokens = new ArrayList<>(TOKENS_PER_BLOCK);
1:5c4d5c7:         protected List<Node> children = new ArrayList<>(TOKENS_PER_BLOCK + 1);
1:5c4d5c7:         protected int position = 0;
1:5c4d5c7: 
1:5c4d5c7:         public InteriorNode()
1:5c4d5c7:         {
1:5c4d5c7:             super(null, null);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public boolean isSerializable()
1:5c4d5c7:         {
1:5c4d5c7:             return true;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void serialize(long childBlockIndex, ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             serializeHeader(buf);
1:5c4d5c7:             serializeTokens(buf);
1:5c4d5c7:             serializeChildOffsets(childBlockIndex, buf);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public int childCount()
1:5c4d5c7:         {
1:5c4d5c7:             return children.size();
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public int tokenCount()
1:5c4d5c7:         {
1:5c4d5c7:             return tokens.size();
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public Long smallestToken()
1:5c4d5c7:         {
1:5c4d5c7:             return tokens.get(0);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected void add(Long token, InteriorNode leftChild, InteriorNode rightChild)
1:5c4d5c7:         {
1:5c4d5c7:             int pos = tokens.size();
1:5c4d5c7:             if (pos == TOKENS_PER_BLOCK)
1:5c4d5c7:             {
1:5c4d5c7:                 InteriorNode sibling = split();
1:5c4d5c7:                 sibling.add(token, leftChild, rightChild);
1:5c4d5c7: 
1:5c4d5c7:             }
1:68d2526:             else
1:68d2526:             {
1:5c4d5c7:                 if (leftChild != null)
1:5c4d5c7:                     children.add(pos, leftChild);
1:5c4d5c7: 
1:5c4d5c7:                 if (rightChild != null)
1:5c4d5c7:                 {
1:5c4d5c7:                     children.add(pos + 1, rightChild);
1:5c4d5c7:                     rightChild.parent = this;
1:5c4d5c7:                 }
1:5c4d5c7: 
1:5c4d5c7:                 updateTokenRange(token);
1:5c4d5c7:                 tokens.add(pos, token);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected void add(Leaf node)
1:5c4d5c7:         {
1:5c4d5c7: 
1:5c4d5c7:             if (position == (TOKENS_PER_BLOCK + 1))
1:5c4d5c7:             {
1:5c4d5c7:                 rightmostParent = split();
1:5c4d5c7:                 rightmostParent.add(node);
1:5c4d5c7:             }
1:5c4d5c7:             else
1:5c4d5c7:             {
1:5c4d5c7: 
1:5c4d5c7:                 node.parent = this;
1:5c4d5c7:                 children.add(position, node);
1:5c4d5c7:                 position++;
1:5c4d5c7: 
1:5c4d5c7:                 // the first child is referenced only during bulk load. we don't take a value
1:5c4d5c7:                 // to store into the tree, one is subtracted since position has already been incremented
1:5c4d5c7:                 // for the next node to be added
1:5c4d5c7:                 if (position - 1 == 0)
1:5c4d5c7:                     return;
1:5c4d5c7: 
1:5c4d5c7: 
1:5c4d5c7:                 // tokens are inserted one behind the current position, but 2 is subtracted because
1:5c4d5c7:                 // position has already been incremented for the next add
1:5c4d5c7:                 Long smallestToken = node.smallestToken();
1:5c4d5c7:                 updateTokenRange(smallestToken);
1:5c4d5c7:                 tokens.add(position - 2, smallestToken);
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected InteriorNode split()
1:5c4d5c7:         {
1:5c4d5c7:             Pair<Long, InteriorNode> splitResult = splitBlock();
1:5c4d5c7:             Long middleValue = splitResult.left;
1:5c4d5c7:             InteriorNode sibling = splitResult.right;
1:5c4d5c7:             InteriorNode leftChild = null;
1:5c4d5c7: 
1:5c4d5c7:             // create a new root if necessary
1:5c4d5c7:             if (parent == null)
1:5c4d5c7:             {
1:5c4d5c7:                 parent = new InteriorNode();
1:5c4d5c7:                 root = parent;
1:5c4d5c7:                 sibling.parent = parent;
1:5c4d5c7:                 leftChild = this;
1:5c4d5c7:                 numBlocks++;
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             parent.add(middleValue, leftChild, sibling);
1:5c4d5c7: 
1:5c4d5c7:             return sibling;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected Pair<Long, InteriorNode> splitBlock()
1:5c4d5c7:         {
1:5c4d5c7:             final int splitPosition = TOKENS_PER_BLOCK - 2;
1:5c4d5c7:             InteriorNode sibling = new InteriorNode();
1:5c4d5c7:             sibling.parent = parent;
1:5c4d5c7:             next = sibling;
1:5c4d5c7: 
1:5c4d5c7:             Long middleValue = tokens.get(splitPosition);
1:5c4d5c7: 
1:5c4d5c7:             for (int i = splitPosition; i < TOKENS_PER_BLOCK; i++)
1:5c4d5c7:             {
1:5c4d5c7:                 if (i != TOKENS_PER_BLOCK && i != splitPosition)
1:5c4d5c7:                 {
1:5c4d5c7:                     long token = tokens.get(i);
1:5c4d5c7:                     sibling.updateTokenRange(token);
1:5c4d5c7:                     sibling.tokens.add(token);
1:5c4d5c7:                 }
1:5c4d5c7: 
1:5c4d5c7:                 Node child = children.get(i + 1);
1:5c4d5c7:                 child.parent = sibling;
1:5c4d5c7:                 sibling.children.add(child);
1:5c4d5c7:                 sibling.position++;
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             for (int i = TOKENS_PER_BLOCK; i >= splitPosition; i--)
1:5c4d5c7:             {
1:5c4d5c7:                 if (i != TOKENS_PER_BLOCK)
1:5c4d5c7:                     tokens.remove(i);
1:5c4d5c7: 
1:5c4d5c7:                 if (i != splitPosition)
1:5c4d5c7:                     children.remove(i);
1:5c4d5c7:             }
1:5c4d5c7: 
1:5c4d5c7:             nodeMinToken = smallestToken();
1:5c4d5c7:             nodeMaxToken = tokens.get(tokens.size() - 1);
1:5c4d5c7:             numBlocks++;
1:5c4d5c7: 
1:5c4d5c7:             return Pair.create(middleValue, sibling);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         protected boolean isFull()
1:5c4d5c7:         {
1:5c4d5c7:             return (position >= TOKENS_PER_BLOCK + 1);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         private void serializeTokens(ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             tokens.forEach(buf::putLong);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         private void serializeChildOffsets(long childBlockIndex, ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             for (int i = 0; i < children.size(); i++)
1:5c4d5c7:                 buf.putLong((childBlockIndex + i) * BLOCK_BYTES);
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public static class LevelIterator extends AbstractIterator<Node>
1:5c4d5c7:     {
1:5c4d5c7:         private Node currentNode;
1:5c4d5c7: 
1:5c4d5c7:         LevelIterator(Node first)
1:5c4d5c7:         {
1:5c4d5c7:             currentNode = first;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public Node computeNext()
1:5c4d5c7:         {
1:5c4d5c7:             if (currentNode == null)
1:5c4d5c7:                 return endOfData();
1:5c4d5c7: 
1:5c4d5c7:             Node returnNode = currentNode;
1:5c4d5c7:             currentNode = returnNode.next;
1:5c4d5c7: 
1:5c4d5c7:             return returnNode;
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7: 
1:5c4d5c7:     protected static void alignBuffer(ByteBuffer buffer, int blockSize)
1:5c4d5c7:     {
1:5c4d5c7:         long curPos = buffer.position();
1:5c4d5c7:         if ((curPos & (blockSize - 1)) != 0) // align on the block boundary if needed
1:5c4d5c7:             buffer.position((int) FBUtilities.align(curPos, blockSize));
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7: }
============================================================================
author:Alex Petrov
-------------------------------------------------------------------------------
commit:7d857b4
/////////////////////////////////////////////////////////////////////////
1: import java.util.*;
1: import java.util.function.*;
1: import com.carrotsearch.hppc.LongArrayList;
1: import com.carrotsearch.hppc.cursors.LongCursor;
1: import com.carrotsearch.hppc.cursors.LongObjectCursor;
1: import org.apache.cassandra.dht.*;
/////////////////////////////////////////////////////////////////////////
1:             return BLOCK_HEADER_BYTES + ((int) tokenCount * LEAF_ENTRY_BYTES);
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Tree node,
1:      *
1:      * B+-tree consists of root, interior nodes and leaves. Root can be either a node or a leaf.
1:      *
1:      * Depending on the concrete implementation of {@code TokenTreeBuilder}
1:      * leaf can be partial or static (in case of {@code StaticTokenTreeBuilder} or dynamic in case
1:      * of {@code DynamicTokenTreeBuilder}
1:      */
/////////////////////////////////////////////////////////////////////////
1:         /**
1:          * Shared header part, written for all node types:
1:          *     [  info byte  ] [  token count   ] [ min node token ] [ max node token ]
1:          *     [      1b     ] [    2b (short)  ] [   8b (long)    ] [    8b (long)   ]
1:          **/
1:             /**
1:              * Serializes the shared part of the header
1:              */
/////////////////////////////////////////////////////////////////////////
1:         /**
1:          * In addition to shared header part, root header stores version information,
1:          * overall token count and min/max tokens for the whole tree:
1:          *     [      magic    ] [  overall token count  ] [ min tree token ] [ max tree token ]
1:          *     [   2b (short)  ] [         8b (long)     ] [   8b (long)    ] [    8b (long)   ]
1:          */
/////////////////////////////////////////////////////////////////////////
1:                 return isLeaf() ? ENTRY_TYPE_MASK : 0;
1:                     case ab:
1:                     case ac:
1:                         buf.putShort(AC_MAGIC);
1:                     default:
1:                         throw new RuntimeException("Unsupported version");
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Leaf consists of
1:      *   - header (format described in {@code Header} )
1:      *   - data (format described in {@code LeafEntry})
1:      *   - overflow collision entries, that hold {@value OVERFLOW_TRAILER_CAPACITY} of {@code RowOffset}.
1:      */
/////////////////////////////////////////////////////////////////////////
1:         protected LeafEntry createEntry(final long tok, final KeyOffsets offsets)
1:             LongArrayList rawOffsets = new LongArrayList(offsets.size());
1: 
1:             offsets.forEach(new Consumer<LongObjectCursor<long[]>>()
1:             {
1:                 public void accept(LongObjectCursor<long[]> cursor)
1:                 {
1:                     for (long l : cursor.value)
1:                     {
1:                         rawOffsets.add(cursor.key);
1:                         rawOffsets.add(l);
1:                     }
1:                 }
1:             });
1: 
1:             int offsetCount = rawOffsets.size();
1:                     return new SimpleLeafEntry(tok, rawOffsets.get(0), rawOffsets.get(1));
1:                     assert offsetCount % 2 == 0;
1:                     if (offsetCount == 4)
1:                     {
1:                         if (rawOffsets.get(0) < Integer.MAX_VALUE && rawOffsets.get(1) < Integer.MAX_VALUE &&
1:                             rawOffsets.get(2) < Integer.MAX_VALUE && rawOffsets.get(3) < Integer.MAX_VALUE)
1:                         {
1:                             return new PackedCollisionLeafEntry(tok, (int)rawOffsets.get(0), (int) rawOffsets.get(1),
1:                                                                 (int) rawOffsets.get(2), (int) rawOffsets.get(3));
1:                         }
1:                     }
1:                     return createOverflowEntry(tok, offsetCount, rawOffsets);
1:         private LeafEntry createOverflowEntry(final long tok, final int offsetCount, final LongArrayList offsets)
1:                 overflowCollisions = new LongArrayList(offsetCount);
1:             int overflowCount = (overflowCollisions.size() + offsetCount) / 2;
1:             if (overflowCount >= OVERFLOW_TRAILER_CAPACITY)
1:                 throw new AssertionError("cannot have more than " + OVERFLOW_TRAILER_CAPACITY + " overflow collisions per leaf, but had: " + overflowCount);
1: 
1:             LeafEntry entry = new OverflowCollisionLeafEntry(tok, (short) (overflowCollisions.size() / 2), (short) (offsetCount / 2));
1:             overflowCollisions.addAll(offsets);
1:         /**
1:          * A leaf of the B+-Tree, that holds information about the row offset(s) for
1:          * the current token.
1:          *
1:          * Main 3 types of leaf entries are:
1:          *   1) simple leaf entry: holding just a single row offset
1:          *   2) packed collision leaf entry: holding two entries that would fit together into 168 bytes
1:          *   3) overflow entry: only holds offset in overflow trailer and amount of entries belonging to this leaf
1:          */
1:             public abstract void serialize(ByteBuffer buf);
1:         /**
1:          * Simple leaf, that can store a single row offset, having the following format:
1:          *
1:          *     [    type    ] [   token   ] [ partition offset ] [ row offset ]
1:          *     [ 2b (short) ] [ 8b (long) ] [     8b (long)    ] [  8b (long) ]
1:          */
1:             private final long partitionOffset;
1:             private final long rowOffset;
1:             public SimpleLeafEntry(final long tok, final long partitionOffset, final long rowOffset)
1:                 this.partitionOffset = partitionOffset;
1:                 this.rowOffset = rowOffset;
/////////////////////////////////////////////////////////////////////////
1:             @Override
1:             public void serialize(ByteBuffer buf)
1:                 buf.putShort((short) type().ordinal())
1:                    .putLong(token)
1:                    .putLong(partitionOffset)
1:                    .putLong(rowOffset);
1:         /**
1:          * Packed collision entry, can store two offsets, if each one of their positions
1:          * fit into 4 bytes.
1:          *     [    type    ] [   token   ] [ partition offset 1 ] [ row offset  1] [ partition offset 1 ] [ row offset  1]
1:          *     [ 2b (short) ] [ 8b (long) ] [      4b (int)      ] [    4b (int)  ] [      4b (int)      ] [    4b (int)  ]
1:          */
1:         protected class PackedCollisionLeafEntry extends LeafEntry
1:             private final int partitionOffset1;
1:             private final int rowOffset1;
1:             private final int partitionOffset2;
1:             private final int rowOffset2;
1:             public PackedCollisionLeafEntry(final long tok, final int partitionOffset1, final int rowOffset1,
1:                                             final int partitionOffset2, final int rowOffset2)
1:                 this.partitionOffset1 = partitionOffset1;
1:                 this.rowOffset1 = rowOffset1;
1:                 this.partitionOffset2 = partitionOffset2;
1:                 this.rowOffset2 = rowOffset2;
/////////////////////////////////////////////////////////////////////////
1:             @Override
1:             public void serialize(ByteBuffer buf)
1:                 buf.putShort((short) type().ordinal())
1:                    .putLong(token)
1:                    .putInt(partitionOffset1)
1:                    .putInt(rowOffset1)
1:                    .putInt(partitionOffset2)
1:                    .putInt(rowOffset2);
1:         /**
1:          * Overflow collision entry, holds an entry with three or more offsets, or two offsets
1:          * that cannot be packed into 16 bytes.
1:          *     [    type    ] [   token   ] [ start index ] [    count    ]
1:          *     [ 2b (short) ] [ 8b (long) ] [   8b (long) ] [  8b (long)  ]
1:          *
1:          *   - [ start index ] is a position of first item belonging to this leaf entry in the overflow trailer
1:          *   - [ count ] is the amount of items belonging to this leaf entry that are stored in the overflow trailer
1:          */
/////////////////////////////////////////////////////////////////////////
1:             @Override
1:             public void serialize(ByteBuffer buf)
1:                 buf.putShort((short) type().ordinal())
1:                    .putLong(token)
1:                    .putLong(startIndex)
1:                    .putLong(count);
1:     /**
1:      * Interior node consists of:
1:      *    - (interior node) header
1:      *    - tokens (serialized as longs, with count stored in header)
1:      *    - child offsets
1:      */
author:Dave Brosius
-------------------------------------------------------------------------------
commit:68d2526
/////////////////////////////////////////////////////////////////////////
0:             for (LongCursor o : offsets)
1:             {
/////////////////////////////////////////////////////////////////////////
1:             else
1:             {
author:Jordan West
-------------------------------------------------------------------------------
commit:020dd2d
/////////////////////////////////////////////////////////////////////////
0:                 // exta offset is supposed to be an unsigned 16-bit integer
commit:5c4d5c7
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.cassandra.index.sasi.disk;
1: 
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
0: import java.util.ArrayList;
0: import java.util.Iterator;
0: import java.util.List;
1: 
1: import org.apache.cassandra.io.util.DataOutputPlus;
1: import org.apache.cassandra.utils.AbstractIterator;
1: import org.apache.cassandra.utils.FBUtilities;
1: import org.apache.cassandra.utils.Pair;
1: 
0: import com.carrotsearch.hppc.LongArrayList;
0: import com.carrotsearch.hppc.LongSet;
0: import com.carrotsearch.hppc.cursors.LongCursor;
1: 
1: public abstract class AbstractTokenTreeBuilder implements TokenTreeBuilder
1: {
1:     protected int numBlocks;
1:     protected Node root;
1:     protected InteriorNode rightmostParent;
1:     protected Leaf leftmostLeaf;
1:     protected Leaf rightmostLeaf;
1:     protected long tokenCount = 0;
1:     protected long treeMinToken;
1:     protected long treeMaxToken;
1: 
1:     public void add(TokenTreeBuilder other)
1:     {
1:         add(other.iterator());
1:     }
1: 
1:     public TokenTreeBuilder finish()
1:     {
1:         if (root == null)
1:             constructTree();
1: 
1:         return this;
1:     }
1: 
1:     public long getTokenCount()
1:     {
1:         return tokenCount;
1:     }
1: 
1:     public int serializedSize()
1:     {
1:         if (numBlocks == 1)
0:             return (BLOCK_HEADER_BYTES + ((int) tokenCount * 16));
1:         else
1:             return numBlocks * BLOCK_BYTES;
1:     }
1: 
1:     public void write(DataOutputPlus out) throws IOException
1:     {
1:         ByteBuffer blockBuffer = ByteBuffer.allocate(BLOCK_BYTES);
1:         Iterator<Node> levelIterator = root.levelIterator();
1:         long childBlockIndex = 1;
1: 
1:         while (levelIterator != null)
1:         {
1:             Node firstChild = null;
1:             while (levelIterator.hasNext())
1:             {
1:                 Node block = levelIterator.next();
1: 
1:                 if (firstChild == null && !block.isLeaf())
1:                     firstChild = ((InteriorNode) block).children.get(0);
1: 
1:                 if (block.isSerializable())
1:                 {
1:                     block.serialize(childBlockIndex, blockBuffer);
1:                     flushBuffer(blockBuffer, out, numBlocks != 1);
1:                 }
1: 
1:                 childBlockIndex += block.childCount();
1:             }
1: 
1:             levelIterator = (firstChild == null) ? null : firstChild.levelIterator();
1:         }
1:     }
1: 
1:     protected abstract void constructTree();
1: 
1:     protected void flushBuffer(ByteBuffer buffer, DataOutputPlus o, boolean align) throws IOException
1:     {
1:         // seek to end of last block before flushing
1:         if (align)
1:             alignBuffer(buffer, BLOCK_BYTES);
1: 
1:         buffer.flip();
1:         o.write(buffer);
1:         buffer.clear();
1:     }
1: 
1:     protected abstract class Node
1:     {
1:         protected InteriorNode parent;
1:         protected Node next;
1:         protected Long nodeMinToken, nodeMaxToken;
1: 
1:         public Node(Long minToken, Long maxToken)
1:         {
1:             nodeMinToken = minToken;
1:             nodeMaxToken = maxToken;
1:         }
1: 
1:         public abstract boolean isSerializable();
1:         public abstract void serialize(long childBlockIndex, ByteBuffer buf);
1:         public abstract int childCount();
1:         public abstract int tokenCount();
1: 
1:         public Long smallestToken()
1:         {
1:             return nodeMinToken;
1:         }
1: 
1:         public Long largestToken()
1:         {
1:             return nodeMaxToken;
1:         }
1: 
1:         public Iterator<Node> levelIterator()
1:         {
1:             return new LevelIterator(this);
1:         }
1: 
1:         public boolean isLeaf()
1:         {
1:             return (this instanceof Leaf);
1:         }
1: 
1:         protected boolean isLastLeaf()
1:         {
1:             return this == rightmostLeaf;
1:         }
1: 
1:         protected boolean isRoot()
1:         {
1:             return this == root;
1:         }
1: 
1:         protected void updateTokenRange(long token)
1:         {
1:             nodeMinToken = nodeMinToken == null ? token : Math.min(nodeMinToken, token);
1:             nodeMaxToken = nodeMaxToken == null ? token : Math.max(nodeMaxToken, token);
1:         }
1: 
1:         protected void serializeHeader(ByteBuffer buf)
1:         {
1:             Header header;
1:             if (isRoot())
1:                 header = new RootHeader();
1:             else if (!isLeaf())
1:                 header = new InteriorNodeHeader();
1:             else
1:                 header = new LeafHeader();
1: 
1:             header.serialize(buf);
1:             alignBuffer(buf, BLOCK_HEADER_BYTES);
1:         }
1: 
1:         private abstract class Header
1:         {
1:             public void serialize(ByteBuffer buf)
1:             {
1:                 buf.put(infoByte())
1:                    .putShort((short) (tokenCount()))
1:                    .putLong(nodeMinToken)
1:                    .putLong(nodeMaxToken);
1:             }
1: 
1:             protected abstract byte infoByte();
1:         }
1: 
1:         private class RootHeader extends Header
1:         {
1:             public void serialize(ByteBuffer buf)
1:             {
1:                 super.serialize(buf);
1:                 writeMagic(buf);
1:                 buf.putLong(tokenCount)
1:                    .putLong(treeMinToken)
1:                    .putLong(treeMaxToken);
1:             }
1: 
1:             protected byte infoByte()
1:             {
1:                 // if leaf, set leaf indicator and last leaf indicator (bits 0 & 1)
1:                 // if not leaf, clear both bits
0:                 return (byte) ((isLeaf()) ? 3 : 0);
1:             }
1: 
1:             protected void writeMagic(ByteBuffer buf)
1:             {
1:                 switch (Descriptor.CURRENT_VERSION)
1:                 {
0:                     case Descriptor.VERSION_AB:
1:                         buf.putShort(AB_MAGIC);
1:                         break;
1: 
1:                     default:
1:                         break;
1:                 }
1: 
1:             }
1:         }
1: 
1:         private class InteriorNodeHeader extends Header
1:         {
1:             // bit 0 (leaf indicator) & bit 1 (last leaf indicator) cleared
1:             protected byte infoByte()
1:             {
1:                 return 0;
1:             }
1:         }
1: 
1:         private class LeafHeader extends Header
1:         {
1:             // bit 0 set as leaf indicator
1:             // bit 1 set if this is last leaf of data
1:             protected byte infoByte()
1:             {
1:                 byte infoByte = 1;
1:                 infoByte |= (isLastLeaf()) ? (1 << LAST_LEAF_SHIFT) : 0;
1: 
1:                 return infoByte;
1:             }
1:         }
1: 
1:     }
1: 
1:     protected abstract class Leaf extends Node
1:     {
1:         protected LongArrayList overflowCollisions;
1: 
1:         public Leaf(Long minToken, Long maxToken)
1:         {
1:             super(minToken, maxToken);
1:         }
1: 
1:         public int childCount()
1:         {
1:             return 0;
1:         }
1: 
1:         protected void serializeOverflowCollisions(ByteBuffer buf)
1:         {
1:             if (overflowCollisions != null)
1:                 for (LongCursor offset : overflowCollisions)
1:                     buf.putLong(offset.value);
1:         }
1: 
1:         public void serialize(long childBlockIndex, ByteBuffer buf)
1:         {
1:             serializeHeader(buf);
1:             serializeData(buf);
1:             serializeOverflowCollisions(buf);
1:         }
1: 
1:         protected abstract void serializeData(ByteBuffer buf);
1: 
0:         protected LeafEntry createEntry(final long tok, final LongSet offsets)
1:         {
0:             int offsetCount = offsets.size();
1:             switch (offsetCount)
1:             {
1:                 case 0:
1:                     throw new AssertionError("no offsets for token " + tok);
0:                 case 1:
0:                     long offset = offsets.toArray()[0];
0:                     if (offset > MAX_OFFSET)
0:                         throw new AssertionError("offset " + offset + " cannot be greater than " + MAX_OFFSET);
0:                     else if (offset <= Integer.MAX_VALUE)
0:                         return new SimpleLeafEntry(tok, offset);
1:                     else
0:                         return new FactoredOffsetLeafEntry(tok, offset);
1:                 case 2:
0:                     long[] rawOffsets = offsets.toArray();
0:                     if (rawOffsets[0] <= Integer.MAX_VALUE && rawOffsets[1] <= Integer.MAX_VALUE &&
0:                         (rawOffsets[0] <= Short.MAX_VALUE || rawOffsets[1] <= Short.MAX_VALUE))
0:                         return new PackedCollisionLeafEntry(tok, rawOffsets);
1:                     else
0:                         return createOverflowEntry(tok, offsetCount, offsets);
1:                 default:
0:                     return createOverflowEntry(tok, offsetCount, offsets);
1:             }
1:         }
1: 
0:         private LeafEntry createOverflowEntry(final long tok, final int offsetCount, final LongSet offsets)
1:         {
1:             if (overflowCollisions == null)
0:                 overflowCollisions = new LongArrayList();
1: 
0:             LeafEntry entry = new OverflowCollisionLeafEntry(tok, (short) overflowCollisions.size(), (short) offsetCount);
0:             for (LongCursor o : offsets) {
0:                 if (overflowCollisions.size() == OVERFLOW_TRAILER_CAPACITY)
0:                     throw new AssertionError("cannot have more than " + OVERFLOW_TRAILER_CAPACITY + " overflow collisions per leaf");
1:                 else
0:                     overflowCollisions.add(o.value);
1:             }
1:             return entry;
1:         }
1: 
1:         protected abstract class LeafEntry
1:         {
1:             protected final long token;
1: 
1:             abstract public EntryType type();
0:             abstract public int offsetData();
0:             abstract public short offsetExtra();
1: 
1:             public LeafEntry(final long tok)
1:             {
1:                 token = tok;
1:             }
1: 
1:             public void serialize(ByteBuffer buf)
1:             {
0:                 buf.putShort((short) type().ordinal())
0:                    .putShort(offsetExtra())
0:                    .putLong(token)
0:                    .putInt(offsetData());
1:             }
1: 
1:         }
1: 
1: 
0:         // assumes there is a single offset and the offset is <= Integer.MAX_VALUE
1:         protected class SimpleLeafEntry extends LeafEntry
1:         {
0:             private final long offset;
1: 
0:             public SimpleLeafEntry(final long tok, final long off)
1:             {
1:                 super(tok);
0:                 offset = off;
1:             }
1: 
1:             public EntryType type()
1:             {
1:                 return EntryType.SIMPLE;
1:             }
1: 
0:             public int offsetData()
1:             {
0:                 return (int) offset;
1:             }
1: 
0:             public short offsetExtra()
1:             {
1:                 return 0;
1:             }
1:         }
1: 
0:         // assumes there is a single offset and Integer.MAX_VALUE < offset <= MAX_OFFSET
0:         // take the middle 32 bits of offset (or the top 32 when considering offset is max 48 bits)
0:         // and store where offset is normally stored. take bottom 16 bits of offset and store in entry header
0:         private class FactoredOffsetLeafEntry extends LeafEntry
1:         {
0:             private final long offset;
1: 
0:             public FactoredOffsetLeafEntry(final long tok, final long off)
1:             {
1:                 super(tok);
0:                 offset = off;
1:             }
1: 
1:             public EntryType type()
1:             {
0:                 return EntryType.FACTORED;
1:             }
1: 
0:             public int offsetData()
1:             {
0:                 return (int) (offset >>> Short.SIZE);
1:             }
1: 
0:             public short offsetExtra()
1:             {
0:                 return (short) offset;
1:             }
1:         }
1: 
0:         // holds an entry with two offsets that can be packed in an int & a short
0:         // the int offset is stored where offset is normally stored. short offset is
0:         // stored in entry header
0:         private class PackedCollisionLeafEntry extends LeafEntry
1:         {
0:             private short smallerOffset;
0:             private int largerOffset;
1: 
0:             public PackedCollisionLeafEntry(final long tok, final long[] offs)
1:             {
1:                 super(tok);
1: 
0:                 smallerOffset = (short) Math.min(offs[0], offs[1]);
0:                 largerOffset = (int) Math.max(offs[0], offs[1]);
1:             }
1: 
1:             public EntryType type()
1:             {
1:                 return EntryType.PACKED;
1:             }
1: 
0:             public int offsetData()
1:             {
0:                 return largerOffset;
1:             }
1: 
0:             public short offsetExtra()
1:             {
0:                 return smallerOffset;
1:             }
1:         }
1: 
0:         // holds an entry with three or more offsets, or two offsets that cannot
0:         // be packed into an int & a short. the index into the overflow list
0:         // is stored where the offset is normally stored. the number of overflowed offsets
0:         // for the entry is stored in the entry header
1:         private class OverflowCollisionLeafEntry extends LeafEntry
1:         {
1:             private final short startIndex;
1:             private final short count;
1: 
1:             public OverflowCollisionLeafEntry(final long tok, final short collisionStartIndex, final short collisionCount)
1:             {
1:                 super(tok);
1:                 startIndex = collisionStartIndex;
1:                 count = collisionCount;
1:             }
1: 
1:             public EntryType type()
1:             {
1:                 return EntryType.OVERFLOW;
1:             }
1: 
0:             public int offsetData()
1:             {
0:                 return startIndex;
1:             }
1: 
0:             public short offsetExtra()
1:             {
0:                 return count;
1:             }
1: 
1:         }
1: 
1:     }
1: 
1:     protected class InteriorNode extends Node
1:     {
1:         protected List<Long> tokens = new ArrayList<>(TOKENS_PER_BLOCK);
1:         protected List<Node> children = new ArrayList<>(TOKENS_PER_BLOCK + 1);
1:         protected int position = 0;
1: 
1:         public InteriorNode()
1:         {
1:             super(null, null);
1:         }
1: 
1:         public boolean isSerializable()
1:         {
1:             return true;
1:         }
1: 
1:         public void serialize(long childBlockIndex, ByteBuffer buf)
1:         {
1:             serializeHeader(buf);
1:             serializeTokens(buf);
1:             serializeChildOffsets(childBlockIndex, buf);
1:         }
1: 
1:         public int childCount()
1:         {
1:             return children.size();
1:         }
1: 
1:         public int tokenCount()
1:         {
1:             return tokens.size();
1:         }
1: 
1:         public Long smallestToken()
1:         {
1:             return tokens.get(0);
1:         }
1: 
1:         protected void add(Long token, InteriorNode leftChild, InteriorNode rightChild)
1:         {
1:             int pos = tokens.size();
1:             if (pos == TOKENS_PER_BLOCK)
1:             {
1:                 InteriorNode sibling = split();
1:                 sibling.add(token, leftChild, rightChild);
1: 
1:             }
0:             else {
1:                 if (leftChild != null)
1:                     children.add(pos, leftChild);
1: 
1:                 if (rightChild != null)
1:                 {
1:                     children.add(pos + 1, rightChild);
1:                     rightChild.parent = this;
1:                 }
1: 
1:                 updateTokenRange(token);
1:                 tokens.add(pos, token);
1:             }
1:         }
1: 
1:         protected void add(Leaf node)
1:         {
1: 
1:             if (position == (TOKENS_PER_BLOCK + 1))
1:             {
1:                 rightmostParent = split();
1:                 rightmostParent.add(node);
1:             }
1:             else
1:             {
1: 
1:                 node.parent = this;
1:                 children.add(position, node);
1:                 position++;
1: 
1:                 // the first child is referenced only during bulk load. we don't take a value
1:                 // to store into the tree, one is subtracted since position has already been incremented
1:                 // for the next node to be added
1:                 if (position - 1 == 0)
1:                     return;
1: 
1: 
1:                 // tokens are inserted one behind the current position, but 2 is subtracted because
1:                 // position has already been incremented for the next add
1:                 Long smallestToken = node.smallestToken();
1:                 updateTokenRange(smallestToken);
1:                 tokens.add(position - 2, smallestToken);
1:             }
1: 
1:         }
1: 
1:         protected InteriorNode split()
1:         {
1:             Pair<Long, InteriorNode> splitResult = splitBlock();
1:             Long middleValue = splitResult.left;
1:             InteriorNode sibling = splitResult.right;
1:             InteriorNode leftChild = null;
1: 
1:             // create a new root if necessary
1:             if (parent == null)
1:             {
1:                 parent = new InteriorNode();
1:                 root = parent;
1:                 sibling.parent = parent;
1:                 leftChild = this;
1:                 numBlocks++;
1:             }
1: 
1:             parent.add(middleValue, leftChild, sibling);
1: 
1:             return sibling;
1:         }
1: 
1:         protected Pair<Long, InteriorNode> splitBlock()
1:         {
1:             final int splitPosition = TOKENS_PER_BLOCK - 2;
1:             InteriorNode sibling = new InteriorNode();
1:             sibling.parent = parent;
1:             next = sibling;
1: 
1:             Long middleValue = tokens.get(splitPosition);
1: 
1:             for (int i = splitPosition; i < TOKENS_PER_BLOCK; i++)
1:             {
1:                 if (i != TOKENS_PER_BLOCK && i != splitPosition)
1:                 {
1:                     long token = tokens.get(i);
1:                     sibling.updateTokenRange(token);
1:                     sibling.tokens.add(token);
1:                 }
1: 
1:                 Node child = children.get(i + 1);
1:                 child.parent = sibling;
1:                 sibling.children.add(child);
1:                 sibling.position++;
1:             }
1: 
1:             for (int i = TOKENS_PER_BLOCK; i >= splitPosition; i--)
1:             {
1:                 if (i != TOKENS_PER_BLOCK)
1:                     tokens.remove(i);
1: 
1:                 if (i != splitPosition)
1:                     children.remove(i);
1:             }
1: 
1:             nodeMinToken = smallestToken();
1:             nodeMaxToken = tokens.get(tokens.size() - 1);
1:             numBlocks++;
1: 
1:             return Pair.create(middleValue, sibling);
1:         }
1: 
1:         protected boolean isFull()
1:         {
1:             return (position >= TOKENS_PER_BLOCK + 1);
1:         }
1: 
1:         private void serializeTokens(ByteBuffer buf)
1:         {
1:             tokens.forEach(buf::putLong);
1:         }
1: 
1:         private void serializeChildOffsets(long childBlockIndex, ByteBuffer buf)
1:         {
1:             for (int i = 0; i < children.size(); i++)
1:                 buf.putLong((childBlockIndex + i) * BLOCK_BYTES);
1:         }
1:     }
1: 
1:     public static class LevelIterator extends AbstractIterator<Node>
1:     {
1:         private Node currentNode;
1: 
1:         LevelIterator(Node first)
1:         {
1:             currentNode = first;
1:         }
1: 
1:         public Node computeNext()
1:         {
1:             if (currentNode == null)
1:                 return endOfData();
1: 
1:             Node returnNode = currentNode;
1:             currentNode = returnNode.next;
1: 
1:             return returnNode;
1:         }
1:     }
1: 
1: 
1:     protected static void alignBuffer(ByteBuffer buffer, int blockSize)
1:     {
1:         long curPos = buffer.position();
1:         if ((curPos & (blockSize - 1)) != 0) // align on the block boundary if needed
1:             buffer.position((int) FBUtilities.align(curPos, blockSize));
1:     }
1: 
1: }
============================================================================
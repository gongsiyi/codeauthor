1:3c9538a: /**
1:3c9538a:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:3c9538a:  * contributor license agreements.  See the NOTICE file distributed with
1:3c9538a:  * this work for additional information regarding copyright ownership.
1:3c9538a:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:3c9538a:  * (the "License"); you may not use this file except in compliance with
1:3c9538a:  * the License.  You may obtain a copy of the License at
1:3c9538a:  *
1:3c9538a:  *     http://www.apache.org/licenses/LICENSE-2.0
1:3c9538a:  *
1:3c9538a:  * Unless required by applicable law or agreed to in writing, software
1:3c9538a:  * distributed under the License is distributed on an "AS IS" BASIS,
1:3c9538a:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:3c9538a:  * See the License for the specific language governing permissions and
1:3c9538a:  * limitations under the License.
10:3c9538a:  */
1:3c9538a: package org.apache.mahout.clustering;
5:3c9538a: 
1:3c9538a: import org.apache.mahout.math.Vector;
1:3c9538a: import org.apache.mahout.math.function.SquareRootFunction;
1:3c9538a: 
1:3c9538a: /**
1:28a69a0:  * An online Gaussian statistics accumulator based upon Knuth (who cites Welford) which is declared to be
1:3c9538a:  * numerically-stable. See http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
1:3c9538a:  */
1:3c9538a: public class OnlineGaussianAccumulator implements GaussianAccumulator {
1:3c9538a: 
1:3218e95:   private double sumWeight;
1:3c9538a:   private Vector mean;
1:b588af3:   private Vector s;
1:3c9538a:   private Vector variance;
1:3c9538a: 
1:ebc7393:   @Override
1:3c9538a:   public double getN() {
1:b588af3:     return sumWeight;
2:3c9538a:   }
1:3c9538a: 
1:ebc7393:   @Override
1:3c9538a:   public Vector getMean() {
1:3c9538a:     return mean;
1:3c9538a:   }
1:3c9538a: 
1:ebc7393:   @Override
1:3c9538a:   public Vector getStd() {
1:76059d4:     return variance.clone().assign(new SquareRootFunction());
1:3c9538a:   }
1:3c9538a: 
1:b588af3:   /* from Wikipedia: http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
1:b588af3:    * 
1:b588af3:    * Weighted incremental algorithm
1:b588af3:    * 
1:b588af3:    * def weighted_incremental_variance(dataWeightPairs):
1:b588af3:    * mean = 0
1:b588af3:    * S = 0
1:b588af3:    * sumweight = 0
1:b588af3:    * for x, weight in dataWeightPairs: # Alternately "for x in zip(data, weight):"
1:b588af3:    *     temp = weight + sumweight
1:b588af3:    *     Q = x - mean
1:b588af3:    *      R = Q * weight / temp
1:b588af3:    *      S = S + sumweight * Q * R
1:b588af3:    *      mean = mean + R
1:b588af3:    *      sumweight = temp
1:b588af3:    *  Variance = S / (sumweight-1)  # if sample is the population, omit -1
1:b588af3:    *  return Variance
1:b588af3:    */
1:ebc7393:   @Override
1:b588af3:   public void observe(Vector x, double weight) {
1:b588af3:     double temp = weight + sumWeight;
1:d61a0ee:     Vector q;
1:b588af3:     if (mean == null) {
1:3c9538a:       mean = x.like();
1:d61a0ee:       q = x.clone();
2:3c9538a:     } else {
1:d61a0ee:       q = x.minus(mean);
1:3c9538a:     }
1:d61a0ee:     Vector r = q.times(weight).divide(temp);
1:b588af3:     if (s == null) {
1:d61a0ee:       s = q.times(sumWeight).times(r);
1:b588af3:     } else {
1:d61a0ee:       s = s.plus(q.times(sumWeight).times(r));
1:b588af3:     }
1:d61a0ee:     mean = mean.plus(r);
1:b588af3:     sumWeight = temp;
1:d61a0ee:     variance = s.divide(sumWeight - 1); //  # if sample is the population, omit -1
1:3c9538a:   }
1:b588af3: 
1:ebc7393:   @Override
1:3c9538a:   public void compute() {
1:3c9538a:     // nothing to do here!
1:3c9538a:   }
1:3c9538a: 
1:3c9538a:   @Override
1:3c9538a:   public double getAverageStd() {
1:b588af3:     if (sumWeight == 0.0) {
1:b588af3:       return 0.0;
1:3c9538a:     } else {
1:3c9538a:       Vector std = getStd();
1:3c9538a:       return std.zSum() / std.size();
1:3c9538a:     }
1:3c9538a:   }
1:3c9538a: 
1:3c9538a:   @Override
1:3c9538a:   public Vector getVariance() {
1:3c9538a:     return variance;
1:3c9538a:   }
1:3c9538a: 
1:3c9538a: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:3218e95
/////////////////////////////////////////////////////////////////////////
1:   private double sumWeight;
commit:d61a0ee
/////////////////////////////////////////////////////////////////////////
1:     Vector q;
1:       q = x.clone();
1:       q = x.minus(mean);
1:     Vector r = q.times(weight).divide(temp);
1:       s = q.times(sumWeight).times(r);
1:       s = s.plus(q.times(sumWeight).times(r));
1:     mean = mean.plus(r);
1:     variance = s.divide(sumWeight - 1); //  # if sample is the population, omit -1
commit:b588af3
/////////////////////////////////////////////////////////////////////////
0:   private double sumWeight = 0.0;
1:   private Vector s;
1:     return sumWeight;
/////////////////////////////////////////////////////////////////////////
1:   /* from Wikipedia: http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
1:    * 
1:    * Weighted incremental algorithm
1:    * 
1:    * def weighted_incremental_variance(dataWeightPairs):
1:    * mean = 0
1:    * S = 0
1:    * sumweight = 0
1:    * for x, weight in dataWeightPairs: # Alternately "for x in zip(data, weight):"
1:    *     temp = weight + sumweight
1:    *     Q = x - mean
1:    *      R = Q * weight / temp
1:    *      S = S + sumweight * Q * R
1:    *      mean = mean + R
1:    *      sumweight = temp
1:    *  Variance = S / (sumweight-1)  # if sample is the population, omit -1
1:    *  return Variance
1:    */
1: 
1:   public void observe(Vector x, double weight) {
1:     double temp = weight + sumWeight;
0:     Vector Q;
1:     if (mean == null) {
0:       Q = x.clone();
0:       Q = x.minus(mean);
0:     Vector R = Q.times(weight).divide(temp);
1:     if (s == null) {
0:       s = Q.times(sumWeight).times(R);
1:     } else {
0:       s = s.plus(Q.times(sumWeight).times(R));
1:     }
0:     mean = mean.plus(R);
1:     sumWeight = temp;
0:     variance = s.divide(sumWeight - 1);//  # if sample is the population, omit -1
/////////////////////////////////////////////////////////////////////////
1:     if (sumWeight == 0.0) {
1:       return 0.0;
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
0:   private Vector m2;
/////////////////////////////////////////////////////////////////////////
0:     if (m2 != null) {
0:       m2 = m2.plus(delta.times(x.minus(mean)));
0:       m2 = delta.times(x.minus(mean));
0:     variance = m2.divide(n - 1);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:28a69a0
/////////////////////////////////////////////////////////////////////////
1:  * An online Gaussian statistics accumulator based upon Knuth (who cites Welford) which is declared to be
commit:237bcbd
/////////////////////////////////////////////////////////////////////////
0:   public void observe(Vector x) {
0:     n++;
0:       delta = x.minus(mean);
0:       delta = x.clone();
0:       M2 = M2.plus(delta.times(x.minus(mean)));
0:       M2 = delta.times(x.minus(mean));
commit:76059d4
/////////////////////////////////////////////////////////////////////////
1:     return variance.clone().assign(new SquareRootFunction());
/////////////////////////////////////////////////////////////////////////
commit:ebc7393
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   @Override
1:   @Override
1:   @Override
0:     n += weight;
0:     Vector weightedX = x.times(weight);
0:       delta = weightedX.minus(mean);
0:       delta = weightedX.clone();
0:       M2 = M2.plus(delta.times(weightedX.minus(mean)));
0:       M2 = delta.times(weightedX.minus(mean));
1:   @Override
commit:3c9538a
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.mahout.clustering;
1: 
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.function.SquareRootFunction;
1: 
1: /**
0:  * An online Gaussian statistics accumulator based upon Knuth (who cites Wellford) which is declared to be
1:  * numerically-stable. See http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
0:  * The cited algorithm has been modified to accumulate weighted Vectors
1:  */
1: public class OnlineGaussianAccumulator implements GaussianAccumulator {
0:   private double n = 0;
1: 
1:   private Vector mean;
1: 
0:   private Vector M2;
1: 
1:   private Vector variance;
1: 
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.OnlineGaussianAccumulator#getN()
1:    */
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.GaussianAccumulator#getN()
1:    */
1:   public double getN() {
0:     return n;
1:   }
1: 
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.OnlineGaussianAccumulator#getMean()
1:    */
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.GaussianAccumulator#getMean()
1:    */
1:   public Vector getMean() {
1:     return mean;
1:   }
1: 
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.OnlineGaussianAccumulator#getVariance()
1:    */
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.GaussianAccumulator#getStd()
1:    */
1:   public Vector getStd() {
0:     return variance.assign(new SquareRootFunction());
1:   }
1: 
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.OnlineGaussianAccumulator#observe(org.apache.mahout.math.Vector, double)
1:    */
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.GaussianAccumulator#observe(org.apache.mahout.math.Vector, double)
1:    */
0:   public void observe(Vector x, double weight) {
0:     n = n + weight;
0:     Vector delta;
0:     if (mean != null) {
0:       delta = x.minus(mean);
1:     } else {
1:       mean = x.like();
0:       delta = x.clone();
1:     }
0:     mean = mean.plus(delta.divide(n));
1: 
0:     if (M2 != null) {
0:       M2 = M2.plus(delta.times(x.minus(mean)));
1:     } else {
0:       M2 = delta.times(x.minus(mean));
1:     }
0:     variance = M2.divide(n - 1);
1:   }
1: 
0:   /* (non-Javadoc)
0:    * @see org.apache.mahout.clustering.GaussianAccumulator#compute()
1:    */
1:   public void compute() {
1:     // nothing to do here!
1:   }
1: 
1:   @Override
1:   public double getAverageStd() {
0:     if (n == 0) {
0:       return 0;
1:     } else {
1:       Vector std = getStd();
1:       return std.zSum() / std.size();
1:     }
1:   }
1: 
1:   @Override
1:   public Vector getVariance() {
1:     return variance;
1:   }
1: 
1: }
============================================================================
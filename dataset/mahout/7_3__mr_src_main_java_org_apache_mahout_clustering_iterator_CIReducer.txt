1:3eba6f2: /*
1:564c3e1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:564c3e1:  * contributor license agreements.  See the NOTICE file distributed with
1:564c3e1:  * this work for additional information regarding copyright ownership.
1:564c3e1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:564c3e1:  * (the "License"); you may not use this file except in compliance with
1:564c3e1:  * the License.  You may obtain a copy of the License at
1:3eba6f2:  *
1:564c3e1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:dc637e8:  *
1:564c3e1:  * Unless required by applicable law or agreed to in writing, software
1:564c3e1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:564c3e1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:564c3e1:  * See the License for the specific language governing permissions and
1:564c3e1:  * limitations under the License.
1:3eba6f2:  */
1:dc637e8: 
1:8d102ea: package org.apache.mahout.clustering.iterator;
1:dc637e8: 
1:dc637e8: import java.io.IOException;
1:85f9ece: import java.util.ArrayList;
1:dc637e8: import java.util.Iterator;
1:3eba6f2: import java.util.List;
1:dc637e8: 
1:590ffed: import org.apache.hadoop.conf.Configuration;
1:3eba6f2: import org.apache.hadoop.fs.Path;
1:dc637e8: import org.apache.hadoop.io.IntWritable;
1:dc637e8: import org.apache.hadoop.mapreduce.Reducer;
1:3eba6f2: import org.apache.mahout.clustering.Cluster;
1:3eba6f2: import org.apache.mahout.clustering.classify.ClusterClassifier;
1:dc637e8: 
1:2153bb9: public class CIReducer extends Reducer<IntWritable,ClusterWritable,IntWritable,ClusterWritable> {
1:529b114:   
1:3eba6f2:   private ClusterClassifier classifier;
1:3eba6f2:   private ClusteringPolicy policy;
1:3eba6f2:   
1:dc637e8:   @Override
1:529b114:   protected void reduce(IntWritable key, Iterable<ClusterWritable> values, Context context) throws IOException,
1:529b114:       InterruptedException {
1:529b114:     Iterator<ClusterWritable> iter = values.iterator();
1:2424717:     Cluster first = iter.next().getValue(); // there must always be at least one
1:529b114:     while (iter.hasNext()) {
1:2424717:       Cluster cluster = iter.next().getValue();
1:2424717:       first.observe(cluster);
3:dc637e8:     }
1:85f9ece:     List<Cluster> models = new ArrayList<>();
1:2424717:     models.add(first);
1:3eba6f2:     classifier = new ClusterClassifier(models, policy);
1:3eba6f2:     classifier.close();
1:2424717:     context.write(key, new ClusterWritable(first));
1:dc637e8:   }
1:dc637e8: 
1:3eba6f2:   @Override
1:3eba6f2:   protected void setup(Context context) throws IOException, InterruptedException {
1:590ffed:     Configuration conf = context.getConfiguration();
1:590ffed:     String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
1:3eba6f2:     classifier = new ClusterClassifier();
1:590ffed:     classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
1:3eba6f2:     policy = classifier.getPolicy();
1:3eba6f2:     policy.update(classifier);
1:3eba6f2:     super.setup(context);
1:3eba6f2:   }
1:3eba6f2:   
1:dc637e8: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
/////////////////////////////////////////////////////////////////////////
1:     List<Cluster> models = new ArrayList<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Ted Dunning
-------------------------------------------------------------------------------
commit:402e296
/////////////////////////////////////////////////////////////////////////
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:210b265
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
0:     List<Cluster> models = Lists.newArrayList();
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:2424717
/////////////////////////////////////////////////////////////////////////
1:     Cluster first = iter.next().getValue(); // there must always be at least one
1:       Cluster cluster = iter.next().getValue();
1:       first.observe(cluster);
1:     models.add(first);
1:     context.write(key, new ClusterWritable(first));
commit:590ffed
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = context.getConfiguration();
1:     String priorClustersPath = conf.get(ClusterIterator.PRIOR_PATH_KEY);
1:     classifier.readFromSeqFiles(conf, new Path(priorClustersPath));
commit:3eba6f2
/////////////////////////////////////////////////////////////////////////
0: import java.util.ArrayList;
1: import java.util.List;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.mahout.clustering.Cluster;
1: import org.apache.mahout.clustering.classify.ClusterClassifier;
1:   private ClusterClassifier classifier;
1:   private ClusteringPolicy policy;
1:   
/////////////////////////////////////////////////////////////////////////
0:     List<Cluster> models = new ArrayList<Cluster>();
0:     models.add(first.getValue());
1:     classifier = new ClusterClassifier(models, policy);
1:     classifier.close();
1:   /*
0:    * (non-Javadoc)
1:    * 
0:    * @see
0:    * org.apache.hadoop.mapreduce.Mapper#setup(org.apache.hadoop.mapreduce.Mapper
0:    * .Context)
1:    */
1:   @Override
1:   protected void setup(Context context) throws IOException, InterruptedException {
0:     String priorClustersPath = context.getConfiguration().get(ClusterIterator.PRIOR_PATH_KEY);
1:     classifier = new ClusterClassifier();
0:     classifier.readFromSeqFiles(new Path(priorClustersPath));
1:     policy = classifier.getPolicy();
1:     policy.update(classifier);
1:     super.setup(context);
1:   }
1:   
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.iterator;
commit:529b114
/////////////////////////////////////////////////////////////////////////
1:   
1:   protected void reduce(IntWritable key, Iterable<ClusterWritable> values, Context context) throws IOException,
1:       InterruptedException {
1:     Iterator<ClusterWritable> iter = values.iterator();
1:     while (iter.hasNext()) {
0:       if (first == null) {
commit:2153bb9
/////////////////////////////////////////////////////////////////////////
1: public class CIReducer extends Reducer<IntWritable,ClusterWritable,IntWritable,ClusterWritable> {
0:   protected void reduce(IntWritable key, Iterable<ClusterWritable> values,
0:     Iterator<ClusterWritable> iter =values.iterator();
0:     ClusterWritable first = null;
0:       ClusterWritable cw = iter.next();
0:         first = cw;
0:         first.getValue().observe(cw.getValue());
0:     first.getValue().computeParameters();
commit:dc637e8
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.clustering;
1: 
1: import java.io.IOException;
1: import java.util.Iterator;
1: 
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Reducer;
0: import org.apache.mahout.clustering.Cluster;
1: 
0: public class CIReducer extends Reducer<IntWritable,Cluster,IntWritable,Cluster> {
1:   
0:   /*
0:    * (non-Javadoc)
1:    * 
0:    * @see org.apache.hadoop.mapreduce.Reducer#reduce(java.lang.Object,
0:    * java.lang.Iterable, org.apache.hadoop.mapreduce.Reducer.Context)
0:    */
1:   @Override
0:   protected void reduce(IntWritable key, Iterable<Cluster> values,
0:       Context context) throws IOException, InterruptedException {
0:     Iterator<Cluster> iter =values.iterator();
0:     Cluster first = null;
0:     while(iter.hasNext()){
0:       Cluster cl = iter.next();
0:       if (first == null){
0:         first = cl;
1:       }
0:       else {
0:         first.observe(cl);
1:       }
1:     }
0:     first.computeParameters();
0:     context.write(key, first);
1:   }
1:   
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
0: 
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
0: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
0:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
0:  */
0: 
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:       } else {
============================================================================
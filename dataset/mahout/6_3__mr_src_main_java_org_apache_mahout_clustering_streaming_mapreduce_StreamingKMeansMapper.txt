1:1d6dc49: /*
1:1d6dc49:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:1d6dc49:  * contributor license agreements.  See the NOTICE file distributed with
1:1d6dc49:  * this work for additional information regarding copyright ownership.
1:1d6dc49:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:1d6dc49:  * (the "License"); you may not use this file except in compliance with
1:1d6dc49:  * the License.  You may obtain a copy of the License at
1:1d6dc49:  *
1:1d6dc49:  *     http://www.apache.org/licenses/LICENSE-2.0
1:1d6dc49:  *
1:1d6dc49:  * Unless required by applicable law or agreed to in writing, software
1:1d6dc49:  * distributed under the License is distributed on an "AS IS" BASIS,
1:1d6dc49:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:1d6dc49:  * See the License for the specific language governing permissions and
1:1d6dc49:  * limitations under the License.
1:1d6dc49:  */
1:1d6dc49: 
1:1d6dc49: package org.apache.mahout.clustering.streaming.mapreduce;
1:1d6dc49: 
1:1d6dc49: import java.io.IOException;
1:85f9ece: import java.util.ArrayList;
1:6b6b8a0: import java.util.List;
1:1d6dc49: 
1:1d6dc49: import org.apache.hadoop.conf.Configuration;
1:1d6dc49: import org.apache.hadoop.io.IntWritable;
1:1d6dc49: import org.apache.hadoop.io.Writable;
1:1d6dc49: import org.apache.hadoop.mapreduce.Mapper;
1:6b6b8a0: import org.apache.mahout.clustering.ClusteringUtils;
1:1d6dc49: import org.apache.mahout.clustering.streaming.cluster.StreamingKMeans;
1:1d6dc49: import org.apache.mahout.math.Centroid;
1:1d6dc49: import org.apache.mahout.math.VectorWritable;
1:1d6dc49: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1:1d6dc49: 
1:1d6dc49: public class StreamingKMeansMapper extends Mapper<Writable, VectorWritable, IntWritable, CentroidWritable> {
1:6b6b8a0:   private static final int NUM_ESTIMATE_POINTS = 1000;
1:6b6b8a0: 
1:1d6dc49:   /**
1:1d6dc49:    * The clusterer object used to cluster the points received by this mapper online.
1:1d6dc49:    */
1:1d6dc49:   private StreamingKMeans clusterer;
1:1d6dc49: 
1:1d6dc49:   /**
1:1d6dc49:    * Number of points clustered so far.
1:1d6dc49:    */
1:1d6dc49:   private int numPoints = 0;
1:1d6dc49: 
1:6b6b8a0:   private boolean estimateDistanceCutoff = false;
1:6b6b8a0: 
1:6b6b8a0:   private List<Centroid> estimatePoints;
1:6b6b8a0: 
1:1d6dc49:   @Override
1:1d6dc49:   public void setup(Context context) {
1:1d6dc49:     // At this point the configuration received from the Driver is assumed to be valid.
1:1d6dc49:     // No other checks are made.
1:1d6dc49:     Configuration conf = context.getConfiguration();
1:1d6dc49:     UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);
1:1d6dc49:     int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);
1:6b6b8a0:     double estimatedDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF,
1:6b6b8a0:         StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);
1:6b6b8a0:     if (estimatedDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
1:6b6b8a0:       estimateDistanceCutoff = true;
1:85f9ece:       estimatePoints = new ArrayList<>();
1:6b6b8a0:     }
1:1d6dc49:     // There is no way of estimating the distance cutoff unless we have some data.
1:6b6b8a0:     clusterer = new StreamingKMeans(searcher, numClusters, estimatedDistanceCutoff);
1:6b6b8a0:   }
1:6b6b8a0: 
1:6b6b8a0:   private void clusterEstimatePoints() {
1:6b6b8a0:     clusterer.setDistanceCutoff(ClusteringUtils.estimateDistanceCutoff(
1:6b6b8a0:         estimatePoints, clusterer.getDistanceMeasure()));
1:6b6b8a0:     clusterer.cluster(estimatePoints);
1:6b6b8a0:     estimateDistanceCutoff = false;
2:1d6dc49:   }
1:1d6dc49: 
1:1d6dc49:   @Override
1:1d6dc49:   public void map(Writable key, VectorWritable point, Context context) {
1:6b6b8a0:     Centroid centroid = new Centroid(numPoints++, point.get(), 1);
1:6b6b8a0:     if (estimateDistanceCutoff) {
1:6b6b8a0:       if (numPoints < NUM_ESTIMATE_POINTS) {
1:6b6b8a0:         estimatePoints.add(centroid);
1:6b6b8a0:       } else if (numPoints == NUM_ESTIMATE_POINTS) {
1:6b6b8a0:         clusterEstimatePoints();
1:6a8cfcd:       }
1:6b6b8a0:     } else {
1:6b6b8a0:       clusterer.cluster(centroid);
1:6b6b8a0:     }
1:6b6b8a0:   }
1:1d6dc49: 
1:1d6dc49:   @Override
1:1d6dc49:   public void cleanup(Context context) throws IOException, InterruptedException {
1:6b6b8a0:     // We should cluster the points at the end if they haven't yet been clustered.
1:6b6b8a0:     if (estimateDistanceCutoff) {
1:6b6b8a0:       clusterEstimatePoints();
1:6b6b8a0:     }
1:1d6dc49:     // Reindex the centroids before passing them to the reducer.
1:1d6dc49:     clusterer.reindexCentroids();
1:1d6dc49:     // All outputs have the same key to go to the same final reducer.
1:1d6dc49:     for (Centroid centroid : clusterer) {
1:1d6dc49:       context.write(new IntWritable(0), new CentroidWritable(centroid));
1:1d6dc49:     }
1:1d6dc49:   }
1:1d6dc49: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
/////////////////////////////////////////////////////////////////////////
1:       estimatePoints = new ArrayList<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:6a8cfcd
/////////////////////////////////////////////////////////////////////////
1:       }
author:dfilimon
-------------------------------------------------------------------------------
commit:6b6b8a0
/////////////////////////////////////////////////////////////////////////
1: import java.util.List;
0: import com.google.common.collect.Lists;
1: import org.apache.mahout.clustering.ClusteringUtils;
1:   private static final int NUM_ESTIMATE_POINTS = 1000;
1: 
/////////////////////////////////////////////////////////////////////////
1:   private boolean estimateDistanceCutoff = false;
1: 
1:   private List<Centroid> estimatePoints;
1: 
/////////////////////////////////////////////////////////////////////////
1:     double estimatedDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF,
1:         StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);
1:     if (estimatedDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
1:       estimateDistanceCutoff = true;
0:       estimatePoints = Lists.newArrayList();
1:     }
1:     clusterer = new StreamingKMeans(searcher, numClusters, estimatedDistanceCutoff);
1:   }
1: 
1:   private void clusterEstimatePoints() {
1:     clusterer.setDistanceCutoff(ClusteringUtils.estimateDistanceCutoff(
1:         estimatePoints, clusterer.getDistanceMeasure()));
1:     clusterer.cluster(estimatePoints);
1:     estimateDistanceCutoff = false;
1:     Centroid centroid = new Centroid(numPoints++, point.get(), 1);
1:     if (estimateDistanceCutoff) {
1:       if (numPoints < NUM_ESTIMATE_POINTS) {
1:         estimatePoints.add(centroid);
1:       } else if (numPoints == NUM_ESTIMATE_POINTS) {
1:         clusterEstimatePoints();
1:   }
1:     } else {
1:       clusterer.cluster(centroid);
1:     }
1:     // We should cluster the points at the end if they haven't yet been clustered.
1:     if (estimateDistanceCutoff) {
1:       clusterEstimatePoints();
1:     }
commit:1d6dc49
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.clustering.streaming.mapreduce;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.Writable;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.mahout.clustering.streaming.cluster.StreamingKMeans;
1: import org.apache.mahout.math.Centroid;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1: 
1: public class StreamingKMeansMapper extends Mapper<Writable, VectorWritable, IntWritable, CentroidWritable> {
1:   /**
1:    * The clusterer object used to cluster the points received by this mapper online.
1:    */
1:   private StreamingKMeans clusterer;
1: 
1:   /**
1:    * Number of points clustered so far.
1:    */
1:   private int numPoints = 0;
1: 
1:   @Override
1:   public void setup(Context context) {
1:     // At this point the configuration received from the Driver is assumed to be valid.
1:     // No other checks are made.
1:     Configuration conf = context.getConfiguration();
1:     UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);
1:     int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);
1:     // There is no way of estimating the distance cutoff unless we have some data.
0:     clusterer = new StreamingKMeans(searcher, numClusters,
0:         conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF, 1e-4f));
1:   }
1: 
1:   @Override
1:   public void map(Writable key, VectorWritable point, Context context) {
0:     clusterer.cluster(new Centroid(numPoints++, point.get().clone(), 1));
1:   }
1: 
1:   @Override
1:   public void cleanup(Context context) throws IOException, InterruptedException {
1:     // Reindex the centroids before passing them to the reducer.
1:     clusterer.reindexCentroids();
1:     // All outputs have the same key to go to the same final reducer.
1:     for (Centroid centroid : clusterer) {
1:       context.write(new IntWritable(0), new CentroidWritable(centroid));
1:     }
1:   }
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
0:         conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF, 1.0e-4f));
============================================================================
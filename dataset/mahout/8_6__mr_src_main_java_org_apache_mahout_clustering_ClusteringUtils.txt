1:e70534f: /**
1:e70534f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:e70534f:  * contributor license agreements.  See the NOTICE file distributed with
1:e70534f:  * this work for additional information regarding copyright ownership.
1:e70534f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:e70534f:  * (the "License"); you may not use this file except in compliance with
1:e70534f:  * the License.  You may obtain a copy of the License at
1:e70534f:  *
1:e70534f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:e70534f:  *
1:e70534f:  * Unless required by applicable law or agreed to in writing, software
1:e70534f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:e70534f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:e70534f:  * See the License for the specific language governing permissions and
1:e70534f:  * limitations under the License.
1:e70534f:  */
1:e70534f: 
1:fd24254: package org.apache.mahout.clustering;
1:fd24254: 
1:85f9ece: import java.util.ArrayList;
1:fd24254: import java.util.List;
1:fd24254: 
1:fd24254: import com.google.common.base.Preconditions;
1:fd24254: import com.google.common.collect.Iterables;
1:fd24254: import com.google.common.collect.Lists;
1:fd24254: import org.apache.mahout.common.distance.DistanceMeasure;
1:fd24254: import org.apache.mahout.common.distance.EuclideanDistanceMeasure;
1:fd24254: import org.apache.mahout.math.Centroid;
1:fd24254: import org.apache.mahout.math.DenseMatrix;
1:fd24254: import org.apache.mahout.math.Matrix;
1:fd24254: import org.apache.mahout.math.Vector;
1:fd24254: import org.apache.mahout.math.WeightedVector;
1:fd24254: import org.apache.mahout.math.neighborhood.BruteSearch;
1:fd24254: import org.apache.mahout.math.neighborhood.ProjectionSearch;
1:fd24254: import org.apache.mahout.math.neighborhood.Searcher;
1:fd24254: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1:fd24254: import org.apache.mahout.math.random.WeightedThing;
1:fd24254: import org.apache.mahout.math.stats.OnlineSummarizer;
1:fd24254: 
1:4ca6b86: public final class ClusteringUtils {
1:4ca6b86:   private ClusteringUtils() {
1:4ca6b86:   }
1:4ca6b86: 
1:fd24254:   /**
1:fd24254:    * Computes the summaries for the distances in each cluster.
1:fd24254:    * @param datapoints iterable of datapoints.
1:fd24254:    * @param centroids iterable of Centroids.
1:fd24254:    * @return a list of OnlineSummarizers where the i-th element is the summarizer corresponding to the cluster whose
1:fd24254:    * index is i.
1:fd24254:    */
1:fd24254:   public static List<OnlineSummarizer> summarizeClusterDistances(Iterable<? extends Vector> datapoints,
1:fd24254:                                                                  Iterable<? extends Vector> centroids,
1:fd24254:                                                                  DistanceMeasure distanceMeasure) {
1:fd24254:     UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);
1:fd24254:     searcher.addAll(centroids);
1:85f9ece:     List<OnlineSummarizer> summarizers = new ArrayList<>();
1:fd24254:     if (searcher.size() == 0) {
1:fd24254:       return summarizers;
1:fd24254:     }
1:fd24254:     for (int i = 0; i < searcher.size(); ++i) {
1:fd24254:       summarizers.add(new OnlineSummarizer());
1:fd24254:     }
1:fd24254:     for (Vector v : datapoints) {
1:fd24254:       Centroid closest = (Centroid)searcher.search(v,  1).get(0).getValue();
1:fd24254:       OnlineSummarizer summarizer = summarizers.get(closest.getIndex());
1:fd24254:       summarizer.add(distanceMeasure.distance(v, closest));
1:fd24254:     }
1:fd24254:     return summarizers;
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Adds up the distances from each point to its closest cluster and returns the sum.
1:fd24254:    * @param datapoints iterable of datapoints.
1:fd24254:    * @param centroids iterable of Centroids.
1:fd24254:    * @return the total cost described above.
1:fd24254:    */
1:fd24254:   public static double totalClusterCost(Iterable<? extends Vector> datapoints, Iterable<? extends Vector> centroids) {
1:fd24254:     DistanceMeasure distanceMeasure = new EuclideanDistanceMeasure();
1:fd24254:     UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);
1:fd24254:     searcher.addAll(centroids);
1:fd24254:     return totalClusterCost(datapoints, searcher);
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Adds up the distances from each point to its closest cluster and returns the sum.
1:fd24254:    * @param datapoints iterable of datapoints.
1:fd24254:    * @param centroids searcher of Centroids.
1:fd24254:    * @return the total cost described above.
1:fd24254:    */
1:fd24254:   public static double totalClusterCost(Iterable<? extends Vector> datapoints, Searcher centroids) {
1:fd24254:     double totalCost = 0;
1:fd24254:     for (Vector vector : datapoints) {
1:f09ea54:       totalCost += centroids.searchFirst(vector, false).getWeight();
1:fd24254:     }
1:fd24254:     return totalCost;
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Estimates the distance cutoff. In StreamingKMeans, the distance between two vectors divided
1:fd24254:    * by this value is used as a probability threshold when deciding whether to form a new cluster
1:fd24254:    * or not.
1:fd24254:    * Small values (comparable to the minimum distance between two points) are preferred as they
1:fd24254:    * guarantee with high likelihood that all but very close points are put in separate clusters
1:fd24254:    * initially. The clusters themselves are actually collapsed periodically when their number goes
1:fd24254:    * over the maximum number of clusters and the distanceCutoff is increased.
1:fd24254:    * So, the returned value is only an initial estimate.
1:fd24254:    * @param data the datapoints whose distance is to be estimated.
1:fd24254:    * @param distanceMeasure the distance measure used to compute the distance between two points.
1:fd24254:    * @return the minimum distance between the first sampleLimit points
1:fd24254:    * @see org.apache.mahout.clustering.streaming.cluster.StreamingKMeans#clusterInternal(Iterable, boolean)
1:fd24254:    */
1:6b6b8a0:   public static double estimateDistanceCutoff(List<? extends Vector> data, DistanceMeasure distanceMeasure) {
1:6b6b8a0:     BruteSearch searcher = new BruteSearch(distanceMeasure);
1:6b6b8a0:     searcher.addAll(data);
1:fd24254:     double minDistance = Double.POSITIVE_INFINITY;
1:6b6b8a0:     for (Vector vector : data) {
1:6b6b8a0:       double closest = searcher.searchFirst(vector, true).getWeight();
1:6b6b8a0:       if (minDistance > 0 && closest < minDistance) {
1:fd24254:         minDistance = closest;
1:fd24254:       }
1:fd24254:       searcher.add(vector);
1:fd24254:     }
1:fd24254:     return minDistance;
1:fd24254:   }
1:fd24254: 
1:91f15ec:   public static <T extends Vector> double estimateDistanceCutoff(
1:91f15ec:       Iterable<T> data, DistanceMeasure distanceMeasure, int sampleLimit) {
1:6b6b8a0:     return estimateDistanceCutoff(Lists.newArrayList(Iterables.limit(data, sampleLimit)), distanceMeasure);
1:6b6b8a0:   }
1:6b6b8a0: 
1:fd24254:   /**
1:fd24254:    * Computes the Davies-Bouldin Index for a given clustering.
1:fd24254:    * See http://en.wikipedia.org/wiki/Clustering_algorithm#Internal_evaluation
1:fd24254:    * @param centroids list of centroids
1:fd24254:    * @param distanceMeasure distance measure for inter-cluster distances
1:fd24254:    * @param clusterDistanceSummaries summaries of the clusters; See summarizeClusterDistances
1:fd24254:    * @return the Davies-Bouldin Index
1:fd24254:    */
1:fd24254:   public static double daviesBouldinIndex(List<? extends Vector> centroids, DistanceMeasure distanceMeasure,
1:fd24254:                                           List<OnlineSummarizer> clusterDistanceSummaries) {
1:fd24254:     Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(),
1:fd24254:         "Number of centroids and cluster summaries differ.");
1:fd24254:     int n = centroids.size();
1:fd24254:     double totalDBIndex = 0;
1:fd24254:     // The inner loop shouldn't be reduced for j = i + 1 to n because the computation of the Davies-Bouldin
1:fd24254:     // index is not really symmetric.
1:fd24254:     // For a given cluster i, we look for a cluster j that maximizes the ratio of the sum of average distances
1:fd24254:     // from points in cluster i to its center and and points in cluster j to its center to the distance between
1:fd24254:     // cluster i and cluster j.
1:fd24254:     // The maximization is the key issue, as the cluster that maximizes this ratio might be j for i but is NOT
1:fd24254:     // NECESSARILY i for j.
1:fd24254:     for (int i = 0; i < n; ++i) {
1:fd24254:       double averageDistanceI = clusterDistanceSummaries.get(i).getMean();
1:fd24254:       double maxDBIndex = 0;
1:fd24254:       for (int j = 0; j < n; ++j) {
1:fd24254:         if (i != j) {
1:58cc1ae:           double dbIndex = (averageDistanceI + clusterDistanceSummaries.get(j).getMean())
1:58cc1ae:               / distanceMeasure.distance(centroids.get(i), centroids.get(j));
1:fd24254:           if (dbIndex > maxDBIndex) {
1:fd24254:             maxDBIndex = dbIndex;
1:fd24254:           }
1:fd24254:         }
1:fd24254:       }
1:fd24254:       totalDBIndex += maxDBIndex;
1:fd24254:     }
1:fd24254:     return totalDBIndex / n;
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Computes the Dunn Index of a given clustering. See http://en.wikipedia.org/wiki/Dunn_index
1:fd24254:    * @param centroids list of centroids
1:fd24254:    * @param distanceMeasure distance measure to compute inter-centroid distance with
1:fd24254:    * @param clusterDistanceSummaries summaries of the clusters; See summarizeClusterDistances
1:fd24254:    * @return the Dunn Index
1:fd24254:    */
1:fd24254:   public static double dunnIndex(List<? extends Vector> centroids, DistanceMeasure distanceMeasure,
1:fd24254:                                  List<OnlineSummarizer> clusterDistanceSummaries) {
1:fd24254:     Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(),
1:fd24254:         "Number of centroids and cluster summaries differ.");
1:fd24254:     int n = centroids.size();
1:fd24254:     // Intra-cluster distances will come from the OnlineSummarizer, and will be the median distance (noting that
1:fd24254:     // the median for just one value is that value).
1:fd24254:     // A variety of metrics can be used for the intra-cluster distance including max distance between two points,
1:fd24254:     // mean distance, etc. Median distance was chosen as this is more robust to outliers and characterizes the
1:fd24254:     // distribution of distances (from a point to the center) better.
1:fd24254:     double maxIntraClusterDistance = 0;
1:fd24254:     for (OnlineSummarizer summarizer : clusterDistanceSummaries) {
1:fd24254:       if (summarizer.getCount() > 0) {
1:fd24254:         double intraClusterDistance;
1:fd24254:         if (summarizer.getCount() == 1) {
1:fd24254:           intraClusterDistance = summarizer.getMean();
1:fd24254:         } else {
1:fd24254:           intraClusterDistance = summarizer.getMedian();
1:fd24254:         }
1:fd24254:         if (maxIntraClusterDistance < intraClusterDistance) {
1:fd24254:           maxIntraClusterDistance = intraClusterDistance;
1:fd24254:         }
1:fd24254:       }
1:fd24254:     }
1:fd24254:     double minDunnIndex = Double.POSITIVE_INFINITY;
1:fd24254:     for (int i = 0; i < n; ++i) {
1:fd24254:       // Distances are symmetric, so d(i, j) = d(j, i).
1:fd24254:       for (int j = i + 1; j < n; ++j) {
1:fd24254:         double dunnIndex = distanceMeasure.distance(centroids.get(i), centroids.get(j));
1:fd24254:         if (minDunnIndex > dunnIndex) {
1:fd24254:           minDunnIndex = dunnIndex;
1:fd24254:         }
1:fd24254:       }
1:fd24254:     }
1:fd24254:     return minDunnIndex / maxIntraClusterDistance;
1:fd24254:   }
1:fd24254: 
1:fd24254:   public static double choose2(double n) {
1:fd24254:     return n * (n - 1) / 2;
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Creates a confusion matrix by searching for the closest cluster of both the row clustering and column clustering
1:fd24254:    * of a point and adding its weight to that cell of the matrix.
1:fd24254:    * It doesn't matter which clustering is the row clustering and which is the column clustering. If they're
1:fd24254:    * interchanged, the resulting matrix is the transpose of the original one.
1:fd24254:    * @param rowCentroids clustering one
1:fd24254:    * @param columnCentroids clustering two
1:fd24254:    * @param datapoints datapoints whose closest cluster we need to find
1:fd24254:    * @param distanceMeasure distance measure to use
1:fd24254:    * @return the confusion matrix
1:fd24254:    */
1:fd24254:   public static Matrix getConfusionMatrix(List<? extends Vector> rowCentroids, List<? extends  Vector> columnCentroids,
1:fd24254:                                           Iterable<? extends Vector> datapoints, DistanceMeasure distanceMeasure) {
1:fd24254:     Searcher rowSearcher = new BruteSearch(distanceMeasure);
1:fd24254:     rowSearcher.addAll(rowCentroids);
1:fd24254:     Searcher columnSearcher = new BruteSearch(distanceMeasure);
1:fd24254:     columnSearcher.addAll(columnCentroids);
1:fd24254: 
1:fd24254:     int numRows = rowCentroids.size();
1:fd24254:     int numCols = columnCentroids.size();
1:fd24254:     Matrix confusionMatrix = new DenseMatrix(numRows, numCols);
1:fd24254: 
1:fd24254:     for (Vector vector : datapoints) {
1:fd24254:       WeightedThing<Vector> closestRowCentroid = rowSearcher.search(vector, 1).get(0);
1:fd24254:       WeightedThing<Vector> closestColumnCentroid = columnSearcher.search(vector, 1).get(0);
1:fd24254:       int row = ((Centroid) closestRowCentroid.getValue()).getIndex();
1:fd24254:       int column = ((Centroid) closestColumnCentroid.getValue()).getIndex();
1:fd24254:       double vectorWeight;
1:fd24254:       if (vector instanceof WeightedVector) {
1:fd24254:         vectorWeight = ((WeightedVector) vector).getWeight();
1:fd24254:       } else {
1:fd24254:         vectorWeight = 1;
1:fd24254:       }
1:fd24254:       confusionMatrix.set(row, column, confusionMatrix.get(row, column) + vectorWeight);
1:fd24254:     }
1:fd24254: 
1:fd24254:     return confusionMatrix;
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Computes the Adjusted Rand Index for a given confusion matrix.
1:fd24254:    * @param confusionMatrix confusion matrix; not to be confused with the more restrictive ConfusionMatrix class
1:fd24254:    * @return the Adjusted Rand Index
1:fd24254:    */
1:fd24254:   public static double getAdjustedRandIndex(Matrix confusionMatrix) {
1:fd24254:     int numRows = confusionMatrix.numRows();
1:fd24254:     int numCols = confusionMatrix.numCols();
1:fd24254:     double rowChoiceSum = 0;
1:6b6b8a0:     double columnChoiceSum = 0;
1:fd24254:     double totalChoiceSum = 0;
1:fd24254:     double total = 0;
1:fd24254:     for (int i = 0; i < numRows; ++i) {
1:fd24254:       double rowSum = 0;
1:fd24254:       for (int j = 0; j < numCols; ++j) {
1:fd24254:         rowSum += confusionMatrix.get(i, j);
1:fd24254:         totalChoiceSum += choose2(confusionMatrix.get(i, j));
1:fd24254:       }
1:fd24254:       total += rowSum;
1:fd24254:       rowChoiceSum += choose2(rowSum);
1:fd24254:     }
1:fd24254:     for (int j = 0; j < numCols; ++j) {
1:fd24254:       double columnSum = 0;
1:fd24254:       for (int i = 0; i < numRows; ++i) {
1:fd24254:         columnSum += confusionMatrix.get(i, j);
1:fd24254:       }
1:fd24254:       columnChoiceSum += choose2(columnSum);
1:fd24254:     }
1:fd24254:     double rowColumnChoiceSumDivTotal = rowChoiceSum * columnChoiceSum / choose2(total);
1:fd24254:     return (totalChoiceSum - rowColumnChoiceSumDivTotal)
1:fd24254:         / ((rowChoiceSum + columnChoiceSum) / 2 - rowColumnChoiceSumDivTotal);
1:fd24254:   }
1:fd24254: 
1:fd24254:   /**
1:fd24254:    * Computes the total weight of the points in the given Vector iterable.
1:fd24254:    * @param data iterable of points
1:fd24254:    * @return total weight
1:fd24254:    */
1:fd24254:   public static double totalWeight(Iterable<? extends Vector> data) {
1:fd24254:     double sum = 0;
1:fd24254:     for (Vector row : data) {
1:fd24254:       Preconditions.checkNotNull(row);
1:fd24254:       if (row instanceof WeightedVector) {
1:fd24254:         sum += ((WeightedVector)row).getWeight();
1:fd24254:       } else {
1:fd24254:         sum++;
1:fd24254:       }
1:fd24254:     }
1:fd24254:     return sum;
1:fd24254:   }
1:fd24254: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
/////////////////////////////////////////////////////////////////////////
1:     List<OnlineSummarizer> summarizers = new ArrayList<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Sean Owen
-------------------------------------------------------------------------------
commit:91f15ec
/////////////////////////////////////////////////////////////////////////
1:   public static <T extends Vector> double estimateDistanceCutoff(
1:       Iterable<T> data, DistanceMeasure distanceMeasure, int sampleLimit) {
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:e70534f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
author:dfilimon
-------------------------------------------------------------------------------
commit:6b6b8a0
/////////////////////////////////////////////////////////////////////////
1:   public static double estimateDistanceCutoff(List<? extends Vector> data, DistanceMeasure distanceMeasure) {
1:     BruteSearch searcher = new BruteSearch(distanceMeasure);
1:     searcher.addAll(data);
1:     for (Vector vector : data) {
1:       double closest = searcher.searchFirst(vector, true).getWeight();
1:       if (minDistance > 0 && closest < minDistance) {
/////////////////////////////////////////////////////////////////////////
0:   public static double estimateDistanceCutoff(Iterable<? extends Vector> data, DistanceMeasure distanceMeasure,
0:                                               int sampleLimit) {
1:     return estimateDistanceCutoff(Lists.newArrayList(Iterables.limit(data, sampleLimit)), distanceMeasure);
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     double columnChoiceSum = 0;
/////////////////////////////////////////////////////////////////////////
commit:f09ea54
/////////////////////////////////////////////////////////////////////////
1:       totalCost += centroids.searchFirst(vector, false).getWeight();
commit:fd24254
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering;
1: 
1: import java.util.List;
1: 
1: import com.google.common.base.Preconditions;
1: import com.google.common.collect.Iterables;
1: import com.google.common.collect.Lists;
1: import org.apache.mahout.common.distance.DistanceMeasure;
1: import org.apache.mahout.common.distance.EuclideanDistanceMeasure;
1: import org.apache.mahout.math.Centroid;
1: import org.apache.mahout.math.DenseMatrix;
1: import org.apache.mahout.math.Matrix;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.WeightedVector;
1: import org.apache.mahout.math.neighborhood.BruteSearch;
1: import org.apache.mahout.math.neighborhood.ProjectionSearch;
1: import org.apache.mahout.math.neighborhood.Searcher;
1: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1: import org.apache.mahout.math.random.WeightedThing;
1: import org.apache.mahout.math.stats.OnlineSummarizer;
1: 
0: public class ClusteringUtils {
1:   /**
1:    * Computes the summaries for the distances in each cluster.
1:    * @param datapoints iterable of datapoints.
1:    * @param centroids iterable of Centroids.
1:    * @return a list of OnlineSummarizers where the i-th element is the summarizer corresponding to the cluster whose
1:    * index is i.
1:    */
1:   public static List<OnlineSummarizer> summarizeClusterDistances(Iterable<? extends Vector> datapoints,
1:                                                                  Iterable<? extends Vector> centroids,
1:                                                                  DistanceMeasure distanceMeasure) {
1:     UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);
1:     searcher.addAll(centroids);
0:     List<OnlineSummarizer> summarizers = Lists.newArrayList();
1:     if (searcher.size() == 0) {
1:       return summarizers;
1:     }
1:     for (int i = 0; i < searcher.size(); ++i) {
1:       summarizers.add(new OnlineSummarizer());
1:     }
1:     for (Vector v : datapoints) {
1:       Centroid closest = (Centroid)searcher.search(v,  1).get(0).getValue();
1:       OnlineSummarizer summarizer = summarizers.get(closest.getIndex());
1:       summarizer.add(distanceMeasure.distance(v, closest));
1:     }
1:     return summarizers;
1:   }
1: 
1:   /**
1:    * Adds up the distances from each point to its closest cluster and returns the sum.
1:    * @param datapoints iterable of datapoints.
1:    * @param centroids iterable of Centroids.
1:    * @return the total cost described above.
1:    */
1:   public static double totalClusterCost(Iterable<? extends Vector> datapoints, Iterable<? extends Vector> centroids) {
1:     DistanceMeasure distanceMeasure = new EuclideanDistanceMeasure();
1:     UpdatableSearcher searcher = new ProjectionSearch(distanceMeasure, 3, 1);
1:     searcher.addAll(centroids);
1:     return totalClusterCost(datapoints, searcher);
1:   }
1: 
1:   /**
1:    * Adds up the distances from each point to its closest cluster and returns the sum.
1:    * @param datapoints iterable of datapoints.
1:    * @param centroids searcher of Centroids.
1:    * @return the total cost described above.
1:    */
1:   public static double totalClusterCost(Iterable<? extends Vector> datapoints, Searcher centroids) {
1:     double totalCost = 0;
1:     for (Vector vector : datapoints) {
0:       Centroid closest = (Centroid) centroids.searchFirst(vector, false).getValue();
0:       totalCost += closest.getWeight();
1:     }
1:     return totalCost;
1:   }
1: 
1:   /**
1:    * Estimates the distance cutoff. In StreamingKMeans, the distance between two vectors divided
1:    * by this value is used as a probability threshold when deciding whether to form a new cluster
1:    * or not.
1:    * Small values (comparable to the minimum distance between two points) are preferred as they
1:    * guarantee with high likelihood that all but very close points are put in separate clusters
1:    * initially. The clusters themselves are actually collapsed periodically when their number goes
1:    * over the maximum number of clusters and the distanceCutoff is increased.
1:    * So, the returned value is only an initial estimate.
1:    * @param data the datapoints whose distance is to be estimated.
1:    * @param distanceMeasure the distance measure used to compute the distance between two points.
1:    * @return the minimum distance between the first sampleLimit points
1:    * @see org.apache.mahout.clustering.streaming.cluster.StreamingKMeans#clusterInternal(Iterable, boolean)
1:    */
0:   public static double estimateDistanceCutoff(Iterable<? extends Vector> data,
0:                                               DistanceMeasure distanceMeasure, int sampleLimit) {
0:     Iterable<? extends Vector> limitedData = Iterables.limit(data, sampleLimit);
0:     ProjectionSearch searcher = new ProjectionSearch(distanceMeasure, 3, 1);
0:     searcher.add(limitedData.iterator().next());
1:     double minDistance = Double.POSITIVE_INFINITY;
0:     for (Vector vector : Iterables.skip(limitedData, 1)) {
0:       double closest = searcher.searchFirst(vector, false).getWeight();
0:       if (closest < minDistance) {
1:         minDistance = closest;
1:       }
1:       searcher.add(vector);
1:     }
1:     return minDistance;
1:   }
1: 
1:   /**
1:    * Computes the Davies-Bouldin Index for a given clustering.
1:    * See http://en.wikipedia.org/wiki/Clustering_algorithm#Internal_evaluation
1:    * @param centroids list of centroids
1:    * @param distanceMeasure distance measure for inter-cluster distances
1:    * @param clusterDistanceSummaries summaries of the clusters; See summarizeClusterDistances
1:    * @return the Davies-Bouldin Index
1:    */
1:   public static double daviesBouldinIndex(List<? extends Vector> centroids, DistanceMeasure distanceMeasure,
1:                                           List<OnlineSummarizer> clusterDistanceSummaries) {
1:     Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(),
1:         "Number of centroids and cluster summaries differ.");
1:     int n = centroids.size();
1:     double totalDBIndex = 0;
1:     // The inner loop shouldn't be reduced for j = i + 1 to n because the computation of the Davies-Bouldin
1:     // index is not really symmetric.
1:     // For a given cluster i, we look for a cluster j that maximizes the ratio of the sum of average distances
1:     // from points in cluster i to its center and and points in cluster j to its center to the distance between
1:     // cluster i and cluster j.
1:     // The maximization is the key issue, as the cluster that maximizes this ratio might be j for i but is NOT
1:     // NECESSARILY i for j.
1:     for (int i = 0; i < n; ++i) {
1:       double averageDistanceI = clusterDistanceSummaries.get(i).getMean();
1:       double maxDBIndex = 0;
1:       for (int j = 0; j < n; ++j) {
1:         if (i != j) {
0:           double dbIndex = (averageDistanceI + clusterDistanceSummaries.get(j).getMean()) /
0:               distanceMeasure.distance(centroids.get(i), centroids.get(j));
1:           if (dbIndex > maxDBIndex) {
1:             maxDBIndex = dbIndex;
1:           }
1:         }
1:       }
1:       totalDBIndex += maxDBIndex;
1:     }
1:     return totalDBIndex / n;
1:   }
1: 
1:   /**
1:    * Computes the Dunn Index of a given clustering. See http://en.wikipedia.org/wiki/Dunn_index
1:    * @param centroids list of centroids
1:    * @param distanceMeasure distance measure to compute inter-centroid distance with
1:    * @param clusterDistanceSummaries summaries of the clusters; See summarizeClusterDistances
1:    * @return the Dunn Index
1:    */
1:   public static double dunnIndex(List<? extends Vector> centroids, DistanceMeasure distanceMeasure,
1:                                  List<OnlineSummarizer> clusterDistanceSummaries) {
1:     Preconditions.checkArgument(centroids.size() == clusterDistanceSummaries.size(),
1:         "Number of centroids and cluster summaries differ.");
1:     int n = centroids.size();
1:     // Intra-cluster distances will come from the OnlineSummarizer, and will be the median distance (noting that
1:     // the median for just one value is that value).
1:     // A variety of metrics can be used for the intra-cluster distance including max distance between two points,
1:     // mean distance, etc. Median distance was chosen as this is more robust to outliers and characterizes the
1:     // distribution of distances (from a point to the center) better.
1:     double maxIntraClusterDistance = 0;
1:     for (OnlineSummarizer summarizer : clusterDistanceSummaries) {
1:       if (summarizer.getCount() > 0) {
1:         double intraClusterDistance;
1:         if (summarizer.getCount() == 1) {
1:           intraClusterDistance = summarizer.getMean();
1:         } else {
1:           intraClusterDistance = summarizer.getMedian();
1:         }
1:         if (maxIntraClusterDistance < intraClusterDistance) {
1:           maxIntraClusterDistance = intraClusterDistance;
1:         }
1:       }
1:     }
1:     double minDunnIndex = Double.POSITIVE_INFINITY;
1:     for (int i = 0; i < n; ++i) {
1:       // Distances are symmetric, so d(i, j) = d(j, i).
1:       for (int j = i + 1; j < n; ++j) {
1:         double dunnIndex = distanceMeasure.distance(centroids.get(i), centroids.get(j));
1:         if (minDunnIndex > dunnIndex) {
1:           minDunnIndex = dunnIndex;
1:         }
1:       }
1:     }
1:     return minDunnIndex / maxIntraClusterDistance;
1:   }
1: 
1:   public static double choose2(double n) {
1:     return n * (n - 1) / 2;
1:   }
1: 
1:   /**
1:    * Creates a confusion matrix by searching for the closest cluster of both the row clustering and column clustering
1:    * of a point and adding its weight to that cell of the matrix.
1:    * It doesn't matter which clustering is the row clustering and which is the column clustering. If they're
1:    * interchanged, the resulting matrix is the transpose of the original one.
1:    * @param rowCentroids clustering one
1:    * @param columnCentroids clustering two
1:    * @param datapoints datapoints whose closest cluster we need to find
1:    * @param distanceMeasure distance measure to use
1:    * @return the confusion matrix
1:    */
1:   public static Matrix getConfusionMatrix(List<? extends Vector> rowCentroids, List<? extends  Vector> columnCentroids,
1:                                           Iterable<? extends Vector> datapoints, DistanceMeasure distanceMeasure) {
1:     Searcher rowSearcher = new BruteSearch(distanceMeasure);
1:     rowSearcher.addAll(rowCentroids);
1:     Searcher columnSearcher = new BruteSearch(distanceMeasure);
1:     columnSearcher.addAll(columnCentroids);
1: 
1:     int numRows = rowCentroids.size();
1:     int numCols = columnCentroids.size();
1:     Matrix confusionMatrix = new DenseMatrix(numRows, numCols);
1: 
1:     for (Vector vector : datapoints) {
1:       WeightedThing<Vector> closestRowCentroid = rowSearcher.search(vector, 1).get(0);
1:       WeightedThing<Vector> closestColumnCentroid = columnSearcher.search(vector, 1).get(0);
1:       int row = ((Centroid) closestRowCentroid.getValue()).getIndex();
1:       int column = ((Centroid) closestColumnCentroid.getValue()).getIndex();
1:       double vectorWeight;
1:       if (vector instanceof WeightedVector) {
1:         vectorWeight = ((WeightedVector) vector).getWeight();
1:       } else {
1:         vectorWeight = 1;
1:       }
1:       confusionMatrix.set(row, column, confusionMatrix.get(row, column) + vectorWeight);
1:     }
1: 
1:     return confusionMatrix;
1:   }
1: 
1:   /**
1:    * Computes the Adjusted Rand Index for a given confusion matrix.
1:    * @param confusionMatrix confusion matrix; not to be confused with the more restrictive ConfusionMatrix class
1:    * @return the Adjusted Rand Index
1:    */
1:   public static double getAdjustedRandIndex(Matrix confusionMatrix) {
1:     int numRows = confusionMatrix.numRows();
1:     int numCols = confusionMatrix.numCols();
1:     double rowChoiceSum = 0;
0:     double columnChoiceSum = 0;
1:     double totalChoiceSum = 0;
1:     double total = 0;
1:     for (int i = 0; i < numRows; ++i) {
1:       double rowSum = 0;
1:       for (int j = 0; j < numCols; ++j) {
1:         rowSum += confusionMatrix.get(i, j);
1:         totalChoiceSum += choose2(confusionMatrix.get(i, j));
1:       }
1:       total += rowSum;
1:       rowChoiceSum += choose2(rowSum);
1:     }
1:     for (int j = 0; j < numCols; ++j) {
1:       double columnSum = 0;
1:       for (int i = 0; i < numRows; ++i) {
1:         columnSum += confusionMatrix.get(i, j);
1:       }
1:       columnChoiceSum += choose2(columnSum);
1:     }
1:     double rowColumnChoiceSumDivTotal = rowChoiceSum * columnChoiceSum / choose2(total);
1:     return (totalChoiceSum - rowColumnChoiceSumDivTotal)
1:         / ((rowChoiceSum + columnChoiceSum) / 2 - rowColumnChoiceSumDivTotal);
1:   }
1: 
1:   /**
1:    * Computes the total weight of the points in the given Vector iterable.
1:    * @param data iterable of points
1:    * @return total weight
1:    */
1:   public static double totalWeight(Iterable<? extends Vector> data) {
1:     double sum = 0;
1:     for (Vector row : data) {
1:       Preconditions.checkNotNull(row);
1:       if (row instanceof WeightedVector) {
1:         sum += ((WeightedVector)row).getWeight();
1:       } else {
1:         sum++;
1:       }
1:     }
1:     return sum;
1:   }
1: }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1:           double dbIndex = (averageDistanceI + clusterDistanceSummaries.get(j).getMean())
1:               / distanceMeasure.distance(centroids.get(i), centroids.get(j));
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
1: public final class ClusteringUtils {
1:   private ClusteringUtils() {
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     double columnChoiceSum = 0;
============================================================================
1:175701c: /**
1:175701c:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:175701c:  * contributor license agreements. See the NOTICE file distributed with this
1:175701c:  * work for additional information regarding copyright ownership. The ASF
1:175701c:  * licenses this file to You under the Apache License, Version 2.0 (the
1:175701c:  * "License"); you may not use this file except in compliance with the License.
1:175701c:  * You may obtain a copy of the License at
1:175701c:  *
1:175701c:  * http://www.apache.org/licenses/LICENSE-2.0
1:175701c:  *
1:175701c:  * Unless required by applicable law or agreed to in writing, software
1:175701c:  * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
1:175701c:  * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
1:175701c:  * License for the specific language governing permissions and limitations under
1:175701c:  * the License.
1:175701c:  */
1:175701c: 
1:175701c: package org.apache.mahout.math.hadoop;
1:175701c: 
1:175701c: import java.io.IOException;
1:175701c: 
1:175701c: import org.apache.hadoop.conf.Configuration;
1:175701c: import org.apache.hadoop.fs.Path;
1:175701c: import org.apache.hadoop.io.IntWritable;
1:175701c: import org.apache.hadoop.io.NullWritable;
1:03e6875: import org.apache.hadoop.io.Writable;
1:175701c: import org.apache.hadoop.mapreduce.Job;
1:175701c: import org.apache.hadoop.mapreduce.Mapper;
1:175701c: import org.apache.hadoop.mapreduce.Reducer;
1:175701c: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:175701c: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:175701c: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:175701c: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:229aeff: import org.apache.mahout.common.ClassUtils;
1:175701c: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
1:175701c: import org.apache.mahout.math.DenseVector;
1:175701c: import org.apache.mahout.math.Vector;
1:175701c: import org.apache.mahout.math.VectorWritable;
1:175701c: import org.apache.mahout.math.function.Functions;
1:175701c: 
1:175701c: import com.google.common.io.Closeables;
1:175701c: 
1:175701c: /**
1:175701c:  * MatrixColumnMeansJob is a job for calculating the column-wise mean of a
1:175701c:  * DistributedRowMatrix. This job can be accessed using
1:175701c:  * DistributedRowMatrix.columnMeans()
1:175701c:  */
1:229aeff: public final class MatrixColumnMeansJob {
1:175701c: 
1:175701c:   public static final String VECTOR_CLASS =
1:175701c:     "DistributedRowMatrix.columnMeans.vector.class";
1:175701c: 
1:229aeff:   private MatrixColumnMeansJob() {
1:229aeff:   }
1:229aeff: 
1:175701c:   public static Vector run(Configuration conf,
1:175701c:                            Path inputPath,
1:175701c:                            Path outputVectorTmpPath) throws IOException {
1:03e6875:     return run(conf, inputPath, outputVectorTmpPath, null);
4:175701c:   }
1:175701c: 
1:175701c:   /**
1:175701c:    * Job for calculating column-wise mean of a DistributedRowMatrix
1:175701c:    *
1:175701c:    * @param initialConf
1:175701c:    * @param inputPath
1:175701c:    *          path to DistributedRowMatrix input
1:229aeff:    * @param outputVectorTmpPath
1:175701c:    *          path for temporary files created during job
1:175701c:    * @param vectorClass
1:175701c:    *          String of desired class for returned vector e.g. DenseVector,
1:175701c:    *          RandomAccessSparseVector (may be null for {@link DenseVector} )
1:175701c:    * @return Vector containing column-wise mean of DistributedRowMatrix
1:175701c:    */
1:175701c:   public static Vector run(Configuration initialConf,
1:175701c:                            Path inputPath,
1:175701c:                            Path outputVectorTmpPath,
1:175701c:                            String vectorClass) throws IOException {
1:175701c: 
3:175701c:     try {
1:175701c:       initialConf.set(VECTOR_CLASS,
1:175701c:                       vectorClass == null ? DenseVector.class.getName()
1:175701c:                           : vectorClass);
1:175701c: 
1:03e6875:       Job job = new Job(initialConf, "MatrixColumnMeansJob");
1:03e6875:       job.setJarByClass(MatrixColumnMeansJob.class);
1:175701c: 
1:03e6875:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1:03e6875:       
1:175701c:       outputVectorTmpPath.getFileSystem(job.getConfiguration())
1:175701c:                          .delete(outputVectorTmpPath, true);
1:175701c:       job.setNumReduceTasks(1);
1:175701c:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1:175701c:       FileInputFormat.addInputPath(job, inputPath);
1:175701c:       job.setInputFormatClass(SequenceFileInputFormat.class);
1:175701c:       job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:175701c:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1:175701c: 
1:175701c:       job.setMapperClass(MatrixColumnMeansMapper.class);
1:175701c:       job.setReducerClass(MatrixColumnMeansReducer.class);
1:175701c:       job.setMapOutputKeyClass(NullWritable.class);
1:175701c:       job.setMapOutputValueClass(VectorWritable.class);
1:175701c:       job.setOutputKeyClass(IntWritable.class);
1:175701c:       job.setOutputValueClass(VectorWritable.class);
1:175701c:       job.submit();
1:175701c:       job.waitForCompletion(true);
1:175701c: 
1:175701c:       Path tmpFile = new Path(outputVectorTmpPath, "part-r-00000");
1:175701c:       SequenceFileValueIterator<VectorWritable> iterator =
1:87c15be:         new SequenceFileValueIterator<>(tmpFile, true, initialConf);
1:175701c:       try {
1:175701c:         if (iterator.hasNext()) {
1:175701c:           return iterator.next().get();
1:229aeff:         } else {
1:175701c:           return (Vector) Class.forName(vectorClass).getConstructor(int.class)
2:175701c:                                .newInstance(0);
1:175701c:         }
1:175701c:       } finally {
1:31cb292:         Closeables.close(iterator, true);
1:175701c:       }
1:4ca6b86:     } catch (IOException ioe) {
1:4ca6b86:       throw ioe;
1:175701c:     } catch (Throwable thr) {
1:4ca6b86:       throw new IOException(thr);
1:229aeff:     }
1:175701c:   }
1:175701c: 
1:175701c:   /**
1:175701c:    * Mapper for calculation of column-wise mean.
1:175701c:    */
1:175701c:   public static class MatrixColumnMeansMapper extends
1:03e6875:       Mapper<Writable, VectorWritable, NullWritable, VectorWritable> {
1:175701c: 
1:229aeff:     private Vector runningSum;
1:229aeff:     private String vectorClass;
1:175701c: 
1:175701c:     @Override
1:175701c:     public void setup(Context context) {
1:175701c:       vectorClass = context.getConfiguration().get(VECTOR_CLASS);
1:175701c:     }
1:175701c: 
1:175701c:     /**
1:175701c:      * The mapper computes a running sum of the vectors the task has seen.
1:175701c:      * Element 0 of the running sum vector contains a count of the number of
1:175701c:      * vectors that have been seen. The remaining elements contain the
1:175701c:      * column-wise running sum. Nothing is written at this stage
1:175701c:      */
1:175701c:     @Override
1:03e6875:     public void map(Writable r, VectorWritable v, Context context)
1:175701c:       throws IOException {
1:175701c:       if (runningSum == null) {
1:175701c:           /*
1:175701c:            * If this is the first vector the mapper has seen, instantiate a new
1:175701c:            * vector using the parameter VECTOR_CLASS
1:175701c:            */
1:229aeff:         runningSum = ClassUtils.instantiateAs(vectorClass,
1:229aeff:                                               Vector.class,
1:229aeff:                                               new Class<?>[] { int.class },
1:229aeff:                                               new Object[] { v.get().size() + 1 });
1:175701c:         runningSum.set(0, 1);
1:175701c:         runningSum.viewPart(1, v.get().size()).assign(v.get());
2:175701c:       } else {
1:175701c:         runningSum.set(0, runningSum.get(0) + 1);
1:175701c:         runningSum.viewPart(1, v.get().size()).assign(v.get(), Functions.PLUS);
1:175701c:       }
1:175701c:     }
1:175701c: 
1:175701c:     /**
1:175701c:      * The column-wise sum is written at the cleanup stage. A single reducer is
1:175701c:      * forced so null can be used for the key
1:175701c:      */
1:175701c:     @Override
1:175701c:     public void cleanup(Context context) throws InterruptedException,
1:175701c:       IOException {
1:175701c:       if (runningSum != null) {
1:175701c:         context.write(NullWritable.get(), new VectorWritable(runningSum));
1:175701c:       }
1:175701c:     }
1:175701c: 
1:175701c:   }
1:175701c: 
1:175701c:   /**
1:175701c:    * The reducer adds the partial column-wise sums from each of the mappers to
1:175701c:    * compute the total column-wise sum. The total sum is then divided by the
1:175701c:    * total count of vectors to determine the column-wise mean.
1:175701c:    */
1:175701c:   public static class MatrixColumnMeansReducer extends
1:175701c:       Reducer<NullWritable, VectorWritable, IntWritable, VectorWritable> {
1:175701c: 
1:229aeff:     private static final IntWritable ONE = new IntWritable(1);
1:229aeff: 
1:229aeff:     private String vectorClass;
1:335a993:     private Vector outputVector;
1:335a993:     private final VectorWritable outputVectorWritable = new VectorWritable();
1:175701c: 
1:175701c:     @Override
1:175701c:     public void setup(Context context) {
1:175701c:       vectorClass = context.getConfiguration().get(VECTOR_CLASS);
1:175701c:     }
1:175701c: 
1:175701c:     @Override
1:175701c:     public void reduce(NullWritable n,
1:175701c:                        Iterable<VectorWritable> vectors,
1:229aeff:                        Context context) throws IOException, InterruptedException {
1:175701c: 
1:175701c:       /**
1:175701c:        * Add together partial column-wise sums from mappers
1:175701c:        */
1:175701c:       for (VectorWritable v : vectors) {
1:175701c:         if (outputVector == null) {
1:175701c:           outputVector = v.get();
1:175701c:         } else {
1:175701c:           outputVector.assign(v.get(), Functions.PLUS);
1:175701c:         }
1:175701c:       }
1:175701c: 
1:175701c:       /**
1:175701c:        * Divide total column-wise sum by count of vectors, which corresponds to
1:175701c:        * the number of rows in the DistributedRowMatrix
1:175701c:        */
1:175701c:       if (outputVector != null) {
1:175701c:         outputVectorWritable.set(outputVector.viewPart(1,
1:175701c:                                                        outputVector.size() - 1)
1:175701c:                                              .divide(outputVector.get(0)));
1:229aeff:         context.write(ONE, outputVectorWritable);
1:175701c:       } else {
1:229aeff:         Vector emptyVector = ClassUtils.instantiateAs(vectorClass,
1:229aeff:                                                       Vector.class,
1:229aeff:                                                       new Class<?>[] { int.class },
1:229aeff:                                                       new Object[] { 0 });
1:229aeff:         context.write(ONE, new VectorWritable(emptyVector));
1:175701c:       }
1:175701c:     }
1:175701c:   }
1:175701c: 
1:175701c: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:87c15be
/////////////////////////////////////////////////////////////////////////
1:         new SequenceFileValueIterator<>(tmpFile, true, initialConf);
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:335a993
/////////////////////////////////////////////////////////////////////////
1:     private Vector outputVector;
1:     private final VectorWritable outputVectorWritable = new VectorWritable();
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
1:     } catch (IOException ioe) {
1:       throw ioe;
1:       throw new IOException(thr);
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.ClassUtils;
/////////////////////////////////////////////////////////////////////////
1: public final class MatrixColumnMeansJob {
1:   private MatrixColumnMeansJob() {
1:   }
1: 
0:     return run(conf, inputPath, outputVectorTmpPath, VECTOR_CLASS);
/////////////////////////////////////////////////////////////////////////
1:    * @param outputVectorTmpPath
/////////////////////////////////////////////////////////////////////////
0:       if (thr instanceof IOException) {
1:       } else {
1:       }
/////////////////////////////////////////////////////////////////////////
1:     private Vector runningSum;
1:     private String vectorClass;
/////////////////////////////////////////////////////////////////////////
1:         runningSum = ClassUtils.instantiateAs(vectorClass,
1:                                               Vector.class,
1:                                               new Class<?>[] { int.class },
1:                                               new Object[] { v.get().size() + 1 });
/////////////////////////////////////////////////////////////////////////
1:     private static final IntWritable ONE = new IntWritable(1);
1: 
1:     private String vectorClass;
0:     Vector outputVector;
/////////////////////////////////////////////////////////////////////////
1:                        Context context) throws IOException, InterruptedException {
/////////////////////////////////////////////////////////////////////////
1:         context.write(ONE, outputVectorWritable);
1:         Vector emptyVector = ClassUtils.instantiateAs(vectorClass,
1:                                                       Vector.class,
1:                                                       new Class<?>[] { int.class },
1:                                                       new Object[] { 0 });
1:         context.write(ONE, new VectorWritable(emptyVector));
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
1:         Closeables.close(iterator, true);
author:Dmitriy Lyubimov
-------------------------------------------------------------------------------
commit:03e6875
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.io.Writable;
/////////////////////////////////////////////////////////////////////////
1:     return run(conf, inputPath, outputVectorTmpPath, null);
/////////////////////////////////////////////////////////////////////////
1:       Job job = new Job(initialConf, "MatrixColumnMeansJob");
1:       job.setJarByClass(MatrixColumnMeansJob.class);
1:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1:       
/////////////////////////////////////////////////////////////////////////
0:         new SequenceFileValueIterator<VectorWritable>(tmpFile, true, initialConf);
/////////////////////////////////////////////////////////////////////////
1:       Mapper<Writable, VectorWritable, NullWritable, VectorWritable> {
/////////////////////////////////////////////////////////////////////////
1:     public void map(Writable r, VectorWritable v, Context context)
commit:175701c
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements. See the NOTICE file distributed with this
1:  * work for additional information regarding copyright ownership. The ASF
1:  * licenses this file to You under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance with the License.
1:  * You may obtain a copy of the License at
1:  *
1:  * http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
1:  * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
1:  * License for the specific language governing permissions and limitations under
1:  * the License.
1:  */
1: 
1: package org.apache.mahout.math.hadoop;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.NullWritable;
0: import org.apache.hadoop.mapred.JobConf;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.Reducer;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.function.Functions;
1: 
1: import com.google.common.io.Closeables;
1: 
1: /**
1:  * MatrixColumnMeansJob is a job for calculating the column-wise mean of a
1:  * DistributedRowMatrix. This job can be accessed using
1:  * DistributedRowMatrix.columnMeans()
1:  */
0: public class MatrixColumnMeansJob {
1: 
1:   public static final String VECTOR_CLASS =
1:     "DistributedRowMatrix.columnMeans.vector.class";
1: 
1:   public static Vector run(Configuration conf,
1:                            Path inputPath,
1:                            Path outputVectorTmpPath) throws IOException {
0:     return run(conf, inputPath, outputVectorTmpPath);
1:   }
1: 
1:   /**
1:    * Job for calculating column-wise mean of a DistributedRowMatrix
1:    *
1:    * @param initialConf
1:    * @param inputPath
1:    *          path to DistributedRowMatrix input
0:    * @param tmpPath
1:    *          path for temporary files created during job
1:    * @param vectorClass
1:    *          String of desired class for returned vector e.g. DenseVector,
1:    *          RandomAccessSparseVector (may be null for {@link DenseVector} )
1:    * @return Vector containing column-wise mean of DistributedRowMatrix
1:    */
1:   public static Vector run(Configuration initialConf,
1:                            Path inputPath,
1:                            Path outputVectorTmpPath,
1:                            String vectorClass) throws IOException {
1: 
1:     try {
1:       initialConf.set(VECTOR_CLASS,
1:                       vectorClass == null ? DenseVector.class.getName()
1:                           : vectorClass);
1: 
0:       @SuppressWarnings("deprecation")
0:       JobConf oldApiConf = new JobConf(initialConf);
1: 
0:       org.apache.hadoop.mapred.FileOutputFormat.setOutputPath(oldApiConf,
0:                                                               outputVectorTmpPath);
0:       Job job = new Job(initialConf);
1:       outputVectorTmpPath.getFileSystem(job.getConfiguration())
1:                          .delete(outputVectorTmpPath, true);
1:       job.setNumReduceTasks(1);
1:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1:       FileInputFormat.addInputPath(job, inputPath);
1:       job.setInputFormatClass(SequenceFileInputFormat.class);
1:       job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:       FileOutputFormat.setOutputPath(job, outputVectorTmpPath);
1: 
1:       job.setMapperClass(MatrixColumnMeansMapper.class);
1:       job.setReducerClass(MatrixColumnMeansReducer.class);
1:       job.setMapOutputKeyClass(NullWritable.class);
1:       job.setMapOutputValueClass(VectorWritable.class);
1:       job.setOutputKeyClass(IntWritable.class);
1:       job.setOutputValueClass(VectorWritable.class);
1:       job.submit();
1:       job.waitForCompletion(true);
1: 
1:       Path tmpFile = new Path(outputVectorTmpPath, "part-r-00000");
1:       SequenceFileValueIterator<VectorWritable> iterator =
0:         new SequenceFileValueIterator<VectorWritable>(tmpFile, true, oldApiConf);
1:       try {
1:         if (iterator.hasNext()) {
1:           return iterator.next().get();
1:         } else {
1:           return (Vector) Class.forName(vectorClass).getConstructor(int.class)
1:                                .newInstance(0);
1:         }
1:       } finally {
0:         Closeables.closeQuietly(iterator);
1:       }
1:     } catch (Throwable thr) {
0:       if (thr instanceof IOException)
0:         throw (IOException) thr;
0:       else
0:         throw new IOException(thr);
1:     }
1:   }
1: 
1:   /**
1:    * Mapper for calculation of column-wise mean.
1:    */
1:   public static class MatrixColumnMeansMapper extends
0:       Mapper<IntWritable, VectorWritable, NullWritable, VectorWritable> {
1: 
0:     private Vector runningSum = null;
0:     private String vectorClass = null;
1: 
1:     @Override
1:     public void setup(Context context) {
1:       vectorClass = context.getConfiguration().get(VECTOR_CLASS);
1:     }
1: 
1:     /**
1:      * The mapper computes a running sum of the vectors the task has seen.
1:      * Element 0 of the running sum vector contains a count of the number of
1:      * vectors that have been seen. The remaining elements contain the
1:      * column-wise running sum. Nothing is written at this stage
1:      */
1:     @Override
0:     public void map(IntWritable r, VectorWritable v, Context context)
1:       throws IOException {
1:       if (runningSum == null) {
1:         try {
1:           /*
1:            * If this is the first vector the mapper has seen, instantiate a new
1:            * vector using the parameter VECTOR_CLASS
1:            */
0:           runningSum =
0:             (Vector) Class.forName(vectorClass).getConstructor(int.class)
0:                           .newInstance(v.get().size() + 1);
0:         } catch (Exception e) {
0:           e.printStackTrace();
1:         }
1:         runningSum.set(0, 1);
1:         runningSum.viewPart(1, v.get().size()).assign(v.get());
1:       } else {
1:         runningSum.set(0, runningSum.get(0) + 1);
1:         runningSum.viewPart(1, v.get().size()).assign(v.get(), Functions.PLUS);
1:       }
1:     }
1: 
1:     /**
1:      * The column-wise sum is written at the cleanup stage. A single reducer is
1:      * forced so null can be used for the key
1:      */
1:     @Override
1:     public void cleanup(Context context) throws InterruptedException,
1:       IOException {
1:       if (runningSum != null) {
1:         context.write(NullWritable.get(), new VectorWritable(runningSum));
1:       }
1:     }
1: 
1:   }
1: 
1:   /**
1:    * The reducer adds the partial column-wise sums from each of the mappers to
1:    * compute the total column-wise sum. The total sum is then divided by the
1:    * total count of vectors to determine the column-wise mean.
1:    */
1:   public static class MatrixColumnMeansReducer extends
1:       Reducer<NullWritable, VectorWritable, IntWritable, VectorWritable> {
1: 
0:     private static final IntWritable one = new IntWritable(1);
0:     private String vectorClass = null;
0:     Vector outputVector = null;
0:     VectorWritable outputVectorWritable = new VectorWritable();
1: 
1:     @Override
1:     public void setup(Context context) {
1:       vectorClass = context.getConfiguration().get(VECTOR_CLASS);
1:     }
1: 
1:     @Override
1:     public void reduce(NullWritable n,
1:                        Iterable<VectorWritable> vectors,
0:                        Context context) throws IOException,
0:       InterruptedException {
1: 
1:       /**
1:        * Add together partial column-wise sums from mappers
1:        */
1:       for (VectorWritable v : vectors) {
1:         if (outputVector == null) {
1:           outputVector = v.get();
1:         } else {
1:           outputVector.assign(v.get(), Functions.PLUS);
1:         }
1:       }
1: 
1:       /**
1:        * Divide total column-wise sum by count of vectors, which corresponds to
1:        * the number of rows in the DistributedRowMatrix
1:        */
1:       if (outputVector != null) {
1:         outputVectorWritable.set(outputVector.viewPart(1,
1:                                                        outputVector.size() - 1)
1:                                              .divide(outputVector.get(0)));
0:         context.write(one, outputVectorWritable);
1:       } else {
1:         try {
0:           Vector emptyVector =
0:             (Vector) Class.forName(vectorClass).getConstructor(int.class)
1:                           .newInstance(0);
0:           context.write(one, new VectorWritable(emptyVector));
0:         } catch (Exception e) {
0:           e.printStackTrace();
1:         }
1:       }
1:     }
1:   }
1: 
1: }
============================================================================
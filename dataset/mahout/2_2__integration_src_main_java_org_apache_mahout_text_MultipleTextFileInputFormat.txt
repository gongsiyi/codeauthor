1:d711ac1: /**
1:d711ac1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:d711ac1:  * contributor license agreements.  See the NOTICE file distributed with
1:d711ac1:  * this work for additional information regarding copyright ownership.
1:d711ac1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:d711ac1:  * (the "License"); you may not use this file except in compliance with
1:d711ac1:  * the License.  You may obtain a copy of the License at
1:d711ac1:  *
1:d711ac1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:d711ac1:  *
1:d711ac1:  * Unless required by applicable law or agreed to in writing, software
1:d711ac1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:d711ac1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:d711ac1:  * See the License for the specific language governing permissions and
1:d711ac1:  * limitations under the License.
1:d711ac1:  */
1:d711ac1: 
1:d711ac1: package org.apache.mahout.text;
1:d711ac1: 
1:d711ac1: import java.io.IOException;
1:d711ac1: 
1:d711ac1: import org.apache.hadoop.io.BytesWritable;
1:d711ac1: import org.apache.hadoop.io.IntWritable;
1:d711ac1: import org.apache.hadoop.mapreduce.InputSplit;
1:d711ac1: import org.apache.hadoop.mapreduce.RecordReader;
1:d711ac1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1:d711ac1: import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;
1:d711ac1: import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;
1:d711ac1: import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
1:d711ac1: 
1:d711ac1: /**
1:d711ac1:  * 
1:d711ac1:  * Used in combining a large number of text files into one text input reader
1:d711ac1:  * along with the WholeFileRecordReader class.
1:d711ac1:  * 
1:d711ac1:  */
1:d711ac1: public class MultipleTextFileInputFormat extends CombineFileInputFormat<IntWritable, BytesWritable> {
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public RecordReader<IntWritable, BytesWritable> createRecordReader(InputSplit inputSplit,
1:d711ac1:                                                                       TaskAttemptContext taskAttemptContext)
1:d711ac1:       throws IOException {
1:87c15be:     return new CombineFileRecordReader<>((CombineFileSplit) inputSplit,
1:87c15be:         taskAttemptContext, WholeFileRecordReader.class);
1:d711ac1:   }
1:d711ac1: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:87c15be
/////////////////////////////////////////////////////////////////////////
1:     return new CombineFileRecordReader<>((CombineFileSplit) inputSplit,
1:         taskAttemptContext, WholeFileRecordReader.class);
author:smarthi
-------------------------------------------------------------------------------
commit:d711ac1
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.text;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.io.BytesWritable;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.InputSplit;
1: import org.apache.hadoop.mapreduce.RecordReader;
1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1: import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;
1: import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
1: 
1: /**
1:  * 
1:  * Used in combining a large number of text files into one text input reader
1:  * along with the WholeFileRecordReader class.
1:  * 
1:  */
1: public class MultipleTextFileInputFormat extends CombineFileInputFormat<IntWritable, BytesWritable> {
1: 
1:   @Override
1:   public RecordReader<IntWritable, BytesWritable> createRecordReader(InputSplit inputSplit,
1:                                                                       TaskAttemptContext taskAttemptContext)
1:       throws IOException {
0:     return new CombineFileRecordReader<IntWritable, BytesWritable>((CombineFileSplit) inputSplit,
0:       taskAttemptContext, WholeFileRecordReader.class);
1:   }
1: }
============================================================================
1:29a7f38: /**
1:29a7f38:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:29a7f38:  * contributor license agreements.  See the NOTICE file distributed with
1:29a7f38:  * this work for additional information regarding copyright ownership.
1:29a7f38:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:29a7f38:  * (the "License"); you may not use this file except in compliance with
1:29a7f38:  * the License.  You may obtain a copy of the License at
1:29a7f38:  *
1:29a7f38:  *     http://www.apache.org/licenses/LICENSE-2.0
1:29a7f38:  *
1:29a7f38:  * Unless required by applicable law or agreed to in writing, software
1:29a7f38:  * distributed under the License is distributed on an "AS IS" BASIS,
1:29a7f38:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:29a7f38:  * See the License for the specific language governing permissions and
1:29a7f38:  * limitations under the License.
1:29a7f38:  */
6:29a7f38: 
1:4194a28: package org.apache.mahout.classifier.naivebayes.test;
1:29a7f38: 
1:d8d721a: import java.io.IOException;
1:d8d721a: import java.util.List;
1:d8d721a: import java.util.Map;
1:229aeff: import java.util.regex.Pattern;
1:d8d721a: 
1:85f9ece: import com.google.common.base.Preconditions;
1:29a7f38: import org.apache.hadoop.conf.Configuration;
1:d8d721a: import org.apache.hadoop.fs.FileSystem;
1:29a7f38: import org.apache.hadoop.fs.Path;
1:d8d721a: import org.apache.hadoop.io.SequenceFile;
1:29a7f38: import org.apache.hadoop.io.Text;
1:29a7f38: import org.apache.hadoop.mapreduce.Job;
1:29a7f38: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:29a7f38: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:29a7f38: import org.apache.hadoop.util.ToolRunner;
1:29a7f38: import org.apache.mahout.classifier.ClassifierResult;
1:29a7f38: import org.apache.mahout.classifier.ResultAnalyzer;
1:d8d721a: import org.apache.mahout.classifier.naivebayes.AbstractNaiveBayesClassifier;
1:29a7f38: import org.apache.mahout.classifier.naivebayes.BayesUtils;
1:d8d721a: import org.apache.mahout.classifier.naivebayes.ComplementaryNaiveBayesClassifier;
1:d8d721a: import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;
1:d8d721a: import org.apache.mahout.classifier.naivebayes.StandardNaiveBayesClassifier;
1:29a7f38: import org.apache.mahout.common.AbstractJob;
1:29a7f38: import org.apache.mahout.common.HadoopUtil;
1:29a7f38: import org.apache.mahout.common.Pair;
1:29a7f38: import org.apache.mahout.common.commandline.DefaultOptionCreator;
1:29a7f38: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:29a7f38: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:29a7f38: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
1:29a7f38: import org.apache.mahout.math.Vector;
1:29a7f38: import org.apache.mahout.math.VectorWritable;
1:29a7f38: import org.slf4j.Logger;
1:29a7f38: import org.slf4j.LoggerFactory;
1:29a7f38: 
1:29a7f38: /**
1:29a7f38:  * Test the (Complementary) Naive Bayes model that was built during training
1:29a7f38:  * by running the iterating the test set and comparing it to the model
1:29a7f38:  */
1:29a7f38: public class TestNaiveBayesDriver extends AbstractJob {
1:4194a28: 
1:4194a28:   private static final Logger log = LoggerFactory.getLogger(TestNaiveBayesDriver.class);
1:4194a28: 
1:29a7f38:   public static final String COMPLEMENTARY = "class"; //b for bayes, c for complementary
1:229aeff:   private static final Pattern SLASH = Pattern.compile("/");
1:29a7f38: 
1:29a7f38:   public static void main(String[] args) throws Exception {
1:29a7f38:     ToolRunner.run(new Configuration(), new TestNaiveBayesDriver(), args);
8:29a7f38:   }
1:d8d721a: 
1:29a7f38:   @Override
1:29a7f38:   public int run(String[] args) throws Exception {
1:29a7f38:     addInputOption();
1:29a7f38:     addOutputOption();
1:29a7f38:     addOption(addOption(DefaultOptionCreator.overwriteOption().create()));
1:29a7f38:     addOption("model", "m", "The path to the model built during training", true);
1:29a7f38:     addOption(buildOption("testComplementary", "c", "test complementary?", false, false, String.valueOf(false)));
1:2ab5e92:     addOption(buildOption("runSequential", "seq", "run sequential?", false, false, String.valueOf(false)));
1:29a7f38:     addOption("labelIndex", "l", "The path to the location of the label index", true);
1:6db7f62:     Map<String, List<String>> parsedArgs = parseArguments(args);
1:29a7f38:     if (parsedArgs == null) {
1:d8d721a:       return -1;
1:29a7f38:     }
1:29a7f38:     if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:29a7f38:       HadoopUtil.delete(getConf(), getOutputPath());
1:29a7f38:     }
1:678957e: 
1:2ab5e92:     boolean sequential = hasOption("runSequential");
1:678957e:     boolean succeeded;
1:d8d721a:     if (sequential) {
1:678957e:        runSequential();
2:d8d721a:     } else {
1:678957e:       succeeded = runMapReduce();
1:c94a7d0:       if (!succeeded) {
1:c94a7d0:         return -1;
1:c94a7d0:       }
1:29a7f38:     }
1:678957e: 
1:29a7f38:     //load the labels
1:6db7f62:     Map<Integer, String> labelMap = BayesUtils.readLabelIndex(getConf(), new Path(getOption("labelIndex")));
1:d8d721a: 
1:29a7f38:     //loop over the results and create the confusion matrix
1:4194a28:     SequenceFileDirIterable<Text, VectorWritable> dirIterable =
1:87c15be:         new SequenceFileDirIterable<>(getOutputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
1:29a7f38:     ResultAnalyzer analyzer = new ResultAnalyzer(labelMap.values(), "DEFAULT");
1:4194a28:     analyzeResults(labelMap, dirIterable, analyzer);
1:29a7f38: 
1:678957e:     log.info("{} Results: {}", hasOption("testComplementary") ? "Complementary" : "Standard NB", analyzer);
1:4194a28:     return 0;
1:29a7f38:   }
1:d8d721a: 
1:678957e:   private void runSequential() throws IOException {
1:678957e:     boolean complementary = hasOption("testComplementary");
1:678957e:     FileSystem fs = FileSystem.get(getConf());
1:678957e:     NaiveBayesModel model = NaiveBayesModel.materialize(new Path(getOption("model")), getConf());
1:9a5bab5:     
1:9a5bab5:     // Ensure that if we are testing in complementary mode, the model has been
1:9a5bab5:     // trained complementary. a complementarty model will work for standard classification
1:9a5bab5:     // a standard model will not work for complementary classification
1:9a5bab5:     if (complementary){
1:87c15be:         Preconditions.checkArgument((model.isComplemtary()),
1:9a5bab5:             "Complementary mode in model is different from test mode");
1:9a5bab5:     }
1:9a5bab5:     
1:678957e:     AbstractNaiveBayesClassifier classifier;
1:678957e:     if (complementary) {
1:678957e:       classifier = new ComplementaryNaiveBayesClassifier(model);
1:678957e:     } else {
1:678957e:       classifier = new StandardNaiveBayesClassifier(model);
1:678957e:     }
1:678957e: 
1:85f9ece:     try (SequenceFile.Writer writer =
1:85f9ece:              SequenceFile.createWriter(fs, getConf(), new Path(getOutputPath(), "part-r-00000"),
1:85f9ece:                  Text.class, VectorWritable.class)) {
1:678957e:       SequenceFileDirIterable<Text, VectorWritable> dirIterable =
1:87c15be:           new SequenceFileDirIterable<>(getInputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
1:678957e:       // loop through the part-r-* files in getInputPath() and get classification scores for all entries
1:678957e:       for (Pair<Text, VectorWritable> pair : dirIterable) {
1:678957e:         writer.append(new Text(SLASH.split(pair.getFirst().toString())[1]),
1:678957e:             new VectorWritable(classifier.classifyFull(pair.getSecond().get())));
1:678957e:       }
1:678957e:     }
1:678957e:   }
1:678957e: 
1:678957e:   private boolean runMapReduce() throws IOException,
1:d8d721a:       InterruptedException, ClassNotFoundException {
1:d8d721a:     Path model = new Path(getOption("model"));
1:d8d721a:     HadoopUtil.cacheFiles(model, getConf());
1:d8d721a:     //the output key is the expected value, the output value are the scores for all the labels
1:d8d721a:     Job testJob = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, BayesTestMapper.class,
1:678957e:         Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
1:d8d721a:     //testJob.getConfiguration().set(LABEL_KEY, getOption("--labels"));
1:9a5bab5: 
1:678957e: 
1:9a5bab5:     boolean complementary = hasOption("testComplementary");
1:d8d721a:     testJob.getConfiguration().set(COMPLEMENTARY, String.valueOf(complementary));
1:229aeff:     return testJob.waitForCompletion(true);
1:d8d721a:   }
1:ede812b: 
1:4194a28:   private static void analyzeResults(Map<Integer, String> labelMap,
1:4194a28:                                      SequenceFileDirIterable<Text, VectorWritable> dirIterable,
1:4194a28:                                      ResultAnalyzer analyzer) {
1:4194a28:     for (Pair<Text, VectorWritable> pair : dirIterable) {
1:4194a28:       int bestIdx = Integer.MIN_VALUE;
1:4194a28:       double bestScore = Long.MIN_VALUE;
1:dc62944:       for (Vector.Element element : pair.getSecond().get().all()) {
1:4194a28:         if (element.get() > bestScore) {
1:4194a28:           bestScore = element.get();
1:4194a28:           bestIdx = element.index();
1:d8d721a:         }
1:d8d721a:       }
1:4194a28:       if (bestIdx != Integer.MIN_VALUE) {
1:4194a28:         ClassifierResult classifierResult = new ClassifierResult(labelMap.get(bestIdx), bestScore);
1:4194a28:         analyzer.addInstance(pair.getFirst().toString(), classifierResult);
1:d8d721a:       }
1:29a7f38:     }
1:29a7f38:   }
1:29a7f38: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.base.Preconditions;
/////////////////////////////////////////////////////////////////////////
1:     try (SequenceFile.Writer writer =
1:              SequenceFile.createWriter(fs, getConf(), new Path(getOutputPath(), "part-r-00000"),
1:                  Text.class, VectorWritable.class)) {
/////////////////////////////////////////////////////////////////////////
commit:87c15be
/////////////////////////////////////////////////////////////////////////
1:         new SequenceFileDirIterable<>(getOutputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
/////////////////////////////////////////////////////////////////////////
1:         Preconditions.checkArgument((model.isComplemtary()),
/////////////////////////////////////////////////////////////////////////
1:           new SequenceFileDirIterable<>(getInputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:9a5bab5
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Preconditions;
/////////////////////////////////////////////////////////////////////////
1:     
1:     // Ensure that if we are testing in complementary mode, the model has been
1:     // trained complementary. a complementarty model will work for standard classification
1:     // a standard model will not work for complementary classification
1:     if (complementary){
0:         Preconditions.checkArgument((model.isComplemtary() == complementary),
1:             "Complementary mode in model is different from test mode");
1:     }
1:     
0:     SequenceFile.Writer writer = SequenceFile.createWriter(fs, getConf(), new Path(getOutputPath(), "part-r-00000"),
0:         Text.class, VectorWritable.class);
/////////////////////////////////////////////////////////////////////////
1: 
1:     boolean complementary = hasOption("testComplementary");
commit:210b265
/////////////////////////////////////////////////////////////////////////
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:678957e
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1: 
1:     boolean succeeded;
1:        runSequential();
1:       succeeded = runMapReduce();
1: 
0:         new SequenceFileDirIterable<Text, VectorWritable>(getOutputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
1:     log.info("{} Results: {}", hasOption("testComplementary") ? "Complementary" : "Standard NB", analyzer);
1:   private void runSequential() throws IOException {
1:     boolean complementary = hasOption("testComplementary");
1:     FileSystem fs = FileSystem.get(getConf());
1:     NaiveBayesModel model = NaiveBayesModel.materialize(new Path(getOption("model")), getConf());
1:     AbstractNaiveBayesClassifier classifier;
1:     if (complementary) {
1:       classifier = new ComplementaryNaiveBayesClassifier(model);
1:     } else {
1:       classifier = new StandardNaiveBayesClassifier(model);
1:     }
0:     SequenceFile.Writer writer =
0:         SequenceFile.createWriter(fs, getConf(), new Path(getOutputPath(), "part-r-00000"), Text.class, VectorWritable.class);
1: 
0:     try {
1:       SequenceFileDirIterable<Text, VectorWritable> dirIterable =
0:           new SequenceFileDirIterable<Text, VectorWritable>(getInputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
1:       // loop through the part-r-* files in getInputPath() and get classification scores for all entries
1:       for (Pair<Text, VectorWritable> pair : dirIterable) {
1:         writer.append(new Text(SLASH.split(pair.getFirst().toString())[1]),
1:             new VectorWritable(classifier.classifyFull(pair.getSecond().get())));
1:       }
0:     } finally {
0:       Closeables.close(writer, false);
1:     }
1:   }
1: 
1:   private boolean runMapReduce() throws IOException,
1:         Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
1: 
commit:ede812b
/////////////////////////////////////////////////////////////////////////
1:     
0:     //boolean complementary = parsedArgs.containsKey("testComplementary"); //always result to false as key in hash map is "--testComplementary"
0:     boolean complementary = hasOption("testComplementary"); //or  complementary = parsedArgs.containsKey("--testComplementary");
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
1:       for (Vector.Element element : pair.getSecond().get().all()) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1: import java.util.regex.Pattern;
/////////////////////////////////////////////////////////////////////////
1:   private static final Pattern SLASH = Pattern.compile("/");
/////////////////////////////////////////////////////////////////////////
0:       Reader reader = new Reader(fs, getInputPath(), getConf());
0:         writer.append(new Text(SLASH.split(key.toString())[1]),
/////////////////////////////////////////////////////////////////////////
1:     return testJob.waitForCompletion(true);
commit:c94a7d0
/////////////////////////////////////////////////////////////////////////
0:     boolean succeeded = testJob.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
1:     }
commit:4194a28
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.classifier.naivebayes.test;
/////////////////////////////////////////////////////////////////////////
1: 
1:   private static final Logger log = LoggerFactory.getLogger(TestNaiveBayesDriver.class);
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     SequenceFileDirIterable<Text, VectorWritable> dirIterable =
0:         new SequenceFileDirIterable<Text, VectorWritable>(getOutputPath(),
0:                                                           PathType.LIST,
0:                                                           PathFilters.partFilter(),
0:                                                           getConf());
1:     analyzeResults(labelMap, dirIterable, analyzer);
0:     log.info("{} Results: {}", complementary ? "Complementary" : "Standard NB", analyzer);
1:     return 0;
1:   private static void analyzeResults(Map<Integer, String> labelMap,
1:                                      SequenceFileDirIterable<Text, VectorWritable> dirIterable,
1:                                      ResultAnalyzer analyzer) {
1:     for (Pair<Text, VectorWritable> pair : dirIterable) {
1:       int bestIdx = Integer.MIN_VALUE;
1:       double bestScore = Long.MIN_VALUE;
0:       for (Vector.Element element : pair.getSecond().get()) {
1:         if (element.get() > bestScore) {
1:           bestScore = element.get();
1:           bestIdx = element.index();
1:       if (bestIdx != Integer.MIN_VALUE) {
1:         ClassifierResult classifierResult = new ClassifierResult(labelMap.get(bestIdx), bestScore);
1:         analyzer.addInstance(pair.getFirst().toString(), classifierResult);
author:Robin Anil
-------------------------------------------------------------------------------
commit:2ab5e92
/////////////////////////////////////////////////////////////////////////
1:     addOption(buildOption("runSequential", "seq", "run sequential?", false, false, String.valueOf(false)));
/////////////////////////////////////////////////////////////////////////
0:     boolean complementary = hasOption("testComplementary");
1:     boolean sequential = hasOption("runSequential");
commit:a344c6b
/////////////////////////////////////////////////////////////////////////
0:         writer.append(new Text(key.toString().split("/")[1]),
0:             new VectorWritable(classifier.classifyFull(vw.get())));
commit:d8d721a
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import java.util.List;
1: import java.util.Map;
1: 
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.io.SequenceFile;
0: import org.apache.hadoop.io.SequenceFile.Reader;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.classifier.naivebayes.AbstractNaiveBayesClassifier;
1: import org.apache.mahout.classifier.naivebayes.ComplementaryNaiveBayesClassifier;
1: import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;
1: import org.apache.mahout.classifier.naivebayes.StandardNaiveBayesClassifier;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     addOption(buildOption("runSequential", "seq", "run sequential?", true, false, String.valueOf(false)));
/////////////////////////////////////////////////////////////////////////
1:     
0:     boolean sequential = Boolean.parseBoolean(getOption("runSequential"));
1:     if (sequential) {
0:       FileSystem fs = FileSystem.get(getConf());
0:       NaiveBayesModel model = NaiveBayesModel.materialize(new Path(getOption("model")), getConf());
0:       AbstractNaiveBayesClassifier classifier;
0:       if (complementary) {
0:         classifier = new ComplementaryNaiveBayesClassifier(model);
1:       } else {
0:         classifier = new StandardNaiveBayesClassifier(model);
1:       }
0:       SequenceFile.Writer writer =
0:           new SequenceFile.Writer(fs, getConf(), getOutputPath(), Text.class, VectorWritable.class);
0:       SequenceFile.Reader reader = new Reader(fs, getInputPath(), getConf());
0:       Text key = new Text();
0:       VectorWritable vw = new VectorWritable();
0:       while (reader.next(key, vw)) {
0:         writer.append(key, new VectorWritable(classifier.classifyFull(vw.get())));
1:       }
0:       writer.close();
0:       reader.close();
1:     } else {
0:       boolean succeeded = runMapReduce(parsedArgs);
0:       if (!succeeded) {
1:         return -1;
1:       }
1:     
/////////////////////////////////////////////////////////////////////////
0:   private boolean runMapReduce(Map<String, List<String>> parsedArgs) throws IOException,
1:       InterruptedException, ClassNotFoundException {
1:     Path model = new Path(getOption("model"));
1:     HadoopUtil.cacheFiles(model, getConf());
1:     //the output key is the expected value, the output value are the scores for all the labels
1:     Job testJob = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, BayesTestMapper.class,
0:             Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
1:     //testJob.getConfiguration().set(LABEL_KEY, getOption("--labels"));
0:     boolean complementary = parsedArgs.containsKey("testComplementary");
1:     testJob.getConfiguration().set(COMPLEMENTARY, String.valueOf(complementary));
0:     boolean succeeded = testJob.waitForCompletion(true);
0:     return succeeded;
1:   }
1: 
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6db7f62
/////////////////////////////////////////////////////////////////////////
0: import java.util.List;
/////////////////////////////////////////////////////////////////////////
1:     Map<String, List<String>> parsedArgs = parseArguments(args);
0:     Path model = new Path(getOption("model"));
0:     //testJob.getConfiguration().set(LABEL_KEY, getOption("--labels"));
0:     boolean complementary = parsedArgs.containsKey("testComplementary");
1:     Map<Integer, String> labelMap = BayesUtils.readLabelIndex(getConf(), new Path(getOption("labelIndex")));
commit:8193b05
/////////////////////////////////////////////////////////////////////////
0:         if (bestIdx != Integer.MIN_VALUE) {
commit:29a7f38
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.classifier.naivebayes.test;
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1: import org.apache.hadoop.util.ToolRunner;
1: import org.apache.mahout.classifier.ClassifierResult;
1: import org.apache.mahout.classifier.ResultAnalyzer;
1: import org.apache.mahout.classifier.naivebayes.BayesUtils;
1: import org.apache.mahout.common.AbstractJob;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.commandline.DefaultOptionCreator;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
0: import java.util.Map;
1: 
1: /**
1:  * Test the (Complementary) Naive Bayes model that was built during training
1:  * by running the iterating the test set and comparing it to the model
1:  */
1: public class TestNaiveBayesDriver extends AbstractJob {
0:   private transient static Logger log = LoggerFactory.getLogger(TestNaiveBayesDriver.class);
0:   public static final String LABEL_KEY = "labels";
1:   public static final String COMPLEMENTARY = "class"; //b for bayes, c for complementary
1: 
1:   public static void main(String[] args) throws Exception {
1:     ToolRunner.run(new Configuration(), new TestNaiveBayesDriver(), args);
1:   }
1: 
1:   @Override
1:   public int run(String[] args) throws Exception {
0:     int result = 0;
1:     addInputOption();
1:     addOutputOption();
1:     addOption(addOption(DefaultOptionCreator.overwriteOption().create()));
1:     addOption("model", "m", "The path to the model built during training", true);
1:     addOption(buildOption("testComplementary", "c", "test complementary?", false, false, String.valueOf(false)));
1:     addOption("labelIndex", "l", "The path to the location of the label index", true);
0:     Map<String, String> parsedArgs = parseArguments(args);
1:     if (parsedArgs == null) {
0:       return -1;
1:     }
1:     if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:       HadoopUtil.delete(getConf(), getOutputPath());
1:     }
0:     Path model = new Path(parsedArgs.get("--model"));
0:     HadoopUtil.cacheFiles(model, getConf());
0:     //the output key is the expected value, the output value are the scores for all the labels
0:     Job testJob = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, BayesTestMapper.class,
0:             Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
0:     //testJob.getConfiguration().set(LABEL_KEY, parsedArgs.get("--labels"));
0:     boolean complementary = parsedArgs.containsKey("--testComplementary");
0:     testJob.getConfiguration().set(COMPLEMENTARY, String.valueOf(complementary));
0:     testJob.waitForCompletion(true);
1:     //load the labels
0:     Map<Integer, String> labelMap = BayesUtils.readLabelIndex(getConf(), new Path(parsedArgs.get("--labelIndex")));
1: 
1:     //loop over the results and create the confusion matrix
0:     SequenceFileDirIterable<Text, VectorWritable> dirIterable = new SequenceFileDirIterable<Text, VectorWritable>(getOutputPath(), PathType.LIST, PathFilters.partFilter(), getConf());
1:     ResultAnalyzer analyzer = new ResultAnalyzer(labelMap.values(), "DEFAULT");
0:     analyzeResults(labelMap, dirIterable, analyzer, complementary);
1: 
0:     log.info((complementary ? "Complementary" : "Standard NB") + " Results: {}", analyzer);
0:     return result;
1:   }
1: 
0:   private void analyzeResults(Map<Integer, String> labelMap, SequenceFileDirIterable<Text, VectorWritable> dirIterable, ResultAnalyzer analyzer, boolean complementary) {
0:     double bestScore;
0:     int bestIdx;
0:     if (complementary){
0:       for (Pair<Text, VectorWritable> pair : dirIterable) {
0:         bestIdx = Integer.MIN_VALUE;
0:         bestScore = Long.MIN_VALUE;
0:         for (Vector.Element element : pair.getSecond().get()) {
0:           if (element.get() > bestScore) {
0:             bestScore = element.get();
0:             bestIdx = element.index();
1:           }
1:         }
0:         if (bestIdx != Integer.MAX_VALUE) {
0:           ClassifierResult classifierResult = new ClassifierResult(labelMap.get(bestIdx), bestScore);
0:           analyzer.addInstance(pair.getFirst().toString(), classifierResult);
1:         }
1:       }
0:     } else {
0:       for (Pair<Text, VectorWritable> pair : dirIterable) {
0:         bestIdx = Integer.MIN_VALUE;
0:         bestScore = Long.MIN_VALUE;
0:         for (Vector.Element element : pair.getSecond().get()) {
0:           if (element.get() > bestScore) {
0:             bestScore = element.get();
0:             bestIdx = element.index();
1:           }
1:         }
0:         if (bestIdx != Integer.MIN_VALUE) {
0:           ClassifierResult classifierResult = new ClassifierResult(labelMap.get(bestIdx), bestScore);
0:           analyzer.addInstance(pair.getFirst().toString(), classifierResult);
1:         }
1:       }
1:     }
1: 
1:   }
1: }
============================================================================
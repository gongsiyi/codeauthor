1:8a2c0f3: /**
1:8a2c0f3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:8a2c0f3:  * contributor license agreements.  See the NOTICE file distributed with
1:8a2c0f3:  * this work for additional information regarding copyright ownership.
1:8a2c0f3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:8a2c0f3:  * (the "License"); you may not use this file except in compliance with
1:8a2c0f3:  * the License.  You may obtain a copy of the License at
1:8a2c0f3:  *
1:8a2c0f3:  *     http://www.apache.org/licenses/LICENSE-2.0
1:8a2c0f3:  *
1:8a2c0f3:  * Unless required by applicable law or agreed to in writing, software
1:8a2c0f3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:8a2c0f3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:8a2c0f3:  * See the License for the specific language governing permissions and
1:8a2c0f3:  * limitations under the License.
1:8a2c0f3:  */
1:8a2c0f3: 
1:8a2c0f3: package org.apache.mahout.classifier.sgd;
1:8a2c0f3: 
1:8a2c0f3: import org.apache.commons.cli2.CommandLine;
1:8a2c0f3: import org.apache.commons.cli2.Group;
1:8a2c0f3: import org.apache.commons.cli2.Option;
1:8a2c0f3: import org.apache.commons.cli2.builder.ArgumentBuilder;
1:8a2c0f3: import org.apache.commons.cli2.builder.DefaultOptionBuilder;
1:8a2c0f3: import org.apache.commons.cli2.builder.GroupBuilder;
1:8a2c0f3: import org.apache.commons.cli2.commandline.Parser;
1:8a2c0f3: import org.apache.commons.cli2.util.HelpFormatter;
1:4ef9d31: import org.apache.commons.io.Charsets;
1:8a2c0f3: import org.apache.hadoop.conf.Configuration;
1:8a2c0f3: import org.apache.hadoop.fs.Path;
1:e6a308b: import org.apache.hadoop.fs.PathFilter;
1:8a2c0f3: import org.apache.hadoop.io.Text;
1:8a2c0f3: import org.apache.mahout.classifier.ClassifierResult;
1:8a2c0f3: import org.apache.mahout.classifier.ResultAnalyzer;
1:8a2c0f3: import org.apache.mahout.common.Pair;
1:8a2c0f3: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:8a2c0f3: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterator;
1:8a2c0f3: import org.apache.mahout.math.Vector;
1:8a2c0f3: import org.apache.mahout.math.VectorWritable;
1:8a2c0f3: import org.apache.mahout.vectorizer.encoders.Dictionary;
1:8a2c0f3: 
1:8a2c0f3: import java.io.File;
1:8a2c0f3: import java.io.FileInputStream;
1:8a2c0f3: import java.io.IOException;
1:229aeff: import java.io.OutputStreamWriter;
1:8a2c0f3: import java.io.PrintWriter;
1:8a2c0f3: 
1:8a2c0f3: /**
1:128e3be:  * Run the ASF email, as trained by TrainASFEmail
1:8a2c0f3:  */
1:8a2c0f3: public final class TestASFEmail {
1:8a2c0f3: 
1:8a2c0f3:   private String inputFile;
1:8a2c0f3:   private String modelFile;
1:8a2c0f3: 
1:3c22856:   private TestASFEmail() {}
1:8a2c0f3: 
1:8a2c0f3:   public static void main(String[] args) throws IOException {
1:8a2c0f3:     TestASFEmail runner = new TestASFEmail();
1:8a2c0f3:     if (runner.parseArgs(args)) {
1:229aeff:       runner.run(new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));
2:8a2c0f3:     }
1:8a2c0f3:   }
1:8a2c0f3: 
1:8a2c0f3:   public void run(PrintWriter output) throws IOException {
1:8a2c0f3: 
1:8a2c0f3:     File base = new File(inputFile);
1:8a2c0f3:     //contains the best model
1:4fbfbc6:     OnlineLogisticRegression classifier =
1:4fbfbc6:         ModelSerializer.readBinary(new FileInputStream(modelFile), OnlineLogisticRegression.class);
1:8a2c0f3: 
1:8a2c0f3: 
1:8a2c0f3:     Dictionary asfDictionary = new Dictionary();
1:8a2c0f3:     Configuration conf = new Configuration();
1:e6a308b:     PathFilter testFilter = new PathFilter() {
1:e6a308b:       @Override
1:e6a308b:       public boolean accept(Path path) {
1:e6a308b:         return path.getName().contains("test");
1:e6a308b:       }
1:e6a308b:     };
1:3c22856:     SequenceFileDirIterator<Text, VectorWritable> iter =
1:4ef9d31:         new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter,
1:3c22856:         null, true, conf);
1:8a2c0f3: 
1:8a2c0f3:     long numItems = 0;
1:8a2c0f3:     while (iter.hasNext()) {
1:8a2c0f3:       Pair<Text, VectorWritable> next = iter.next();
1:8a2c0f3:       asfDictionary.intern(next.getFirst().toString());
1:8a2c0f3:       numItems++;
1:8a2c0f3:     }
1:8a2c0f3: 
1:229aeff:     System.out.println(numItems + " test files");
1:8a2c0f3:     ResultAnalyzer ra = new ResultAnalyzer(asfDictionary.values(), "DEFAULT");
1:4ef9d31:     iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter,
2:8a2c0f3:             null, true, conf);
1:128e3be:     while (iter.hasNext()) {
1:8a2c0f3:       Pair<Text, VectorWritable> next = iter.next();
1:8a2c0f3:       String ng = next.getFirst().toString();
1:8a2c0f3: 
1:8a2c0f3:       int actual = asfDictionary.intern(ng);
1:8a2c0f3:       Vector result = classifier.classifyFull(next.getSecond().get());
1:8a2c0f3:       int cat = result.maxValueIndex();
1:8a2c0f3:       double score = result.maxValue();
1:8a2c0f3:       double ll = classifier.logLikelihood(actual, next.getSecond().get());
1:8a2c0f3:       ClassifierResult cr = new ClassifierResult(asfDictionary.values().get(cat), score, ll);
1:8a2c0f3:       ra.addInstance(asfDictionary.values().get(actual), cr);
1:8a2c0f3: 
1:8a2c0f3:     }
1:229aeff:     output.println(ra);
1:8a2c0f3:   }
1:8a2c0f3: 
1:4fbfbc6:   boolean parseArgs(String[] args) {
1:8a2c0f3:     DefaultOptionBuilder builder = new DefaultOptionBuilder();
1:8a2c0f3: 
1:8a2c0f3:     Option help = builder.withLongName("help").withDescription("print this list").create();
1:8a2c0f3: 
1:8a2c0f3:     ArgumentBuilder argumentBuilder = new ArgumentBuilder();
1:8a2c0f3:     Option inputFileOption = builder.withLongName("input")
1:8a2c0f3:             .withRequired(true)
1:8a2c0f3:             .withArgument(argumentBuilder.withName("input").withMaximum(1).create())
1:8a2c0f3:             .withDescription("where to get training data")
1:8a2c0f3:             .create();
1:8a2c0f3: 
1:8a2c0f3:     Option modelFileOption = builder.withLongName("model")
1:8a2c0f3:             .withRequired(true)
1:8a2c0f3:             .withArgument(argumentBuilder.withName("model").withMaximum(1).create())
1:8a2c0f3:             .withDescription("where to get a model")
1:8a2c0f3:             .create();
1:8a2c0f3: 
1:8a2c0f3:     Group normalArgs = new GroupBuilder()
1:8a2c0f3:             .withOption(help)
1:8a2c0f3:             .withOption(inputFileOption)
1:8a2c0f3:             .withOption(modelFileOption)
1:8a2c0f3:             .create();
1:8a2c0f3: 
1:8a2c0f3:     Parser parser = new Parser();
1:8a2c0f3:     parser.setHelpOption(help);
1:8a2c0f3:     parser.setHelpTrigger("--help");
1:8a2c0f3:     parser.setGroup(normalArgs);
1:8a2c0f3:     parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));
1:8a2c0f3:     CommandLine cmdLine = parser.parseAndHelp(args);
1:8a2c0f3: 
1:8a2c0f3:     if (cmdLine == null) {
1:8a2c0f3:       return false;
1:8a2c0f3:     }
1:8a2c0f3: 
1:8a2c0f3:     inputFile = (String) cmdLine.getValue(inputFileOption);
1:8a2c0f3:     modelFile = (String) cmdLine.getValue(modelFileOption);
1:8a2c0f3:     return true;
1:8a2c0f3:   }
1:8a2c0f3: 
1:8a2c0f3: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:4ef9d31
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.commons.io.Charsets;
/////////////////////////////////////////////////////////////////////////
1:         new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter,
/////////////////////////////////////////////////////////////////////////
1:     iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, testFilter,
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:3c22856
/////////////////////////////////////////////////////////////////////////
1:   private TestASFEmail() {}
/////////////////////////////////////////////////////////////////////////
1:     SequenceFileDirIterator<Text, VectorWritable> iter =
0:         new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, testFilter,
1:         null, true, conf);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Charsets;
/////////////////////////////////////////////////////////////////////////
1: import java.io.OutputStreamWriter;
/////////////////////////////////////////////////////////////////////////
1:       runner.run(new PrintWriter(new OutputStreamWriter(System.out, Charsets.UTF_8), true));
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     System.out.println(numItems + " test files");
/////////////////////////////////////////////////////////////////////////
1:     output.println(ra);
commit:822a5e1
/////////////////////////////////////////////////////////////////////////
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     OnlineLogisticRegression classifier =
1:         ModelSerializer.readBinary(new FileInputStream(modelFile), OnlineLogisticRegression.class);
0:     //<String> overallCounts = HashMultiset.create();
/////////////////////////////////////////////////////////////////////////
1:   boolean parseArgs(String[] args) {
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:e6a308b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.fs.PathFilter;
/////////////////////////////////////////////////////////////////////////
1:     PathFilter testFilter = new PathFilter() {
1:       @Override
1:       public boolean accept(Path path) {
1:         return path.getName().contains("test");
1:       }
1:     };
0:     SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, testFilter,
/////////////////////////////////////////////////////////////////////////
0:     iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, testFilter,
commit:128e3be
/////////////////////////////////////////////////////////////////////////
1:  * Run the ASF email, as trained by TrainASFEmail
/////////////////////////////////////////////////////////////////////////
1:     while (iter.hasNext()) {
commit:8a2c0f3
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.sgd;
1: 
0: import com.google.common.collect.HashMultiset;
0: import com.google.common.collect.Multiset;
1: import org.apache.commons.cli2.CommandLine;
1: import org.apache.commons.cli2.Group;
1: import org.apache.commons.cli2.Option;
1: import org.apache.commons.cli2.builder.ArgumentBuilder;
1: import org.apache.commons.cli2.builder.DefaultOptionBuilder;
1: import org.apache.commons.cli2.builder.GroupBuilder;
1: import org.apache.commons.cli2.commandline.Parser;
1: import org.apache.commons.cli2.util.HelpFormatter;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Text;
1: import org.apache.mahout.classifier.ClassifierResult;
1: import org.apache.mahout.classifier.ResultAnalyzer;
1: import org.apache.mahout.common.Pair;
0: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterator;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.vectorizer.encoders.Dictionary;
1: 
1: import java.io.File;
1: import java.io.FileInputStream;
1: import java.io.IOException;
1: import java.io.PrintWriter;
1: 
1: /**
0:  * Run the 20 news groups test data through SGD, as trained by {@link TrainNewsGroups}.
1:  */
1: public final class TestASFEmail {
1: 
1:   private String inputFile;
1:   private String modelFile;
1: 
0:   private TestASFEmail() {
1:   }
1: 
1:   public static void main(String[] args) throws IOException {
1:     TestASFEmail runner = new TestASFEmail();
1:     if (runner.parseArgs(args)) {
0:       runner.run(new PrintWriter(System.out, true));
1:     }
1:   }
1: 
1:   public void run(PrintWriter output) throws IOException {
1: 
1:     File base = new File(inputFile);
1:     //contains the best model
0:     OnlineLogisticRegression classifier = ModelSerializer.readBinary(new FileInputStream(modelFile), OnlineLogisticRegression.class);
1: 
1: 
1:     Dictionary asfDictionary = new Dictionary();
0:     Multiset<String> overallCounts = HashMultiset.create();
1:     Configuration conf = new Configuration();
0:     SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, PathFilters.partFilter(),
1:             null, true, conf);
1: 
1:     long numItems = 0;
1:     while (iter.hasNext()) {
1:       Pair<Text, VectorWritable> next = iter.next();
1:       asfDictionary.intern(next.getFirst().toString());
1:       numItems++;
1:     }
1: 
0:     System.out.printf("%d test files\n", numItems);
1:     ResultAnalyzer ra = new ResultAnalyzer(asfDictionary.values(), "DEFAULT");
0:     iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, PathFilters.partFilter(),
1:             null, true, conf);
0:     while (iter.hasNext()){
1:       Pair<Text, VectorWritable> next = iter.next();
1:       String ng = next.getFirst().toString();
1: 
1:       int actual = asfDictionary.intern(ng);
0:       NewsgroupHelper helper = new NewsgroupHelper();
1:       Vector result = classifier.classifyFull(next.getSecond().get());
1:       int cat = result.maxValueIndex();
1:       double score = result.maxValue();
1:       double ll = classifier.logLikelihood(actual, next.getSecond().get());
1:       ClassifierResult cr = new ClassifierResult(asfDictionary.values().get(cat), score, ll);
1:       ra.addInstance(asfDictionary.values().get(actual), cr);
1: 
1:     }
0:     output.printf("%s\n\n", ra.toString());
1:   }
1: 
0:   protected boolean parseArgs(String[] args) {
1:     DefaultOptionBuilder builder = new DefaultOptionBuilder();
1: 
1:     Option help = builder.withLongName("help").withDescription("print this list").create();
1: 
1:     ArgumentBuilder argumentBuilder = new ArgumentBuilder();
1:     Option inputFileOption = builder.withLongName("input")
1:             .withRequired(true)
1:             .withArgument(argumentBuilder.withName("input").withMaximum(1).create())
1:             .withDescription("where to get training data")
1:             .create();
1: 
1:     Option modelFileOption = builder.withLongName("model")
1:             .withRequired(true)
1:             .withArgument(argumentBuilder.withName("model").withMaximum(1).create())
1:             .withDescription("where to get a model")
1:             .create();
1: 
1:     Group normalArgs = new GroupBuilder()
1:             .withOption(help)
1:             .withOption(inputFileOption)
1:             .withOption(modelFileOption)
1:             .create();
1: 
1:     Parser parser = new Parser();
1:     parser.setHelpOption(help);
1:     parser.setHelpTrigger("--help");
1:     parser.setGroup(normalArgs);
1:     parser.setHelpFormatter(new HelpFormatter(" ", "", " ", 130));
1:     CommandLine cmdLine = parser.parseAndHelp(args);
1: 
1:     if (cmdLine == null) {
1:       return false;
1:     }
1: 
1:     inputFile = (String) cmdLine.getValue(inputFileOption);
1:     modelFile = (String) cmdLine.getValue(modelFileOption);
1:     return true;
1:   }
1: 
1: }
============================================================================
1:b35e54f: /**
1:b35e54f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b35e54f:  * contributor license agreements.  See the NOTICE file distributed with
1:b35e54f:  * this work for additional information regarding copyright ownership.
1:b35e54f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b35e54f:  * (the "License"); you may not use this file except in compliance with
1:b35e54f:  * the License.  You may obtain a copy of the License at
1:b35e54f:  *
1:b35e54f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:b35e54f:  *
1:b35e54f:  * Unless required by applicable law or agreed to in writing, software
1:b35e54f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b35e54f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b35e54f:  * See the License for the specific language governing permissions and
1:b35e54f:  * limitations under the License.
1:b35e54f:  */
1:b35e54f: 
1:7120506: package org.apache.mahout.clustering.spectral.kmeans;
1:b35e54f: 
1:b35e54f: import java.util.Collection;
1:b35e54f: import java.util.HashSet;
1:b35e54f: import java.util.List;
1:b35e54f: 
1:b35e54f: import org.apache.hadoop.conf.Configuration;
1:b35e54f: import org.apache.hadoop.fs.FileSystem;
1:b35e54f: import org.apache.hadoop.fs.Path;
1:b35e54f: import org.apache.hadoop.mapreduce.Job;
1:b35e54f: import org.apache.mahout.clustering.Cluster;
1:b35e54f: import org.apache.mahout.clustering.ClusteringTestUtils;
1:b35e54f: import org.apache.mahout.clustering.iterator.ClusterWritable;
1:7120506: import org.apache.mahout.clustering.spectral.kmeans.EigenSeedGenerator;
1:b35e54f: import org.apache.mahout.common.MahoutTestCase;
1:b35e54f: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1:b35e54f: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterable;
1:b35e54f: import org.apache.mahout.math.RandomAccessSparseVector;
1:b35e54f: import org.apache.mahout.math.Vector;
1:b35e54f: import org.apache.mahout.math.VectorWritable;
1:b35e54f: import org.junit.Before;
1:b35e54f: import org.junit.Test;
1:b35e54f: 
1:b35e54f: import com.google.common.collect.Lists;
1:b35e54f: 
1:b35e54f: public final class TestEigenSeedGenerator extends MahoutTestCase {
1:b35e54f: 
1:b35e54f:   private
1:b35e54f:    static final double[][] RAW = {{1, 0, 0}, {1, 0, 0}, {0, 1, 0}, {0, 1, 0},
1:b35e54f:                                   {0, 1, 0}, {0, 0, 1}, {0, 0, 1}};
1:b35e54f: 
1:b35e54f:   private FileSystem fs;
1:b35e54f: 
1:b35e54f:   private static List<VectorWritable> getPoints() {
1:b35e54f:     List<VectorWritable> points = Lists.newArrayList();
1:b35e54f:     for (double[] fr : RAW) {
1:b35e54f:       Vector vec = new RandomAccessSparseVector(fr.length);
1:b35e54f:       vec.assign(fr);
1:b35e54f:       points.add(new VectorWritable(vec));
1:b35e54f:     }
1:b35e54f:     return points;
1:b35e54f:   }
1:b35e54f: 
1:b35e54f:   @Override
1:b35e54f:   @Before
1:b35e54f:   public void setUp() throws Exception {
1:b35e54f:     super.setUp();
1:921e201:     Configuration conf = getConfiguration();
1:b35e54f:     fs = FileSystem.get(conf);
1:b35e54f:   }
1:b35e54f: 
1:b35e54f:   @Test
1:b35e54f:   public void testEigenSeedGenerator() throws Exception {
1:b35e54f:     List<VectorWritable> points = getPoints();
1:b35e54f:     Job job = new Job();
1:b35e54f:     Configuration conf = job.getConfiguration();
1:b35e54f:     job.setMapOutputValueClass(VectorWritable.class);
1:b35e54f:     Path input = getTestTempFilePath("eigen-input");
1:b35e54f:     Path output = getTestTempDirPath("eigen-output");
1:b35e54f:     ClusteringTestUtils.writePointsToFile(points, input, fs, conf);
1:b35e54f: 
1:b35e54f:     EigenSeedGenerator.buildFromEigens(conf, input, output, 3, new ManhattanDistanceMeasure());
1:b35e54f: 
1:b35e54f:     int clusterCount = 0;
1:02ff22f:     Collection<Integer> set = new HashSet<>();
1:b35e54f:     Vector v[] = new Vector[3];
1:b35e54f:     for (ClusterWritable clusterWritable :
1:b35e54f:          new SequenceFileValueIterable<ClusterWritable>(
1:b35e54f:              new Path(output, "part-eigenSeed"), true, conf)) {
1:b35e54f:       Cluster cluster = clusterWritable.getValue();
1:b35e54f:       int id = cluster.getId();
1:b35e54f:       assertTrue(set.add(id)); // validate unique id's
1:b35e54f:       v[id] = cluster.getCenter();
1:b35e54f:       clusterCount++;
1:b35e54f:     }
1:b35e54f:     assertEquals(3, clusterCount); // validate sample count
1:b35e54f:     // validate pair-wise orthogonality
1:b35e54f:     assertEquals(0, v[0].dot(v[1]), 1E-10);
1:b35e54f:     assertEquals(0, v[1].dot(v[2]), 1E-10);
1:b35e54f:     assertEquals(0, v[0].dot(v[2]), 1E-10);
1:b35e54f:   }
1:b35e54f: 
1:b35e54f: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:     Collection<Integer> set = new HashSet<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:7120506
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral.kmeans;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.spectral.kmeans.EigenSeedGenerator;
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:smarthi
-------------------------------------------------------------------------------
commit:99a5ce8
/////////////////////////////////////////////////////////////////////////
author:Robin Anil
-------------------------------------------------------------------------------
commit:b35e54f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.kmeans;
1: 
1: import java.util.Collection;
1: import java.util.HashSet;
1: import java.util.List;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.mahout.clustering.Cluster;
1: import org.apache.mahout.clustering.ClusteringTestUtils;
1: import org.apache.mahout.clustering.iterator.ClusterWritable;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterable;
1: import org.apache.mahout.math.RandomAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Before;
1: import org.junit.Test;
1: 
1: import com.google.common.collect.Lists;
1: 
1: public final class TestEigenSeedGenerator extends MahoutTestCase {
1: 
1:   private
1:    static final double[][] RAW = {{1, 0, 0}, {1, 0, 0}, {0, 1, 0}, {0, 1, 0},
1:                                   {0, 1, 0}, {0, 0, 1}, {0, 0, 1}};
1: 
1:   private FileSystem fs;
1: 
1:   private static List<VectorWritable> getPoints() {
1:     List<VectorWritable> points = Lists.newArrayList();
1:     for (double[] fr : RAW) {
1:       Vector vec = new RandomAccessSparseVector(fr.length);
1:       vec.assign(fr);
1:       points.add(new VectorWritable(vec));
1:     }
1:     return points;
1:   }
1: 
1:   @Override
1:   @Before
1:   public void setUp() throws Exception {
1:     super.setUp();
0:     Configuration conf = new Configuration();
1:     fs = FileSystem.get(conf);
1:   }
1: 
0:   /** Story: test eigen seed generation generates 3 clusters with proper ids and data */
1:   @Test
1:   public void testEigenSeedGenerator() throws Exception {
1:     List<VectorWritable> points = getPoints();
1:     Job job = new Job();
1:     Configuration conf = job.getConfiguration();
1:     job.setMapOutputValueClass(VectorWritable.class);
1:     Path input = getTestTempFilePath("eigen-input");
1:     Path output = getTestTempDirPath("eigen-output");
1:     ClusteringTestUtils.writePointsToFile(points, input, fs, conf);
1: 
1:     EigenSeedGenerator.buildFromEigens(conf, input, output, 3, new ManhattanDistanceMeasure());
1: 
1:     int clusterCount = 0;
0:     Collection<Integer> set = new HashSet<Integer>();
1:     Vector v[] = new Vector[3];
1:     for (ClusterWritable clusterWritable :
1:          new SequenceFileValueIterable<ClusterWritable>(
1:              new Path(output, "part-eigenSeed"), true, conf)) {
1:       Cluster cluster = clusterWritable.getValue();
1:       int id = cluster.getId();
1:       assertTrue(set.add(id)); // validate unique id's
1:       v[id] = cluster.getCenter();
1:       clusterCount++;
1:     }
1:     assertEquals(3, clusterCount); // validate sample count
1:     // validate pair-wise orthogonality
1:     assertEquals(0, v[0].dot(v[1]), 1E-10);
1:     assertEquals(0, v[1].dot(v[2]), 1E-10);
1:     assertEquals(0, v[0].dot(v[2]), 1E-10);
1:   }
1: 
1: }
============================================================================
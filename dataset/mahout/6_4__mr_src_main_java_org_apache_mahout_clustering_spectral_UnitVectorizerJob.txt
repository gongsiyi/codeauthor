2:48d069f: /**
1:48d069f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:48d069f:  * contributor license agreements.  See the NOTICE file distributed with
1:48d069f:  * this work for additional information regarding copyright ownership.
1:48d069f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:48d069f:  * (the "License"); you may not use this file except in compliance with
1:48d069f:  * the License.  You may obtain a copy of the License at
2:48d069f:  *
1:48d069f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:48d069f:  *
1:48d069f:  * Unless required by applicable law or agreed to in writing, software
1:48d069f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:48d069f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:48d069f:  * See the License for the specific language governing permissions and
1:48d069f:  * limitations under the License.
2:48d069f:  */
4:48d069f: 
1:b60c909: package org.apache.mahout.clustering.spectral;
1:48d069f: 
1:48d069f: import java.io.IOException;
1:48d069f: 
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.fs.Path;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.mapreduce.Job;
1:48d069f: import org.apache.hadoop.mapreduce.Mapper;
1:48d069f: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: 
1:48d069f: /**
1:48d069f:  * <p>Given a DistributedRowMatrix, this job normalizes each row to unit
1:48d069f:  * vector length. If the input is a matrix U, and the output is a matrix
1:48d069f:  * W, the job follows:</p>
1:39fe224:  *
1:39fe224:  * <p>{@code v_ij = u_ij / sqrt(sum_j(u_ij * u_ij))}</p>
1:48d069f:  */
1:48d069f: public final class UnitVectorizerJob {
1:48d069f: 
1:049e7dc:   private UnitVectorizerJob() {
1:049e7dc:   }
1:049e7dc: 
1:049e7dc:   public static void runJob(Path input, Path output)
1:48d069f:     throws IOException, InterruptedException, ClassNotFoundException {
1:48d069f:     
1:48d069f:     Configuration conf = new Configuration();
1:48d069f:     Job job = new Job(conf, "UnitVectorizerJob");
1:48d069f:     
1:48d069f:     job.setInputFormatClass(SequenceFileInputFormat.class);
1:48d069f:     job.setOutputKeyClass(IntWritable.class);
1:48d069f:     job.setOutputValueClass(VectorWritable.class);
1:48d069f:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:48d069f:     job.setMapperClass(UnitVectorizerMapper.class);
1:48d069f:     job.setNumReduceTasks(0);
1:48d069f:     
1:48d069f:     FileInputFormat.addInputPath(job, input);
1:48d069f:     FileOutputFormat.setOutputPath(job, output);
1:48d069f: 
1:765834c:     job.setJarByClass(UnitVectorizerJob.class);
1:765834c: 
1:7c2b664:     boolean succeeded = job.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       throw new IllegalStateException("Job failed!");
1:7c2b664:     }
3:48d069f:   }
1:48d069f:   
1:48d069f:   public static class UnitVectorizerMapper
1:48d069f:     extends Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable> {
1:48d069f:     
1:48d069f:     @Override
1:48d069f:     protected void map(IntWritable row, VectorWritable vector, Context context) 
1:48d069f:       throws IOException, InterruptedException {
1:dc62944:       context.write(row, new VectorWritable(vector.get().normalize(2)));
1:48d069f:     }
1:dc62944: 
1:48d069f:   }
1:48d069f: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       context.write(row, new VectorWritable(vector.get().normalize(2)));
1: 
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = job.waitForCompletion(true);
1:     if (!succeeded) {
1:       throw new IllegalStateException("Job failed!");
1:     }
commit:765834c
/////////////////////////////////////////////////////////////////////////
1:     job.setJarByClass(UnitVectorizerJob.class);
1: 
commit:39fe224
/////////////////////////////////////////////////////////////////////////
1:  *
1:  * <p>{@code v_ij = u_ij / sqrt(sum_j(u_ij * u_ij))}</p>
commit:85ec3a3
/////////////////////////////////////////////////////////////////////////
0:     private static double vectorNorm(Iterable<Vector.Element> u) {
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
1:   private UnitVectorizerJob() {
1:   }
1: 
1:   public static void runJob(Path input, Path output)
/////////////////////////////////////////////////////////////////////////
0:     private static double vectorNorm(Vector u) {
0:       for (Vector.Element e : u) {
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:48d069f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
0: import org.apache.mahout.math.RandomAccessSparseVector;
0: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
0: import org.apache.mahout.math.function.Functions;
1: 
1: /**
1:  * <p>Given a DistributedRowMatrix, this job normalizes each row to unit
1:  * vector length. If the input is a matrix U, and the output is a matrix
1:  * W, the job follows:</p>
1:  * 
0:  * <p><code>v_ij = u_ij / sqrt(sum_j(u_ij * u_ij))</code></p>
1:  */
1: public final class UnitVectorizerJob {
1: 
0:   public static void runJob(Path input, Path output) 
1:     throws IOException, InterruptedException, ClassNotFoundException {
1:     
1:     Configuration conf = new Configuration();
1:     Job job = new Job(conf, "UnitVectorizerJob");
1:     
1:     job.setInputFormatClass(SequenceFileInputFormat.class);
1:     job.setOutputKeyClass(IntWritable.class);
1:     job.setOutputValueClass(VectorWritable.class);
1:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:     job.setMapperClass(UnitVectorizerMapper.class);
1:     job.setNumReduceTasks(0);
1:     
1:     FileInputFormat.addInputPath(job, input);
1:     FileOutputFormat.setOutputPath(job, output);
1: 
0:     job.waitForCompletion(true);
1:   }
1:   
1:   public static class UnitVectorizerMapper
1:     extends Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable> {
1:     
1:     @Override
1:     protected void map(IntWritable row, VectorWritable vector, Context context) 
1:       throws IOException, InterruptedException {
1:       
0:       // set up the return value and perform the computations
0:       double norm = vectorNorm(vector.get());
0:       Vector w = vector.get().assign(Functions.div(norm));
0:       RandomAccessSparseVector out = new RandomAccessSparseVector(w);
1:       
0:       // finally write the output
0:       context.write(row, new VectorWritable(out));
1:     }
1:     
1:     /**
0:      * Sums the squares of all elements together, then takes the square root
0:      * of that sum.
0:      * @param u
0:      * @return
1:      */
0:     private double vectorNorm(Vector u) {
0:       double retval = 0.0;
0:       for (Vector.Element e : u) {;
0:         retval += Functions.POW.apply(e.get(), 2);
1:       }
0:       return Functions.SQRT.apply(retval);
1:     }
1:   }
1: }
============================================================================
1:48d069f: /**
1:48d069f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:48d069f:  * contributor license agreements.  See the NOTICE file distributed with
1:48d069f:  * this work for additional information regarding copyright ownership.
1:48d069f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:48d069f:  * (the "License"); you may not use this file except in compliance with
1:48d069f:  * the License.  You may obtain a copy of the License at
1:48d069f:  *
1:48d069f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:48d069f:  *
1:48d069f:  * Unless required by applicable law or agreed to in writing, software
1:48d069f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:48d069f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:48d069f:  * See the License for the specific language governing permissions and
1:48d069f:  * limitations under the License.
1:48d069f:  */
1:48d069f: 
1:b60c909: package org.apache.mahout.clustering.spectral;
1:48d069f: 
1:48d069f: import java.util.List;
1:48d069f: import java.util.Map;
1:48d069f: import java.util.Set;
1:48d069f: 
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.io.LongWritable;
1:48d069f: import org.apache.hadoop.io.Text;
1:48d069f: import org.apache.hadoop.mapreduce.Mapper;
1:48d069f: import org.apache.hadoop.mapreduce.Reducer;
1:48d069f: import org.apache.mahout.common.DummyRecordWriter;
1:48d069f: import org.apache.mahout.common.MahoutTestCase;
1:48d069f: import org.apache.mahout.math.Vector;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: import org.apache.mahout.math.hadoop.DistributedRowMatrix.MatrixEntryWritable;
1:48d069f: import org.junit.Test;
1:48d069f: 
1:48d069f: /**
1:48d069f:  * <p>Tests the affinity matrix input M/R task.</p>
1:48d069f:  * 
1:48d069f:  * <p>The tricky item with this task is that the format of the input
1:48d069f:  * must be correct; it must take the form of a graph input, and for the
1:48d069f:  * current implementation, the input must be symmetric, e.g. the weight
1:48d069f:  * from node A to B = the weight from node B to A. This is not explicitly
1:48d069f:  * enforced within the task itself (since, as of the time these tests were 
1:48d069f:  * written, we have not yet decided on a final rule regarding the 
1:48d069f:  * symmetry/non-symmetry of the affinity matrix, so we are unofficially 
1:48d069f:  * enforcing symmetry). Input looks something like this:</p>
1:48d069f:  * 
1:48d069f:  * <pre>0, 0, 0
1:48d069f:  * 0, 1, 10
1:48d069f:  * 0, 2, 20
1:48d069f:  * ...
1:48d069f:  * 1, 0, 10
1:48d069f:  * 2, 0, 20
1:48d069f:  * ...</pre>
1:48d069f:  * 
1:48d069f:  * <p>The mapper's task is simply to convert each line of text into a
1:48d069f:  * DistributedRowMatrix entry, allowing the reducer to join each entry
1:48d069f:  * of the same row into a VectorWritable.</p>
1:48d069f:  * 
1:48d069f:  * <p>Exceptions are thrown in cases of bad input format: if there are
1:48d069f:  * more or fewer than 3 numbers per line, or any of the numbers are missing.
1:48d069f:  */
1:48d069f: public class TestAffinityMatrixInputJob extends MahoutTestCase {
1:48d069f:   
1:049e7dc:   private static final String [] RAW = {"0,0,0", "0,1,5", "0,2,10", "1,0,5", "1,1,0",
1:049e7dc:                                         "1,2,20", "2,0,10", "2,1,20", "2,2,0"};
1:049e7dc:   private static final int RAW_DIMENSIONS = 3;
1:48d069f: 
1:48d069f:   @Test
1:48d069f:   public void testAffinityMatrixInputMapper() throws Exception {
1:48d069f:     AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();
1:921e201:     Configuration conf = getConfiguration();
1:b60c909:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:48d069f:     
1:48d069f:     // set up the dummy writer and the M/R context
1:049e7dc:     DummyRecordWriter<IntWritable, MatrixEntryWritable> writer =
1:02ff22f:       new DummyRecordWriter<>();
1:049e7dc:     Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context 
1:48d069f:       context = DummyRecordWriter.build(mapper, conf, writer);
1:48d069f: 
1:48d069f:     // loop through all the points and test each one is converted
1:48d069f:     // successfully to a DistributedRowMatrix.MatrixEntry
1:049e7dc:     for (String s : RAW) {
1:049e7dc:       mapper.map(new LongWritable(), new Text(s), context);
1:48d069f:     }
1:48d069f: 
1:48d069f:     // test the data was successfully constructed
1:049e7dc:     assertEquals("Number of map results", RAW_DIMENSIONS, writer.getData().size());
1:48d069f:     Set<IntWritable> keys = writer.getData().keySet();
1:48d069f:     for (IntWritable i : keys) {
1:48d069f:       List<MatrixEntryWritable> row = writer.getData().get(i);
1:049e7dc:       assertEquals("Number of items in row", RAW_DIMENSIONS, row.size());
1:48d069f:     }
1:48d069f:   }
1:48d069f:   
1:48d069f:   @Test
1:48d069f:   public void testAffinitymatrixInputReducer() throws Exception {
1:48d069f:     AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();
1:921e201:     Configuration conf = getConfiguration();
1:b60c909:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:48d069f:     
1:48d069f:     // set up the dummy writer and the M/R context
1:049e7dc:     DummyRecordWriter<IntWritable, MatrixEntryWritable> mapWriter =
1:02ff22f:       new DummyRecordWriter<>();
1:049e7dc:     Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context
1:48d069f:       mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);
1:48d069f: 
1:48d069f:     // loop through all the points and test each one is converted
1:48d069f:     // successfully to a DistributedRowMatrix.MatrixEntry
1:049e7dc:     for (String s : RAW) {
1:049e7dc:       mapper.map(new LongWritable(), new Text(s), mapContext);
1:48d069f:     }
1:48d069f:     // store the data for checking later
1:48d069f:     Map<IntWritable, List<MatrixEntryWritable>> map = mapWriter.getData();
1:48d069f: 
1:48d069f:     // now reduce the data
1:48d069f:     AffinityMatrixInputReducer reducer = new AffinityMatrixInputReducer();
1:48d069f:     DummyRecordWriter<IntWritable, VectorWritable> redWriter = 
1:02ff22f:       new DummyRecordWriter<>();
1:049e7dc:     Reducer<IntWritable, MatrixEntryWritable,
1:48d069f:       IntWritable, VectorWritable>.Context redContext = DummyRecordWriter
1:48d069f:       .build(reducer, conf, redWriter, IntWritable.class, MatrixEntryWritable.class);
1:48d069f:     for (IntWritable key : mapWriter.getKeys()) {
1:48d069f:       reducer.reduce(key, mapWriter.getValue(key), redContext);
1:48d069f:     }
1:48d069f:     
1:48d069f:     // check that all the elements are correctly ordered
1:049e7dc:     assertEquals("Number of reduce results", RAW_DIMENSIONS, redWriter.getData().size());
1:48d069f:     for (IntWritable row : redWriter.getKeys()) {
1:48d069f:       List<VectorWritable> list = redWriter.getValue(row);
1:48d069f:       assertEquals("Should only be one vector", 1, list.size());
1:48d069f:       // check that the elements in the array are correctly ordered
1:48d069f:       Vector v = list.get(0).get();
1:dc62944:       for (Vector.Element e : v.all()) {
1:48d069f:         // find this value in the original map
1:48d069f:         MatrixEntryWritable toCompare = new MatrixEntryWritable();
1:48d069f:         toCompare.setRow(-1);
1:48d069f:         toCompare.setCol(e.index());
1:48d069f:         toCompare.setVal(e.get());
1:48d069f:         assertTrue("This entry was correctly placed in its row", map.get(row).contains(toCompare));
1:48d069f:       }
1:48d069f:     }
1:48d069f:   }
1:48d069f: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:       new DummyRecordWriter<>();
/////////////////////////////////////////////////////////////////////////
1:       new DummyRecordWriter<>();
/////////////////////////////////////////////////////////////////////////
1:       new DummyRecordWriter<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
/////////////////////////////////////////////////////////////////////////
1:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
1:       for (Vector.Element e : v.all()) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private static final String [] RAW = {"0,0,0", "0,1,5", "0,2,10", "1,0,5", "1,1,0",
1:                                         "1,2,20", "2,0,10", "2,1,20", "2,2,0"};
1:   private static final int RAW_DIMENSIONS = 3;
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:     DummyRecordWriter<IntWritable, MatrixEntryWritable> writer =
0:       new DummyRecordWriter<IntWritable, MatrixEntryWritable>();
1:     Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context 
1:     for (String s : RAW) {
1:       mapper.map(new LongWritable(), new Text(s), context);
1:     assertEquals("Number of map results", RAW_DIMENSIONS, writer.getData().size());
1:       assertEquals("Number of items in row", RAW_DIMENSIONS, row.size());
/////////////////////////////////////////////////////////////////////////
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:     DummyRecordWriter<IntWritable, MatrixEntryWritable> mapWriter =
0:       new DummyRecordWriter<IntWritable, MatrixEntryWritable>();
1:     Mapper<LongWritable, Text, IntWritable, MatrixEntryWritable>.Context
1:     for (String s : RAW) {
1:       mapper.map(new LongWritable(), new Text(s), mapContext);
/////////////////////////////////////////////////////////////////////////
1:     Reducer<IntWritable, MatrixEntryWritable,
/////////////////////////////////////////////////////////////////////////
1:     assertEquals("Number of reduce results", RAW_DIMENSIONS, redWriter.getData().size());
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:48d069f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.util.List;
1: import java.util.Map;
1: import java.util.Set;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.LongWritable;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.Reducer;
0: import org.apache.mahout.clustering.spectral.eigencuts.EigencutsKeys;
1: import org.apache.mahout.common.DummyRecordWriter;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
0: import org.apache.mahout.math.hadoop.DistributedRowMatrix;
1: import org.apache.mahout.math.hadoop.DistributedRowMatrix.MatrixEntryWritable;
1: import org.junit.Test;
1: 
1: /**
1:  * <p>Tests the affinity matrix input M/R task.</p>
1:  * 
1:  * <p>The tricky item with this task is that the format of the input
1:  * must be correct; it must take the form of a graph input, and for the
1:  * current implementation, the input must be symmetric, e.g. the weight
1:  * from node A to B = the weight from node B to A. This is not explicitly
1:  * enforced within the task itself (since, as of the time these tests were 
1:  * written, we have not yet decided on a final rule regarding the 
1:  * symmetry/non-symmetry of the affinity matrix, so we are unofficially 
1:  * enforcing symmetry). Input looks something like this:</p>
1:  * 
1:  * <pre>0, 0, 0
1:  * 0, 1, 10
1:  * 0, 2, 20
1:  * ...
1:  * 1, 0, 10
1:  * 2, 0, 20
1:  * ...</pre>
1:  * 
1:  * <p>The mapper's task is simply to convert each line of text into a
1:  * DistributedRowMatrix entry, allowing the reducer to join each entry
1:  * of the same row into a VectorWritable.</p>
1:  * 
1:  * <p>Exceptions are thrown in cases of bad input format: if there are
1:  * more or fewer than 3 numbers per line, or any of the numbers are missing.
1:  */
1: public class TestAffinityMatrixInputJob extends MahoutTestCase {
1:   
0:   private String [] raw = {"0,0,0", "0,1,5", "0,2,10", "1,0,5", "1,1,0", 
0:                           "1,2,20", "2,0,10", "2,1,20", "2,2,0"};
0:   private int rawDimensions = 3;
1: 
1:   @Test
1:   public void testAffinityMatrixInputMapper() throws Exception {
1:     AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();
0:     Configuration conf = new Configuration();
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, rawDimensions);
1:     
1:     // set up the dummy writer and the M/R context
0:     DummyRecordWriter<IntWritable, DistributedRowMatrix.MatrixEntryWritable> writer = 
0:       new DummyRecordWriter<IntWritable, DistributedRowMatrix.MatrixEntryWritable>();
0:     Mapper<LongWritable, Text, IntWritable, DistributedRowMatrix.MatrixEntryWritable>.Context 
1:       context = DummyRecordWriter.build(mapper, conf, writer);
1: 
1:     // loop through all the points and test each one is converted
1:     // successfully to a DistributedRowMatrix.MatrixEntry
0:     for (int i = 0; i < raw.length; i++) {
0:       mapper.map(new LongWritable(), new Text(raw[i]), context);
1:     }
1: 
1:     // test the data was successfully constructed
0:     assertEquals("Number of map results", rawDimensions, writer.getData().size());
1:     Set<IntWritable> keys = writer.getData().keySet();
1:     for (IntWritable i : keys) {
1:       List<MatrixEntryWritable> row = writer.getData().get(i);
0:       assertEquals("Number of items in row", rawDimensions, row.size());
1:     }
1:   }
1:   
1:   @Test
1:   public void testAffinitymatrixInputReducer() throws Exception {
1:     AffinityMatrixInputMapper mapper = new AffinityMatrixInputMapper();
0:     Configuration conf = new Configuration();
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, rawDimensions);
1:     
1:     // set up the dummy writer and the M/R context
0:     DummyRecordWriter<IntWritable, DistributedRowMatrix.MatrixEntryWritable> mapWriter = 
0:       new DummyRecordWriter<IntWritable, DistributedRowMatrix.MatrixEntryWritable>();
0:     Mapper<LongWritable, Text, IntWritable, DistributedRowMatrix.MatrixEntryWritable>.Context 
1:       mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);
1: 
1:     // loop through all the points and test each one is converted
1:     // successfully to a DistributedRowMatrix.MatrixEntry
0:     for (int i = 0; i < raw.length; i++) {
0:       mapper.map(new LongWritable(), new Text(raw[i]), mapContext);
1:     }
1:     // store the data for checking later
1:     Map<IntWritable, List<MatrixEntryWritable>> map = mapWriter.getData();
1: 
1:     // now reduce the data
1:     AffinityMatrixInputReducer reducer = new AffinityMatrixInputReducer();
1:     DummyRecordWriter<IntWritable, VectorWritable> redWriter = 
0:       new DummyRecordWriter<IntWritable, VectorWritable>();
0:     Reducer<IntWritable, DistributedRowMatrix.MatrixEntryWritable, 
1:       IntWritable, VectorWritable>.Context redContext = DummyRecordWriter
1:       .build(reducer, conf, redWriter, IntWritable.class, MatrixEntryWritable.class);
1:     for (IntWritable key : mapWriter.getKeys()) {
1:       reducer.reduce(key, mapWriter.getValue(key), redContext);
1:     }
1:     
1:     // check that all the elements are correctly ordered
0:     assertEquals("Number of reduce results", rawDimensions, redWriter.getData().size());
1:     for (IntWritable row : redWriter.getKeys()) {
1:       List<VectorWritable> list = redWriter.getValue(row);
1:       assertEquals("Should only be one vector", 1, list.size());
1:       // check that the elements in the array are correctly ordered
1:       Vector v = list.get(0).get();
0:       for (Vector.Element e : v) {
1:         // find this value in the original map
1:         MatrixEntryWritable toCompare = new MatrixEntryWritable();
1:         toCompare.setRow(-1);
1:         toCompare.setCol(e.index());
1:         toCompare.setVal(e.get());
1:         assertTrue("This entry was correctly placed in its row", map.get(row).contains(toCompare));
1:       }
1:     }
1:   }
1: }
============================================================================
1:61ae2e7: /**
1:61ae2e7:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:61ae2e7:  * contributor license agreements.  See the NOTICE file distributed with
1:61ae2e7:  * this work for additional information regarding copyright ownership.
1:61ae2e7:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:61ae2e7:  * (the "License"); you may not use this file except in compliance with
1:61ae2e7:  * the License.  You may obtain a copy of the License at
1:61ae2e7:  *
1:61ae2e7:  *     http://www.apache.org/licenses/LICENSE-2.0
1:61ae2e7:  *
1:61ae2e7:  * Unless required by applicable law or agreed to in writing, software
1:61ae2e7:  * distributed under the License is distributed on an "AS IS" BASIS,
1:61ae2e7:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:61ae2e7:  * See the License for the specific language governing permissions and
1:61ae2e7:  * limitations under the License.
1:61ae2e7:  */
1:d8e91f9: 
1:10d6663: package org.apache.mahout.vectorizer;
1:61ae2e7: 
1:d8e91f9: import java.io.IOException;
1:22d7d31: import java.util.List;
10:22d7d31: 
1:2e5449f: import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
1:58cc1ae: import com.google.common.collect.Lists;
1:d608a88: import com.google.common.io.Closeables;
1:22d7d31: import org.apache.hadoop.conf.Configuration;
1:22d7d31: import org.apache.hadoop.fs.FileSystem;
1:22d7d31: import org.apache.hadoop.fs.Path;
1:22d7d31: import org.apache.hadoop.io.SequenceFile;
1:22d7d31: import org.apache.hadoop.io.Text;
1:e3ec9d8: import org.apache.hadoop.util.ToolRunner;
1:10d6663: import org.apache.mahout.common.MahoutTestCase;
1:d8e91f9: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:d8e91f9: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:d8e91f9: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
1:d8e91f9: import org.apache.mahout.math.Vector;
1:d8e91f9: import org.apache.mahout.math.VectorWritable;
1:22d7d31: import org.junit.Test;
1:22d7d31: 
1:2e5449f: @ThreadLeakScope(ThreadLeakScope.Scope.NONE)
1:22d7d31: public class SparseVectorsFromSequenceFilesTest extends MahoutTestCase {
1:61ae2e7: 
1:22d7d31:   private static final int NUM_DOCS = 100;
1:22d7d31:   
1:22d7d31:   private Configuration conf;
1:22d7d31:   private Path inputPath;
1:22d7d31: 
1:d8e91f9:   private void setupDocs() throws IOException {
1:e3ec9d8:     conf = getConfiguration();
1:22d7d31: 
1:22d7d31:     inputPath = getTestTempFilePath("documents/docs.file");
1:1de8cec:     FileSystem fs = FileSystem.get(inputPath.toUri(), conf);
1:1de8cec: 
1:22d7d31:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1:22d7d31: 
1:22d7d31:     RandomDocumentGenerator gen = new RandomDocumentGenerator();
1:d608a88: 
1:d608a88:     try {
1:d608a88:       for (int i = 0; i < NUM_DOCS; i++) {
1:d608a88:         writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));
1:d608a88:       }
1:d608a88:     } finally {
1:87d4b2e:       Closeables.close(writer, false);
1:d8e91f9:     }
2:22d7d31:   }
1:d8e91f9: 
1:d8e91f9: 
1:22d7d31:   @Test
1:22d7d31:   public void testCreateTermFrequencyVectors() throws Exception {
1:d8e91f9:     setupDocs();
1:356bfd1:     runTest(false, false, false, -1, NUM_DOCS);
1:22d7d31:   }
1:1de8cec: 
1:22d7d31:   @Test
1:22d7d31:   public void testCreateTermFrequencyVectorsNam() throws Exception {
1:d8e91f9:     setupDocs();
1:356bfd1:     runTest(false, false, true, -1, NUM_DOCS);
1:22d7d31:   }
1:22d7d31:   
1:22d7d31:   @Test
1:22d7d31:   public void testCreateTermFrequencyVectorsSeq() throws Exception {
1:d8e91f9:     setupDocs();
1:356bfd1:     runTest(false, true, false, -1, NUM_DOCS);
1:22d7d31:   }
1:22d7d31:   
1:22d7d31:   @Test
1:22d7d31:   public void testCreateTermFrequencyVectorsSeqNam() throws Exception {
1:d8e91f9:     setupDocs();
1:356bfd1:     runTest(false, true, true, -1, NUM_DOCS);
1:22d7d31:   }
1:d8e91f9: 
1:d8e91f9:   @Test
1:d8e91f9:   public void testPruning() throws Exception {
1:e3ec9d8:     conf = getConfiguration();
1:d8e91f9:     inputPath = getTestTempFilePath("documents/docs.file");
1:1de8cec:     FileSystem fs = FileSystem.get(inputPath.toUri(), conf);
1:d8e91f9: 
1:d8e91f9:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1:d8e91f9: 
1:d8e91f9:     String [] docs = {"a b c", "a a a a a b", "a a a a a c"};
1:d8e91f9: 
1:d8e91f9:     try {
1:d8e91f9:       for (int i = 0; i < docs.length; i++) {
1:d8e91f9:         writer.append(new Text("Document::ID::" + i), new Text(docs[i]));
1:d8e91f9:       }
1:d8e91f9:     } finally {
1:87d4b2e:       Closeables.close(writer, false);
1:d8e91f9:     }
1:356bfd1:     Path outPath = runTest(false, false, false, 2, docs.length);
1:d8e91f9:     Path tfidfVectors = new Path(outPath, "tfidf-vectors");
1:d8e91f9:     int count = 0;
1:d8e91f9:     Vector [] res = new Vector[docs.length];
1:d8e91f9:     for (VectorWritable value :
1:d8e91f9:          new SequenceFileDirValueIterable<VectorWritable>(
1:d8e91f9:              tfidfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {
1:d8e91f9:       Vector v = value.get();
1:d8e91f9:       System.out.println(v);
1:d8e91f9:       assertEquals(2, v.size());
1:d8e91f9:       res[count] = v;
1:d8e91f9:       count++;
1:d8e91f9:     }
1:d8e91f9:     assertEquals(docs.length, count);
1:d8e91f9:     //the first doc should have two values, the second and third should have 1, since the a gets removed
1:d8e91f9:     assertEquals(2, res[0].getNumNondefaultElements());
1:d8e91f9:     assertEquals(1, res[1].getNumNondefaultElements());
1:d8e91f9:     assertEquals(1, res[2].getNumNondefaultElements());
1:356bfd1:   }
1:356bfd1: 
1:356bfd1:   @Test
1:356bfd1:   public void testPruningTF() throws Exception {
1:e3ec9d8:     conf = getConfiguration();
1:356bfd1:     FileSystem fs = FileSystem.get(conf);
1:356bfd1: 
1:356bfd1:     inputPath = getTestTempFilePath("documents/docs.file");
1:356bfd1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1:356bfd1: 
1:356bfd1:     String [] docs = {"a b c", "a a a a a b", "a a a a a c"};
1:d8e91f9: 
1:356bfd1:     try {
1:356bfd1:       for (int i = 0; i < docs.length; i++) {
1:356bfd1:         writer.append(new Text("Document::ID::" + i), new Text(docs[i]));
1:356bfd1:       }
1:356bfd1:     } finally {
1:87d4b2e:       Closeables.close(writer, false);
1:356bfd1:     }
1:356bfd1:     Path outPath = runTest(true, false, false, 2, docs.length);
1:356bfd1:     Path tfVectors = new Path(outPath, "tf-vectors");
1:356bfd1:     int count = 0;
1:356bfd1:     Vector [] res = new Vector[docs.length];
1:356bfd1:     for (VectorWritable value :
1:356bfd1:          new SequenceFileDirValueIterable<VectorWritable>(
1:356bfd1:              tfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {
1:356bfd1:       Vector v = value.get();
1:356bfd1:       System.out.println(v);
1:356bfd1:       assertEquals(2, v.size());
1:356bfd1:       res[count] = v;
1:356bfd1:       count++;
1:356bfd1:     }
1:356bfd1:     assertEquals(docs.length, count);
1:356bfd1:     //the first doc should have two values, the second and third should have 1, since the a gets removed
1:356bfd1:     assertEquals(2, res[0].getNumNondefaultElements());
1:356bfd1:     assertEquals(1, res[1].getNumNondefaultElements());
1:356bfd1:     assertEquals(1, res[2].getNumNondefaultElements());
1:d8e91f9:   }
1:356bfd1: 
1:356bfd1:   private Path runTest(boolean tfWeighting, boolean sequential, boolean named, double maxDFSigma, int numDocs) throws Exception {
1:22d7d31:     Path outputPath = getTestTempFilePath("output");
1:22d7d31: 
1:58cc1ae:     List<String> argList = Lists.newLinkedList();
1:22d7d31:     argList.add("-i");
1:22d7d31:     argList.add(inputPath.toString());
1:22d7d31:     argList.add("-o");
1:22d7d31:     argList.add(outputPath.toString());
1:22d7d31:     
1:61ae2e7:     if (sequential) {
1:22d7d31:       argList.add("-seq");
1:61ae2e7:     }
1:22d7d31:     
1:61ae2e7:     if (named) {
1:22d7d31:       argList.add("-nv");
1:61ae2e7:     }
1:e64dd36:     if (maxDFSigma >= 0) {
1:d8e91f9:       argList.add("--maxDFSigma");
1:d8e91f9:       argList.add(String.valueOf(maxDFSigma));
1:d8e91f9:     }
1:e64dd36:     if (tfWeighting) {
1:356bfd1:       argList.add("--weight");
1:356bfd1:       argList.add("tf");
1:356bfd1:     }
1:61ae2e7:     String[] args = argList.toArray(new String[argList.size()]);
1:22d7d31:     
1:e3ec9d8:     ToolRunner.run(getConfiguration(), new SparseVectorsFromSequenceFiles(), args);
1:22d7d31: 
1:22d7d31:     Path tfVectors = new Path(outputPath, "tf-vectors");
1:22d7d31:     Path tfidfVectors = new Path(outputPath, "tfidf-vectors");
1:22d7d31:     
1:d8e91f9:     DictionaryVectorizerTest.validateVectors(conf, numDocs, tfVectors, sequential, named);
1:229aeff:     if (!tfWeighting) {
1:356bfd1:       DictionaryVectorizerTest.validateVectors(conf, numDocs, tfidfVectors, sequential, named);
1:356bfd1:     }
1:d8e91f9:     return outputPath;
1:22d7d31:   }  
1:22d7d31: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:2e5449f
/////////////////////////////////////////////////////////////////////////
1: import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
/////////////////////////////////////////////////////////////////////////
1: @ThreadLeakScope(ThreadLeakScope.Scope.NONE)
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
1:     List<String> argList = Lists.newLinkedList();
commit:d608a88
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1: 
1:     try {
1:       for (int i = 0; i < NUM_DOCS; i++) {
1:         writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));
1:       }
1:     } finally {
0:       Closeables.closeQuietly(writer);
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(writer, true);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(writer, true);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(writer, true);
commit:356bfd1
/////////////////////////////////////////////////////////////////////////
1:     runTest(false, false, false, -1, NUM_DOCS);
1:     runTest(false, false, true, -1, NUM_DOCS);
1:     runTest(false, true, false, -1, NUM_DOCS);
1:     runTest(false, true, true, -1, NUM_DOCS);
/////////////////////////////////////////////////////////////////////////
1:     Path outPath = runTest(false, false, false, 2, docs.length);
/////////////////////////////////////////////////////////////////////////
1:   @Test
1:   public void testPruningTF() throws Exception {
0:     conf = new Configuration();
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     inputPath = getTestTempFilePath("documents/docs.file");
1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1: 
1:     String [] docs = {"a b c", "a a a a a b", "a a a a a c"};
1: 
1:     try {
1:       for (int i = 0; i < docs.length; i++) {
1:         writer.append(new Text("Document::ID::" + i), new Text(docs[i]));
1:       }
1:     } finally {
0:       Closeables.closeQuietly(writer);
1:     }
1:     Path outPath = runTest(true, false, false, 2, docs.length);
1:     Path tfVectors = new Path(outPath, "tf-vectors");
1:     int count = 0;
1:     Vector [] res = new Vector[docs.length];
1:     for (VectorWritable value :
1:          new SequenceFileDirValueIterable<VectorWritable>(
1:              tfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {
1:       Vector v = value.get();
1:       System.out.println(v);
1:       assertEquals(2, v.size());
1:       res[count] = v;
1:       count++;
1:     }
1:     assertEquals(docs.length, count);
1:     //the first doc should have two values, the second and third should have 1, since the a gets removed
1:     assertEquals(2, res[0].getNumNondefaultElements());
1:     assertEquals(1, res[1].getNumNondefaultElements());
1:     assertEquals(1, res[2].getNumNondefaultElements());
1:   }
1: 
1:   private Path runTest(boolean tfWeighting, boolean sequential, boolean named, double maxDFSigma, int numDocs) throws Exception {
/////////////////////////////////////////////////////////////////////////
0:     if (tfWeighting){
1:       argList.add("--weight");
1:       argList.add("tf");
1:     }
/////////////////////////////////////////////////////////////////////////
0:     if (tfWeighting == false) {
1:       DictionaryVectorizerTest.validateVectors(conf, numDocs, tfidfVectors, sequential, named);
1:     }
commit:d8e91f9
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
0: import org.apache.mahout.math.NamedVector;
0: import org.apache.mahout.math.RandomAccessSparseVector;
0: import org.apache.mahout.math.SequentialAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
/////////////////////////////////////////////////////////////////////////
1:   }
1: 
1:   private void setupDocs() throws IOException {
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:     setupDocs();
0:     runTest(false, false, -1, NUM_DOCS);
1:     setupDocs();
0:     runTest(false, true, -1, NUM_DOCS);
1:     setupDocs();
0:     runTest(true, false, -1, NUM_DOCS);
1:     setupDocs();
0:     runTest(true, true, -1, NUM_DOCS);
1: 
1:   @Test
1:   public void testPruning() throws Exception {
0:     conf = new Configuration();
0:     FileSystem fs = FileSystem.get(conf);
1: 
1:     inputPath = getTestTempFilePath("documents/docs.file");
1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1: 
1:     String [] docs = {"a b c", "a a a a a b", "a a a a a c"};
1: 
1:     try {
1:       for (int i = 0; i < docs.length; i++) {
1:         writer.append(new Text("Document::ID::" + i), new Text(docs[i]));
1:       }
1:     } finally {
0:       Closeables.closeQuietly(writer);
1:     }
0:     Path outPath = runTest(false, false, 2, docs.length);
1:     Path tfidfVectors = new Path(outPath, "tfidf-vectors");
1:     int count = 0;
1:     Vector [] res = new Vector[docs.length];
1:     for (VectorWritable value :
1:          new SequenceFileDirValueIterable<VectorWritable>(
1:              tfidfVectors, PathType.LIST, PathFilters.partFilter(), null, true, conf)) {
1:       Vector v = value.get();
1:       System.out.println(v);
1:       assertEquals(2, v.size());
1:       res[count] = v;
1:       count++;
1:     }
1:     assertEquals(docs.length, count);
1:     //the first doc should have two values, the second and third should have 1, since the a gets removed
1:     assertEquals(2, res[0].getNumNondefaultElements());
1:     assertEquals(1, res[1].getNumNondefaultElements());
1:     assertEquals(1, res[2].getNumNondefaultElements());
1:   }
1: 
0:   private Path runTest(boolean sequential, boolean named, double maxDFSigma, int numDocs) throws Exception {
/////////////////////////////////////////////////////////////////////////
0:     if (maxDFSigma >= 0){
1:       argList.add("--maxDFSigma");
1:       argList.add(String.valueOf(maxDFSigma));
1:     }
/////////////////////////////////////////////////////////////////////////
1:     DictionaryVectorizerTest.validateVectors(conf, numDocs, tfVectors, sequential, named);
0:     DictionaryVectorizerTest.validateVectors(conf, numDocs, tfidfVectors, sequential, named);
1:     return outputPath;
author:Isabel Drost
-------------------------------------------------------------------------------
commit:e3ec9d8
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.util.ToolRunner;
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     ToolRunner.run(getConfiguration(), new SparseVectorsFromSequenceFiles(), args);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     if (!tfWeighting) {
commit:1de8cec
/////////////////////////////////////////////////////////////////////////
1:     FileSystem fs = FileSystem.get(inputPath.toUri(), conf);
1: 
/////////////////////////////////////////////////////////////////////////
1:     FileSystem fs = FileSystem.get(inputPath.toUri(), conf);
1: 
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     FileSystem fs = FileSystem.get(conf);
/////////////////////////////////////////////////////////////////////////
0:     DictionaryVectorizerTest.validateVectors(conf, NUM_DOCS, tfVectors, sequential, named);
0:     DictionaryVectorizerTest.validateVectors(conf, NUM_DOCS, tfidfVectors, sequential, named);
commit:61ae2e7
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:   private void runTest(boolean sequential, boolean named) throws Exception {
/////////////////////////////////////////////////////////////////////////
1:     if (sequential) {
1:     }
1:     if (named) {
1:     }
1:     String[] args = argList.toArray(new String[argList.size()]);
author:tcp
-------------------------------------------------------------------------------
commit:e64dd36
/////////////////////////////////////////////////////////////////////////
1:     if (maxDFSigma >= 0) {
1:     if (tfWeighting) {
author:Robin Anil
-------------------------------------------------------------------------------
commit:10d6663
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.vectorizer;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.MahoutTestCase;
author:Andrew L. Farris
-------------------------------------------------------------------------------
commit:22d7d31
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.text;
1: 
0: import java.util.LinkedList;
1: import java.util.List;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.Text;
0: import org.apache.mahout.utils.MahoutTestCase;
0: import org.apache.mahout.utils.vectors.text.DictionaryVectorizerTest;
0: import org.apache.mahout.utils.vectors.text.RandomDocumentGenerator;
0: import org.junit.Before;
1: import org.junit.Test;
1: 
1: 
1: public class SparseVectorsFromSequenceFilesTest extends MahoutTestCase {
1:   private static final int NUM_DOCS = 100;
1:   
1:   private Configuration conf;
0:   private FileSystem fs;
1:   private Path inputPath;
1:   
0:   @Override
0:   @Before
0:   public void setUp() throws Exception {
0:     super.setUp();
0:     conf = new Configuration();
0:     fs = FileSystem.get(conf);
1: 
1:     inputPath = getTestTempFilePath("documents/docs.file");
1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, inputPath, Text.class, Text.class);
1: 
1:     RandomDocumentGenerator gen = new RandomDocumentGenerator();
1:     
0:     for (int i = 0; i < NUM_DOCS; i++) {
0:       writer.append(new Text("Document::ID::" + i), new Text(gen.getRandomDocument()));
1:     }
0:     writer.close();
1:   }
1:   
1:   
1:   @Test
1:   public void testCreateTermFrequencyVectors() throws Exception {
0:     runTest(false, false);
1:   }
1: 
1:   @Test
1:   public void testCreateTermFrequencyVectorsNam() throws Exception {
0:     runTest(false, true);
1:   }
1:   
1:   @Test
1:   public void testCreateTermFrequencyVectorsSeq() throws Exception {
0:     runTest(true, false);
1:   }
1:   
1:   @Test
1:   public void testCreateTermFrequencyVectorsSeqNam() throws Exception {
0:     runTest(true, true);
1:   }
1:   
0:   protected void runTest(boolean sequential, boolean named) throws Exception {
1:     Path outputPath = getTestTempFilePath("output");
1: 
1:     
0:     List<String> argList = new LinkedList<String>();
1:     argList.add("-i");
1:     argList.add(inputPath.toString());
1:     argList.add("-o");
1:     argList.add(outputPath.toString());
1:     
0:     if (sequential) 
1:       argList.add("-seq");
1:     
0:     if (named)
1:       argList.add("-nv");
1:     
0:     String[] args = argList.toArray(new String[0]);
1:     
0:     SparseVectorsFromSequenceFiles.main(args);
1: 
1:     Path tfVectors = new Path(outputPath, "tf-vectors");
1:     Path tfidfVectors = new Path(outputPath, "tfidf-vectors");
1:     
0:     DictionaryVectorizerTest.validateVectors(fs, conf, NUM_DOCS, tfVectors, sequential, named);
0:     DictionaryVectorizerTest.validateVectors(fs, conf, NUM_DOCS, tfidfVectors, sequential, named);
1:   }  
1: }
============================================================================
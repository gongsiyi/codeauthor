1:27d33a2: /**
1:27d33a2:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:27d33a2:  * contributor license agreements.  See the NOTICE file distributed with
1:27d33a2:  * this work for additional information regarding copyright ownership.
1:27d33a2:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:27d33a2:  * (the "License"); you may not use this file except in compliance with
1:27d33a2:  * the License.  You may obtain a copy of the License at
2:27d33a2:  *
1:27d33a2:  *     http://www.apache.org/licenses/LICENSE-2.0
1:27d33a2:  *
1:27d33a2:  * Unless required by applicable law or agreed to in writing, software
1:27d33a2:  * distributed under the License is distributed on an "AS IS" BASIS,
1:27d33a2:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:27d33a2:  * See the License for the specific language governing permissions and
1:27d33a2:  * limitations under the License.
1:27d33a2:  */
4:27d33a2: 
1:27d33a2: package org.apache.mahout.classifier.sequencelearning.hmm;
1:27d33a2: 
1:27d33a2: import org.apache.mahout.math.DenseMatrix;
1:27d33a2: import org.apache.mahout.math.Matrix;
1:27d33a2: import org.apache.mahout.math.Vector;
1:27d33a2: 
1:27d33a2: /**
1:27d33a2:  * Class containing implementations of the three major HMM algorithms: forward,
1:27d33a2:  * backward and Viterbi
1:27d33a2:  */
1:27d33a2: public final class HmmAlgorithms {
1:27d33a2: 
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * No public constructors for utility classes.
1:27d33a2:    */
1:27d33a2:   private HmmAlgorithms() {
1:27d33a2:     // nothing to do here really
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * External function to compute a matrix of alpha factors
1:27d33a2:    *
1:27d33a2:    * @param model        model to run forward algorithm for.
1:27d33a2:    * @param observations observation sequence to train on.
1:27d33a2:    * @param scaled       Should log-scaled beta factors be computed?
1:27d33a2:    * @return matrix of alpha factors.
1:27d33a2:    */
1:74f849b:   public static Matrix forwardAlgorithm(HmmModel model, int[] observations, boolean scaled) {
1:d53cf4a:     Matrix alpha = new DenseMatrix(observations.length, model.getNrOfHiddenStates());
1:27d33a2:     forwardAlgorithm(alpha, model, observations, scaled);
1:27d33a2: 
1:27d33a2:     return alpha;
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Internal function to compute the alpha factors
1:27d33a2:    *
1:27d33a2:    * @param alpha        matrix to store alpha factors in.
1:27d33a2:    * @param model        model to use for alpha factor computation.
1:27d33a2:    * @param observations observation sequence seen.
1:27d33a2:    * @param scaled       set to true if log-scaled beta factors should be computed.
1:27d33a2:    */
1:74f849b:   static void forwardAlgorithm(Matrix alpha, HmmModel model, int[] observations, boolean scaled) {
1:27d33a2: 
1:27d33a2:     // fetch references to the model parameters
1:27d33a2:     Vector ip = model.getInitialProbabilities();
1:27d33a2:     Matrix b = model.getEmissionMatrix();
1:27d33a2:     Matrix a = model.getTransitionMatrix();
1:27d33a2: 
1:27d33a2:     if (scaled) { // compute log scaled alpha values
1:27d33a2:       // Initialization
1:d53cf4a:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:d53cf4a:         alpha.setQuick(0, i, Math.log(ip.getQuick(i) * b.getQuick(i, observations[0])));
1:d53cf4a:       }
1:27d33a2: 
1:27d33a2:       // Induction
1:27d33a2:       for (int t = 1; t < observations.length; t++) {
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           double sum = Double.NEGATIVE_INFINITY; // log(0)
1:27d33a2:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:27d33a2:             double tmp = alpha.getQuick(t - 1, j) + Math.log(a.getQuick(j, i));
1:d53cf4a:             if (tmp > Double.NEGATIVE_INFINITY) {
1:d53cf4a:               // make sure we handle log(0) correctly
1:971a56d:               sum = tmp + Math.log1p(Math.exp(sum - tmp));
1:d53cf4a:             }
1:27d33a2:           }
1:27d33a2:           alpha.setQuick(t, i, sum + Math.log(b.getQuick(i, observations[t])));
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     } else {
1:27d33a2: 
1:27d33a2:       // Initialization
1:d53cf4a:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:         alpha.setQuick(0, i, ip.getQuick(i) * b.getQuick(i, observations[0]));
1:d53cf4a:       }
1:27d33a2: 
1:27d33a2:       // Induction
1:27d33a2:       for (int t = 1; t < observations.length; t++) {
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           double sum = 0.0;
1:27d33a2:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:27d33a2:             sum += alpha.getQuick(t - 1, j) * a.getQuick(j, i);
1:27d33a2:           }
1:27d33a2:           alpha.setQuick(t, i, sum * b.getQuick(i, observations[t]));
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * External function to compute a matrix of beta factors
1:27d33a2:    *
1:27d33a2:    * @param model        model to use for estimation.
1:27d33a2:    * @param observations observation sequence seen.
1:27d33a2:    * @param scaled       Set to true if log-scaled beta factors should be computed.
1:27d33a2:    * @return beta factors based on the model and observation sequence.
1:27d33a2:    */
1:74f849b:   public static Matrix backwardAlgorithm(HmmModel model, int[] observations, boolean scaled) {
1:27d33a2:     // initialize the matrix
1:d53cf4a:     Matrix beta = new DenseMatrix(observations.length, model.getNrOfHiddenStates());
1:27d33a2:     // compute the beta factors
1:27d33a2:     backwardAlgorithm(beta, model, observations, scaled);
1:27d33a2: 
1:27d33a2:     return beta;
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Internal function to compute the beta factors
1:27d33a2:    *
1:27d33a2:    * @param beta         Matrix to store resulting factors in.
1:27d33a2:    * @param model        model to use for factor estimation.
1:27d33a2:    * @param observations sequence of observations to estimate.
1:27d33a2:    * @param scaled       set to true to compute log-scaled parameters.
1:27d33a2:    */
1:74f849b:   static void backwardAlgorithm(Matrix beta, HmmModel model, int[] observations, boolean scaled) {
1:27d33a2:     // fetch references to the model parameters
1:27d33a2:     Matrix b = model.getEmissionMatrix();
1:27d33a2:     Matrix a = model.getTransitionMatrix();
1:27d33a2: 
1:27d33a2:     if (scaled) { // compute log-scaled factors
1:27d33a2:       // initialization
1:d53cf4a:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:         beta.setQuick(observations.length - 1, i, 0);
1:d53cf4a:       }
1:27d33a2: 
1:27d33a2:       // induction
1:27d33a2:       for (int t = observations.length - 2; t >= 0; t--) {
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           double sum = Double.NEGATIVE_INFINITY; // log(0)
1:27d33a2:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:27d33a2:             double tmp = beta.getQuick(t + 1, j) + Math.log(a.getQuick(i, j))
1:27d33a2:                 + Math.log(b.getQuick(j, observations[t + 1]));
1:d53cf4a:             if (tmp > Double.NEGATIVE_INFINITY) {
1:d53cf4a:               // handle log(0)
1:971a56d:               sum = tmp + Math.log1p(Math.exp(sum - tmp));
1:d53cf4a:             }
1:27d33a2:           }
1:27d33a2:           beta.setQuick(t, i, sum);
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     } else {
1:27d33a2:       // initialization
1:d53cf4a:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:         beta.setQuick(observations.length - 1, i, 1);
1:d53cf4a:       }
1:27d33a2:       // induction
1:27d33a2:       for (int t = observations.length - 2; t >= 0; t--) {
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           double sum = 0;
1:d53cf4a:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:d53cf4a:             sum += beta.getQuick(t + 1, j) * a.getQuick(i, j) * b.getQuick(j, observations[t + 1]);
1:d53cf4a:           }
1:27d33a2:           beta.setQuick(t, i, sum);
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Viterbi algorithm to compute the most likely hidden sequence for a given
1:27d33a2:    * model and observed sequence
1:27d33a2:    *
1:27d33a2:    * @param model        HmmModel for which the Viterbi path should be computed
1:27d33a2:    * @param observations Sequence of observations
1:27d33a2:    * @param scaled       Use log-scaled computations, this requires higher computational
1:27d33a2:    *                     effort but is numerically more stable for large observation
1:27d33a2:    *                     sequences
1:27d33a2:    * @return nrOfObservations 1D int array containing the most likely hidden
1:27d33a2:    *         sequence
1:27d33a2:    */
1:74f849b:   public static int[] viterbiAlgorithm(HmmModel model, int[] observations, boolean scaled) {
1:27d33a2: 
1:27d33a2:     // probability that the most probable hidden states ends at state i at
1:27d33a2:     // time t
1:27d33a2:     double[][] delta = new double[observations.length][model
1:27d33a2:         .getNrOfHiddenStates()];
1:27d33a2: 
1:27d33a2:     // previous hidden state in the most probable state leading up to state
1:27d33a2:     // i at time t
1:27d33a2:     int[][] phi = new int[observations.length - 1][model.getNrOfHiddenStates()];
1:27d33a2: 
1:27d33a2:     // initialize the return array
1:27d33a2:     int[] sequence = new int[observations.length];
1:27d33a2: 
1:27d33a2:     viterbiAlgorithm(sequence, delta, phi, model, observations, scaled);
1:27d33a2: 
1:27d33a2:     return sequence;
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Internal version of the viterbi algorithm, allowing to reuse existing
1:27d33a2:    * arrays instead of allocating new ones
1:27d33a2:    *
1:27d33a2:    * @param sequence     NrOfObservations 1D int array for storing the viterbi sequence
1:27d33a2:    * @param delta        NrOfObservations x NrHiddenStates 2D double array for storing the
1:27d33a2:    *                     delta factors
1:27d33a2:    * @param phi          NrOfObservations-1 x NrHiddenStates 2D int array for storing the
1:27d33a2:    *                     phi values
1:27d33a2:    * @param model        HmmModel for which the viterbi path should be computed
1:27d33a2:    * @param observations Sequence of observations
1:27d33a2:    * @param scaled       Use log-scaled computations, this requires higher computational
1:27d33a2:    *                     effort but is numerically more stable for large observation
1:27d33a2:    *                     sequences
1:27d33a2:    */
1:74f849b:   static void viterbiAlgorithm(int[] sequence, double[][] delta, int[][] phi, HmmModel model, int[] observations,
1:74f849b:       boolean scaled) {
1:27d33a2:     // fetch references to the model parameters
1:27d33a2:     Vector ip = model.getInitialProbabilities();
1:27d33a2:     Matrix b = model.getEmissionMatrix();
1:27d33a2:     Matrix a = model.getTransitionMatrix();
1:27d33a2: 
1:27d33a2:     // Initialization
1:27d33a2:     if (scaled) {
1:27d33a2:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:         delta[0][i] = Math.log(ip.getQuick(i) * b.getQuick(i, observations[0]));
1:27d33a2:       }
1:27d33a2:     } else {
1:27d33a2: 
1:27d33a2:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:         delta[0][i] = ip.getQuick(i) * b.getQuick(i, observations[0]);
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2: 
1:27d33a2:     // Induction
1:27d33a2:     // iterate over the time
1:27d33a2:     if (scaled) {
1:27d33a2:       for (int t = 1; t < observations.length; t++) {
1:27d33a2:         // iterate over the hidden states
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           // find the maximum probability and most likely state
1:27d33a2:           // leading up
1:27d33a2:           // to this
1:27d33a2:           int maxState = 0;
1:27d33a2:           double maxProb = delta[t - 1][0] + Math.log(a.getQuick(0, i));
1:27d33a2:           for (int j = 1; j < model.getNrOfHiddenStates(); j++) {
1:27d33a2:             double prob = delta[t - 1][j] + Math.log(a.getQuick(j, i));
1:27d33a2:             if (prob > maxProb) {
1:27d33a2:               maxProb = prob;
1:27d33a2:               maxState = j;
1:27d33a2:             }
1:27d33a2:           }
1:27d33a2:           delta[t][i] = maxProb + Math.log(b.getQuick(i, observations[t]));
1:27d33a2:           phi[t - 1][i] = maxState;
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     } else {
1:27d33a2:       for (int t = 1; t < observations.length; t++) {
1:27d33a2:         // iterate over the hidden states
1:27d33a2:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:           // find the maximum probability and most likely state
1:27d33a2:           // leading up
1:27d33a2:           // to this
1:27d33a2:           int maxState = 0;
1:27d33a2:           double maxProb = delta[t - 1][0] * a.getQuick(0, i);
1:27d33a2:           for (int j = 1; j < model.getNrOfHiddenStates(); j++) {
1:27d33a2:             double prob = delta[t - 1][j] * a.getQuick(j, i);
1:27d33a2:             if (prob > maxProb) {
1:27d33a2:               maxProb = prob;
1:27d33a2:               maxState = j;
1:27d33a2:             }
1:27d33a2:           }
1:27d33a2:           delta[t][i] = maxProb * b.getQuick(i, observations[t]);
1:27d33a2:           phi[t - 1][i] = maxState;
1:27d33a2:         }
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2: 
1:27d33a2:     // find the most likely end state for initialization
1:27d33a2:     double maxProb;
1:d53cf4a:     if (scaled) {
1:27d33a2:       maxProb = Double.NEGATIVE_INFINITY;
1:d53cf4a:     } else {
1:d53cf4a:       maxProb = 0.0;
1:d53cf4a:     }
1:27d33a2:     for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:27d33a2:       if (delta[observations.length - 1][i] > maxProb) {
1:27d33a2:         maxProb = delta[observations.length - 1][i];
1:27d33a2:         sequence[observations.length - 1] = i;
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2: 
1:27d33a2:     // now backtrack to find the most likely hidden sequence
1:d53cf4a:     for (int t = observations.length - 2; t >= 0; t--) {
1:27d33a2:       sequence[t] = phi[t][sequence[t + 1]];
1:d53cf4a:     }
1:27d33a2:   }
1:27d33a2: 
1:27d33a2: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:971a56d
/////////////////////////////////////////////////////////////////////////
1:               sum = tmp + Math.log1p(Math.exp(sum - tmp));
/////////////////////////////////////////////////////////////////////////
1:               sum = tmp + Math.log1p(Math.exp(sum - tmp));
commit:d53cf4a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     Matrix alpha = new DenseMatrix(observations.length, model.getNrOfHiddenStates());
/////////////////////////////////////////////////////////////////////////
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:         alpha.setQuick(0, i, Math.log(ip.getQuick(i) * b.getQuick(i, observations[0])));
1:       }
/////////////////////////////////////////////////////////////////////////
1:             if (tmp > Double.NEGATIVE_INFINITY) {
1:               // make sure we handle log(0) correctly
1:             }
/////////////////////////////////////////////////////////////////////////
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:       }
/////////////////////////////////////////////////////////////////////////
1:     Matrix beta = new DenseMatrix(observations.length, model.getNrOfHiddenStates());
/////////////////////////////////////////////////////////////////////////
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:       }
/////////////////////////////////////////////////////////////////////////
1:             if (tmp > Double.NEGATIVE_INFINITY) {
1:               // handle log(0)
1:             }
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:       }
1:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:             sum += beta.getQuick(t + 1, j) * a.getQuick(i, j) * b.getQuick(j, observations[t + 1]);
1:           }
/////////////////////////////////////////////////////////////////////////
1:     if (scaled) {
1:     } else {
1:       maxProb = 0.0;
1:     }
/////////////////////////////////////////////////////////////////////////
1:     for (int t = observations.length - 2; t >= 0; t--) {
1:     }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:74f849b
/////////////////////////////////////////////////////////////////////////
1:   public static Matrix forwardAlgorithm(HmmModel model, int[] observations, boolean scaled) {
/////////////////////////////////////////////////////////////////////////
1:   static void forwardAlgorithm(Matrix alpha, HmmModel model, int[] observations, boolean scaled) {
/////////////////////////////////////////////////////////////////////////
1:   public static Matrix backwardAlgorithm(HmmModel model, int[] observations, boolean scaled) {
/////////////////////////////////////////////////////////////////////////
1:   static void backwardAlgorithm(Matrix beta, HmmModel model, int[] observations, boolean scaled) {
/////////////////////////////////////////////////////////////////////////
1:   public static int[] viterbiAlgorithm(HmmModel model, int[] observations, boolean scaled) {
/////////////////////////////////////////////////////////////////////////
1:   static void viterbiAlgorithm(int[] sequence, double[][] delta, int[][] phi, HmmModel model, int[] observations,
1:       boolean scaled) {
author:Isabel Drost
-------------------------------------------------------------------------------
commit:27d33a2
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.sequencelearning.hmm;
1: 
1: import org.apache.mahout.math.DenseMatrix;
1: import org.apache.mahout.math.Matrix;
1: import org.apache.mahout.math.Vector;
1: 
1: /**
1:  * Class containing implementations of the three major HMM algorithms: forward,
1:  * backward and Viterbi
1:  *
0:  * @author mheimel
1:  */
1: public final class HmmAlgorithms {
1: 
1: 
1:   /**
1:    * No public constructors for utility classes.
1:    */
1:   private HmmAlgorithms() {
1:     // nothing to do here really
1:   }
1: 
1:   /**
1:    * External function to compute a matrix of alpha factors
1:    *
1:    * @param model        model to run forward algorithm for.
1:    * @param observations observation sequence to train on.
1:    * @param scaled       Should log-scaled beta factors be computed?
1:    * @return matrix of alpha factors.
1:    */
0:   public static Matrix forwardAlgorithm(HmmModel model, int[] observations,
0:                                         boolean scaled) {
1: 
0:     DenseMatrix alpha = new DenseMatrix(observations.length, model
0:         .getNrOfHiddenStates());
1: 
1:     forwardAlgorithm(alpha, model, observations, scaled);
1: 
1:     return alpha;
1:   }
1: 
1:   /**
1:    * Internal function to compute the alpha factors
1:    *
1:    * @param alpha        matrix to store alpha factors in.
1:    * @param model        model to use for alpha factor computation.
1:    * @param observations observation sequence seen.
1:    * @param scaled       set to true if log-scaled beta factors should be computed.
1:    */
0:   static void forwardAlgorithm(Matrix alpha, HmmModel model,
0:                                int[] observations, boolean scaled) {
1: 
1:     // fetch references to the model parameters
1:     Vector ip = model.getInitialProbabilities();
1:     Matrix b = model.getEmissionMatrix();
1:     Matrix a = model.getTransitionMatrix();
1: 
1:     if (scaled) { // compute log scaled alpha values
1:       // Initialization
0:       for (int i = 0; i < model.getNrOfHiddenStates(); i++)
0:         alpha.setQuick(0, i, Math.log(ip.getQuick(i)
0:             * b.getQuick(i, observations[0])));
1: 
1:       // Induction
1:       for (int t = 1; t < observations.length; t++) {
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           double sum = Double.NEGATIVE_INFINITY; // log(0)
1:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:             double tmp = alpha.getQuick(t - 1, j) + Math.log(a.getQuick(j, i));
0:             if (tmp > Double.NEGATIVE_INFINITY) // make sure we
0:               // handle
0:               // log(0) correctly
0:               sum = tmp + Math.log(1 + Math.exp(sum - tmp));
1:           }
1:           alpha.setQuick(t, i, sum + Math.log(b.getQuick(i, observations[t])));
1:         }
1:       }
1:     } else {
1: 
1:       // Initialization
0:       for (int i = 0; i < model.getNrOfHiddenStates(); i++)
1:         alpha.setQuick(0, i, ip.getQuick(i) * b.getQuick(i, observations[0]));
1: 
1:       // Induction
1:       for (int t = 1; t < observations.length; t++) {
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           double sum = 0.0;
1:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:             sum += alpha.getQuick(t - 1, j) * a.getQuick(j, i);
1:           }
1:           alpha.setQuick(t, i, sum * b.getQuick(i, observations[t]));
1:         }
1:       }
1:     }
1:   }
1: 
1:   /**
1:    * External function to compute a matrix of beta factors
1:    *
1:    * @param model        model to use for estimation.
1:    * @param observations observation sequence seen.
1:    * @param scaled       Set to true if log-scaled beta factors should be computed.
1:    * @return beta factors based on the model and observation sequence.
1:    */
0:   public static Matrix backwardAlgorithm(HmmModel model, int[] observations,
0:                                          boolean scaled) {
1: 
1:     // initialize the matrix
0:     DenseMatrix beta = new DenseMatrix(observations.length, model
0:         .getNrOfHiddenStates());
1:     // compute the beta factors
1:     backwardAlgorithm(beta, model, observations, scaled);
1: 
1:     return beta;
1:   }
1: 
1:   /**
1:    * Internal function to compute the beta factors
1:    *
1:    * @param beta         Matrix to store resulting factors in.
1:    * @param model        model to use for factor estimation.
1:    * @param observations sequence of observations to estimate.
1:    * @param scaled       set to true to compute log-scaled parameters.
1:    */
0:   static void backwardAlgorithm(Matrix beta, HmmModel model,
0:                                 int[] observations, boolean scaled) {
1:     // fetch references to the model parameters
1:     Matrix b = model.getEmissionMatrix();
1:     Matrix a = model.getTransitionMatrix();
1: 
1:     if (scaled) { // compute log-scaled factors
1:       // initialization
0:       for (int i = 0; i < model.getNrOfHiddenStates(); i++)
1:         beta.setQuick(observations.length - 1, i, 0);
1: 
1:       // induction
1:       for (int t = observations.length - 2; t >= 0; t--) {
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           double sum = Double.NEGATIVE_INFINITY; // log(0)
1:           for (int j = 0; j < model.getNrOfHiddenStates(); j++) {
1:             double tmp = beta.getQuick(t + 1, j) + Math.log(a.getQuick(i, j))
1:                 + Math.log(b.getQuick(j, observations[t + 1]));
0:             if (tmp > Double.NEGATIVE_INFINITY) // handle log(0)
0:               sum = tmp + Math.log(1 + Math.exp(sum - tmp));
1:           }
1:           beta.setQuick(t, i, sum);
1:         }
1:       }
1:     } else {
1:       // initialization
0:       for (int i = 0; i < model.getNrOfHiddenStates(); i++)
1:         beta.setQuick(observations.length - 1, i, 1);
1:       // induction
1:       for (int t = observations.length - 2; t >= 0; t--) {
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           double sum = 0;
0:           for (int j = 0; j < model.getNrOfHiddenStates(); j++)
0:             sum += beta.getQuick(t + 1, j) * a.getQuick(i, j)
0:                 * b.getQuick(j, observations[t + 1]);
1:           beta.setQuick(t, i, sum);
1:         }
1:       }
1:     }
1:   }
1: 
1:   /**
1:    * Viterbi algorithm to compute the most likely hidden sequence for a given
1:    * model and observed sequence
1:    *
1:    * @param model        HmmModel for which the Viterbi path should be computed
1:    * @param observations Sequence of observations
1:    * @param scaled       Use log-scaled computations, this requires higher computational
1:    *                     effort but is numerically more stable for large observation
1:    *                     sequences
1:    * @return nrOfObservations 1D int array containing the most likely hidden
1:    *         sequence
1:    */
0:   public static int[] viterbiAlgorithm(HmmModel model, int[] observations,
0:                                        boolean scaled) {
1: 
1:     // probability that the most probable hidden states ends at state i at
1:     // time t
1:     double[][] delta = new double[observations.length][model
1:         .getNrOfHiddenStates()];
1: 
1:     // previous hidden state in the most probable state leading up to state
1:     // i at time t
1:     int[][] phi = new int[observations.length - 1][model.getNrOfHiddenStates()];
1: 
1:     // initialize the return array
1:     int[] sequence = new int[observations.length];
1: 
1:     viterbiAlgorithm(sequence, delta, phi, model, observations, scaled);
1: 
1:     return sequence;
1:   }
1: 
1:   /**
1:    * Internal version of the viterbi algorithm, allowing to reuse existing
1:    * arrays instead of allocating new ones
1:    *
1:    * @param sequence     NrOfObservations 1D int array for storing the viterbi sequence
1:    * @param delta        NrOfObservations x NrHiddenStates 2D double array for storing the
1:    *                     delta factors
1:    * @param phi          NrOfObservations-1 x NrHiddenStates 2D int array for storing the
1:    *                     phi values
1:    * @param model        HmmModel for which the viterbi path should be computed
1:    * @param observations Sequence of observations
1:    * @param scaled       Use log-scaled computations, this requires higher computational
1:    *                     effort but is numerically more stable for large observation
1:    *                     sequences
1:    */
0:   static void viterbiAlgorithm(int[] sequence, double[][] delta, int[][] phi,
0:                                HmmModel model, int[] observations, boolean scaled) {
1:     // fetch references to the model parameters
1:     Vector ip = model.getInitialProbabilities();
1:     Matrix b = model.getEmissionMatrix();
1:     Matrix a = model.getTransitionMatrix();
1: 
1:     // Initialization
1:     if (scaled) {
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:         delta[0][i] = Math.log(ip.getQuick(i) * b.getQuick(i, observations[0]));
1:       }
1:     } else {
1: 
1:       for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:         delta[0][i] = ip.getQuick(i) * b.getQuick(i, observations[0]);
1:       }
1:     }
1: 
1:     // Induction
1:     // iterate over the time
1:     if (scaled) {
1:       for (int t = 1; t < observations.length; t++) {
1:         // iterate over the hidden states
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           // find the maximum probability and most likely state
1:           // leading up
1:           // to this
1:           int maxState = 0;
1:           double maxProb = delta[t - 1][0] + Math.log(a.getQuick(0, i));
1:           for (int j = 1; j < model.getNrOfHiddenStates(); j++) {
1:             double prob = delta[t - 1][j] + Math.log(a.getQuick(j, i));
1:             if (prob > maxProb) {
1:               maxProb = prob;
1:               maxState = j;
1:             }
1:           }
1:           delta[t][i] = maxProb + Math.log(b.getQuick(i, observations[t]));
1:           phi[t - 1][i] = maxState;
1:         }
1:       }
1:     } else {
1:       for (int t = 1; t < observations.length; t++) {
1:         // iterate over the hidden states
1:         for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:           // find the maximum probability and most likely state
1:           // leading up
1:           // to this
1:           int maxState = 0;
1:           double maxProb = delta[t - 1][0] * a.getQuick(0, i);
1:           for (int j = 1; j < model.getNrOfHiddenStates(); j++) {
1:             double prob = delta[t - 1][j] * a.getQuick(j, i);
1:             if (prob > maxProb) {
1:               maxProb = prob;
1:               maxState = j;
1:             }
1:           }
1:           delta[t][i] = maxProb * b.getQuick(i, observations[t]);
1:           phi[t - 1][i] = maxState;
1:         }
1:       }
1:     }
1: 
1:     // find the most likely end state for initialization
1:     double maxProb;
0:     if (scaled)
1:       maxProb = Double.NEGATIVE_INFINITY;
0:     else
0:       maxProb = 0;
1:     for (int i = 0; i < model.getNrOfHiddenStates(); i++) {
1:       if (delta[observations.length - 1][i] > maxProb) {
1:         maxProb = delta[observations.length - 1][i];
1:         sequence[observations.length - 1] = i;
1:       }
1:     }
1: 
1:     // now backtrack to find the most likely hidden sequence
0:     for (int t = observations.length - 2; t >= 0; t--)
1:       sequence[t] = phi[t][sequence[t + 1]];
1:   }
1: 
1: }
============================================================================
1:131eb4a: /**
1:131eb4a:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:131eb4a:  * contributor license agreements.  See the NOTICE file distributed with
1:131eb4a:  * this work for additional information regarding copyright ownership.
1:131eb4a:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:131eb4a:  * (the "License"); you may not use this file except in compliance with
1:131eb4a:  * the License.  You may obtain a copy of the License at
1:131eb4a:  *
1:131eb4a:  *     http://www.apache.org/licenses/LICENSE-2.0
1:131eb4a:  *
1:131eb4a:  * Unless required by applicable law or agreed to in writing, software
1:131eb4a:  * distributed under the License is distributed on an "AS IS" BASIS,
1:131eb4a:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:131eb4a:  * See the License for the specific language governing permissions and
1:131eb4a:  * limitations under the License.
1:131eb4a:  */
1:131eb4a: package org.apache.mahout.clustering.lda.cvb;
1:131eb4a: 
1:131eb4a: import org.apache.hadoop.io.IntWritable;
1:131eb4a: import org.apache.mahout.math.DenseVector;
1:131eb4a: import org.apache.mahout.math.Matrix;
1:131eb4a: import org.apache.mahout.math.SparseRowMatrix;
1:131eb4a: import org.apache.mahout.math.Vector;
1:131eb4a: import org.apache.mahout.math.VectorWritable;
1:131eb4a: 
1:131eb4a: import java.io.IOException;
1:131eb4a: 
1:131eb4a: public class CVB0DocInferenceMapper extends CachingCVB0Mapper {
1:131eb4a: 
1:4aed7cc:   private final VectorWritable topics = new VectorWritable();
1:4aed7cc: 
1:131eb4a:   @Override
1:131eb4a:   public void map(IntWritable docId, VectorWritable doc, Context context)
1:6d16230:     throws IOException, InterruptedException {
1:4fbfbc6:     int numTopics = getNumTopics();
1:4aed7cc:     Vector docTopics = new DenseVector(numTopics).assign(1.0 / numTopics);
1:131eb4a:     Matrix docModel = new SparseRowMatrix(numTopics, doc.get().size());
1:4fbfbc6:     int maxIters = getMaxIters();
1:4fbfbc6:     ModelTrainer modelTrainer = getModelTrainer();
1:e64dd36:     for (int i = 0; i < maxIters; i++) {
1:131eb4a:       modelTrainer.getReadModel().trainDocTopicModel(doc.get(), docTopics, docModel);
1:131eb4a:     }
1:4aed7cc:     topics.set(docTopics);
1:4aed7cc:     context.write(docId, topics);
1:131eb4a:   }
1:131eb4a: 
1:131eb4a:   @Override
1:131eb4a:   protected void cleanup(Context context) {
1:4fbfbc6:     getModelTrainer().stop();
1:131eb4a:   }
1:131eb4a: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:4aed7cc
/////////////////////////////////////////////////////////////////////////
1:   private final VectorWritable topics = new VectorWritable();
1: 
1:     Vector docTopics = new DenseVector(numTopics).assign(1.0 / numTopics);
1:     topics.set(docTopics);
1:     context.write(docId, topics);
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:     throws IOException, InterruptedException {
commit:4841efb
/////////////////////////////////////////////////////////////////////////
0:     Vector docTopics = new DenseVector(new double[numTopics]).assign(1.0 / numTopics);
author:tcp
-------------------------------------------------------------------------------
commit:e64dd36
/////////////////////////////////////////////////////////////////////////
1:     for (int i = 0; i < maxIters; i++) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
1:     int numTopics = getNumTopics();
0:     Vector docTopics = new DenseVector(new double[numTopics]).assign(1.0 /numTopics);
1:     int maxIters = getMaxIters();
1:     ModelTrainer modelTrainer = getModelTrainer();
/////////////////////////////////////////////////////////////////////////
1:     getModelTrainer().stop();
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:131eb4a
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.mahout.clustering.lda.cvb;
1: 
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Matrix;
1: import org.apache.mahout.math.SparseRowMatrix;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: 
1: import java.io.IOException;
1: 
1: public class CVB0DocInferenceMapper extends CachingCVB0Mapper {
1: 
1:   @Override
1:   public void map(IntWritable docId, VectorWritable doc, Context context)
0:       throws IOException, InterruptedException {
0:     Vector docTopics = new DenseVector(new double[numTopics]).assign(1d/numTopics);
1:     Matrix docModel = new SparseRowMatrix(numTopics, doc.get().size());
0:     for(int i = 0; i < maxIters; i++) {
1:       modelTrainer.getReadModel().trainDocTopicModel(doc.get(), docTopics, docModel);
1:     }
0:     context.write(docId, new VectorWritable(docTopics));
1:   }
1: 
1:   @Override
1:   protected void cleanup(Context context) {
0:     modelTrainer.stop();
1:   }
1: }
============================================================================
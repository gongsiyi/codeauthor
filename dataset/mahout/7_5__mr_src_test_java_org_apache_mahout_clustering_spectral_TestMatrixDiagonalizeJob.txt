1:48d069f: /**
1:48d069f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:48d069f:  * contributor license agreements.  See the NOTICE file distributed with
1:48d069f:  * this work for additional information regarding copyright ownership.
1:48d069f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:48d069f:  * (the "License"); you may not use this file except in compliance with
1:48d069f:  * the License.  You may obtain a copy of the License at
1:48d069f:  *
1:48d069f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:48d069f:  *
1:48d069f:  * Unless required by applicable law or agreed to in writing, software
1:48d069f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:48d069f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:48d069f:  * See the License for the specific language governing permissions and
1:48d069f:  * limitations under the License.
1:48d069f:  */
1:48d069f: 
1:b60c909: package org.apache.mahout.clustering.spectral;
1:48d069f: 
1:48d069f: import java.util.List;
1:48d069f: 
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.io.NullWritable;
1:48d069f: import org.apache.hadoop.mapreduce.Mapper;
1:48d069f: import org.apache.hadoop.mapreduce.Reducer;
1:b60c909: import org.apache.mahout.clustering.spectral.MatrixDiagonalizeJob.MatrixDiagonalizeMapper;
1:b60c909: import org.apache.mahout.clustering.spectral.MatrixDiagonalizeJob.MatrixDiagonalizeReducer;
1:48d069f: import org.apache.mahout.common.DummyRecordWriter;
1:48d069f: import org.apache.mahout.common.MahoutTestCase;
1:48d069f: import org.apache.mahout.math.RandomAccessSparseVector;
1:48d069f: import org.apache.mahout.math.Vector;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: import org.junit.Test;
1:48d069f: 
1:48d069f: /**
1:48d069f:  * <p>The MatrixDiagonalize task is pretty simple: given a matrix,
1:48d069f:  * it sums the elements of the row, and sticks the sum in position (i, i) 
1:48d069f:  * of a new matrix of identical dimensions to the original.</p>
1:48d069f:  */
1:48d069f: public class TestMatrixDiagonalizeJob extends MahoutTestCase {
1:48d069f:   
1:049e7dc:   private static final double[][] RAW = { {1, 2, 3}, {4, 5, 6}, {7, 8, 9} };
1:049e7dc:   private static final int RAW_DIMENSIONS = 3;
1:48d069f:   
1:48d069f:   private static double rowSum(double [] row) {
1:48d069f:     double sum = 0;
1:049e7dc:     for (double r : row) {
1:049e7dc:       sum += r;
1:049e7dc:     }
1:48d069f:     return sum;
1:48d069f:   }
1:48d069f: 
1:48d069f:   @Test
1:48d069f:   public void testMatrixDiagonalizeMapper() throws Exception {
1:48d069f:     MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();
1:921e201:     Configuration conf = getConfiguration();
1:b60c909:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:48d069f:     
1:48d069f:     // set up the dummy writers
1:b60c909:     DummyRecordWriter<NullWritable, IntDoublePairWritable> writer =
1:02ff22f:       new DummyRecordWriter<>();
1:48d069f:     Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context 
1:48d069f:       context = DummyRecordWriter.build(mapper, conf, writer);
1:48d069f:     
1:48d069f:     // perform the mapping
1:049e7dc:     for (int i = 0; i < RAW_DIMENSIONS; i++) {
1:049e7dc:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);
1:049e7dc:       toAdd.assign(RAW[i]);
1:48d069f:       mapper.map(new IntWritable(i), new VectorWritable(toAdd), context);
1:48d069f:     }
1:48d069f:     
1:48d069f:     // check the number of the results
1:049e7dc:     assertEquals("Number of map results", RAW_DIMENSIONS,
1:48d069f:         writer.getValue(NullWritable.get()).size());
1:48d069f:   }
1:48d069f:   
1:48d069f:   @Test
1:48d069f:  public void testMatrixDiagonalizeReducer() throws Exception {
1:48d069f:     MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();
1:921e201:     Configuration conf = getConfiguration();
1:b60c909:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:48d069f:     
1:48d069f:     // set up the dummy writers
1:48d069f:     DummyRecordWriter<NullWritable, IntDoublePairWritable> mapWriter = 
1:02ff22f:       new DummyRecordWriter<>();
1:48d069f:     Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context 
1:48d069f:       mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);
1:48d069f:     
1:48d069f:     // perform the mapping
1:049e7dc:     for (int i = 0; i < RAW_DIMENSIONS; i++) {
1:049e7dc:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);
1:049e7dc:       toAdd.assign(RAW[i]);
1:48d069f:       mapper.map(new IntWritable(i), new VectorWritable(toAdd), mapContext);
1:48d069f:     }
1:48d069f:     
1:48d069f:     // now perform the reduction
1:48d069f:     MatrixDiagonalizeReducer reducer = new MatrixDiagonalizeReducer();
1:48d069f:     DummyRecordWriter<NullWritable, VectorWritable> redWriter = new
1:02ff22f:       DummyRecordWriter<>();
1:48d069f:     Reducer<NullWritable, IntDoublePairWritable, NullWritable, VectorWritable>.Context
1:48d069f:       redContext = DummyRecordWriter.build(reducer, conf, redWriter, 
1:48d069f:       NullWritable.class, IntDoublePairWritable.class);
1:48d069f:     
1:48d069f:     // only need one reduction
1:48d069f:     reducer.reduce(NullWritable.get(), mapWriter.getValue(NullWritable.get()), redContext);
1:48d069f:     
1:48d069f:     // first, make sure there's only one result
1:48d069f:     List<VectorWritable> list = redWriter.getValue(NullWritable.get());
1:48d069f:     assertEquals("Only a single resulting vector", 1, list.size());
1:48d069f:     Vector v = list.get(0).get();
1:48d069f:     for (int i = 0; i < v.size(); i++) {
1:049e7dc:       assertEquals("Element sum is correct", rowSum(RAW[i]), v.get(i),0.01);
1:48d069f:     }
1:48d069f:   }
1:48d069f: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:       new DummyRecordWriter<>();
/////////////////////////////////////////////////////////////////////////
1:       new DummyRecordWriter<>();
/////////////////////////////////////////////////////////////////////////
1:       DummyRecordWriter<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.spectral.MatrixDiagonalizeJob.MatrixDiagonalizeMapper;
1: import org.apache.mahout.clustering.spectral.MatrixDiagonalizeJob.MatrixDiagonalizeReducer;
/////////////////////////////////////////////////////////////////////////
1:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
1:     DummyRecordWriter<NullWritable, IntDoublePairWritable> writer =
/////////////////////////////////////////////////////////////////////////
1:     conf.setInt(Keys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
1:   private static final double[][] RAW = { {1, 2, 3}, {4, 5, 6}, {7, 8, 9} };
1:   private static final int RAW_DIMENSIONS = 3;
1:     for (double r : row) {
1:       sum += r;
1:     }
/////////////////////////////////////////////////////////////////////////
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
/////////////////////////////////////////////////////////////////////////
1:     for (int i = 0; i < RAW_DIMENSIONS; i++) {
1:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);
1:       toAdd.assign(RAW[i]);
1:     assertEquals("Number of map results", RAW_DIMENSIONS,
/////////////////////////////////////////////////////////////////////////
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, RAW_DIMENSIONS);
/////////////////////////////////////////////////////////////////////////
1:     for (int i = 0; i < RAW_DIMENSIONS; i++) {
1:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(RAW_DIMENSIONS);
1:       toAdd.assign(RAW[i]);
/////////////////////////////////////////////////////////////////////////
1:       assertEquals("Element sum is correct", rowSum(RAW[i]), v.get(i),0.01);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:48d069f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.util.List;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.NullWritable;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.Reducer;
0: import org.apache.mahout.clustering.spectral.common.MatrixDiagonalizeJob.MatrixDiagonalizeMapper;
0: import org.apache.mahout.clustering.spectral.common.MatrixDiagonalizeJob.MatrixDiagonalizeReducer;
0: import org.apache.mahout.clustering.spectral.eigencuts.EigencutsKeys;
1: import org.apache.mahout.common.DummyRecordWriter;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.math.RandomAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Test;
1: 
1: /**
1:  * <p>The MatrixDiagonalize task is pretty simple: given a matrix,
1:  * it sums the elements of the row, and sticks the sum in position (i, i) 
1:  * of a new matrix of identical dimensions to the original.</p>
1:  */
1: public class TestMatrixDiagonalizeJob extends MahoutTestCase {
1:   
0:   private double [][] raw = { {1, 2, 3}, {4, 5, 6}, {7, 8, 9} };
0:   private int rawDimensions = 3;
1:   
1:   private static double rowSum(double [] row) {
1:     double sum = 0;
0:     for (int i = 0; i < row.length; i++) { sum += row[i]; }
1:     return sum;
1:   }
1: 
1:   @Test
1:   public void testMatrixDiagonalizeMapper() throws Exception {
1:     MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();
0:     Configuration conf = new Configuration();
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, rawDimensions);
1:     
1:     // set up the dummy writers
0:     DummyRecordWriter<NullWritable, IntDoublePairWritable> writer = 
0:       new DummyRecordWriter<NullWritable, IntDoublePairWritable>();
1:     Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context 
1:       context = DummyRecordWriter.build(mapper, conf, writer);
1:     
1:     // perform the mapping
0:     for (int i = 0; i < rawDimensions; i++) {
0:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(rawDimensions);
0:       toAdd.assign(raw[i]);
1:       mapper.map(new IntWritable(i), new VectorWritable(toAdd), context);
1:     }
1:     
1:     // check the number of the results
0:     assertEquals("Number of map results", rawDimensions, 
1:         writer.getValue(NullWritable.get()).size());
1:   }
1:   
1:   @Test
1:  public void testMatrixDiagonalizeReducer() throws Exception {
1:     MatrixDiagonalizeMapper mapper = new MatrixDiagonalizeMapper();
0:     Configuration conf = new Configuration();
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, rawDimensions);
1:     
1:     // set up the dummy writers
1:     DummyRecordWriter<NullWritable, IntDoublePairWritable> mapWriter = 
0:       new DummyRecordWriter<NullWritable, IntDoublePairWritable>();
1:     Mapper<IntWritable, VectorWritable, NullWritable, IntDoublePairWritable>.Context 
1:       mapContext = DummyRecordWriter.build(mapper, conf, mapWriter);
1:     
1:     // perform the mapping
0:     for (int i = 0; i < rawDimensions; i++) {
0:       RandomAccessSparseVector toAdd = new RandomAccessSparseVector(rawDimensions);
0:       toAdd.assign(raw[i]);
1:       mapper.map(new IntWritable(i), new VectorWritable(toAdd), mapContext);
1:     }
1:     
1:     // now perform the reduction
1:     MatrixDiagonalizeReducer reducer = new MatrixDiagonalizeReducer();
1:     DummyRecordWriter<NullWritable, VectorWritable> redWriter = new
0:       DummyRecordWriter<NullWritable, VectorWritable>();
1:     Reducer<NullWritable, IntDoublePairWritable, NullWritable, VectorWritable>.Context
1:       redContext = DummyRecordWriter.build(reducer, conf, redWriter, 
1:       NullWritable.class, IntDoublePairWritable.class);
1:     
1:     // only need one reduction
1:     reducer.reduce(NullWritable.get(), mapWriter.getValue(NullWritable.get()), redContext);
1:     
1:     // first, make sure there's only one result
1:     List<VectorWritable> list = redWriter.getValue(NullWritable.get());
1:     assertEquals("Only a single resulting vector", 1, list.size());
1:     Vector v = list.get(0).get();
1:     for (int i = 0; i < v.size(); i++) {
0:       assertEquals("Element sum is correct", rowSum(raw[i]), v.get(i),0.01);
1:     }
1:   }
1: }
============================================================================
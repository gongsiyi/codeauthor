2:9d44881: /**
1:9d44881:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:9d44881:  * contributor license agreements.  See the NOTICE file distributed with
1:9d44881:  * this work for additional information regarding copyright ownership.
1:9d44881:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:9d44881:  * (the "License"); you may not use this file except in compliance with
1:9d44881:  * the License.  You may obtain a copy of the License at
8:9d44881:  *
1:9d44881:  *     http://www.apache.org/licenses/LICENSE-2.0
1:9d44881:  *
1:9d44881:  * Unless required by applicable law or agreed to in writing, software
1:9d44881:  * distributed under the License is distributed on an "AS IS" BASIS,
1:9d44881:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:9d44881:  * See the License for the specific language governing permissions and
1:9d44881:  * limitations under the License.
2:9d44881:  */
21:9d44881: 
1:9d44881: package org.apache.mahout.clustering.topdown.postprocessor;
1:9d44881: 
1:85f9ece: import java.io.IOException;
1:85f9ece: import java.util.HashMap;
1:85f9ece: import java.util.Map;
1:85f9ece: 
1:9d44881: import org.apache.hadoop.conf.Configuration;
1:9d44881: import org.apache.hadoop.fs.FileSystem;
1:9d44881: import org.apache.hadoop.fs.Path;
1:9d44881: import org.apache.hadoop.io.LongWritable;
1:9d44881: import org.apache.hadoop.io.SequenceFile;
1:9d44881: import org.apache.hadoop.io.SequenceFile.Writer;
1:9d44881: import org.apache.hadoop.io.Writable;
1:8953d93: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
1:9d44881: import org.apache.mahout.clustering.topdown.PathDirectory;
1:564c3e1: import org.apache.mahout.common.IOUtils;
1:564c3e1: import org.apache.mahout.common.Pair;
1:9d44881: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:564c3e1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:564c3e1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
1:9d44881: import org.apache.mahout.math.VectorWritable;
1:bbf5369: 
1:9d44881: /**
1:9d44881:  * This class reads the output of any clustering algorithm, and, creates separate directories for different
1:9d44881:  * clusters. Each cluster directory's name is its clusterId. Each and every point is written in the cluster
1:9d44881:  * directory associated with that point.
1:bbf5369:  * <p/>
1:9d44881:  * This class incorporates a sequential algorithm and is appropriate for use for data which has been clustered
1:9d44881:  * sequentially.
1:bbf5369:  * <p/>
1:564c3e1:  * The sequential and non sequential version, both are being used from {@link ClusterOutputPostProcessorDriver}.
1:9d44881:  */
1:564c3e1: public final class ClusterOutputPostProcessor {
1:bbf5369: 
1:9d44881:   private Path clusteredPoints;
1:564c3e1:   private final FileSystem fileSystem;
1:564c3e1:   private final Configuration conf;
1:564c3e1:   private final Path clusterPostProcessorOutput;
1:85f9ece:   private final Map<String, Path> postProcessedClusterDirectories = new HashMap<>();
1:564c3e1:   private long uniqueVectorId = 0L;
1:bbf5369:   private final Map<String, SequenceFile.Writer> writersForClusters;
1:bbf5369: 
1:9d44881:   public ClusterOutputPostProcessor(Path clusterOutputToBeProcessed,
1:9d44881:                                     Path output,
1:564c3e1:                                     Configuration hadoopConfiguration) throws IOException {
1:9d44881:     this.clusterPostProcessorOutput = output;
1:564c3e1:     this.clusteredPoints = PathDirectory.getClusterOutputClusteredPoints(clusterOutputToBeProcessed);
1:9d44881:     this.conf = hadoopConfiguration;
1:85f9ece:     this.writersForClusters = new HashMap<>();
1:bbf5369:     fileSystem = clusteredPoints.getFileSystem(conf);
7:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:9d44881:    * This method takes the clustered points output by the clustering algorithms as input and writes them into
1:9d44881:    * their respective clusters.
1:9d44881:    */
1:564c3e1:   public void process() throws IOException {
1:9d44881:     createPostProcessDirectory();
1:bbf5369:     for (Pair<?, WeightedVectorWritable> record
1:58cc1ae:         : new SequenceFileDirIterable<Writable, WeightedVectorWritable>(clusteredPoints, PathType.GLOB, PathFilters.partFilter(),
1:58cc1ae:                                                                         null, false, conf)) {
1:564c3e1:       String clusterId = record.getFirst().toString().trim();
1:564c3e1:       putVectorInRespectiveCluster(clusterId, record.getSecond());
1:9d44881:     }
1:564c3e1:     IOUtils.close(writersForClusters.values());
1:564c3e1:     writersForClusters.clear();
1:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:9d44881:    * Creates the directory to put post processed clusters.
1:9d44881:    */
1:9d44881:   private void createPostProcessDirectory() throws IOException {
1:6d16230:     if (!fileSystem.exists(clusterPostProcessorOutput)
1:6d16230:             && !fileSystem.mkdirs(clusterPostProcessorOutput)) {
1:229aeff:       throw new IOException("Error creating cluster post processor directory");
1:9d44881:     }
1:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:9d44881:    * Finds out the cluster directory of the vector and writes it into the specified cluster.
1:9d44881:    */
1:9d44881:   private void putVectorInRespectiveCluster(String clusterId, WeightedVectorWritable point) throws IOException {
1:9d44881:     Writer writer = findWriterForVector(clusterId);
1:9d44881:     postProcessedClusterDirectories.put(clusterId,
1:4841efb:             PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));
1:9d44881:     writeVectorToCluster(writer, point);
1:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:9d44881:    * Finds out the path in cluster where the point is supposed to be written.
1:9d44881:    */
1:9d44881:   private Writer findWriterForVector(String clusterId) throws IOException {
1:9d44881:     Path clusterDirectory = PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId);
1:9d44881:     Writer writer = writersForClusters.get(clusterId);
1:9d44881:     if (writer == null) {
1:564c3e1:       Path pathToWrite = new Path(clusterDirectory, new Path("part-m-0"));
1:564c3e1:       writer = new Writer(fileSystem, conf, pathToWrite, LongWritable.class, VectorWritable.class);
1:9d44881:       writersForClusters.put(clusterId, writer);
1:9d44881:     }
1:9d44881:     return writer;
1:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:9d44881:    * Writes vector to the cluster directory.
1:9d44881:    */
1:9d44881:   private void writeVectorToCluster(Writer writer, WeightedVectorWritable point) throws IOException {
1:9d44881:     writer.append(new LongWritable(uniqueVectorId++), new VectorWritable(point.getVector()));
1:9d44881:     writer.sync();
1:9d44881:   }
1:bbf5369: 
1:9d44881:   /**
1:564c3e1:    * @return the set of all post processed cluster paths.
1:9d44881:    */
1:bbf5369:   public Map<String, Path> getPostProcessedClusterDirectories() {
1:9d44881:     return postProcessedClusterDirectories;
1:9d44881:   }
1:bbf5369: 
1:9d44881:   public void setClusteredPoints(Path clusteredPoints) {
1:9d44881:     this.clusteredPoints = clusteredPoints;
1:4841efb:   }
1:bbf5369: 
1:9d44881: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import java.util.HashMap;
1: import java.util.Map;
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private final Map<String, Path> postProcessedClusterDirectories = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:     this.writersForClusters = new HashMap<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1:         : new SequenceFileDirIterable<Writable, WeightedVectorWritable>(clusteredPoints, PathType.GLOB, PathFilters.partFilter(),
1:                                                                         null, false, conf)) {
commit:6d16230
/////////////////////////////////////////////////////////////////////////
0:     for (Pair<?,WeightedVectorWritable> record
0:         : new SequenceFileDirIterable<Writable,WeightedVectorWritable>(clusteredPoints,
/////////////////////////////////////////////////////////////////////////
1:     if (!fileSystem.exists(clusterPostProcessorOutput)
1:         && !fileSystem.mkdirs(clusterPostProcessorOutput)) {
commit:4841efb
/////////////////////////////////////////////////////////////////////////
1:         PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));
/////////////////////////////////////////////////////////////////////////
1: }
author:smarthi
-------------------------------------------------------------------------------
commit:4da4468
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Maps;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   private final Map<String, Path> postProcessedClusterDirectories = Maps.newHashMap();
/////////////////////////////////////////////////////////////////////////
0:     this.writersForClusters = Maps.newHashMap();
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:bbf5369
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import java.io.IOException;
0: import java.util.HashMap;
0: import java.util.Map;
1: 
1:  * <p/>
1:  * <p/>
1: 
0:   private final Map<String, Path> postProcessedClusterDirectories = new HashMap<String, Path>();
1:   private final Map<String, SequenceFile.Writer> writersForClusters;
1: 
0:     this.writersForClusters = new HashMap<String, SequenceFile.Writer>();
1:     fileSystem = clusteredPoints.getFileSystem(conf);
1: 
1:     for (Pair<?, WeightedVectorWritable> record
0:             : new SequenceFileDirIterable<Writable, WeightedVectorWritable>(clusteredPoints,
0:             PathType.GLOB,
0:             PathFilters.partFilter(),
0:             null,
0:             false,
0:             conf)) {
1: 
0:             && !fileSystem.mkdirs(clusterPostProcessorOutput)) {
1: 
0:             PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:   public Map<String, Path> getPostProcessedClusterDirectories() {
1: 
1: 
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
0:     if (!fileSystem.exists(clusterPostProcessorOutput) &&
0:         !fileSystem.mkdirs(clusterPostProcessorOutput)) {
1:       throw new IOException("Error creating cluster post processor directory");
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.IOUtils;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
/////////////////////////////////////////////////////////////////////////
1:  * The sequential and non sequential version, both are being used from {@link ClusterOutputPostProcessorDriver}.
1: public final class ClusterOutputPostProcessor {
1:   private final FileSystem fileSystem;
1:   private final Configuration conf;
1:   private final Path clusterPostProcessorOutput;
0:   private final Map<String,Path> postProcessedClusterDirectories = new HashMap<String,Path>();
1:   private long uniqueVectorId = 0L;
0:   private final Map<String,SequenceFile.Writer> writersForClusters;
1:                                     Configuration hadoopConfiguration) throws IOException {
1:     this.clusteredPoints = PathDirectory.getClusterOutputClusteredPoints(clusterOutputToBeProcessed);
0:     fileSystem = clusteredPoints.getFileSystem(conf);    
1:   public void process() throws IOException {
0:     for (Pair<?,WeightedVectorWritable> record : 
0:          new SequenceFileDirIterable<Writable,WeightedVectorWritable>(clusteredPoints,
0:                                                                       PathType.GLOB,
0:                                                                       PathFilters.partFilter(),
0:                                                                       null,
0:                                                                       false,
0:                                                                       conf)) {
1:       String clusterId = record.getFirst().toString().trim();
1:       putVectorInRespectiveCluster(clusterId, record.getSecond());
1:     IOUtils.close(writersForClusters.values());
1:     writersForClusters.clear();
/////////////////////////////////////////////////////////////////////////
0:       if (!fileSystem.mkdirs(clusterPostProcessorOutput)) {
/////////////////////////////////////////////////////////////////////////
0:                                         PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));
/////////////////////////////////////////////////////////////////////////
1:       Path pathToWrite = new Path(clusterDirectory, new Path("part-m-0"));
1:       writer = new Writer(fileSystem, conf, pathToWrite, LongWritable.class, VectorWritable.class);
/////////////////////////////////////////////////////////////////////////
1:    * @return the set of all post processed cluster paths.
/////////////////////////////////////////////////////////////////////////
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:8953d93
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
commit:9d44881
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.clustering.topdown.postprocessor;
1: 
0: import static org.apache.mahout.clustering.topdown.PathDirectory.getClusterOutputClusteredPoints;
0: import static org.apache.mahout.clustering.topdown.PathDirectory.getClusterPathForClusterId;
1: 
0: import java.io.IOException;
0: import java.util.HashMap;
0: import java.util.Map;
1: 
1: import org.apache.hadoop.conf.Configuration;
0: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
0: import org.apache.hadoop.fs.FileUtil;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.LongWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.SequenceFile.Writer;
1: import org.apache.hadoop.io.Writable;
0: import org.apache.hadoop.io.WritableComparable;
0: import org.apache.mahout.clustering.WeightedVectorWritable;
1: import org.apache.mahout.clustering.topdown.PathDirectory;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.math.VectorWritable;
1: 
1: /**
1:  * This class reads the output of any clustering algorithm, and, creates separate directories for different
1:  * clusters. Each cluster directory's name is its clusterId. Each and every point is written in the cluster
1:  * directory associated with that point.
1:  * 
1:  * This class incorporates a sequential algorithm and is appropriate for use for data which has been clustered
1:  * sequentially.
1:  * 
0:  * The sequential and non sequential version, both are being used from @ClusterOutputPostProcessorDriver.
1:  * 
1:  */
0: public class ClusterOutputPostProcessor {
1:   
1:   private Path clusteredPoints;
0:   private FileSystem fileSystem;
0:   private Configuration conf;
0:   private Path clusterPostProcessorOutput;
0:   private Map<String,Path> postProcessedClusterDirectories = new HashMap<String,Path>();
0:   private long uniqueVectorId = 0;
0:   private Map<String,SequenceFile.Writer> writersForClusters;
1:   
1:   public ClusterOutputPostProcessor(Path clusterOutputToBeProcessed,
1:                                     Path output,
0:                                     Configuration hadoopConfiguration) {
1:     this.clusterPostProcessorOutput = output;
0:     this.clusteredPoints = getClusterOutputClusteredPoints(clusterOutputToBeProcessed);
1:     this.conf = hadoopConfiguration;
0:     this.writersForClusters = new HashMap<String,SequenceFile.Writer>();
1:   }
1:   
1:   /**
1:    * 
1:    * This method takes the clustered points output by the clustering algorithms as input and writes them into
1:    * their respective clusters.
1:    * 
0:    * @throws IOException
0:    * @throws IllegalAccessException
0:    * @throws InstantiationException
1:    */
0:   public void process() throws IOException, InstantiationException, IllegalAccessException {
1:     
0:     fileSystem = clusteredPoints.getFileSystem(conf);
1:     
1:     createPostProcessDirectory();
1:     
0:     FileStatus[] partFiles = getAllClusteredPointPartFiles();
0:     for (FileStatus partFile : partFiles) {
0:       SequenceFile.Reader clusteredPointsReader = new SequenceFile.Reader(fileSystem, partFile.getPath(),
0:           conf);
0:       WritableComparable clusterIdAsKey = (WritableComparable) clusteredPointsReader.getKeyClass()
0:           .newInstance();
0:       Writable vector = (Writable) clusteredPointsReader.getValueClass().newInstance();
0:       while (clusteredPointsReader.next(clusterIdAsKey, vector)) {
0:         String clusterId = clusterIdAsKey.toString().trim();
0:         putVectorInRespectiveCluster(clusterId, (WeightedVectorWritable) vector);
1:       }
1:       
0:       clusteredPointsReader.close();
0:       closeWriters();
1:     }
1:     
1:   }
1:   
1:   /**
0:    * Returns all the part files in the clusterdPoints directory.
1:    */
0:   private FileStatus[] getAllClusteredPointPartFiles() throws IOException {
0:     Path[] partFilePaths = FileUtil.stat2Paths(fileSystem.globStatus(clusteredPoints,
0:       PathFilters.partFilter()));
0:     FileStatus[] partFileStatuses = fileSystem.listStatus(partFilePaths, PathFilters.partFilter());
0:     return partFileStatuses;
1:   }
1:   
1:   /**
1:    * Creates the directory to put post processed clusters.
1:    */
1:   private void createPostProcessDirectory() throws IOException {
0:     if (!fileSystem.exists(clusterPostProcessorOutput)) {
0:       boolean directoryCreationSuccessFlag = fileSystem.mkdirs(clusterPostProcessorOutput);
0:       if (!directoryCreationSuccessFlag) {
0:         throw new IOException("Error creating cluster post processor directory");
1:       }
1:     }
1:   }
1:   
1:   /**
1:    * 
1:    * Finds out the cluster directory of the vector and writes it into the specified cluster.
1:    */
1:   private void putVectorInRespectiveCluster(String clusterId, WeightedVectorWritable point) throws IOException {
1:     Writer writer = findWriterForVector(clusterId);
1:     postProcessedClusterDirectories.put(clusterId,
0:       getClusterPathForClusterId(clusterPostProcessorOutput, clusterId));
1:     writeVectorToCluster(writer, point);
1:   }
1:   
1:   /**
1:    * Finds out the path in cluster where the point is supposed to be written.
1:    */
1:   private Writer findWriterForVector(String clusterId) throws IOException {
1:     Path clusterDirectory = PathDirectory.getClusterPathForClusterId(clusterPostProcessorOutput, clusterId);
1:     Writer writer = writersForClusters.get(clusterId);
1:     if (writer == null) {
0:       final Path pathToWrite = new Path(clusterDirectory, new Path("part-m-0"));
0:       SequenceFile.Writer fileWriter = new SequenceFile.Writer(fileSystem, conf, pathToWrite,
0:           LongWritable.class, VectorWritable.class);
0:       writer = fileWriter;
1:       writersForClusters.put(clusterId, writer);
1:     }
1:     return writer;
1:   }
1:   
1:   /**
1:    * Writes vector to the cluster directory.
1:    */
1:   private void writeVectorToCluster(Writer writer, WeightedVectorWritable point) throws IOException {
1:     writer.append(new LongWritable(uniqueVectorId++), new VectorWritable(point.getVector()));
1:     writer.sync();
1:   }
1:   
1:   /**
1:    * 
0:    * Returns the set of all post processed cluster paths.
1:    */
0:   public Map<String,Path> getPostProcessedClusterDirectories() {
1:     return postProcessedClusterDirectories;
1:   }
1:   
1:   public void setClusteredPoints(Path clusteredPoints) {
1:     this.clusteredPoints = clusteredPoints;
1:   }
1:   
0:   public void closeWriters() throws IOException {
0:     for (Writer writer : writersForClusters.values()) {
0:       writer.close();
1:     }
1:   }
1:   
1: }
============================================================================
1:80366ee: /*
1:80366ee:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:80366ee:  * contributor license agreements.  See the NOTICE file distributed with
1:80366ee:  * this work for additional information regarding copyright ownership.
1:80366ee:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:80366ee:  * (the "License"); you may not use this file except in compliance with
1:80366ee:  * the License.  You may obtain a copy of the License at
1:80366ee:  *
1:80366ee:  *     http://www.apache.org/licenses/LICENSE-2.0
1:80366ee:  *
1:80366ee:  * Unless required by applicable law or agreed to in writing, software
1:80366ee:  * distributed under the License is distributed on an "AS IS" BASIS,
1:80366ee:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:80366ee:  * See the License for the specific language governing permissions and
1:80366ee:  * limitations under the License.
1:80366ee:  */
2:80366ee: 
1:a4778a4: package org.apache.mahout.common.lucene;
1:80366ee: 
1:80366ee: import com.google.common.collect.AbstractIterator;
1:80366ee: import org.apache.lucene.analysis.TokenStream;
1:a4778a4: import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
1:80366ee: 
1:a4778a4: import java.io.IOException;
1:a4778a4: 
1:a4778a4: /**
1:a4778a4:  * Provide an Iterator for the tokens in a TokenStream.
1:6a4942c:  *
1:4841efb:  * Note, it is the responsibility of the instantiating class to properly consume the
1:4841efb:  * {@link org.apache.lucene.analysis.TokenStream}.  See the Lucene {@link org.apache.lucene.analysis.TokenStream}
1:4841efb:  * documentation for more information.
1:a4778a4:  */
1:a4778a4: //TODO: consider using the char/byte arrays instead of strings, esp. when we upgrade to Lucene 4.0
1:a4778a4: public final class TokenStreamIterator extends AbstractIterator<String> {
1:80366ee: 
1:80366ee:   private final TokenStream tokenStream;
1:80366ee: 
1:a4778a4:   public TokenStreamIterator(TokenStream tokenStream) {
1:80366ee:     this.tokenStream = tokenStream;
1:80366ee:   }
1:80366ee: 
1:80366ee:   @Override
1:80366ee:   protected String computeNext() {
1:80366ee:     try {
1:80366ee:       if (tokenStream.incrementToken()) {
1:a4778a4:         return tokenStream.getAttribute(CharTermAttribute.class).toString();
1:80366ee:       } else {
1:2e5449f:         tokenStream.end();
1:2e5449f:         tokenStream.close();
1:80366ee:         return endOfData();
1:80366ee:       }
1:80366ee:     } catch (IOException e) {
1:3d44c1e:       throw new IllegalStateException("IO error while tokenizing", e);
1:80366ee:     }
1:80366ee:   }
1:80366ee: 
1:80366ee: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:2e5449f
/////////////////////////////////////////////////////////////////////////
1:         tokenStream.end();
1:         tokenStream.close();
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:4841efb
/////////////////////////////////////////////////////////////////////////
1:  * Note, it is the responsibility of the instantiating class to properly consume the
1:  * {@link org.apache.lucene.analysis.TokenStream}.  See the Lucene {@link org.apache.lucene.analysis.TokenStream}
1:  * documentation for more information.
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6a4942c
/////////////////////////////////////////////////////////////////////////
1:  *
0:  * Note, it is the responsibility of the instantiating class to properly consume the {@link org.apache.lucene.analysis.TokenStream}.  See
0:  * the Lucene {@link org.apache.lucene.analysis.TokenStream} documentation for more information.
commit:a4778a4
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.common.lucene;
1: import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
1: import java.io.IOException;
1: 
1: /**
1:  * Provide an Iterator for the tokens in a TokenStream.
1:  */
1: //TODO: consider using the char/byte arrays instead of strings, esp. when we upgrade to Lucene 4.0
1: public final class TokenStreamIterator extends AbstractIterator<String> {
1:   public TokenStreamIterator(TokenStream tokenStream) {
/////////////////////////////////////////////////////////////////////////
1:         return tokenStream.getAttribute(CharTermAttribute.class).toString();
0:       throw new RuntimeException("IO error while tokenizing", e);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:3d44c1e
/////////////////////////////////////////////////////////////////////////
1:       throw new IllegalStateException("IO error while tokenizing", e);
commit:80366ee
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.vectorizer.encoders;
1: 
0: import java.io.IOException;
1: 
1: import com.google.common.collect.AbstractIterator;
1: import org.apache.lucene.analysis.TokenStream;
0: import org.apache.lucene.analysis.tokenattributes.TermAttribute;
1: 
0: final class TokenStreamIterator extends AbstractIterator<String> {
1: 
1:   private final TokenStream tokenStream;
1: 
0:   TokenStreamIterator(TokenStream tokenStream) {
1:     this.tokenStream = tokenStream;
1:   }
1: 
1:   @Override
1:   protected String computeNext() {
1:     try {
1:       if (tokenStream.incrementToken()) {
0:         return tokenStream.getAttribute(TermAttribute.class).term();
1:       } else {
1:         return endOfData();
1:       }
1:     } catch (IOException e) {
0:       throw new TokenizationException("IO error while tokenizing", e);
1:     }
1:   }
1: 
1: }
============================================================================
2:506d84d: /**
1:506d84d:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:506d84d:  * contributor license agreements.  See the NOTICE file distributed with
1:506d84d:  * this work for additional information regarding copyright ownership.
1:506d84d:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:506d84d:  * (the "License"); you may not use this file except in compliance with
1:506d84d:  * the License.  You may obtain a copy of the License at
1:506d84d:  *
1:506d84d:  *     http://www.apache.org/licenses/LICENSE-2.0
1:506d84d:  *
1:506d84d:  * Unless required by applicable law or agreed to in writing, software
1:506d84d:  * distributed under the License is distributed on an "AS IS" BASIS,
1:506d84d:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:506d84d:  * See the License for the specific language governing permissions and
1:506d84d:  * limitations under the License.
2:506d84d:  */
3:506d84d: 
1:506d84d: package org.apache.mahout.math.decomposer.hebbian;
1:506d84d: 
1:506d84d: 
1:506d84d: import org.apache.mahout.math.Vector;
1:4f91f44: import org.apache.mahout.math.function.PlusMult;
1:506d84d: 
1:506d84d: public class HebbianUpdater implements EigenUpdater {
1:506d84d: 
1:f696d36:   @Override
1:506d84d:   public void update(Vector pseudoEigen,
2:506d84d:                      Vector trainingVector,
1:506d84d:                      TrainingState currentState) {
1:506d84d:     double trainingVectorNorm = trainingVector.norm(2);
1:506d84d:     int numPreviousEigens = currentState.getNumEigensProcessed();
1:bdb1c48:     if (numPreviousEigens > 0 && currentState.isFirstPass()) {
1:bdb1c48:       updateTrainingProjectionsVector(currentState, trainingVector, numPreviousEigens - 1);
1:506d84d:     }
1:506d84d:     if (currentState.getActivationDenominatorSquared() == 0 || trainingVectorNorm == 0) {
1:506d84d:       if (currentState.getActivationDenominatorSquared() == 0) {
1:4f91f44:         pseudoEigen.assign(trainingVector, new PlusMult(1));
1:506d84d:         currentState.setHelperVector(currentState.currentTrainingProjection().clone());
1:506d84d:         double helperNorm = currentState.getHelperVector().norm(2);
1:506d84d:         currentState.setActivationDenominatorSquared(trainingVectorNorm * trainingVectorNorm - helperNorm * helperNorm);
1:506d84d:       }
1:506d84d:       return;
1:506d84d:     }
1:506d84d:     currentState.setActivationNumerator(pseudoEigen.dot(trainingVector));
1:39fe224:     currentState.setActivationNumerator(
1:39fe224:         currentState.getActivationNumerator()
1:39fe224:             - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));
1:506d84d: 
1:6d16230:     double activation = currentState.getActivationNumerator()
1:6d16230:         / Math.sqrt(currentState.getActivationDenominatorSquared());
1:39fe224:     currentState.setActivationDenominatorSquared(
1:39fe224:         currentState.getActivationDenominatorSquared()
1:39fe224:             + 2 * activation * currentState.getActivationNumerator()
1:6d16230:             + activation * activation
1:6d16230:                 * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));
1:506d84d:     if (numPreviousEigens > 0) {
1:4f91f44:       currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusMult(activation));
1:506d84d:     }
1:4f91f44:     pseudoEigen.assign(trainingVector, new PlusMult(activation));
1:506d84d:   }
1:506d84d: 
1:ea65197:   private static void updateTrainingProjectionsVector(TrainingState state,
1:ea65197:                                                       Vector trainingVector,
1:ea65197:                                                       int previousEigenIndex) {
1:506d84d:     Vector previousEigen = state.mostRecentEigen();
1:506d84d:     Vector currentTrainingVectorProjection = state.currentTrainingProjection();
1:506d84d:     double projection = previousEigen.dot(trainingVector);
1:506d84d:     currentTrainingVectorProjection.set(previousEigenIndex, projection);
1:506d84d:   }
1:506d84d: 
1:506d84d: }
============================================================================
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:bdb1c48
/////////////////////////////////////////////////////////////////////////
1:     if (numPreviousEigens > 0 && currentState.isFirstPass()) {
1:       updateTrainingProjectionsVector(currentState, trainingVector, numPreviousEigens - 1);
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:     double activation = currentState.getActivationNumerator()
1:         / Math.sqrt(currentState.getActivationDenominatorSquared());
1:             + activation * activation
1:                 * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:39fe224
/////////////////////////////////////////////////////////////////////////
1:     currentState.setActivationNumerator(
1:         currentState.getActivationNumerator()
1:             - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));
1:     currentState.setActivationDenominatorSquared(
1:         currentState.getActivationDenominatorSquared()
1:             + 2 * activation * currentState.getActivationNumerator()
0:             + activation * activation * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));
commit:f696d36
/////////////////////////////////////////////////////////////////////////
1:   @Override
commit:ff3da8c
commit:290e76f
/////////////////////////////////////////////////////////////////////////
commit:ea65197
/////////////////////////////////////////////////////////////////////////
0:   @Override
/////////////////////////////////////////////////////////////////////////
1:   private static void updateTrainingProjectionsVector(TrainingState state,
1:                                                       Vector trainingVector,
1:                                                       int previousEigenIndex) {
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:4f91f44
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.math.function.PlusMult;
/////////////////////////////////////////////////////////////////////////
1:         pseudoEigen.assign(trainingVector, new PlusMult(1));
/////////////////////////////////////////////////////////////////////////
1:       currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusMult(activation));
1:     pseudoEigen.assign(trainingVector, new PlusMult(activation));
commit:506d84d
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.math.decomposer.hebbian;
1: 
1: 
0: import org.apache.mahout.math.PlusFunction;
0: import org.apache.mahout.math.PlusWithScaleFunction;
1: import org.apache.mahout.math.Vector;
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
1: 
1: 
1: public class HebbianUpdater implements EigenUpdater {
1: 
1:   /**
0:    * Logger for this class.
1:    */
0:   private static final Logger log = LoggerFactory.getLogger(HebbianUpdater.class);
1: 
1:   public void update(Vector pseudoEigen,
1:                      Vector trainingVector,
1:                      TrainingState currentState) {
1:     double trainingVectorNorm = trainingVector.norm(2);
1:     int numPreviousEigens = currentState.getNumEigensProcessed();
1:     if (numPreviousEigens > 0) {
0:       if (currentState.isFirstPass()) {
0:         updateTrainingProjectionsVector(currentState,
0:             trainingVector,
0:             numPreviousEigens - 1);
1:       }
1:     }
1:     if (currentState.getActivationDenominatorSquared() == 0 || trainingVectorNorm == 0) {
1:       if (currentState.getActivationDenominatorSquared() == 0) {
0:         pseudoEigen.assign(trainingVector, new PlusFunction());
1:         currentState.setHelperVector(currentState.currentTrainingProjection().clone());
1:         double helperNorm = currentState.getHelperVector().norm(2);
1:         currentState.setActivationDenominatorSquared(trainingVectorNorm * trainingVectorNorm - helperNorm * helperNorm);
1:       }
1:       return;
1:     }
1:     currentState.setActivationNumerator(pseudoEigen.dot(trainingVector));
0:     currentState.setActivationNumerator(currentState.getActivationNumerator() - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));
1: 
0:     double activation = currentState.getActivationNumerator() / Math.sqrt(currentState.getActivationDenominatorSquared());
0:     currentState.setActivationDenominatorSquared(currentState.getActivationDenominatorSquared() + 2 * activation * currentState.getActivationNumerator()
0:         + (activation * activation) * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));
0:     if (numPreviousEigens > 0)
0:       currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusWithScaleFunction(activation));
0:     pseudoEigen.assign(trainingVector, new PlusWithScaleFunction(activation));
1:   }
1: 
0:   private void updateTrainingProjectionsVector(TrainingState state,
1:                                                Vector trainingVector,
0:                                                int previousEigenIndex) {
1:     Vector previousEigen = state.mostRecentEigen();
1:     Vector currentTrainingVectorProjection = state.currentTrainingProjection();
1:     double projection = previousEigen.dot(trainingVector);
1:     currentTrainingVectorProjection.set(previousEigenIndex, projection);
1:   }
1: 
1: }
commit:e98c2ec
/////////////////////////////////////////////////////////////////////////
commit:ecb08e8
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one or more
0:  * contributor license agreements.  See the NOTICE file distributed with
0:  * this work for additional information regarding copyright ownership.
0:  * The ASF licenses this file to You under the Apache License, Version 2.0
0:  * (the "License"); you may not use this file except in compliance with
0:  * the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: package org.apache.mahout.math.decomposer.hebbian;
0: 
0: 
0: import org.apache.mahout.math.PlusFunction;
0: import org.apache.mahout.math.PlusWithScaleFunction;
0: import org.apache.mahout.math.Vector;
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
0: 
0: 
0: public class HebbianUpdater implements EigenUpdater {
0: 
0:   /**
0:    * Logger for this class.
0:    */
0:   private static final Logger log = LoggerFactory.getLogger(HebbianUpdater.class);
0: 
0:   public void update(Vector pseudoEigen,
0:                      Vector trainingVector,
0:                      TrainingState currentState) {
0:     double trainingVectorNorm = trainingVector.norm(2);
0:     int numPreviousEigens = currentState.getNumEigensProcessed();
0:     if (numPreviousEigens > 0) {
0:       if (currentState.isFirstPass()) {
0:         updateTrainingProjectionsVector(currentState,
0:             trainingVector,
0:             numPreviousEigens - 1);
0:       }
0:     }
0:     if (currentState.getActivationDenominatorSquared() == 0 || trainingVectorNorm == 0) {
0:       if (currentState.getActivationDenominatorSquared() == 0) {
0:         pseudoEigen.assign(trainingVector, new PlusFunction());
0:         currentState.setHelperVector(currentState.currentTrainingProjection().clone());
0:         double helperNorm = currentState.getHelperVector().norm(2);
0:         currentState.setActivationDenominatorSquared(trainingVectorNorm * trainingVectorNorm - helperNorm * helperNorm);
0:       }
0:       return;
0:     }
0:     currentState.setActivationNumerator(pseudoEigen.dot(trainingVector));
0:     currentState.setActivationNumerator(currentState.getActivationNumerator() - currentState.getHelperVector().dot(currentState.currentTrainingProjection()));
0: 
0:     double activation = currentState.getActivationNumerator() / Math.sqrt(currentState.getActivationDenominatorSquared());
0:     currentState.setActivationDenominatorSquared(currentState.getActivationDenominatorSquared() + 2 * activation * currentState.getActivationNumerator()
0:         + (activation * activation) * (trainingVector.getLengthSquared() - currentState.currentTrainingProjection().getLengthSquared()));
0:     if (numPreviousEigens > 0)
0:       currentState.getHelperVector().assign(currentState.currentTrainingProjection(), new PlusWithScaleFunction(activation));
0:     pseudoEigen.assign(trainingVector, new PlusWithScaleFunction(activation));
0:   }
0: 
0:   private void updateTrainingProjectionsVector(TrainingState state,
0:                                                Vector trainingVector,
0:                                                int previousEigenIndex) {
0:     Vector previousEigen = state.mostRecentEigen();
0:     Vector currentTrainingVectorProjection = state.currentTrainingProjection();
0:     double projection = previousEigen.dot(trainingVector);
0:     currentTrainingVectorProjection.set(previousEigenIndex, projection);
0:   }
0: 
0: }
============================================================================
1:172bb3b: /* Licensed to the Apache Software Foundation (ASF) under one or more
1:172bb3b:  * contributor license agreements.  See the NOTICE file distributed with
1:172bb3b:  * this work for additional information regarding copyright ownership.
1:172bb3b:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:172bb3b:  * (the "License"); you may not use this file except in compliance with
1:172bb3b:  * the License.  You may obtain a copy of the License at
1:933e22a:  *
1:172bb3b:  *     http://www.apache.org/licenses/LICENSE-2.0
1:3eba6f2:  *
1:172bb3b:  * Unless required by applicable law or agreed to in writing, software
1:172bb3b:  * distributed under the License is distributed on an "AS IS" BASIS,
1:172bb3b:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:172bb3b:  * See the License for the specific language governing permissions and
1:172bb3b:  * limitations under the License.
1:172bb3b:  */
1:8d102ea: package org.apache.mahout.clustering.classify;
2:76e80dc: 
1:172bb3b: import java.io.DataInput;
1:172bb3b: import java.io.DataOutput;
1:172bb3b: import java.io.IOException;
1:85f9ece: import java.util.ArrayList;
1:172bb3b: import java.util.List;
1:76e80dc: import java.util.Locale;
1:76e80dc: 
1:85f9ece: import com.google.common.io.Closeables;
1:76e80dc: import org.apache.hadoop.conf.Configuration;
1:76e80dc: import org.apache.hadoop.fs.FileSystem;
1:76e80dc: import org.apache.hadoop.fs.Path;
1:76e80dc: import org.apache.hadoop.io.IntWritable;
1:76e80dc: import org.apache.hadoop.io.SequenceFile;
1:76e80dc: import org.apache.hadoop.io.Text;
1:172bb3b: import org.apache.hadoop.io.Writable;
1:172bb3b: import org.apache.mahout.classifier.AbstractVectorClassifier;
1:172bb3b: import org.apache.mahout.classifier.OnlineLearner;
1:8d102ea: import org.apache.mahout.clustering.Cluster;
1:8d102ea: import org.apache.mahout.clustering.iterator.ClusterWritable;
1:8d102ea: import org.apache.mahout.clustering.iterator.ClusteringPolicy;
1:8d102ea: import org.apache.mahout.clustering.iterator.ClusteringPolicyWritable;
1:e0ec7c1: import org.apache.mahout.common.ClassUtils;
1:76e80dc: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:76e80dc: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:76e80dc: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
1:172bb3b: import org.apache.mahout.math.Vector;
1:172bb3b: import org.apache.mahout.math.VectorWritable;
1:3eba6f2: 
1:172bb3b: /**
1:3eba6f2:  * This classifier works with any ClusteringPolicy and its associated Clusters.
1:3eba6f2:  * It is initialized with a policy and a list of compatible clusters and
1:3eba6f2:  * thereafter it can classify any new Vector into one or more of the clusters
1:3eba6f2:  * based upon the pdf() function which each cluster supports.
1:85f9ece:  * <p/>
1:172bb3b:  * In addition, it is an OnlineLearner and can be trained. Training amounts to
1:172bb3b:  * asking the actual model to observe the vector and closing the classifier
1:172bb3b:  * causes all the models to computeParameters.
1:85f9ece:  * <p/>
1:3eba6f2:  * Because a ClusterClassifier implements Writable, it can be written-to and
1:52d824f:  * read-from a sequence file as a single entity. For sequential and MapReduce
1:3eba6f2:  * clustering in conjunction with a ClusterIterator; however, it utilizes an
1:3eba6f2:  * exploded file format. In this format, the iterator writes the policy to a
1:3eba6f2:  * single POLICY_FILE_NAME file in the clustersOut directory and the models are
1:3eba6f2:  * written to one or more part-n files so that multiple reducers may employed to
1:3eba6f2:  * produce them.
1:172bb3b:  */
1:15712a6: public class ClusterClassifier extends AbstractVectorClassifier implements OnlineLearner, Writable {
1:85f9ece: 
1:3eba6f2:   private static final String POLICY_FILE_NAME = "_policy";
1:85f9ece: 
1:172bb3b:   private List<Cluster> models;
1:85f9ece: 
1:172bb3b:   private String modelClass;
1:85f9ece: 
1:76e80dc:   private ClusteringPolicy policy;
1:85f9ece: 
1:172bb3b:   /**
1:172bb3b:    * The public constructor accepts a list of clusters to become the models
1:85f9ece:    *
1:85f9ece:    * @param models a List<Cluster>
1:85f9ece:    * @param policy a ClusteringPolicy
1:172bb3b:    */
1:76e80dc:   public ClusterClassifier(List<Cluster> models, ClusteringPolicy policy) {
1:172bb3b:     this.models = models;
1:172bb3b:     modelClass = models.get(0).getClass().getName();
1:76e80dc:     this.policy = policy;
6:172bb3b:   }
1:85f9ece: 
1:52d824f:   // needed for serialization/De-serialization
1:85f9ece:   public ClusterClassifier() {
1:85f9ece:   }
1:85f9ece: 
1:76e80dc:   // only used by MR ClusterIterator
1:76e80dc:   protected ClusterClassifier(ClusteringPolicy policy) {
1:76e80dc:     this.policy = policy;
1:76e80dc:   }
1:85f9ece: 
1:172bb3b:   @Override
1:172bb3b:   public Vector classify(Vector instance) {
1:3eba6f2:     return policy.classify(instance, this);
1:172bb3b:   }
1:85f9ece: 
1:172bb3b:   @Override
1:172bb3b:   public double classifyScalar(Vector instance) {
1:15712a6:     if (models.size() == 2) {
1:15712a6:       double pdf0 = models.get(0).pdf(new VectorWritable(instance));
1:15712a6:       double pdf1 = models.get(1).pdf(new VectorWritable(instance));
1:172bb3b:       return pdf0 / (pdf0 + pdf1);
1:172bb3b:     }
1:172bb3b:     throw new IllegalStateException();
1:172bb3b:   }
1:85f9ece: 
1:172bb3b:   @Override
1:172bb3b:   public int numCategories() {
1:15712a6:     return models.size();
1:172bb3b:   }
1:85f9ece: 
1:15712a6:   @Override
1:172bb3b:   public void write(DataOutput out) throws IOException {
1:15712a6:     out.writeInt(models.size());
1:172bb3b:     out.writeUTF(modelClass);
1:76e80dc:     new ClusteringPolicyWritable(policy).write(out);
1:15712a6:     for (Cluster cluster : models) {
1:172bb3b:       cluster.write(out);
1:172bb3b:     }
1:172bb3b:   }
1:85f9ece: 
1:15712a6:   @Override
1:172bb3b:   public void readFields(DataInput in) throws IOException {
1:172bb3b:     int size = in.readInt();
1:172bb3b:     modelClass = in.readUTF();
1:85f9ece:     models = new ArrayList<>();
1:76e80dc:     ClusteringPolicyWritable clusteringPolicyWritable = new ClusteringPolicyWritable();
1:76e80dc:     clusteringPolicyWritable.readFields(in);
1:76e80dc:     policy = clusteringPolicyWritable.getValue();
1:172bb3b:     for (int i = 0; i < size; i++) {
1:e0ec7c1:       Cluster element = ClassUtils.instantiateAs(modelClass, Cluster.class);
1:172bb3b:       element.readFields(in);
1:e0ec7c1:       models.add(element);
1:172bb3b:     }
1:172bb3b:   }
1:85f9ece: 
1:15712a6:   @Override
1:172bb3b:   public void train(int actual, Vector instance) {
1:15712a6:     models.get(actual).observe(new VectorWritable(instance));
1:172bb3b:   }
1:85f9ece: 
1:933e22a:   /**
1:933e22a:    * Train the models given an additional weight. Unique to ClusterClassifier
1:85f9ece:    *
1:85f9ece:    * @param actual the int index of a model
1:85f9ece:    * @param data   a data Vector
1:85f9ece:    * @param weight a double weighting factor
1:933e22a:    */
1:933e22a:   public void train(int actual, Vector data, double weight) {
1:15712a6:     models.get(actual).observe(new VectorWritable(data), weight);
1:933e22a:   }
1:85f9ece: 
1:15712a6:   @Override
1:15712a6:   public void train(long trackingKey, String groupKey, int actual, Vector instance) {
1:15712a6:     models.get(actual).observe(new VectorWritable(instance));
1:172bb3b:   }
1:85f9ece: 
1:15712a6:   @Override
1:172bb3b:   public void train(long trackingKey, int actual, Vector instance) {
1:15712a6:     models.get(actual).observe(new VectorWritable(instance));
1:172bb3b:   }
1:85f9ece: 
1:15712a6:   @Override
1:172bb3b:   public void close() {
1:3eba6f2:     policy.close(this);
1:172bb3b:   }
1:85f9ece: 
1:172bb3b:   public List<Cluster> getModels() {
1:172bb3b:     return models;
1:172bb3b:   }
1:85f9ece: 
1:76e80dc:   public ClusteringPolicy getPolicy() {
1:76e80dc:     return policy;
1:76e80dc:   }
1:85f9ece: 
1:76e80dc:   public void writeToSeqFiles(Path path) throws IOException {
1:457db94:     writePolicy(policy, path);
1:76e80dc:     Configuration config = new Configuration();
1:76e80dc:     FileSystem fs = FileSystem.get(path.toUri(), config);
1:76e80dc:     ClusterWritable cw = new ClusterWritable();
1:76e80dc:     for (int i = 0; i < models.size(); i++) {
1:85f9ece:       try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, config,
1:85f9ece:           new Path(path, "part-" + String.format(Locale.ENGLISH, "%05d", i)), IntWritable.class,
1:85f9ece:           ClusterWritable.class)) {
1:76e80dc:         Cluster cluster = models.get(i);
1:76e80dc:         cw.setValue(cluster);
1:76e80dc:         Writable key = new IntWritable(i);
1:76e80dc:         writer.append(key, cw);
1:76e80dc:       }
1:76e80dc:     }
1:76e80dc:   }
1:85f9ece: 
1:590ffed:   public void readFromSeqFiles(Configuration conf, Path path) throws IOException {
1:76e80dc:     Configuration config = new Configuration();
1:85f9ece:     List<Cluster> clusters = new ArrayList<>();
1:76e80dc:     for (ClusterWritable cw : new SequenceFileDirValueIterable<ClusterWritable>(path, PathType.LIST,
1:76e80dc:         PathFilters.logsCRCFilter(), config)) {
1:590ffed:       Cluster cluster = cw.getValue();
1:590ffed:       cluster.configure(conf);
1:590ffed:       clusters.add(cluster);
1:76e80dc:     }
1:76e80dc:     this.models = clusters;
1:76e80dc:     modelClass = models.get(0).getClass().getName();
1:76e80dc:     this.policy = readPolicy(path);
1:76e80dc:   }
1:85f9ece: 
1:457db94:   public static ClusteringPolicy readPolicy(Path path) throws IOException {
1:3eba6f2:     Path policyPath = new Path(path, POLICY_FILE_NAME);
1:76e80dc:     Configuration config = new Configuration();
1:76e80dc:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
1:76e80dc:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, policyPath, config);
1:76e80dc:     Text key = new Text();
1:76e80dc:     ClusteringPolicyWritable cpw = new ClusteringPolicyWritable();
1:76e80dc:     reader.next(key, cpw);
1:52d824f:     Closeables.close(reader, true);
1:76e80dc:     return cpw.getValue();
1:76e80dc:   }
1:85f9ece: 
1:457db94:   public static void writePolicy(ClusteringPolicy policy, Path path) throws IOException {
1:3eba6f2:     Path policyPath = new Path(path, POLICY_FILE_NAME);
1:76e80dc:     Configuration config = new Configuration();
1:76e80dc:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
1:76e80dc:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, policyPath, Text.class,
1:76e80dc:         ClusteringPolicyWritable.class);
1:76e80dc:     writer.append(new Text(), new ClusteringPolicyWritable(policy));
1:52d824f:     Closeables.close(writer, false);
1:76e80dc:   }
1:172bb3b: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
1: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1:  * <p/>
1:  * <p/>
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
1:    *
1:    * @param models a List<Cluster>
1:    * @param policy a ClusteringPolicy
1: 
1:   public ClusterClassifier() {
1:   }
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:     models = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:    *
1:    * @param actual the int index of a model
1:    * @param data   a data Vector
1:    * @param weight a double weighting factor
1: 
1: 
1: 
1: 
1: 
1: 
1:       try (SequenceFile.Writer writer = new SequenceFile.Writer(fs, config,
1:           new Path(path, "part-" + String.format(Locale.ENGLISH, "%05d", i)), IntWritable.class,
1:           ClusterWritable.class)) {
1: 
1:     List<Cluster> clusters = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:52d824f
/////////////////////////////////////////////////////////////////////////
1:  * read-from a sequence file as a single entity. For sequential and MapReduce
/////////////////////////////////////////////////////////////////////////
1:   // needed for serialization/De-serialization
/////////////////////////////////////////////////////////////////////////
1:     Closeables.close(reader, true);
/////////////////////////////////////////////////////////////////////////
1:     Closeables.close(writer, false);
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(writer, false);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(writer, true);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:590ffed
/////////////////////////////////////////////////////////////////////////
1:   public void readFromSeqFiles(Configuration conf, Path path) throws IOException {
1:       Cluster cluster = cw.getValue();
1:       cluster.configure(conf);
1:       clusters.add(cluster);
commit:3eba6f2
/////////////////////////////////////////////////////////////////////////
1:  * This classifier works with any ClusteringPolicy and its associated Clusters.
1:  * It is initialized with a policy and a list of compatible clusters and
1:  * thereafter it can classify any new Vector into one or more of the clusters
1:  * based upon the pdf() function which each cluster supports.
1:  * 
1:  * Because a ClusterClassifier implements Writable, it can be written-to and
0:  * read-from a sequence file as a single entity. For sequential and mapreduce
1:  * clustering in conjunction with a ClusterIterator; however, it utilizes an
1:  * exploded file format. In this format, the iterator writes the policy to a
1:  * single POLICY_FILE_NAME file in the clustersOut directory and the models are
1:  * written to one or more part-n files so that multiple reducers may employed to
1:  * produce them.
1:   private static final String POLICY_FILE_NAME = "_policy";
1:   
/////////////////////////////////////////////////////////////////////////
1:     return policy.classify(instance, this);
/////////////////////////////////////////////////////////////////////////
1:     policy.close(this);
/////////////////////////////////////////////////////////////////////////
1:     Path policyPath = new Path(path, POLICY_FILE_NAME);
/////////////////////////////////////////////////////////////////////////
1:     Path policyPath = new Path(path, POLICY_FILE_NAME);
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.classify;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.Cluster;
1: import org.apache.mahout.clustering.iterator.ClusterWritable;
1: import org.apache.mahout.clustering.iterator.ClusteringPolicy;
1: import org.apache.mahout.clustering.iterator.ClusteringPolicyWritable;
commit:457db94
/////////////////////////////////////////////////////////////////////////
1:     writePolicy(policy, path);
/////////////////////////////////////////////////////////////////////////
1:   public static ClusteringPolicy readPolicy(Path path) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:   public static void writePolicy(ClusteringPolicy policy, Path path) throws IOException {
commit:76e80dc
/////////////////////////////////////////////////////////////////////////
1: import java.util.Locale;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.Text;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
1: 
0: import com.google.common.collect.Lists;
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1:   private ClusteringPolicy policy;
1:   
0:    * @param policy
0:    *          a ClusteringPolicy
1:   public ClusterClassifier(List<Cluster> models, ClusteringPolicy policy) {
1:     this.policy = policy;
1:   // only used by MR ClusterIterator
1:   protected ClusterClassifier(ClusteringPolicy policy) {
1:     this.policy = policy;
1:   }
1:   
0:     return policy.classify(instance, models);
/////////////////////////////////////////////////////////////////////////
1:     new ClusteringPolicyWritable(policy).write(out);
/////////////////////////////////////////////////////////////////////////
1:     ClusteringPolicyWritable clusteringPolicyWritable = new ClusteringPolicyWritable();
1:     clusteringPolicyWritable.readFields(in);
1:     policy = clusteringPolicyWritable.getValue();
/////////////////////////////////////////////////////////////////////////
0:   
1:   public ClusteringPolicy getPolicy() {
1:     return policy;
1:   }
0:   
1:   public void writeToSeqFiles(Path path) throws IOException {
0:     writePolicy(path);
1:     Configuration config = new Configuration();
1:     FileSystem fs = FileSystem.get(path.toUri(), config);
0:     SequenceFile.Writer writer = null;
1:     ClusterWritable cw = new ClusterWritable();
1:     for (int i = 0; i < models.size(); i++) {
0:       try {
1:         Cluster cluster = models.get(i);
1:         cw.setValue(cluster);
0:         writer = new SequenceFile.Writer(fs, config,
0:             new Path(path, "part-" + String.format(Locale.ENGLISH, "%05d", i)), IntWritable.class,
0:             ClusterWritable.class);
1:         Writable key = new IntWritable(i);
1:         writer.append(key, cw);
0:       } finally {
0:         Closeables.closeQuietly(writer);
1:       }
1:     }
1:   }
0:   
0:   public void readFromSeqFiles(Path path) throws IOException {
1:     Configuration config = new Configuration();
0:     List<Cluster> clusters = Lists.newArrayList();
1:     for (ClusterWritable cw : new SequenceFileDirValueIterable<ClusterWritable>(path, PathType.LIST,
1:         PathFilters.logsCRCFilter(), config)) {
0:       clusters.add(cw.getValue());
1:     }
1:     this.models = clusters;
1:     modelClass = models.get(0).getClass().getName();
1:     this.policy = readPolicy(path);
1:   }
0:   
0:   private ClusteringPolicy readPolicy(Path path) throws IOException {
0:     Path policyPath = new Path(path, "_policy");
1:     Configuration config = new Configuration();
1:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
1:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, policyPath, config);
1:     Text key = new Text();
1:     ClusteringPolicyWritable cpw = new ClusteringPolicyWritable();
1:     reader.next(key, cpw);
1:     return cpw.getValue();
1:   }
0:   
0:   protected void writePolicy(Path path) throws IOException {
0:     Path policyPath = new Path(path, "_policy");
1:     Configuration config = new Configuration();
1:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, policyPath, Text.class,
1:         ClusteringPolicyWritable.class);
1:     writer.append(new Text(), new ClusteringPolicyWritable(policy));
0:     writer.close();
1:   }
commit:dc637e8
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       Vector pdfs = new DenseVector(models.size());
commit:933e22a
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * Train the models given an additional weight. Unique to ClusterClassifier
1:    * 
0:    * @param actual
0:    *          the int index of a model
0:    * @param data
0:    *          a data Vector
0:    * @param weight
0:    *          a double weighting factor
1:    */
1:   public void train(int actual, Vector data, double weight) {
0:     getModels().get(actual).observe(new VectorWritable(data), weight);
1:   }
0:   
commit:172bb3b
/////////////////////////////////////////////////////////////////////////
1: /* Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
0:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: package org.apache.mahout.clustering;
0: 
1: import java.io.DataInput;
1: import java.io.DataOutput;
1: import java.io.IOException;
0: import java.util.ArrayList;
0: import java.util.Collection;
1: import java.util.List;
0: 
1: import org.apache.hadoop.io.Writable;
1: import org.apache.mahout.classifier.AbstractVectorClassifier;
1: import org.apache.mahout.classifier.OnlineLearner;
0: import org.apache.mahout.clustering.fuzzykmeans.FuzzyKMeansClusterer;
0: import org.apache.mahout.clustering.fuzzykmeans.SoftCluster;
0: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
0: import org.apache.mahout.math.function.TimesFunction;
0: 
1: /**
0:  * This classifier works with any clustering Cluster. It is initialized with a
0:  * list of compatible clusters and thereafter it can classify any new Vector
0:  * into one or more of the clusters based upon the pdf() function which each
0:  * cluster supports.
0:  * 
1:  * In addition, it is an OnlineLearner and can be trained. Training amounts to
1:  * asking the actual model to observe the vector and closing the classifier
1:  * causes all the models to computeParameters.
1:  */
0: public class ClusterClassifier extends AbstractVectorClassifier implements
0:     OnlineLearner, Writable {
0:   
1:   private List<Cluster> models;
0:   
1:   private String modelClass;
0:   
1:   /**
1:    * The public constructor accepts a list of clusters to become the models
0:    * 
0:    * @param models
0:    *          a List<Cluster>
1:    */
0:   public ClusterClassifier(List<Cluster> models) {
1:     this.models = models;
1:     modelClass = models.get(0).getClass().getName();
1:   }
0:   
0:   // needed for serialization/deserialization
0:   public ClusterClassifier() {}
0:   
1:   @Override
1:   public Vector classify(Vector instance) {
0:     Vector pdfs = new DenseVector(getModels().size());
0:     if (getModels().get(0) instanceof SoftCluster) {
0:       Collection<SoftCluster> clusters = new ArrayList<SoftCluster>();
0:       List<Double> distances = new ArrayList<Double>();
0:       for (Cluster model : getModels()) {
0:         SoftCluster sc = (SoftCluster) model;
0:         clusters.add(sc);
0:         distances.add(sc.getMeasure().distance(instance, sc.getCenter()));
1:       }
0:       return new FuzzyKMeansClusterer().computePi(clusters, distances);
0:     } else {
0:       int i = 0;
0:       for (Cluster model : getModels()) {
0:         pdfs.set(i++, model.pdf(new VectorWritable(instance)));
1:       }
0:       return pdfs.assign(new TimesFunction(), 1.0 / pdfs.zSum());
1:     }
1:   }
0:   
1:   @Override
1:   public double classifyScalar(Vector instance) {
0:     if (getModels().size() == 2) {
0:       double pdf0 = getModels().get(0).pdf(new VectorWritable(instance));
0:       double pdf1 = getModels().get(1).pdf(new VectorWritable(instance));
1:       return pdf0 / (pdf0 + pdf1);
1:     }
1:     throw new IllegalStateException();
1:   }
0:   
1:   @Override
1:   public int numCategories() {
0:     return getModels().size();
1:   }
0:   
1:   public void write(DataOutput out) throws IOException {
0:     out.writeInt(getModels().size());
1:     out.writeUTF(modelClass);
0:     for (Cluster cluster : getModels()) {
1:       cluster.write(out);
1:     }
1:   }
0:   
1:   public void readFields(DataInput in) throws IOException {
1:     int size = in.readInt();
1:     modelClass = in.readUTF();
0:     ClassLoader ccl = Thread.currentThread().getContextClassLoader();
0:     try {
0:       Class<? extends Cluster> factory = ccl.loadClass(modelClass).asSubclass(
0:           Cluster.class);
0:       
0:       models = new ArrayList<Cluster>();
1:       for (int i = 0; i < size; i++) {
0:         Cluster element = factory.newInstance();
1:         element.readFields(in);
0:         getModels().add(element);
1:       }
0:     } catch (ClassNotFoundException e) {
0:       throw new IllegalStateException(e);
0:     } catch (InstantiationException e) {
0:       throw new IllegalStateException(e);
0:     } catch (IllegalAccessException e) {
0:       throw new IllegalStateException(e);
1:     }
1:   }
0:   
1:   public void train(int actual, Vector instance) {
0:     getModels().get(actual).observe(new VectorWritable(instance));
1:   }
0:   
0:   public void train(long trackingKey, String groupKey, int actual,
0:       Vector instance) {
0:     getModels().get(actual).observe(new VectorWritable(instance));
1:   }
0:   
1:   public void train(long trackingKey, int actual, Vector instance) {
0:     getModels().get(actual).observe(new VectorWritable(instance));
1:   }
0:   
1:   public void close() {
0:     for (Cluster cluster : getModels()) {
0:       cluster.computeParameters();
1:     }
1:   }
0:   
1:   public List<Cluster> getModels() {
1:     return models;
1:   }
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:e0ec7c1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.ClassUtils;
/////////////////////////////////////////////////////////////////////////
0:     models = Lists.newArrayList();
0:     for (int i = 0; i < size; i++) {
1:       Cluster element = ClassUtils.instantiateAs(modelClass, Cluster.class);
0:       element.readFields(in);
1:       models.add(element);
commit:15712a6
/////////////////////////////////////////////////////////////////////////
1: public class ClusterClassifier extends AbstractVectorClassifier implements OnlineLearner, Writable {
/////////////////////////////////////////////////////////////////////////
0:     Vector pdfs = new DenseVector(models.size());
0:     if (models.get(0) instanceof SoftCluster) {
0:       for (Cluster model : models) {
/////////////////////////////////////////////////////////////////////////
0:       for (Cluster model : models) {
/////////////////////////////////////////////////////////////////////////
1:     if (models.size() == 2) {
1:       double pdf0 = models.get(0).pdf(new VectorWritable(instance));
1:       double pdf1 = models.get(1).pdf(new VectorWritable(instance));
/////////////////////////////////////////////////////////////////////////
1:     return models.size();
1:   @Override
1:     out.writeInt(models.size());
1:     for (Cluster cluster : models) {
1:   @Override
/////////////////////////////////////////////////////////////////////////
0:         models.add(element);
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:     models.get(actual).observe(new VectorWritable(instance));
/////////////////////////////////////////////////////////////////////////
1:     models.get(actual).observe(new VectorWritable(data), weight);
1:   @Override
1:   public void train(long trackingKey, String groupKey, int actual, Vector instance) {
1:     models.get(actual).observe(new VectorWritable(instance));
1:   @Override
1:     models.get(actual).observe(new VectorWritable(instance));
1:   @Override
0:     for (Cluster cluster : models) {
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:74f849b
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
0:       Collection<SoftCluster> clusters = Lists.newArrayList();
0:       List<Double> distances = Lists.newArrayList();
/////////////////////////////////////////////////////////////////////////
0:       models = Lists.newArrayList();
============================================================================
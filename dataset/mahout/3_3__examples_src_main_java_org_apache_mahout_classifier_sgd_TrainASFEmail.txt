1:4fbfbc6: /*
1:8a2c0f3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:8a2c0f3:  * contributor license agreements.  See the NOTICE file distributed with
1:8a2c0f3:  * this work for additional information regarding copyright ownership.
1:8a2c0f3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:8a2c0f3:  * (the "License"); you may not use this file except in compliance with
1:8a2c0f3:  * the License.  You may obtain a copy of the License at
3:8a2c0f3:  *
1:8a2c0f3:  *     http://www.apache.org/licenses/LICENSE-2.0
1:8a2c0f3:  *
1:8a2c0f3:  * Unless required by applicable law or agreed to in writing, software
1:8a2c0f3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:8a2c0f3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:8a2c0f3:  * See the License for the specific language governing permissions and
1:8a2c0f3:  * limitations under the License.
1:8a2c0f3:  */
8:8a2c0f3: 
1:4fbfbc6: package org.apache.mahout.classifier.sgd;
1:8a2c0f3: 
1:8a2c0f3: import com.google.common.collect.HashMultiset;
1:8a2c0f3: import com.google.common.collect.Multiset;
1:8a2c0f3: import com.google.common.collect.Ordering;
1:8a2c0f3: import org.apache.hadoop.conf.Configuration;
1:8a2c0f3: import org.apache.hadoop.fs.Path;
1:e6a308b: import org.apache.hadoop.fs.PathFilter;
1:8a2c0f3: import org.apache.hadoop.io.Text;
1:69f324d: import org.apache.mahout.common.AbstractJob;
1:8a2c0f3: import org.apache.mahout.common.Pair;
1:8a2c0f3: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:8a2c0f3: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterator;
1:8a2c0f3: import org.apache.mahout.ep.State;
1:8a2c0f3: import org.apache.mahout.math.VectorWritable;
1:8a2c0f3: import org.apache.mahout.vectorizer.encoders.Dictionary;
1:69f324d: 
1:8a2c0f3: import java.io.File;
1:4ef9d31: import java.util.ArrayList;
1:8a2c0f3: import java.util.Collections;
1:8a2c0f3: import java.util.List;
1:8a2c0f3: 
1:69f324d: public final class TrainASFEmail extends AbstractJob {
1:8a2c0f3: 
1:8a2c0f3:   private TrainASFEmail() {
1:8a2c0f3:   }
1:8a2c0f3: 
1:69f324d:   @Override
1:69f324d:   public int run(String[] args) throws Exception {
1:69f324d:     addInputOption();
1:69f324d:     addOutputOption();
1:69f324d:     addOption("categories", "nc", "The number of categories to train on", true);
1:69f324d:     addOption("cardinality", "c", "The size of the vectors to use", "100000");
1:69f324d:     addOption("threads", "t", "The number of threads to use in the learner", "20");
1:229aeff:     addOption("poolSize", "p", "The number of CrossFoldLearners to use in the AdaptiveLogisticRegression. "
1:229aeff:                                + "Higher values require more memory.", "5");
1:69f324d:     if (parseArguments(args) == null) {
1:69f324d:       return -1;
1:8a2c0f3:     }
1:8a2c0f3: 
1:69f324d:     File base = new File(getInputPath().toString());
1:69f324d: 
1:4fbfbc6:     Multiset<String> overallCounts = HashMultiset.create();
1:69f324d:     File output = new File(getOutputPath().toString());
1:69f324d:     output.mkdirs();
1:69f324d:     int numCats = Integer.parseInt(getOption("categories"));
1:69f324d:     int cardinality = Integer.parseInt(getOption("cardinality", "100000"));
1:69f324d:     int threadCount = Integer.parseInt(getOption("threads", "20"));
1:69f324d:     int poolSize = Integer.parseInt(getOption("poolSize", "5"));
1:8a2c0f3:     Dictionary asfDictionary = new Dictionary();
1:229aeff:     AdaptiveLogisticRegression learningAlgorithm =
1:229aeff:         new AdaptiveLogisticRegression(numCats, cardinality, new L1(), threadCount, poolSize);
1:8a2c0f3:     learningAlgorithm.setInterval(800);
1:8a2c0f3:     learningAlgorithm.setAveragingWindow(500);
1:8a2c0f3: 
1:8a2c0f3:     //We ran seq2encoded and split input already, so let's just build up the dictionary
1:8a2c0f3:     Configuration conf = new Configuration();
1:e6a308b:     PathFilter trainFilter = new PathFilter() {
1:e6a308b:       @Override
1:e6a308b:       public boolean accept(Path path) {
1:e6a308b:         return path.getName().contains("training");
1:e6a308b:       }
1:e6a308b:     };
1:229aeff:     SequenceFileDirIterator<Text, VectorWritable> iter =
1:4ef9d31:         new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter, null, true, conf);
1:8a2c0f3:     long numItems = 0;
1:8a2c0f3:     while (iter.hasNext()) {
1:8a2c0f3:       Pair<Text, VectorWritable> next = iter.next();
1:8a2c0f3:       asfDictionary.intern(next.getFirst().toString());
1:8a2c0f3:       numItems++;
1:8a2c0f3:     }
1:8a2c0f3: 
1:229aeff:     System.out.println(numItems + " training files");
1:8a2c0f3: 
1:8a2c0f3:     SGDInfo info = new SGDInfo();
1:8a2c0f3: 
1:4ef9d31:     iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter,
2:8a2c0f3:             null, true, conf);
1:4fbfbc6:     int k = 0;
1:8a2c0f3:     while (iter.hasNext()) {
1:8a2c0f3:       Pair<Text, VectorWritable> next = iter.next();
1:8a2c0f3:       String ng = next.getFirst().toString();
1:8a2c0f3:       int actual = asfDictionary.intern(ng);
1:8a2c0f3:       //we already have encoded
1:8a2c0f3:       learningAlgorithm.train(actual, next.getSecond().get());
1:8a2c0f3:       k++;
1:8a2c0f3:       State<AdaptiveLogisticRegression.Wrapper, CrossFoldLearner> best = learningAlgorithm.getBest();
1:8a2c0f3: 
1:69f324d:       SGDHelper.analyzeState(info, 0, k, best);
1:8a2c0f3:     }
1:8a2c0f3:     learningAlgorithm.close();
1:8a2c0f3:     //TODO: how to dissection since we aren't processing the files here
1:8a2c0f3:     //SGDHelper.dissect(leakType, asfDictionary, learningAlgorithm, files, overallCounts);
1:8a2c0f3:     System.out.println("exiting main, writing model to " + output);
1:8a2c0f3: 
1:8a2c0f3:     ModelSerializer.writeBinary(output + "/asf.model",
1:8a2c0f3:             learningAlgorithm.getBest().getPayload().getLearner().getModels().get(0));
1:8a2c0f3: 
1:4ef9d31:     List<Integer> counts = new ArrayList<>();
1:229aeff:     System.out.println("Word counts");
1:8a2c0f3:     for (String count : overallCounts.elementSet()) {
1:8a2c0f3:       counts.add(overallCounts.count(count));
1:8a2c0f3:     }
1:8a2c0f3:     Collections.sort(counts, Ordering.natural().reverse());
1:8a2c0f3:     k = 0;
1:8a2c0f3:     for (Integer count : counts) {
1:229aeff:       System.out.println(k + "\t" + count);
1:8a2c0f3:       k++;
1:8a2c0f3:       if (k > 1000) {
1:8a2c0f3:         break;
1:69f324d:       }
1:8a2c0f3:     }
1:229aeff:     return 0;
1:8a2c0f3:   }
1:69f324d: 
1:69f324d:   public static void main(String[] args) throws Exception {
1:69f324d:     TrainASFEmail trainer = new TrainASFEmail();
1:69f324d:     trainer.run(args);
1:8a2c0f3:   }
1:8a2c0f3: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:4ef9d31
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
/////////////////////////////////////////////////////////////////////////
1:         new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter, null, true, conf);
/////////////////////////////////////////////////////////////////////////
1:     iter = new SequenceFileDirIterator<>(new Path(base.toString()), PathType.LIST, trainFilter,
/////////////////////////////////////////////////////////////////////////
1:     List<Integer> counts = new ArrayList<>();
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     addOption("poolSize", "p", "The number of CrossFoldLearners to use in the AdaptiveLogisticRegression. "
1:                                + "Higher values require more memory.", "5");
/////////////////////////////////////////////////////////////////////////
1:     AdaptiveLogisticRegression learningAlgorithm =
1:         new AdaptiveLogisticRegression(numCats, cardinality, new L1(), threadCount, poolSize);
/////////////////////////////////////////////////////////////////////////
1:     SequenceFileDirIterator<Text, VectorWritable> iter =
0:         new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()),
0:                                                           PathType.LIST,
0:                                                           trainFilter,
0:                                                           null,
0:                                                           true,
0:                                                           conf);
/////////////////////////////////////////////////////////////////////////
1:     System.out.println(numItems + " training files");
/////////////////////////////////////////////////////////////////////////
1:     System.out.println("Word counts");
1:       System.out.println(k + "\t" + count);
1:     return 0;
commit:822a5e1
/////////////////////////////////////////////////////////////////////////
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
1: /*
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.classifier.sgd;
/////////////////////////////////////////////////////////////////////////
0: public final class TrainASFEmail {
0:   //private static final String[] LEAK_LABELS = {"none", "month-year", "day-month-year"};
/////////////////////////////////////////////////////////////////////////
1:     Multiset<String> overallCounts = HashMultiset.create();
/////////////////////////////////////////////////////////////////////////
1:     int k = 0;
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:69f324d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.AbstractJob;
1: 
/////////////////////////////////////////////////////////////////////////
1: public final class TrainASFEmail extends AbstractJob {
1:   @Override
1:   public int run(String[] args) throws Exception {
0:     int result = 0;
1:     addInputOption();
1:     addOutputOption();
1:     addOption("categories", "nc", "The number of categories to train on", true);
1:     addOption("cardinality", "c", "The size of the vectors to use", "100000");
1:     addOption("threads", "t", "The number of threads to use in the learner", "20");
0:     addOption("poolSize", "p", "The number of CrossFoldLearners to use in the AdaptiveLogisticRegression.  Higher values require more memory.", "5");
1:     if (parseArguments(args) == null) {
1:       return -1;
1:     File base = new File(getInputPath().toString());
1: 
0:     Multiset<String> overallCounts = HashMultiset.create();
1:     File output = new File(getOutputPath().toString());
1:     output.mkdirs();
1:     int numCats = Integer.parseInt(getOption("categories"));
1:     int cardinality = Integer.parseInt(getOption("cardinality", "100000"));
1:     int threadCount = Integer.parseInt(getOption("threads", "20"));
1:     int poolSize = Integer.parseInt(getOption("poolSize", "5"));
0:     AdaptiveLogisticRegression learningAlgorithm = new AdaptiveLogisticRegression(numCats, cardinality, new L1(), threadCount, poolSize);
/////////////////////////////////////////////////////////////////////////
1:       SGDHelper.analyzeState(info, 0, k, best);
/////////////////////////////////////////////////////////////////////////
0:     return result;
1:   }
1: 
1:   public static void main(String[] args) throws Exception {
1:     TrainASFEmail trainer = new TrainASFEmail();
1:     trainer.run(args);
commit:e6a308b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.fs.PathFilter;
/////////////////////////////////////////////////////////////////////////
1:     PathFilter trainFilter = new PathFilter() {
1:       @Override
1:       public boolean accept(Path path) {
1:         return path.getName().contains("training");
1:       }
1:     };
0:     SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, trainFilter,
/////////////////////////////////////////////////////////////////////////
0:     iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, trainFilter,
commit:8a2c0f3
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.classifier.sgd;
0: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: 
1: import com.google.common.collect.HashMultiset;
0: import com.google.common.collect.Lists;
1: import com.google.common.collect.Multiset;
1: import com.google.common.collect.Ordering;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Text;
1: import org.apache.mahout.common.Pair;
0: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterator;
1: import org.apache.mahout.ep.State;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.vectorizer.encoders.Dictionary;
1: 
1: import java.io.File;
0: import java.io.IOException;
1: import java.util.Collections;
1: import java.util.List;
1: 
0: /**
1:  *
1:  *
0:  **/
0: public class TrainASFEmail {
0:   private static final String[] LEAK_LABELS = {"none", "month-year", "day-month-year"};
1: 
0:   private static Multiset<String> overallCounts;
1: 
1:   private TrainASFEmail() {
1:   }
1: 
0:   public static void main(String[] args) throws IOException {
0:     File base = new File(args[0]);
1: 
0:     overallCounts = HashMultiset.create();
0:     File output = new File(args[1]);
0:     output.mkdirs();
0:     int numCats = Integer.parseInt(args[2]);
0:     int cardinality = Integer.parseInt(args[3]);
1: 
0:     int leakType = 0;
0:     if (args.length > 4) {
0:       leakType = Integer.parseInt(args[4]);
1:     }
1: 
1:     Dictionary asfDictionary = new Dictionary();
1: 
1: 
0:     AdaptiveLogisticRegression learningAlgorithm = new AdaptiveLogisticRegression(numCats, cardinality, new L1());
1:     learningAlgorithm.setInterval(800);
1:     learningAlgorithm.setAveragingWindow(500);
1: 
1:     //We ran seq2encoded and split input already, so let's just build up the dictionary
1:     Configuration conf = new Configuration();
0:     SequenceFileDirIterator<Text, VectorWritable> iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, PathFilters.partFilter(),
1:             null, true, conf);
1:     long numItems = 0;
1:     while (iter.hasNext()) {
1:       Pair<Text, VectorWritable> next = iter.next();
1:       asfDictionary.intern(next.getFirst().toString());
1:       numItems++;
1:     }
1: 
0:     System.out.printf("%d training files\n", numItems);
1: 
1: 
0:     int k = 0;
1:     SGDInfo info = new SGDInfo();
1: 
0:     iter = new SequenceFileDirIterator<Text, VectorWritable>(new Path(base.toString()), PathType.LIST, PathFilters.partFilter(),
1:             null, true, conf);
1:     while (iter.hasNext()) {
1:       Pair<Text, VectorWritable> next = iter.next();
1:       String ng = next.getFirst().toString();
1:       int actual = asfDictionary.intern(ng);
1:       //we already have encoded
1:       learningAlgorithm.train(actual, next.getSecond().get());
1:       k++;
1:       State<AdaptiveLogisticRegression.Wrapper, CrossFoldLearner> best = learningAlgorithm.getBest();
1: 
0:       SGDHelper.analyzeState(info, leakType, k, best);
1:     }
1:     learningAlgorithm.close();
1:     //TODO: how to dissection since we aren't processing the files here
1:     //SGDHelper.dissect(leakType, asfDictionary, learningAlgorithm, files, overallCounts);
1:     System.out.println("exiting main, writing model to " + output);
1: 
1:     ModelSerializer.writeBinary(output + "/asf.model",
1:             learningAlgorithm.getBest().getPayload().getLearner().getModels().get(0));
1: 
0:     List<Integer> counts = Lists.newArrayList();
0:     System.out.printf("Word counts\n");
1:     for (String count : overallCounts.elementSet()) {
1:       counts.add(overallCounts.count(count));
1:     }
1:     Collections.sort(counts, Ordering.natural().reverse());
1:     k = 0;
1:     for (Integer count : counts) {
0:       System.out.printf("%d\t%d\n", k, count);
1:       k++;
1:       if (k > 1000) {
1:         break;
1:       }
1:     }
1:   }
1: }
============================================================================
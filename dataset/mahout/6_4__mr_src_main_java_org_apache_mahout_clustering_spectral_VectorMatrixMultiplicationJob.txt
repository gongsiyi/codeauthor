1:48d069f: /**
1:48d069f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:48d069f:  * contributor license agreements.  See the NOTICE file distributed with
1:48d069f:  * this work for additional information regarding copyright ownership.
1:48d069f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:48d069f:  * (the "License"); you may not use this file except in compliance with
1:48d069f:  * the License.  You may obtain a copy of the License at
3:48d069f:  *
1:48d069f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:48d069f:  *
1:48d069f:  * Unless required by applicable law or agreed to in writing, software
1:48d069f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:48d069f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:48d069f:  * See the License for the specific language governing permissions and
1:48d069f:  * limitations under the License.
1:48d069f:  */
4:48d069f: 
1:b60c909: package org.apache.mahout.clustering.spectral;
1:48d069f: 
1:48d069f: import java.io.IOException;
1:48d069f: 
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.fs.FileSystem;
1:48d069f: import org.apache.hadoop.fs.Path;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.mapreduce.Job;
1:48d069f: import org.apache.hadoop.mapreduce.Mapper;
1:48d069f: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:48d069f: import org.apache.mahout.math.DenseVector;
1:48d069f: import org.apache.mahout.math.Vector;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: import org.apache.mahout.math.function.Functions;
1:48d069f: import org.apache.mahout.math.hadoop.DistributedRowMatrix;
1:48d069f: 
1:48d069f: /**
1:48d069f:  * <p>This class handles the three-way multiplication of the digonal matrix
1:48d069f:  * and the Markov transition matrix inherent in the Eigencuts algorithm.
1:48d069f:  * The equation takes the form:</p>
1:39fe224:  *
1:39fe224:  * {@code W = D^(1/2) * M * D^(1/2)}
1:39fe224:  *
1:48d069f:  * <p>Since the diagonal matrix D has only n non-zero elements, it is represented
1:48d069f:  * as a dense vector in this job, rather than a full n-by-n matrix. This job
1:48d069f:  * performs the multiplications and returns the new DRM.
1:48d069f:  */
1:48d069f: public final class VectorMatrixMultiplicationJob {
1:48d069f: 
1:049e7dc:   private VectorMatrixMultiplicationJob() {
1:049e7dc:   }
1:049e7dc: 
1:48d069f:   /**
1:48d069f:    * Invokes the job.
1:48d069f:    * @param markovPath Path to the markov DRM's sequence files
1:48d069f:    */
1:049e7dc:   public static DistributedRowMatrix runJob(Path markovPath, Vector diag, Path outputPath)
1:049e7dc:     throws IOException, ClassNotFoundException, InterruptedException {
1:48d069f:     
1:78545ff:     return runJob(markovPath, diag, outputPath, new Path(outputPath, "tmp"));
1:78545ff:   }
1:78545ff: 
1:78545ff:   public static DistributedRowMatrix runJob(Path markovPath, Vector diag, Path outputPath, Path tmpPath)
1:78545ff:     throws IOException, ClassNotFoundException, InterruptedException {
1:78545ff: 
1:48d069f:     // set up the serialization of the diagonal vector
1:48d069f:     Configuration conf = new Configuration();
1:1de8cec:     FileSystem fs = FileSystem.get(markovPath.toUri(), conf);
1:48d069f:     markovPath = fs.makeQualified(markovPath);
1:48d069f:     outputPath = fs.makeQualified(outputPath);
1:48d069f:     Path vectorOutputPath = new Path(outputPath.getParent(), "vector");
1:b60c909:     VectorCache.save(new IntWritable(Keys.DIAGONAL_CACHE_INDEX), diag, vectorOutputPath, conf);
1:78545ff: 
1:48d069f:     // set up the job itself
1:48d069f:     Job job = new Job(conf, "VectorMatrixMultiplication");
1:48d069f:     job.setInputFormatClass(SequenceFileInputFormat.class);
1:48d069f:     job.setOutputKeyClass(IntWritable.class);
1:48d069f:     job.setOutputValueClass(VectorWritable.class);
1:48d069f:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:48d069f:     job.setMapperClass(VectorMatrixMultiplicationMapper.class);
1:48d069f:     job.setNumReduceTasks(0);
1:78545ff: 
1:48d069f:     FileInputFormat.addInputPath(job, markovPath);
1:48d069f:     FileOutputFormat.setOutputPath(job, outputPath);
1:765834c: 
1:765834c:     job.setJarByClass(VectorMatrixMultiplicationJob.class);
1:765834c: 
1:7c2b664:     boolean succeeded = job.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       throw new IllegalStateException("Job failed!");
1:7c2b664:     }
1:78545ff: 
1:48d069f:     // build the resulting DRM from the results
1:78545ff:     return new DistributedRowMatrix(outputPath, tmpPath,
1:48d069f:         diag.size(), diag.size());
1:48d069f:   }
1:48d069f:   
1:48d069f:   public static class VectorMatrixMultiplicationMapper
1:48d069f:     extends Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable> {
1:48d069f:     
1:48d069f:     private Vector diagonal;
1:48d069f:     
1:48d069f:     @Override
1:48d069f:     protected void setup(Context context) throws IOException, InterruptedException {
1:48d069f:       // read in the diagonal vector from the distributed cache
1:48d069f:       super.setup(context);
1:48d069f:       Configuration config = context.getConfiguration();
1:a13b4b7:       diagonal = VectorCache.load(config);
1:48d069f:       if (diagonal == null) {
1:48d069f:         throw new IOException("No vector loaded from cache!");
1:48d069f:       }
1:48d069f:       if (!(diagonal instanceof DenseVector)) {
1:48d069f:         diagonal = new DenseVector(diagonal);
1:48d069f:       }
1:48d069f:     }
1:48d069f:     
1:48d069f:     @Override
1:48d069f:     protected void map(IntWritable key, VectorWritable row, Context ctx) 
1:48d069f:       throws IOException, InterruptedException {
1:48d069f:       
1:dc62944:       for (Vector.Element e : row.get().all()) {
1:48d069f:         double dii = Functions.SQRT.apply(diagonal.get(key.get()));
1:48d069f:         double djj = Functions.SQRT.apply(diagonal.get(e.index()));
1:48d069f:         double mij = e.get();
1:48d069f:         e.set(dii * mij * djj);
1:48d069f:       }
1:48d069f:       ctx.write(key, row);
1:48d069f:     }
1:48d069f:     
1:48d069f:     /**
1:48d069f:      * Performs the setup of the Mapper. Used by unit tests.
2:48d069f:      * @param diag
1:48d069f:      */
1:48d069f:     void setup(Vector diag) {
1:48d069f:       this.diagonal = diag;
1:48d069f:     }
1:48d069f:   }
1:48d069f: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     VectorCache.save(new IntWritable(Keys.DIAGONAL_CACHE_INDEX), diag, vectorOutputPath, conf);
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
1:       for (Vector.Element e : row.get().all()) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = job.waitForCompletion(true);
1:     if (!succeeded) {
1:       throw new IllegalStateException("Job failed!");
1:     }
commit:1de8cec
/////////////////////////////////////////////////////////////////////////
1:     FileSystem fs = FileSystem.get(markovPath.toUri(), conf);
commit:765834c
/////////////////////////////////////////////////////////////////////////
1: 
1:     job.setJarByClass(VectorMatrixMultiplicationJob.class);
1: 
commit:39fe224
/////////////////////////////////////////////////////////////////////////
1:  *
1:  * {@code W = D^(1/2) * M * D^(1/2)}
1:  *
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
1:       diagonal = VectorCache.load(config);
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
1:   private VectorMatrixMultiplicationJob() {
1:   }
1: 
1:   public static DistributedRowMatrix runJob(Path markovPath, Vector diag, Path outputPath)
1:     throws IOException, ClassNotFoundException, InterruptedException {
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:78545ff
/////////////////////////////////////////////////////////////////////////
1:     return runJob(markovPath, diag, outputPath, new Path(outputPath, "tmp"));
1:   }
1: 
1:   public static DistributedRowMatrix runJob(Path markovPath, Vector diag, Path outputPath, Path tmpPath)
1:     throws IOException, ClassNotFoundException, InterruptedException {
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:     return new DistributedRowMatrix(outputPath, tmpPath,
commit:48d069f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
0: import org.apache.mahout.clustering.spectral.eigencuts.EigencutsKeys;
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.function.Functions;
1: import org.apache.mahout.math.hadoop.DistributedRowMatrix;
1: 
1: /**
1:  * <p>This class handles the three-way multiplication of the digonal matrix
1:  * and the Markov transition matrix inherent in the Eigencuts algorithm.
1:  * The equation takes the form:</p>
1:  * 
0:  * <code>W = D^(1/2) * M * D^(1/2)</code>
1:  * 
1:  * <p>Since the diagonal matrix D has only n non-zero elements, it is represented
1:  * as a dense vector in this job, rather than a full n-by-n matrix. This job
1:  * performs the multiplications and returns the new DRM.
1:  */
1: public final class VectorMatrixMultiplicationJob {
1: 
1:   /**
1:    * Invokes the job.
1:    * @param markovPath Path to the markov DRM's sequence files
1:    * @param diag
0:    * @param outputPath
0:    * @return
1:    */
0:   public static DistributedRowMatrix runJob(Path markovPath, Vector diag, 
0:       Path outputPath) throws IOException, ClassNotFoundException, InterruptedException {
1:     
1:     // set up the serialization of the diagonal vector
1:     Configuration conf = new Configuration();
0:     FileSystem fs = FileSystem.get(conf);
1:     markovPath = fs.makeQualified(markovPath);
1:     outputPath = fs.makeQualified(outputPath);
1:     Path vectorOutputPath = new Path(outputPath.getParent(), "vector");
0:     VectorCache.save(new IntWritable(EigencutsKeys.DIAGONAL_CACHE_INDEX), diag, vectorOutputPath, conf);
1:     
1:     // set up the job itself
1:     Job job = new Job(conf, "VectorMatrixMultiplication");
1:     job.setInputFormatClass(SequenceFileInputFormat.class);
1:     job.setOutputKeyClass(IntWritable.class);
1:     job.setOutputValueClass(VectorWritable.class);
1:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:     job.setMapperClass(VectorMatrixMultiplicationMapper.class);
1:     job.setNumReduceTasks(0);
1:     
1:     FileInputFormat.addInputPath(job, markovPath);
1:     FileOutputFormat.setOutputPath(job, outputPath);
0:     job.waitForCompletion(true);
1:     
1:     // build the resulting DRM from the results
0:     return new DistributedRowMatrix(outputPath, new Path(outputPath, "tmp"), 
1:         diag.size(), diag.size());
1:   }
1:   
1:   public static class VectorMatrixMultiplicationMapper
1:     extends Mapper<IntWritable, VectorWritable, IntWritable, VectorWritable> {
1:     
1:     private Vector diagonal;
1:     
1:     @Override
1:     protected void setup(Context context) throws IOException, InterruptedException {
1:       // read in the diagonal vector from the distributed cache
1:       super.setup(context);
1:       Configuration config = context.getConfiguration();
0:       diagonal = VectorCache.load(new IntWritable(EigencutsKeys.DIAGONAL_CACHE_INDEX), config);
1:       if (diagonal == null) {
1:         throw new IOException("No vector loaded from cache!");
1:       }
1:       if (!(diagonal instanceof DenseVector)) {
1:         diagonal = new DenseVector(diagonal);
1:       }
1:     }
1:     
1:     @Override
1:     protected void map(IntWritable key, VectorWritable row, Context ctx) 
1:       throws IOException, InterruptedException {
1:       
0:       for (Vector.Element e : row.get()) {
1:         double dii = Functions.SQRT.apply(diagonal.get(key.get()));
1:         double djj = Functions.SQRT.apply(diagonal.get(e.index()));
1:         double mij = e.get();
1:         e.set(dii * mij * djj);
1:       }
1:       ctx.write(key, row);
1:     }
1:     
1:     /**
1:      * Performs the setup of the Mapper. Used by unit tests.
1:      * @param diag
1:      */
1:     void setup(Vector diag) {
1:       this.diagonal = diag;
1:     }
1:   }
1: }
============================================================================
1:81d64c0: /**
1:81d64c0:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:81d64c0:  * contributor license agreements.  See the NOTICE file distributed with
1:81d64c0:  * this work for additional information regarding copyright ownership.
1:81d64c0:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:81d64c0:  * (the "License"); you may not use this file except in compliance with
1:81d64c0:  * the License.  You may obtain a copy of the License at
1:81d64c0:  *
1:81d64c0:  *     http://www.apache.org/licenses/LICENSE-2.0
1:81d64c0:  *
1:81d64c0:  * Unless required by applicable law or agreed to in writing, software
1:81d64c0:  * distributed under the License is distributed on an "AS IS" BASIS,
1:81d64c0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:81d64c0:  * See the License for the specific language governing permissions and
1:81d64c0:  * limitations under the License.
1:81d64c0:  */
1:e200147: 
1:81d64c0: package org.apache.mahout.cf.taste.hadoop.als;
1:c3154b8: 
1:8a8e10d: import org.apache.hadoop.conf.Configuration;
1:81d64c0: import org.apache.hadoop.io.IntWritable;
1:81d64c0: import org.apache.hadoop.mapreduce.Job;
1:81d64c0: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:df39ce4: import org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper;
1:81d64c0: import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
1:81d64c0: import org.apache.hadoop.util.ToolRunner;
1:81d64c0: import org.apache.mahout.cf.taste.hadoop.RecommendedItemsWritable;
1:81d64c0: import org.apache.mahout.common.AbstractJob;
1:c3154b8: 
1:81d64c0: import java.util.List;
1:81d64c0: import java.util.Map;
1:c3154b8: 
1:81d64c0: /**
1:81d64c0:  * <p>Computes the top-N recommendations per user from a decomposition of the rating matrix</p>
1:81d64c0:  *
1:81d64c0:  * <p>Command line arguments specific to this class are:</p>
1:81d64c0:  *
1:81d64c0:  * <ol>
1:81d64c0:  * <li>--input (path): Directory containing the vectorized user ratings</li>
1:81d64c0:  * <li>--output (path): path where output should go</li>
1:df39ce4:  * <li>--numRecommendations (int): maximum number of recommendations per user (default: 10)</li>
1:81d64c0:  * <li>--maxRating (double): maximum rating of an item</li>
1:df39ce4:  * <li>--numThreads (int): threads to use per mapper, (default: 1)</li>
1:81d64c0:  * </ol>
1:81d64c0:  */
1:81d64c0: public class RecommenderJob extends AbstractJob {
1:e200147: 
1:df39ce4:   static final String NUM_RECOMMENDATIONS = RecommenderJob.class.getName() + ".numRecommendations";
1:df39ce4:   static final String USER_FEATURES_PATH = RecommenderJob.class.getName() + ".userFeatures";
1:df39ce4:   static final String ITEM_FEATURES_PATH = RecommenderJob.class.getName() + ".itemFeatures";
1:df39ce4:   static final String MAX_RATING = RecommenderJob.class.getName() + ".maxRating";
1:bbd2b7e:   static final String USER_INDEX_PATH = RecommenderJob.class.getName() + ".userIndex";
1:bbd2b7e:   static final String ITEM_INDEX_PATH = RecommenderJob.class.getName() + ".itemIndex";
24:81d64c0: 
1:81d64c0:   static final int DEFAULT_NUM_RECOMMENDATIONS = 10;
1:81d64c0: 
1:81d64c0:   public static void main(String[] args) throws Exception {
1:81d64c0:     ToolRunner.run(new RecommenderJob(), args);
1:8a8e10d:   }
1:8a8e10d: 
5:81d64c0:   @Override
1:81d64c0:   public int run(String[] args) throws Exception {
1:c3154b8: 
1:81d64c0:     addInputOption();
1:81d64c0:     addOption("userFeatures", null, "path to the user feature matrix", true);
1:81d64c0:     addOption("itemFeatures", null, "path to the item feature matrix", true);
1:81d64c0:     addOption("numRecommendations", null, "number of recommendations per user",
1:81d64c0:         String.valueOf(DEFAULT_NUM_RECOMMENDATIONS));
1:81d64c0:     addOption("maxRating", null, "maximum rating available", true);
1:df39ce4:     addOption("numThreads", null, "threads per mapper", String.valueOf(1));
1:bbd2b7e:     addOption("usesLongIDs", null, "input contains long IDs that need to be translated");
1:bbd2b7e:     addOption("userIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");
1:bbd2b7e:     addOption("itemIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");
1:81d64c0:     addOutputOption();
1:c3154b8: 
1:6db7f62:     Map<String,List<String>> parsedArgs = parseArguments(args);
1:81d64c0:     if (parsedArgs == null) {
1:81d64c0:       return -1;
1:8a8e10d:     }
1:e200147: 
1:df39ce4:     Job prediction = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class,
1:df39ce4:         MultithreadedSharingMapper.class, IntWritable.class, RecommendedItemsWritable.class, TextOutputFormat.class);
1:8a8e10d:     Configuration conf = prediction.getConfiguration();
1:8a8e10d: 
1:df39ce4:     int numThreads = Integer.parseInt(getOption("numThreads"));
1:df39ce4: 
1:8a8e10d:     conf.setInt(NUM_RECOMMENDATIONS, Integer.parseInt(getOption("numRecommendations")));
1:8a8e10d:     conf.set(USER_FEATURES_PATH, getOption("userFeatures"));
1:8a8e10d:     conf.set(ITEM_FEATURES_PATH, getOption("itemFeatures"));
1:8a8e10d:     conf.set(MAX_RATING, getOption("maxRating"));
1:8a8e10d: 
1:bbd2b7e:     boolean usesLongIDs = Boolean.parseBoolean(getOption("usesLongIDs"));
1:bbd2b7e:     if (usesLongIDs) {
1:bbd2b7e:       conf.set(ParallelALSFactorizationJob.USES_LONG_IDS, String.valueOf(true));
1:bbd2b7e:       conf.set(USER_INDEX_PATH, getOption("userIDIndex"));
1:bbd2b7e:       conf.set(ITEM_INDEX_PATH, getOption("itemIDIndex"));
1:bbd2b7e:     }
1:bbd2b7e: 
1:5d66758:     MultithreadedMapper.setMapperClass(prediction, PredictionMapper.class);
1:df39ce4:     MultithreadedMapper.setNumberOfThreads(prediction, numThreads);
1:df39ce4: 
1:7c2b664:     boolean succeeded = prediction.waitForCompletion(true);
1:229aeff:     if (!succeeded) {
1:7c2b664:       return -1;
1:e200147:     }
1:e200147: 
1:81d64c0:     return 0;
1:e200147:   }
1:81d64c0: 
13:81d64c0: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:bbd2b7e
/////////////////////////////////////////////////////////////////////////
1:   static final String USER_INDEX_PATH = RecommenderJob.class.getName() + ".userIndex";
1:   static final String ITEM_INDEX_PATH = RecommenderJob.class.getName() + ".itemIndex";
/////////////////////////////////////////////////////////////////////////
1:     addOption("usesLongIDs", null, "input contains long IDs that need to be translated");
1:     addOption("userIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");
1:     addOption("itemIDIndex", null, "index for user long IDs (necessary if usesLongIDs is true)");
/////////////////////////////////////////////////////////////////////////
1:     boolean usesLongIDs = Boolean.parseBoolean(getOption("usesLongIDs"));
1:     if (usesLongIDs) {
1:       conf.set(ParallelALSFactorizationJob.USES_LONG_IDS, String.valueOf(true));
1:       conf.set(USER_INDEX_PATH, getOption("userIDIndex"));
1:       conf.set(ITEM_INDEX_PATH, getOption("itemIDIndex"));
1:     }
1: 
commit:5d66758
/////////////////////////////////////////////////////////////////////////
1:     MultithreadedMapper.setMapperClass(prediction, PredictionMapper.class);
commit:df39ce4
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper;
/////////////////////////////////////////////////////////////////////////
1:  * <li>--numRecommendations (int): maximum number of recommendations per user (default: 10)</li>
1:  * <li>--numThreads (int): threads to use per mapper, (default: 1)</li>
1:   static final String NUM_RECOMMENDATIONS = RecommenderJob.class.getName() + ".numRecommendations";
1:   static final String USER_FEATURES_PATH = RecommenderJob.class.getName() + ".userFeatures";
1:   static final String ITEM_FEATURES_PATH = RecommenderJob.class.getName() + ".itemFeatures";
1:   static final String MAX_RATING = RecommenderJob.class.getName() + ".maxRating";
/////////////////////////////////////////////////////////////////////////
1:     addOption("numThreads", null, "threads per mapper", String.valueOf(1));
/////////////////////////////////////////////////////////////////////////
1:     Job prediction = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class,
1:         MultithreadedSharingMapper.class, IntWritable.class, RecommendedItemsWritable.class, TextOutputFormat.class);
1:     int numThreads = Integer.parseInt(getOption("numThreads"));
1: 
0:     MultithreadedMapper.setMapperClass(prediction, SharingPredictionMapper.class);
1:     MultithreadedMapper.setNumberOfThreads(prediction, numThreads);
1: 
/////////////////////////////////////////////////////////////////////////
commit:63c81f1
/////////////////////////////////////////////////////////////////////////
0:       U = ALS.readMatrixByRows(pathToU, ctx.getConfiguration());
0:       M = ALS.readMatrixByRows(pathToM, ctx.getConfiguration());
commit:8a8e10d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:  * <li>--NUM_FEATURES (int): number of features to use for decomposition </li>
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = prediction.getConfiguration();
1: 
1:     conf.setInt(NUM_RECOMMENDATIONS, Integer.parseInt(getOption("numRecommendations")));
1:     conf.set(USER_FEATURES_PATH, getOption("userFeatures"));
1:     conf.set(ITEM_FEATURES_PATH, getOption("itemFeatures"));
1:     conf.set(MAX_RATING, getOption("maxRating"));
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       recommendationsPerUser = ctx.getConfiguration().getInt(NUM_RECOMMENDATIONS, DEFAULT_NUM_RECOMMENDATIONS);
/////////////////////////////////////////////////////////////////////////
1:     }
0:     // we can use a simple dot product computation, as both vectors are dense
0:     private double dot(Vector x, Vector y) {
0:       int numFeatures = x.size();
0:       double sum = 0;
0:       for (int n = 0; n < numFeatures; n++) {
0:         sum += x.getQuick(n) * y.getQuick(n);
1:       }
0:       return sum;
/////////////////////////////////////////////////////////////////////////
0:       final TopItemQueue topItemQueue = new TopItemQueue(recommendationsPerUser);
0:       final Vector userFeatures = U.get(userID);
0:             double predictedRating = dot(userFeatures, itemFeatures);
0:             MutableRecommendedItem top = topItemQueue.top();
0:             if (predictedRating > top.getValue()) {
0:               top.set(itemID, (float) predictedRating);
0:               topItemQueue.updateTop();
/////////////////////////////////////////////////////////////////////////
0:       List<RecommendedItem> recommendedItems = topItemQueue.getTopItems();
0:       if (!recommendedItems.isEmpty()) {
1: 
0:         // cap predictions to maxRating
0:           ((MutableRecommendedItem) topItem).capToMaxValue(maxRating);
commit:49bf055
/////////////////////////////////////////////////////////////////////////
commit:c3154b8
/////////////////////////////////////////////////////////////////////////
0: import java.util.Collections;
0: import java.util.PriorityQueue;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   private static final Comparator<RecommendedItem> DESCENDING_BY_PREFERENCE_VALUE =
0:       Collections.reverseOrder(BY_PREFERENCE_VALUE);
1: 
/////////////////////////////////////////////////////////////////////////
0:     private PriorityQueue<RecommendedItem> topKItems;
1: 
0:     private RecommendedItemsWritable recommendations = new RecommendedItemsWritable();
/////////////////////////////////////////////////////////////////////////
1: 
0:       topKItems = new PriorityQueue<RecommendedItem>(recommendationsPerUser + 1, BY_PREFERENCE_VALUE);
/////////////////////////////////////////////////////////////////////////
0:       topKItems.clear();
1: 
0:             if (topKItems.size() < recommendationsPerUser) {
0:               topKItems.add(new CappableRecommendedItem(itemID, (float) predictedRating));
0:             } else if (predictedRating > topKItems.peek().getValue()) {
0:               topKItems.add(new CappableRecommendedItem(itemID, (float) predictedRating));
0:               topKItems.poll();
1: 
/////////////////////////////////////////////////////////////////////////
0:         List<RecommendedItem> recommendedItems = Lists.newArrayList(topKItems);
0:         Collections.sort(recommendedItems, DESCENDING_BY_PREFERENCE_VALUE);
0:           ((CappableRecommendedItem) topItem).capToMaxValue(maxRating);
0:         recommendations.set(recommendedItems);
0:         ctx.write(userIDWritable, recommendations);
commit:87a2503
/////////////////////////////////////////////////////////////////////////
0:         for (RecommendedItem topItem : recommendedItems) {
commit:e200147
/////////////////////////////////////////////////////////////////////////
0:     private RecommendedItemsWritable result = new RecommendedItemsWritable();
1: 
/////////////////////////////////////////////////////////////////////////
1: 
0:             // manual check to avoid an object instantiation per unknown item
0:             if (topKItems.size() < recommendationsPerUser || (float) predictedRating > topKItems.peek().getValue()) {
0:               topKItems.offer(new GenericRecommendedItem(itemID, (float) predictedRating));
1:             }
1: 
0:         List<RecommendedItem> recommendedItems = topKItems.retrieve();
0:         for (RecommendedItem topItem : topKItems.retrieve()) {
0:           topItem.capToMaxValue(maxRating);
1:         }
1: 
0:         result.set(recommendedItems);
0:         ctx.write(userIDWritable, result);
commit:81d64c0
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.cf.taste.hadoop.als;
1: 
0: import com.google.common.collect.Lists;
0: import com.google.common.primitives.Floats;
0: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Job;
0: import org.apache.hadoop.mapreduce.Mapper;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
1: import org.apache.hadoop.util.ToolRunner;
0: import org.apache.mahout.cf.taste.common.TopK;
1: import org.apache.mahout.cf.taste.hadoop.RecommendedItemsWritable;
0: import org.apache.mahout.cf.taste.impl.recommender.GenericRecommendedItem;
0: import org.apache.mahout.cf.taste.recommender.RecommendedItem;
1: import org.apache.mahout.common.AbstractJob;
0: import org.apache.mahout.math.Vector;
0: import org.apache.mahout.math.VectorWritable;
0: import org.apache.mahout.math.function.IntObjectProcedure;
0: import org.apache.mahout.math.map.OpenIntObjectHashMap;
0: import org.apache.mahout.math.set.OpenIntHashSet;
1: 
0: import java.io.IOException;
0: import java.util.Comparator;
0: import java.util.Iterator;
1: import java.util.List;
1: import java.util.Map;
1: 
1: /**
1:  * <p>Computes the top-N recommendations per user from a decomposition of the rating matrix</p>
1:  *
1:  * <p>Command line arguments specific to this class are:</p>
1:  *
1:  * <ol>
1:  * <li>--input (path): Directory containing the vectorized user ratings</li>
1:  * <li>--output (path): path where output should go</li>
0:  * <li>--numRecommendations (int): maximum number of recommendations per user</li>
1:  * <li>--maxRating (double): maximum rating of an item</li>
0:  * <li>--numFeatures (int): number of features to use for decomposition </li>
1:  * </ol>
1:  */
1: public class RecommenderJob extends AbstractJob {
1: 
0:   private static final String NUM_RECOMMENDATIONS = RecommenderJob.class.getName() + ".numRecommendations";
0:   private static final String USER_FEATURES_PATH = RecommenderJob.class.getName() + ".userFeatures";
0:   private static final String ITEM_FEATURES_PATH = RecommenderJob.class.getName() + ".itemFeatures";
0:   private static final String MAX_RATING = RecommenderJob.class.getName() + ".maxRating";
1: 
1:   static final int DEFAULT_NUM_RECOMMENDATIONS = 10;
1: 
1:   public static void main(String[] args) throws Exception {
1:     ToolRunner.run(new RecommenderJob(), args);
1:   }
1: 
1:   @Override
1:   public int run(String[] args) throws Exception {
1: 
1:     addInputOption();
1:     addOption("userFeatures", null, "path to the user feature matrix", true);
1:     addOption("itemFeatures", null, "path to the item feature matrix", true);
1:     addOption("numRecommendations", null, "number of recommendations per user",
1:         String.valueOf(DEFAULT_NUM_RECOMMENDATIONS));
1:     addOption("maxRating", null, "maximum rating available", true);
1:     addOutputOption();
1: 
0:     Map<String,String> parsedArgs = parseArguments(args);
1:     if (parsedArgs == null) {
1:       return -1;
1:     }
1: 
0:     Job prediction = prepareJob(getInputPath(), getOutputPath(), SequenceFileInputFormat.class, PredictionMapper.class,
0:         IntWritable.class, RecommendedItemsWritable.class, TextOutputFormat.class);
0:     prediction.getConfiguration().setInt(NUM_RECOMMENDATIONS,
0:         Integer.parseInt(parsedArgs.get("--numRecommendations")));
0:     prediction.getConfiguration().set(USER_FEATURES_PATH, parsedArgs.get("--userFeatures"));
0:     prediction.getConfiguration().set(ITEM_FEATURES_PATH, parsedArgs.get("--itemFeatures"));
0:     prediction.getConfiguration().set(MAX_RATING, parsedArgs.get("--maxRating"));
0:     prediction.waitForCompletion(true);
1: 
1:     return 0;
1:   }
1: 
0:   private static final Comparator<RecommendedItem> BY_PREFERENCE_VALUE =
0:       new Comparator<RecommendedItem>() {
1:         @Override
0:         public int compare(RecommendedItem one, RecommendedItem two) {
0:           return Floats.compare(one.getValue(), two.getValue());
1:         }
0:       };
1: 
0:   static class PredictionMapper
0:       extends Mapper<IntWritable,VectorWritable,IntWritable,RecommendedItemsWritable> {
1: 
0:     private OpenIntObjectHashMap<Vector> U;
0:     private OpenIntObjectHashMap<Vector> M;
1: 
0:     private int recommendationsPerUser;
0:     private float maxRating;
1: 
1:     @Override
0:     protected void setup(Context ctx) throws IOException, InterruptedException {
0:       recommendationsPerUser = ctx.getConfiguration().getInt(NUM_RECOMMENDATIONS,
0:           DEFAULT_NUM_RECOMMENDATIONS);
1: 
0:       Path pathToU = new Path(ctx.getConfiguration().get(USER_FEATURES_PATH));
0:       Path pathToM = new Path(ctx.getConfiguration().get(ITEM_FEATURES_PATH));
1: 
0:       U = ALSUtils.readMatrixByRows(pathToU, ctx.getConfiguration());
0:       M = ALSUtils.readMatrixByRows(pathToM, ctx.getConfiguration());
1: 
0:       maxRating = Float.parseFloat(ctx.getConfiguration().get(MAX_RATING));
1:     }
1: 
1:     @Override
0:     protected void map(IntWritable userIDWritable, VectorWritable ratingsWritable, Context ctx)
0:         throws IOException, InterruptedException {
1: 
0:       Vector ratings = ratingsWritable.get();
0:       final int userID = userIDWritable.get();
0:       final OpenIntHashSet alreadyRatedItems = new OpenIntHashSet(ratings.getNumNondefaultElements());
0:       final TopK<RecommendedItem> topKItems = new TopK<RecommendedItem>(recommendationsPerUser, BY_PREFERENCE_VALUE);
1: 
0:       Iterator<Vector.Element> ratingsIterator = ratings.iterateNonZero();
0:       while (ratingsIterator.hasNext()) {
0:         alreadyRatedItems.add(ratingsIterator.next().index());
1:       }
1: 
0:       M.forEachPair(new IntObjectProcedure<Vector>() {
1:         @Override
0:         public boolean apply(int itemID, Vector itemFeatures) {
0:           if (!alreadyRatedItems.contains(itemID)) {
0:             double predictedRating = U.get(userID).dot(itemFeatures);
0:             topKItems.offer(new GenericRecommendedItem(itemID, (float) predictedRating));
1:           }
0:           return true;
1:         }
0:       });
1: 
0:       List<RecommendedItem> recommendedItems = Lists.newArrayListWithExpectedSize(recommendationsPerUser);
0:       for (RecommendedItem topItem : topKItems.retrieve()) {
0:         recommendedItems.add(new GenericRecommendedItem(topItem.getItemID(), Math.min(topItem.getValue(), maxRating)));
1:       }
1: 
0:       if (!topKItems.isEmpty()) {
0:         ctx.write(userIDWritable, new RecommendedItemsWritable(recommendedItems));
1:       }
1:     }
1:   }
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:10c535c
/////////////////////////////////////////////////////////////////////////
0:     private final RecommendedItemsWritable recommendations = new RecommendedItemsWritable();
/////////////////////////////////////////////////////////////////////////
0:     private static double dot(Vector x, Vector y) {
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     if (!succeeded) {
0:     }
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = prediction.waitForCompletion(true);
0:     if (!succeeded) 
1:       return -1;
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6db7f62
/////////////////////////////////////////////////////////////////////////
1:     Map<String,List<String>> parsedArgs = parseArguments(args);
/////////////////////////////////////////////////////////////////////////
0:         Integer.parseInt(getOption("numRecommendations")));
0:     prediction.getConfiguration().set(USER_FEATURES_PATH, getOption("userFeatures"));
0:     prediction.getConfiguration().set(ITEM_FEATURES_PATH, getOption("itemFeatures"));
0:     prediction.getConfiguration().set(MAX_RATING, getOption("maxRating"));
0:     if (!succeeded)
0: 
============================================================================
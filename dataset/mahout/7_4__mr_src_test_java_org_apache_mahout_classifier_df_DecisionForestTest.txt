1:1608f61: /**
1:1608f61:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:1608f61:  * contributor license agreements.  See the NOTICE file distributed with
1:1608f61:  * this work for additional information regarding copyright ownership.
1:1608f61:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:1608f61:  * (the "License"); you may not use this file except in compliance with
1:1608f61:  * the License.  You may obtain a copy of the License at
1:1608f61:  *
1:1608f61:  *     http://www.apache.org/licenses/LICENSE-2.0
1:1608f61:  *
1:1608f61:  * Unless required by applicable law or agreed to in writing, software
1:1608f61:  * distributed under the License is distributed on an "AS IS" BASIS,
1:1608f61:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:1608f61:  * See the License for the specific language governing permissions and
1:1608f61:  * limitations under the License.
1:1608f61:  */
2:1608f61: 
1:1608f61: package org.apache.mahout.classifier.df;
1:1608f61: 
1:1608f61: import java.util.List;
1:1608f61: import java.util.Random;
1:1608f61: 
1:1608f61: import org.apache.mahout.classifier.df.builder.DecisionTreeBuilder;
1:1608f61: import org.apache.mahout.classifier.df.data.Data;
1:1608f61: import org.apache.mahout.classifier.df.data.DataLoader;
1:1608f61: import org.apache.mahout.classifier.df.data.Dataset;
1:1608f61: import org.apache.mahout.classifier.df.data.DescriptorException;
1:1608f61: import org.apache.mahout.classifier.df.data.Instance;
1:1608f61: import org.apache.mahout.classifier.df.node.Node;
1:1608f61: import org.apache.mahout.common.MahoutTestCase;
1:1608f61: import org.apache.mahout.common.RandomUtils;
1:1608f61: import org.junit.Test;
1:1608f61: 
1:1608f61: import com.google.common.collect.Lists;
1:1ffa3a4: @Deprecated
1:2deba36: public final class DecisionForestTest extends MahoutTestCase {
1:1608f61: 
1:1608f61:   private static final String[] TRAIN_DATA = {"sunny,85,85,FALSE,no",
1:1608f61:     "sunny,80,90,TRUE,no", "overcast,83,86,FALSE,yes",
1:1608f61:     "rainy,70,96,FALSE,yes", "rainy,68,80,FALSE,yes", "rainy,65,70,TRUE,no",
1:1608f61:     "overcast,64,65,TRUE,yes", "sunny,72,95,FALSE,no",
1:1608f61:     "sunny,69,70,FALSE,yes", "rainy,75,80,FALSE,yes", "sunny,75,70,TRUE,yes",
1:1608f61:     "overcast,72,90,TRUE,yes", "overcast,81,75,FALSE,yes",
1:1608f61:     "rainy,71,91,TRUE,no"};
1:1608f61:   
1:1608f61:   private static final String[] TEST_DATA = {"rainy,70,96,TRUE,-",
1:1608f61:     "overcast,64,65,TRUE,-", "sunny,75,90,TRUE,-",};
1:1608f61: 
1:1608f61:   private Random rng;
1:1608f61: 
1:1608f61:   @Override
1:1608f61:   public void setUp() throws Exception {
1:1608f61:     super.setUp();
1:1608f61:     rng = RandomUtils.getRandom();
2:1608f61:   }
1:1608f61: 
1:1608f61:   private static Data[] generateTrainingDataA() throws DescriptorException {
1:1608f61:     // Dataset
1:1608f61:     Dataset dataset = DataLoader.generateDataset("C N N C L", false, TRAIN_DATA);
1:1608f61:     
1:1608f61:     // Training data
1:1608f61:     Data data = DataLoader.loadData(dataset, TRAIN_DATA);
1:1608f61:     @SuppressWarnings("unchecked")
1:1608f61:     List<Instance>[] instances = new List[3];
1:1608f61:     for (int i = 0; i < instances.length; i++) {
1:1608f61:       instances[i] = Lists.newArrayList();
1:1608f61:     }
1:1608f61:     for (int i = 0; i < data.size(); i++) {
1:1608f61:       if (data.get(i).get(0) == 0.0d) {
1:1608f61:         instances[0].add(data.get(i));
1:1608f61:       } else {
1:1608f61:         instances[1].add(data.get(i));
1:1608f61:       }
1:1608f61:     }
1:1608f61:     Data[] datas = new Data[instances.length];
1:1608f61:     for (int i = 0; i < datas.length; i++) {
1:1608f61:       datas[i] = new Data(dataset, instances[i]);
1:1608f61:     }
1:1608f61: 
1:1608f61:     return datas;
1:1608f61:   }
1:1608f61: 
1:1608f61:   private static Data[] generateTrainingDataB() throws DescriptorException {
1:1608f61: 
1:1608f61:     // Training data
1:1608f61:     String[] trainData = new String[20];
1:1608f61:     for (int i = 0; i < trainData.length; i++) {
1:1608f61:       if (i % 3 == 0) {
1:1608f61:         trainData[i] = "A," + (40 - i) + ',' +  (i + 20);
1:1608f61:       } else if (i % 3 == 1) {
1:1608f61:         trainData[i] = "B," + (i + 20) + ',' +  (40 - i);
1:1608f61:       } else {
1:1608f61:         trainData[i] = "C," + (i + 20) + ',' +  (i + 20);
1:1608f61:       }
1:1608f61:     }
1:1608f61:     // Dataset
1:1608f61:     Dataset dataset = DataLoader.generateDataset("C N L", true, trainData);
1:1608f61:     Data[] datas = new Data[3];
1:1608f61:     datas[0] = DataLoader.loadData(dataset, trainData);
1:1608f61: 
1:1608f61:     // Training data
1:1608f61:     trainData = new String[20];
1:1608f61:     for (int i = 0; i < trainData.length; i++) {
1:1608f61:       if (i % 2 == 0) {
1:1608f61:         trainData[i] = "A," + (50 - i) + ',' +  (i + 10);
1:1608f61:       } else {
1:1608f61:         trainData[i] = "B," + (i + 10) + ',' +  (50 - i);
1:1608f61:       }
1:1608f61:     }
1:1608f61:     datas[1] = DataLoader.loadData(dataset, trainData);
1:1608f61: 
1:1608f61:     // Training data
1:1608f61:     trainData = new String[10];
1:1608f61:     for (int i = 0; i < trainData.length; i++) {
1:1608f61:       trainData[i] = "A," + (40 - i) + ',' +  (i + 20);
1:1608f61:     }
1:1608f61:     datas[2] = DataLoader.loadData(dataset, trainData);
1:1608f61: 
1:1608f61:     return datas;
1:1608f61:   }
1:1608f61:   
1:1608f61:   private DecisionForest buildForest(Data[] datas) {
1:1608f61:     List<Node> trees = Lists.newArrayList();
1:1608f61:     for (Data data : datas) {
1:1608f61:       // build tree
1:1608f61:       DecisionTreeBuilder builder = new DecisionTreeBuilder();
1:1608f61:       builder.setM(data.getDataset().nbAttributes() - 1);
1:1608f61:       builder.setMinSplitNum(0);
1:1608f61:       builder.setComplemented(false);
1:1608f61:       trees.add(builder.build(rng, data));
1:1608f61:     }
1:1608f61:     return new DecisionForest(trees);
1:1608f61:   }
1:1608f61:   
1:1608f61:   @Test
1:1608f61:   public void testClassify() throws DescriptorException {
1:1608f61:     // Training data
1:1608f61:     Data[] datas = generateTrainingDataA();
1:1608f61:     // Build Forest
1:1608f61:     DecisionForest forest = buildForest(datas);
1:1608f61:     // Test data
1:91f15ec:     Dataset dataset = datas[0].getDataset();
1:91f15ec:     Data testData = DataLoader.loadData(dataset, TEST_DATA);
1:1608f61: 
1:91f15ec:     double noValue = dataset.valueOf(4, "no");
1:864ba1a:     double yesValue = dataset.valueOf(4, "yes");
1:91f15ec:     assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(0)), EPSILON);
1:2deba36:     // This one is tie-broken -- 1 is OK too
1:91f15ec:     //assertEquals(yesValue, forest.classify(testData.getDataset(), rng, testData.get(1)), EPSILON);
1:91f15ec:     assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(2)), EPSILON);
1:1608f61:   }
1:1608f61: 
1:1608f61:   @Test
1:1608f61:   public void testClassifyData() throws DescriptorException {
1:1608f61:     // Training data
1:1608f61:     Data[] datas = generateTrainingDataA();
1:1608f61:     // Build Forest
1:1608f61:     DecisionForest forest = buildForest(datas);
1:1608f61:     // Test data
1:91f15ec:     Dataset dataset = datas[0].getDataset();
1:91f15ec:     Data testData = DataLoader.loadData(dataset, TEST_DATA);
1:1608f61: 
1:1608f61:     double[][] predictions = new double[testData.size()][];
1:1608f61:     forest.classify(testData, predictions);
1:91f15ec:     double noValue = dataset.valueOf(4, "no");
1:91f15ec:     double yesValue = dataset.valueOf(4, "yes");
1:91f15ec:     assertArrayEquals(new double[][]{{noValue, Double.NaN, Double.NaN},
1:91f15ec:         {noValue, yesValue, Double.NaN}, {noValue, noValue, Double.NaN}}, predictions);
1:1608f61:   }
1:1608f61: 
1:1608f61:   @Test
1:1608f61:   public void testRegression() throws DescriptorException {
1:1608f61:     Data[] datas = generateTrainingDataB();
1:1608f61:     DecisionForest[] forests = new DecisionForest[datas.length];
1:1608f61:     for (int i = 0; i < datas.length; i++) {
1:1608f61:       Data[] subDatas = new Data[datas.length - 1];
1:1608f61:       int k = 0;
1:1608f61:       for (int j = 0; j < datas.length; j++) {
1:1608f61:         if (j != i) {
1:1608f61:           subDatas[k] = datas[j];
1:1608f61:           k++;
1:1608f61:         }
1:1608f61:       }
1:1608f61:       forests[i] = buildForest(subDatas);
1:1608f61:     }
1:1608f61:     
1:1608f61:     double[][] predictions = new double[datas[0].size()][];
1:1608f61:     forests[0].classify(datas[0], predictions);
1:2deba36:     assertArrayEquals(new double[]{20.0, 20.0}, predictions[0], EPSILON);
1:2deba36:     assertArrayEquals(new double[]{39.0, 29.0}, predictions[1], EPSILON);
1:2deba36:     assertArrayEquals(new double[]{Double.NaN, 29.0}, predictions[2], EPSILON);
1:2deba36:     assertArrayEquals(new double[]{Double.NaN, 23.0}, predictions[17], EPSILON);
1:1608f61: 
1:1608f61:     predictions = new double[datas[1].size()][];
1:1608f61:     forests[1].classify(datas[1], predictions);
1:2deba36:     assertArrayEquals(new double[]{30.0, 29.0}, predictions[19], EPSILON);
1:1608f61: 
1:1608f61:     predictions = new double[datas[2].size()][];
1:1608f61:     forests[2].classify(datas[2], predictions);
1:2deba36:     assertArrayEquals(new double[]{29.0, 28.0}, predictions[9], EPSILON);
1:1608f61: 
1:2deba36:     assertEquals(20.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(0)), EPSILON);
1:2deba36:     assertEquals(34.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(1)), EPSILON);
1:2deba36:     assertEquals(29.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(2)), EPSILON);
1:1608f61:   }
1:1608f61: }
============================================================================
author:smarthi
-------------------------------------------------------------------------------
commit:1ffa3a4
/////////////////////////////////////////////////////////////////////////
1: @Deprecated
author:Andrew Musselman
-------------------------------------------------------------------------------
commit:864ba1a
/////////////////////////////////////////////////////////////////////////
1:     double yesValue = dataset.valueOf(4, "yes");
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:670a7d2
/////////////////////////////////////////////////////////////////////////
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Sean Owen
-------------------------------------------------------------------------------
commit:91f15ec
/////////////////////////////////////////////////////////////////////////
1:     Dataset dataset = datas[0].getDataset();
1:     Data testData = DataLoader.loadData(dataset, TEST_DATA);
1:     double noValue = dataset.valueOf(4, "no");
1:     double yesValue = dataset.valueOf(4, "yes");
1:     assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(0)), EPSILON);
1:     //assertEquals(yesValue, forest.classify(testData.getDataset(), rng, testData.get(1)), EPSILON);
1:     assertEquals(noValue, forest.classify(testData.getDataset(), rng, testData.get(2)), EPSILON);
/////////////////////////////////////////////////////////////////////////
1:     Dataset dataset = datas[0].getDataset();
1:     Data testData = DataLoader.loadData(dataset, TEST_DATA);
1:     double noValue = dataset.valueOf(4, "no");
0:     double yesValue = dataset.valueOf(4, "yes");
1:     assertArrayEquals(new double[][]{{noValue, Double.NaN, Double.NaN},
1:         {noValue, yesValue, Double.NaN}, {noValue, noValue, Double.NaN}}, predictions);
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:2deba36
/////////////////////////////////////////////////////////////////////////
1: public final class DecisionForestTest extends MahoutTestCase {
/////////////////////////////////////////////////////////////////////////
0:     assertEquals(1.0, forest.classify(testData.getDataset(), rng, testData.get(0)), EPSILON);
1:     // This one is tie-broken -- 1 is OK too
0:     assertEquals(0.0, forest.classify(testData.getDataset(), rng, testData.get(1)), EPSILON);
0:     assertEquals(1.0, forest.classify(testData.getDataset(), rng, testData.get(2)), EPSILON);
/////////////////////////////////////////////////////////////////////////
0:     assertArrayEquals(new double[][]{{1.0, Double.NaN, Double.NaN},
0:         {1.0, 0.0, Double.NaN}, {1.0, 1.0, Double.NaN}}, predictions);
/////////////////////////////////////////////////////////////////////////
1:     assertArrayEquals(new double[]{20.0, 20.0}, predictions[0], EPSILON);
1:     assertArrayEquals(new double[]{39.0, 29.0}, predictions[1], EPSILON);
1:     assertArrayEquals(new double[]{Double.NaN, 29.0}, predictions[2], EPSILON);
1:     assertArrayEquals(new double[]{Double.NaN, 23.0}, predictions[17], EPSILON);
1:     assertArrayEquals(new double[]{30.0, 29.0}, predictions[19], EPSILON);
1:     assertArrayEquals(new double[]{29.0, 28.0}, predictions[9], EPSILON);
1:     assertEquals(20.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(0)), EPSILON);
1:     assertEquals(34.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(1)), EPSILON);
1:     assertEquals(29.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(2)), EPSILON);
commit:1608f61
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.df;
1: 
1: import java.util.List;
1: import java.util.Random;
1: 
1: import org.apache.mahout.classifier.df.builder.DecisionTreeBuilder;
1: import org.apache.mahout.classifier.df.data.Data;
1: import org.apache.mahout.classifier.df.data.DataLoader;
1: import org.apache.mahout.classifier.df.data.Dataset;
1: import org.apache.mahout.classifier.df.data.DescriptorException;
1: import org.apache.mahout.classifier.df.data.Instance;
1: import org.apache.mahout.classifier.df.node.Node;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.RandomUtils;
1: import org.junit.Test;
1: 
1: import com.google.common.collect.Lists;
1: 
0: public class DecisionForestTest extends MahoutTestCase {
1: 
1:   private static final String[] TRAIN_DATA = {"sunny,85,85,FALSE,no",
1:     "sunny,80,90,TRUE,no", "overcast,83,86,FALSE,yes",
1:     "rainy,70,96,FALSE,yes", "rainy,68,80,FALSE,yes", "rainy,65,70,TRUE,no",
1:     "overcast,64,65,TRUE,yes", "sunny,72,95,FALSE,no",
1:     "sunny,69,70,FALSE,yes", "rainy,75,80,FALSE,yes", "sunny,75,70,TRUE,yes",
1:     "overcast,72,90,TRUE,yes", "overcast,81,75,FALSE,yes",
1:     "rainy,71,91,TRUE,no"};
1:   
1:   private static final String[] TEST_DATA = {"rainy,70,96,TRUE,-",
1:     "overcast,64,65,TRUE,-", "sunny,75,90,TRUE,-",};
1: 
1:   private Random rng;
1: 
1:   @Override
1:   public void setUp() throws Exception {
1:     super.setUp();
1:     rng = RandomUtils.getRandom();
1:   }
1: 
1:   private static Data[] generateTrainingDataA() throws DescriptorException {
1:     // Dataset
1:     Dataset dataset = DataLoader.generateDataset("C N N C L", false, TRAIN_DATA);
1:     
1:     // Training data
1:     Data data = DataLoader.loadData(dataset, TRAIN_DATA);
1:     @SuppressWarnings("unchecked")
1:     List<Instance>[] instances = new List[3];
1:     for (int i = 0; i < instances.length; i++) {
1:       instances[i] = Lists.newArrayList();
1:     }
1:     for (int i = 0; i < data.size(); i++) {
1:       if (data.get(i).get(0) == 0.0d) {
1:         instances[0].add(data.get(i));
1:       } else {
1:         instances[1].add(data.get(i));
1:       }
1:     }
1:     Data[] datas = new Data[instances.length];
1:     for (int i = 0; i < datas.length; i++) {
1:       datas[i] = new Data(dataset, instances[i]);
1:     }
1: 
1:     return datas;
1:   }
1: 
1:   private static Data[] generateTrainingDataB() throws DescriptorException {
1: 
1:     // Training data
1:     String[] trainData = new String[20];
1:     for (int i = 0; i < trainData.length; i++) {
1:       if (i % 3 == 0) {
1:         trainData[i] = "A," + (40 - i) + ',' +  (i + 20);
1:       } else if (i % 3 == 1) {
1:         trainData[i] = "B," + (i + 20) + ',' +  (40 - i);
1:       } else {
1:         trainData[i] = "C," + (i + 20) + ',' +  (i + 20);
1:       }
1:     }
1:     // Dataset
1:     Dataset dataset = DataLoader.generateDataset("C N L", true, trainData);
1:     Data[] datas = new Data[3];
1:     datas[0] = DataLoader.loadData(dataset, trainData);
1: 
1:     // Training data
1:     trainData = new String[20];
1:     for (int i = 0; i < trainData.length; i++) {
1:       if (i % 2 == 0) {
1:         trainData[i] = "A," + (50 - i) + ',' +  (i + 10);
1:       } else {
1:         trainData[i] = "B," + (i + 10) + ',' +  (50 - i);
1:       }
1:     }
1:     datas[1] = DataLoader.loadData(dataset, trainData);
1: 
1:     // Training data
1:     trainData = new String[10];
1:     for (int i = 0; i < trainData.length; i++) {
1:       trainData[i] = "A," + (40 - i) + ',' +  (i + 20);
1:     }
1:     datas[2] = DataLoader.loadData(dataset, trainData);
1: 
1:     return datas;
1:   }
1:   
1:   private DecisionForest buildForest(Data[] datas) {
1:     List<Node> trees = Lists.newArrayList();
1:     for (Data data : datas) {
1:       // build tree
1:       DecisionTreeBuilder builder = new DecisionTreeBuilder();
1:       builder.setM(data.getDataset().nbAttributes() - 1);
1:       builder.setMinSplitNum(0);
1:       builder.setComplemented(false);
1:       trees.add(builder.build(rng, data));
1:     }
1:     return new DecisionForest(trees);
1:   }
1:   
1:   @Test
1:   public void testClassify() throws DescriptorException {
1:     // Training data
1:     Data[] datas = generateTrainingDataA();
1:     // Build Forest
1:     DecisionForest forest = buildForest(datas);
1:     // Test data
0:     Data testData = DataLoader.loadData(datas[0].getDataset(), TEST_DATA);
1: 
0:     for (int i = 0; i < testData.size(); i++) {
0:       assertEquals(1.0, forest.classify(testData.getDataset(), rng, testData.get(i)), 0);
1:     }
1:   }
1: 
1:   @Test
1:   public void testClassifyData() throws DescriptorException {
1:     // Training data
1:     Data[] datas = generateTrainingDataA();
1:     // Build Forest
1:     DecisionForest forest = buildForest(datas);
1:     // Test data
0:     Data testData = DataLoader.loadData(datas[0].getDataset(), TEST_DATA);
1: 
1:     double[][] predictions = new double[testData.size()][];
1:     forest.classify(testData, predictions);
0:     assertArrayEquals(predictions, new double[][] {{1.0,Double.NaN,Double.NaN},
0:       {1.0,0.0,Double.NaN},{1.0,1.0,Double.NaN}});
1:   }
1: 
1:   @Test
1:   public void testRegression() throws DescriptorException {
1:     Data[] datas = generateTrainingDataB();
1:     DecisionForest[] forests = new DecisionForest[datas.length];
1:     for (int i = 0; i < datas.length; i++) {
1:       Data[] subDatas = new Data[datas.length - 1];
1:       int k = 0;
1:       for (int j = 0; j < datas.length; j++) {
1:         if (j != i) {
1:           subDatas[k] = datas[j];
1:           k++;
1:         }
1:       }
1:       forests[i] = buildForest(subDatas);
1:     }
1:     
1:     double[][] predictions = new double[datas[0].size()][];
1:     forests[0].classify(datas[0], predictions);
0:     assertArrayEquals(predictions[0], new double[] {20.0, 20.0}, 0);
0:     assertArrayEquals(predictions[1], new double[] {39.0, 29.0}, 0);
0:     assertArrayEquals(predictions[2], new double[] {Double.NaN, 29.0}, 0);
0:     assertArrayEquals(predictions[17], new double[] {Double.NaN, 23.0}, 0);
1: 
1:     predictions = new double[datas[1].size()][];
1:     forests[1].classify(datas[1], predictions);
0:     assertArrayEquals(predictions[19], new double[] {30.0, 29.0}, 0);
1: 
1:     predictions = new double[datas[2].size()][];
1:     forests[2].classify(datas[2], predictions);
0:     assertArrayEquals(predictions[9], new double[] {29.0, 28.0}, 0);
1: 
0:     assertEquals(20.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(0)), 0);
0:     assertEquals(34.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(1)), 0);
0:     assertEquals(29.0, forests[0].classify(datas[0].getDataset(), rng, datas[0].get(2)), 0);
1:   }
1: }
============================================================================
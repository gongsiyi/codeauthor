1:b479bd2: /**
1:b479bd2:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b479bd2:  * contributor license agreements.  See the NOTICE file distributed with
1:b479bd2:  * this work for additional information regarding copyright ownership.
1:b479bd2:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b479bd2:  * (the "License"); you may not use this file except in compliance with
1:b479bd2:  * the License.  You may obtain a copy of the License at
3:b479bd2:  *
1:b479bd2:  *     http://www.apache.org/licenses/LICENSE-2.0
1:b479bd2:  *
1:b479bd2:  * Unless required by applicable law or agreed to in writing, software
1:b479bd2:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b479bd2:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b479bd2:  * See the License for the specific language governing permissions and
1:b479bd2:  * limitations under the License.
1:5a2250c:  */
1:5a2250c: 
1:b479bd2: package org.apache.mahout.math.hadoop.stochasticsvd;
10:b479bd2: 
1:b479bd2: import java.io.Closeable;
1:b479bd2: import java.io.File;
1:ffc7fab: import java.io.IOException;
1:b479bd2: import java.util.Deque;
1:b479bd2: import java.util.Random;
1:b479bd2: 
1:58cc1ae: import com.google.common.collect.Lists;
1:b479bd2: import org.apache.hadoop.conf.Configuration;
1:b479bd2: import org.apache.hadoop.fs.FileSystem;
1:b479bd2: import org.apache.hadoop.fs.Path;
1:b479bd2: import org.apache.hadoop.io.IntWritable;
1:b479bd2: import org.apache.hadoop.io.SequenceFile;
1:b479bd2: import org.apache.hadoop.io.SequenceFile.CompressionType;
1:b479bd2: import org.apache.hadoop.io.compress.DefaultCodec;
1:229aeff: import org.apache.mahout.common.IOUtils;
1:b479bd2: import org.apache.mahout.common.MahoutTestCase;
1:b479bd2: import org.apache.mahout.common.RandomUtils;
1:b479bd2: import org.apache.mahout.math.DenseMatrix;
1:175701c: import org.apache.mahout.math.DenseVector;
1:b479bd2: import org.apache.mahout.math.SequentialAccessSparseVector;
1:b479bd2: import org.apache.mahout.math.SingularValueDecomposition;
1:b479bd2: import org.apache.mahout.math.Vector;
1:b479bd2: import org.apache.mahout.math.VectorWritable;
1:b479bd2: import org.junit.Test;
1:b479bd2: 
1:175701c: import com.google.common.io.Closeables;
1:175701c: 
1:b479bd2: /**
1:175701c:  * 
1:b479bd2:  * Tests SSVD solver with a made-up data running hadoop solver in a local mode.
1:b479bd2:  * It requests full-rank SSVD and then compares singular values to that of
1:b479bd2:  * Colt's SVD asserting epsilon(precision) 1e-10 or whatever most recent value
1:b479bd2:  * configured.
1:175701c:  * 
1:5a2250c:  */
1:b479bd2: public class LocalSSVDSolverSparseSequentialTest extends MahoutTestCase {
1:b479bd2: 
1:b479bd2:   private static final double s_epsilon = 1.0E-10d;
1:ffc7fab: 
1:10c535c:   // removing from tests to reduce test running time
1:5a2250c:   /* 
1:b479bd2:   @Test
1:175701c:   public void testSSVDSolverSparse() throws IOException {
1:ffc7fab:     runSSVDSolver(0);
1:ffc7fab:   }
1:175701c:    */
1:175701c: 
1:ffc7fab:   @Test
1:175701c:   public void testSSVDSolverPowerIterations1() throws IOException {
1:ffc7fab:     runSSVDSolver(1);
1:ffc7fab:   }
1:175701c: 
1:ffc7fab:   public void runSSVDSolver(int q) throws IOException {
1:5a2250c: 
1:921e201:     Configuration conf = getConfiguration();
1:b479bd2:     conf.set("mapred.job.tracker", "local");
1:b479bd2:     conf.set("fs.default.name", "file:///");
1:ffc7fab: 
1:b479bd2:     // conf.set("mapred.job.tracker","localhost:11011");
1:b479bd2:     // conf.set("fs.default.name","hdfs://localhost:11010/");
1:b479bd2: 
1:58cc1ae:     Deque<Closeable> closeables = Lists.newLinkedList();;
1:b479bd2:     Random rnd = RandomUtils.getRandom();
1:b479bd2: 
1:b479bd2:     File tmpDir = getTestTempDir("svdtmp");
1:b479bd2:     conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());
1:b479bd2: 
1:b479bd2:     Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");
1:b479bd2: 
1:b479bd2:     // create distributed row matrix-like struct
1:ffc7fab:     SequenceFile.Writer w =
1:ffc7fab:       SequenceFile.createWriter(FileSystem.getLocal(conf),
1:ffc7fab:                                 conf,
1:ffc7fab:                                 aLocPath,
1:ffc7fab:                                 IntWritable.class,
1:ffc7fab:                                 VectorWritable.class,
1:ffc7fab:                                 CompressionType.BLOCK,
1:ffc7fab:                                 new DefaultCodec());
1:b479bd2:     closeables.addFirst(w);
1:b479bd2: 
1:b479bd2:     int n = 100;
1:5a2250c:     int m = 2000;
1:ffc7fab:     double percent = 5;
1:ffc7fab: 
1:b479bd2:     VectorWritable vw = new VectorWritable();
1:b479bd2:     IntWritable roww = new IntWritable();
1:b479bd2: 
1:b479bd2:     double muAmplitude = 50.0;
1:b479bd2:     for (int i = 0; i < m; i++) {
1:96117d3:       Vector dv = new SequentialAccessSparseVector(n);
1:ffc7fab:       for (int j = 0; j < n * percent / 100; j++) {
1:b479bd2:         dv.setQuick(rnd.nextInt(n), muAmplitude * (rnd.nextDouble() - 0.5));
1:b479bd2:       }
1:b479bd2:       roww.set(i);
1:b479bd2:       vw.set(dv);
1:b479bd2:       w.append(roww, vw);
1:b479bd2:     }
1:b479bd2:     closeables.remove(w);
1:87d4b2e:     Closeables.close(w, false);
1:b479bd2: 
1:1de8cec:     FileSystem fs = FileSystem.get(aLocPath.toUri(), conf);
1:b479bd2: 
1:b479bd2:     Path tempDirPath = getTestTempDirPath("svd-proc");
1:b479bd2:     Path aPath = new Path(tempDirPath, "A/A.seq");
1:b479bd2:     fs.copyFromLocalFile(aLocPath, aPath);
1:b479bd2: 
1:b479bd2:     Path svdOutPath = new Path(tempDirPath, "SSVD-out");
1:b479bd2: 
1:b479bd2:     // make sure we wipe out previous test results, just a convenience
1:b479bd2:     fs.delete(svdOutPath, true);
1:b479bd2: 
1:ffc7fab:     // Solver starts here:
1:ffc7fab:     System.out.println("Input prepared, starting solver...");
1:ffc7fab: 
1:ffc7fab:     int ablockRows = 867;
1:ffc7fab:     int p = 60;
1:ffc7fab:     int k = 40;
1:ffc7fab:     SSVDSolver ssvd =
1:ffc7fab:       new SSVDSolver(conf,
1:ffc7fab:                      new Path[] { aPath },
1:ffc7fab:                      svdOutPath,
1:ffc7fab:                      ablockRows,
1:ffc7fab:                      k,
1:ffc7fab:                      p,
1:ffc7fab:                      3);
1:5a2250c:     ssvd.setOuterBlockHeight(500);
1:5a2250c:     ssvd.setAbtBlockHeight(251);
1:175701c: 
1:5a2250c:     /*
1:5a2250c:      * removing V,U jobs from this test to reduce running time. i will keep them
1:5a2250c:      * put in the dense test though.
1:5a2250c:      */
1:5a2250c:     ssvd.setComputeU(false);
1:5a2250c:     ssvd.setComputeV(false);
1:175701c: 
1:b479bd2:     ssvd.setOverwrite(true);
1:ffc7fab:     ssvd.setQ(q);
1:8bac914:     ssvd.setBroadcast(true);
1:b479bd2:     ssvd.run();
1:5a2250c: 
1:175701c:     Vector stochasticSValues = ssvd.getSingularValues();
1:b479bd2:     System.out.println("--SSVD solver singular values:");
1:b479bd2:     dumpSv(stochasticSValues);
1:b479bd2:     System.out.println("--Colt SVD solver singular values:");
1:b479bd2: 
1:b479bd2:     // try to run the same thing without stochastic algo
1:b717cfc:     DenseMatrix a = SSVDHelper.drmLoadAsDense(fs, aPath, conf);
1:b479bd2: 
1:b479bd2:     // SingularValueDecompositionImpl svd=new SingularValueDecompositionImpl(new
1:b479bd2:     // Array2DRowRealMatrix(a));
1:ffc7fab:     SingularValueDecomposition svd2 =
1:b717cfc:       new SingularValueDecomposition(a);
1:b479bd2: 
1:175701c:     Vector svalues2 = new DenseVector(svd2.getSingularValues());
1:b479bd2:     dumpSv(svalues2);
1:b479bd2: 
1:b479bd2:     for (int i = 0; i < k + p; i++) {
1:175701c:       assertTrue(Math.abs(svalues2.getQuick(i) - stochasticSValues.getQuick(i)) <= s_epsilon);
1:b479bd2:     }
1:b479bd2: 
1:b717cfc:     DenseMatrix mQ =
1:b717cfc:       SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "Bt-job/"
1:b717cfc:         + BtJob.OUTPUT_Q + "-*"), conf);
1:b479bd2: 
1:b717cfc:     SSVDCommonTest.assertOrthonormality(mQ,
1:b717cfc:                                         false,
1:b717cfc:                                         s_epsilon);
1:b479bd2: 
1:229aeff:     IOUtils.close(closeables);
1:b479bd2:   }
1:b479bd2: 
1:175701c:   static void dumpSv(Vector s) {
1:b479bd2:     System.out.printf("svs: ");
1:dc62944:     for (Vector.Element el : s.all()) {
1:175701c:       System.out.printf("%f  ", el.get());
1:b479bd2:     }
1:b479bd2:     System.out.println();
1:b479bd2: 
1:b479bd2:   }
1:b479bd2: 
1:b479bd2:   static void dump(double[][] matrix) {
1:b479bd2:     for (double[] aMatrix : matrix) {
1:b479bd2:       for (double anAMatrix : aMatrix) {
1:b479bd2:         System.out.printf("%f  ", anAMatrix);
1:b479bd2:       }
1:b479bd2:       System.out.println();
1:b479bd2:     }
1:b479bd2:   }
1:b479bd2: 
1:b479bd2: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:Dmitriy Lyubimov
-------------------------------------------------------------------------------
commit:b717cfc
/////////////////////////////////////////////////////////////////////////
1:     DenseMatrix a = SSVDHelper.drmLoadAsDense(fs, aPath, conf);
1:       new SingularValueDecomposition(a);
/////////////////////////////////////////////////////////////////////////
1:     DenseMatrix mQ =
1:       SSVDHelper.drmLoadAsDense(fs, new Path(svdOutPath, "Bt-job/"
1:         + BtJob.OUTPUT_Q + "-*"), conf);
1:     SSVDCommonTest.assertOrthonormality(mQ,
1:                                         false,
1:                                         s_epsilon);
commit:175701c
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.math.DenseVector;
1: import com.google.common.io.Closeables;
1: 
/////////////////////////////////////////////////////////////////////////
1:   public void testSSVDSolverSparse() throws IOException {
1: 
1:   public void testSSVDSolverPowerIterations1() throws IOException {
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:     Vector stochasticSValues = ssvd.getSingularValues();
0:     double[][] a = SSVDHelper.loadDistributedRowMatrix(fs, aPath, conf);
1:     Vector svalues2 = new DenseVector(svd2.getSingularValues());
1:       assertTrue(Math.abs(svalues2.getQuick(i) - stochasticSValues.getQuick(i)) <= s_epsilon);
0:       SSVDHelper.loadDistributedRowMatrix(fs, new Path(svdOutPath, "Bt-job/"
0:     SSVDCommonTest.assertOrthonormality(new DenseMatrix(mQ),
0:                                            false,
0:                                            s_epsilon);
/////////////////////////////////////////////////////////////////////////
0:      * double[][] u = SSVDSolver.loadDistributedRowMatrix(fs, new
0:      * Path(svdOutPath, "U/[^_]*"), conf);
1:      * 
0:      * SSVDPrototypeTest .assertOrthonormality(new DenseMatrix(u), false,
0:      * s_epsilon); double[][] v = SSVDSolver.loadDistributedRowMatrix(fs, new
0:      * Path(svdOutPath, "V/[^_]*"), conf);
1:      * 
0:      * SSVDPrototypeTest .assertOrthonormality(new DenseMatrix(v), false,
0:      * s_epsilon);
1:      */
1:   static void dumpSv(Vector s) {
0:     for (Vector.Element el : s) {
1:       System.out.printf("%f  ", el.get());
commit:8bac914
/////////////////////////////////////////////////////////////////////////
1:     ssvd.setBroadcast(true);
commit:ebeade9
/////////////////////////////////////////////////////////////////////////
commit:5214b1d
/////////////////////////////////////////////////////////////////////////
0:     ssvd.setBroadcast(true);
commit:5a2250c
/////////////////////////////////////////////////////////////////////////
1:   /*
0:    * removing from tests to reduce test running time
1:    */
0:   /* @Test */
/////////////////////////////////////////////////////////////////////////
1:     int m = 2000;
/////////////////////////////////////////////////////////////////////////
1:     ssvd.setOuterBlockHeight(500);
1:     ssvd.setAbtBlockHeight(251);
1:     
1:     /*
1:      * removing V,U jobs from this test to reduce running time. i will keep them
1:      * put in the dense test though.
1:      */
1:     ssvd.setComputeU(false);
1:     ssvd.setComputeV(false);
1:     
/////////////////////////////////////////////////////////////////////////
0:     /*
0:      * removing tests on U and V to keep this test leaner. I will keep U,V
0:      * computation and assertions in the dense tests though.
1:      */
1: 
0:     /*
/////////////////////////////////////////////////////////////////////////
0:     */
commit:ffc7fab
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
/////////////////////////////////////////////////////////////////////////
0:   public void testSSVDSolverSparse() throws IOException { 
1:     runSSVDSolver(0);
1:   }
1:   
1:   @Test
0:   public void testSSVDSolverPowerIterations1() throws IOException { 
1:     runSSVDSolver(1);
1:   }
1:   
1:   public void runSSVDSolver(int q) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     SequenceFile.Writer w =
1:       SequenceFile.createWriter(FileSystem.getLocal(conf),
1:                                 conf,
1:                                 aLocPath,
1:                                 IntWritable.class,
1:                                 VectorWritable.class,
1:                                 CompressionType.BLOCK,
1:                                 new DefaultCodec());
0:     int m = 20000;
1:     int ablockRows = 867;
1:     int p = 60;
1:     int k = 40;
1:     double percent = 5;
1: 
1:       for (int j = 0; j < n * percent / 100; j++) {
/////////////////////////////////////////////////////////////////////////
0:     Closeables.close(w, true);
/////////////////////////////////////////////////////////////////////////
1:     // Solver starts here:
1:     System.out.println("Input prepared, starting solver...");
1: 
1:     SSVDSolver ssvd =
1:       new SSVDSolver(conf,
1:                      new Path[] { aPath },
1:                      svdOutPath,
1:                      ablockRows,
0:                      500,
1:                      k,
1:                      p,
1:                      3);
1:     ssvd.setQ(q);
/////////////////////////////////////////////////////////////////////////
1:     SingularValueDecomposition svd2 =
0:       new SingularValueDecomposition(new DenseMatrix(a));
/////////////////////////////////////////////////////////////////////////
0:       Assert
0:         .assertTrue(Math.abs(svalues2[i] - stochasticSValues[i]) <= s_epsilon);
0:     double[][] mQ =
0:       SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath, "Bt-job/"
0:           + BtJob.OUTPUT_Q + "-*"), conf);
0:     SSVDPrototypeTest
0:       .assertOrthonormality(new DenseMatrix(mQ), false, s_epsilon);
0:     double[][] u =
0:       SSVDSolver.loadDistributedRowMatrix(fs,
0:                                           new Path(svdOutPath, "U/[^_]*"),
0:                                           conf);
0:     SSVDPrototypeTest
0:       .assertOrthonormality(new DenseMatrix(u), false, s_epsilon);
0:     double[][] v =
0:       SSVDSolver.loadDistributedRowMatrix(fs,
0:                                           new Path(svdOutPath, "V/[^_]*"),
0:                                           conf);
0:     SSVDPrototypeTest
0:       .assertOrthonormality(new DenseMatrix(v), false, s_epsilon);
commit:b479bd2
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
0:  */
1: 
1: package org.apache.mahout.math.hadoop.stochasticsvd;
1: 
1: import java.io.Closeable;
1: import java.io.File;
1: import java.util.Deque;
0: import java.util.LinkedList;
1: import java.util.Random;
1: 
0: import junit.framework.Assert;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.SequenceFile.CompressionType;
1: import org.apache.hadoop.io.compress.DefaultCodec;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.RandomUtils;
1: import org.apache.mahout.math.DenseMatrix;
1: import org.apache.mahout.math.SequentialAccessSparseVector;
1: import org.apache.mahout.math.SingularValueDecomposition;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Test;
1: 
1: /**
1:  * 
1:  * Tests SSVD solver with a made-up data running hadoop solver in a local mode.
1:  * It requests full-rank SSVD and then compares singular values to that of
1:  * Colt's SVD asserting epsilon(precision) 1e-10 or whatever most recent value
1:  * configured.
1:  * 
0:  */
1: public class LocalSSVDSolverSparseSequentialTest extends MahoutTestCase {
1: 
1:   private static final double s_epsilon = 1.0E-10d;
1: 
1:   @Test
0:   public void testSSVDSolver() throws Exception {
1: 
0:     Configuration conf = new Configuration();
1:     conf.set("mapred.job.tracker", "local");
1:     conf.set("fs.default.name", "file:///");
1: 
1:     // conf.set("mapred.job.tracker","localhost:11011");
1:     // conf.set("fs.default.name","hdfs://localhost:11010/");
1: 
0:     Deque<Closeable> closeables = new LinkedList<Closeable>();
1:     Random rnd = RandomUtils.getRandom();
1: 
1:     File tmpDir = getTestTempDir("svdtmp");
1:     conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());
1: 
1:     Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");
1: 
1:     // create distributed row matrix-like struct
0:     SequenceFile.Writer w = SequenceFile.createWriter(FileSystem.getLocal(conf), conf, aLocPath, IntWritable.class,
0:         VectorWritable.class, CompressionType.BLOCK, new DefaultCodec());
1:     closeables.addFirst(w);
1: 
1:     int n = 100;
0:     Vector dv;
1:     VectorWritable vw = new VectorWritable();
1:     IntWritable roww = new IntWritable();
1: 
1:     double muAmplitude = 50.0;
0:     int m = 1000;
1:     for (int i = 0; i < m; i++) {
0:       dv=new SequentialAccessSparseVector(n);
0:       for (int j = 0; j < n / 5; j++) {
1:         dv.setQuick(rnd.nextInt(n), muAmplitude * (rnd.nextDouble() - 0.5));
1:       }
1:       roww.set(i);
1:       vw.set(dv);
1:       w.append(roww, vw);
1:     }
1:     closeables.remove(w);
0:     w.close();
1: 
0:     FileSystem fs = FileSystem.get(conf);
1: 
1:     Path tempDirPath = getTestTempDirPath("svd-proc");
1:     Path aPath = new Path(tempDirPath, "A/A.seq");
1:     fs.copyFromLocalFile(aLocPath, aPath);
1: 
1:     Path svdOutPath = new Path(tempDirPath, "SSVD-out");
1: 
1:     // make sure we wipe out previous test results, just a convenience
1:     fs.delete(svdOutPath, true);
1: 
0:     int ablockRows = 251;
0:     int p = 60;
0:     int k = 40;
0:     SSVDSolver ssvd = new SSVDSolver(conf, new Path[] { aPath }, svdOutPath, ablockRows, k, p, 3);
0:     // ssvd.setcUHalfSigma(true);
0:     // ssvd.setcVHalfSigma(true);
1:     ssvd.setOverwrite(true);
1:     ssvd.run();
1: 
0:     double[] stochasticSValues = ssvd.getSingularValues();
1:     System.out.println("--SSVD solver singular values:");
1:     dumpSv(stochasticSValues);
1:     System.out.println("--Colt SVD solver singular values:");
1: 
1:     // try to run the same thing without stochastic algo
0:     double[][] a = SSVDSolver.loadDistributedRowMatrix(fs, aPath, conf);
1: 
1:     // SingularValueDecompositionImpl svd=new SingularValueDecompositionImpl(new
1:     // Array2DRowRealMatrix(a));
0:     SingularValueDecomposition svd2 = new SingularValueDecomposition(new DenseMatrix(a));
1: 
0:     a = null;
1: 
0:     double[] svalues2 = svd2.getSingularValues();
1:     dumpSv(svalues2);
1: 
1:     for (int i = 0; i < k + p; i++) {
0:       Assert.assertTrue(Math.abs(svalues2[i] - stochasticSValues[i]) <= s_epsilon);
1:     }
1: 
0:     double[][] q = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath, "Bt-job/" + BtJob.OUTPUT_Q + "-*"),
0:         conf);
1: 
0:     SSVDPrototypeTest.assertOrthonormality(new DenseMatrix(q), false, s_epsilon);
1: 
0:     double[][] u = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath, "U/[^_]*"), conf);
1: 
0:     SSVDPrototypeTest.assertOrthonormality(new DenseMatrix(u), false, s_epsilon);
0:     double[][] v = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath, "V/[^_]*"), conf);
1: 
0:     SSVDPrototypeTest.assertOrthonormality(new DenseMatrix(v), false, s_epsilon);
1:   }
1: 
0:   static void dumpSv(double[] s) {
1:     System.out.printf("svs: ");
0:     for (double value : s) {
0:       System.out.printf("%f  ", value);
1:     }
1:     System.out.println();
1: 
1:   }
1: 
1:   static void dump(double[][] matrix) {
1:     for (double[] aMatrix : matrix) {
1:       for (double anAMatrix : aMatrix) {
1:         System.out.printf("%f  ", anAMatrix);
1:       }
1:       System.out.println();
1:     }
1:   }
1: 
1: }
commit:151de0d
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one or more
0:  * contributor license agreements.  See the NOTICE file distributed with
0:  * this work for additional information regarding copyright ownership.
0:  * The ASF licenses this file to You under the Apache License, Version 2.0
0:  * (the "License"); you may not use this file except in compliance with
0:  * the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: package org.apache.mahout.math.hadoop.stochasticsvd;
0: 
0: import java.io.Closeable;
0: import java.io.File;
0: import java.util.LinkedList;
0: import java.util.Random;
0: 
0: import junit.framework.Assert;
0: 
0: import org.apache.hadoop.conf.Configuration;
0: import org.apache.hadoop.fs.FileSystem;
0: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.io.IntWritable;
0: import org.apache.hadoop.io.SequenceFile;
0: import org.apache.hadoop.io.SequenceFile.CompressionType;
0: import org.apache.hadoop.io.compress.DefaultCodec;
0: import org.apache.mahout.common.MahoutTestCase;
0: import org.apache.mahout.math.DenseMatrix;
0: import org.apache.mahout.math.DenseVector;
0: import org.apache.mahout.math.SingularValueDecomposition;
0: import org.apache.mahout.math.VectorWritable;
0: import org.junit.Test;
0: 
0: /**
0:  * 
0:  * Tests SSVD solver with a made-up data running hadoop 
0:  * solver in a local mode. It requests full-rank SSVD and 
0:  * then compares singular values to that of Colt's SVD 
0:  * asserting epsilon(precision) 1e-10 or whatever most recent 
0:  * value configured. 
0:  * 
0:  */
0: public class LocalSSVDSolverTest extends MahoutTestCase {
0: 
0:   private static final double s_epsilon = 1.0E-10d;
0: 
0:   @Test
0:   public void testSSVDSolver() throws Exception {
0: 
0:     Configuration conf = new Configuration();
0:     conf.set("mapred.job.tracker", "local");
0:     conf.set("fs.default.name", "file:///");
0: 
0:     // conf.set("mapred.job.tracker","localhost:11011");
0:     // conf.set("fs.default.name","hdfs://localhost:11010/");
0: 
0:     LinkedList<Closeable> closeables = new LinkedList<Closeable>();
0:     Random rnd = new Random();
0:     int m = 1000, n = 100, k = 40, p = 60, ablockRows = 251;
0: 
0:     double muAmplitude = 5e+1;
0: 
0:     File tmpDir = new File("svdtmp");
0:     tmpDir.mkdir();
0:     conf.set("hadoop.tmp.dir", tmpDir.getAbsolutePath());
0: 
0:     File aDir = new File(tmpDir, "A");
0:     aDir.mkdir();
0: 
0:     Path aLocPath = new Path(new Path(aDir.getAbsolutePath()), "A.seq");
0: 
0:     // create distributed row matrix-like struct
0:     SequenceFile.Writer w = SequenceFile.createWriter(
0:         FileSystem.getLocal(conf), conf, aLocPath, IntWritable.class,
0:         VectorWritable.class, CompressionType.BLOCK, new DefaultCodec());
0:     closeables.addFirst(w);
0: 
0:     double[] row = new double[n];
0:     DenseVector dv = new DenseVector(row, true);
0:     VectorWritable vw = new VectorWritable(dv);
0:     IntWritable roww = new IntWritable();
0: 
0:     for (int i = 0; i < m; i++) {
0:       for (int j = 0; j < n; j++)
0:         row[j] = muAmplitude * (rnd.nextDouble() - 0.5);
0:       roww.set(i);
0:       w.append(roww, vw);
0:     }
0:     closeables.remove(w);
0:     w.close();
0: 
0:     FileSystem fs = FileSystem.get(conf);
0: 
0:     Path tempDirPath = new Path(fs.getWorkingDirectory(), "svd-proc");
0:     Path aPath = new Path(tempDirPath, "A/A.seq");
0:     fs.copyFromLocalFile(aLocPath, aPath);
0: 
0:     Path svdOutPath = new Path(tempDirPath, "SSVD-out");
0: 
0:     // make sure we wipe out previous test results, just a convenience
0:     fs.delete(svdOutPath, true);
0: 
0:     SSVDSolver ssvd = new SSVDSolver(conf, new Path[] { aPath }, svdOutPath,
0:         ablockRows, k, p, 3);
0:     // ssvd.setcUHalfSigma(true);
0:     // ssvd.setcVHalfSigma(true);
0:     ssvd.run();
0: 
0:     double[] stochasticSValues = ssvd.getSingularValues();
0:     System.out.println("--SSVD solver singular values:");
0:     dumpSv(stochasticSValues);
0:     System.out.println("--Colt SVD solver singular values:");
0: 
0:     // try to run the same thing without stochastic algo
0:     double[][] a = SSVDSolver.loadDistributedRowMatrix(fs, aPath, conf);
0: 
0:     // SingularValueDecompositionImpl svd=new SingularValueDecompositionImpl(new
0:     // Array2DRowRealMatrix(a));
0:     SingularValueDecomposition svd2 = new SingularValueDecomposition(
0:         new DenseMatrix(a));
0: 
0:     a = null;
0: 
0:     double[] svalues2 = svd2.getSingularValues();
0:     dumpSv(svalues2);
0: 
0:     for (int i = 0; i < k + p; i++)
0:       Assert
0:           .assertTrue(Math.abs(svalues2[i] - stochasticSValues[i]) <= s_epsilon);
0: 
0:     double[][] q = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath,
0:         "Bt-job/" + BtJob.OUTPUT_Q + "-*"), conf);
0: 
0:     SSVDPrototypeTest
0:         .assertOrthonormality(new DenseMatrix(q), false, s_epsilon);
0: 
0:     double[][] u = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath,
0:         "U/[^_]*"), conf);
0: 
0:     SSVDPrototypeTest
0:         .assertOrthonormality(new DenseMatrix(u), false, s_epsilon);
0:     double[][] v = SSVDSolver.loadDistributedRowMatrix(fs, new Path(svdOutPath,
0:         "V/[^_]*"), conf);
0: 
0:     SSVDPrototypeTest
0:         .assertOrthonormality(new DenseMatrix(v), false, s_epsilon);
0:   }
0: 
0:   static void dumpSv(double[] s) {
0:     System.out.printf("svs: ");
0:     for (int i = 0; i < s.length; i++)
0:       System.out.printf("%f  ", s[i]);
0:     System.out.println();
0: 
0:   }
0: 
0:   static void dump(double[][] matrix) {
0:     for (int i = 0; i < matrix.length; i++) {
0:       for (int j = 0; j < matrix[i].length; j++)
0:         System.out.printf("%f  ", matrix[i][j]);
0:       System.out.println();
0:     }
0:   }
0: 
0: }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
1:     Deque<Closeable> closeables = Lists.newLinkedList();;
commit:d608a88
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
0:     Closeables.closeQuietly(w);
commit:58fb7c5
/////////////////////////////////////////////////////////////////////////
0:     File tmpDir = getTestTempDir("svdtmp");
0:     Path aLocPath = new Path(getTestTempDirPath("svdtmp/A"), "A.seq");
/////////////////////////////////////////////////////////////////////////
0:     Path tempDirPath = getTestTempDirPath("svd-proc");
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
1:     Closeables.close(w, false);
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
1:     for (Vector.Element el : s.all()) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:10c535c
/////////////////////////////////////////////////////////////////////////
1:   // removing from tests to reduce test running time
0:   /* 
0:   @Test
0:    */
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.IOUtils;
/////////////////////////////////////////////////////////////////////////
1:     IOUtils.close(closeables);
commit:1de8cec
/////////////////////////////////////////////////////////////////////////
1:     FileSystem fs = FileSystem.get(aLocPath.toUri(), conf);
commit:4194a28
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       assertTrue(Math.abs(svalues2[i] - stochasticSValues[i]) <= s_epsilon);
commit:1499411
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     int ablockRows = 867;
0:     int p = 60;
0:     int k = 40;
commit:96117d3
/////////////////////////////////////////////////////////////////////////
1:       Vector dv = new SequentialAccessSparseVector(n);
commit:b16c260
/////////////////////////////////////////////////////////////////////////
0: import java.util.Deque;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.io.Writable;
0: import org.apache.mahout.common.RandomUtils;
/////////////////////////////////////////////////////////////////////////
0:     Deque<Closeable> closeables = new LinkedList<Closeable>();
0:     Random rnd = RandomUtils.getRandom();
/////////////////////////////////////////////////////////////////////////
0:     int n = 100;
0:     Writable vw = new VectorWritable(dv);
0:     double muAmplitude = 50.0;
0:     int m = 1000;
0:       for (int j = 0; j < n; j++) {
0:       }
/////////////////////////////////////////////////////////////////////////
0:     int ablockRows = 251;
0:     int p = 60;
0:     int k = 40;
/////////////////////////////////////////////////////////////////////////
0:     for (int i = 0; i < k + p; i++) {
0:       Assert.assertTrue(Math.abs(svalues2[i] - stochasticSValues[i]) <= s_epsilon);
0:     }
0:     SSVDPrototypeTest.assertOrthonormality(new DenseMatrix(q), false, s_epsilon);
0:                                                                     "U/[^_]*"), conf);
0:     SSVDPrototypeTest.assertOrthonormality(new DenseMatrix(u), false, s_epsilon);
/////////////////////////////////////////////////////////////////////////
0:     for (double value : s) {
0:       System.out.printf("%f  ", value);
0:     }
0:     for (double[] aMatrix : matrix) {
0:       for (double anAMatrix : aMatrix) {
0:         System.out.printf("%f  ", anAMatrix);
0:       }
commit:c4550a1
/////////////////////////////////////////////////////////////////////////
0:     ssvd.setOverwrite(true);
============================================================================
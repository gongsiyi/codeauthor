1:172bb3b: /**
1:172bb3b:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:172bb3b:  * contributor license agreements.  See the NOTICE file distributed with
1:172bb3b:  * this work for additional information regarding copyright ownership.
1:172bb3b:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:172bb3b:  * (the "License"); you may not use this file except in compliance with
1:172bb3b:  * the License.  You may obtain a copy of the License at
1:4dd8881:  *
1:172bb3b:  *     http://www.apache.org/licenses/LICENSE-2.0
4:172bb3b:  *
1:172bb3b:  * Unless required by applicable law or agreed to in writing, software
1:172bb3b:  * distributed under the License is distributed on an "AS IS" BASIS,
1:172bb3b:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:172bb3b:  * See the License for the specific language governing permissions and
1:172bb3b:  * limitations under the License.
1:172bb3b:  */
1:8d102ea: package org.apache.mahout.clustering.iterator;
1:529b114: 
1:4dd8881: import java.io.IOException;
1:529b114: 
1:4dd8881: import org.apache.hadoop.conf.Configuration;
1:dc637e8: import org.apache.hadoop.fs.FileStatus;
1:4dd8881: import org.apache.hadoop.fs.FileSystem;
1:4dd8881: import org.apache.hadoop.fs.Path;
1:dc637e8: import org.apache.hadoop.io.IntWritable;
1:dc637e8: import org.apache.hadoop.mapreduce.Job;
1:dc637e8: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:dc637e8: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:dc637e8: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:dc637e8: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:3eba6f2: import org.apache.mahout.clustering.Cluster;
1:8d102ea: import org.apache.mahout.clustering.classify.ClusterClassifier;
1:4dd8881: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:4dd8881: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:4dd8881: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
1:dc637e8: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
1:172bb3b: import org.apache.mahout.math.Vector;
1:4dd8881: import org.apache.mahout.math.VectorWritable;
1:529b114: 
1:dc637e8: import com.google.common.io.Closeables;
1:529b114: 
1:4dd8881: /**
1:6b390e7:  * This is a clustering iterator which works with a set of Vector data and a prior ClusterClassifier which has been
1:6b390e7:  * initialized with a set of models. Its implementation is algorithm-neutral and works for any iterative clustering
1:ee41571:  * algorithm (currently k-means and fuzzy-k-means) that processes all the input vectors in each iteration.
1:6b390e7:  * The cluster classifier is configured with a ClusteringPolicy to select the desired clustering algorithm.
1:172bb3b:  */
1:229aeff: public final class ClusterIterator {
1:529b114:   
1:2153bb9:   public static final String PRIOR_PATH_KEY = "org.apache.mahout.clustering.prior.path";
1:229aeff: 
1:229aeff:   private ClusterIterator() {
1:229aeff:   }
1:a28cf1d:   
1:dc637e8:   /**
1:6b390e7:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations
1:229aeff:    *
1:529b114:    * @param data
1:a6bdcbb:    *          a {@code List<Vector>} of input vectors
1:529b114:    * @param classifier
1:529b114:    *          a prior ClusterClassifier
1:529b114:    * @param numIterations
1:529b114:    *          the int number of iterations to perform
1:3eba6f2:    * 
1:172bb3b:    * @return the posterior ClusterClassifier
1:4dd8881:    */
1:229aeff:   public static ClusterClassifier iterate(Iterable<Vector> data, ClusterClassifier classifier, int numIterations) {
1:3eba6f2:     ClusteringPolicy policy = classifier.getPolicy();
1:dc637e8:     for (int iteration = 1; iteration <= numIterations; iteration++) {
1:172bb3b:       for (Vector vector : data) {
1:1ac30a4:         // update the policy based upon the prior
1:1ac30a4:         policy.update(classifier);
1:172bb3b:         // classification yields probabilities
1:933e22a:         Vector probabilities = classifier.classify(vector);
1:933e22a:         // policy selects weights for models given those probabilities
1:4dd8881:         Vector weights = policy.select(probabilities);
1:172bb3b:         // training causes all models to observe data
1:dc62944:         for (Vector.Element e : weights.nonZeroes()) {
1:dc62944:           int index = e.index();
1:933e22a:           classifier.train(index, vector, weights.get(index));
1:a28cf1d:         }
1:a28cf1d:       }
1:172bb3b:       // compute the posterior models
1:933e22a:       classifier.close();
1:2153bb9:     }
1:933e22a:     return classifier;
1:4dd8881:   }
1:a28cf1d:   
1:172bb3b:   /**
1:6b390e7:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a sequential
1:6b390e7:    * implementation
1:3eba6f2:    * 
1:590ffed:    * @param conf
1:590ffed:    *          the Configuration
1:529b114:    * @param inPath
1:529b114:    *          a Path to input VectorWritables
1:529b114:    * @param priorPath
1:529b114:    *          a Path to the prior classifier
1:529b114:    * @param outPath
1:529b114:    *          a Path of output directory
1:529b114:    * @param numIterations
1:529b114:    *          the int number of iterations to perform
1:dc637e8:    */
1:229aeff:   public static void iterateSeq(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
1:229aeff:     throws IOException {
1:76e80dc:     ClusterClassifier classifier = new ClusterClassifier();
1:590ffed:     classifier.readFromSeqFiles(conf, priorPath);
1:3eba6f2:     Path clustersOut = null;
1:3eba6f2:     int iteration = 1;
1:3eba6f2:     while (iteration <= numIterations) {
1:2153bb9:       for (VectorWritable vw : new SequenceFileDirValueIterable<VectorWritable>(inPath, PathType.LIST,
1:2153bb9:           PathFilters.logsCRCFilter(), conf)) {
1:4dd8881:         Vector vector = vw.get();
1:4dd8881:         // classification yields probabilities
1:4dd8881:         Vector probabilities = classifier.classify(vector);
1:4dd8881:         // policy selects weights for models given those probabilities
1:3eba6f2:         Vector weights = classifier.getPolicy().select(probabilities);
1:4dd8881:         // training causes all models to observe data
1:dc62944:         for (Vector.Element e : weights.nonZeroes()) {
1:dc62944:           int index = e.index();
1:4dd8881:           classifier.train(index, vector, weights.get(index));
1:4dd8881:         }
1:4dd8881:       }
1:4dd8881:       // compute the posterior models
1:4dd8881:       classifier.close();
1:4dd8881:       // update the policy
1:3eba6f2:       classifier.getPolicy().update(classifier);
1:4dd8881:       // output the classifier
1:3eba6f2:       clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);
1:3eba6f2:       classifier.writeToSeqFiles(clustersOut);
1:3eba6f2:       FileSystem fs = FileSystem.get(outPath.toUri(), conf);
1:3eba6f2:       iteration++;
1:3eba6f2:       if (isConverged(clustersOut, conf, fs)) {
1:564c3e1:         break;
1:564c3e1:       }
1:3eba6f2:     }
1:3eba6f2:     Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
1:3eba6f2:     FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);
1:4dd8881:   }
1:529b114:   
1:172bb3b:   /**
1:6b390e7:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a mapreduce
1:6b390e7:    * implementation
1:dc637e8:    * 
1:590ffed:    * @param conf
1:590ffed:    *          the Configuration
1:529b114:    * @param inPath
1:529b114:    *          a Path to input VectorWritables
1:529b114:    * @param priorPath
1:529b114:    *          a Path to the prior classifier
1:529b114:    * @param outPath
1:529b114:    *          a Path of output directory
1:529b114:    * @param numIterations
1:529b114:    *          the int number of iterations to perform
1:172bb3b:    */
1:229aeff:   public static void iterateMR(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
1:229aeff:     throws IOException, InterruptedException, ClassNotFoundException {
1:3eba6f2:     ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);
1:3eba6f2:     Path clustersOut = null;
1:3eba6f2:     int iteration = 1;
1:3eba6f2:     while (iteration <= numIterations) {
1:2153bb9:       conf.set(PRIOR_PATH_KEY, priorPath.toString());
1:529b114:       
1:2153bb9:       String jobName = "Cluster Iterator running iteration " + iteration + " over priorPath: " + priorPath;
1:2153bb9:       Job job = new Job(conf, jobName);
1:dc637e8:       job.setMapOutputKeyClass(IntWritable.class);
1:2153bb9:       job.setMapOutputValueClass(ClusterWritable.class);
1:dc637e8:       job.setOutputKeyClass(IntWritable.class);
1:2153bb9:       job.setOutputValueClass(ClusterWritable.class);
1:529b114:       
1:dc637e8:       job.setInputFormatClass(SequenceFileInputFormat.class);
1:dc637e8:       job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:dc637e8:       job.setMapperClass(CIMapper.class);
1:dc637e8:       job.setReducerClass(CIReducer.class);
1:529b114:       
1:dc637e8:       FileInputFormat.addInputPath(job, inPath);
1:3eba6f2:       clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);
1:2153bb9:       priorPath = clustersOut;
1:2153bb9:       FileOutputFormat.setOutputPath(job, clustersOut);
1:529b114:       
1:dc637e8:       job.setJarByClass(ClusterIterator.class);
1:dc637e8:       if (!job.waitForCompletion(true)) {
1:2153bb9:         throw new InterruptedException("Cluster Iteration " + iteration + " failed processing " + priorPath);
1:dc637e8:       }
1:457db94:       ClusterClassifier.writePolicy(policy, clustersOut);
1:dc637e8:       FileSystem fs = FileSystem.get(outPath.toUri(), conf);
1:3eba6f2:       iteration++;
1:2153bb9:       if (isConverged(clustersOut, conf, fs)) {
1:3eba6f2:         break;
1:dc637e8:       }
1:dc637e8:     }
1:3eba6f2:     Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
1:3eba6f2:     FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);
1:4dd8881:   }
1:529b114:   
1:dc637e8:   /**
1:6b390e7:    * Return if all of the Clusters in the parts in the filePath have converged or not
1:dc637e8:    * 
1:529b114:    * @param filePath
1:529b114:    *          the file path to the single file containing the clusters
1:dc637e8:    * @return true if all Clusters are converged
1:529b114:    * @throws IOException
1:529b114:    *           if there was an IO error
1:dc637e8:    */
1:229aeff:   private static boolean isConverged(Path filePath, Configuration conf, FileSystem fs) throws IOException {
1:dc637e8:     for (FileStatus part : fs.listStatus(filePath, PathFilters.partFilter())) {
1:87c15be:       SequenceFileValueIterator<ClusterWritable> iterator = new SequenceFileValueIterator<>(
1:dc637e8:           part.getPath(), true, conf);
1:dc637e8:       while (iterator.hasNext()) {
1:2153bb9:         ClusterWritable value = iterator.next();
1:2153bb9:         if (!value.getValue().isConverged()) {
1:31cb292:           Closeables.close(iterator, true);
1:dc637e8:           return false;
1:dc637e8:         }
1:dc637e8:       }
1:dc637e8:     }
1:dc637e8:     return true;
1:dc637e8:   }
1:4dd8881: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:87c15be
/////////////////////////////////////////////////////////////////////////
1:       SequenceFileValueIterator<ClusterWritable> iterator = new SequenceFileValueIterator<>(
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:ee41571
/////////////////////////////////////////////////////////////////////////
1:  * algorithm (currently k-means and fuzzy-k-means) that processes all the input vectors in each iteration.
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
1:           Closeables.close(iterator, true);
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:dc62944
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         for (Vector.Element e : weights.nonZeroes()) {
1:           int index = e.index();
/////////////////////////////////////////////////////////////////////////
1:         for (Vector.Element e : weights.nonZeroes()) {
1:           int index = e.index();
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1: public final class ClusterIterator {
1: 
1:   private ClusterIterator() {
1:   }
1:    *
/////////////////////////////////////////////////////////////////////////
1:   public static ClusterClassifier iterate(Iterable<Vector> data, ClusterClassifier classifier, int numIterations) {
/////////////////////////////////////////////////////////////////////////
1:   public static void iterateSeq(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
1:     throws IOException {
/////////////////////////////////////////////////////////////////////////
1:   public static void iterateMR(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
1:     throws IOException, InterruptedException, ClassNotFoundException {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private static boolean isConverged(Path filePath, Configuration conf, FileSystem fs) throws IOException {
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
0:   public static void iterateMR(Path inPath, Path priorPath, Path outPath,
0:                                int numIterations) throws IOException, InterruptedException,
/////////////////////////////////////////////////////////////////////////
0:       if (isConverged(outPath, conf, fs)) {
1:         break;
1:       }
/////////////////////////////////////////////////////////////////////////
0:   private static boolean isConverged(Path filePath, Configuration conf, FileSystem fs)
commit:a6bdcbb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:    *          a {@code List<Vector>} of input vectors
0:   public ClusterClassifier iterate(Iterable<Vector> data, ClusterClassifier classifier, int numIterations) {
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it.hasNext();) {
/////////////////////////////////////////////////////////////////////////
0:   public void iterate(Path inPath, Path priorPath, Path outPath, int numIterations) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:   private static void writeClassifier(ClusterClassifier classifier, Path outPath, String k) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:   private static ClusterClassifier readClassifier(Path inPath) throws IOException {
commit:15712a6
/////////////////////////////////////////////////////////////////////////
0:   private final ClusteringPolicy policy;
/////////////////////////////////////////////////////////////////////////
0:                                    ClusterClassifier classifier,
0:                                    int numIterations) {
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it.hasNext();) {
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:590ffed
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:    * @param conf
1:    *          the Configuration
/////////////////////////////////////////////////////////////////////////
0:   public void iterateSeq(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
0:       throws IOException {
1:     classifier.readFromSeqFiles(conf, priorPath);
/////////////////////////////////////////////////////////////////////////
1:    * @param conf
1:    *          the Configuration
/////////////////////////////////////////////////////////////////////////
0:   public void iterateMR(Configuration conf, Path inPath, Path priorPath, Path outPath, int numIterations)
0:       throws IOException, InterruptedException, ClassNotFoundException {
commit:6b390e7
/////////////////////////////////////////////////////////////////////////
1:  * This is a clustering iterator which works with a set of Vector data and a prior ClusterClassifier which has been
1:  * initialized with a set of models. Its implementation is algorithm-neutral and works for any iterative clustering
0:  * algorithm (currently k-means, fuzzy-k-means and Dirichlet) that processes all the input vectors in each iteration.
1:  * The cluster classifier is configured with a ClusteringPolicy to select the desired clustering algorithm.
1:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations
/////////////////////////////////////////////////////////////////////////
1:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a sequential
1:    * implementation
/////////////////////////////////////////////////////////////////////////
1:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a mapreduce
1:    * implementation
/////////////////////////////////////////////////////////////////////////
1:    * Return if all of the Clusters in the parts in the filePath have converged or not
commit:3eba6f2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.Cluster;
/////////////////////////////////////////////////////////////////////////
0:    * @param policy
0:    *          the ClusteringPolicy to use
1:    * 
1:     ClusteringPolicy policy = classifier.getPolicy();
/////////////////////////////////////////////////////////////////////////
1:    * 
0:     HadoopUtil.delete(conf, outPath);
1:     Path clustersOut = null;
1:     int iteration = 1;
1:     while (iteration <= numIterations) {
1:         Vector weights = classifier.getPolicy().select(probabilities);
/////////////////////////////////////////////////////////////////////////
1:       classifier.getPolicy().update(classifier);
1:       clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);
1:       classifier.writeToSeqFiles(clustersOut);
1:       FileSystem fs = FileSystem.get(outPath.toUri(), conf);
1:       iteration++;
1:       if (isConverged(clustersOut, conf, fs)) {
1:         break;
1:       }
1:     Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
1:     FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);
/////////////////////////////////////////////////////////////////////////
1:     ClusteringPolicy policy = ClusterClassifier.readPolicy(priorPath);
1:     Path clustersOut = null;
1:     int iteration = 1;
1:     while (iteration <= numIterations) {
/////////////////////////////////////////////////////////////////////////
1:       clustersOut = new Path(outPath, Cluster.CLUSTERS_DIR + iteration);
/////////////////////////////////////////////////////////////////////////
1:       iteration++;
1:     Path finalClustersIn = new Path(outPath, Cluster.CLUSTERS_DIR + (iteration - 1) + Cluster.FINAL_ITERATION_SUFFIX);
1:     FileSystem.get(clustersOut.toUri(), conf).rename(clustersOut, finalClustersIn);
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.iterator;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.classify.ClusterClassifier;
commit:457db94
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       ClusterClassifier.writePolicy(policy, clustersOut);
commit:76e80dc
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     ClusterClassifier classifier = new ClusterClassifier();
0:     classifier.readFromSeqFiles(priorPath);
/////////////////////////////////////////////////////////////////////////
0:       classifier.writeToSeqFiles(new Path(outPath, "classifier-" + iteration));
/////////////////////////////////////////////////////////////////////////
0:     ClusterClassifier classifier = new ClusterClassifier(policy);
/////////////////////////////////////////////////////////////////////////
0:       classifier.writePolicy(clustersOut);
/////////////////////////////////////////////////////////////////////////
commit:1ac30a4
/////////////////////////////////////////////////////////////////////////
1:         // update the policy based upon the prior
1:         policy.update(classifier);
/////////////////////////////////////////////////////////////////////////
commit:a28cf1d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.io.Text;
/////////////////////////////////////////////////////////////////////////
0:   public static final String POLICY_PATH_KEY = "org.apache.mahout.clustering.policy.path";
/////////////////////////////////////////////////////////////////////////
0:     Path policyPath = new Path(outPath, "policy.seq");
0:     writePolicy(policy, policyPath);
0:     conf.set(POLICY_PATH_KEY, policyPath.toString());
/////////////////////////////////////////////////////////////////////////
1:   
0:   public static ClusteringPolicy readPolicy(Path policyPath) throws IOException {
0:     Configuration config = new Configuration();
0:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
0:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, policyPath, config);
0:     Text key = new Text();
0:     ClusteringPolicyWritable cpw = new ClusteringPolicyWritable();
0:     reader.next(key, cpw);
0:     return cpw.getValue();
1:   }
1:   
0:   public static void writePolicy(ClusteringPolicy policy, Path policyPath) throws IOException {
0:     Configuration config = new Configuration();
0:     FileSystem fs = FileSystem.get(policyPath.toUri(), config);
0:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, policyPath, Text.class,
0:         ClusteringPolicyWritable.class);
0:     writer.append(new Text(), new ClusteringPolicyWritable(policy));
0:     writer.close();
1:   }
commit:529b114
/////////////////////////////////////////////////////////////////////////
0:  * This is an experimental clustering iterator which works with a
0:  * ClusteringPolicy and a prior ClusterClassifier which has been initialized
0:  * with a set of models. To date, it has been tested with k-means and Dirichlet
0:  * clustering. See examples DisplayKMeans and DisplayDirichlet which have been
0:  * switched over to use it.
1:   
1:   
1:   
1:   
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations
1:    * @param data
0:    *          a {@code List<Vector>} of input vectors
1:    * @param classifier
1:    *          a prior ClusterClassifier
1:    * @param numIterations
1:    *          the int number of iterations to perform
/////////////////////////////////////////////////////////////////////////
1:   
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations using a sequential implementation
1:    * @param inPath
1:    *          a Path to input VectorWritables
1:    * @param priorPath
1:    *          a Path to the prior classifier
1:    * @param outPath
1:    *          a Path of output directory
1:    * @param numIterations
1:    *          the int number of iterations to perform
/////////////////////////////////////////////////////////////////////////
1:   
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations using a mapreduce implementation
1:    * @param inPath
1:    *          a Path to input VectorWritables
1:    * @param priorPath
1:    *          a Path to the prior classifier
1:    * @param outPath
1:    *          a Path of output directory
1:    * @param numIterations
1:    *          the int number of iterations to perform
/////////////////////////////////////////////////////////////////////////
1:       
/////////////////////////////////////////////////////////////////////////
1:       
1:       
1:       
/////////////////////////////////////////////////////////////////////////
1:   
0:    * Return if all of the Clusters in the parts in the filePath have converged
0:    * or not
1:    * @param filePath
1:    *          the file path to the single file containing the clusters
1:    * @throws IOException
1:    *           if there was an IO error
/////////////////////////////////////////////////////////////////////////
0:   
/////////////////////////////////////////////////////////////////////////
0:   
commit:2153bb9
/////////////////////////////////////////////////////////////////////////
0: import java.util.List;
0: import java.util.Locale;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Lists;
0:  * This is an experimental clustering iterator which works with a ClusteringPolicy and a prior ClusterClassifier which
0:  * has been initialized with a set of models. To date, it has been tested with k-means and Dirichlet clustering. See
0:  * examples DisplayKMeans and DisplayDirichlet which have been switched over to use it.
0: 
1:   public static final String PRIOR_PATH_KEY = "org.apache.mahout.clustering.prior.path";
0: 
0: 
0: 
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations
0:    * @param data a {@code List<Vector>} of input vectors
0:    * @param classifier a prior ClusterClassifier
0:    * @param numIterations the int number of iterations to perform
0:   public ClusterClassifier iterate(Iterable<Vector> data, ClusterClassifier classifier, int numIterations) {
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it.hasNext();) {
/////////////////////////////////////////////////////////////////////////
0: 
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a sequential
0:    * implementation
0:    * @param inPath a Path to input VectorWritables
0:    * @param priorPath a Path to the prior classifier
0:    * @param outPath a Path of output directory
0:    * @param numIterations the int number of iterations to perform
0:   public void iterateSeq(Path inPath, Path priorPath, Path outPath, int numIterations) throws IOException {
1:       for (VectorWritable vw : new SequenceFileDirValueIterable<VectorWritable>(inPath, PathType.LIST,
1:           PathFilters.logsCRCFilter(), conf)) {
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it.hasNext();) {
/////////////////////////////////////////////////////////////////////////
0:       writeClassifier(classifier, new Path(outPath, "classifier-" + iteration));
0: 
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of iterations using a mapreduce
0:    * implementation
0:    * @param inPath a Path to input VectorWritables
0:    * @param priorPath a Path to the prior classifier
0:    * @param outPath a Path of output directory
0:    * @param numIterations the int number of iterations to perform
0:   public void iterateMR(Path inPath, Path priorPath, Path outPath, int numIterations) throws IOException,
0:       InterruptedException, ClassNotFoundException {
0:     HadoopUtil.delete(conf, outPath);
1:       conf.set(PRIOR_PATH_KEY, priorPath.toString());
0: 
1:       String jobName = "Cluster Iterator running iteration " + iteration + " over priorPath: " + priorPath;
0:       System.out.println(jobName);
1:       Job job = new Job(conf, jobName);
1:       job.setMapOutputValueClass(ClusterWritable.class);
1:       job.setOutputValueClass(ClusterWritable.class);
0: 
0: 
0:       Path clustersOut = new Path(outPath, "clusters-" + iteration);
1:       priorPath = clustersOut;
1:       FileOutputFormat.setOutputPath(job, clustersOut);
0: 
1:         throw new InterruptedException("Cluster Iteration " + iteration + " failed processing " + priorPath);
1:       if (isConverged(clustersOut, conf, fs)) {
0: 
0:    * Return if all of the Clusters in the parts in the filePath have converged or not
0:    * @param filePath the file path to the single file containing the clusters
0:    * @throws IOException if there was an IO error
0:   private boolean isConverged(Path filePath, Configuration conf, FileSystem fs) throws IOException {
0:       SequenceFileValueIterator<ClusterWritable> iterator = new SequenceFileValueIterator<ClusterWritable>(
1:         ClusterWritable value = iterator.next();
1:         if (!value.getValue().isConverged()) {
/////////////////////////////////////////////////////////////////////////
0: 
0:   public static void writeClassifier(ClusterClassifier classifier, Path outPath) throws IOException {
0:     SequenceFile.Writer writer = null;
0:     ClusterWritable cw = new ClusterWritable();
0:     for (int i = 0; i < classifier.getModels().size(); i++) {
0:       try {
0:         Cluster cluster = classifier.getModels().get(i);
0:         cw.setValue(cluster);
0:         writer = new SequenceFile.Writer(fs, config, new Path(outPath, "part-"
0:             + String.format(Locale.ENGLISH, "%05d", i)), IntWritable.class, ClusterWritable.class);
0:         Writable key = new IntWritable(i);
0:         writer.append(key, cw);
0:       } finally {
0:         Closeables.closeQuietly(writer);
1:       }
0: 
0:   public static ClusterClassifier readClassifier(Path inPath) throws IOException {
0:     List<Cluster> clusters = Lists.newArrayList();
0:     for (ClusterWritable cw : new SequenceFileDirValueIterable<ClusterWritable>(inPath, PathType.LIST,
0:         PathFilters.logsCRCFilter(), config)) {
0:       clusters.add(cw.getValue());
0:     ClusterClassifier classifierOut = new ClusterClassifier(clusters);
commit:dc637e8
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
0: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
1: import com.google.common.io.Closeables;
0: 
/////////////////////////////////////////////////////////////////////////
0:   public ClusterClassifier iterate(Iterable<Vector> data,
0:       ClusterClassifier classifier, int numIterations) {
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it
0:             .hasNext();) {
/////////////////////////////////////////////////////////////////////////
0:    * iterations using a sequential implementation
/////////////////////////////////////////////////////////////////////////
0:   public void iterateSeq(Path inPath, Path priorPath, Path outPath,
0:       int numIterations) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:   /**
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations using a mapreduce implementation
1:    * 
0:    * @param inPath
0:    *          a Path to input VectorWritables
0:    * @param priorPath
0:    *          a Path to the prior classifier
0:    * @param outPath
0:    *          a Path of output directory
0:    * @param numIterations
0:    *          the int number of iterations to perform
0:    * @throws IOException
0:    * @throws ClassNotFoundException
0:    * @throws InterruptedException
1:    */
0:   public void iterateMR(Path inPath, Path priorPath, Path outPath,
0:       int numIterations) throws IOException, InterruptedException,
0:       ClassNotFoundException {
0:     Configuration conf = new Configuration();
1:     for (int iteration = 1; iteration <= numIterations; iteration++) {
0:       conf.set("org.apache.mahout.clustering.prior.path", priorPath.toString());
0:       
0:       Job job = new Job(conf, "Cluster Iterator running iteration " + iteration
0:           + " over priorPath: " + priorPath);
1:       job.setMapOutputKeyClass(IntWritable.class);
0:       job.setMapOutputValueClass(Cluster.class);
1:       job.setOutputKeyClass(IntWritable.class);
0:       job.setOutputValueClass(Cluster.class);
0:       
1:       job.setInputFormatClass(SequenceFileInputFormat.class);
1:       job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:       job.setMapperClass(CIMapper.class);
1:       job.setReducerClass(CIReducer.class);
0:       
1:       FileInputFormat.addInputPath(job, inPath);
0:       FileOutputFormat.setOutputPath(job, outPath);
0:       
1:       job.setJarByClass(ClusterIterator.class);
0:       HadoopUtil.delete(conf, outPath);
1:       if (!job.waitForCompletion(true)) {
0:         throw new InterruptedException("Cluster Iteration " + iteration
0:             + " failed processing " + priorPath);
1:       }
1:       FileSystem fs = FileSystem.get(outPath.toUri(), conf);
0:       if (isConverged(outPath, conf, fs)) break;
1:     }
1:   }
0:   
1:   /**
0:    * Return if all of the Clusters in the parts in the filePath have converged
0:    * or not
1:    * 
0:    * @param filePath
0:    *          the file path to the single file containing the clusters
1:    * @return true if all Clusters are converged
0:    * @throws IOException
0:    *           if there was an IO error
1:    */
0:   private boolean isConverged(Path filePath, Configuration conf, FileSystem fs)
0:       throws IOException {
1:     for (FileStatus part : fs.listStatus(filePath, PathFilters.partFilter())) {
0:       SequenceFileValueIterator<Cluster> iterator = new SequenceFileValueIterator<Cluster>(
1:           part.getPath(), true, conf);
1:       while (iterator.hasNext()) {
0:         Cluster value = iterator.next();
0:         if (!value.isConverged()) {
0:           Closeables.closeQuietly(iterator);
1:           return false;
1:         }
1:       }
1:     }
1:     return true;
1:   }
0:   
0:   public static void writeClassifier(ClusterClassifier classifier,
0:       Path outPath, String k) throws IOException {
0:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, outPath,
0:         Text.class, ClusterClassifier.class);
/////////////////////////////////////////////////////////////////////////
0:   public static ClusterClassifier readClassifier(Path inPath)
0:       throws IOException {
commit:4dd8881
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.io.SequenceFile;
0: import org.apache.hadoop.io.Text;
0: import org.apache.hadoop.io.Writable;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirValueIterable;
1: import org.apache.mahout.math.VectorWritable;
/////////////////////////////////////////////////////////////////////////
0:       ClusterClassifier classifier, int numIterations) {
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it
0:             .hasNext();) {
/////////////////////////////////////////////////////////////////////////
0:   
1:   /**
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations
1:    * 
0:    * @param inPath
0:    *          a Path to input VectorWritables
0:    * @param priorPath
0:    *          a Path to the prior classifier
0:    * @param outPath
0:    *          a Path of output directory
0:    * @param numIterations
0:    *          the int number of iterations to perform
0:    * @throws IOException
1:    */
0:   public void iterate(Path inPath, Path priorPath, Path outPath,
0:       int numIterations) throws IOException {
0:     ClusterClassifier classifier = readClassifier(priorPath);
0:     Configuration conf = new Configuration();
0:     for (int iteration = 1; iteration <= numIterations; iteration++) {
0:       for (VectorWritable vw : new SequenceFileDirValueIterable<VectorWritable>(
0:           inPath, PathType.LIST, PathFilters.logsCRCFilter(), conf)) {
1:         Vector vector = vw.get();
1:         // classification yields probabilities
1:         Vector probabilities = classifier.classify(vector);
1:         // policy selects weights for models given those probabilities
1:         Vector weights = policy.select(probabilities);
1:         // training causes all models to observe data
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it
0:             .hasNext();) {
0:           int index = it.next().index();
1:           classifier.train(index, vector, weights.get(index));
1:         }
1:       }
1:       // compute the posterior models
1:       classifier.close();
1:       // update the policy
0:       policy.update(classifier);
1:       // output the classifier
0:       writeClassifier(classifier, new Path(outPath, "classifier-" + iteration),
0:           String.valueOf(iteration));
1:     }
1:   }
0:   
0:   private void writeClassifier(ClusterClassifier classifier, Path outPath, String k)
0:       throws IOException {
0:     Configuration config = new Configuration();
0:     FileSystem fs = FileSystem.get(outPath.toUri(), config);
0:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, outPath,
0:         Text.class, ClusterClassifier.class);
0:     Writable key = new Text(k);
0:     writer.append(key, classifier);
0:     writer.close();
1:   }
0:   
0:   private ClusterClassifier readClassifier(Path inPath) throws IOException {
0:     Configuration config = new Configuration();
0:     FileSystem fs = FileSystem.get(inPath.toUri(), config);
0:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, inPath, config);
0:     Writable key = new Text();
0:     ClusterClassifier classifierOut = new ClusterClassifier();
0:     reader.next(key, classifierOut);
0:     reader.close();
0:     return classifierOut;
1:   }
commit:933e22a
/////////////////////////////////////////////////////////////////////////
0: import java.util.Iterator;
/////////////////////////////////////////////////////////////////////////
0:    * @param classifier
0:    *          a prior ClusterClassifier
0:   public ClusterClassifier iterate(List<Vector> data,
0:       ClusterClassifier classifier, int numIterations) {
1:         Vector probabilities = classifier.classify(vector);
1:         // policy selects weights for models given those probabilities
0:         Vector weights = policy.select(probabilities);
0:         for (Iterator<Vector.Element> it = weights.iterateNonZero(); it
0:             .hasNext();) {
0:           int index = it.next().index();
1:           classifier.train(index, vector, weights.get(index));
0:         }
1:       classifier.close();
0:       policy.update(classifier);
1:     return classifier;
commit:172bb3b
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: package org.apache.mahout.clustering;
0: 
0: import java.util.List;
0: 
1: import org.apache.mahout.math.Vector;
0: 
1: /**
0:  * This is an experimental clustering iterator which works with a
0:  * ClusteringPolicy and a prior ClusterClassifier which has been initialized
0:  * with a set of models. To date, it has been tested with k-means and Dirichlet
0:  * clustering. See examples DisplayKMeans and DisplayDirichlet which have been
0:  * switched over to use it.
1:  * 
1:  */
0: public class ClusterIterator {
0:   
0:   public ClusterIterator(ClusteringPolicy policy) {
0:     super();
0:     this.policy = policy;
0:   }
0:   
0:   private ClusteringPolicy policy;
0:   
1:   /**
0:    * Iterate over data using a prior-trained ClusterClassifier, for a number of
0:    * iterations
1:    * 
0:    * @param data
0:    *          a List<Vector> of input vectors
0:    * @param prior
0:    *          the prior-trained ClusterClassifier
0:    * @param numIterations
0:    *          the int number of iterations to perform
1:    * @return the posterior ClusterClassifier
1:    */
0:   public ClusterClassifier iterate(List<Vector> data, ClusterClassifier prior,
0:       int numIterations) {
0:     for (int iteration = 1; iteration <= numIterations; iteration++) {
1:       for (Vector vector : data) {
1:         // classification yields probabilities
0:         Vector pdfs = prior.classify(vector);
0:         // policy selects a model given those probabilities
0:         int selected = policy.select(pdfs);
1:         // training causes all models to observe data
0:         prior.train(selected, vector);
0:       }
1:       // compute the posterior models
0:       prior.close();
0:       // update the policy
0:       policy.update(prior);
0:     }
0:     return prior;
0:   }
0: }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:d608a88
/////////////////////////////////////////////////////////////////////////
0:       Closeables.closeQuietly(writer);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.closeQuietly(reader);
commit:96024a7
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
0:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, config, outPath, Text.class, ClusterClassifier.class);
0:     try {
0:       Writable key = new Text(k);
0:       writer.append(key, classifier);
0:     } finally {
0:       Closeables.close(writer, false);
0:     }
/////////////////////////////////////////////////////////////////////////
0:     try {
0:       reader.next(key, classifierOut);
0:     } finally {
0:       Closeables.close(reader, false);
0:     }
============================================================================
2:10740e3: /**
1:10740e3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:10740e3:  * contributor license agreements.  See the NOTICE file distributed with
1:10740e3:  * this work for additional information regarding copyright ownership.
1:10740e3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:10740e3:  * (the "License"); you may not use this file except in compliance with
1:10740e3:  * the License.  You may obtain a copy of the License at
1:10740e3:  *
1:10740e3:  *     http://www.apache.org/licenses/LICENSE-2.0
1:10740e3:  *
1:10740e3:  * Unless required by applicable law or agreed to in writing, software
1:10740e3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:10740e3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:10740e3:  * See the License for the specific language governing permissions and
1:10740e3:  * limitations under the License.
2:10740e3:  */
5:10740e3: 
1:10740e3: package org.apache.mahout.utils.vectors.lucene;
1:10740e3: 
1:10740e3: import com.google.common.collect.AbstractIterator;
1:10740e3: import org.apache.lucene.index.IndexReader;
1:10740e3: import org.apache.lucene.index.Terms;
1:10740e3: import org.apache.lucene.index.TermsEnum;
1:10740e3: import org.apache.lucene.util.BytesRef;
1:10740e3: import org.apache.mahout.math.NamedVector;
1:10740e3: import org.apache.mahout.math.Vector;
1:10740e3: import org.apache.mahout.utils.Bump125;
1:10740e3: import org.apache.mahout.utils.vectors.TermInfo;
1:10740e3: import org.apache.mahout.vectorizer.Weight;
1:10740e3: import org.slf4j.Logger;
1:10740e3: import org.slf4j.LoggerFactory;
1:10740e3: 
1:10740e3: import java.io.IOException;
1:10740e3: 
1:10740e3: /**
1:10740e3:  * Iterate over a Lucene index, extracting term vectors.
1:10740e3:  * Subclasses define how much information to retrieve from the Lucene index.
1:10740e3:  */
1:10740e3: public abstract class AbstractLuceneIterator extends AbstractIterator<Vector> {
1:6d16230:   private static final Logger log = LoggerFactory.getLogger(LuceneIterator.class);
1:6d16230:   protected final IndexReader indexReader;
1:6d16230:   protected final String field;
1:6d16230:   protected final TermInfo terminfo;
1:6d16230:   protected final double normPower;
1:6d16230:   protected final Weight weight;
1:6d16230:   protected final Bump125 bump = new Bump125();
1:6d16230:   protected int nextDocId;
1:6d16230:   protected int maxErrorDocs;
1:6d16230:   protected int numErrorDocs;
1:6d16230:   protected long nextLogRecord = bump.increment();
1:6d16230:   protected int skippedErrorMessages;
1:10740e3: 
1:6d16230:   public AbstractLuceneIterator(TermInfo terminfo, double normPower, IndexReader indexReader, Weight weight,
1:6d16230:       double maxPercentErrorDocs, String field) {
1:6d16230:     this.terminfo = terminfo;
1:6d16230:     this.normPower = normPower;
1:6d16230:     this.indexReader = indexReader;
1:10740e3: 
1:6d16230:     this.weight = weight;
1:6d16230:     this.nextDocId = 0;
1:6d16230:     this.maxErrorDocs = (int) (maxPercentErrorDocs * indexReader.numDocs());
1:6d16230:     this.field = field;
1:6d16230:   }
1:10740e3: 
1:6d16230:   /**
1:6d16230:    * Given the document name, derive a name for the vector. This may involve
1:6d16230:    * reading the document from Lucene and setting up any other state that the
1:6d16230:    * subclass wants. This will be called once for each document that the
1:6d16230:    * iterator processes.
1:6d16230:    * @param documentIndex the lucene document index.
1:6d16230:    * @return the name to store in the vector.
1:6d16230:    */
1:6d16230:   protected abstract String getVectorName(int documentIndex) throws IOException;
1:10740e3: 
1:6d16230:   @Override
1:6d16230:   protected Vector computeNext() {
1:6d16230:     try {
1:6d16230:       int doc;
1:6d16230:       Terms termFreqVector;
1:6d16230:       String name;
1:10740e3: 
1:6d16230:       do {
1:6d16230:         doc = this.nextDocId;
1:6d16230:         nextDocId++;
1:10740e3: 
1:6d16230:         if (doc >= indexReader.maxDoc()) {
1:6d16230:           return endOfData();
1:6d16230:         }
1:6d16230: 
1:6d16230:         termFreqVector = indexReader.getTermVector(doc, field);
1:6d16230:         name = getVectorName(doc);
1:6d16230: 
1:6d16230:         if (termFreqVector == null) {
1:6d16230:           numErrorDocs++;
1:6d16230:           if (numErrorDocs >= maxErrorDocs) {
1:6d16230:             log.error("There are too many documents that do not have a term vector for {}", field);
1:6d16230:             throw new IllegalStateException("There are too many documents that do not have a term vector for "
1:6d16230:                 + field);
6:10740e3:           }
1:6d16230:           if (numErrorDocs >= nextLogRecord) {
1:6d16230:             if (skippedErrorMessages == 0) {
1:6d16230:               log.warn("{} does not have a term vector for {}", name, field);
3:10740e3:             } else {
1:6d16230:               log.warn("{} documents do not have a term vector for {}", numErrorDocs, field);
1:10740e3:             }
1:6d16230:             nextLogRecord = bump.increment();
1:6d16230:             skippedErrorMessages = 0;
1:6d16230:           } else {
1:6d16230:             skippedErrorMessages++;
1:10740e3:           }
1:10740e3:         }
1:6d16230:       } while (termFreqVector == null);
1:10740e3: 
1:6d16230:       // The loop exits with termFreqVector and name set.
1:6d16230: 
1:4d0cd66:       TermsEnum te = termFreqVector.iterator();
1:6d16230:       BytesRef term;
1:6d16230:       TFDFMapper mapper = new TFDFMapper(indexReader.numDocs(), weight, this.terminfo);
1:6d16230:       mapper.setExpectations(field, termFreqVector.size());
1:6d16230:       while ((term = te.next()) != null) {
1:6d16230:         mapper.map(term, (int) te.totalTermFreq());
1:10740e3:       }
1:6d16230:       Vector result = mapper.getVector();
1:6d16230:       if (result == null) {
1:6d16230:         // TODO is this right? last version would produce null in the iteration in this case, though it
1:6d16230:         // seems like that may not be desirable
1:6d16230:         return null;
1:6d16230:       }
1:6d16230: 
1:6d16230:       if (normPower == LuceneIterable.NO_NORMALIZING) {
1:6d16230:         result = new NamedVector(result, name);
1:6d16230:       } else {
1:6d16230:         result = new NamedVector(result.normalize(normPower), name);
1:6d16230:       }
1:6d16230:       return result;
1:6d16230:     } catch (IOException ioe) {
1:6d16230:       throw new IllegalStateException(ioe);
1:6d16230:     }
1:10740e3:   }
1:10740e3: }
============================================================================
author:smarthi
-------------------------------------------------------------------------------
commit:4d0cd66
/////////////////////////////////////////////////////////////////////////
1:       TermsEnum te = termFreqVector.iterator();
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:   private static final Logger log = LoggerFactory.getLogger(LuceneIterator.class);
1:   protected final IndexReader indexReader;
1:   protected final String field;
1:   protected final TermInfo terminfo;
1:   protected final double normPower;
1:   protected final Weight weight;
1:   protected final Bump125 bump = new Bump125();
1:   protected int nextDocId;
1:   protected int maxErrorDocs;
1:   protected int numErrorDocs;
1:   protected long nextLogRecord = bump.increment();
1:   protected int skippedErrorMessages;
1:   public AbstractLuceneIterator(TermInfo terminfo, double normPower, IndexReader indexReader, Weight weight,
1:       double maxPercentErrorDocs, String field) {
1:     this.terminfo = terminfo;
1:     this.normPower = normPower;
1:     this.indexReader = indexReader;
1:     this.weight = weight;
1:     this.nextDocId = 0;
1:     this.maxErrorDocs = (int) (maxPercentErrorDocs * indexReader.numDocs());
1:     this.field = field;
1:   }
1:   /**
1:    * Given the document name, derive a name for the vector. This may involve
1:    * reading the document from Lucene and setting up any other state that the
1:    * subclass wants. This will be called once for each document that the
1:    * iterator processes.
1:    * @param documentIndex the lucene document index.
1:    * @return the name to store in the vector.
1:    */
1:   protected abstract String getVectorName(int documentIndex) throws IOException;
1:   @Override
1:   protected Vector computeNext() {
1:     try {
1:       int doc;
1:       Terms termFreqVector;
1:       String name;
1:       do {
1:         doc = this.nextDocId;
1:         nextDocId++;
1:         if (doc >= indexReader.maxDoc()) {
1:           return endOfData();
1:         }
1: 
1:         termFreqVector = indexReader.getTermVector(doc, field);
1:         name = getVectorName(doc);
1: 
1:         if (termFreqVector == null) {
1:           numErrorDocs++;
1:           if (numErrorDocs >= maxErrorDocs) {
1:             log.error("There are too many documents that do not have a term vector for {}", field);
1:             throw new IllegalStateException("There are too many documents that do not have a term vector for "
1:                 + field);
1:           if (numErrorDocs >= nextLogRecord) {
1:             if (skippedErrorMessages == 0) {
1:               log.warn("{} does not have a term vector for {}", name, field);
1:               log.warn("{} documents do not have a term vector for {}", numErrorDocs, field);
1:             nextLogRecord = bump.increment();
1:             skippedErrorMessages = 0;
1:           } else {
1:             skippedErrorMessages++;
1:       } while (termFreqVector == null);
1:       // The loop exits with termFreqVector and name set.
1: 
0:       TermsEnum te = termFreqVector.iterator(null);
1:       BytesRef term;
1:       TFDFMapper mapper = new TFDFMapper(indexReader.numDocs(), weight, this.terminfo);
1:       mapper.setExpectations(field, termFreqVector.size());
1:       while ((term = te.next()) != null) {
1:         mapper.map(term, (int) te.totalTermFreq());
1:       Vector result = mapper.getVector();
1:       if (result == null) {
1:         // TODO is this right? last version would produce null in the iteration in this case, though it
1:         // seems like that may not be desirable
1:         return null;
1:       }
1: 
1:       if (normPower == LuceneIterable.NO_NORMALIZING) {
1:         result = new NamedVector(result, name);
1:       } else {
1:         result = new NamedVector(result.normalize(normPower), name);
1:       }
1:       return result;
1:     } catch (IOException ioe) {
1:       throw new IllegalStateException(ioe);
1:   }
commit:3c22856
/////////////////////////////////////////////////////////////////////////
0:     public AbstractLuceneIterator(TermInfo terminfo, double normPower, IndexReader indexReader, Weight weight,
0:         double maxPercentErrorDocs, String field) {
0:       this.terminfo = terminfo;
0:       this.normPower = normPower;
0:       this.indexReader = indexReader;
0:       this.weight = weight;
0:       this.nextDocId = 0;
0:       this.maxErrorDocs = (int) (maxPercentErrorDocs * indexReader.numDocs());
0:       this.field = field;
/////////////////////////////////////////////////////////////////////////
0:               throw new IllegalStateException("There are too many documents that do not have a term vector for " +
0:                   field);
author:Ted Dunning
-------------------------------------------------------------------------------
commit:402e296
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
author:Benson Margulies
-------------------------------------------------------------------------------
commit:10740e3
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.utils.vectors.lucene;
1: 
1: import com.google.common.collect.AbstractIterator;
0: import org.apache.lucene.document.Document;
1: import org.apache.lucene.index.IndexReader;
1: import org.apache.lucene.index.Terms;
1: import org.apache.lucene.index.TermsEnum;
1: import org.apache.lucene.util.BytesRef;
1: import org.apache.mahout.math.NamedVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.utils.Bump125;
1: import org.apache.mahout.utils.vectors.TermInfo;
1: import org.apache.mahout.vectorizer.Weight;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: import java.io.IOException;
0: import java.util.Set;
0: import java.util.TreeSet;
1: 
1: /**
1:  * Iterate over a Lucene index, extracting term vectors.
1:  * Subclasses define how much information to retrieve from the Lucene index.
1:  */
1: public abstract class AbstractLuceneIterator extends AbstractIterator<Vector> {
0:     private static final Logger log = LoggerFactory.getLogger(LuceneIterator.class);
0:     protected final IndexReader indexReader;
0:     protected final String field;
0:     protected final TermInfo terminfo;
0:     protected final double normPower;
0:     protected final Weight weight;
0:     protected final Bump125 bump = new Bump125();
0:     protected int nextDocId;
0:     protected int maxErrorDocs;
0:     protected int numErrorDocs;
0:     protected long nextLogRecord = bump.increment();
0:     protected int skippedErrorMessages;
1: 
0:     public AbstractLuceneIterator(TermInfo terminfo, double normPower, IndexReader indexReader, Weight weight, double maxPercentErrorDocs, String field) {
0:         this.terminfo = terminfo;
0:         this.normPower = normPower;
0:         this.indexReader = indexReader;
1: 
0:         this.weight = weight;
0:         this.nextDocId = 0;
0:         this.maxErrorDocs = (int) (maxPercentErrorDocs * indexReader.numDocs());
0:         this.field = field;
1:     }
1: 
1:     /**
0:      * Given the document name, derive a name for the vector. This may involve
0:      * reading the document from Lucene and setting up any other state that the
0:      * subclass wants. This will be called once for each document that the
0:      * iterator processes.
0:      * @param documentIndex the lucene document index.
0:      * @return the name to store in the vector.
1:      */
0:     protected abstract String getVectorName(int documentIndex) throws IOException;
1: 
0:     @Override
0:     protected Vector computeNext() {
0:       try {
0:         int doc;
0:         Terms termFreqVector;
0:         String name;
1: 
0:         do {
0:           name = null;
0:           doc = this.nextDocId;
0:           nextDocId++;
1: 
0:           if (doc >= indexReader.maxDoc()) {
0:             return endOfData();
1:           }
1: 
0:           termFreqVector = indexReader.getTermVector(doc, field);
0:           name = getVectorName(doc);
1: 
0:           if (termFreqVector == null) {
0:             numErrorDocs++;
0:             if (numErrorDocs >= maxErrorDocs) {
0:               log.error("There are too many documents that do not have a term vector for {}", field);
0:               throw new IllegalStateException("There are too many documents that do not have a term vector for " + field);
1:             }
0:             if (numErrorDocs >= nextLogRecord) {
0:               if (skippedErrorMessages == 0) {
0:                 log.warn("{} does not have a term vector for {}", name, field);
1:               } else {
0:                 log.warn("{} documents do not have a term vector for {}", numErrorDocs, field);
1:               }
0:               nextLogRecord = bump.increment();
0:               skippedErrorMessages = 0;
1:             } else {
0:               skippedErrorMessages++;
1:             }
1:           }
0:         } while (termFreqVector == null);
1: 
0:         // The loop exits with termFreqVector and name set.
1: 
0:         TermsEnum te = termFreqVector.iterator(null);
0:         BytesRef term;
0:         TFDFMapper mapper = new TFDFMapper(indexReader.numDocs(), weight, this.terminfo);
0:         mapper.setExpectations(field, termFreqVector.size());
0:         while ((term = te.next()) != null) {
0:           mapper.map(term, (int) te.totalTermFreq());
1:         }
0:         Vector result = mapper.getVector();
0:         if (result == null) {
0:           // TODO is this right? last version would produce null in the iteration in this case, though it
0:           // seems like that may not be desirable
0:           return null;
1:         }
1: 
0:         if (normPower == LuceneIterable.NO_NORMALIZING) {
0:           result = new NamedVector(result, name);
1:         } else {
0:           result = new NamedVector(result.normalize(normPower), name);
1:         }
0:         return result;
0:       } catch (IOException ioe) {
0:         throw new IllegalStateException(ioe);
1:       }
1:     }
1: }
============================================================================
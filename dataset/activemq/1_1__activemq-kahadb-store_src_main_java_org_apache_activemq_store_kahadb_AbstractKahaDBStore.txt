1:74846bb: /**
1:74846bb:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:74846bb:  * contributor license agreements.  See the NOTICE file distributed with
1:74846bb:  * this work for additional information regarding copyright ownership.
1:74846bb:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:74846bb:  * (the "License"); you may not use this file except in compliance with
1:74846bb:  * the License.  You may obtain a copy of the License at
1:74846bb:  *
1:74846bb:  *      http://www.apache.org/licenses/LICENSE-2.0
1:74846bb:  *
1:74846bb:  * Unless required by applicable law or agreed to in writing, software
1:74846bb:  * distributed under the License is distributed on an "AS IS" BASIS,
1:74846bb:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:74846bb:  * See the License for the specific language governing permissions and
1:74846bb:  * limitations under the License.
1:74846bb:  */
1:74846bb: 
1:74846bb: package org.apache.activemq.store.kahadb;
1:74846bb: 
1:74846bb: import java.io.File;
1:74846bb: import java.io.IOException;
1:74846bb: import java.util.Date;
1:74846bb: import java.util.concurrent.atomic.AtomicBoolean;
1:74846bb: import java.util.concurrent.atomic.AtomicLong;
1:74846bb: import java.util.concurrent.locks.ReentrantReadWriteLock;
1:74846bb: 
1:74846bb: import org.apache.activemq.broker.LockableServiceSupport;
1:74846bb: import org.apache.activemq.broker.Locker;
1:74846bb: import org.apache.activemq.store.SharedFileLocker;
1:74846bb: import org.apache.activemq.store.kahadb.data.KahaEntryType;
1:74846bb: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
1:74846bb: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1:74846bb: import org.apache.activemq.store.kahadb.disk.journal.Location;
1:74846bb: import org.apache.activemq.store.kahadb.disk.page.PageFile;
1:74846bb: import org.apache.activemq.store.kahadb.disk.page.Transaction;
1:74846bb: import org.apache.activemq.util.ByteSequence;
1:74846bb: import org.apache.activemq.util.DataByteArrayInputStream;
1:74846bb: import org.apache.activemq.util.DataByteArrayOutputStream;
1:74846bb: import org.apache.activemq.util.IOHelper;
1:74846bb: import org.apache.activemq.util.ServiceStopper;
1:74846bb: import org.slf4j.Logger;
1:74846bb: import org.slf4j.LoggerFactory;
1:74846bb: 
1:74846bb: public abstract class AbstractKahaDBStore extends LockableServiceSupport {
1:74846bb: 
1:74846bb:     static final Logger LOG = LoggerFactory.getLogger(AbstractKahaDBStore.class);
1:74846bb: 
1:74846bb:     public static final String PROPERTY_LOG_SLOW_ACCESS_TIME = "org.apache.activemq.store.kahadb.LOG_SLOW_ACCESS_TIME";
1:74846bb:     public static final int LOG_SLOW_ACCESS_TIME = Integer.getInteger(PROPERTY_LOG_SLOW_ACCESS_TIME, 0);
1:74846bb: 
1:74846bb:     protected File directory;
1:74846bb:     protected PageFile pageFile;
1:74846bb:     protected Journal journal;
1:74846bb:     protected AtomicLong journalSize = new AtomicLong(0);
1:74846bb:     protected boolean failIfDatabaseIsLocked;
1:74846bb:     protected long checkpointInterval = 5*1000;
1:74846bb:     protected long cleanupInterval = 30*1000;
1:74846bb:     protected boolean checkForCorruptJournalFiles = false;
1:74846bb:     protected boolean checksumJournalFiles = true;
1:74846bb:     protected boolean forceRecoverIndex = false;
1:74846bb:     protected int journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
1:74846bb:     protected int journalMaxWriteBatchSize = Journal.DEFAULT_MAX_WRITE_BATCH_SIZE;
1:74846bb:     protected boolean archiveCorruptedIndex = false;
1:74846bb:     protected boolean enableIndexWriteAsync = false;
1:74846bb:     protected boolean enableJournalDiskSyncs = false;
1:74846bb:     protected boolean deleteAllJobs = false;
1:74846bb:     protected int indexWriteBatchSize = PageFile.DEFAULT_WRITE_BATCH_SIZE;
1:74846bb:     protected boolean useIndexLFRUEviction = false;
1:74846bb:     protected float indexLFUEvictionFactor = 0.2f;
1:74846bb:     protected boolean ignoreMissingJournalfiles = false;
1:74846bb:     protected int indexCacheSize = 1000;
1:74846bb:     protected boolean enableIndexDiskSyncs = true;
1:74846bb:     protected boolean enableIndexRecoveryFile = true;
1:74846bb:     protected boolean enableIndexPageCaching = true;
1:74846bb:     protected boolean archiveDataLogs;
1:74846bb:     protected boolean purgeStoreOnStartup;
1:74846bb:     protected File directoryArchive;
1:74846bb: 
1:74846bb:     protected AtomicBoolean opened = new AtomicBoolean();
1:74846bb:     protected Thread checkpointThread;
1:74846bb:     protected final Object checkpointThreadLock = new Object();
1:74846bb:     protected ReentrantReadWriteLock checkpointLock = new ReentrantReadWriteLock();
1:74846bb:     protected ReentrantReadWriteLock indexLock = new ReentrantReadWriteLock();
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @return the name to give this store's PageFile instance.
1:74846bb:      */
1:74846bb:     protected abstract String getPageFileName();
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @return the location of the data directory if no set by configuration.
1:74846bb:      */
1:74846bb:     protected abstract File getDefaultDataDirectory();
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Loads the store from disk.
1:74846bb:      *
1:74846bb:      * Based on configuration this method can either load an existing store or it can purge
1:74846bb:      * an existing store and start in a clean state.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs during the load.
1:74846bb:      */
1:74846bb:     public abstract void load() throws IOException;
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Unload the state of the Store to disk and shuts down all resources assigned to this
1:74846bb:      * KahaDB store implementation.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs during the store unload.
1:74846bb:      */
1:74846bb:     public abstract void unload() throws IOException;
1:74846bb: 
1:74846bb:     @Override
1:74846bb:     protected void doStart() throws Exception {
1:74846bb:         this.indexLock.writeLock().lock();
1:74846bb:         if (getDirectory() == null) {
1:74846bb:             setDirectory(getDefaultDataDirectory());
1:74846bb:         }
1:74846bb:         IOHelper.mkdirs(getDirectory());
1:74846bb:         try {
1:74846bb:             if (isPurgeStoreOnStartup()) {
1:74846bb:                 getJournal().start();
1:74846bb:                 getJournal().delete();
1:74846bb:                 getJournal().close();
1:74846bb:                 journal = null;
1:74846bb:                 getPageFile().delete();
1:74846bb:                 LOG.info("{} Persistence store purged.", this);
1:74846bb:                 setPurgeStoreOnStartup(false);
1:74846bb:             }
1:74846bb: 
1:74846bb:             load();
1:74846bb:             store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
1:74846bb:         } finally {
1:74846bb:             this.indexLock.writeLock().unlock();
1:74846bb:         }
1:74846bb:     }
1:74846bb: 
1:74846bb:     @Override
1:74846bb:     protected void doStop(ServiceStopper stopper) throws Exception {
1:74846bb:         unload();
1:74846bb:     }
1:74846bb: 
1:74846bb:     public PageFile getPageFile() {
1:74846bb:         if (pageFile == null) {
1:74846bb:             pageFile = createPageFile();
1:74846bb:         }
1:74846bb:         return pageFile;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public Journal getJournal() throws IOException {
1:74846bb:         if (journal == null) {
1:74846bb:             journal = createJournal();
1:74846bb:         }
1:74846bb:         return journal;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public File getDirectory() {
1:74846bb:         return directory;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setDirectory(File directory) {
1:74846bb:         this.directory = directory;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isArchiveCorruptedIndex() {
1:74846bb:         return archiveCorruptedIndex;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setArchiveCorruptedIndex(boolean archiveCorruptedIndex) {
1:74846bb:         this.archiveCorruptedIndex = archiveCorruptedIndex;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isFailIfDatabaseIsLocked() {
1:74846bb:         return failIfDatabaseIsLocked;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setFailIfDatabaseIsLocked(boolean failIfDatabaseIsLocked) {
1:74846bb:         this.failIfDatabaseIsLocked = failIfDatabaseIsLocked;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isCheckForCorruptJournalFiles() {
1:74846bb:         return checkForCorruptJournalFiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setCheckForCorruptJournalFiles(boolean checkForCorruptJournalFiles) {
1:74846bb:         this.checkForCorruptJournalFiles = checkForCorruptJournalFiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public long getCheckpointInterval() {
1:74846bb:         return checkpointInterval;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setCheckpointInterval(long checkpointInterval) {
1:74846bb:         this.checkpointInterval = checkpointInterval;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public long getCleanupInterval() {
1:74846bb:         return cleanupInterval;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setCleanupInterval(long cleanupInterval) {
1:74846bb:         this.cleanupInterval = cleanupInterval;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isChecksumJournalFiles() {
1:74846bb:         return checksumJournalFiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setChecksumJournalFiles(boolean checksumJournalFiles) {
1:74846bb:         this.checksumJournalFiles = checksumJournalFiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isForceRecoverIndex() {
1:74846bb:         return forceRecoverIndex;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setForceRecoverIndex(boolean forceRecoverIndex) {
1:74846bb:         this.forceRecoverIndex = forceRecoverIndex;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public int getJournalMaxFileLength() {
1:74846bb:         return journalMaxFileLength;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setJournalMaxFileLength(int journalMaxFileLength) {
1:74846bb:         this.journalMaxFileLength = journalMaxFileLength;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public int getJournalMaxWriteBatchSize() {
1:74846bb:         return journalMaxWriteBatchSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setJournalMaxWriteBatchSize(int journalMaxWriteBatchSize) {
1:74846bb:         this.journalMaxWriteBatchSize = journalMaxWriteBatchSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isEnableIndexWriteAsync() {
1:74846bb:         return enableIndexWriteAsync;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setEnableIndexWriteAsync(boolean enableIndexWriteAsync) {
1:74846bb:         this.enableIndexWriteAsync = enableIndexWriteAsync;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isEnableJournalDiskSyncs() {
1:74846bb:         return enableJournalDiskSyncs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setEnableJournalDiskSyncs(boolean syncWrites) {
1:74846bb:         this.enableJournalDiskSyncs = syncWrites;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isDeleteAllJobs() {
1:74846bb:         return deleteAllJobs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setDeleteAllJobs(boolean deleteAllJobs) {
1:74846bb:         this.deleteAllJobs = deleteAllJobs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @return the archiveDataLogs
1:74846bb:      */
1:74846bb:     public boolean isArchiveDataLogs() {
1:74846bb:         return this.archiveDataLogs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @param archiveDataLogs the archiveDataLogs to set
1:74846bb:      */
1:74846bb:     public void setArchiveDataLogs(boolean archiveDataLogs) {
1:74846bb:         this.archiveDataLogs = archiveDataLogs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @return the directoryArchive
1:74846bb:      */
1:74846bb:     public File getDirectoryArchive() {
1:74846bb:         return this.directoryArchive;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * @param directoryArchive the directoryArchive to set
1:74846bb:      */
1:74846bb:     public void setDirectoryArchive(File directoryArchive) {
1:74846bb:         this.directoryArchive = directoryArchive;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public int getIndexCacheSize() {
1:74846bb:         return indexCacheSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setIndexCacheSize(int indexCacheSize) {
1:74846bb:         this.indexCacheSize = indexCacheSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public int getIndexWriteBatchSize() {
1:74846bb:         return indexWriteBatchSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setIndexWriteBatchSize(int indexWriteBatchSize) {
1:74846bb:         this.indexWriteBatchSize = indexWriteBatchSize;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isUseIndexLFRUEviction() {
1:74846bb:         return useIndexLFRUEviction;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setUseIndexLFRUEviction(boolean useIndexLFRUEviction) {
1:74846bb:         this.useIndexLFRUEviction = useIndexLFRUEviction;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public float getIndexLFUEvictionFactor() {
1:74846bb:         return indexLFUEvictionFactor;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setIndexLFUEvictionFactor(float indexLFUEvictionFactor) {
1:74846bb:         this.indexLFUEvictionFactor = indexLFUEvictionFactor;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isEnableIndexDiskSyncs() {
1:74846bb:         return enableIndexDiskSyncs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setEnableIndexDiskSyncs(boolean enableIndexDiskSyncs) {
1:74846bb:         this.enableIndexDiskSyncs = enableIndexDiskSyncs;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isEnableIndexRecoveryFile() {
1:74846bb:         return enableIndexRecoveryFile;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setEnableIndexRecoveryFile(boolean enableIndexRecoveryFile) {
1:74846bb:         this.enableIndexRecoveryFile = enableIndexRecoveryFile;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isEnableIndexPageCaching() {
1:74846bb:         return enableIndexPageCaching;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setEnableIndexPageCaching(boolean enableIndexPageCaching) {
1:74846bb:         this.enableIndexPageCaching = enableIndexPageCaching;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isPurgeStoreOnStartup() {
1:74846bb:         return this.purgeStoreOnStartup;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setPurgeStoreOnStartup(boolean purge) {
1:74846bb:         this.purgeStoreOnStartup = purge;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public boolean isIgnoreMissingJournalfiles() {
1:74846bb:         return ignoreMissingJournalfiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public void setIgnoreMissingJournalfiles(boolean ignoreMissingJournalfiles) {
1:74846bb:         this.ignoreMissingJournalfiles = ignoreMissingJournalfiles;
1:74846bb:     }
1:74846bb: 
1:74846bb:     public long size() {
1:74846bb:         if (!isStarted()) {
1:74846bb:             return 0;
1:74846bb:         }
1:74846bb:         try {
1:74846bb:             return journalSize.get() + pageFile.getDiskSize();
1:74846bb:         } catch (IOException e) {
1:74846bb:             throw new RuntimeException(e);
1:74846bb:         }
1:74846bb:     }
1:74846bb: 
1:74846bb:     @Override
1:74846bb:     public Locker createDefaultLocker() throws IOException {
1:74846bb:         SharedFileLocker locker = new SharedFileLocker();
1:74846bb:         locker.setDirectory(this.getDirectory());
1:74846bb:         return locker;
1:74846bb:     }
1:74846bb: 
1:74846bb:     @Override
1:74846bb:     public void init() throws Exception {
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Store a command in the Journal and process to update the Store index.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The specific JournalCommand to store and process.
1:74846bb:      *
1:74846bb:      * @returns the Location where the data was written in the Journal.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs storing or processing the command.
1:74846bb:      */
1:74846bb:     public Location store(JournalCommand<?> command) throws IOException {
1:74846bb:         return store(command, isEnableIndexDiskSyncs(), null, null, null);
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Store a command in the Journal and process to update the Store index.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The specific JournalCommand to store and process.
1:74846bb:      * @param sync
1:74846bb:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:74846bb:      *
1:74846bb:      * @returns the Location where the data was written in the Journal.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs storing or processing the command.
1:74846bb:      */
1:74846bb:     public Location store(JournalCommand<?> command, boolean sync) throws IOException {
1:74846bb:         return store(command, sync, null, null, null);
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Store a command in the Journal and process to update the Store index.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The specific JournalCommand to store and process.
1:74846bb:      * @param onJournalStoreComplete
1:74846bb:      *      The Runnable to call when the Journal write operation completes.
1:74846bb:      *
1:74846bb:      * @returns the Location where the data was written in the Journal.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs storing or processing the command.
1:74846bb:      */
1:74846bb:     public Location store(JournalCommand<?> command, Runnable onJournalStoreComplete) throws IOException {
1:74846bb:         return store(command, isEnableIndexDiskSyncs(), null, null, onJournalStoreComplete);
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Store a command in the Journal and process to update the Store index.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The specific JournalCommand to store and process.
1:74846bb:      * @param sync
1:74846bb:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:74846bb:      * @param before
1:74846bb:      *      The Runnable instance to execute before performing the store and process operation.
1:74846bb:      * @param after
1:74846bb:      *      The Runnable instance to execute after performing the store and process operation.
1:74846bb:      *
1:74846bb:      * @returns the Location where the data was written in the Journal.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs storing or processing the command.
1:74846bb:      */
1:74846bb:     public Location store(JournalCommand<?> command, boolean sync, Runnable before, Runnable after) throws IOException {
1:74846bb:         return store(command, sync, before, after, null);
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * All updated are are funneled through this method. The updates are converted to a
1:74846bb:      * JournalMessage which is logged to the journal and then the data from the JournalMessage
1:74846bb:      * is used to update the index just like it would be done during a recovery process.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The specific JournalCommand to store and process.
1:74846bb:      * @param sync
1:74846bb:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:74846bb:      * @param before
1:74846bb:      *      The Runnable instance to execute before performing the store and process operation.
1:74846bb:      * @param after
1:74846bb:      *      The Runnable instance to execute after performing the store and process operation.
1:74846bb:      * @param onJournalStoreComplete
1:74846bb:      *      Callback to be run when the journal write operation is complete.
1:74846bb:      *
1:74846bb:      * @returns the Location where the data was written in the Journal.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs storing or processing the command.
1:74846bb:      */
1:74846bb:     public Location store(JournalCommand<?> command, boolean sync, Runnable before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
1:74846bb:         try {
1:74846bb: 
1:74846bb:             if (before != null) {
1:74846bb:                 before.run();
1:74846bb:             }
1:74846bb: 
1:74846bb:             ByteSequence sequence = toByteSequence(command);
1:74846bb:             Location location;
1:74846bb:             checkpointLock.readLock().lock();
1:74846bb:             try {
1:74846bb: 
1:74846bb:                 long start = System.currentTimeMillis();
1:74846bb:                 location = onJournalStoreComplete == null ? journal.write(sequence, sync) :
1:74846bb:                                                             journal.write(sequence, onJournalStoreComplete);
1:74846bb:                 long start2 = System.currentTimeMillis();
1:74846bb: 
1:74846bb:                 process(command, location);
1:74846bb: 
1:74846bb:                 long end = System.currentTimeMillis();
1:74846bb:                 if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:74846bb:                     LOG.info("Slow KahaDB access: Journal append took: {} ms, Index update took {} ms",
1:74846bb:                              (start2-start), (end-start2));
1:74846bb:                 }
1:74846bb:             } finally {
1:74846bb:                 checkpointLock.readLock().unlock();
1:74846bb:             }
1:74846bb: 
1:74846bb:             if (after != null) {
1:74846bb:                 after.run();
1:74846bb:             }
1:74846bb: 
1:74846bb:             if (checkpointThread != null && !checkpointThread.isAlive()) {
1:74846bb:                 startCheckpoint();
1:74846bb:             }
1:74846bb:             return location;
1:74846bb:         } catch (IOException ioe) {
1:74846bb:             LOG.error("KahaDB failed to store to Journal", ioe);
1:74846bb:             if (brokerService != null) {
1:74846bb:                 brokerService.handleIOException(ioe);
1:74846bb:             }
1:74846bb:             throw ioe;
1:74846bb:         }
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Loads a previously stored JournalMessage
1:74846bb:      *
1:74846bb:      * @param location
1:74846bb:      *      The location of the journal command to read.
1:74846bb:      *
1:74846bb:      * @return a new un-marshaled JournalCommand instance.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs reading the stored command.
1:74846bb:      */
1:74846bb:     protected JournalCommand<?> load(Location location) throws IOException {
1:74846bb:         ByteSequence data = journal.read(location);
1:74846bb:         DataByteArrayInputStream is = new DataByteArrayInputStream(data);
1:74846bb:         byte readByte = is.readByte();
1:74846bb:         KahaEntryType type = KahaEntryType.valueOf(readByte);
1:74846bb:         if (type == null) {
1:74846bb:             try {
1:74846bb:                 is.close();
1:74846bb:             } catch (IOException e) {
1:74846bb:             }
1:74846bb:             throw new IOException("Could not load journal record. Invalid location: " + location);
1:74846bb:         }
1:74846bb:         JournalCommand<?> message = (JournalCommand<?>)type.createMessage();
1:74846bb:         message.mergeFramed(is);
1:74846bb:         return message;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Process a stored or recovered JournalCommand instance and update the DB Index with the
1:74846bb:      * state changes that this command produces.  This can be called either as a new DB operation
1:74846bb:      * or as a replay during recovery operations.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The JournalCommand to process.
1:74846bb:      * @param location
1:74846bb:      *      The location in the Journal where the command was written or read from.
1:74846bb:      */
1:74846bb:     protected abstract void process(JournalCommand<?> command, Location location) throws IOException;
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Perform a checkpoint operation with optional cleanup.
1:74846bb:      *
1:74846bb:      * Called by the checkpoint background thread periodically to initiate a checkpoint operation
1:74846bb:      * and if the cleanup flag is set a cleanup sweep should be done to allow for release of no
1:74846bb:      * longer needed journal log files etc.
1:74846bb:      *
1:74846bb:      * @param cleanup
1:74846bb:      *      Should the method do a simple checkpoint or also perform a journal cleanup.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs during the checkpoint operation.
1:74846bb:      */
1:74846bb:     protected void checkpointUpdate(final boolean cleanup) throws IOException {
1:74846bb:         checkpointLock.writeLock().lock();
1:74846bb:         try {
1:74846bb:             this.indexLock.writeLock().lock();
1:74846bb:             try {
1:74846bb:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:74846bb:                     @Override
1:74846bb:                     public void execute(Transaction tx) throws IOException {
1:74846bb:                         checkpointUpdate(tx, cleanup);
1:74846bb:                     }
1:74846bb:                 });
1:74846bb:             } finally {
1:74846bb:                 this.indexLock.writeLock().unlock();
1:74846bb:             }
1:74846bb: 
1:74846bb:         } finally {
1:74846bb:             checkpointLock.writeLock().unlock();
1:74846bb:         }
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Perform the checkpoint update operation.  If the cleanup flag is true then the
1:74846bb:      * operation should also purge any unused Journal log files.
1:74846bb:      *
1:74846bb:      * This method must always be called with the checkpoint and index write locks held.
1:74846bb:      *
1:74846bb:      * @param tx
1:74846bb:      *      The TX under which to perform the checkpoint update.
1:74846bb:      * @param cleanup
1:74846bb:      *      Should the checkpoint also do unused Journal file cleanup.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs while performing the checkpoint.
1:74846bb:      */
1:74846bb:     protected abstract void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException;
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Creates a new ByteSequence that represents the marshaled form of the given Journal Command.
1:74846bb:      *
1:74846bb:      * @param command
1:74846bb:      *      The Journal Command that should be marshaled to bytes for writing.
1:74846bb:      *
1:74846bb:      * @return the byte representation of the given journal command.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs while serializing the command.
1:74846bb:      */
1:74846bb:     protected ByteSequence toByteSequence(JournalCommand<?> data) throws IOException {
1:74846bb:         int size = data.serializedSizeFramed();
1:74846bb:         DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
1:74846bb:         os.writeByte(data.type().getNumber());
1:74846bb:         data.writeFramed(os);
1:74846bb:         return os.toByteSequence();
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Create the PageFile instance and configure it using the configuration options
1:74846bb:      * currently set.
1:74846bb:      *
1:74846bb:      * @return the newly created and configured PageFile instance.
1:74846bb:      */
1:74846bb:     protected PageFile createPageFile() {
1:74846bb:         PageFile index = new PageFile(getDirectory(), getPageFileName());
1:74846bb:         index.setEnableWriteThread(isEnableIndexWriteAsync());
1:74846bb:         index.setWriteBatchSize(getIndexWriteBatchSize());
1:74846bb:         index.setPageCacheSize(getIndexCacheSize());
1:74846bb:         index.setUseLFRUEviction(isUseIndexLFRUEviction());
1:74846bb:         index.setLFUEvictionFactor(getIndexLFUEvictionFactor());
1:74846bb:         index.setEnableDiskSyncs(isEnableIndexDiskSyncs());
1:74846bb:         index.setEnableRecoveryFile(isEnableIndexRecoveryFile());
1:74846bb:         index.setEnablePageCaching(isEnableIndexPageCaching());
1:74846bb:         return index;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Create a new Journal instance and configure it using the currently set configuration
1:74846bb:      * options.  If an archive directory is configured than this method will attempt to create
1:74846bb:      * that directory if it does not already exist.
1:74846bb:      *
1:74846bb:      * @return the newly created an configured Journal instance.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs while creating the Journal object.
1:74846bb:      */
1:74846bb:     protected Journal createJournal() throws IOException {
1:74846bb:         Journal manager = new Journal();
1:74846bb:         manager.setDirectory(getDirectory());
1:74846bb:         manager.setMaxFileLength(getJournalMaxFileLength());
1:74846bb:         manager.setCheckForCorruptionOnStartup(isCheckForCorruptJournalFiles());
1:74846bb:         manager.setChecksum(isChecksumJournalFiles() || isCheckForCorruptJournalFiles());
1:74846bb:         manager.setWriteBatchSize(getJournalMaxWriteBatchSize());
1:74846bb:         manager.setArchiveDataLogs(isArchiveDataLogs());
1:74846bb:         manager.setSizeAccumulator(journalSize);
1:74846bb:         manager.setEnableAsyncDiskSync(isEnableJournalDiskSyncs());
1:74846bb:         if (getDirectoryArchive() != null) {
1:74846bb:             IOHelper.mkdirs(getDirectoryArchive());
1:74846bb:             manager.setDirectoryArchive(getDirectoryArchive());
1:74846bb:         }
1:74846bb:         return manager;
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Starts the checkpoint Thread instance if not already running and not disabled
1:74846bb:      * by configuration.
1:74846bb:      */
1:74846bb:     protected void startCheckpoint() {
1:74846bb:         if (checkpointInterval == 0 && cleanupInterval == 0) {
1:74846bb:             LOG.info("periodic checkpoint/cleanup disabled, will ocurr on clean shutdown/restart");
1:74846bb:             return;
1:74846bb:         }
1:74846bb:         synchronized (checkpointThreadLock) {
1:74846bb:             boolean start = false;
1:74846bb:             if (checkpointThread == null) {
1:74846bb:                 start = true;
1:74846bb:             } else if (!checkpointThread.isAlive()) {
1:74846bb:                 start = true;
1:74846bb:                 LOG.info("KahaDB: Recovering checkpoint thread after death");
1:74846bb:             }
1:74846bb:             if (start) {
1:74846bb:                 checkpointThread = new Thread("ActiveMQ Journal Checkpoint Worker") {
1:74846bb:                     @Override
1:74846bb:                     public void run() {
1:74846bb:                         try {
1:74846bb:                             long lastCleanup = System.currentTimeMillis();
1:74846bb:                             long lastCheckpoint = System.currentTimeMillis();
1:74846bb:                             // Sleep for a short time so we can periodically check
1:74846bb:                             // to see if we need to exit this thread.
1:74846bb:                             long sleepTime = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
1:74846bb:                             while (opened.get()) {
1:74846bb:                                 Thread.sleep(sleepTime);
1:74846bb:                                 long now = System.currentTimeMillis();
1:74846bb:                                 if( cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval) ) {
1:74846bb:                                     checkpointCleanup(true);
1:74846bb:                                     lastCleanup = now;
1:74846bb:                                     lastCheckpoint = now;
1:74846bb:                                 } else if( checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval )) {
1:74846bb:                                     checkpointCleanup(false);
1:74846bb:                                     lastCheckpoint = now;
1:74846bb:                                 }
1:74846bb:                             }
1:74846bb:                         } catch (InterruptedException e) {
1:74846bb:                             // Looks like someone really wants us to exit this thread...
1:74846bb:                         } catch (IOException ioe) {
1:74846bb:                             LOG.error("Checkpoint failed", ioe);
1:74846bb:                             brokerService.handleIOException(ioe);
1:74846bb:                         }
1:74846bb:                     }
1:74846bb:                 };
1:74846bb: 
1:74846bb:                 checkpointThread.setDaemon(true);
1:74846bb:                 checkpointThread.start();
1:74846bb:             }
1:74846bb:         }
1:74846bb:     }
1:74846bb: 
1:74846bb:     /**
1:74846bb:      * Called from the worker thread to start a checkpoint.
1:74846bb:      *
1:74846bb:      * This method ensure that the store is in an opened state and optionaly logs information
1:74846bb:      * related to slow store access times.
1:74846bb:      *
1:74846bb:      * @param cleanup
1:74846bb:      *      Should a cleanup of the journal occur during the checkpoint operation.
1:74846bb:      *
1:74846bb:      * @throws IOException if an error occurs during the checkpoint operation.
1:74846bb:      */
1:74846bb:     protected void checkpointCleanup(final boolean cleanup) throws IOException {
1:74846bb:         long start;
1:74846bb:         this.indexLock.writeLock().lock();
1:74846bb:         try {
1:74846bb:             start = System.currentTimeMillis();
1:74846bb:             if (!opened.get()) {
1:74846bb:                 return;
1:74846bb:             }
1:74846bb:         } finally {
1:74846bb:             this.indexLock.writeLock().unlock();
1:74846bb:         }
1:74846bb:         checkpointUpdate(cleanup);
1:74846bb:         long end = System.currentTimeMillis();
1:74846bb:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:74846bb:             LOG.info("Slow KahaDB access: cleanup took {}", (end - start));
1:74846bb:         }
1:74846bb:     }
1:74846bb: }
============================================================================
author:Timothy Bish
-------------------------------------------------------------------------------
commit:74846bb
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *      http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.activemq.store.kahadb;
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.util.Date;
1: import java.util.concurrent.atomic.AtomicBoolean;
1: import java.util.concurrent.atomic.AtomicLong;
1: import java.util.concurrent.locks.ReentrantReadWriteLock;
1: 
1: import org.apache.activemq.broker.LockableServiceSupport;
1: import org.apache.activemq.broker.Locker;
1: import org.apache.activemq.store.SharedFileLocker;
1: import org.apache.activemq.store.kahadb.data.KahaEntryType;
1: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
1: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1: import org.apache.activemq.store.kahadb.disk.journal.Location;
1: import org.apache.activemq.store.kahadb.disk.page.PageFile;
1: import org.apache.activemq.store.kahadb.disk.page.Transaction;
1: import org.apache.activemq.util.ByteSequence;
1: import org.apache.activemq.util.DataByteArrayInputStream;
1: import org.apache.activemq.util.DataByteArrayOutputStream;
1: import org.apache.activemq.util.IOHelper;
1: import org.apache.activemq.util.ServiceStopper;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: public abstract class AbstractKahaDBStore extends LockableServiceSupport {
1: 
1:     static final Logger LOG = LoggerFactory.getLogger(AbstractKahaDBStore.class);
1: 
1:     public static final String PROPERTY_LOG_SLOW_ACCESS_TIME = "org.apache.activemq.store.kahadb.LOG_SLOW_ACCESS_TIME";
1:     public static final int LOG_SLOW_ACCESS_TIME = Integer.getInteger(PROPERTY_LOG_SLOW_ACCESS_TIME, 0);
1: 
1:     protected File directory;
1:     protected PageFile pageFile;
1:     protected Journal journal;
1:     protected AtomicLong journalSize = new AtomicLong(0);
1:     protected boolean failIfDatabaseIsLocked;
1:     protected long checkpointInterval = 5*1000;
1:     protected long cleanupInterval = 30*1000;
1:     protected boolean checkForCorruptJournalFiles = false;
1:     protected boolean checksumJournalFiles = true;
1:     protected boolean forceRecoverIndex = false;
1:     protected int journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
1:     protected int journalMaxWriteBatchSize = Journal.DEFAULT_MAX_WRITE_BATCH_SIZE;
1:     protected boolean archiveCorruptedIndex = false;
1:     protected boolean enableIndexWriteAsync = false;
1:     protected boolean enableJournalDiskSyncs = false;
1:     protected boolean deleteAllJobs = false;
1:     protected int indexWriteBatchSize = PageFile.DEFAULT_WRITE_BATCH_SIZE;
1:     protected boolean useIndexLFRUEviction = false;
1:     protected float indexLFUEvictionFactor = 0.2f;
1:     protected boolean ignoreMissingJournalfiles = false;
1:     protected int indexCacheSize = 1000;
1:     protected boolean enableIndexDiskSyncs = true;
1:     protected boolean enableIndexRecoveryFile = true;
1:     protected boolean enableIndexPageCaching = true;
1:     protected boolean archiveDataLogs;
1:     protected boolean purgeStoreOnStartup;
1:     protected File directoryArchive;
1: 
1:     protected AtomicBoolean opened = new AtomicBoolean();
1:     protected Thread checkpointThread;
1:     protected final Object checkpointThreadLock = new Object();
1:     protected ReentrantReadWriteLock checkpointLock = new ReentrantReadWriteLock();
1:     protected ReentrantReadWriteLock indexLock = new ReentrantReadWriteLock();
1: 
1:     /**
1:      * @return the name to give this store's PageFile instance.
1:      */
1:     protected abstract String getPageFileName();
1: 
1:     /**
1:      * @return the location of the data directory if no set by configuration.
1:      */
1:     protected abstract File getDefaultDataDirectory();
1: 
1:     /**
1:      * Loads the store from disk.
1:      *
1:      * Based on configuration this method can either load an existing store or it can purge
1:      * an existing store and start in a clean state.
1:      *
1:      * @throws IOException if an error occurs during the load.
1:      */
1:     public abstract void load() throws IOException;
1: 
1:     /**
1:      * Unload the state of the Store to disk and shuts down all resources assigned to this
1:      * KahaDB store implementation.
1:      *
1:      * @throws IOException if an error occurs during the store unload.
1:      */
1:     public abstract void unload() throws IOException;
1: 
1:     @Override
1:     protected void doStart() throws Exception {
1:         this.indexLock.writeLock().lock();
1:         if (getDirectory() == null) {
1:             setDirectory(getDefaultDataDirectory());
1:         }
1:         IOHelper.mkdirs(getDirectory());
1:         try {
1:             if (isPurgeStoreOnStartup()) {
1:                 getJournal().start();
1:                 getJournal().delete();
1:                 getJournal().close();
1:                 journal = null;
1:                 getPageFile().delete();
1:                 LOG.info("{} Persistence store purged.", this);
1:                 setPurgeStoreOnStartup(false);
1:             }
1: 
1:             load();
1:             store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
1:         } finally {
1:             this.indexLock.writeLock().unlock();
1:         }
1:     }
1: 
1:     @Override
1:     protected void doStop(ServiceStopper stopper) throws Exception {
1:         unload();
1:     }
1: 
1:     public PageFile getPageFile() {
1:         if (pageFile == null) {
1:             pageFile = createPageFile();
1:         }
1:         return pageFile;
1:     }
1: 
1:     public Journal getJournal() throws IOException {
1:         if (journal == null) {
1:             journal = createJournal();
1:         }
1:         return journal;
1:     }
1: 
1:     public File getDirectory() {
1:         return directory;
1:     }
1: 
1:     public void setDirectory(File directory) {
1:         this.directory = directory;
1:     }
1: 
1:     public boolean isArchiveCorruptedIndex() {
1:         return archiveCorruptedIndex;
1:     }
1: 
1:     public void setArchiveCorruptedIndex(boolean archiveCorruptedIndex) {
1:         this.archiveCorruptedIndex = archiveCorruptedIndex;
1:     }
1: 
1:     public boolean isFailIfDatabaseIsLocked() {
1:         return failIfDatabaseIsLocked;
1:     }
1: 
1:     public void setFailIfDatabaseIsLocked(boolean failIfDatabaseIsLocked) {
1:         this.failIfDatabaseIsLocked = failIfDatabaseIsLocked;
1:     }
1: 
1:     public boolean isCheckForCorruptJournalFiles() {
1:         return checkForCorruptJournalFiles;
1:     }
1: 
1:     public void setCheckForCorruptJournalFiles(boolean checkForCorruptJournalFiles) {
1:         this.checkForCorruptJournalFiles = checkForCorruptJournalFiles;
1:     }
1: 
1:     public long getCheckpointInterval() {
1:         return checkpointInterval;
1:     }
1: 
1:     public void setCheckpointInterval(long checkpointInterval) {
1:         this.checkpointInterval = checkpointInterval;
1:     }
1: 
1:     public long getCleanupInterval() {
1:         return cleanupInterval;
1:     }
1: 
1:     public void setCleanupInterval(long cleanupInterval) {
1:         this.cleanupInterval = cleanupInterval;
1:     }
1: 
1:     public boolean isChecksumJournalFiles() {
1:         return checksumJournalFiles;
1:     }
1: 
1:     public void setChecksumJournalFiles(boolean checksumJournalFiles) {
1:         this.checksumJournalFiles = checksumJournalFiles;
1:     }
1: 
1:     public boolean isForceRecoverIndex() {
1:         return forceRecoverIndex;
1:     }
1: 
1:     public void setForceRecoverIndex(boolean forceRecoverIndex) {
1:         this.forceRecoverIndex = forceRecoverIndex;
1:     }
1: 
1:     public int getJournalMaxFileLength() {
1:         return journalMaxFileLength;
1:     }
1: 
1:     public void setJournalMaxFileLength(int journalMaxFileLength) {
1:         this.journalMaxFileLength = journalMaxFileLength;
1:     }
1: 
1:     public int getJournalMaxWriteBatchSize() {
1:         return journalMaxWriteBatchSize;
1:     }
1: 
1:     public void setJournalMaxWriteBatchSize(int journalMaxWriteBatchSize) {
1:         this.journalMaxWriteBatchSize = journalMaxWriteBatchSize;
1:     }
1: 
1:     public boolean isEnableIndexWriteAsync() {
1:         return enableIndexWriteAsync;
1:     }
1: 
1:     public void setEnableIndexWriteAsync(boolean enableIndexWriteAsync) {
1:         this.enableIndexWriteAsync = enableIndexWriteAsync;
1:     }
1: 
1:     public boolean isEnableJournalDiskSyncs() {
1:         return enableJournalDiskSyncs;
1:     }
1: 
1:     public void setEnableJournalDiskSyncs(boolean syncWrites) {
1:         this.enableJournalDiskSyncs = syncWrites;
1:     }
1: 
1:     public boolean isDeleteAllJobs() {
1:         return deleteAllJobs;
1:     }
1: 
1:     public void setDeleteAllJobs(boolean deleteAllJobs) {
1:         this.deleteAllJobs = deleteAllJobs;
1:     }
1: 
1:     /**
1:      * @return the archiveDataLogs
1:      */
1:     public boolean isArchiveDataLogs() {
1:         return this.archiveDataLogs;
1:     }
1: 
1:     /**
1:      * @param archiveDataLogs the archiveDataLogs to set
1:      */
1:     public void setArchiveDataLogs(boolean archiveDataLogs) {
1:         this.archiveDataLogs = archiveDataLogs;
1:     }
1: 
1:     /**
1:      * @return the directoryArchive
1:      */
1:     public File getDirectoryArchive() {
1:         return this.directoryArchive;
1:     }
1: 
1:     /**
1:      * @param directoryArchive the directoryArchive to set
1:      */
1:     public void setDirectoryArchive(File directoryArchive) {
1:         this.directoryArchive = directoryArchive;
1:     }
1: 
1:     public int getIndexCacheSize() {
1:         return indexCacheSize;
1:     }
1: 
1:     public void setIndexCacheSize(int indexCacheSize) {
1:         this.indexCacheSize = indexCacheSize;
1:     }
1: 
1:     public int getIndexWriteBatchSize() {
1:         return indexWriteBatchSize;
1:     }
1: 
1:     public void setIndexWriteBatchSize(int indexWriteBatchSize) {
1:         this.indexWriteBatchSize = indexWriteBatchSize;
1:     }
1: 
1:     public boolean isUseIndexLFRUEviction() {
1:         return useIndexLFRUEviction;
1:     }
1: 
1:     public void setUseIndexLFRUEviction(boolean useIndexLFRUEviction) {
1:         this.useIndexLFRUEviction = useIndexLFRUEviction;
1:     }
1: 
1:     public float getIndexLFUEvictionFactor() {
1:         return indexLFUEvictionFactor;
1:     }
1: 
1:     public void setIndexLFUEvictionFactor(float indexLFUEvictionFactor) {
1:         this.indexLFUEvictionFactor = indexLFUEvictionFactor;
1:     }
1: 
1:     public boolean isEnableIndexDiskSyncs() {
1:         return enableIndexDiskSyncs;
1:     }
1: 
1:     public void setEnableIndexDiskSyncs(boolean enableIndexDiskSyncs) {
1:         this.enableIndexDiskSyncs = enableIndexDiskSyncs;
1:     }
1: 
1:     public boolean isEnableIndexRecoveryFile() {
1:         return enableIndexRecoveryFile;
1:     }
1: 
1:     public void setEnableIndexRecoveryFile(boolean enableIndexRecoveryFile) {
1:         this.enableIndexRecoveryFile = enableIndexRecoveryFile;
1:     }
1: 
1:     public boolean isEnableIndexPageCaching() {
1:         return enableIndexPageCaching;
1:     }
1: 
1:     public void setEnableIndexPageCaching(boolean enableIndexPageCaching) {
1:         this.enableIndexPageCaching = enableIndexPageCaching;
1:     }
1: 
1:     public boolean isPurgeStoreOnStartup() {
1:         return this.purgeStoreOnStartup;
1:     }
1: 
1:     public void setPurgeStoreOnStartup(boolean purge) {
1:         this.purgeStoreOnStartup = purge;
1:     }
1: 
1:     public boolean isIgnoreMissingJournalfiles() {
1:         return ignoreMissingJournalfiles;
1:     }
1: 
1:     public void setIgnoreMissingJournalfiles(boolean ignoreMissingJournalfiles) {
1:         this.ignoreMissingJournalfiles = ignoreMissingJournalfiles;
1:     }
1: 
1:     public long size() {
1:         if (!isStarted()) {
1:             return 0;
1:         }
1:         try {
1:             return journalSize.get() + pageFile.getDiskSize();
1:         } catch (IOException e) {
1:             throw new RuntimeException(e);
1:         }
1:     }
1: 
1:     @Override
1:     public Locker createDefaultLocker() throws IOException {
1:         SharedFileLocker locker = new SharedFileLocker();
1:         locker.setDirectory(this.getDirectory());
1:         return locker;
1:     }
1: 
1:     @Override
1:     public void init() throws Exception {
1:     }
1: 
1:     /**
1:      * Store a command in the Journal and process to update the Store index.
1:      *
1:      * @param command
1:      *      The specific JournalCommand to store and process.
1:      *
1:      * @returns the Location where the data was written in the Journal.
1:      *
1:      * @throws IOException if an error occurs storing or processing the command.
1:      */
1:     public Location store(JournalCommand<?> command) throws IOException {
1:         return store(command, isEnableIndexDiskSyncs(), null, null, null);
1:     }
1: 
1:     /**
1:      * Store a command in the Journal and process to update the Store index.
1:      *
1:      * @param command
1:      *      The specific JournalCommand to store and process.
1:      * @param sync
1:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:      *
1:      * @returns the Location where the data was written in the Journal.
1:      *
1:      * @throws IOException if an error occurs storing or processing the command.
1:      */
1:     public Location store(JournalCommand<?> command, boolean sync) throws IOException {
1:         return store(command, sync, null, null, null);
1:     }
1: 
1:     /**
1:      * Store a command in the Journal and process to update the Store index.
1:      *
1:      * @param command
1:      *      The specific JournalCommand to store and process.
1:      * @param onJournalStoreComplete
1:      *      The Runnable to call when the Journal write operation completes.
1:      *
1:      * @returns the Location where the data was written in the Journal.
1:      *
1:      * @throws IOException if an error occurs storing or processing the command.
1:      */
1:     public Location store(JournalCommand<?> command, Runnable onJournalStoreComplete) throws IOException {
1:         return store(command, isEnableIndexDiskSyncs(), null, null, onJournalStoreComplete);
1:     }
1: 
1:     /**
1:      * Store a command in the Journal and process to update the Store index.
1:      *
1:      * @param command
1:      *      The specific JournalCommand to store and process.
1:      * @param sync
1:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:      * @param before
1:      *      The Runnable instance to execute before performing the store and process operation.
1:      * @param after
1:      *      The Runnable instance to execute after performing the store and process operation.
1:      *
1:      * @returns the Location where the data was written in the Journal.
1:      *
1:      * @throws IOException if an error occurs storing or processing the command.
1:      */
1:     public Location store(JournalCommand<?> command, boolean sync, Runnable before, Runnable after) throws IOException {
1:         return store(command, sync, before, after, null);
1:     }
1: 
1:     /**
1:      * All updated are are funneled through this method. The updates are converted to a
1:      * JournalMessage which is logged to the journal and then the data from the JournalMessage
1:      * is used to update the index just like it would be done during a recovery process.
1:      *
1:      * @param command
1:      *      The specific JournalCommand to store and process.
1:      * @param sync
1:      *      Should the store operation be done synchronously. (ignored if completion passed).
1:      * @param before
1:      *      The Runnable instance to execute before performing the store and process operation.
1:      * @param after
1:      *      The Runnable instance to execute after performing the store and process operation.
1:      * @param onJournalStoreComplete
1:      *      Callback to be run when the journal write operation is complete.
1:      *
1:      * @returns the Location where the data was written in the Journal.
1:      *
1:      * @throws IOException if an error occurs storing or processing the command.
1:      */
1:     public Location store(JournalCommand<?> command, boolean sync, Runnable before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
1:         try {
1: 
1:             if (before != null) {
1:                 before.run();
1:             }
1: 
1:             ByteSequence sequence = toByteSequence(command);
1:             Location location;
1:             checkpointLock.readLock().lock();
1:             try {
1: 
1:                 long start = System.currentTimeMillis();
1:                 location = onJournalStoreComplete == null ? journal.write(sequence, sync) :
1:                                                             journal.write(sequence, onJournalStoreComplete);
1:                 long start2 = System.currentTimeMillis();
1: 
1:                 process(command, location);
1: 
1:                 long end = System.currentTimeMillis();
1:                 if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:                     LOG.info("Slow KahaDB access: Journal append took: {} ms, Index update took {} ms",
1:                              (start2-start), (end-start2));
1:                 }
1:             } finally {
1:                 checkpointLock.readLock().unlock();
1:             }
1: 
1:             if (after != null) {
1:                 after.run();
1:             }
1: 
1:             if (checkpointThread != null && !checkpointThread.isAlive()) {
1:                 startCheckpoint();
1:             }
1:             return location;
1:         } catch (IOException ioe) {
1:             LOG.error("KahaDB failed to store to Journal", ioe);
1:             if (brokerService != null) {
1:                 brokerService.handleIOException(ioe);
1:             }
1:             throw ioe;
1:         }
1:     }
1: 
1:     /**
1:      * Loads a previously stored JournalMessage
1:      *
1:      * @param location
1:      *      The location of the journal command to read.
1:      *
1:      * @return a new un-marshaled JournalCommand instance.
1:      *
1:      * @throws IOException if an error occurs reading the stored command.
1:      */
1:     protected JournalCommand<?> load(Location location) throws IOException {
1:         ByteSequence data = journal.read(location);
1:         DataByteArrayInputStream is = new DataByteArrayInputStream(data);
1:         byte readByte = is.readByte();
1:         KahaEntryType type = KahaEntryType.valueOf(readByte);
1:         if (type == null) {
1:             try {
1:                 is.close();
1:             } catch (IOException e) {
1:             }
1:             throw new IOException("Could not load journal record. Invalid location: " + location);
1:         }
1:         JournalCommand<?> message = (JournalCommand<?>)type.createMessage();
1:         message.mergeFramed(is);
1:         return message;
1:     }
1: 
1:     /**
1:      * Process a stored or recovered JournalCommand instance and update the DB Index with the
1:      * state changes that this command produces.  This can be called either as a new DB operation
1:      * or as a replay during recovery operations.
1:      *
1:      * @param command
1:      *      The JournalCommand to process.
1:      * @param location
1:      *      The location in the Journal where the command was written or read from.
1:      */
1:     protected abstract void process(JournalCommand<?> command, Location location) throws IOException;
1: 
1:     /**
1:      * Perform a checkpoint operation with optional cleanup.
1:      *
1:      * Called by the checkpoint background thread periodically to initiate a checkpoint operation
1:      * and if the cleanup flag is set a cleanup sweep should be done to allow for release of no
1:      * longer needed journal log files etc.
1:      *
1:      * @param cleanup
1:      *      Should the method do a simple checkpoint or also perform a journal cleanup.
1:      *
1:      * @throws IOException if an error occurs during the checkpoint operation.
1:      */
1:     protected void checkpointUpdate(final boolean cleanup) throws IOException {
1:         checkpointLock.writeLock().lock();
1:         try {
1:             this.indexLock.writeLock().lock();
1:             try {
1:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                     @Override
1:                     public void execute(Transaction tx) throws IOException {
1:                         checkpointUpdate(tx, cleanup);
1:                     }
1:                 });
1:             } finally {
1:                 this.indexLock.writeLock().unlock();
1:             }
1: 
1:         } finally {
1:             checkpointLock.writeLock().unlock();
1:         }
1:     }
1: 
1:     /**
1:      * Perform the checkpoint update operation.  If the cleanup flag is true then the
1:      * operation should also purge any unused Journal log files.
1:      *
1:      * This method must always be called with the checkpoint and index write locks held.
1:      *
1:      * @param tx
1:      *      The TX under which to perform the checkpoint update.
1:      * @param cleanup
1:      *      Should the checkpoint also do unused Journal file cleanup.
1:      *
1:      * @throws IOException if an error occurs while performing the checkpoint.
1:      */
1:     protected abstract void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException;
1: 
1:     /**
1:      * Creates a new ByteSequence that represents the marshaled form of the given Journal Command.
1:      *
1:      * @param command
1:      *      The Journal Command that should be marshaled to bytes for writing.
1:      *
1:      * @return the byte representation of the given journal command.
1:      *
1:      * @throws IOException if an error occurs while serializing the command.
1:      */
1:     protected ByteSequence toByteSequence(JournalCommand<?> data) throws IOException {
1:         int size = data.serializedSizeFramed();
1:         DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
1:         os.writeByte(data.type().getNumber());
1:         data.writeFramed(os);
1:         return os.toByteSequence();
1:     }
1: 
1:     /**
1:      * Create the PageFile instance and configure it using the configuration options
1:      * currently set.
1:      *
1:      * @return the newly created and configured PageFile instance.
1:      */
1:     protected PageFile createPageFile() {
1:         PageFile index = new PageFile(getDirectory(), getPageFileName());
1:         index.setEnableWriteThread(isEnableIndexWriteAsync());
1:         index.setWriteBatchSize(getIndexWriteBatchSize());
1:         index.setPageCacheSize(getIndexCacheSize());
1:         index.setUseLFRUEviction(isUseIndexLFRUEviction());
1:         index.setLFUEvictionFactor(getIndexLFUEvictionFactor());
1:         index.setEnableDiskSyncs(isEnableIndexDiskSyncs());
1:         index.setEnableRecoveryFile(isEnableIndexRecoveryFile());
1:         index.setEnablePageCaching(isEnableIndexPageCaching());
1:         return index;
1:     }
1: 
1:     /**
1:      * Create a new Journal instance and configure it using the currently set configuration
1:      * options.  If an archive directory is configured than this method will attempt to create
1:      * that directory if it does not already exist.
1:      *
1:      * @return the newly created an configured Journal instance.
1:      *
1:      * @throws IOException if an error occurs while creating the Journal object.
1:      */
1:     protected Journal createJournal() throws IOException {
1:         Journal manager = new Journal();
1:         manager.setDirectory(getDirectory());
1:         manager.setMaxFileLength(getJournalMaxFileLength());
1:         manager.setCheckForCorruptionOnStartup(isCheckForCorruptJournalFiles());
1:         manager.setChecksum(isChecksumJournalFiles() || isCheckForCorruptJournalFiles());
1:         manager.setWriteBatchSize(getJournalMaxWriteBatchSize());
1:         manager.setArchiveDataLogs(isArchiveDataLogs());
1:         manager.setSizeAccumulator(journalSize);
1:         manager.setEnableAsyncDiskSync(isEnableJournalDiskSyncs());
1:         if (getDirectoryArchive() != null) {
1:             IOHelper.mkdirs(getDirectoryArchive());
1:             manager.setDirectoryArchive(getDirectoryArchive());
1:         }
1:         return manager;
1:     }
1: 
1:     /**
1:      * Starts the checkpoint Thread instance if not already running and not disabled
1:      * by configuration.
1:      */
1:     protected void startCheckpoint() {
1:         if (checkpointInterval == 0 && cleanupInterval == 0) {
1:             LOG.info("periodic checkpoint/cleanup disabled, will ocurr on clean shutdown/restart");
1:             return;
1:         }
1:         synchronized (checkpointThreadLock) {
1:             boolean start = false;
1:             if (checkpointThread == null) {
1:                 start = true;
1:             } else if (!checkpointThread.isAlive()) {
1:                 start = true;
1:                 LOG.info("KahaDB: Recovering checkpoint thread after death");
1:             }
1:             if (start) {
1:                 checkpointThread = new Thread("ActiveMQ Journal Checkpoint Worker") {
1:                     @Override
1:                     public void run() {
1:                         try {
1:                             long lastCleanup = System.currentTimeMillis();
1:                             long lastCheckpoint = System.currentTimeMillis();
1:                             // Sleep for a short time so we can periodically check
1:                             // to see if we need to exit this thread.
1:                             long sleepTime = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
1:                             while (opened.get()) {
1:                                 Thread.sleep(sleepTime);
1:                                 long now = System.currentTimeMillis();
1:                                 if( cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval) ) {
1:                                     checkpointCleanup(true);
1:                                     lastCleanup = now;
1:                                     lastCheckpoint = now;
1:                                 } else if( checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval )) {
1:                                     checkpointCleanup(false);
1:                                     lastCheckpoint = now;
1:                                 }
1:                             }
1:                         } catch (InterruptedException e) {
1:                             // Looks like someone really wants us to exit this thread...
1:                         } catch (IOException ioe) {
1:                             LOG.error("Checkpoint failed", ioe);
1:                             brokerService.handleIOException(ioe);
1:                         }
1:                     }
1:                 };
1: 
1:                 checkpointThread.setDaemon(true);
1:                 checkpointThread.start();
1:             }
1:         }
1:     }
1: 
1:     /**
1:      * Called from the worker thread to start a checkpoint.
1:      *
1:      * This method ensure that the store is in an opened state and optionaly logs information
1:      * related to slow store access times.
1:      *
1:      * @param cleanup
1:      *      Should a cleanup of the journal occur during the checkpoint operation.
1:      *
1:      * @throws IOException if an error occurs during the checkpoint operation.
1:      */
1:     protected void checkpointCleanup(final boolean cleanup) throws IOException {
1:         long start;
1:         this.indexLock.writeLock().lock();
1:         try {
1:             start = System.currentTimeMillis();
1:             if (!opened.get()) {
1:                 return;
1:             }
1:         } finally {
1:             this.indexLock.writeLock().unlock();
1:         }
1:         checkpointUpdate(cleanup);
1:         long end = System.currentTimeMillis();
1:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:             LOG.info("Slow KahaDB access: cleanup took {}", (end - start));
1:         }
1:     }
1: }
============================================================================
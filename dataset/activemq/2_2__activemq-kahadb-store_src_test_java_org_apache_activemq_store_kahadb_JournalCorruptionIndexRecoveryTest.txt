1:a7178a4: /**
1:a7178a4:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:a7178a4:  * contributor license agreements.  See the NOTICE file distributed with
1:a7178a4:  * this work for additional information regarding copyright ownership.
1:a7178a4:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:a7178a4:  * (the "License"); you may not use this file except in compliance with
1:a7178a4:  * the License.  You may obtain a copy of the License at
1:a7178a4:  *
1:a7178a4:  *      http://www.apache.org/licenses/LICENSE-2.0
1:a7178a4:  *
1:a7178a4:  * Unless required by applicable law or agreed to in writing, software
1:a7178a4:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a7178a4:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a7178a4:  * See the License for the specific language governing permissions and
1:a7178a4:  * limitations under the License.
1:a7178a4:  */
1:a7178a4: package org.apache.activemq.store.kahadb;
14:a7178a4: 
1:822e2be: import static org.apache.activemq.store.kahadb.JournalCorruptionEofIndexRecoveryTest.drain;
1:a7178a4: import static org.junit.Assert.assertEquals;
1:a7178a4: import static org.junit.Assert.assertTrue;
1:a7178a4: 
1:a7178a4: import java.io.File;
1:a7178a4: import java.io.IOException;
1:a7178a4: import java.util.Arrays;
1:a7178a4: import java.util.Collection;
1:a7178a4: 
1:a7178a4: import javax.jms.Connection;
1:a7178a4: import javax.jms.Destination;
1:a7178a4: import javax.jms.Message;
1:a7178a4: import javax.jms.MessageConsumer;
1:a7178a4: import javax.jms.MessageProducer;
1:a7178a4: import javax.jms.Session;
1:a7178a4: 
1:a7178a4: import org.apache.activemq.ActiveMQConnectionFactory;
1:a7178a4: import org.apache.activemq.broker.BrokerService;
1:a7178a4: import org.apache.activemq.command.ActiveMQQueue;
1:a7178a4: import org.apache.activemq.store.kahadb.disk.journal.DataFile;
1:a7178a4: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1:822e2be: import org.apache.activemq.store.kahadb.disk.journal.Location;
1:a7178a4: import org.apache.activemq.util.ByteSequence;
1:a7178a4: import org.apache.activemq.util.RecoverableRandomAccessFile;
1:a7178a4: import org.junit.After;
1:a7178a4: import org.junit.Test;
1:a7178a4: import org.junit.runner.RunWith;
1:a7178a4: import org.junit.runners.Parameterized;
1:a7178a4: import org.slf4j.Logger;
1:a7178a4: import org.slf4j.LoggerFactory;
1:a7178a4: 
1:a7178a4: @RunWith(Parameterized.class)
1:a7178a4: public class JournalCorruptionIndexRecoveryTest {
1:a7178a4: 
1:a7178a4:     private static final Logger LOG = LoggerFactory.getLogger(JournalCorruptionIndexRecoveryTest.class);
1:a7178a4: 
1:13044de:     private final String KAHADB_DIRECTORY = "target/activemq-data/";
1:13044de:     private final String payload = new String(new byte[1024]);
1:a7178a4: 
1:13044de:     private ActiveMQConnectionFactory cf = null;
1:13044de:     private BrokerService broker = null;
1:a7178a4:     private final Destination destination = new ActiveMQQueue("Test");
1:a7178a4:     private String connectionUri;
1:a7178a4:     private KahaDBPersistenceAdapter adapter;
1:a7178a4: 
1:a7178a4:     @Parameterized.Parameter(0)
1:a7178a4:     public byte fill = Byte.valueOf("3");
1:a7178a4: 
1:a7178a4:     @Parameterized.Parameters(name = "fill=#{0}")
1:a7178a4:     public static Iterable<Object[]> parameters() {
1:a7178a4:         // corruption can be valid record type values
1:a7178a4:         return Arrays.asList(new Object[][]{{Byte.valueOf("1")}, {Byte.valueOf("0")}, {Byte.valueOf("2")}, {Byte.valueOf("-1")} });
2:a7178a4:     }
1:a7178a4: 
1:a7178a4:     protected void startBroker() throws Exception {
1:a7178a4:         doStartBroker(true);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     protected void restartBroker() throws Exception {
1:a7178a4:         File dataDir = broker.getPersistenceAdapter().getDirectory();
1:a7178a4: 
1:a7178a4:         if (broker != null) {
1:a7178a4:             broker.stop();
1:a7178a4:             broker.waitUntilStopped();
1:a7178a4:         }
1:a7178a4: 
1:a7178a4:         whackIndex(dataDir);
1:a7178a4: 
1:a7178a4:         doStartBroker(false);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private void doStartBroker(boolean delete) throws Exception {
1:a7178a4:         broker = new BrokerService();
1:a7178a4:         broker.setDeleteAllMessagesOnStartup(delete);
1:a7178a4:         broker.setPersistent(true);
1:a7178a4:         broker.setUseJmx(true);
1:13044de:         broker.setDataDirectory(KAHADB_DIRECTORY);
1:a7178a4:         broker.addConnector("tcp://localhost:0");
1:a7178a4: 
1:a7178a4:         configurePersistence(broker);
1:a7178a4: 
1:a7178a4:         connectionUri = "vm://localhost?create=false";
1:a7178a4:         cf = new ActiveMQConnectionFactory(connectionUri);
1:a7178a4: 
1:a7178a4:         broker.start();
1:a7178a4:         LOG.info("Starting broker..");
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     protected void configurePersistence(BrokerService brokerService) throws Exception {
1:a7178a4:         adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();
1:a7178a4: 
1:a7178a4:         // ensure there are a bunch of data files but multiple entries in each
1:a7178a4:         adapter.setJournalMaxFileLength(1024 * 20);
1:a7178a4: 
1:a7178a4:         // speed up the test case, checkpoint an cleanup early and often
1:a7178a4:         adapter.setCheckpointInterval(5000);
1:a7178a4:         adapter.setCleanupInterval(5000);
1:a7178a4: 
1:a7178a4:         adapter.setCheckForCorruptJournalFiles(true);
1:a7178a4:         adapter.setIgnoreMissingJournalfiles(true);
1:62bdbb0: 
1:62bdbb0:         adapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL_ASYNC.name());
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     @After
1:a7178a4:     public void tearDown() throws Exception {
1:a7178a4:         if (broker != null) {
1:a7178a4:             broker.stop();
1:a7178a4:             broker.waitUntilStopped();
1:a7178a4:         }
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     @Test
1:a7178a4:     public void testRecoveryAfterCorruptionMiddle() throws Exception {
1:a7178a4:         startBroker();
1:a7178a4: 
1:a7178a4:         produceMessagesToConsumeMultipleDataFiles(50);
1:a7178a4: 
1:a7178a4:         int numFiles = getNumberOfJournalFiles();
1:a7178a4: 
1:a7178a4:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1:a7178a4: 
1:a7178a4:         corruptBatchMiddle(3);
1:a7178a4: 
1:a7178a4:         restartBroker();
1:a7178a4: 
1:a7178a4:         assertEquals("missing one message", 49, broker.getAdminView().getTotalMessageCount());
1:a7178a4:         assertEquals("Drain", 49, drainQueue(49));
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     @Test
1:a7178a4:     public void testRecoveryAfterCorruptionEnd() throws Exception {
1:a7178a4:         startBroker();
1:a7178a4: 
1:a7178a4:         produceMessagesToConsumeMultipleDataFiles(50);
1:a7178a4: 
1:a7178a4:         int numFiles = getNumberOfJournalFiles();
1:a7178a4: 
1:a7178a4:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1:a7178a4: 
1:a7178a4:         corruptBatchEnd(4);
1:a7178a4: 
1:a7178a4:         restartBroker();
1:a7178a4: 
1:a7178a4:         assertEquals("missing one message", 49, broker.getAdminView().getTotalMessageCount());
1:a7178a4:         assertEquals("Drain", 49, drainQueue(49));
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     @Test
1:a7178a4:     public void testRecoveryAfterCorruption() throws Exception {
1:a7178a4:         startBroker();
1:a7178a4: 
1:a7178a4:         produceMessagesToConsumeMultipleDataFiles(50);
1:a7178a4: 
1:a7178a4:         int numFiles = getNumberOfJournalFiles();
1:a7178a4: 
1:a7178a4:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1:a7178a4: 
1:a7178a4:         corruptBatchMiddle(3);
1:a7178a4:         corruptBatchEnd(4);
1:a7178a4: 
1:a7178a4:         restartBroker();
1:a7178a4: 
1:a7178a4:         assertEquals("missing one message", 48, broker.getAdminView().getTotalMessageCount());
1:a7178a4:         assertEquals("Drain", 48, drainQueue(48));
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private void whackIndex(File dataDir) {
1:a7178a4:         File indexToDelete = new File(dataDir, "db.data");
1:a7178a4:         LOG.info("Whacking index: " + indexToDelete);
1:a7178a4:         indexToDelete.delete();
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private void corruptBatchMiddle(int i) throws IOException {
1:a7178a4:         corruptBatch(i, false);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private void corruptBatchEnd(int i) throws IOException {
1:a7178a4:         corruptBatch(i, true);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private void corruptBatch(int id, boolean atEnd) throws IOException {
1:a7178a4: 
1:13044de:         Collection<DataFile> files = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
1:a7178a4:         DataFile dataFile = (DataFile) files.toArray()[id];
1:a7178a4: 
1:a7178a4:         RecoverableRandomAccessFile randomAccessFile = dataFile.openRandomAccessFile();
1:a7178a4: 
1:a7178a4:         final ByteSequence header = new ByteSequence(Journal.BATCH_CONTROL_RECORD_HEADER);
1:a7178a4:         byte data[] = new byte[1024 * 20];
1:a7178a4: 
1:a7178a4:         ByteSequence bs = new ByteSequence(data, 0, randomAccessFile.read(data, 0, data.length));
1:a7178a4: 
1:a7178a4:         int pos = 0;
1:a7178a4:         int offset = 0;
1:a7178a4:         int end = atEnd ? Integer.MAX_VALUE : 3;
1:a7178a4:         for (int i = 0; i < end; i++) {
1:a7178a4:             int found = bs.indexOf(header, pos);
1:a7178a4:             if (found == -1) {
1:a7178a4:                 break;
1:a7178a4:             }
1:a7178a4:             offset = found;
1:a7178a4:             pos++;
1:a7178a4:         }
1:a7178a4: 
1:a7178a4:         LOG.info("Whacking batch record in file:" + id + ", at offset: " + offset + " with fill:" + fill);
1:a7178a4:         // whack that record
1:a7178a4:         byte[] bla = new byte[Journal.BATCH_CONTROL_RECORD_HEADER.length];
1:a7178a4:         Arrays.fill(bla, fill);
1:a7178a4:         randomAccessFile.seek(offset);
1:a7178a4:         randomAccessFile.write(bla, 0, bla.length);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private int getNumberOfJournalFiles() throws IOException {
1:13044de:         Collection<DataFile> files = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
1:a7178a4:         int reality = 0;
1:a7178a4:         for (DataFile file : files) {
1:a7178a4:             if (file != null) {
1:a7178a4:                 reality++;
1:a7178a4:             }
1:a7178a4:         }
1:a7178a4:         return reality;
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private int produceMessages(Destination destination, int numToSend) throws Exception {
1:a7178a4:         int sent = 0;
1:13044de:         Connection connection = new ActiveMQConnectionFactory(broker.getTransportConnectors().get(0).getConnectUri()).createConnection();
2:a7178a4:         connection.start();
1:a7178a4:         try {
2:a7178a4:             Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:a7178a4:             MessageProducer producer = session.createProducer(destination);
1:a7178a4:             for (int i = 0; i < numToSend; i++) {
1:a7178a4:                 producer.send(createMessage(session, i));
1:a7178a4:                 sent++;
1:a7178a4:             }
1:a7178a4:         } finally {
2:a7178a4:             connection.close();
1:a7178a4:         }
1:a7178a4: 
1:a7178a4:         return sent;
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private int produceMessagesToConsumeMultipleDataFiles(int numToSend) throws Exception {
1:a7178a4:         return produceMessages(destination, numToSend);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private Message createMessage(Session session, int i) throws Exception {
1:a7178a4:         return session.createTextMessage(payload + "::" + i);
1:a7178a4:     }
1:a7178a4: 
1:a7178a4:     private int drainQueue(int max) throws Exception {
1:822e2be:         return drain(cf, destination, max);
1:a7178a4:     }
1:822e2be: 
1:a7178a4: }
============================================================================
author:gtully
-------------------------------------------------------------------------------
commit:822e2be
/////////////////////////////////////////////////////////////////////////
1: import static org.apache.activemq.store.kahadb.JournalCorruptionEofIndexRecoveryTest.drain;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.disk.journal.Location;
/////////////////////////////////////////////////////////////////////////
1:         return drain(cf, destination, max);
1: 
commit:62bdbb0
/////////////////////////////////////////////////////////////////////////
1: 
1:         adapter.setPreallocationScope(Journal.PreallocationScope.ENTIRE_JOURNAL_ASYNC.name());
commit:a7178a4
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *      http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.activemq.store.kahadb;
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.util.Arrays;
1: import java.util.Collection;
1: import javax.jms.Connection;
1: import javax.jms.Destination;
1: import javax.jms.Message;
1: import javax.jms.MessageConsumer;
1: import javax.jms.MessageProducer;
1: import javax.jms.Session;
1: import org.apache.activemq.ActiveMQConnectionFactory;
1: import org.apache.activemq.broker.BrokerService;
1: import org.apache.activemq.command.ActiveMQQueue;
1: import org.apache.activemq.store.kahadb.disk.journal.DataFile;
1: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1: import org.apache.activemq.util.ByteSequence;
1: import org.apache.activemq.util.RecoverableRandomAccessFile;
1: import org.junit.After;
1: import org.junit.Test;
1: import org.junit.runner.RunWith;
1: import org.junit.runners.Parameterized;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: 
1: import static org.junit.Assert.assertEquals;
1: import static org.junit.Assert.assertTrue;
1: 
1: 
1: @RunWith(Parameterized.class)
1: public class JournalCorruptionIndexRecoveryTest {
1: 
1:     private static final Logger LOG = LoggerFactory.getLogger(JournalCorruptionIndexRecoveryTest.class);
1: 
0:     ActiveMQConnectionFactory cf = null;
0:     BrokerService broker = null;
1:     private final Destination destination = new ActiveMQQueue("Test");
1:     private String connectionUri;
1:     private KahaDBPersistenceAdapter adapter;
1: 
1:     @Parameterized.Parameter(0)
1:     public byte fill = Byte.valueOf("3");
1: 
1:     @Parameterized.Parameters(name = "fill=#{0}")
1:     public static Iterable<Object[]> parameters() {
1:         // corruption can be valid record type values
1:         return Arrays.asList(new Object[][]{{Byte.valueOf("1")}, {Byte.valueOf("0")}, {Byte.valueOf("2")}, {Byte.valueOf("-1")} });
1:     }
1: 
1:     protected void startBroker() throws Exception {
1:         doStartBroker(true);
1:     }
1: 
1: 
1:     protected void restartBroker() throws Exception {
1:         File dataDir = broker.getPersistenceAdapter().getDirectory();
1: 
1:         if (broker != null) {
1:             broker.stop();
1:             broker.waitUntilStopped();
1:         }
1: 
1:         whackIndex(dataDir);
1: 
1:         doStartBroker(false);
1:     }
1: 
1: 
1:     private void doStartBroker(boolean delete) throws Exception {
1:         broker = new BrokerService();
1:         broker.setDeleteAllMessagesOnStartup(delete);
1:         broker.setPersistent(true);
1:         broker.setUseJmx(true);
1:         broker.addConnector("tcp://localhost:0");
1: 
1:         configurePersistence(broker);
1: 
1:         connectionUri = "vm://localhost?create=false";
1:         cf = new ActiveMQConnectionFactory(connectionUri);
1: 
1:         broker.start();
1:         LOG.info("Starting broker..");
1:     }
1: 
1:     protected void configurePersistence(BrokerService brokerService) throws Exception {
1:         adapter = (KahaDBPersistenceAdapter) brokerService.getPersistenceAdapter();
1: 
1:         // ensure there are a bunch of data files but multiple entries in each
1:         adapter.setJournalMaxFileLength(1024 * 20);
1: 
1:         // speed up the test case, checkpoint an cleanup early and often
1:         adapter.setCheckpointInterval(5000);
1:         adapter.setCleanupInterval(5000);
1: 
1:         adapter.setCheckForCorruptJournalFiles(true);
1:         adapter.setIgnoreMissingJournalfiles(true);
1: 
1:     }
1: 
1:     @After
1:     public void tearDown() throws Exception {
1:         if (broker != null) {
1:             broker.stop();
1:             broker.waitUntilStopped();
1:         }
1:     }
1: 
1:     @Test
1:     public void testRecoveryAfterCorruptionMiddle() throws Exception {
1:         startBroker();
1: 
1:         produceMessagesToConsumeMultipleDataFiles(50);
1: 
1:         int numFiles = getNumberOfJournalFiles();
1: 
1:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1: 
1:         corruptBatchMiddle(3);
1: 
1:         restartBroker();
1: 
1:         assertEquals("missing one message", 49, broker.getAdminView().getTotalMessageCount());
1: 
1:         assertEquals("Drain", 49, drainQueue(49));
1:     }
1: 
1: 
1:     @Test
1:     public void testRecoveryAfterCorruptionEnd() throws Exception {
1:         startBroker();
1: 
1:         produceMessagesToConsumeMultipleDataFiles(50);
1: 
1:         int numFiles = getNumberOfJournalFiles();
1: 
1:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1: 
1:         corruptBatchEnd(4);
1: 
1:         restartBroker();
1: 
1:         assertEquals("missing one message", 49, broker.getAdminView().getTotalMessageCount());
1: 
1:         assertEquals("Drain", 49, drainQueue(49));
1: 
1:     }
1: 
1:     @Test
1:     public void testRecoveryAfterCorruption() throws Exception {
1:         startBroker();
1: 
1:         produceMessagesToConsumeMultipleDataFiles(50);
1: 
1:         int numFiles = getNumberOfJournalFiles();
1: 
1:         assertTrue("more than x files: " + numFiles, numFiles > 4);
1: 
1:         corruptBatchMiddle(3);
1:         corruptBatchEnd(4);
1: 
1:         restartBroker();
1: 
1:         assertEquals("missing one message", 48, broker.getAdminView().getTotalMessageCount());
1:         assertEquals("Drain", 48, drainQueue(48));
1: 
1:     }
1: 
1:     private void whackIndex(File dataDir) {
1: 
1:         File indexToDelete = new File(dataDir, "db.data");
1:         LOG.info("Whacking index: " + indexToDelete);
1:         indexToDelete.delete();
1: 
1:     }
1: 
1:     private void corruptBatchMiddle(int i) throws IOException {
1:         corruptBatch(i, false);
1:     }
1: 
1:     private void corruptBatchEnd(int i) throws IOException {
1:         corruptBatch(i, true);
1:     }
1: 
1:     private void corruptBatch(int id, boolean atEnd) throws IOException {
1: 
0:         Collection<DataFile> files =
0:                 ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
1:         DataFile dataFile = (DataFile) files.toArray()[id];
1: 
1:         RecoverableRandomAccessFile randomAccessFile = dataFile.openRandomAccessFile();
1: 
1:         final ByteSequence header = new ByteSequence(Journal.BATCH_CONTROL_RECORD_HEADER);
1:         byte data[] = new byte[1024 * 20];
1: 
1:         ByteSequence bs = new ByteSequence(data, 0, randomAccessFile.read(data, 0, data.length));
1: 
1:         int pos = 0;
1:         int offset = 0;
1:         int end = atEnd ? Integer.MAX_VALUE : 3;
1:         for (int i = 0; i < end; i++) {
1:             int found = bs.indexOf(header, pos);
1:             if (found == -1) {
1:                 break;
1:             }
1:             offset = found;
1:             pos++;
1:         }
1: 
1:         LOG.info("Whacking batch record in file:" + id + ", at offset: " + offset + " with fill:" + fill);
1:         // whack that record
1:         byte[] bla = new byte[Journal.BATCH_CONTROL_RECORD_HEADER.length];
1:         Arrays.fill(bla, fill);
1:         randomAccessFile.seek(offset);
1:         randomAccessFile.write(bla, 0, bla.length);
1:     }
1: 
1: 
1:     private int getNumberOfJournalFiles() throws IOException {
1: 
0:         Collection<DataFile> files =
0:                 ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
1:         int reality = 0;
1:         for (DataFile file : files) {
1:             if (file != null) {
1:                 reality++;
1:             }
1:         }
1:         return reality;
1:     }
1: 
1: 
1:     private int produceMessages(Destination destination, int numToSend) throws Exception {
1:         int sent = 0;
0:         Connection connection = new ActiveMQConnectionFactory(
0:                 broker.getTransportConnectors().get(0).getConnectUri()).createConnection();
1:         connection.start();
1:         try {
1:             Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:             MessageProducer producer = session.createProducer(destination);
1:             for (int i = 0; i < numToSend; i++) {
1:                 producer.send(createMessage(session, i));
1:                 sent++;
1:             }
1:         } finally {
1:             connection.close();
1:         }
1: 
1:         return sent;
1:     }
1: 
1:     private int produceMessagesToConsumeMultipleDataFiles(int numToSend) throws Exception {
1:         return produceMessages(destination, numToSend);
1:     }
1: 
0:     final String payload = new String(new byte[1024]);
1: 
1:     private Message createMessage(Session session, int i) throws Exception {
1:         return session.createTextMessage(payload + "::" + i);
1:     }
1: 
1:     private int drainQueue(int max) throws Exception {
0:         Connection connection = cf.createConnection();
1:         connection.start();
1:         Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
0:         MessageConsumer consumer = session.createConsumer(destination);
0:         int count = 0;
0:         while (count < max && consumer.receive(5000) != null) {
0:             count++;
1:         }
0:         consumer.close();
1:         connection.close();
0:         return count;
1:     }
1: }
author:Timothy Bish
-------------------------------------------------------------------------------
commit:13044de
/////////////////////////////////////////////////////////////////////////
0: import static org.junit.Assert.assertEquals;
0: import static org.junit.Assert.assertTrue;
0: 
0: 
0: 
/////////////////////////////////////////////////////////////////////////
1:     private final String KAHADB_DIRECTORY = "target/activemq-data/";
1:     private final String payload = new String(new byte[1024]);
0: 
1:     private ActiveMQConnectionFactory cf = null;
1:     private BrokerService broker = null;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         broker.setDataDirectory(KAHADB_DIRECTORY);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         Collection<DataFile> files = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
/////////////////////////////////////////////////////////////////////////
1:         Collection<DataFile> files = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getStore().getJournal().getFileMap().values();
/////////////////////////////////////////////////////////////////////////
1:         Connection connection = new ActiveMQConnectionFactory(broker.getTransportConnectors().get(0).getConnectUri()).createConnection();
/////////////////////////////////////////////////////////////////////////
============================================================================
1:f1f9348: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:f1f9348:  *
1:f1f9348:  *    http://www.apache.org/licenses/LICENSE-2.0
1:f1f9348:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
2:f1f9348:  */
13:f1f9348: 
1:349c59c: package org.apache.carbondata.processing.loading.sort.unsafe.merger;
1:a734add: 
1:f1f9348: import java.io.DataOutputStream;
1:f1f9348: import java.io.File;
1:f1f9348: import java.io.FileNotFoundException;
1:f1f9348: import java.io.IOException;
1:f1f9348: import java.util.AbstractQueue;
1:7ef9164: import java.util.NoSuchElementException;
1:f1f9348: import java.util.PriorityQueue;
1:a734add: import java.util.concurrent.Callable;
1:f1f9348: 
1:f1f9348: import org.apache.carbondata.common.logging.LogService;
1:f1f9348: import org.apache.carbondata.common.logging.LogServiceFactory;
1:c100251: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:f1f9348: import org.apache.carbondata.core.util.CarbonUtil;
1:2b41f14: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.SortTempChunkHolder;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
1:349c59c: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1:349c59c: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
1:2b41f14: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
1:f1f9348: 
1:a734add: public class UnsafeIntermediateFileMerger implements Callable<Void> {
2:f1f9348:   /**
1:f1f9348:    * LOGGER
1:f1f9348:    */
1:f1f9348:   private static final LogService LOGGER =
1:f1f9348:       LogServiceFactory.getLogService(UnsafeIntermediateFileMerger.class.getName());
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * recordHolderHeap
1:f1f9348:    */
1:f1f9348:   private AbstractQueue<SortTempChunkHolder> recordHolderHeap;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * fileCounter
1:f1f9348:    */
1:f1f9348:   private int fileCounter;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * stream
1:f1f9348:    */
1:f1f9348:   private DataOutputStream stream;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * totalNumberOfRecords
1:f1f9348:    */
1:f1f9348:   private int totalNumberOfRecords;
1:8d8b589: 
1:f1f9348:   private SortParameters mergerParameters;
1:2b41f14:   private TableFieldStat tableFieldStat;
1:f1f9348:   private File[] intermediateFiles;
1:f1f9348:   private File outPutFile;
1:8d8b589: 
1:c100251:   private int writeBufferSize;
1:c100251:   private String compressorName;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:8d8b589: 
1:a734add:   private Throwable throwable;
1:8d8b589: 
1:f1f9348:   /**
1:f1f9348:    * IntermediateFileMerger Constructor
1:f1f9348:    */
1:f1f9348:   public UnsafeIntermediateFileMerger(SortParameters mergerParameters, File[] intermediateFiles,
1:f1f9348:       File outPutFile) {
1:f1f9348:     this.mergerParameters = mergerParameters;
1:f1f9348:     this.fileCounter = intermediateFiles.length;
1:f1f9348:     this.intermediateFiles = intermediateFiles;
1:f1f9348:     this.outPutFile = outPutFile;
1:c100251:     this.writeBufferSize = mergerParameters.getBufferSize();
1:c100251:     this.compressorName = mergerParameters.getSortTempCompressorName();
1:2b41f14:     this.tableFieldStat = new TableFieldStat(mergerParameters);
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:956833e:   }
1:f1f9348: 
1:a734add:   @Override public Void call() throws Exception {
1:f1f9348:     long intermediateMergeStartTime = System.currentTimeMillis();
1:f1f9348:     int fileConterConst = fileCounter;
2:f1f9348:     try {
1:f1f9348:       startSorting();
1:f1f9348:       initialize();
1:f1f9348:       while (hasNext()) {
1:c100251:         writeDataToFile(next());
1:98df130:       }
1:f1f9348:       double intermediateMergeCostTime =
1:f1f9348:           (System.currentTimeMillis() - intermediateMergeStartTime) / 1000.0;
1:f1f9348:       LOGGER.info("============================== Intermediate Merge of " + fileConterConst
1:f1f9348:           + " Sort Temp Files Cost Time: " + intermediateMergeCostTime + "(s)");
1:f1f9348:     } catch (Exception e) {
1:f1f9348:       LOGGER.error(e, "Problem while intermediate merging");
1:a734add:       clear();
1:a734add:       throwable = e;
1:f1f9348:     } finally {
1:f1f9348:       CarbonUtil.closeStreams(this.stream);
1:a734add:       if (null == throwable) {
1:f1f9348:         try {
1:f1f9348:           finish();
1:f1f9348:         } catch (CarbonSortKeyAndGroupByException e) {
1:f1f9348:           LOGGER.error(e, "Problem while deleting the merge file");
1:a734add:           throwable = e;
23:f1f9348:         }
2:8d8b589:       } else {
1:a734add:         if (!outPutFile.delete()) {
1:f1f9348:           LOGGER.error("Problem while deleting the merge file");
1:8d8b589:         }
1:8d8b589:       }
1:8d8b589:     }
1:a734add:     if (null != throwable) {
1:a734add:       throw new CarbonSortKeyAndGroupByException(throwable);
1:8d8b589:     }
1:a734add:     return null;
1:8d8b589:   }
1:8d8b589: 
1:f1f9348:   /**
1:f1f9348:    * This method is responsible for initializing the out stream
1:f1f9348:    *
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException
1:f1f9348:    */
1:f1f9348:   private void initialize() throws CarbonSortKeyAndGroupByException {
1:c100251:     try {
1:c100251:       stream = FileFactory.getDataOutputStream(outPutFile.getPath(), FileFactory.FileType.LOCAL,
1:c100251:           writeBufferSize, compressorName);
1:c100251:       this.stream.writeInt(this.totalNumberOfRecords);
1:c100251:     } catch (FileNotFoundException e) {
1:c100251:       throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
1:c100251:     } catch (IOException e) {
1:c100251:       throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
1:8d8b589:     }
1:8d8b589:   }
1:f1f9348: 
1:f1f9348:   /**
1:2b41f14:    * This method will be used to get sorted sort temp row from the sort temp files
1:f1f9348:    *
1:f1f9348:    * @return sorted record sorted record
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow getSortedRecordFromFile()
1:2b41f14:       throws CarbonSortKeyAndGroupByException {
1:2b41f14:     IntermediateSortTempRow row = null;
1:f1f9348: 
1:f1f9348:     // poll the top object from heap
1:f1f9348:     // heap maintains binary tree which is based on heap condition that will
1:f1f9348:     // be based on comparator we are passing the heap
1:f1f9348:     // when will call poll it will always delete root of the tree and then
1:f1f9348:     // it does trickel down operation complexity is log(n)
1:f1f9348:     SortTempChunkHolder poll = this.recordHolderHeap.poll();
1:f1f9348: 
1:f1f9348:     // get the row from chunk
1:f1f9348:     row = poll.getRow();
1:f1f9348: 
1:f1f9348:     // check if there no entry present
1:f1f9348:     if (!poll.hasNext()) {
1:f1f9348:       // if chunk is empty then close the stream
1:f1f9348:       poll.close();
1:f1f9348: 
1:f1f9348:       // change the file counter
1:f1f9348:       --this.fileCounter;
1:f1f9348: 
1:f1f9348:       // reaturn row
1:f1f9348:       return row;
1:a734add:     }
1:f1f9348: 
1:f1f9348:     // read new row
1:f1f9348:     poll.readRow();
1:f1f9348: 
1:f1f9348:     // add to heap
1:f1f9348:     this.recordHolderHeap.add(poll);
1:f1f9348: 
1:f1f9348:     // return row
1:f1f9348:     return row;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * Below method will be used to start storing process This method will get
1:f1f9348:    * all the temp files present in sort temp folder then it will create the
1:f1f9348:    * record holder heap and then it will read first record from each file and
1:f1f9348:    * initialize the heap
1:f1f9348:    *
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException
1:f1f9348:    */
1:f1f9348:   private void startSorting() throws CarbonSortKeyAndGroupByException {
1:f1f9348:     LOGGER.info("Number of temp file: " + this.fileCounter);
1:f1f9348: 
1:f1f9348:     // create record holder heap
1:f1f9348:     createRecordHolderQueue(intermediateFiles);
1:f1f9348: 
1:f1f9348:     // iterate over file list and create chunk holder and add to heap
1:f1f9348:     LOGGER.info("Started adding first record from each file");
1:f1f9348: 
1:f1f9348:     SortTempChunkHolder sortTempFileChunkHolder = null;
1:f1f9348: 
1:f1f9348:     for (File tempFile : intermediateFiles) {
1:f1f9348:       // create chunk holder
1:f27efb3:       sortTempFileChunkHolder =
1:f27efb3:           new UnsafeSortTempFileChunkHolder(tempFile, mergerParameters, false);
1:f1f9348: 
1:f1f9348:       sortTempFileChunkHolder.readRow();
1:f1f9348:       this.totalNumberOfRecords += sortTempFileChunkHolder.numberOfRows();
1:f1f9348: 
1:f1f9348:       // add to heap
1:f1f9348:       this.recordHolderHeap.add(sortTempFileChunkHolder);
1:f1f9348:     }
1:f1f9348: 
1:2b41f14:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to create the heap which will be used to hold
1:f1f9348:    * the chunk of data
1:f1f9348:    *
1:f1f9348:    * @param listFiles list of temp files
1:f1f9348:    */
1:f1f9348:   private void createRecordHolderQueue(File[] listFiles) {
1:f1f9348:     // creating record holder heap
1:f1f9348:     this.recordHolderHeap = new PriorityQueue<SortTempChunkHolder>(listFiles.length);
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:2b41f14:    * This method will be used to get the sorted sort temp row
1:f1f9348:    *
1:f1f9348:    * @return sorted row
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
1:7ef9164:     if (hasNext()) {
1:7ef9164:       return getSortedRecordFromFile();
1:7ef9164:     } else {
1:7ef9164:       throw new NoSuchElementException("No more elements to return");
1:7ef9164:     }
1:7ef9164: 
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to check whether any more element is present or
1:f1f9348:    * not
1:f1f9348:    *
1:f1f9348:    * @return more element is present
1:f1f9348:    */
1:f1f9348:   private boolean hasNext() {
1:f1f9348:     return this.fileCounter > 0;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * Below method will be used to write data to file
1:f1f9348:    *
1:2b41f14:    * @throws IOException problem while writing
1:f1f9348:    */
1:2b41f14:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
1:2b41f14:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
1:8d8b589:   }
1:f1f9348: 
1:f1f9348:   private void finish() throws CarbonSortKeyAndGroupByException {
1:a734add:     clear();
1:f1f9348:     try {
1:f1f9348:       CarbonUtil.deleteFiles(intermediateFiles);
1:eaadc88:     } catch (IOException e) {
1:f1f9348:       throw new CarbonSortKeyAndGroupByException("Problem while deleting the intermediate files");
1:f1f9348:     }
1:f1f9348:   }
1:a734add: 
1:a734add:   private void clear() {
1:a734add:     if (null != recordHolderHeap) {
1:a734add:       SortTempChunkHolder sortTempChunkHolder;
1:a734add:       while (!recordHolderHeap.isEmpty()) {
1:a734add:         sortTempChunkHolder = recordHolderHeap.poll();
1:a734add:         if (null != sortTempChunkHolder) {
1:a734add:           sortTempChunkHolder.close();
1:a734add:         }
1:a734add:       }
1:a734add:     }
1:a734add:   }
1:f1f9348: }
============================================================================
author:kumarvishal09
-------------------------------------------------------------------------------
commit:f27efb3
/////////////////////////////////////////////////////////////////////////
1:       sortTempFileChunkHolder =
1:           new UnsafeSortTempFileChunkHolder(tempFile, mergerParameters, false);
author:Raghunandan S
-------------------------------------------------------------------------------
commit:7ef9164
/////////////////////////////////////////////////////////////////////////
1: import java.util.NoSuchElementException;
/////////////////////////////////////////////////////////////////////////
1:     if (hasNext()) {
1:       return getSortedRecordFromFile();
1:     } else {
1:       throw new NoSuchElementException("No more elements to return");
1:     }
1: 
commit:06b0d08
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: public class UnsafeIntermediateFileMerger implements Runnable {
/////////////////////////////////////////////////////////////////////////
0:   @Override
0:   public void run() {
/////////////////////////////////////////////////////////////////////////
author:xuchuanyin
-------------------------------------------------------------------------------
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
/////////////////////////////////////////////////////////////////////////
1:   private TableFieldStat tableFieldStat;
1:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:     this.tableFieldStat = new TableFieldStat(mergerParameters);
1:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to get sorted sort temp row from the sort temp files
1:   private IntermediateSortTempRow getSortedRecordFromFile()
1:       throws CarbonSortKeyAndGroupByException {
1:     IntermediateSortTempRow row = null;
/////////////////////////////////////////////////////////////////////////
1:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to get the sorted sort temp row
1:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
1:    * @throws IOException problem while writing
1:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
1:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
0: import java.math.BigDecimal;
0: import java.nio.ByteBuffer;
0: import java.util.Arrays;
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
/////////////////////////////////////////////////////////////////////////
1: 
1: 
0:   private int dimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
1: 
0:   private long[] nullSetWords;
1: 
0:   private ByteBuffer rowData;
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = mergerParameters.getDimColCount();
0:     this.complexCnt = mergerParameters.getComplexDimColCount();
0:     this.measureCnt = mergerParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = mergerParameters.getNoDictionaryDimnesionColumn();
0:     this.measureDataTypes = mergerParameters.getMeasureDataType();
0:     this.nullSetWords = new long[((measureCnt - 1) >> 6) + 1];
0:     // Take size of 2 MB for each row. I think it is high enough to use
0:     rowData = ByteBuffer.allocate(2 * 1024 * 1024);
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted record from file
0:   private Object[] getSortedRecordFromFile() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = null;
/////////////////////////////////////////////////////////////////////////
0:     LOGGER.info("Heap Size" + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted row
0:   private Object[] next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:    * @throws CarbonSortKeyAndGroupByException problem while writing
0:   private void writeDataToFile(Object[] row) throws CarbonSortKeyAndGroupByException, IOException {
0:     int dimCount = 0;
0:     int size = 0;
0:     for (; dimCount < isNoDictionaryDimensionColumn.length; dimCount++) {
0:       if (isNoDictionaryDimensionColumn[dimCount]) {
0:         byte[] col = (byte[]) row[dimCount];
0:         rowData.putShort((short) col.length);
0:         size += 2;
0:         rowData.put(col);
0:         size += col.length;
1:       } else {
0:         rowData.putInt((int) row[dimCount]);
0:         size += 4;
1:       }
1:     }
1: 
0:     // write complex dimensions here.
0:     int dimensionSize = dimCnt + complexCnt;
0:     for (; dimCount < dimensionSize; dimCount++) {
0:       byte[] col = (byte[]) row[dimCount];
0:       rowData.putShort((short)col.length);
0:       size += 2;
0:       rowData.put(col);
0:       size += col.length;
1:     }
0:     Arrays.fill(nullSetWords, 0);
0:     int nullSetSize = nullSetWords.length * 8;
0:     int nullLoc = size;
0:     size += nullSetSize;
0:     for (int mesCount = 0; mesCount < measureCnt; mesCount++) {
0:       Object value = row[mesCount + dimensionSize];
0:       if (null != value) {
0:         DataType dataType = measureDataTypes[mesCount];
0:         if (dataType == DataTypes.SHORT) {
0:           rowData.putShort(size, (Short) value);
0:           size += 2;
0:         } else if (dataType == DataTypes.INT) {
0:           rowData.putInt(size, (Integer) value);
0:           size += 4;
0:         } else if (dataType == DataTypes.LONG) {
0:           rowData.putLong(size, (Long) value);
0:           size += 8;
0:         } else if (dataType == DataTypes.DOUBLE) {
0:           rowData.putDouble(size, (Double) value);
0:           size += 8;
0:         } else if (DataTypes.isDecimal(dataType)) {
0:           byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(((BigDecimal) value));
0:           rowData.putShort(size, (short) bigDecimalInBytes.length);
0:           size += 2;
0:           for (int i = 0; i < bigDecimalInBytes.length; i++) {
0:             rowData.put(size++, bigDecimalInBytes[i]);
1:           }
1:         }
0:         UnsafeCarbonRowPage.set(nullSetWords, mesCount);
1:       } else {
0:         UnsafeCarbonRowPage.unset(nullSetWords, mesCount);
1:       }
1:     }
0:     for (int i = 0; i < nullSetWords.length; i++) {
0:       rowData.putLong(nullLoc, nullSetWords[i]);
0:       nullLoc += 8;
1:     }
0:     byte[] rowBytes = new byte[size];
0:     rowData.position(0);
0:     rowData.get(rowBytes);
0:     stream.write(rowBytes);
0:     rowData.clear();
0:       rowData.clear();
commit:21704cf
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
0: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
/////////////////////////////////////////////////////////////////////////
0:   private TableFieldStat tableFieldStat;
0:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:     this.tableFieldStat = new TableFieldStat(mergerParameters);
0:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get sorted sort temp row from the sort temp files
0:   private IntermediateSortTempRow getSortedRecordFromFile()
0:       throws CarbonSortKeyAndGroupByException {
0:     IntermediateSortTempRow row = null;
/////////////////////////////////////////////////////////////////////////
0:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted sort temp row
0:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:    * @throws IOException problem while writing
0:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
0:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
commit:c100251
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   private int dimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
1:   private int writeBufferSize;
1:   private String compressorName;
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = mergerParameters.getDimColCount();
0:     this.complexCnt = mergerParameters.getComplexDimColCount();
0:     this.measureCnt = mergerParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = mergerParameters.getNoDictionaryDimnesionColumn();
0:     this.measureDataTypes = mergerParameters.getMeasureDataType();
1:     this.writeBufferSize = mergerParameters.getBufferSize();
1:     this.compressorName = mergerParameters.getSortTempCompressorName();
0:     this.nullSetWords = new long[((measureCnt - 1) >> 6) + 1];
/////////////////////////////////////////////////////////////////////////
1:         writeDataToFile(next());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       stream = FileFactory.getDataOutputStream(outPutFile.getPath(), FileFactory.FileType.LOCAL,
1:           writeBufferSize, compressorName);
1:       this.stream.writeInt(this.totalNumberOfRecords);
1:     } catch (FileNotFoundException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
1:     } catch (IOException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
/////////////////////////////////////////////////////////////////////////
0:   private void writeDataToFile(Object[] row) throws CarbonSortKeyAndGroupByException, IOException {
0:     for (; dimCount < isNoDictionaryDimensionColumn.length; dimCount++) {
0:       if (isNoDictionaryDimensionColumn[dimCount]) {
/////////////////////////////////////////////////////////////////////////
0:     int dimensionSize = dimCnt + complexCnt;
/////////////////////////////////////////////////////////////////////////
0:     for (int mesCount = 0; mesCount < measureCnt; mesCount++) {
0:         DataType dataType = measureDataTypes[mesCount];
author:Bhavya
-------------------------------------------------------------------------------
commit:e5e74fc
/////////////////////////////////////////////////////////////////////////
0: import java.math.BigDecimal;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
0:           byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(((BigDecimal) value));
author:Jacky Li
-------------------------------------------------------------------------------
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:         } else if (DataTypes.isDecimal(dataType)) {
commit:956833e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:         DataType dataType = type[mesCount];
0:         if (dataType == DataTypes.SHORT) {
0:           rowData.putShort(size, (Short) value);
0:           size += 2;
0:         } else if (dataType == DataTypes.INT) {
0:           rowData.putInt(size, (Integer) value);
0:           size += 4;
0:         } else if (dataType == DataTypes.LONG) {
0:           rowData.putLong(size, (Long) value);
0:           size += 8;
0:         } else if (dataType == DataTypes.DOUBLE) {
0:           rowData.putDouble(size, (Double) value);
0:           size += 8;
0:         } else if (dataType == DataTypes.DECIMAL) {
0:           byte[] bigDecimalInBytes = (byte[]) value;
0:           rowData.putShort(size, (short) bigDecimalInBytes.length);
0:           size += 2;
0:           for (int i = 0; i < bigDecimalInBytes.length; i++) {
0:             rowData.put(size++, bigDecimalInBytes[i]);
1:           }
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.loading.sort.unsafe.merger;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.SortTempChunkHolder;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
1: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
0: import org.apache.carbondata.processing.sort.sortdata.TempSortFileWriter;
0: import org.apache.carbondata.processing.sort.sortdata.TempSortFileWriterFactory;
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.Callable;
/////////////////////////////////////////////////////////////////////////
1: public class UnsafeIntermediateFileMerger implements Callable<Void> {
/////////////////////////////////////////////////////////////////////////
1:   private Throwable throwable;
1: 
/////////////////////////////////////////////////////////////////////////
1:   @Override public Void call() throws Exception {
/////////////////////////////////////////////////////////////////////////
1:       clear();
1:       throwable = e;
1:       if (null == throwable) {
1:           throwable = e;
1:         if (!outPutFile.delete()) {
1:     if (null != throwable) {
1:       throw new CarbonSortKeyAndGroupByException(throwable);
1:     }
1:     return null;
/////////////////////////////////////////////////////////////////////////
1:     clear();
/////////////////////////////////////////////////////////////////////////
1: 
1:   private void clear() {
1:     if (null != recordHolderHeap) {
1:       SortTempChunkHolder sortTempChunkHolder;
1:       while (!recordHolderHeap.isEmpty()) {
1:         sortTempChunkHolder = recordHolderHeap.poll();
1:         if (null != sortTempChunkHolder) {
1:           sortTempChunkHolder.close();
1:         }
1:       }
1:     }
1:   }
author:anubhav100
-------------------------------------------------------------------------------
commit:eb0405d
/////////////////////////////////////////////////////////////////////////
0:             rowData.putShort(size, (Short) value);
0:             size += 2;
0:             break;
0:             rowData.putInt(size, (Integer) value);
0:             size += 4;
0:             break;
author:jackylk
-------------------------------------------------------------------------------
commit:98df130
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
/////////////////////////////////////////////////////////////////////////
0:     DataType[] type = mergerParameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:         switch (type[mesCount]) {
0:           case SHORT:
0:           case INT:
0:           case LONG:
0:             rowData.putLong(size, (Long) value);
0:             size += 8;
0:             break;
0:           case DOUBLE:
0:             rowData.putDouble(size, (Double) value);
0:             size += 8;
0:             break;
0:           case DECIMAL:
0:             byte[] bigDecimalInBytes = (byte[]) value;
0:             rowData.putShort(size, (short)bigDecimalInBytes.length);
0:             size += 2;
0:             for (int i = 0; i < bigDecimalInBytes.length; i++) {
0:               rowData.put(size++, bigDecimalInBytes[i]);
1:             }
0:             break;
commit:8cca0af
/////////////////////////////////////////////////////////////////////////
0:         if (aggType[mesCount] == CarbonCommonConstants.DOUBLE_MEASURE) {
commit:eaadc88
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     } catch (IOException e) {
author:ravipesala
-------------------------------------------------------------------------------
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
0:     int dimensionSize =
0:         mergerParameters.getDimColCount() + mergerParameters.getComplexDimColCount();
commit:aca59ce
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:           byte[] bigDecimalInBytes = (byte[]) value;
commit:f1f9348
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.newflow.sort.unsafe.merger;
1: 
0: import java.io.BufferedOutputStream;
1: import java.io.DataOutputStream;
1: import java.io.File;
1: import java.io.FileNotFoundException;
0: import java.io.FileOutputStream;
1: import java.io.IOException;
0: import java.math.BigDecimal;
0: import java.nio.ByteBuffer;
1: import java.util.AbstractQueue;
0: import java.util.Arrays;
1: import java.util.PriorityQueue;
0: import java.util.concurrent.Callable;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.core.util.CarbonUtilException;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.UnsafeCarbonRowPage;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.SortTempChunkHolder;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
0: import org.apache.carbondata.processing.sortandgroupby.exception.CarbonSortKeyAndGroupByException;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.SortParameters;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.TempSortFileWriter;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.TempSortFileWriterFactory;
1: 
0: public class UnsafeIntermediateFileMerger implements Callable<Void> {
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(UnsafeIntermediateFileMerger.class.getName());
1: 
1:   /**
1:    * recordHolderHeap
1:    */
1:   private AbstractQueue<SortTempChunkHolder> recordHolderHeap;
1: 
1:   /**
1:    * fileCounter
1:    */
1:   private int fileCounter;
1: 
1:   /**
1:    * stream
1:    */
1:   private DataOutputStream stream;
1: 
1:   /**
1:    * totalNumberOfRecords
1:    */
1:   private int totalNumberOfRecords;
1: 
1:   /**
0:    * writer
1:    */
0:   private TempSortFileWriter writer;
1: 
1:   private SortParameters mergerParameters;
1: 
1:   private File[] intermediateFiles;
1: 
1:   private File outPutFile;
1: 
0:   private boolean[] noDictionarycolumnMapping;
1: 
0:   private long[] nullSetWords;
1: 
0:   private ByteBuffer rowData;
1: 
1:   /**
1:    * IntermediateFileMerger Constructor
1:    */
1:   public UnsafeIntermediateFileMerger(SortParameters mergerParameters, File[] intermediateFiles,
1:       File outPutFile) {
1:     this.mergerParameters = mergerParameters;
1:     this.fileCounter = intermediateFiles.length;
1:     this.intermediateFiles = intermediateFiles;
1:     this.outPutFile = outPutFile;
0:     noDictionarycolumnMapping = mergerParameters.getNoDictionaryDimnesionColumn();
0:     this.nullSetWords = new long[((mergerParameters.getMeasureColCount() - 1) >> 6) + 1];
0:     // Take size of 2 MB for each row. I think it is high enough to use
0:     rowData = ByteBuffer.allocate(2*1024*1024);
1:   }
1: 
0:   @Override public Void call() throws Exception {
1:     long intermediateMergeStartTime = System.currentTimeMillis();
1:     int fileConterConst = fileCounter;
0:     boolean isFailed = false;
1:     try {
1:       startSorting();
1:       initialize();
1:       while (hasNext()) {
0:         writeDataTofile(next());
1:       }
1:       double intermediateMergeCostTime =
1:           (System.currentTimeMillis() - intermediateMergeStartTime) / 1000.0;
1:       LOGGER.info("============================== Intermediate Merge of " + fileConterConst
1:           + " Sort Temp Files Cost Time: " + intermediateMergeCostTime + "(s)");
1:     } catch (Exception e) {
1:       LOGGER.error(e, "Problem while intermediate merging");
0:       isFailed = true;
1:     } finally {
1:       CarbonUtil.closeStreams(this.stream);
0:       if (null != writer) {
0:         writer.finish();
1:       }
0:       if (!isFailed) {
1:         try {
1:           finish();
1:         } catch (CarbonSortKeyAndGroupByException e) {
1:           LOGGER.error(e, "Problem while deleting the merge file");
1:         }
0:       } else {
0:         if (outPutFile.delete()) {
1:           LOGGER.error("Problem while deleting the merge file");
1:         }
1:       }
1:     }
1: 
0:     return null;
1:   }
1: 
1:   /**
1:    * This method is responsible for initializing the out stream
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   private void initialize() throws CarbonSortKeyAndGroupByException {
0:     if (!mergerParameters.isSortFileCompressionEnabled() && !mergerParameters.isPrefetch()) {
1:       try {
0:         this.stream = new DataOutputStream(
0:             new BufferedOutputStream(new FileOutputStream(outPutFile),
0:                 mergerParameters.getFileWriteBufferSize()));
0:         this.stream.writeInt(this.totalNumberOfRecords);
0:       } catch (FileNotFoundException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
0:       } catch (IOException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
1:       }
0:     } else {
0:       writer = TempSortFileWriterFactory.getInstance()
0:           .getTempSortFileWriter(mergerParameters.isSortFileCompressionEnabled(),
0:               mergerParameters.getDimColCount(), mergerParameters.getComplexDimColCount(),
0:               mergerParameters.getMeasureColCount(), mergerParameters.getNoDictionaryCount(),
0:               mergerParameters.getFileWriteBufferSize());
0:       writer.initiaize(outPutFile, totalNumberOfRecords);
1:     }
1:   }
1: 
1:   /**
0:    * This method will be used to get the sorted record from file
1:    *
1:    * @return sorted record sorted record
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] getSortedRecordFromFile() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = null;
1: 
1:     // poll the top object from heap
1:     // heap maintains binary tree which is based on heap condition that will
1:     // be based on comparator we are passing the heap
1:     // when will call poll it will always delete root of the tree and then
1:     // it does trickel down operation complexity is log(n)
1:     SortTempChunkHolder poll = this.recordHolderHeap.poll();
1: 
1:     // get the row from chunk
1:     row = poll.getRow();
1: 
1:     // check if there no entry present
1:     if (!poll.hasNext()) {
1:       // if chunk is empty then close the stream
1:       poll.close();
1: 
1:       // change the file counter
1:       --this.fileCounter;
1: 
1:       // reaturn row
1:       return row;
1:     }
1: 
1:     // read new row
1:     poll.readRow();
1: 
1:     // add to heap
1:     this.recordHolderHeap.add(poll);
1: 
1:     // return row
1:     return row;
1:   }
1: 
1:   /**
1:    * Below method will be used to start storing process This method will get
1:    * all the temp files present in sort temp folder then it will create the
1:    * record holder heap and then it will read first record from each file and
1:    * initialize the heap
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   private void startSorting() throws CarbonSortKeyAndGroupByException {
1:     LOGGER.info("Number of temp file: " + this.fileCounter);
1: 
1:     // create record holder heap
1:     createRecordHolderQueue(intermediateFiles);
1: 
1:     // iterate over file list and create chunk holder and add to heap
1:     LOGGER.info("Started adding first record from each file");
1: 
1:     SortTempChunkHolder sortTempFileChunkHolder = null;
1: 
1:     for (File tempFile : intermediateFiles) {
1:       // create chunk holder
0:       sortTempFileChunkHolder = new UnsafeSortTempFileChunkHolder(tempFile, mergerParameters);
1: 
1:       sortTempFileChunkHolder.readRow();
1:       this.totalNumberOfRecords += sortTempFileChunkHolder.numberOfRows();
1: 
1:       // add to heap
1:       this.recordHolderHeap.add(sortTempFileChunkHolder);
1:     }
1: 
0:     LOGGER.info("Heap Size" + this.recordHolderHeap.size());
1:   }
1: 
1:   /**
1:    * This method will be used to create the heap which will be used to hold
1:    * the chunk of data
1:    *
1:    * @param listFiles list of temp files
1:    */
1:   private void createRecordHolderQueue(File[] listFiles) {
1:     // creating record holder heap
1:     this.recordHolderHeap = new PriorityQueue<SortTempChunkHolder>(listFiles.length);
1:   }
1: 
1:   /**
0:    * This method will be used to get the sorted row
1:    *
1:    * @return sorted row
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] next() throws CarbonSortKeyAndGroupByException {
0:     return getSortedRecordFromFile();
1:   }
1: 
1:   /**
1:    * This method will be used to check whether any more element is present or
1:    * not
1:    *
1:    * @return more element is present
1:    */
1:   private boolean hasNext() {
1:     return this.fileCounter > 0;
1:   }
1: 
1:   /**
1:    * Below method will be used to write data to file
1:    *
0:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
0:   private void writeDataTofile(Object[] row) throws CarbonSortKeyAndGroupByException, IOException {
0:     int dimCount = 0;
0:     int size = 0;
0:     char[] aggType = mergerParameters.getAggType();
0:     for (; dimCount < noDictionarycolumnMapping.length; dimCount++) {
0:       if (noDictionarycolumnMapping[dimCount]) {
0:         byte[] col = (byte[]) row[dimCount];
0:         rowData.putShort((short) col.length);
0:         size += 2;
0:         rowData.put(col);
0:         size += col.length;
0:       } else {
0:         rowData.putInt((int) row[dimCount]);
0:         size += 4;
1:       }
1:     }
1: 
0:     // write complex dimensions here.
0:     int dimensionSize = mergerParameters.getDimColCount();
0:     int measureSize = mergerParameters.getMeasureColCount();
0:     for (; dimCount < dimensionSize; dimCount++) {
0:       byte[] col = (byte[]) row[dimCount];
0:       rowData.putShort((short)col.length);
0:       size += 2;
0:       rowData.put(col);
0:       size += col.length;
1:     }
0:     Arrays.fill(nullSetWords, 0);
0:     int nullSetSize = nullSetWords.length * 8;
0:     int nullLoc = size;
0:     size += nullSetSize;
0:     for (int mesCount = 0; mesCount < measureSize; mesCount++) {
0:       Object value = row[mesCount + dimensionSize];
0:       if (null != value) {
0:         if (aggType[mesCount] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:           Double val = (Double) value;
0:           rowData.putDouble(size, val);
0:           size += 8;
0:         } else if (aggType[mesCount] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:           Long val = (Long) value;
0:           rowData.putLong(size, val);
0:           size += 8;
0:         } else if (aggType[mesCount] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:           BigDecimal val = (BigDecimal) value;
0:           byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:           rowData.putShort(size, (short)bigDecimalInBytes.length);
0:           size += 2;
0:           for (int i = 0; i < bigDecimalInBytes.length; i++) {
0:             rowData.put(size++, bigDecimalInBytes[i]);
1:           }
1:         }
0:         UnsafeCarbonRowPage.set(nullSetWords, mesCount);
0:       } else {
0:         UnsafeCarbonRowPage.unset(nullSetWords, mesCount);
1:       }
1:     }
0:     for (int i = 0; i < nullSetWords.length; i++) {
0:       rowData.putLong(nullLoc, nullSetWords[i]);
0:       nullLoc += 8;
1:     }
0:     byte[] rowBytes = new byte[size];
0:     rowData.position(0);
0:     rowData.get(rowBytes);
0:     stream.write(rowBytes);
0:     rowData.clear();
1:   }
1: 
1:   private void finish() throws CarbonSortKeyAndGroupByException {
0:     if (recordHolderHeap != null) {
0:       int size = recordHolderHeap.size();
0:       for (int i = 0; i < size; i++) {
0:         recordHolderHeap.poll().close();
1:       }
1:     }
1:     try {
1:       CarbonUtil.deleteFiles(intermediateFiles);
0:       rowData.clear();
0:     } catch (CarbonUtilException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while deleting the intermediate files");
1:     }
1:   }
1: }
author:QiangCai
-------------------------------------------------------------------------------
commit:256dbed
/////////////////////////////////////////////////////////////////////////
0:     rowData = ByteBuffer.allocate(2 * 1024 * 1024);
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
============================================================================
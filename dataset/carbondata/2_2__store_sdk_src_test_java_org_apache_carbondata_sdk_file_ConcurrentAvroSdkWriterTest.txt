1:94d2089: /*
1:94d2089:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:94d2089:  * contributor license agreements.  See the NOTICE file distributed with
1:94d2089:  * this work for additional information regarding copyright ownership.
1:94d2089:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:94d2089:  * (the "License"); you may not use this file except in compliance with
1:94d2089:  * the License.  You may obtain a copy of the License at
1:94d2089:  *
1:94d2089:  *    http://www.apache.org/licenses/LICENSE-2.0
1:94d2089:  *
1:94d2089:  * Unless required by applicable law or agreed to in writing, software
1:94d2089:  * distributed under the License is distributed on an "AS IS" BASIS,
1:94d2089:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:94d2089:  * See the License for the specific language governing permissions and
1:94d2089:  * limitations under the License.
1:94d2089:  */
1:94d2089: 
1:94d2089: package org.apache.carbondata.sdk.file;
1:94d2089: 
1:94d2089: import java.io.File;
1:94d2089: import java.io.IOException;
1:94d2089: import java.util.concurrent.ExecutorService;
1:94d2089: import java.util.concurrent.Executors;
1:94d2089: import java.util.concurrent.TimeUnit;
1:94d2089: 
1:94d2089: import org.apache.avro.generic.GenericData;
1:94d2089: import org.apache.commons.io.FileUtils;
1:8f1a029: import org.apache.hadoop.conf.Configuration;
1:94d2089: import org.junit.Assert;
1:94d2089: import org.junit.Test;
1:94d2089: 
1:94d2089: /**
1:94d2089:  * multi-thread Test suite for {@link CSVCarbonWriter}
1:94d2089:  */
1:94d2089: public class ConcurrentAvroSdkWriterTest {
1:94d2089: 
1:94d2089:   private static final int recordsPerItr = 10;
1:94d2089:   private static final short numOfThreads = 4;
1:94d2089: 
1:94d2089:   @Test public void testWriteFiles() throws IOException {
1:94d2089:     String path = "./testWriteFiles";
1:94d2089:     FileUtils.deleteDirectory(new File(path));
1:94d2089: 
1:94d2089:     String mySchema =
1:94d2089:         "{" + "  \"name\": \"address\", " + "   \"type\": \"record\", " + "    \"fields\": [  "
1:94d2089:             + "  { \"name\": \"name\", \"type\": \"string\"}, "
1:94d2089:             + "  { \"name\": \"age\", \"type\": \"int\"}, " + "  { " + "    \"name\": \"address\", "
1:94d2089:             + "      \"type\": { " + "    \"type\" : \"record\", "
1:94d2089:             + "        \"name\" : \"my_address\", " + "        \"fields\" : [ "
1:94d2089:             + "    {\"name\": \"street\", \"type\": \"string\"}, "
1:94d2089:             + "    {\"name\": \"city\", \"type\": \"string\"} " + "  ]} " + "  } " + "] " + "}";
1:94d2089: 
1:94d2089:     String json =
1:94d2089:         "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1:94d2089: 
1:94d2089:     // conversion to GenericData.Record
1:94d2089:     org.apache.avro.Schema avroSchema = new org.apache.avro.Schema.Parser().parse(mySchema);
1:94d2089:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
1:94d2089: 
1:94d2089:     ExecutorService executorService = Executors.newFixedThreadPool(numOfThreads);
1:94d2089:     try {
1:94d2089:       CarbonWriterBuilder builder = CarbonWriter.builder().outputPath(path);
1:8f1a029:       CarbonWriter writer = builder.buildThreadSafeWriterForAvroInput(avroSchema, numOfThreads,
1:8f1a029:           TestUtil.configuration);
1:94d2089:       // write in multi-thread
1:94d2089:       for (int i = 0; i < numOfThreads; i++) {
1:94d2089:         executorService.submit(new WriteLogic(writer, record));
1:94d2089:       }
1:94d2089:       executorService.shutdown();
1:94d2089:       executorService.awaitTermination(2, TimeUnit.HOURS);
1:94d2089:       writer.close();
1:94d2089:     } catch (Exception e) {
1:94d2089:       e.printStackTrace();
1:94d2089:       Assert.fail(e.getMessage());
1:94d2089:     }
1:94d2089: 
1:94d2089:     // read the files and verify the count
1:94d2089:     CarbonReader reader;
1:94d2089:     try {
1:94d2089:       reader =
1:8f1a029:           CarbonReader.builder(path, "_temp").projection(new String[] { "name", "age" }).build(new Configuration(false));
1:94d2089:       int i = 0;
1:94d2089:       while (reader.hasNext()) {
1:94d2089:         Object[] row = (Object[]) reader.readNextRow();
1:94d2089:         i++;
1:94d2089:       }
1:94d2089:       Assert.assertEquals(i, numOfThreads * recordsPerItr);
1:94d2089:       reader.close();
1:94d2089:     } catch (InterruptedException e) {
1:94d2089:       e.printStackTrace();
1:94d2089:       Assert.fail(e.getMessage());
1:94d2089:     }
1:94d2089: 
1:94d2089:     FileUtils.deleteDirectory(new File(path));
1:94d2089:   }
1:94d2089: 
1:94d2089:   class WriteLogic implements Runnable {
1:94d2089:     CarbonWriter writer;
1:94d2089:     GenericData.Record record;
1:94d2089: 
1:94d2089:     WriteLogic(CarbonWriter writer, GenericData.Record record) {
1:94d2089:       this.writer = writer;
1:94d2089:       this.record = record;
1:94d2089:     }
1:94d2089: 
1:94d2089:     @Override public void run() {
1:94d2089:       try {
1:94d2089:         for (int i = 0; i < recordsPerItr; i++) {
1:94d2089:           writer.write(record);
1:94d2089:         }
1:94d2089:       } catch (IOException e) {
1:94d2089:         e.printStackTrace();
1:94d2089:         Assert.fail(e.getMessage());
1:94d2089:       }
1:94d2089:     }
1:94d2089:   }
1:94d2089: 
1:94d2089: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
/////////////////////////////////////////////////////////////////////////
1:       CarbonWriter writer = builder.buildThreadSafeWriterForAvroInput(avroSchema, numOfThreads,
1:           TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           CarbonReader.builder(path, "_temp").projection(new String[] { "name", "age" }).build(new Configuration(false));
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:94d2089
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.sdk.file;
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.TimeUnit;
1: 
1: import org.apache.avro.generic.GenericData;
1: import org.apache.commons.io.FileUtils;
1: import org.junit.Assert;
1: import org.junit.Test;
1: 
1: /**
1:  * multi-thread Test suite for {@link CSVCarbonWriter}
1:  */
1: public class ConcurrentAvroSdkWriterTest {
1: 
1:   private static final int recordsPerItr = 10;
1:   private static final short numOfThreads = 4;
1: 
1:   @Test public void testWriteFiles() throws IOException {
1:     String path = "./testWriteFiles";
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     String mySchema =
1:         "{" + "  \"name\": \"address\", " + "   \"type\": \"record\", " + "    \"fields\": [  "
1:             + "  { \"name\": \"name\", \"type\": \"string\"}, "
1:             + "  { \"name\": \"age\", \"type\": \"int\"}, " + "  { " + "    \"name\": \"address\", "
1:             + "      \"type\": { " + "    \"type\" : \"record\", "
1:             + "        \"name\" : \"my_address\", " + "        \"fields\" : [ "
1:             + "    {\"name\": \"street\", \"type\": \"string\"}, "
1:             + "    {\"name\": \"city\", \"type\": \"string\"} " + "  ]} " + "  } " + "] " + "}";
1: 
1:     String json =
1:         "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1: 
1:     // conversion to GenericData.Record
1:     org.apache.avro.Schema avroSchema = new org.apache.avro.Schema.Parser().parse(mySchema);
1:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
1: 
1:     ExecutorService executorService = Executors.newFixedThreadPool(numOfThreads);
1:     try {
1:       CarbonWriterBuilder builder = CarbonWriter.builder().outputPath(path);
0:       CarbonWriter writer = builder.buildThreadSafeWriterForAvroInput(avroSchema, numOfThreads);
1:       // write in multi-thread
1:       for (int i = 0; i < numOfThreads; i++) {
1:         executorService.submit(new WriteLogic(writer, record));
1:       }
1:       executorService.shutdown();
1:       executorService.awaitTermination(2, TimeUnit.HOURS);
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     // read the files and verify the count
1:     CarbonReader reader;
1:     try {
1:       reader =
0:           CarbonReader.builder(path, "_temp").projection(new String[] { "name", "age" }).build();
1:       int i = 0;
1:       while (reader.hasNext()) {
1:         Object[] row = (Object[]) reader.readNextRow();
1:         i++;
1:       }
1:       Assert.assertEquals(i, numOfThreads * recordsPerItr);
1:       reader.close();
1:     } catch (InterruptedException e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1:   class WriteLogic implements Runnable {
1:     CarbonWriter writer;
1:     GenericData.Record record;
1: 
1:     WriteLogic(CarbonWriter writer, GenericData.Record record) {
1:       this.writer = writer;
1:       this.record = record;
1:     }
1: 
1:     @Override public void run() {
1:       try {
1:         for (int i = 0; i < recordsPerItr; i++) {
1:           writer.write(record);
1:         }
1:       } catch (IOException e) {
1:         e.printStackTrace();
1:         Assert.fail(e.getMessage());
1:       }
1:     }
1:   }
1: 
1: }
============================================================================
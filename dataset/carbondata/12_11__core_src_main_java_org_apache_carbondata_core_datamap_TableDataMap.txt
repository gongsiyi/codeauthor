1:b434346: /*
1:b434346:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b434346:  * contributor license agreements.  See the NOTICE file distributed with
1:b434346:  * this work for additional information regarding copyright ownership.
1:b434346:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b434346:  * (the "License"); you may not use this file except in compliance with
1:b434346:  * the License.  You may obtain a copy of the License at
2:b434346:  *
1:b434346:  *    http://www.apache.org/licenses/LICENSE-2.0
1:b434346:  *
1:b434346:  * Unless required by applicable law or agreed to in writing, software
1:b434346:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b434346:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b434346:  * See the License for the specific language governing permissions and
1:b434346:  * limitations under the License.
1:b434346:  */
1:f089287: package org.apache.carbondata.core.datamap;
1:b434346: 
1:f089287: import java.io.IOException;
1:b681244: import java.util.ArrayList;
1:b434346: import java.util.List;
1:e580d64: import java.util.Map;
1:b434346: 
1:fc2a7eb: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:2bad144: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:d35fbaf: import org.apache.carbondata.core.datamap.dev.BlockletSerializer;
1:fc2a7eb: import org.apache.carbondata.core.datamap.dev.DataMap;
1:fc2a7eb: import org.apache.carbondata.core.datamap.dev.DataMapFactory;
1:fc2a7eb: import org.apache.carbondata.core.datamap.dev.fgdatamap.FineGrainBlocklet;
1:ca7e2e3: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1:d35fbaf: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:f089287: import org.apache.carbondata.core.indexstore.Blocklet;
1:28f78b2: import org.apache.carbondata.core.indexstore.BlockletDetailsFetcher;
1:28f78b2: import org.apache.carbondata.core.indexstore.ExtendedBlocklet;
1:8d3c774: import org.apache.carbondata.core.indexstore.PartitionSpec;
1:ca7e2e3: import org.apache.carbondata.core.indexstore.SegmentPropertiesFetcher;
1:b434346: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1:56330ae: import org.apache.carbondata.core.metadata.schema.table.DataMapSchema;
1:3894e1d: import org.apache.carbondata.core.scan.expression.Expression;
1:b434346: import org.apache.carbondata.core.scan.filter.resolver.FilterResolverIntf;
1:4aa0f49: import org.apache.carbondata.events.Event;
1:4aa0f49: import org.apache.carbondata.events.OperationContext;
1:4aa0f49: import org.apache.carbondata.events.OperationEventListener;
1:b434346: 
1:b434346: /**
1:fc2a7eb:  * Index at the table level, user can add any number of DataMap for one table, by
1:fc2a7eb:  * {@code
1:fc2a7eb:  *   CREATE DATAMAP dm ON TABLE table
1:fc2a7eb:  *   USING 'class name of DataMapFactory implementation'
1:fc2a7eb:  * }
1:fc2a7eb:  * Depends on the filter condition it can prune the data (blocklet or row level).
1:b434346:  */
1:fc2a7eb: @InterfaceAudience.Internal
1:937868d: public final class TableDataMap extends OperationEventListener {
1:b681244: 
1:b681244:   private AbsoluteTableIdentifier identifier;
1:b681244: 
1:56330ae:   private DataMapSchema dataMapSchema;
1:b681244: 
1:b681244:   private DataMapFactory dataMapFactory;
1:b434346: 
1:28f78b2:   private BlockletDetailsFetcher blockletDetailsFetcher;
1:b434346: 
1:ca7e2e3:   private SegmentPropertiesFetcher segmentPropertiesFetcher;
1:f089287: 
1:b434346:   /**
1:b434346:    * It is called to initialize and load the required table datamap metadata.
1:b434346:    */
1:fc2a7eb:   TableDataMap(AbsoluteTableIdentifier identifier, DataMapSchema dataMapSchema,
1:fc2a7eb:       DataMapFactory dataMapFactory, BlockletDetailsFetcher blockletDetailsFetcher,
1:ca7e2e3:       SegmentPropertiesFetcher segmentPropertiesFetcher) {
1:b681244:     this.identifier = identifier;
1:56330ae:     this.dataMapSchema = dataMapSchema;
1:b681244:     this.dataMapFactory = dataMapFactory;
1:28f78b2:     this.blockletDetailsFetcher = blockletDetailsFetcher;
1:ca7e2e3:     this.segmentPropertiesFetcher = segmentPropertiesFetcher;
1:b681244:   }
1:b434346: 
1:2018048:   public BlockletDetailsFetcher getBlockletDetailsFetcher() {
1:2018048:     return blockletDetailsFetcher;
1:2018048:   }
1:3894e1d: 
1:b434346: 
1:3894e1d:   /**
1:3894e1d:    * Pass the valid segments and prune the datamap using filter expression
1:3894e1d:    *
1:3894e1d:    * @param segments
1:3894e1d:    * @param filterExp
1:3894e1d:    * @return
1:3894e1d:    */
1:3894e1d:   public List<ExtendedBlocklet> prune(List<Segment> segments, Expression filterExp,
1:3894e1d:       List<PartitionSpec> partitions) throws IOException {
1:3894e1d:     List<ExtendedBlocklet> blocklets = new ArrayList<>();
1:3894e1d:     SegmentProperties segmentProperties;
1:3894e1d:     Map<Segment, List<DataMap>> dataMaps = dataMapFactory.getDataMaps(segments);
1:3894e1d:     for (Segment segment : segments) {
1:3894e1d:       List<Blocklet> pruneBlocklets = new ArrayList<>();
1:3894e1d:       // if filter is not passed then return all the blocklets
1:3894e1d:       if (filterExp == null) {
1:3894e1d:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions);
1:3894e1d:       } else {
1:3894e1d:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment);
1:3894e1d:         for (DataMap dataMap : dataMaps.get(segment)) {
1:3894e1d: 
1:3894e1d:           pruneBlocklets
1:3894e1d:               .addAll(dataMap.prune(filterExp, segmentProperties, partitions, identifier));
1:3894e1d:         }
1:3894e1d:       }
1:3894e1d:       blocklets.addAll(addSegmentId(
1:3894e1d:           blockletDetailsFetcher.getExtendedBlocklets(pruneBlocklets, segment),
1:3894e1d:           segment.toString()));
1:3894e1d:     }
1:3894e1d:     return blocklets;
1:3894e1d:   }
1:3894e1d: 
1:b434346:   /**
1:b434346:    * Pass the valid segments and prune the datamap using filter expression
1:b434346:    *
1:8d3c774:    * @param segments
1:b434346:    * @param filterExp
2:b434346:    * @return
1:b434346:    */
1:8d3c774:   public List<ExtendedBlocklet> prune(List<Segment> segments, FilterResolverIntf filterExp,
1:8d3c774:       List<PartitionSpec> partitions) throws IOException {
1:28f78b2:     List<ExtendedBlocklet> blocklets = new ArrayList<>();
1:ca7e2e3:     SegmentProperties segmentProperties;
1:e580d64:     Map<Segment, List<DataMap>> dataMaps = dataMapFactory.getDataMaps(segments);
1:8d3c774:     for (Segment segment : segments) {
1:28f78b2:       List<Blocklet> pruneBlocklets = new ArrayList<>();
1:d35fbaf:       // if filter is not passed then return all the blocklets
1:d35fbaf:       if (filterExp == null) {
1:d35fbaf:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions);
1:d35fbaf:       } else {
1:d35fbaf:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment);
1:e580d64:         for (DataMap dataMap : dataMaps.get(segment)) {
1:d35fbaf:           pruneBlocklets.addAll(dataMap.prune(filterExp, segmentProperties, partitions));
1:b681244:         }
1:b681244:       }
1:280a400:       blocklets.addAll(addSegmentId(
1:c58eb43:           blockletDetailsFetcher.getExtendedBlocklets(pruneBlocklets, segment),
1:60dfdd3:           segment.toString()));
1:b681244:     }
1:b681244:     return blocklets;
1:b681244:   }
1:b681244: 
1:28f78b2:   private List<ExtendedBlocklet> addSegmentId(List<ExtendedBlocklet> pruneBlocklets,
1:28f78b2:       String segmentId) {
1:28f78b2:     for (ExtendedBlocklet blocklet : pruneBlocklets) {
1:b681244:       blocklet.setSegmentId(segmentId);
1:b681244:     }
1:b681244:     return pruneBlocklets;
1:b681244:   }
1:b681244: 
1:b434346:   /**
1:b434346:    * This is used for making the datamap distributable.
1:b434346:    * It takes the valid segments and returns all the datamaps as distributable objects so that
1:b434346:    * it can be distributed across machines.
1:b434346:    *
1:b434346:    * @return
1:b434346:    */
1:8d3c774:   public List<DataMapDistributable> toDistributable(List<Segment> segments) throws IOException {
1:b681244:     List<DataMapDistributable> distributables = new ArrayList<>();
1:8d3c774:     for (Segment segment : segments) {
1:2018048:       List<DataMapDistributable> list =
1:2018048:           dataMapFactory.toDistributable(segment);
1:2018048:       for (DataMapDistributable distributable : list) {
1:56330ae:         distributable.setDataMapSchema(dataMapSchema);
1:8d3c774:         distributable.setSegment(segment);
1:1e21cd1:         distributable.setTablePath(identifier.getTablePath());
1:b681244:       }
1:1e21cd1:       distributables.addAll(list);
1:b681244:     }
1:b681244:     return distributables;
1:b681244:   }
1:b434346: 
1:b434346:   /**
1:07a77fa:    * This method returns all the datamaps corresponding to the distributable object
1:b434346:    *
1:07a77fa:    * @param distributable
1:b434346:    * @return
1:07a77fa:    * @throws IOException
1:b434346:    */
1:07a77fa:   public List<DataMap> getTableDataMaps(DataMapDistributable distributable) throws IOException {
1:07a77fa:     return dataMapFactory.getDataMaps(distributable);
1:07a77fa:   }
1:b434346: 
1:b434346:   /**
1:b434346:    * This method is used from any machine after it is distributed. It takes the distributable object
1:b434346:    * to prune the filters.
1:b434346:    *
1:b434346:    * @param distributable
1:b434346:    * @param filterExp
1:b434346:    * @return
1:b434346:    */
1:07a77fa:   public List<ExtendedBlocklet> prune(List<DataMap> dataMaps, DataMapDistributable distributable,
1:8d3c774:       FilterResolverIntf filterExp, List<PartitionSpec> partitions) throws IOException {
1:28f78b2:     List<ExtendedBlocklet> detailedBlocklets = new ArrayList<>();
1:0586146:     List<Blocklet> blocklets = new ArrayList<>();
1:0586146:     for (DataMap dataMap : dataMaps) {
1:280a400:       blocklets.addAll(dataMap.prune(filterExp,
1:d35fbaf:           segmentPropertiesFetcher.getSegmentProperties(distributable.getSegment()),
1:ca7e2e3:           partitions));
1:0586146:     }
1:d35fbaf:     BlockletSerializer serializer = new BlockletSerializer();
1:d35fbaf:     String writePath =
1:56330ae:         identifier.getTablePath() + CarbonCommonConstants.FILE_SEPARATOR + dataMapSchema
1:56330ae:             .getDataMapName();
1:9db662a:     if (dataMapFactory.getDataMapLevel() == DataMapLevel.FG) {
1:d35fbaf:       FileFactory.mkdirs(writePath, FileFactory.getFileType(writePath));
1:d35fbaf:     }
1:d35fbaf:     for (Blocklet blocklet : blocklets) {
1:280a400:       ExtendedBlocklet detailedBlocklet = blockletDetailsFetcher
1:c58eb43:           .getExtendedBlocklet(blocklet, distributable.getSegment());
1:9db662a:       if (dataMapFactory.getDataMapLevel() == DataMapLevel.FG) {
1:d35fbaf:         String blockletwritePath =
1:d35fbaf:             writePath + CarbonCommonConstants.FILE_SEPARATOR + System.nanoTime();
1:d35fbaf:         detailedBlocklet.setDataMapWriterPath(blockletwritePath);
1:d35fbaf:         serializer.serializeBlocklet((FineGrainBlocklet) blocklet, blockletwritePath);
1:b681244:       }
1:60dfdd3:       detailedBlocklet.setSegmentId(distributable.getSegment().toString());
1:28f78b2:       detailedBlocklets.add(detailedBlocklet);
1:b434346:     }
1:28f78b2:     return detailedBlocklets;
1:89cfd8e:   }
1:b434346: 
1:b434346:   /**
1:b681244:    * Clear only the datamaps of the segments
1:8d3c774:    * @param segments
1:b681244:    */
1:8d3c774:   public void clear(List<Segment> segments) {
1:8d3c774:     for (Segment segment: segments) {
1:8d3c774:       dataMapFactory.clear(segment);
1:b681244:     }
1:b681244:   }
1:b681244: 
1:b681244:   /**
1:b681244:    * Clears all datamap
1:b681244:    */
1:b681244:   public void clear() {
1:07a77fa:     if (null != dataMapFactory) {
1:b681244:       dataMapFactory.clear();
1:b681244:     }
1:07a77fa:   }
1:b434346: 
1:b681244:   /**
1:d8562e5:    * delete only the datamaps of the segments
1:b434346:    */
1:1fd3703:   public void deleteDatamapData(List<Segment> segments) throws IOException {
1:d8562e5:     for (Segment segment: segments) {
1:d8562e5:       dataMapFactory.deleteDatamapData(segment);
1:d8562e5:     }
1:d8562e5:   }
1:b434346:   /**
1:860e144:    * delete datamap data if any
1:b434346:    */
1:860e144:   public void deleteDatamapData() {
1:860e144:     dataMapFactory.deleteDatamapData();
1:860e144:   }
1:b434346: 
1:56330ae:   public DataMapSchema getDataMapSchema() {
1:56330ae:     return dataMapSchema;
1:1e21cd1:   }
1:07a77fa: 
1:fc2a7eb:   public DataMapFactory getDataMapFactory() {
1:fc2a7eb:     return dataMapFactory;
1:f089287:   }
1:2018048: 
1:937868d:   @Override public void onEvent(Event event, OperationContext opContext) throws Exception {
1:b681244:     dataMapFactory.fireEvent(event);
1:b681244:   }
1:860e144: 
1:b434346:   /**
1:2bad144:    * Method to prune the segments based on task min/max values
1:b434346:    *
1:8d3c774:    * @param segments
1:b434346:    * @param filterExp
1:b434346:    * @return
1:2bad144:    * @throws IOException
1:b434346:    */
1:c58eb43:   public List<Segment> pruneSegments(List<Segment> segments, FilterResolverIntf filterExp)
1:f089287:       throws IOException {
1:65471f2:     List<Segment> prunedSegments = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:8d3c774:     for (Segment segment : segments) {
1:d35fbaf:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
1:d35fbaf:       for (DataMap dataMap : dataMaps) {
1:2bad144:         if (dataMap.isScanRequired(filterExp)) {
1:2bad144:           // If any one task in a given segment contains the data that means the segment need to
1:2bad144:           // be scanned and we need to validate further data maps in the same segment
1:65471f2:           prunedSegments.add(segment);
1:2bad144:           break;
1:d35fbaf:         }
1:4aa0f49:       }
2:2bad144:     }
1:2bad144:     return prunedSegments;
1:2bad144:   }
1:2bad144: }
============================================================================
author:ravipesala
-------------------------------------------------------------------------------
commit:3894e1d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.expression.Expression;
/////////////////////////////////////////////////////////////////////////
1: 
1:   /**
1:    * Pass the valid segments and prune the datamap using filter expression
1:    *
1:    * @param segments
1:    * @param filterExp
1:    * @return
1:    */
1:   public List<ExtendedBlocklet> prune(List<Segment> segments, Expression filterExp,
1:       List<PartitionSpec> partitions) throws IOException {
1:     List<ExtendedBlocklet> blocklets = new ArrayList<>();
1:     SegmentProperties segmentProperties;
1:     Map<Segment, List<DataMap>> dataMaps = dataMapFactory.getDataMaps(segments);
1:     for (Segment segment : segments) {
1:       List<Blocklet> pruneBlocklets = new ArrayList<>();
1:       // if filter is not passed then return all the blocklets
1:       if (filterExp == null) {
1:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions);
1:       } else {
1:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment);
1:         for (DataMap dataMap : dataMaps.get(segment)) {
1: 
1:           pruneBlocklets
1:               .addAll(dataMap.prune(filterExp, segmentProperties, partitions, identifier));
1:         }
1:       }
1:       blocklets.addAll(addSegmentId(
1:           blockletDetailsFetcher.getExtendedBlocklets(pruneBlocklets, segment),
1:           segment.toString()));
1:     }
1:     return blocklets;
1:   }
1: 
commit:60dfdd3
/////////////////////////////////////////////////////////////////////////
1:           segment.toString()));
/////////////////////////////////////////////////////////////////////////
1:       detailedBlocklet.setSegmentId(distributable.getSegment().toString());
commit:d35fbaf
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.dev.BlockletSerializer;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
0: import org.apache.carbondata.core.indexstore.FineGrainBlocklet;
/////////////////////////////////////////////////////////////////////////
1:       // if filter is not passed then return all the blocklets
1:       if (filterExp == null) {
1:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions);
1:       } else {
1:         List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
1:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment);
1:         for (DataMap dataMap : dataMaps) {
1:           pruneBlocklets.addAll(dataMap.prune(filterExp, segmentProperties, partitions));
1:         }
/////////////////////////////////////////////////////////////////////////
1:               segmentPropertiesFetcher.getSegmentProperties(distributable.getSegment()),
1:     BlockletSerializer serializer = new BlockletSerializer();
1:     String writePath =
0:         identifier.getTablePath() + CarbonCommonConstants.FILE_SEPARATOR + dataMapName;
0:     if (dataMapFactory.getDataMapType() == DataMapType.FG) {
1:       FileFactory.mkdirs(writePath, FileFactory.getFileType(writePath));
1:     }
1:     for (Blocklet blocklet : blocklets) {
0:       if (dataMapFactory.getDataMapType() == DataMapType.FG) {
1:         String blockletwritePath =
1:             writePath + CarbonCommonConstants.FILE_SEPARATOR + System.nanoTime();
1:         detailedBlocklet.setDataMapWriterPath(blockletwritePath);
1:         serializer.serializeBlocklet((FineGrainBlocklet) blocklet, blockletwritePath);
0:       }detailedBlocklet.setSegmentId(distributable.getSegment().getSegmentNo());
commit:8d3c774
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.indexstore.PartitionSpec;
/////////////////////////////////////////////////////////////////////////
1:    * @param segments
1:   public List<ExtendedBlocklet> prune(List<Segment> segments, FilterResolverIntf filterExp,
1:       List<PartitionSpec> partitions) throws IOException {
1:     for (Segment segment : segments) {
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
0:           .getExtendedBlocklets(pruneBlocklets, segment), segment.getSegmentNo()));
/////////////////////////////////////////////////////////////////////////
1:   public List<DataMapDistributable> toDistributable(List<Segment> segments) throws IOException {
1:     for (Segment segment : segments) {
0:       List<DataMapDistributable> list = dataMapFactory.toDistributable(segment);
1:         distributable.setSegment(segment);
/////////////////////////////////////////////////////////////////////////
1:       FilterResolverIntf filterExp, List<PartitionSpec> partitions) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:           blockletDetailsFetcher.getExtendedBlocklet(blocklet, distributable.getSegment());
0:       detailedBlocklet.setSegmentId(distributable.getSegment().getSegmentNo());
/////////////////////////////////////////////////////////////////////////
1:    * @param segments
1:   public void clear(List<Segment> segments) {
1:     for (Segment segment: segments) {
1:       dataMapFactory.clear(segment);
/////////////////////////////////////////////////////////////////////////
1:    * @param segments
0:   public List<String> pruneSegments(List<Segment> segments, FilterResolverIntf filterExp)
1:     for (Segment segment : segments) {
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
0:           prunedSegments.add(segment.getSegmentNo());
commit:b8a02f3
/////////////////////////////////////////////////////////////////////////
0:   public List<ExtendedBlocklet> prune(List<String> segmentIds, FilterResolverIntf filterExp,
0:       List<String> partitions) throws IOException {
0:         pruneBlocklets.addAll(dataMap.prune(filterExp, partitions));
/////////////////////////////////////////////////////////////////////////
0:       FilterResolverIntf filterExp, List<String> partitions) throws IOException {
0:       blocklets.addAll(dataMap.prune(filterExp, partitions));
commit:0586146
/////////////////////////////////////////////////////////////////////////
1:     List<Blocklet> blocklets = new ArrayList<>();
0:     List<DataMap> dataMaps = dataMapFactory.getDataMaps(distributable);
1:     for (DataMap dataMap : dataMaps) {
0:       blocklets.addAll(dataMap.prune(filterExp));
1:     }
commit:b681244
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
0: import org.apache.carbondata.core.events.ChangeEvent;
0: public final class TableDataMap implements EventListener {
1: 
1:   private AbsoluteTableIdentifier identifier;
1: 
0:   private String dataMapName;
1: 
1:   private DataMapFactory dataMapFactory;
0:   public TableDataMap(AbsoluteTableIdentifier identifier, String dataMapName,
0:       DataMapFactory dataMapFactory) {
1:     this.identifier = identifier;
0:     this.dataMapName = dataMapName;
1:     this.dataMapFactory = dataMapFactory;
1:   }
/////////////////////////////////////////////////////////////////////////
0:   public List<Blocklet> prune(List<String> segmentIds, FilterResolverIntf filterExp) {
0:     List<Blocklet> blocklets = new ArrayList<>();
0:     for (String segmentId : segmentIds) {
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segmentId);
0:       for (DataMap dataMap : dataMaps) {
0:         List<Blocklet> pruneBlocklets = dataMap.prune(filterExp);
0:         blocklets.addAll(addSegmentId(pruneBlocklets, segmentId));
1:       }
1:     }
1:     return blocklets;
1:   }
1: 
0:   private List<Blocklet> addSegmentId(List<Blocklet> pruneBlocklets, String segmentId) {
0:     for (Blocklet blocklet : pruneBlocklets) {
1:       blocklet.setSegmentId(segmentId);
1:     }
1:     return pruneBlocklets;
1:   }
/////////////////////////////////////////////////////////////////////////
0:   public List<DataMapDistributable> toDistributable(List<String> segmentIds) {
1:     List<DataMapDistributable> distributables = new ArrayList<>();
0:     for (String segmentsId : segmentIds) {
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segmentsId);
0:       for (DataMap dataMap : dataMaps) {
0:         distributables.add(dataMap.toDistributable());
1:       }
1:     }
1:     return distributables;
1:   }
/////////////////////////////////////////////////////////////////////////
0:   public List<Blocklet> prune(DataMapDistributable distributable, FilterResolverIntf filterExp) {
0:     return dataMapFactory.getDataMap(distributable).prune(filterExp);
1:   }
1: 
0:   @Override public void fireEvent(ChangeEvent event) {
1:     dataMapFactory.fireEvent(event);
1:   }
1:    * Clear only the datamaps of the segments
0:    * @param segmentIds
1:    */
0:   public void clear(List<String> segmentIds) {
0:     for (String segmentId: segmentIds) {
0:       dataMapFactory.clear(segmentId);
1:     }
1:   }
1: 
1:   /**
1:    * Clears all datamap
1:    */
1:   public void clear() {
1:     dataMapFactory.clear();
1:   }
1:   /**
0:    * Get the unique name of datamap
0:   public String getDataMapName() {
0:     return dataMapName;
1:   }
commit:b434346
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: package org.apache.carbondata.core.indexstore;
1: 
1: import java.util.List;
1: 
0: import org.apache.carbondata.core.events.EventListener;
1: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1: import org.apache.carbondata.core.scan.filter.resolver.FilterResolverIntf;
1: 
1: /**
0:  * DataMap at the table level, user can add any number of datamaps for one table. Depends
0:  * on the filter condition it can prune the blocklets.
1:  */
0: public interface TableDataMap extends EventListener {
1: 
1:   /**
1:    * It is called to initialize and load the required table datamap metadata.
1:    */
0:   void init(AbsoluteTableIdentifier identifier, String dataMapName);
1: 
1:   /**
0:    * Gives the writer to write the metadata information of this datamap at table level.
1:    *
1:    * @return
1:    */
0:   DataMapWriter getWriter();
1: 
1:   /**
0:    * Create the datamap using the segmentid  and name.
1:    *
0:    * @param identifier
0:    * @param segmentId
1:    * @return
1:    */
0:   DataMap createDataMap(AbsoluteTableIdentifier identifier, String segmentId);
1: 
1:   /**
1:    * Pass the valid segments and prune the datamap using filter expression
1:    *
0:    * @param segmentIds
1:    * @param filterExp
1:    * @return
1:    */
0:   List<Blocklet> prune(List<String> segmentIds, FilterResolverIntf filterExp);
1: 
1:   /**
1:    * This is used for making the datamap distributable.
1:    * It takes the valid segments and returns all the datamaps as distributable objects so that
1:    * it can be distributed across machines.
1:    *
1:    * @return
1:    */
0:   List<DataMapDistributable> toDistributable(List<String> segmentIds);
1: 
1:   /**
1:    * This method is used from any machine after it is distributed. It takes the distributable object
1:    * to prune the filters.
1:    *
1:    * @param distributable
1:    * @param filterExp
1:    * @return
1:    */
0:   List<Blocklet> prune(DataMapDistributable distributable, FilterResolverIntf filterExp);
1: 
1:   /**
0:    * This method checks whether the columns and the type of filters supported
0:    * for this datamap or not
1:    *
1:    * @param filterExp
1:    * @return
1:    */
0:   boolean isFiltersSupported(FilterResolverIntf filterExp);
1: 
1:   /**
0:    * Clears table level datamap
1:    */
0:   void clear();
1: 
1: }
author:rahul
-------------------------------------------------------------------------------
commit:e580d64
/////////////////////////////////////////////////////////////////////////
1: import java.util.Map;
/////////////////////////////////////////////////////////////////////////
1:     Map<Segment, List<DataMap>> dataMaps = dataMapFactory.getDataMaps(segments);
1:         for (DataMap dataMap : dataMaps.get(segment)) {
author:xuchuanyin
-------------------------------------------------------------------------------
commit:1fd3703
/////////////////////////////////////////////////////////////////////////
1:   public void deleteDatamapData(List<Segment> segments) throws IOException {
commit:d8562e5
/////////////////////////////////////////////////////////////////////////
1:    * delete only the datamaps of the segments
0:    */
0:   public void deleteDatamapData(List<Segment> segments) {
1:     for (Segment segment: segments) {
1:       dataMapFactory.deleteDatamapData(segment);
1:     }
1:   }
0:   /**
author:akashrn5
-------------------------------------------------------------------------------
commit:07a77fa
/////////////////////////////////////////////////////////////////////////
1:    * This method returns all the datamaps corresponding to the distributable object
0:    *
1:    * @param distributable
0:    * @return
1:    * @throws IOException
0:    */
1:   public List<DataMap> getTableDataMaps(DataMapDistributable distributable) throws IOException {
1:     return dataMapFactory.getDataMaps(distributable);
1:   }
1: 
0:   /**
/////////////////////////////////////////////////////////////////////////
1:   public List<ExtendedBlocklet> prune(List<DataMap> dataMaps, DataMapDistributable distributable,
/////////////////////////////////////////////////////////////////////////
1:     if (null != dataMapFactory) {
0:       dataMapFactory.clear();
1:     }
commit:2018048
/////////////////////////////////////////////////////////////////////////
1:   public BlockletDetailsFetcher getBlockletDetailsFetcher() {
1:     return blockletDetailsFetcher;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:       List<DataMapDistributable> list =
1:           dataMapFactory.toDistributable(segment);
1:       for (DataMapDistributable distributable : list) {
commit:860e144
/////////////////////////////////////////////////////////////////////////
0:   /**
1:    * delete datamap data if any
0:    */
1:   public void deleteDatamapData() {
1:     dataMapFactory.deleteDatamapData();
1:   }
1: 
author:Jacky Li
-------------------------------------------------------------------------------
commit:9db662a
/////////////////////////////////////////////////////////////////////////
1:     if (dataMapFactory.getDataMapLevel() == DataMapLevel.FG) {
1:       if (dataMapFactory.getDataMapLevel() == DataMapLevel.FG) {
commit:fc2a7eb
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
1: import org.apache.carbondata.core.datamap.dev.DataMap;
1: import org.apache.carbondata.core.datamap.dev.DataMapFactory;
1: import org.apache.carbondata.core.datamap.dev.fgdatamap.FineGrainBlocklet;
/////////////////////////////////////////////////////////////////////////
1:  * Index at the table level, user can add any number of DataMap for one table, by
1:  * {@code
1:  *   CREATE DATAMAP dm ON TABLE table
1:  *   USING 'class name of DataMapFactory implementation'
1:  * }
1:  * Depends on the filter condition it can prune the data (blocklet or row level).
1: @InterfaceAudience.Internal
0:   private DataMapFactory dataMapFactory;
/////////////////////////////////////////////////////////////////////////
1:   TableDataMap(AbsoluteTableIdentifier identifier, DataMapSchema dataMapSchema,
1:       DataMapFactory dataMapFactory, BlockletDetailsFetcher blockletDetailsFetcher,
0:     this.dataMapFactory = dataMapFactory;
/////////////////////////////////////////////////////////////////////////
0:         List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
0:         for (DataMap dataMap : dataMaps) {
/////////////////////////////////////////////////////////////////////////
0:       List<DataMapDistributable> list = dataMapFactory.toDistributable(segment);
/////////////////////////////////////////////////////////////////////////
0:     List<DataMap> dataMaps = dataMapFactory.getDataMaps(distributable);
0:     for (DataMap dataMap : dataMaps) {
0:           dataMap.prune(
/////////////////////////////////////////////////////////////////////////
0:     if (dataMapFactory.getDataMapType() == DataMapLevel.FG) {
0:       if (dataMapFactory.getDataMapType() == DataMapLevel.FG) {
/////////////////////////////////////////////////////////////////////////
0:       dataMapFactory.clear(segment);
/////////////////////////////////////////////////////////////////////////
0:     dataMapFactory.clear();
1:   public DataMapFactory getDataMapFactory() {
1:     return dataMapFactory;
0:     dataMapFactory.fireEvent(event);
/////////////////////////////////////////////////////////////////////////
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
0:       for (DataMap dataMap : dataMaps) {
commit:89a12af
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.datamap.dev.IndexDataMap;
0: import org.apache.carbondata.core.datamap.dev.IndexDataMapFactory;
/////////////////////////////////////////////////////////////////////////
0:  * IndexDataMap at the table level, user can add any number of datamaps for one table. Depends
/////////////////////////////////////////////////////////////////////////
0:   private IndexDataMapFactory indexDataMapFactory;
/////////////////////////////////////////////////////////////////////////
0:       IndexDataMapFactory indexDataMapFactory, BlockletDetailsFetcher blockletDetailsFetcher,
0:     this.indexDataMapFactory = indexDataMapFactory;
/////////////////////////////////////////////////////////////////////////
0:         List<IndexDataMap> dataMaps = indexDataMapFactory.getDataMaps(segment);
0:         for (IndexDataMap dataMap : dataMaps) {
/////////////////////////////////////////////////////////////////////////
0:       List<DataMapDistributable> list = indexDataMapFactory.toDistributable(segment);
/////////////////////////////////////////////////////////////////////////
0:     List<IndexDataMap> indexDataMaps = indexDataMapFactory.getDataMaps(distributable);
0:     for (IndexDataMap indexDataMap : indexDataMaps) {
0:           indexDataMap.prune(
/////////////////////////////////////////////////////////////////////////
0:     if (indexDataMapFactory.getDataMapType() == DataMapType.FG) {
0:       if (indexDataMapFactory.getDataMapType() == DataMapType.FG) {
/////////////////////////////////////////////////////////////////////////
0:       indexDataMapFactory.clear(segment);
/////////////////////////////////////////////////////////////////////////
0:     indexDataMapFactory.clear();
0:   public IndexDataMapFactory getIndexDataMapFactory() {
0:     return indexDataMapFactory;
0:     indexDataMapFactory.fireEvent(event);
/////////////////////////////////////////////////////////////////////////
0:       List<IndexDataMap> dataMaps = indexDataMapFactory.getDataMaps(segment);
0:       for (IndexDataMap dataMap : dataMaps) {
commit:89cfd8e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.indexstore.PartitionSpec;
/////////////////////////////////////////////////////////////////////////
1:       }
0:       detailedBlocklet.setSegmentId(distributable.getSegment().getSegmentNo());
commit:f089287
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.core.datamap;
1: import java.io.IOException;
0: import org.apache.carbondata.core.datamap.dev.DataMap;
0: import org.apache.carbondata.core.datamap.dev.DataMapFactory;
1: import org.apache.carbondata.core.indexstore.Blocklet;
1: 
/////////////////////////////////////////////////////////////////////////
0:   public List<Blocklet> prune(List<String> segmentIds, FilterResolverIntf filterExp)
1:       throws IOException {
/////////////////////////////////////////////////////////////////////////
0:   public List<DataMapDistributable> toDistributable(List<String> segmentIds) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:   public DataMapFactory getDataMapFactory() {
0:     return dataMapFactory;
1:   }
author:sounakr
-------------------------------------------------------------------------------
commit:c58eb43
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       List<PartitionSpec> partitions) throws IOException {
0:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions);
0:         List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
0:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment);
1:           blockletDetailsFetcher.getExtendedBlocklets(pruneBlocklets, segment),
/////////////////////////////////////////////////////////////////////////
0:       FilterResolverIntf filterExp, List<PartitionSpec> partitions) throws IOException {
0:     List<DataMap> dataMaps = dataMapFactory.getDataMaps(distributable);
0:           segmentPropertiesFetcher.getSegmentProperties(distributable.getSegment()),
/////////////////////////////////////////////////////////////////////////
1:           .getExtendedBlocklet(blocklet, distributable.getSegment());
/////////////////////////////////////////////////////////////////////////
1:   public List<Segment> pruneSegments(List<Segment> segments, FilterResolverIntf filterExp)
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment);
commit:ca7e2e3
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1: import org.apache.carbondata.core.indexstore.SegmentPropertiesFetcher;
/////////////////////////////////////////////////////////////////////////
1:   private SegmentPropertiesFetcher segmentPropertiesFetcher;
0: 
0:       DataMapFactory dataMapFactory, BlockletDetailsFetcher blockletDetailsFetcher,
1:       SegmentPropertiesFetcher segmentPropertiesFetcher) {
1:     this.segmentPropertiesFetcher = segmentPropertiesFetcher;
/////////////////////////////////////////////////////////////////////////
1:     SegmentProperties segmentProperties;
0:       segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment.getSegmentNo());
0:         pruneBlocklets.addAll(dataMap.prune(filterExp, segmentProperties, partitions));
/////////////////////////////////////////////////////////////////////////
0:       blocklets.addAll(
0:           dataMap.prune(
0:               filterExp,
0:               segmentPropertiesFetcher.getSegmentProperties(distributable.getSegmentId()),
1:               partitions));
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:280a400
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.readcommitter.ReadCommittedScope;
/////////////////////////////////////////////////////////////////////////
0:    * @param readCommittedScope
0:       List<PartitionSpec> partitions, ReadCommittedScope readCommittedScope) throws IOException {
0:         pruneBlocklets = blockletDetailsFetcher.getAllBlocklets(segment, partitions,
0:             readCommittedScope);
0:         List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment, readCommittedScope);
0:         segmentProperties = segmentPropertiesFetcher.getSegmentProperties(segment,
0:             readCommittedScope);
1:       blocklets.addAll(addSegmentId(
0:           blockletDetailsFetcher.getExtendedBlocklets(pruneBlocklets, segment, readCommittedScope),
0:           segment.getSegmentNo()));
/////////////////////////////////////////////////////////////////////////
0:    * @param readCommittedScope
0:       FilterResolverIntf filterExp, List<PartitionSpec> partitions,
0:       ReadCommittedScope readCommittedScope) throws IOException {
0:     List<DataMap> dataMaps = dataMapFactory.getDataMaps(distributable, readCommittedScope);
1:       blocklets.addAll(dataMap.prune(filterExp,
0:           segmentPropertiesFetcher.getSegmentProperties(distributable.getSegment(),
0:               readCommittedScope),
0:           partitions));
/////////////////////////////////////////////////////////////////////////
1:       ExtendedBlocklet detailedBlocklet = blockletDetailsFetcher
0:           .getExtendedBlocklet(blocklet, distributable.getSegment(), readCommittedScope);
/////////////////////////////////////////////////////////////////////////
0:    * @param readCommittedScope
0:   public List<Segment> pruneSegments(List<Segment> segments, FilterResolverIntf filterExp,
0:       ReadCommittedScope readCommittedScope)
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segment, readCommittedScope);
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:56330ae
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.schema.table.DataMapSchema;
/////////////////////////////////////////////////////////////////////////
1:   private DataMapSchema dataMapSchema;
/////////////////////////////////////////////////////////////////////////
0:   public TableDataMap(AbsoluteTableIdentifier identifier, DataMapSchema dataMapSchema,
1:     this.dataMapSchema = dataMapSchema;
/////////////////////////////////////////////////////////////////////////
1:         distributable.setDataMapSchema(dataMapSchema);
/////////////////////////////////////////////////////////////////////////
1:         identifier.getTablePath() + CarbonCommonConstants.FILE_SEPARATOR + dataMapSchema
1:             .getDataMapName();
/////////////////////////////////////////////////////////////////////////
0: 
1:   public DataMapSchema getDataMapSchema() {
1:     return dataMapSchema;
commit:28f78b2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.indexstore.BlockletDetailsFetcher;
1: import org.apache.carbondata.core.indexstore.ExtendedBlocklet;
/////////////////////////////////////////////////////////////////////////
1:   private BlockletDetailsFetcher blockletDetailsFetcher;
0: 
0:   public TableDataMap(AbsoluteTableIdentifier identifier, String dataMapName,
0:       DataMapFactory dataMapFactory, BlockletDetailsFetcher blockletDetailsFetcher) {
1:     this.blockletDetailsFetcher = blockletDetailsFetcher;
/////////////////////////////////////////////////////////////////////////
0:   public List<ExtendedBlocklet> prune(List<String> segmentIds, FilterResolverIntf filterExp)
1:     List<ExtendedBlocklet> blocklets = new ArrayList<>();
1:       List<Blocklet> pruneBlocklets = new ArrayList<>();
0:         pruneBlocklets.addAll(dataMap.prune(filterExp));
0:       blocklets.addAll(addSegmentId(blockletDetailsFetcher
0:           .getExtendedBlocklets(pruneBlocklets, segmentId), segmentId));
1:   private List<ExtendedBlocklet> addSegmentId(List<ExtendedBlocklet> pruneBlocklets,
1:       String segmentId) {
1:     for (ExtendedBlocklet blocklet : pruneBlocklets) {
/////////////////////////////////////////////////////////////////////////
0:   public List<ExtendedBlocklet> prune(DataMapDistributable distributable,
0:       FilterResolverIntf filterExp) throws IOException {
1:     List<ExtendedBlocklet> detailedBlocklets = new ArrayList<>();
0:       ExtendedBlocklet detailedBlocklet =
0:           blockletDetailsFetcher.getExtendedBlocklet(blocklet, distributable.getSegmentId());
0:       detailedBlocklet.setSegmentId(distributable.getSegmentId());
1:       detailedBlocklets.add(detailedBlocklet);
1:     return detailedBlocklets;
commit:1e21cd1
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
/////////////////////////////////////////////////////////////////////////
0:   private AbsoluteTableIdentifier identifier;
0: 
/////////////////////////////////////////////////////////////////////////
0:   public TableDataMap(AbsoluteTableIdentifier identifier,
0:       String dataMapName, DataMapFactory dataMapFactory) {
0:     this.identifier = identifier;
/////////////////////////////////////////////////////////////////////////
0:       List<DataMapDistributable> list = dataMapFactory.toDistributable(segmentsId);
0:       for (DataMapDistributable distributable: list) {
0:         distributable.setDataMapName(dataMapName);
0:         distributable.setSegmentId(segmentsId);
1:         distributable.setTablePath(identifier.getTablePath());
0:         distributable.setDataMapFactoryClass(dataMapFactory.getClass().getName());
1:       distributables.addAll(list);
/////////////////////////////////////////////////////////////////////////
0:     List<Blocklet> blocklets = dataMapFactory.getDataMap(distributable).prune(filterExp);
0:     for (Blocklet blocklet: blocklets) {
0:       blocklet.setSegmentId(distributable.getSegmentId());
1:     }
0:     return blocklets;
author:rahulforallp
-------------------------------------------------------------------------------
commit:65471f2
/////////////////////////////////////////////////////////////////////////
0:   public List<Segment> pruneSegments(List<Segment> segments, FilterResolverIntf filterExp)
1:     List<Segment> prunedSegments = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:           prunedSegments.add(segment);
commit:4aa0f49
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.events.Event;
1: import org.apache.carbondata.events.OperationContext;
1: import org.apache.carbondata.events.OperationEventListener;
0: public final class TableDataMap implements OperationEventListener {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 
0:   @Override public void onEvent(Event event, OperationContext opContext) {
0:     dataMapFactory.fireEvent(event);
1:   }
author:kunal642
-------------------------------------------------------------------------------
commit:937868d
/////////////////////////////////////////////////////////////////////////
1: public final class TableDataMap extends OperationEventListener {
/////////////////////////////////////////////////////////////////////////
1:   @Override public void onEvent(Event event, OperationContext opContext) throws Exception {
author:manishgupta88
-------------------------------------------------------------------------------
commit:2bad144
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
/////////////////////////////////////////////////////////////////////////
0: 
0:   /**
1:    * Method to prune the segments based on task min/max values
0:    *
0:    * @param segmentIds
0:    * @param filterExp
0:    * @return
1:    * @throws IOException
0:    */
0:   public List<String> pruneSegments(List<String> segmentIds, FilterResolverIntf filterExp)
0:       throws IOException {
0:     List<String> prunedSegments = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
0:     for (String segmentId : segmentIds) {
0:       List<DataMap> dataMaps = dataMapFactory.getDataMaps(segmentId);
0:       for (DataMap dataMap : dataMaps) {
1:         if (dataMap.isScanRequired(filterExp)) {
1:           // If any one task in a given segment contains the data that means the segment need to
1:           // be scanned and we need to validate further data maps in the same segment
0:           prunedSegments.add(segmentId);
1:           break;
1:         }
1:       }
1:     }
1:     return prunedSegments;
1:   }
author:sraghunandan
-------------------------------------------------------------------------------
commit:500654e
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   public TableDataMap(String dataMapName,
============================================================================
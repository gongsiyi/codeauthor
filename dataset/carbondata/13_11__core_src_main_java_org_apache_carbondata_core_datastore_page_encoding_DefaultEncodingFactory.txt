1:edda248: /*
1:edda248:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:edda248:  * contributor license agreements.  See the NOTICE file distributed with
1:edda248:  * this work for additional information regarding copyright ownership.
1:edda248:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:edda248:  * (the "License"); you may not use this file except in compliance with
1:edda248:  * the License.  You may obtain a copy of the License at
1:edda248:  *
1:edda248:  *    http://www.apache.org/licenses/LICENSE-2.0
1:edda248:  *
1:edda248:  * Unless required by applicable law or agreed to in writing, software
1:edda248:  * distributed under the License is distributed on an "AS IS" BASIS,
1:edda248:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:edda248:  * See the License for the specific language governing permissions and
1:edda248:  * limitations under the License.
1:edda248:  */
10:edda248: 
1:edda248: package org.apache.carbondata.core.datastore.page.encoding;
1:a5af0ff: 
1:6f20437: import java.math.BigDecimal;
1:6f20437: 
1:a5af0ff: import org.apache.carbondata.core.datastore.TableSpec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.ColumnPage;
1:6f20437: import org.apache.carbondata.core.datastore.page.DecimalColumnPage;
1:11661eb: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveDeltaFloatingCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveDeltaIntegralCodec;
1:4f7487d: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveFloatingCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveIntegralCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.compress.DirectCompressCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.ComplexDimensionIndexCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.DictDimensionIndexCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.DirectDictDimensionIndexCodec;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.HighCardDictDimensionIndexCodec;
1:438b442: import org.apache.carbondata.core.datastore.page.statistics.PrimitivePageStatsCollector;
1:bc3e684: import org.apache.carbondata.core.datastore.page.statistics.SimpleStatsResult;
1:edda248: import org.apache.carbondata.core.metadata.datatype.DataType;
1:956833e: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:6f20437: import org.apache.carbondata.core.metadata.datatype.DecimalConverterFactory;
1:edda248: 
1:edda248: /**
1:8c1ddbf:  * Default factory will select encoding base on column page data type and statistics
1:edda248:  */
1:8c1ddbf: public class DefaultEncodingFactory extends EncodingFactory {
1:edda248: 
1:7d386a4:   private static final int THREE_BYTES_MAX = (int) Math.pow(2, 23) - 1;
1:7d386a4:   private static final int THREE_BYTES_MIN = - THREE_BYTES_MAX - 1;
1:7d386a4: 
1:e6a4f64:   private static final boolean newWay = false;
1:e6a4f64: 
1:8c1ddbf:   private static EncodingFactory encodingFactory = new DefaultEncodingFactory();
1:8c1ddbf: 
1:8c1ddbf:   public static EncodingFactory getInstance() {
1:8c1ddbf:     // TODO: make it configurable after added new encodingFactory
1:8c1ddbf:     return encodingFactory;
1:8c1ddbf:   }
1:8c1ddbf: 
1:e6a4f64:   @Override
1:e6a4f64:   public ColumnPageEncoder createEncoder(TableSpec.ColumnSpec columnSpec, ColumnPage inputPage) {
1:e6a4f64:     // TODO: add log
1:e6a4f64:     if (columnSpec instanceof TableSpec.MeasureSpec) {
1:e6a4f64:       return createEncoderForMeasure(inputPage);
1:e6a4f64:     } else {
1:e6a4f64:       if (newWay) {
1:e6a4f64:         return createEncoderForDimension((TableSpec.DimensionSpec) columnSpec, inputPage);
1:e6a4f64:       } else {
1:bb0b347:         assert columnSpec instanceof TableSpec.DimensionSpec;
1:e6a4f64:         return createEncoderForDimensionLegacy((TableSpec.DimensionSpec) columnSpec);
1:e6a4f64:       }
1:e6a4f64:     }
1:e6a4f64:   }
1:e6a4f64: 
1:e6a4f64:   private ColumnPageEncoder createEncoderForDimension(TableSpec.DimensionSpec columnSpec,
1:e6a4f64:       ColumnPage inputPage) {
1:8c1ddbf:     switch (columnSpec.getColumnType()) {
1:e6a4f64:       case GLOBAL_DICTIONARY:
1:e6a4f64:       case DIRECT_DICTIONARY:
1:e6a4f64:       case PLAIN_VALUE:
1:e6a4f64:         return new DirectCompressCodec(inputPage.getDataType()).createEncoder(null);
1:e6a4f64:       case COMPLEX:
1:8f08c4a:         return new ComplexDimensionIndexCodec(false, false).createEncoder(null);
1:e6a4f64:       default:
1:8f08c4a:         throw new RuntimeException("unsupported dimension type: " + columnSpec.getColumnType());
1:e6a4f64:     }
1:e6a4f64:   }
1:e6a4f64: 
1:910d496:   private ColumnPageEncoder createEncoderForDimensionLegacy(TableSpec.DimensionSpec dimensionSpec) {
1:8c1ddbf:     switch (dimensionSpec.getColumnType()) {
1:e6a4f64:       case GLOBAL_DICTIONARY:
1:e6a4f64:         return new DictDimensionIndexCodec(
1:e6a4f64:             dimensionSpec.isInSortColumns(),
1:8f08c4a:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex())
1:8f08c4a:             .createEncoder(null);
1:e6a4f64:       case DIRECT_DICTIONARY:
1:e6a4f64:         return new DirectDictDimensionIndexCodec(
1:e6a4f64:             dimensionSpec.isInSortColumns(),
1:8f08c4a:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex())
1:8f08c4a:             .createEncoder(null);
1:e6a4f64:       case PLAIN_VALUE:
1:e6a4f64:         return new HighCardDictDimensionIndexCodec(
1:e6a4f64:             dimensionSpec.isInSortColumns(),
3:e6a4f64:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
1:8f08c4a:             dimensionSpec.getSchemaDataType() == DataTypes.VARCHAR)
1:8f08c4a:             .createEncoder(null);
1:e6a4f64:       default:
2:e6a4f64:         throw new RuntimeException("unsupported dimension type: " +
1:8c1ddbf:             dimensionSpec.getColumnType());
1:e6a4f64:     }
1:e6a4f64:   }
1:e6a4f64: 
1:e6a4f64:   private ColumnPageEncoder createEncoderForMeasure(ColumnPage columnPage) {
1:e6a4f64:     SimpleStatsResult stats = columnPage.getStatistics();
1:956833e:     DataType dataType = stats.getDataType();
1:6abdd97:     if (dataType == DataTypes.BOOLEAN) {
1:0647348:       return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:6abdd97:     } else if (dataType == DataTypes.BYTE ||
1:956833e:         dataType == DataTypes.SHORT ||
1:956833e:         dataType == DataTypes.INT ||
1:956833e:         dataType == DataTypes.LONG) {
1:438b442:       return selectCodecByAlgorithmForIntegral(stats, false).createEncoder(null);
1:f209e8e:     } else if (DataTypes.isDecimal(dataType)) {
1:956833e:       return createEncoderForDecimalDataTypeMeasure(columnPage);
1:438b442:     } else if (dataType == DataTypes.FLOAT || dataType == DataTypes.DOUBLE) {
1:438b442:       return selectCodecByAlgorithmForFloating(stats, false).createEncoder(null);
1:956833e:     } else if (dataType == DataTypes.BYTE_ARRAY) {
1:956833e:       return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:956833e:     } else {
1:956833e:       throw new RuntimeException("unsupported data type: " + stats.getDataType());
1:e6a4f64:     }
1:e6a4f64:   }
1:e6a4f64: 
1:6f20437:   private ColumnPageEncoder createEncoderForDecimalDataTypeMeasure(ColumnPage columnPage) {
1:6f20437:     DecimalConverterFactory.DecimalConverterType decimalConverterType =
1:6f20437:         ((DecimalColumnPage) columnPage).getDecimalConverter().getDecimalConverterType();
1:6f20437:     switch (decimalConverterType) {
1:6f20437:       case DECIMAL_INT:
1:6f20437:       case DECIMAL_LONG:
1:6f20437:         return selectCodecByAlgorithmForDecimal(columnPage.getStatistics(), decimalConverterType)
1:6f20437:             .createEncoder(null);
1:e6a4f64:       default:
1:e6a4f64:         return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:6f20437:     }
1:6f20437:   }
1:6f20437: 
1:e6a4f64:   private static DataType fitLongMinMax(long max, long min) {
1:edda248:     if (max <= Byte.MAX_VALUE && min >= Byte.MIN_VALUE) {
1:956833e:       return DataTypes.BYTE;
1:edda248:     } else if (max <= Short.MAX_VALUE && min >= Short.MIN_VALUE) {
1:956833e:       return DataTypes.SHORT;
1:7d386a4:     } else if (max <= THREE_BYTES_MAX && min >= THREE_BYTES_MIN) {
1:956833e:       return DataTypes.SHORT_INT;
1:edda248:     } else if (max <= Integer.MAX_VALUE && min >= Integer.MIN_VALUE) {
1:956833e:       return DataTypes.INT;
7:edda248:     } else {
1:956833e:       return DataTypes.LONG;
1:a5af0ff:     }
1:a5af0ff:   }
1:edda248: 
1:e6a4f64:   private static DataType fitMinMax(DataType dataType, Object max, Object min) {
1:438b442:     if (dataType == DataTypes.BYTE || dataType == DataTypes.BOOLEAN) {
1:956833e:       return fitLongMinMax((byte) max, (byte) min);
1:956833e:     } else if (dataType == DataTypes.SHORT) {
1:956833e:       return fitLongMinMax((short) max, (short) min);
1:956833e:     } else if (dataType == DataTypes.INT) {
1:956833e:       return fitLongMinMax((int) max, (int) min);
1:438b442:     } else if ((dataType == DataTypes.LONG) || (dataType == DataTypes.TIMESTAMP)) {
1:956833e:       return fitLongMinMax((long) max, (long) min);
1:956833e:     } else if (dataType == DataTypes.DOUBLE) {
1:956833e:       return fitLongMinMax((long) (double) max, (long) (double) min);
1:956833e:     } else {
1:956833e:       throw new RuntimeException("internal error: " + dataType);
1:bc3e684:     }
1:bc3e684:   }
1:bc3e684: 
1:6f20437:   private static DataType fitMinMaxForDecimalType(DataType dataType, Object max, Object min,
1:6f20437:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:6f20437:     long maxValue = ((BigDecimal) max).unscaledValue().longValue();
1:6f20437:     long minValue = ((BigDecimal) min).unscaledValue().longValue();
1:6f20437:     switch (decimalConverterType) {
1:6f20437:       case DECIMAL_INT:
1:6f20437:         return fitLongMinMax((int) maxValue, (int) minValue);
1:6f20437:       case DECIMAL_LONG:
1:6f20437:         return fitLongMinMax(maxValue, minValue);
1:6f20437:       default:
1:6f20437:         throw new RuntimeException("internal error: " + dataType);
1:6f20437:     }
1:6f20437:   }
1:6f20437: 
1:6f20437:   private static DataType fitDeltaForDecimalType(DataType dataType, Object max, Object min,
1:6f20437:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:6f20437:     long maxValue = ((BigDecimal) max).unscaledValue().longValue();
1:6f20437:     long minValue = ((BigDecimal) min).unscaledValue().longValue();
1:6f20437:     switch (decimalConverterType) {
1:6f20437:       case DECIMAL_INT:
1:6f20437:         long value = maxValue - minValue;
1:6f20437:         return compareMinMaxAndSelectDataType(value);
1:6f20437:       case DECIMAL_LONG:
1:956833e:         return DataTypes.LONG;
2:6f20437:       default:
1:6f20437:         throw new RuntimeException("internal error: " + dataType);
1:6f20437:     }
1:6f20437:   }
1:6f20437: 
1:bc3e684:   // fit the long input value into minimum data type
1:e6a4f64:   private static DataType fitDelta(DataType dataType, Object max, Object min) {
1:bc3e684:     // use long data type to calculate delta to avoid overflow
1:bc3e684:     long value;
1:438b442:     if (dataType == DataTypes.BYTE || dataType == DataTypes.BOOLEAN) {
1:956833e:       value = (long) (byte) max - (long) (byte) min;
1:956833e:     } else if (dataType == DataTypes.SHORT) {
1:956833e:       value = (long) (short) max - (long) (short) min;
1:956833e:     } else if (dataType == DataTypes.INT) {
1:956833e:       value = (long) (int) max - (long) (int) min;
1:438b442:     } else if (dataType == DataTypes.LONG || dataType == DataTypes.TIMESTAMP) {
1:38038ad:       value = (long) max - (long) min;
1:38038ad:       // The subtraction overflowed iff the operands have opposing signs
1:38038ad:       // and the result's sign differs from the minuend.
1:38038ad:       boolean overflow = (((long) max ^ (long) min) & ((long) max ^ value)) < 0;
1:38038ad:       if (overflow) {
1:38038ad:         return DataTypes.LONG;
1:38038ad:       }
1:956833e:     } else if (dataType == DataTypes.DOUBLE) {
2:956833e:       return DataTypes.LONG;
1:956833e:     } else {
1:956833e:       throw new RuntimeException("internal error: " + dataType);
1:6f20437:     }
1:6f20437:     return compareMinMaxAndSelectDataType(value);
1:bc3e684:   }
1:6f20437: 
1:6f20437:   private static DataType compareMinMaxAndSelectDataType(long value) {
1:bc3e684:     if (value <= Byte.MAX_VALUE && value >= Byte.MIN_VALUE) {
1:956833e:       return DataTypes.BYTE;
1:bc3e684:     } else if (value <= Short.MAX_VALUE && value >= Short.MIN_VALUE) {
1:956833e:       return DataTypes.SHORT;
1:bc3e684:     } else if (value <= THREE_BYTES_MAX && value >= THREE_BYTES_MIN) {
1:956833e:       return DataTypes.SHORT_INT;
1:bc3e684:     } else if (value <= Integer.MAX_VALUE && value >= Integer.MIN_VALUE) {
1:956833e:       return DataTypes.INT;
1:bc3e684:     } else {
1:956833e:       return DataTypes.LONG;
1:bc3e684:     }
1:bc3e684:   }
1:bc3e684: 
1:e6a4f64:   /**
1:e6a4f64:    * choose between adaptive encoder or delta adaptive encoder, based on whose target data type
1:e6a4f64:    * size is smaller
1:e6a4f64:    */
1:438b442:   static ColumnPageCodec selectCodecByAlgorithmForIntegral(SimpleStatsResult stats,
1:438b442:       boolean isComplexPrimitive) {
1:eadfea7:     DataType srcDataType = stats.getDataType();
1:bc3e684:     DataType adaptiveDataType = fitMinMax(stats.getDataType(), stats.getMax(), stats.getMin());
1:6f20437: 
1:f911403:     DataType deltaDataType = fitDelta(stats.getDataType(), stats.getMax(), stats.getMin());
1:438b442:     // for complex primitive, if source and destination data type is same, use adaptive encoding.
1:438b442:     if (!isComplexPrimitive) {
1:438b442:       // in case of decimal datatype, check if the decimal converter type is Int or Long and based
1:438b442:       // on that get size in bytes
1:438b442:       if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) == srcDataType
1:438b442:           .getSizeInBytes()) {
1:438b442:         // no effect to use adaptive or delta, use compression only
1:438b442:         return new DirectCompressCodec(stats.getDataType());
1:438b442:       }
1:eadfea7:     }
2:edda248:     if (adaptiveDataType.getSizeInBytes() <= deltaDataType.getSizeInBytes()) {
2:edda248:       // choose adaptive encoding
1:e6a4f64:       return new AdaptiveIntegralCodec(stats.getDataType(), adaptiveDataType, stats);
1:6f20437:     } else {
2:edda248:       // choose delta adaptive encoding
1:e6a4f64:       return new AdaptiveDeltaIntegralCodec(stats.getDataType(), deltaDataType, stats);
15:edda248:     }
1:edda248:   }
1:edda248: 
1:4f7487d:   // choose between upscale adaptive encoder or upscale delta adaptive encoder,
1:4f7487d:   // based on whose target data type size is smaller
1:438b442:   static ColumnPageCodec selectCodecByAlgorithmForFloating(SimpleStatsResult stats,
1:438b442:       boolean isComplexPrimitive) {
1:4f7487d:     DataType srcDataType = stats.getDataType();
1:4f7487d:     double maxValue = (double) stats.getMax();
1:4f7487d:     double minValue = (double) stats.getMin();
1:4f7487d:     int decimalCount = stats.getDecimalCount();
1:4f7487d: 
1:438b442:     // For Complex Type primitive we should always choose adaptive path
1:438b442:     // as LV format will be reduced to only V format. Therefore inorder
1:438b442:     // to do that decimal count should be actual count instead of -1.
1:438b442:     if (isComplexPrimitive && decimalCount == -1 && stats instanceof PrimitivePageStatsCollector) {
1:438b442:       decimalCount = ((PrimitivePageStatsCollector)stats).getDecimalForComplexPrimitive();
1:438b442:     }
1:438b442: 
1:4f7487d:     //Here we should use the Max abs as max to getDatatype, let's say -1 and -10000000, -1 is max,
1:4f7487d:     //but we can't use -1 to getDatatype, we should use -10000000.
1:4f7487d:     double absMaxValue = Math.max(Math.abs(maxValue), Math.abs(minValue));
1:4f7487d:     if (decimalCount == 0) {
1:4f7487d:       // short, int, long
1:438b442:       return selectCodecByAlgorithmForIntegral(stats, false);
1:438b442:     } else if (decimalCount < 0 && !isComplexPrimitive) {
1:956833e:       return new DirectCompressCodec(DataTypes.DOUBLE);
1:4f7487d:     } else {
1:4f7487d:       // double
1:91837a6:       // If absMaxValue exceeds LONG.MAX_VALUE, then go for direct compression
1:91837a6:       if ((Math.pow(10, decimalCount) * absMaxValue) > Long.MAX_VALUE) {
1:956833e:         return new DirectCompressCodec(DataTypes.DOUBLE);
1:91837a6:       } else {
1:91837a6:         long max = (long) (Math.pow(10, decimalCount) * absMaxValue);
1:91837a6:         DataType adaptiveDataType = fitLongMinMax(max, 0);
1:91837a6:         DataType deltaDataType = compareMinMaxAndSelectDataType(
1:91837a6:             (long) (Math.pow(10, decimalCount) * (maxValue - minValue)));
1:91837a6:         if (adaptiveDataType.getSizeInBytes() > deltaDataType.getSizeInBytes()) {
1:91837a6:           return new AdaptiveDeltaFloatingCodec(srcDataType, deltaDataType, stats);
1:91837a6:         } else if (adaptiveDataType.getSizeInBytes() < DataTypes.DOUBLE.getSizeInBytes() || (
1:91837a6:             (isComplexPrimitive) && (adaptiveDataType.getSizeInBytes() == DataTypes.DOUBLE
1:91837a6:                 .getSizeInBytes()))) {
1:91837a6:           return new AdaptiveFloatingCodec(srcDataType, adaptiveDataType, stats);
1:91837a6:         } else {
1:91837a6:           return new DirectCompressCodec(DataTypes.DOUBLE);
1:91837a6:         }
1:4f7487d:       }
1:4f7487d:     }
1:4f7487d:   }
1:4f7487d: 
1:6f20437:   /**
1:6f20437:    * choose between adaptive encoder or delta adaptive encoder, based on whose target data type
1:6f20437:    * size is smaller for decimal data type
1:6f20437:    */
1:6f20437:   static ColumnPageCodec selectCodecByAlgorithmForDecimal(SimpleStatsResult stats,
1:6f20437:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:6f20437:     DataType srcDataType = stats.getDataType();
1:6f20437:     DataType adaptiveDataType =
1:6f20437:         fitMinMaxForDecimalType(stats.getDataType(), stats.getMax(), stats.getMin(),
1:6f20437:             decimalConverterType);
1:6f20437:     DataType deltaDataType;
1:4f7487d: 
1:956833e:     if (adaptiveDataType == DataTypes.LONG) {
1:956833e:       deltaDataType = DataTypes.LONG;
1:4f7487d:     } else {
1:6f20437:       deltaDataType = fitDeltaForDecimalType(stats.getDataType(), stats.getMax(), stats.getMin(),
1:6f20437:           decimalConverterType);
1:6f20437:     }
1:6f20437:     // in case of decimal data type check if the decimal converter type is Int or Long and based on
1:6f20437:     // that get size in bytes
1:6f20437:     if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) == srcDataType
1:6f20437:         .getSizeInBytes()) {
1:6f20437:       // no effect to use adaptive or delta, use compression only
1:e6a4f64:       return new DirectCompressCodec(stats.getDataType());
1:6f20437:     }
1:6f20437:     if (adaptiveDataType.getSizeInBytes() <= deltaDataType.getSizeInBytes()) {
1:6f20437:       // choose adaptive encoding
1:6f20437:       return new AdaptiveIntegralCodec(stats.getDataType(), adaptiveDataType, stats);
1:6f20437:     } else {
1:6f20437:       // choose delta adaptive encoding
1:6f20437:       return new AdaptiveDeltaIntegralCodec(stats.getDataType(), deltaDataType, stats);
1:6f20437:     }
1:6f20437:   }
1:6f20437: 
1:edda248: }
============================================================================
author:xuchuanyin
-------------------------------------------------------------------------------
commit:8f08c4a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         return new ComplexDimensionIndexCodec(false, false).createEncoder(null);
1:         throw new RuntimeException("unsupported dimension type: " + columnSpec.getColumnType());
1:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex())
1:             .createEncoder(null);
1:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex())
1:             .createEncoder(null);
1:             dimensionSpec.getSchemaDataType() == DataTypes.VARCHAR)
1:             .createEncoder(null);
commit:dc53dee
/////////////////////////////////////////////////////////////////////////
0:             dimensionSpec.getSchemaDataType() == DataTypes.VARCHAR,
commit:910d496
/////////////////////////////////////////////////////////////////////////
1:   private ColumnPageEncoder createEncoderForDimensionLegacy(TableSpec.DimensionSpec dimensionSpec) {
author:Indhumathi27
-------------------------------------------------------------------------------
commit:91837a6
/////////////////////////////////////////////////////////////////////////
1:       // If absMaxValue exceeds LONG.MAX_VALUE, then go for direct compression
1:       if ((Math.pow(10, decimalCount) * absMaxValue) > Long.MAX_VALUE) {
1:       } else {
1:         long max = (long) (Math.pow(10, decimalCount) * absMaxValue);
1:         DataType adaptiveDataType = fitLongMinMax(max, 0);
1:         DataType deltaDataType = compareMinMaxAndSelectDataType(
1:             (long) (Math.pow(10, decimalCount) * (maxValue - minValue)));
1:         if (adaptiveDataType.getSizeInBytes() > deltaDataType.getSizeInBytes()) {
1:           return new AdaptiveDeltaFloatingCodec(srcDataType, deltaDataType, stats);
1:         } else if (adaptiveDataType.getSizeInBytes() < DataTypes.DOUBLE.getSizeInBytes() || (
1:             (isComplexPrimitive) && (adaptiveDataType.getSizeInBytes() == DataTypes.DOUBLE
1:                 .getSizeInBytes()))) {
1:           return new AdaptiveFloatingCodec(srcDataType, adaptiveDataType, stats);
1:         } else {
1:           return new DirectCompressCodec(DataTypes.DOUBLE);
1:         }
author:sraghunandan
-------------------------------------------------------------------------------
commit:f911403
/////////////////////////////////////////////////////////////////////////
1:     DataType deltaDataType = fitDelta(stats.getDataType(), stats.getMax(), stats.getMin());
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:438b442
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.statistics.PrimitivePageStatsCollector;
/////////////////////////////////////////////////////////////////////////
1:       return selectCodecByAlgorithmForIntegral(stats, false).createEncoder(null);
1:     } else if (dataType == DataTypes.FLOAT || dataType == DataTypes.DOUBLE) {
1:       return selectCodecByAlgorithmForFloating(stats, false).createEncoder(null);
/////////////////////////////////////////////////////////////////////////
1:     if (dataType == DataTypes.BYTE || dataType == DataTypes.BOOLEAN) {
1:     } else if ((dataType == DataTypes.LONG) || (dataType == DataTypes.TIMESTAMP)) {
/////////////////////////////////////////////////////////////////////////
1:     if (dataType == DataTypes.BYTE || dataType == DataTypes.BOOLEAN) {
1:     } else if (dataType == DataTypes.LONG || dataType == DataTypes.TIMESTAMP) {
/////////////////////////////////////////////////////////////////////////
1:   static ColumnPageCodec selectCodecByAlgorithmForIntegral(SimpleStatsResult stats,
1:       boolean isComplexPrimitive) {
/////////////////////////////////////////////////////////////////////////
1:     // for complex primitive, if source and destination data type is same, use adaptive encoding.
1:     if (!isComplexPrimitive) {
1:       // in case of decimal datatype, check if the decimal converter type is Int or Long and based
1:       // on that get size in bytes
1:       if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) == srcDataType
1:           .getSizeInBytes()) {
1:         // no effect to use adaptive or delta, use compression only
1:         return new DirectCompressCodec(stats.getDataType());
1:       }
/////////////////////////////////////////////////////////////////////////
1:   static ColumnPageCodec selectCodecByAlgorithmForFloating(SimpleStatsResult stats,
1:       boolean isComplexPrimitive) {
1:     // For Complex Type primitive we should always choose adaptive path
1:     // as LV format will be reduced to only V format. Therefore inorder
1:     // to do that decimal count should be actual count instead of -1.
1:     if (isComplexPrimitive && decimalCount == -1 && stats instanceof PrimitivePageStatsCollector) {
1:       decimalCount = ((PrimitivePageStatsCollector)stats).getDecimalForComplexPrimitive();
1:     }
1: 
1:       return selectCodecByAlgorithmForIntegral(stats, false);
1:     } else if (decimalCount < 0 && !isComplexPrimitive) {
/////////////////////////////////////////////////////////////////////////
0:       } else if (adaptiveDataType.getSizeInBytes() < DataTypes.DOUBLE.getSizeInBytes() || (
0:           (isComplexPrimitive) && (adaptiveDataType.getSizeInBytes() == DataTypes.DOUBLE
0:               .getSizeInBytes()))) {
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:38038ad
/////////////////////////////////////////////////////////////////////////
1:       value = (long) max - (long) min;
1:       // The subtraction overflowed iff the operands have opposing signs
1:       // and the result's sign differs from the minuend.
1:       boolean overflow = (((long) max ^ (long) min) & ((long) max ^ value)) < 0;
1:       if (overflow) {
1:         return DataTypes.LONG;
1:       }
author:xubo245
-------------------------------------------------------------------------------
commit:0647348
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
commit:6abdd97
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.datastore.page.encoding.rle.RLECodec;
/////////////////////////////////////////////////////////////////////////
1:     if (dataType == DataTypes.BOOLEAN) {
0:       return new RLECodec().createEncoder(null);
1:     } else if (dataType == DataTypes.BYTE ||
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:11661eb
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveDeltaFloatingCodec;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       DataType deltaDataType = compareMinMaxAndSelectDataType(
0:           (long) (Math.pow(10, decimalCount) * (maxValue - minValue)));
0:       if (adaptiveDataType.getSizeInBytes() > deltaDataType.getSizeInBytes()) {
0:         return new AdaptiveDeltaFloatingCodec(srcDataType, deltaDataType, stats);
0:       } else if (adaptiveDataType.getSizeInBytes() < DataTypes.DOUBLE.getSizeInBytes()) {
author:Jacky Li
-------------------------------------------------------------------------------
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
1:     } else if (DataTypes.isDecimal(dataType)) {
commit:956833e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
1:     DataType dataType = stats.getDataType();
0:     if (dataType == DataTypes.BYTE ||
1:         dataType == DataTypes.SHORT ||
1:         dataType == DataTypes.INT ||
1:         dataType == DataTypes.LONG) {
0:       return selectCodecByAlgorithmForIntegral(stats).createEncoder(null);
0:     } else if (dataType == DataTypes.DECIMAL) {
1:       return createEncoderForDecimalDataTypeMeasure(columnPage);
0:     } else if (dataType == DataTypes.FLOAT ||
0:         dataType == DataTypes.DOUBLE) {
0:       return selectCodecByAlgorithmForFloating(stats).createEncoder(null);
1:     } else if (dataType == DataTypes.BYTE_ARRAY) {
1:       return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:     } else {
1:       throw new RuntimeException("unsupported data type: " + stats.getDataType());
/////////////////////////////////////////////////////////////////////////
1:       return DataTypes.BYTE;
1:       return DataTypes.SHORT;
1:       return DataTypes.SHORT_INT;
1:       return DataTypes.INT;
1:       return DataTypes.LONG;
0:     if (dataType == DataTypes.BYTE) {
1:       return fitLongMinMax((byte) max, (byte) min);
1:     } else if (dataType == DataTypes.SHORT) {
1:       return fitLongMinMax((short) max, (short) min);
1:     } else if (dataType == DataTypes.INT) {
1:       return fitLongMinMax((int) max, (int) min);
0:     } else if (dataType == DataTypes.LONG) {
1:       return fitLongMinMax((long) max, (long) min);
1:     } else if (dataType == DataTypes.DOUBLE) {
1:       return fitLongMinMax((long) (double) max, (long) (double) min);
1:     } else {
1:       throw new RuntimeException("internal error: " + dataType);
/////////////////////////////////////////////////////////////////////////
1:         return DataTypes.LONG;
/////////////////////////////////////////////////////////////////////////
0:     if (dataType == DataTypes.BYTE) {
1:       value = (long) (byte) max - (long) (byte) min;
1:     } else if (dataType == DataTypes.SHORT) {
1:       value = (long) (short) max - (long) (short) min;
1:     } else if (dataType == DataTypes.INT) {
1:       value = (long) (int) max - (long) (int) min;
0:     } else if (dataType == DataTypes.LONG) {
0:       // TODO: add overflow detection and return delta type
1:       return DataTypes.LONG;
1:     } else if (dataType == DataTypes.DOUBLE) {
1:       return DataTypes.LONG;
1:     } else {
1:       throw new RuntimeException("internal error: " + dataType);
1:       return DataTypes.BYTE;
1:       return DataTypes.SHORT;
1:       return DataTypes.SHORT_INT;
1:       return DataTypes.INT;
1:       return DataTypes.LONG;
/////////////////////////////////////////////////////////////////////////
1:     if (adaptiveDataType == DataTypes.LONG) {
1:       deltaDataType = DataTypes.LONG;
/////////////////////////////////////////////////////////////////////////
1:       return new DirectCompressCodec(DataTypes.DOUBLE);
0:       if (adaptiveDataType.getSizeInBytes() < DataTypes.DOUBLE.getSizeInBytes()) {
1:         return new DirectCompressCodec(DataTypes.DOUBLE);
/////////////////////////////////////////////////////////////////////////
0:     if (adaptiveDataType == DataTypes.LONG) {
0:       deltaDataType = DataTypes.LONG;
commit:8c1ddbf
/////////////////////////////////////////////////////////////////////////
1:  * Default factory will select encoding base on column page data type and statistics
1: public class DefaultEncodingFactory extends EncodingFactory {
1:   private static EncodingFactory encodingFactory = new DefaultEncodingFactory();
1: 
1:   public static EncodingFactory getInstance() {
1:     // TODO: make it configurable after added new encodingFactory
1:     return encodingFactory;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     switch (columnSpec.getColumnType()) {
/////////////////////////////////////////////////////////////////////////
0:             columnSpec.getColumnType());
1:     switch (dimensionSpec.getColumnType()) {
/////////////////////////////////////////////////////////////////////////
1:             dimensionSpec.getColumnType());
commit:4f7487d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveFloatingCodec;
/////////////////////////////////////////////////////////////////////////
0:         return selectCodecByAlgorithmForIntegral(stats).createEncoder(null);
0:         return selectCodecByAlgorithmForFloating(stats).createEncoder(null);
/////////////////////////////////////////////////////////////////////////
0:         return fitLongMinMax((long) (double) max, (long) (double) min);
/////////////////////////////////////////////////////////////////////////
0:       case DOUBLE:
0:         return DataType.LONG;
/////////////////////////////////////////////////////////////////////////
0:   static ColumnPageCodec selectCodecByAlgorithmForIntegral(SimpleStatsResult stats) {
/////////////////////////////////////////////////////////////////////////
1:   // choose between upscale adaptive encoder or upscale delta adaptive encoder,
1:   // based on whose target data type size is smaller
0:   static ColumnPageCodec selectCodecByAlgorithmForFloating(SimpleStatsResult stats) {
1:     DataType srcDataType = stats.getDataType();
1:     double maxValue = (double) stats.getMax();
1:     double minValue = (double) stats.getMin();
1:     int decimalCount = stats.getDecimalCount();
1: 
1:     //Here we should use the Max abs as max to getDatatype, let's say -1 and -10000000, -1 is max,
1:     //but we can't use -1 to getDatatype, we should use -10000000.
1:     double absMaxValue = Math.max(Math.abs(maxValue), Math.abs(minValue));
1: 
1:     if (decimalCount == 0) {
1:       // short, int, long
0:       return selectCodecByAlgorithmForIntegral(stats);
0:     } else if (decimalCount < 0) {
0:       return new DirectCompressCodec(DataType.DOUBLE);
1:     } else {
1:       // double
0:       long max = (long) (Math.pow(10, decimalCount) * absMaxValue);
0:       DataType adaptiveDataType = fitLongMinMax(max, 0);
0:       if (adaptiveDataType.getSizeInBytes() < DataType.DOUBLE.getSizeInBytes()) {
0:         return new AdaptiveFloatingCodec(srcDataType, adaptiveDataType, stats);
1:       } else {
0:         return new DirectCompressCodec(DataType.DOUBLE);
1:       }
1:     }
1:   }
1: 
commit:e6a4f64
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.ColumnPage;
1: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveDeltaIntegralCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.adaptive.AdaptiveIntegralCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.compress.DirectCompressCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.ComplexDimensionIndexCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.DictDimensionIndexCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.DirectDictDimensionIndexCodec;
1: import org.apache.carbondata.core.datastore.page.encoding.dimension.legacy.HighCardDictDimensionIndexCodec;
/////////////////////////////////////////////////////////////////////////
1:   private static final boolean newWay = false;
1: 
1:   @Override
1:   public ColumnPageEncoder createEncoder(TableSpec.ColumnSpec columnSpec, ColumnPage inputPage) {
1:     // TODO: add log
1:     if (columnSpec instanceof TableSpec.MeasureSpec) {
1:       return createEncoderForMeasure(inputPage);
1:     } else {
1:       if (newWay) {
1:         return createEncoderForDimension((TableSpec.DimensionSpec) columnSpec, inputPage);
1:       } else {
1:         return createEncoderForDimensionLegacy((TableSpec.DimensionSpec) columnSpec);
1:       }
1:     }
1:   }
1: 
1:   private ColumnPageEncoder createEncoderForDimension(TableSpec.DimensionSpec columnSpec,
1:       ColumnPage inputPage) {
0:     Compressor compressor = CompressorFactory.getInstance().getCompressor();
0:     switch (columnSpec.getDimensionType()) {
1:       case GLOBAL_DICTIONARY:
1:       case DIRECT_DICTIONARY:
1:       case PLAIN_VALUE:
1:         return new DirectCompressCodec(inputPage.getDataType()).createEncoder(null);
1:       case COMPLEX:
0:         return new ComplexDimensionIndexCodec(false, false, compressor).createEncoder(null);
1:       default:
1:         throw new RuntimeException("unsupported dimension type: " +
0:             columnSpec.getDimensionType());
1:     }
1:   }
1: 
0:   private ColumnPageEncoder createEncoderForDimensionLegacy(TableSpec.DimensionSpec columnSpec) {
0:     TableSpec.DimensionSpec dimensionSpec = columnSpec;
0:     Compressor compressor = CompressorFactory.getInstance().getCompressor();
0:     switch (dimensionSpec.getDimensionType()) {
1:       case GLOBAL_DICTIONARY:
1:         return new DictDimensionIndexCodec(
1:             dimensionSpec.isInSortColumns(),
1:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor).createEncoder(null);
1:       case DIRECT_DICTIONARY:
1:         return new DirectDictDimensionIndexCodec(
1:             dimensionSpec.isInSortColumns(),
1:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor).createEncoder(null);
1:       case PLAIN_VALUE:
1:         return new HighCardDictDimensionIndexCodec(
1:             dimensionSpec.isInSortColumns(),
1:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor).createEncoder(null);
1:       default:
1:         throw new RuntimeException("unsupported dimension type: " +
0:             dimensionSpec.getDimensionType());
1:     }
1:   }
1: 
1:   private ColumnPageEncoder createEncoderForMeasure(ColumnPage columnPage) {
1:     SimpleStatsResult stats = columnPage.getStatistics();
0:     switch (stats.getDataType()) {
0:       case BYTE:
0:       case SHORT:
0:       case INT:
0:       case LONG:
0:         return selectCodecByAlgorithm(stats).createEncoder(null);
0:       case FLOAT:
0:       case DOUBLE:
0:       case DECIMAL:
0:       case BYTE_ARRAY:
1:         return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:       default:
0:         throw new RuntimeException("unsupported data type: " + stats.getDataType());
1:     }
1:   }
1: 
1:   private static DataType fitLongMinMax(long max, long min) {
/////////////////////////////////////////////////////////////////////////
1:   private static DataType fitMinMax(DataType dataType, Object max, Object min) {
/////////////////////////////////////////////////////////////////////////
1:   private static DataType fitDelta(DataType dataType, Object max, Object min) {
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * choose between adaptive encoder or delta adaptive encoder, based on whose target data type
1:    * size is smaller
1:    */
0:   static ColumnPageCodec selectCodecByAlgorithm(SimpleStatsResult stats) {
/////////////////////////////////////////////////////////////////////////
1:       return new DirectCompressCodec(stats.getDataType());
1:       return new AdaptiveIntegralCodec(stats.getDataType(), adaptiveDataType, stats);
1:       return new AdaptiveDeltaIntegralCodec(stats.getDataType(), deltaDataType, stats);
author:manishgupta88
-------------------------------------------------------------------------------
commit:6f20437
/////////////////////////////////////////////////////////////////////////
1: import java.math.BigDecimal;
1: 
1: import org.apache.carbondata.core.datastore.page.DecimalColumnPage;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DecimalConverterFactory;
/////////////////////////////////////////////////////////////////////////
0:       case DECIMAL:
0:         return createEncoderForDecimalDataTypeMeasure(columnPage);
/////////////////////////////////////////////////////////////////////////
1:   private ColumnPageEncoder createEncoderForDecimalDataTypeMeasure(ColumnPage columnPage) {
1:     DecimalConverterFactory.DecimalConverterType decimalConverterType =
1:         ((DecimalColumnPage) columnPage).getDecimalConverter().getDecimalConverterType();
1:     switch (decimalConverterType) {
1:       case DECIMAL_INT:
1:       case DECIMAL_LONG:
1:         return selectCodecByAlgorithmForDecimal(columnPage.getStatistics(), decimalConverterType)
1:             .createEncoder(null);
1:       default:
0:         return new DirectCompressCodec(columnPage.getDataType()).createEncoder(null);
1:     }
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:   private static DataType fitMinMaxForDecimalType(DataType dataType, Object max, Object min,
1:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:     long maxValue = ((BigDecimal) max).unscaledValue().longValue();
1:     long minValue = ((BigDecimal) min).unscaledValue().longValue();
1:     switch (decimalConverterType) {
1:       case DECIMAL_INT:
1:         return fitLongMinMax((int) maxValue, (int) minValue);
1:       case DECIMAL_LONG:
1:         return fitLongMinMax(maxValue, minValue);
1:       default:
1:         throw new RuntimeException("internal error: " + dataType);
1:     }
1:   }
1: 
1:   private static DataType fitDeltaForDecimalType(DataType dataType, Object max, Object min,
1:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:     long maxValue = ((BigDecimal) max).unscaledValue().longValue();
1:     long minValue = ((BigDecimal) min).unscaledValue().longValue();
1:     switch (decimalConverterType) {
1:       case DECIMAL_INT:
1:         long value = maxValue - minValue;
1:         return compareMinMaxAndSelectDataType(value);
1:       case DECIMAL_LONG:
0:         return DataType.LONG;
1:       default:
1:         throw new RuntimeException("internal error: " + dataType);
1:     }
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     return compareMinMaxAndSelectDataType(value);
1:   }
1: 
1:   private static DataType compareMinMaxAndSelectDataType(long value) {
/////////////////////////////////////////////////////////////////////////
1:     // in case of decimal data type check if the decimal converter type is Int or Long and based on
1:     // that get size in bytes
1:     if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) == srcDataType
1:         .getSizeInBytes()) {
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * choose between adaptive encoder or delta adaptive encoder, based on whose target data type
1:    * size is smaller for decimal data type
1:    */
1:   static ColumnPageCodec selectCodecByAlgorithmForDecimal(SimpleStatsResult stats,
1:       DecimalConverterFactory.DecimalConverterType decimalConverterType) {
1:     DataType srcDataType = stats.getDataType();
1:     DataType adaptiveDataType =
1:         fitMinMaxForDecimalType(stats.getDataType(), stats.getMax(), stats.getMin(),
1:             decimalConverterType);
1:     DataType deltaDataType;
1: 
0:     if (adaptiveDataType == DataType.LONG) {
0:       deltaDataType = DataType.LONG;
1:     } else {
1:       deltaDataType = fitDeltaForDecimalType(stats.getDataType(), stats.getMax(), stats.getMin(),
1:           decimalConverterType);
1:     }
0:     // in case of decimal data type check if the decimal converter type is Int or Long and based on
0:     // that get size in bytes
0:     if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) == srcDataType
0:         .getSizeInBytes()) {
1:       // no effect to use adaptive or delta, use compression only
0:       return new DirectCompressCodec(stats.getDataType());
1:     }
1:     if (adaptiveDataType.getSizeInBytes() <= deltaDataType.getSizeInBytes()) {
1:       // choose adaptive encoding
1:       return new AdaptiveIntegralCodec(stats.getDataType(), adaptiveDataType, stats);
1:     } else {
1:       // choose delta adaptive encoding
1:       return new AdaptiveDeltaIntegralCodec(stats.getDataType(), deltaDataType, stats);
1:     }
1:   }
1: 
author:Raghunandan S
-------------------------------------------------------------------------------
commit:bb0b347
/////////////////////////////////////////////////////////////////////////
1:         assert columnSpec instanceof TableSpec.DimensionSpec;
author:jackylk
-------------------------------------------------------------------------------
commit:a5af0ff
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.TableSpec;
/////////////////////////////////////////////////////////////////////////
0:   @Override
0:   ColumnPageCodec newCodecForFloatingType(SimpleStatsResult stats) {
0:   @Override
0:   ColumnPageCodec newCodecForDecimalType(SimpleStatsResult stats) {
0:   @Override
0:   ColumnPageCodec newCodecForByteArrayType(SimpleStatsResult stats) {
1: 
0:   @Override
0:   public ColumnPageCodec newCodec(TableSpec.DimensionSpec dimensionSpec) {
0:     Compressor compressor = CompressorFactory.getInstance().getCompressor();
0:     switch (dimensionSpec.getDimensionType()) {
0:       case GLOBAL_DICTIONARY:
0:         return new DictDimensionIndexCodec(
0:             dimensionSpec.isInSortColumns(),
0:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor);
0:       case DIRECT_DICTIONARY:
0:         return new DirectDictDimensionIndexCodec(
0:             dimensionSpec.isInSortColumns(),
0:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor);
0:       case PLAIN_VALUE:
0:         return new HighCardDictDimensionIndexCodec(
0:             dimensionSpec.isInSortColumns(),
0:             dimensionSpec.isInSortColumns() && dimensionSpec.isDoInvertedIndex(),
0:             compressor);
0:       case COMPLEX:
0:         return new ComplexDimensionIndexCodec(false, false, compressor);
0:       default:
0:         throw new RuntimeException("unsupported dimension type: " +
0:             dimensionSpec.getDimensionType());
1:     }
1:   }
commit:bc3e684
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.statistics.SimpleStatsResult;
/////////////////////////////////////////////////////////////////////////
0:   private DataType fitLongMinMax(long max, long min) {
/////////////////////////////////////////////////////////////////////////
0:   private DataType fitMinMax(DataType dataType, Object max, Object min) {
0:     switch (dataType) {
0:       case BYTE:
0:         return fitLongMinMax((byte) max, (byte) min);
0:       case SHORT:
0:         return fitLongMinMax((short) max, (short) min);
0:       case INT:
0:         return fitLongMinMax((int) max, (int) min);
0:       case LONG:
0:         return fitLongMinMax((long) max, (long) min);
0:       case DOUBLE:
0:         return DataType.DOUBLE;
0:       default:
0:         throw new RuntimeException("internal error: " + dataType);
1:     }
1:   }
1: 
1:   // fit the long input value into minimum data type
0:   private DataType fitDelta(DataType dataType, Object max, Object min) {
1:     // use long data type to calculate delta to avoid overflow
1:     long value;
0:     switch (dataType) {
0:       case BYTE:
0:         value = (long)(byte) max - (long)(byte) min;
0:         break;
0:       case SHORT:
0:         value = (long)(short) max - (long)(short) min;
0:         break;
0:       case INT:
0:         value = (long)(int) max - (long)(int) min;
0:         break;
0:       case LONG:
0:         // TODO: add overflow detection and return delta type
0:         return DataType.LONG;
0:       default:
0:         throw new RuntimeException("internal error: " + dataType);
1:     }
1:     if (value <= Byte.MAX_VALUE && value >= Byte.MIN_VALUE) {
0:       return DataType.BYTE;
1:     } else if (value <= Short.MAX_VALUE && value >= Short.MIN_VALUE) {
0:       return DataType.SHORT;
1:     } else if (value <= THREE_BYTES_MAX && value >= THREE_BYTES_MIN) {
0:       return DataType.SHORT_INT;
1:     } else if (value <= Integer.MAX_VALUE && value >= Integer.MIN_VALUE) {
0:       return DataType.INT;
1:     } else {
0:       return DataType.LONG;
1:     }
1:   }
1: 
0:   @Override ColumnPageCodec newCodecForIntegralType(SimpleStatsResult stats) {
1:     DataType adaptiveDataType = fitMinMax(stats.getDataType(), stats.getMax(), stats.getMin());
/////////////////////////////////////////////////////////////////////////
0:       deltaDataType = fitDelta(stats.getDataType(), stats.getMax(), stats.getMin());
/////////////////////////////////////////////////////////////////////////
0:       return AdaptiveIntegralCodec.newInstance(
0:       return DeltaIntegralCodec.newInstance(stats.getDataType(), deltaDataType, stats, compressor);
0:   @Override ColumnPageCodec newCodecForFloatingType(SimpleStatsResult stats) {
0:   @Override ColumnPageCodec newCodecForDecimalType(SimpleStatsResult stats) {
0:   @Override ColumnPageCodec newCodecForByteArrayType(SimpleStatsResult stats) {
commit:eadfea7
/////////////////////////////////////////////////////////////////////////
1:     DataType srcDataType = stats.getDataType();
/////////////////////////////////////////////////////////////////////////
0:     if (Math.min(adaptiveDataType.getSizeInBytes(), deltaDataType.getSizeInBytes()) ==
0:         srcDataType.getSizeInBytes()) {
0:       // no effect to use adaptive or delta, use compression only
0:       return DirectCompressCodec.newInstance(srcDataType, compressor);
1:     }
/////////////////////////////////////////////////////////////////////////
0:     return DirectCompressCodec.newInstance(stats.getDataType(), compressor);
0:     return DirectCompressCodec.newInstance(stats.getDataType(), compressor);
0:     return DirectCompressCodec.newInstance(stats.getDataType(), compressor);
commit:7d386a4
/////////////////////////////////////////////////////////////////////////
1:   private static final int THREE_BYTES_MAX = (int) Math.pow(2, 23) - 1;
1:   private static final int THREE_BYTES_MIN = - THREE_BYTES_MAX - 1;
1: 
0:   private static DataType fitDataType(long value) {
0:     } else if (value <= THREE_BYTES_MAX && value >= THREE_BYTES_MIN) {
0:       return DataType.SHORT_INT;
/////////////////////////////////////////////////////////////////////////
0:   private DataType fitDataType(long max, long min) {
1:     } else if (max <= THREE_BYTES_MAX && min >= THREE_BYTES_MIN) {
0:       return DataType.SHORT_INT;
/////////////////////////////////////////////////////////////////////////
0:   private DataType fitDataType(double value, int decimal) {
0:       } else if (value <= THREE_BYTES_MAX && value >= THREE_BYTES_MIN) {
0:         return DataType.SHORT_INT;
/////////////////////////////////////////////////////////////////////////
0:       DataType upscaleAdaptiveDataType = fitDataType(Math.pow(10, decimal) * absMaxValue, decimal);
0:       DataType upscaleDiffDataType =
0:           fitDataType(Math.pow(10, decimal) * (maxValue - minValue), decimal);
commit:edda248
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.core.datastore.page.encoding;
1: 
0: import org.apache.carbondata.core.datastore.compression.Compressor;
0: import org.apache.carbondata.core.datastore.compression.CompressorFactory;
0: import org.apache.carbondata.core.datastore.page.statistics.ColumnPageStatsVO;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: 
1: /**
0:  * Default strategy will select encoding base on column page data type and statistics
1:  */
0: public class DefaultEncodingStrategy extends EncodingStrategy {
1: 
0:   private static final Compressor compressor = CompressorFactory.getInstance().getCompressor();
1: 
0:   // fit the long input value into minimum data type
0:   public static DataType fitDataType(long value) {
0:     if (value <= Byte.MAX_VALUE && value >= Byte.MIN_VALUE) {
0:       return DataType.BYTE;
0:     } else if (value <= Short.MAX_VALUE && value >= Short.MIN_VALUE) {
0:       return DataType.SHORT;
0:     } else if (value <= Integer.MAX_VALUE && value >= Integer.MIN_VALUE) {
0:       return DataType.INT;
1:     } else {
0:       return DataType.LONG;
1:     }
1:   }
1: 
0:   protected DataType fitDataType(long max, long min) {
1:     if (max <= Byte.MAX_VALUE && min >= Byte.MIN_VALUE) {
0:       return DataType.BYTE;
1:     } else if (max <= Short.MAX_VALUE && min >= Short.MIN_VALUE) {
0:       return DataType.SHORT;
1:     } else if (max <= Integer.MAX_VALUE && min >= Integer.MIN_VALUE) {
0:       return DataType.INT;
1:     } else {
0:       return DataType.LONG;
1:     }
1:   }
1: 
0:   // fit the input double value into minimum data type
0:   protected DataType fitDataType(double value, int decimal) {
0:     DataType dataType = DataType.DOUBLE;
0:     if (decimal == 0) {
0:       if (value <= Byte.MAX_VALUE && value >= Byte.MIN_VALUE) {
0:         dataType = DataType.BYTE;
0:       } else if (value <= Short.MAX_VALUE && value >= Short.MIN_VALUE) {
0:         dataType = DataType.SHORT;
0:       } else if (value <= Integer.MAX_VALUE && value >= Integer.MIN_VALUE) {
0:         dataType = DataType.INT;
0:       } else if (value <= Long.MAX_VALUE && value >= Long.MIN_VALUE) {
0:         dataType = DataType.LONG;
1:       }
1:     }
0:     return dataType;
1:   }
1: 
0:   // choose between adaptive encoder or delta adaptive encoder, based on whose target data type
0:   // size is smaller
0:   @Override
0:   ColumnPageCodec newCodecForIntegerType(ColumnPageStatsVO stats) {
0:     DataType adaptiveDataType = fitDataType((long)stats.getMax(), (long)stats.getMin());
0:     DataType deltaDataType;
1: 
0:     // TODO: this handling is for data compatibility, change to Override check when implementing
0:     // encoding override feature
0:     if (adaptiveDataType == DataType.LONG) {
0:       deltaDataType = DataType.LONG;
1:     } else {
0:       deltaDataType = fitDataType((long) stats.getMax() - (long) stats.getMin());
1:     }
1:     if (adaptiveDataType.getSizeInBytes() <= deltaDataType.getSizeInBytes()) {
1:       // choose adaptive encoding
0:       return AdaptiveIntegerCodec.newInstance(
0:           stats.getDataType(), adaptiveDataType, stats, compressor);
1:     } else {
1:       // choose delta adaptive encoding
0:       return DeltaIntegerCodec.newInstance(stats.getDataType(), deltaDataType, stats, compressor);
1:     }
1:   }
1: 
0:   // choose between upscale adaptive encoder or upscale delta adaptive encoder,
0:   // based on whose target data type size is smaller
0:   @Override
0:   ColumnPageCodec newCodecForFloatingType(ColumnPageStatsVO stats) {
0:     DataType srcDataType = stats.getDataType();
0:     double maxValue = (double) stats.getMax();
0:     double minValue = (double) stats.getMin();
0:     int decimal = stats.getDecimal();
1: 
0:     //Here we should use the Max abs as max to getDatatype, let's say -1 and -10000000, -1 is max,
0:     //but we can't use -1 to getDatatype, we should use -10000000.
0:     double absMaxValue = Math.abs(maxValue) >= Math.abs(minValue) ? maxValue : minValue;
1: 
0:     if (decimal == 0) {
0:       // short, int, long
0:       DataType adaptiveDataType = fitDataType(absMaxValue, decimal);
0:       DataType deltaDataType = fitDataType(maxValue - minValue, decimal);
1:       if (adaptiveDataType.getSizeInBytes() <= deltaDataType.getSizeInBytes()) {
1:         // choose adaptive encoding
0:         return AdaptiveIntegerCodec.newInstance(srcDataType, adaptiveDataType, stats, compressor);
1:       } else {
1:         // choose delta adaptive encoding
0:         return DeltaIntegerCodec.newInstance(srcDataType, deltaDataType, stats, compressor);
1:       }
1:     } else {
0:       // double
0:       DataType upscaleAdaptiveDataType = fitDataType(Math.pow(10, decimal) * absMaxValue, 0);
0:       DataType upscaleDiffDataType = fitDataType(Math.pow(10, decimal) * (maxValue - minValue), 0);
0:       if (upscaleAdaptiveDataType.getSizeInBytes() <= upscaleDiffDataType.getSizeInBytes()) {
0:         return UpscaleFloatingCodec.newInstance(
0:             srcDataType, upscaleAdaptiveDataType, stats, compressor);
1:       } else {
0:         return UpscaleDeltaFloatingCodec.newInstance(
0:             srcDataType, upscaleDiffDataType, stats, compressor);
1:       }
1:     }
1:   }
1: 
0:   // for decimal, currently it is a very basic implementation
0:   @Override
0:   ColumnPageCodec newCodecForDecimalType(ColumnPageStatsVO stats) {
0:     return CompressionCodec.newInstance(stats.getDataType(), compressor);
1:   }
1: 
0:   @Override
0:   ColumnPageCodec newCodecForByteArrayType(ColumnPageStatsVO stats) {
0:     return CompressionCodec.newInstance(stats.getDataType(), compressor);
1:   }
1: }
author:ravipesala
-------------------------------------------------------------------------------
commit:9e064ee
/////////////////////////////////////////////////////////////////////////
0:       return DirectCompressCodec.newInstance(stats, compressor);
/////////////////////////////////////////////////////////////////////////
0:     return DirectCompressCodec.newInstance(stats, compressor);
0:     return DirectCompressCodec.newInstance(stats, compressor);
0:     return DirectCompressCodec.newInstance(stats, compressor);
author:QiangCai
-------------------------------------------------------------------------------
commit:434f32d
/////////////////////////////////////////////////////////////////////////
0:       return UpscaleFloatingCodec.newInstance(
0:           srcDataType, upscaleAdaptiveDataType, stats, compressor);
============================================================================
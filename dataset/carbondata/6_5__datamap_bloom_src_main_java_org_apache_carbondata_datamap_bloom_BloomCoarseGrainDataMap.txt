1:b86ff92: /*
1:b86ff92:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b86ff92:  * contributor license agreements.  See the NOTICE file distributed with
1:b86ff92:  * this work for additional information regarding copyright ownership.
1:b86ff92:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b86ff92:  * (the "License"); you may not use this file except in compliance with
1:b86ff92:  * the License.  You may obtain a copy of the License at
1:b86ff92:  *
1:b86ff92:  *    http://www.apache.org/licenses/LICENSE-2.0
1:b86ff92:  *
1:b86ff92:  * Unless required by applicable law or agreed to in writing, software
1:b86ff92:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b86ff92:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b86ff92:  * See the License for the specific language governing permissions and
1:b86ff92:  * limitations under the License.
2:b86ff92:  */
4:b86ff92: 
1:b86ff92: package org.apache.carbondata.datamap.bloom;
1:b86ff92: 
1:b86ff92: import java.io.IOException;
1:b86ff92: import java.io.UnsupportedEncodingException;
1:cd7c210: import java.text.DateFormat;
1:cd7c210: import java.text.SimpleDateFormat;
1:b86ff92: import java.util.ArrayList;
1:cd7c210: import java.util.Arrays;
1:cd7c210: import java.util.Date;
1:cd7c210: import java.util.HashMap;
1:6eb360e: import java.util.HashSet;
1:b86ff92: import java.util.List;
1:cd7c210: import java.util.Map;
1:b86ff92: import java.util.Set;
1:cd7c210: import java.util.TimeZone;
1:cd7c210: import java.util.concurrent.ConcurrentHashMap;
1:b86ff92: 
1:b86ff92: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:b86ff92: import org.apache.carbondata.common.logging.LogService;
1:b86ff92: import org.apache.carbondata.common.logging.LogServiceFactory;
1:047c502: import org.apache.carbondata.core.cache.Cache;
1:cd7c210: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:b86ff92: import org.apache.carbondata.core.datamap.dev.DataMapModel;
1:b86ff92: import org.apache.carbondata.core.datamap.dev.cgdatamap.CoarseGrainDataMap;
1:b86ff92: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1:b86ff92: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:7551cc6: import org.apache.carbondata.core.datastore.page.encoding.bool.BooleanConvert;
1:cd7c210: import org.apache.carbondata.core.devapi.DictionaryGenerationException;
1:b86ff92: import org.apache.carbondata.core.indexstore.Blocklet;
1:b86ff92: import org.apache.carbondata.core.indexstore.PartitionSpec;
1:cd7c210: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1:bd6abbb: import org.apache.carbondata.core.metadata.CarbonMetadata;
1:b86ff92: import org.apache.carbondata.core.metadata.datatype.DataType;
1:b86ff92: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:cd7c210: import org.apache.carbondata.core.metadata.encoder.Encoding;
1:cd7c210: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:bd6abbb: import org.apache.carbondata.core.metadata.schema.table.RelationIdentifier;
1:cd7c210: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:b86ff92: import org.apache.carbondata.core.scan.expression.ColumnExpression;
1:b86ff92: import org.apache.carbondata.core.scan.expression.Expression;
1:b86ff92: import org.apache.carbondata.core.scan.expression.LiteralExpression;
1:b86ff92: import org.apache.carbondata.core.scan.expression.conditional.EqualToExpression;
1:202d099: import org.apache.carbondata.core.scan.expression.conditional.InExpression;
1:202d099: import org.apache.carbondata.core.scan.expression.conditional.ListExpression;
1:b86ff92: import org.apache.carbondata.core.scan.filter.resolver.FilterResolverIntf;
1:cd7c210: import org.apache.carbondata.core.util.CarbonProperties;
1:b86ff92: import org.apache.carbondata.core.util.CarbonUtil;
1:cd7c210: import org.apache.carbondata.processing.loading.DataField;
1:cd7c210: import org.apache.carbondata.processing.loading.converter.BadRecordLogHolder;
1:cd7c210: import org.apache.carbondata.processing.loading.converter.FieldConverter;
1:cd7c210: import org.apache.carbondata.processing.loading.converter.impl.FieldEncoderFactory;
1:b86ff92: 
1:b86ff92: import org.apache.hadoop.fs.Path;
1:047c502: import org.apache.hadoop.util.bloom.CarbonBloomFilter;
1:77a1110: import org.apache.hadoop.util.bloom.Key;
1:b86ff92: 
1:d14c403: /**
1:b86ff92:  * BloomDataCoarseGrainMap is constructed in blocklet level. For each indexed column,
1:b86ff92:  * a bloom filter is constructed to indicate whether a value belongs to this blocklet.
1:b86ff92:  * More information of the index file can be found in the corresponding datamap writer.
1:d14c403:  */
1:b86ff92: @InterfaceAudience.Internal
1:b86ff92: public class BloomCoarseGrainDataMap extends CoarseGrainDataMap {
1:b86ff92:   private static final LogService LOGGER =
1:b86ff92:       LogServiceFactory.getLogService(BloomCoarseGrainDataMap.class.getName());
1:cd7c210:   private Map<String, CarbonColumn> name2Col;
1:047c502:   private Cache<BloomCacheKeyValue.CacheKey, BloomCacheKeyValue.CacheValue> cache;
1:8b33ab2:   private String shardName;
1:d14c403:   private Path indexPath;
1:7b31b91:   private Set<String> filteredShard;
1:7b31b91:   private boolean needShardPrune;
1:cd7c210:   /**
1:cd7c210:    * This is used to convert literal filter value to internal carbon value
1:cd7c210:    */
1:cd7c210:   private Map<String, FieldConverter> name2Converters;
1:cd7c210:   private BadRecordLogHolder badRecordLogHolder;
1:b86ff92: 
1:b86ff92:   @Override
1:8b33ab2:   public void init(DataMapModel dataMapModel) throws IOException {
1:d14c403:     this.indexPath = FileFactory.getPath(dataMapModel.getFilePath());
1:8b33ab2:     this.shardName = indexPath.getName();
1:047c502:     if (dataMapModel instanceof BloomDataMapModel) {
1:047c502:       BloomDataMapModel model = (BloomDataMapModel) dataMapModel;
1:047c502:       this.cache = model.getCache();
13:b86ff92:     }
1:d14c403:   }
1:b86ff92: 
1:7b31b91:   public void setFilteredShard(Set<String> filteredShard) {
1:7b31b91:     this.filteredShard = filteredShard;
1:7b31b91:     // do shard prune when pruning only if bloom index files are merged
1:7b31b91:     this.needShardPrune = filteredShard != null &&
1:7b31b91:             shardName.equals(BloomIndexFileStore.MERGE_BLOOM_INDEX_SHARD_NAME);
1:7b31b91:   }
1:7b31b91: 
1:cd7c210:   /**
1:cd7c210:    * init field converters for index columns
1:cd7c210:    */
1:cd7c210:   public void initIndexColumnConverters(CarbonTable carbonTable, List<CarbonColumn> indexedColumn) {
1:cd7c210:     this.name2Col = new HashMap<>(indexedColumn.size());
1:cd7c210:     for (CarbonColumn col : indexedColumn) {
1:cd7c210:       this.name2Col.put(col.getColName(), col);
1:cd7c210:     }
1:bd6abbb:     String parentTablePath = getAncestorTablePath(carbonTable);
1:cd7c210: 
1:cd7c210:     try {
1:cd7c210:       this.name2Converters = new HashMap<>(indexedColumn.size());
1:cd7c210:       AbsoluteTableIdentifier absoluteTableIdentifier = AbsoluteTableIdentifier
1:cd7c210:           .from(carbonTable.getTablePath(), carbonTable.getCarbonTableIdentifier());
1:cd7c210:       String nullFormat = "\\N";
1:cd7c210:       Map<Object, Integer>[] localCaches = new Map[indexedColumn.size()];
1:cd7c210: 
1:cd7c210:       for (int i = 0; i < indexedColumn.size(); i++) {
1:cd7c210:         localCaches[i] = new ConcurrentHashMap<>();
1:cd7c210:         DataField dataField = new DataField(indexedColumn.get(i));
1:cd7c210:         String dateFormat = CarbonProperties.getInstance().getProperty(
1:cd7c210:             CarbonCommonConstants.CARBON_DATE_FORMAT,
1:cd7c210:             CarbonCommonConstants.CARBON_DATE_DEFAULT_FORMAT);
1:cd7c210:         dataField.setDateFormat(dateFormat);
1:cd7c210:         String tsFormat = CarbonProperties.getInstance().getProperty(
1:cd7c210:             CarbonCommonConstants.CARBON_TIMESTAMP_FORMAT,
1:cd7c210:             CarbonCommonConstants.CARBON_TIMESTAMP_DEFAULT_FORMAT);
1:cd7c210:         dataField.setTimestampFormat(tsFormat);
1:7a1d12a:         FieldConverter fieldConverter = FieldEncoderFactory.getInstance()
1:7a1d12a:             .createFieldEncoder(dataField, absoluteTableIdentifier, i, nullFormat, null, false,
1:bd6abbb:                 localCaches[i], false, parentTablePath);
1:cd7c210:         this.name2Converters.put(indexedColumn.get(i).getColName(), fieldConverter);
1:cd7c210:       }
1:cd7c210:     } catch (IOException e) {
1:cd7c210:       LOGGER.error(e, "Exception occurs while init index columns");
1:cd7c210:       throw new RuntimeException(e);
1:cd7c210:     }
1:cd7c210:     this.badRecordLogHolder = new BadRecordLogHolder();
1:cd7c210:     this.badRecordLogHolder.setLogged(false);
1:cd7c210:   }
1:cd7c210: 
1:bd6abbb:   /**
1:bd6abbb:    * recursively find the ancestor's table path. This is used for dictionary scenario
1:bd6abbb:    * where preagg will use the dictionary of the parent table.
1:bd6abbb:    */
1:bd6abbb:   private String getAncestorTablePath(CarbonTable currentTable) {
1:bd6abbb:     if (!currentTable.isChildDataMap()) {
1:bd6abbb:       return currentTable.getTablePath();
1:bd6abbb:     }
1:bd6abbb: 
1:bd6abbb:     RelationIdentifier parentIdentifier =
1:bd6abbb:         currentTable.getTableInfo().getParentRelationIdentifiers().get(0);
1:bd6abbb:     CarbonTable parentTable = CarbonMetadata.getInstance().getCarbonTable(
1:bd6abbb:         parentIdentifier.getDatabaseName(), parentIdentifier.getTableName());
1:bd6abbb:     return getAncestorTablePath(parentTable);
1:bd6abbb:   }
1:bd6abbb: 
1:b86ff92:   @Override
1:b86ff92:   public List<Blocklet> prune(FilterResolverIntf filterExp, SegmentProperties segmentProperties,
1:b86ff92:       List<PartitionSpec> partitions) throws IOException {
1:6eb360e:     Set<Blocklet> hitBlocklets = new HashSet<>();
1:b86ff92:     if (filterExp == null) {
1:b86ff92:       // null is different from empty here. Empty means after pruning, no blocklet need to scan.
1:b86ff92:       return null;
1:b86ff92:     }
1:b86ff92: 
1:cd7c210:     List<BloomQueryModel> bloomQueryModels;
1:cd7c210:     try {
1:cd7c210:       bloomQueryModels = createQueryModel(filterExp.getFilterExpression());
1:cd7c210:     } catch (DictionaryGenerationException | UnsupportedEncodingException e) {
1:cd7c210:       LOGGER.error(e, "Exception occurs while creating query model");
1:cd7c210:       throw new RuntimeException(e);
1:cd7c210:     }
1:b86ff92:     for (BloomQueryModel bloomQueryModel : bloomQueryModels) {
1:d14c403:       LOGGER.debug("prune blocklet for query: " + bloomQueryModel);
1:047c502:       BloomCacheKeyValue.CacheKey cacheKey = new BloomCacheKeyValue.CacheKey(
1:d14c403:           this.indexPath.toString(), bloomQueryModel.columnName);
1:047c502:       BloomCacheKeyValue.CacheValue cacheValue = cache.get(cacheKey);
1:047c502:       List<CarbonBloomFilter> bloomIndexList = cacheValue.getBloomFilters();
1:047c502:       for (CarbonBloomFilter bloomFilter : bloomIndexList) {
1:7b31b91:         if (needShardPrune && !filteredShard.contains(bloomFilter.getShardName())) {
1:7b31b91:           // skip shard which has been pruned in Main datamap
1:7b31b91:           continue;
1:7b31b91:         }
1:cd7c210:         boolean scanRequired = bloomFilter.membershipTest(new Key(bloomQueryModel.filterValue));
1:d14c403:         if (scanRequired) {
1:d14c403:           LOGGER.debug(String.format("BloomCoarseGrainDataMap: Need to scan -> blocklet#%s",
1:047c502:               String.valueOf(bloomFilter.getBlockletNo())));
1:7b31b91:           Blocklet blocklet = new Blocklet(bloomFilter.getShardName(),
1:7b31b91:                   String.valueOf(bloomFilter.getBlockletNo()));
1:d14c403:           hitBlocklets.add(blocklet);
1:d14c403:         } else {
1:d14c403:           LOGGER.debug(String.format("BloomCoarseGrainDataMap: Skip scan -> blocklet#%s",
1:047c502:               String.valueOf(bloomFilter.getBlockletNo())));
1:b86ff92:         }
1:b86ff92:       }
1:b86ff92:     }
1:6eb360e:     return new ArrayList<>(hitBlocklets);
1:b86ff92:   }
1:b86ff92: 
1:cd7c210:   private List<BloomQueryModel> createQueryModel(Expression expression)
1:cd7c210:       throws DictionaryGenerationException, UnsupportedEncodingException {
1:b86ff92:     List<BloomQueryModel> queryModels = new ArrayList<BloomQueryModel>();
1:202d099:     // bloomdatamap only support equalTo and In operators now
1:b86ff92:     if (expression instanceof EqualToExpression) {
1:b86ff92:       Expression left = ((EqualToExpression) expression).getLeft();
1:b86ff92:       Expression right = ((EqualToExpression) expression).getRight();
1:b86ff92:       String column;
1:b86ff92:       if (left instanceof ColumnExpression && right instanceof LiteralExpression) {
1:b86ff92:         column = ((ColumnExpression) left).getColumnName();
1:cd7c210:         if (this.name2Col.containsKey(column)) {
1:cd7c210:           BloomQueryModel bloomQueryModel =
1:202d099:               buildQueryModelForEqual((ColumnExpression) left, (LiteralExpression) right);
1:b86ff92:           queryModels.add(bloomQueryModel);
1:b86ff92:         }
1:b86ff92:         return queryModels;
1:b86ff92:       } else if (left instanceof LiteralExpression && right instanceof ColumnExpression) {
1:b86ff92:         column = ((ColumnExpression) right).getColumnName();
1:cd7c210:         if (this.name2Col.containsKey(column)) {
1:cd7c210:           BloomQueryModel bloomQueryModel =
1:202d099:               buildQueryModelForEqual((ColumnExpression) right, (LiteralExpression) left);
1:b86ff92:           queryModels.add(bloomQueryModel);
1:202d099:         }
1:b86ff92:         return queryModels;
1:202d099:       } else {
1:b853963:         String errorMsg = "BloomFilter can only support the 'equal' filter like 'Col = PlainValue'";
1:b853963:         LOGGER.warn(errorMsg);
1:b853963:         throw new RuntimeException(errorMsg);
1:b86ff92:       }
1:202d099:     } else if (expression instanceof InExpression) {
1:202d099:       Expression left = ((InExpression) expression).getLeft();
1:202d099:       Expression right = ((InExpression) expression).getRight();
1:202d099:       String column;
1:202d099:       if (left instanceof ColumnExpression && right instanceof ListExpression) {
1:202d099:         column = ((ColumnExpression) left).getColumnName();
1:202d099:         if (this.name2Col.containsKey(column)) {
1:202d099:           List<BloomQueryModel> models =
1:202d099:               buildQueryModelForIn((ColumnExpression) left, (ListExpression) right);
1:202d099:           queryModels.addAll(models);
1:202d099:         }
1:202d099:         return queryModels;
1:202d099:       } else if (left instanceof ListExpression && right instanceof ColumnExpression) {
1:202d099:         column = ((ColumnExpression) right).getColumnName();
1:202d099:         if (this.name2Col.containsKey(column)) {
1:202d099:           List<BloomQueryModel> models =
1:202d099:               buildQueryModelForIn((ColumnExpression) right, (ListExpression) left);
1:202d099:           queryModels.addAll(models);
1:202d099:         }
1:202d099:         return queryModels;
1:202d099:       } else {
1:b853963:         String errorMsg = "BloomFilter can only support the 'in' filter like 'Col in PlainValue'";
1:b853963:         LOGGER.warn(errorMsg);
1:b853963:         throw new RuntimeException(errorMsg);
1:b86ff92:       }
1:b86ff92:     }
1:b86ff92: 
1:b86ff92:     for (Expression child : expression.getChildren()) {
1:cd7c210:       queryModels.addAll(createQueryModel(child));
1:b86ff92:     }
1:b86ff92:     return queryModels;
1:b86ff92:   }
1:b86ff92: 
1:202d099:   private BloomQueryModel buildQueryModelForEqual(ColumnExpression ce,
1:cd7c210:       LiteralExpression le) throws DictionaryGenerationException, UnsupportedEncodingException {
1:cd7c210:     String columnName = ce.getColumnName();
1:cd7c210:     DataType dataType = ce.getDataType();
1:cd7c210:     Object expressionValue = le.getLiteralExpValue();
1:cd7c210:     Object literalValue;
1:cd7c210:     // note that if the datatype is date/timestamp, the expressionValue is long type.
1:7551cc6:     if (null == expressionValue) {
1:7551cc6:       literalValue = null;
1:7551cc6:     } else if (le.getLiteralExpDataType() == DataTypes.DATE) {
1:cd7c210:       DateFormat format = new SimpleDateFormat(CarbonCommonConstants.CARBON_DATE_DEFAULT_FORMAT);
1:cd7c210:       // the below settings are set statically according to DateDirectDirectionaryGenerator
1:cd7c210:       format.setLenient(false);
1:cd7c210:       format.setTimeZone(TimeZone.getTimeZone("GMT"));
1:cd7c210: 
1:cd7c210:       literalValue = format.format(new Date((long) expressionValue / 1000));
1:cd7c210:     } else if (le.getLiteralExpDataType() == DataTypes.TIMESTAMP) {
1:cd7c210:       DateFormat format =
1:cd7c210:           new SimpleDateFormat(CarbonCommonConstants.CARBON_TIMESTAMP_DEFAULT_FORMAT);
1:cd7c210:       // the below settings are set statically according to TimeStampDirectDirectionaryGenerator
1:cd7c210:       format.setLenient(false);
1:cd7c210:       literalValue = format.format(new Date((long) expressionValue / 1000));
1:cd7c210:     } else {
1:cd7c210:       literalValue = expressionValue;
1:cd7c210:     }
1:cd7c210: 
1:cd7c210:     return buildQueryModelInternal(this.name2Col.get(columnName), literalValue, dataType);
1:cd7c210:   }
1:cd7c210: 
1:202d099:   /**
1:202d099:    * for `in` expressions, we use `equal` to handle it.
1:202d099:    * Note that `in` operator needs at least one match not exactly match. since while doing pruning,
1:202d099:    * we collect all the blocklets that will match the querymodel, this will not be a problem.
1:202d099:    */
1:202d099:   private List<BloomQueryModel> buildQueryModelForIn(ColumnExpression ce, ListExpression le)
1:202d099:       throws DictionaryGenerationException, UnsupportedEncodingException {
1:202d099:     List<BloomQueryModel> queryModels = new ArrayList<>();
1:202d099:     for (Expression child : le.getChildren()) {
1:202d099:       queryModels.add(buildQueryModelForEqual(ce, (LiteralExpression) child));
1:202d099:     }
1:202d099:     return queryModels;
1:202d099:   }
1:202d099: 
1:cd7c210:   private BloomQueryModel buildQueryModelInternal(CarbonColumn carbonColumn,
1:cd7c210:       Object filterLiteralValue, DataType filterValueDataType) throws
1:cd7c210:       DictionaryGenerationException, UnsupportedEncodingException {
1:cd7c210:     // convert the filter value to string and apply convertes on it to get carbon internal value
1:cd7c210:     String strFilterValue = null;
1:cd7c210:     if (null != filterLiteralValue) {
1:cd7c210:       strFilterValue = String.valueOf(filterLiteralValue);
1:cd7c210:     }
1:cd7c210: 
1:cd7c210:     Object convertedValue = this.name2Converters.get(carbonColumn.getColName()).convert(
1:cd7c210:         strFilterValue, badRecordLogHolder);
1:cd7c210: 
1:cd7c210:     byte[] internalFilterValue;
1:cd7c210:     if (carbonColumn.isMeasure()) {
1:cd7c210:       // for measures, the value is already the type, just convert it to bytes.
1:a7c4b48:       if (convertedValue == null) {
1:7551cc6:         convertedValue = DataConvertUtil.getNullValueForMeasure(carbonColumn.getDataType(),
1:7551cc6:             carbonColumn.getColumnSchema().getScale());
1:7551cc6:       }
1:7551cc6:       // Carbon stores boolean as byte. Here we convert it for `getValueAsBytes`
1:7551cc6:       if (carbonColumn.getDataType().equals(DataTypes.BOOLEAN)) {
1:7551cc6:         convertedValue = BooleanConvert.boolean2Byte((Boolean)convertedValue);
1:a7c4b48:       }
1:cd7c210:       internalFilterValue = CarbonUtil.getValueAsBytes(carbonColumn.getDataType(), convertedValue);
1:cd7c210:     } else if (carbonColumn.hasEncoding(Encoding.DIRECT_DICTIONARY) ||
1:cd7c210:         carbonColumn.hasEncoding(Encoding.DICTIONARY)) {
1:cd7c210:       // for dictionary/date columns, convert the surrogate key to bytes
1:cd7c210:       internalFilterValue = CarbonUtil.getValueAsBytes(DataTypes.INT, convertedValue);
1:cd7c210:     } else {
1:cd7c210:       // for non dictionary dimensions, is already bytes,
1:cd7c210:       internalFilterValue = (byte[]) convertedValue;
1:cd7c210:     }
1:cd7c210:     if (internalFilterValue.length == 0) {
1:cd7c210:       internalFilterValue = CarbonCommonConstants.MEMBER_DEFAULT_VAL_ARRAY;
1:cd7c210:     }
1:cd7c210:     return new BloomQueryModel(carbonColumn.getColName(), internalFilterValue);
1:cd7c210:   }
1:cd7c210: 
1:b86ff92:   @Override
1:b86ff92:   public boolean isScanRequired(FilterResolverIntf filterExp) {
1:b86ff92:     return true;
1:b86ff92:   }
1:b86ff92: 
1:b86ff92:   @Override
1:b86ff92:   public void clear() {
1:b86ff92:   }
1:b86ff92: 
1:b86ff92:   static class BloomQueryModel {
1:b86ff92:     private String columnName;
1:cd7c210:     private byte[] filterValue;
1:b86ff92: 
1:cd7c210:     /**
1:cd7c210:      * represent an query model will be applyied on bloom index
1:cd7c210:      *
1:cd7c210:      * @param columnName bloom index column
1:cd7c210:      * @param filterValue key for the bloom index,
1:cd7c210:      *                   this value is converted from user specified filter value in query
1:cd7c210:      */
1:cd7c210:     private BloomQueryModel(String columnName, byte[] filterValue) {
1:b86ff92:       this.columnName = columnName;
1:b86ff92:       this.filterValue = filterValue;
1:b86ff92:     }
1:b86ff92: 
1:b86ff92:     @Override
1:b86ff92:     public String toString() {
1:b86ff92:       final StringBuilder sb = new StringBuilder("BloomQueryModel{");
1:b86ff92:       sb.append("columnName='").append(columnName).append('\'');
1:cd7c210:       sb.append(", filterValue=").append(Arrays.toString(filterValue));
1:b86ff92:       sb.append('}');
1:b86ff92:       return sb.toString();
1:b86ff92:     }
1:b86ff92:   }
1:b86ff92: 
1:07a77fa:   @Override
1:07a77fa:   public void finish() {
1:b86ff92: 
1:b86ff92:   }
1:b86ff92: }
============================================================================
author:Manhua
-------------------------------------------------------------------------------
commit:7b31b91
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private Set<String> filteredShard;
1:   private boolean needShardPrune;
/////////////////////////////////////////////////////////////////////////
1:   public void setFilteredShard(Set<String> filteredShard) {
1:     this.filteredShard = filteredShard;
1:     // do shard prune when pruning only if bloom index files are merged
1:     this.needShardPrune = filteredShard != null &&
1:             shardName.equals(BloomIndexFileStore.MERGE_BLOOM_INDEX_SHARD_NAME);
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:         if (needShardPrune && !filteredShard.contains(bloomFilter.getShardName())) {
1:           // skip shard which has been pruned in Main datamap
1:           continue;
1:         }
1:           Blocklet blocklet = new Blocklet(bloomFilter.getShardName(),
1:                   String.valueOf(bloomFilter.getBlockletNo()));
/////////////////////////////////////////////////////////////////////////
commit:b853963
/////////////////////////////////////////////////////////////////////////
1:         String errorMsg = "BloomFilter can only support the 'equal' filter like 'Col = PlainValue'";
1:         LOGGER.warn(errorMsg);
1:         throw new RuntimeException(errorMsg);
/////////////////////////////////////////////////////////////////////////
1:         String errorMsg = "BloomFilter can only support the 'in' filter like 'Col in PlainValue'";
1:         LOGGER.warn(errorMsg);
1:         throw new RuntimeException(errorMsg);
commit:7551cc6
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.bool.BooleanConvert;
/////////////////////////////////////////////////////////////////////////
1:     if (null == expressionValue) {
1:       literalValue = null;
1:     } else if (le.getLiteralExpDataType() == DataTypes.DATE) {
/////////////////////////////////////////////////////////////////////////
1:         convertedValue = DataConvertUtil.getNullValueForMeasure(carbonColumn.getDataType(),
1:             carbonColumn.getColumnSchema().getScale());
1:       }
1:       // Carbon stores boolean as byte. Here we convert it for `getValueAsBytes`
1:       if (carbonColumn.getDataType().equals(DataTypes.BOOLEAN)) {
1:         convertedValue = BooleanConvert.boolean2Byte((Boolean)convertedValue);
author:xuchuanyin
-------------------------------------------------------------------------------
commit:bd6abbb
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.CarbonMetadata;
1: import org.apache.carbondata.core.metadata.schema.table.RelationIdentifier;
/////////////////////////////////////////////////////////////////////////
1:     String parentTablePath = getAncestorTablePath(carbonTable);
/////////////////////////////////////////////////////////////////////////
1:                 localCaches[i], false, parentTablePath);
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * recursively find the ancestor's table path. This is used for dictionary scenario
1:    * where preagg will use the dictionary of the parent table.
1:    */
1:   private String getAncestorTablePath(CarbonTable currentTable) {
1:     if (!currentTable.isChildDataMap()) {
1:       return currentTable.getTablePath();
1:     }
1: 
1:     RelationIdentifier parentIdentifier =
1:         currentTable.getTableInfo().getParentRelationIdentifiers().get(0);
1:     CarbonTable parentTable = CarbonMetadata.getInstance().getCarbonTable(
1:         parentIdentifier.getDatabaseName(), parentIdentifier.getTableName());
1:     return getAncestorTablePath(parentTable);
1:   }
1: 
commit:202d099
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.expression.conditional.InExpression;
1: import org.apache.carbondata.core.scan.expression.conditional.ListExpression;
/////////////////////////////////////////////////////////////////////////
1:     // bloomdatamap only support equalTo and In operators now
/////////////////////////////////////////////////////////////////////////
1:               buildQueryModelForEqual((ColumnExpression) left, (LiteralExpression) right);
/////////////////////////////////////////////////////////////////////////
1:               buildQueryModelForEqual((ColumnExpression) right, (LiteralExpression) left);
1:       } else {
0:         LOGGER.warn("BloomFilter can only support the 'equal' filter like 'Col = PlainValue'");
1:       }
1:     } else if (expression instanceof InExpression) {
1:       Expression left = ((InExpression) expression).getLeft();
1:       Expression right = ((InExpression) expression).getRight();
1:       String column;
1:       if (left instanceof ColumnExpression && right instanceof ListExpression) {
1:         column = ((ColumnExpression) left).getColumnName();
1:         if (this.name2Col.containsKey(column)) {
1:           List<BloomQueryModel> models =
1:               buildQueryModelForIn((ColumnExpression) left, (ListExpression) right);
1:           queryModels.addAll(models);
1:         }
1:         return queryModels;
1:       } else if (left instanceof ListExpression && right instanceof ColumnExpression) {
1:         column = ((ColumnExpression) right).getColumnName();
1:         if (this.name2Col.containsKey(column)) {
1:           List<BloomQueryModel> models =
1:               buildQueryModelForIn((ColumnExpression) right, (ListExpression) left);
1:           queryModels.addAll(models);
1:         }
1:         return queryModels;
1:       } else {
0:         LOGGER.warn("BloomFilter can only support the 'in' filter like 'Col in (PlainValues)'");
/////////////////////////////////////////////////////////////////////////
1:   private BloomQueryModel buildQueryModelForEqual(ColumnExpression ce,
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * for `in` expressions, we use `equal` to handle it.
1:    * Note that `in` operator needs at least one match not exactly match. since while doing pruning,
1:    * we collect all the blocklets that will match the querymodel, this will not be a problem.
1:    */
1:   private List<BloomQueryModel> buildQueryModelForIn(ColumnExpression ce, ListExpression le)
1:       throws DictionaryGenerationException, UnsupportedEncodingException {
1:     List<BloomQueryModel> queryModels = new ArrayList<>();
1:     for (Expression child : le.getChildren()) {
1:       queryModels.add(buildQueryModelForEqual(ce, (LiteralExpression) child));
1:     }
1:     return queryModels;
1:   }
1: 
commit:a7c4b48
/////////////////////////////////////////////////////////////////////////
1:       if (convertedValue == null) {
0:         convertedValue = DataConvertUtil.getNullValueForMeasure(carbonColumn.getDataType());
1:       }
commit:cd7c210
/////////////////////////////////////////////////////////////////////////
1: import java.text.DateFormat;
1: import java.text.SimpleDateFormat;
1: import java.util.Arrays;
1: import java.util.Date;
1: import java.util.HashMap;
1: import java.util.Map;
1: import java.util.TimeZone;
1: import java.util.concurrent.ConcurrentHashMap;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.devapi.DictionaryGenerationException;
1: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1: import org.apache.carbondata.core.metadata.encoder.Encoding;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.processing.loading.DataField;
1: import org.apache.carbondata.processing.loading.converter.BadRecordLogHolder;
1: import org.apache.carbondata.processing.loading.converter.FieldConverter;
1: import org.apache.carbondata.processing.loading.converter.impl.FieldEncoderFactory;
/////////////////////////////////////////////////////////////////////////
1:   private Map<String, CarbonColumn> name2Col;
1:   /**
1:    * This is used to convert literal filter value to internal carbon value
1:    */
1:   private Map<String, FieldConverter> name2Converters;
1:   private BadRecordLogHolder badRecordLogHolder;
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * init field converters for index columns
1:    */
1:   public void initIndexColumnConverters(CarbonTable carbonTable, List<CarbonColumn> indexedColumn) {
1:     this.name2Col = new HashMap<>(indexedColumn.size());
1:     for (CarbonColumn col : indexedColumn) {
1:       this.name2Col.put(col.getColName(), col);
1:     }
1: 
1:     try {
1:       this.name2Converters = new HashMap<>(indexedColumn.size());
1:       AbsoluteTableIdentifier absoluteTableIdentifier = AbsoluteTableIdentifier
1:           .from(carbonTable.getTablePath(), carbonTable.getCarbonTableIdentifier());
1:       String nullFormat = "\\N";
1:       Map<Object, Integer>[] localCaches = new Map[indexedColumn.size()];
1: 
1:       for (int i = 0; i < indexedColumn.size(); i++) {
1:         localCaches[i] = new ConcurrentHashMap<>();
1:         DataField dataField = new DataField(indexedColumn.get(i));
1:         String dateFormat = CarbonProperties.getInstance().getProperty(
1:             CarbonCommonConstants.CARBON_DATE_FORMAT,
1:             CarbonCommonConstants.CARBON_DATE_DEFAULT_FORMAT);
1:         dataField.setDateFormat(dateFormat);
1:         String tsFormat = CarbonProperties.getInstance().getProperty(
1:             CarbonCommonConstants.CARBON_TIMESTAMP_FORMAT,
1:             CarbonCommonConstants.CARBON_TIMESTAMP_DEFAULT_FORMAT);
1:         dataField.setTimestampFormat(tsFormat);
0:         FieldConverter fieldConverter =
0:             FieldEncoderFactory.getInstance().createFieldEncoder(dataField, absoluteTableIdentifier,
0:                 i, nullFormat, null, false, localCaches[i], false);
1:         this.name2Converters.put(indexedColumn.get(i).getColName(), fieldConverter);
1:       }
1:     } catch (IOException e) {
1:       LOGGER.error(e, "Exception occurs while init index columns");
1:       throw new RuntimeException(e);
1:     }
1:     this.badRecordLogHolder = new BadRecordLogHolder();
1:     this.badRecordLogHolder.setLogged(false);
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     List<BloomQueryModel> bloomQueryModels;
1:     try {
1:       bloomQueryModels = createQueryModel(filterExp.getFilterExpression());
1:     } catch (DictionaryGenerationException | UnsupportedEncodingException e) {
1:       LOGGER.error(e, "Exception occurs while creating query model");
1:       throw new RuntimeException(e);
1:     }
/////////////////////////////////////////////////////////////////////////
1:         boolean scanRequired = bloomFilter.membershipTest(new Key(bloomQueryModel.filterValue));
/////////////////////////////////////////////////////////////////////////
1:   private List<BloomQueryModel> createQueryModel(Expression expression)
1:       throws DictionaryGenerationException, UnsupportedEncodingException {
1:         if (this.name2Col.containsKey(column)) {
1:           BloomQueryModel bloomQueryModel =
0:               buildQueryModelFromExpression((ColumnExpression) left, (LiteralExpression) right);
1:         if (this.name2Col.containsKey(column)) {
1:           BloomQueryModel bloomQueryModel =
0:               buildQueryModelFromExpression((ColumnExpression) right, (LiteralExpression) left);
/////////////////////////////////////////////////////////////////////////
1:       queryModels.addAll(createQueryModel(child));
0:   private BloomQueryModel buildQueryModelFromExpression(ColumnExpression ce,
1:       LiteralExpression le) throws DictionaryGenerationException, UnsupportedEncodingException {
1:     String columnName = ce.getColumnName();
1:     DataType dataType = ce.getDataType();
1:     Object expressionValue = le.getLiteralExpValue();
1:     Object literalValue;
1:     // note that if the datatype is date/timestamp, the expressionValue is long type.
0:     if (le.getLiteralExpDataType() == DataTypes.DATE) {
1:       DateFormat format = new SimpleDateFormat(CarbonCommonConstants.CARBON_DATE_DEFAULT_FORMAT);
1:       // the below settings are set statically according to DateDirectDirectionaryGenerator
1:       format.setLenient(false);
1:       format.setTimeZone(TimeZone.getTimeZone("GMT"));
1: 
1:       literalValue = format.format(new Date((long) expressionValue / 1000));
1:     } else if (le.getLiteralExpDataType() == DataTypes.TIMESTAMP) {
1:       DateFormat format =
1:           new SimpleDateFormat(CarbonCommonConstants.CARBON_TIMESTAMP_DEFAULT_FORMAT);
1:       // the below settings are set statically according to TimeStampDirectDirectionaryGenerator
1:       format.setLenient(false);
1:       literalValue = format.format(new Date((long) expressionValue / 1000));
1:     } else {
1:       literalValue = expressionValue;
1:     }
1: 
1:     return buildQueryModelInternal(this.name2Col.get(columnName), literalValue, dataType);
1:   }
1: 
1:   private BloomQueryModel buildQueryModelInternal(CarbonColumn carbonColumn,
1:       Object filterLiteralValue, DataType filterValueDataType) throws
1:       DictionaryGenerationException, UnsupportedEncodingException {
1:     // convert the filter value to string and apply convertes on it to get carbon internal value
1:     String strFilterValue = null;
1:     if (null != filterLiteralValue) {
1:       strFilterValue = String.valueOf(filterLiteralValue);
1:     }
1: 
1:     Object convertedValue = this.name2Converters.get(carbonColumn.getColName()).convert(
1:         strFilterValue, badRecordLogHolder);
1: 
1:     byte[] internalFilterValue;
1:     if (carbonColumn.isMeasure()) {
1:       // for measures, the value is already the type, just convert it to bytes.
1:       internalFilterValue = CarbonUtil.getValueAsBytes(carbonColumn.getDataType(), convertedValue);
1:     } else if (carbonColumn.hasEncoding(Encoding.DIRECT_DICTIONARY) ||
1:         carbonColumn.hasEncoding(Encoding.DICTIONARY)) {
1:       // for dictionary/date columns, convert the surrogate key to bytes
1:       internalFilterValue = CarbonUtil.getValueAsBytes(DataTypes.INT, convertedValue);
1:     } else {
1:       // for non dictionary dimensions, is already bytes,
1:       internalFilterValue = (byte[]) convertedValue;
1:     }
1:     if (internalFilterValue.length == 0) {
1:       internalFilterValue = CarbonCommonConstants.MEMBER_DEFAULT_VAL_ARRAY;
1:     }
1:     return new BloomQueryModel(carbonColumn.getColName(), internalFilterValue);
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     private byte[] filterValue;
1:     /**
1:      * represent an query model will be applyied on bloom index
1:      *
1:      * @param columnName bloom index column
1:      * @param filterValue key for the bloom index,
1:      *                   this value is converted from user specified filter value in query
1:      */
1:     private BloomQueryModel(String columnName, byte[] filterValue) {
/////////////////////////////////////////////////////////////////////////
1:       sb.append(", filterValue=").append(Arrays.toString(filterValue));
commit:6eb360e
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashSet;
/////////////////////////////////////////////////////////////////////////
1:     Set<Blocklet> hitBlocklets = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:     return new ArrayList<>(hitBlocklets);
commit:d14c403
/////////////////////////////////////////////////////////////////////////
0: import java.io.File;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   public static final String BLOOM_INDEX_SUFFIX = ".bloomindex";
0:   private BloomDataMapCache bloomDataMapCache;
1:   private Path indexPath;
1:     this.indexPath = FileFactory.getPath(dataMapModel.getFilePath());
/////////////////////////////////////////////////////////////////////////
0:     this.bloomDataMapCache = BloomDataMapCache.getInstance();
0:   public void setIndexedColumn(Set<String> indexedColumn) {
0:     this.indexedColumn = indexedColumn;
/////////////////////////////////////////////////////////////////////////
1:       LOGGER.debug("prune blocklet for query: " + bloomQueryModel);
0:       BloomDataMapCache.CacheKey cacheKey = new BloomDataMapCache.CacheKey(
1:           this.indexPath.toString(), bloomQueryModel.columnName);
0:       List<BloomDMModel> bloomDMModels = this.bloomDataMapCache.getBloomDMModelByKey(cacheKey);
0:       for (BloomDMModel bloomDMModel : bloomDMModels) {
0:         boolean scanRequired = bloomDMModel.getBloomFilter().mightContain(
0:             convertValueToBytes(bloomQueryModel.dataType, bloomQueryModel.filterValue));
1:         if (scanRequired) {
1:           LOGGER.debug(String.format("BloomCoarseGrainDataMap: Need to scan -> blocklet#%s",
0:               String.valueOf(bloomDMModel.getBlockletNo())));
0:           Blocklet blocklet = new Blocklet(shardName, String.valueOf(bloomDMModel.getBlockletNo()));
1:           hitBlocklets.add(blocklet);
1:         } else {
1:           LOGGER.debug(String.format("BloomCoarseGrainDataMap: Skip scan -> blocklet#%s",
0:               String.valueOf(bloomDMModel.getBlockletNo())));
/////////////////////////////////////////////////////////////////////////
1:   /**
0:    * get bloom index file
0:    * @param shardPath path for the shard
0:    * @param colName index column name
1:    */
0:   public static String getBloomIndexFile(String shardPath, String colName) {
0:     return shardPath.concat(File.separator).concat(colName).concat(BLOOM_INDEX_SUFFIX);
1:   }
0:     private BloomQueryModel(String columnName, DataType dataType, Object filterValue) {
commit:b86ff92
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.datamap.bloom;
1: 
0: import java.io.DataInputStream;
0: import java.io.EOFException;
1: import java.io.IOException;
0: import java.io.ObjectInputStream;
1: import java.io.UnsupportedEncodingException;
1: import java.util.ArrayList;
0: import java.util.HashSet;
1: import java.util.List;
1: import java.util.Set;
1: 
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
1: import org.apache.carbondata.core.datamap.dev.DataMapModel;
1: import org.apache.carbondata.core.datamap.dev.cgdatamap.CoarseGrainDataMap;
1: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
1: import org.apache.carbondata.core.indexstore.Blocklet;
1: import org.apache.carbondata.core.indexstore.PartitionSpec;
0: import org.apache.carbondata.core.memory.MemoryException;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.scan.expression.ColumnExpression;
1: import org.apache.carbondata.core.scan.expression.Expression;
1: import org.apache.carbondata.core.scan.expression.LiteralExpression;
1: import org.apache.carbondata.core.scan.expression.conditional.EqualToExpression;
1: import org.apache.carbondata.core.scan.filter.resolver.FilterResolverIntf;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: 
0: import com.google.common.collect.ArrayListMultimap;
0: import com.google.common.collect.Multimap;
0: import org.apache.commons.lang3.StringUtils;
0: import org.apache.hadoop.fs.FileStatus;
0: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.fs.PathFilter;
1: 
0: /**
1:  * BloomDataCoarseGrainMap is constructed in blocklet level. For each indexed column,
1:  * a bloom filter is constructed to indicate whether a value belongs to this blocklet.
1:  * More information of the index file can be found in the corresponding datamap writer.
1:  */
1: @InterfaceAudience.Internal
1: public class BloomCoarseGrainDataMap extends CoarseGrainDataMap {
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(BloomCoarseGrainDataMap.class.getName());
0:   private String[] indexFilePath;
0:   private Set<String> indexedColumn;
0:   private List<BloomDMModel> bloomIndexList;
0:   private Multimap<String, List<BloomDMModel>> indexCol2BloomDMList;
0:   public static final String BLOOM_INDEX_SUFFIX = ".bloomindex";
1: 
1:   @Override
0:   public void init(DataMapModel dataMapModel) throws MemoryException, IOException {
0:     Path indexPath = FileFactory.getPath(dataMapModel.getFilePath());
0:     FileSystem fs = FileFactory.getFileSystem(indexPath);
0:     if (!fs.exists(indexPath)) {
0:       throw new IOException(
0:           String.format("Path %s for Bloom index dataMap does not exist", indexPath));
1:     }
0:     if (!fs.isDirectory(indexPath)) {
0:       throw new IOException(
0:           String.format("Path %s for Bloom index dataMap must be a directory", indexPath));
1:     }
1: 
0:     FileStatus[] indexFileStatus = fs.listStatus(indexPath, new PathFilter() {
0:       @Override public boolean accept(Path path) {
0:         return path.getName().endsWith(BLOOM_INDEX_SUFFIX);
1:       }
0:     });
0:     indexFilePath = new String[indexFileStatus.length];
0:     indexedColumn = new HashSet<String>();
0:     bloomIndexList = new ArrayList<BloomDMModel>();
0:     indexCol2BloomDMList = ArrayListMultimap.create();
0:     for (int i = 0; i < indexFileStatus.length; i++) {
0:       indexFilePath[i] = indexFileStatus[i].getPath().toString();
0:       String indexCol = StringUtils.substringBetween(indexFilePath[i], ".carbondata.",
0:           BLOOM_INDEX_SUFFIX);
0:       indexedColumn.add(indexCol);
0:       bloomIndexList.addAll(readBloomIndex(indexFilePath[i]));
0:       indexCol2BloomDMList.put(indexCol, readBloomIndex(indexFilePath[i]));
1:     }
0:     LOGGER.info("find bloom index datamap for column: "
0:         + StringUtils.join(indexedColumn, ", "));
1:   }
1: 
0:   private List<BloomDMModel> readBloomIndex(String indexFile) throws IOException {
0:     LOGGER.info("read bloom index from file: " + indexFile);
0:     List<BloomDMModel> bloomDMModelList = new ArrayList<BloomDMModel>();
0:     DataInputStream dataInStream = null;
0:     ObjectInputStream objectInStream = null;
0:     try {
0:       dataInStream = FileFactory.getDataInputStream(indexFile, FileFactory.getFileType(indexFile));
0:       objectInStream = new ObjectInputStream(dataInStream);
0:       try {
0:         BloomDMModel model = null;
0:         while ((model = (BloomDMModel) objectInStream.readObject()) != null) {
0:           LOGGER.info("read bloom index: " + model);
0:           bloomDMModelList.add(model);
1:         }
0:       } catch (EOFException e) {
0:         LOGGER.info("read " + bloomDMModelList.size() + " bloom indices from " + indexFile);
1:       }
0:       return bloomDMModelList;
0:     } catch (ClassNotFoundException e) {
0:       LOGGER.error("Error occrus while reading bloom index");
0:       throw new RuntimeException("Error occrus while reading bloom index", e);
0:     } finally {
0:       CarbonUtil.closeStreams(objectInStream, dataInStream);
1:     }
1:   }
1: 
1:   @Override
1:   public List<Blocklet> prune(FilterResolverIntf filterExp, SegmentProperties segmentProperties,
1:       List<PartitionSpec> partitions) throws IOException {
0:     List<Blocklet> hitBlocklets = new ArrayList<Blocklet>();
1:     if (filterExp == null) {
1:       // null is different from empty here. Empty means after pruning, no blocklet need to scan.
1:       return null;
1:     }
1: 
0:     List<BloomQueryModel> bloomQueryModels = getQueryValue(filterExp.getFilterExpression());
1: 
1:     for (BloomQueryModel bloomQueryModel : bloomQueryModels) {
0:       LOGGER.info("prune blocklet for query: " + bloomQueryModel);
0:       for (List<BloomDMModel> bloomDMModels : indexCol2BloomDMList.get(
0:           bloomQueryModel.columnName)) {
0:         for (BloomDMModel bloomDMModel : bloomDMModels) {
0:           boolean scanRequired = bloomDMModel.getBloomFilter().mightContain(
0:               convertValueToBytes(bloomQueryModel.dataType, bloomQueryModel.filterValue));
0:           if (scanRequired) {
0:             LOGGER.info(String.format(
0:                 "BloomCoarseGrainDataMap: Need to scan block#%s -> blocklet#%s",
0:                 bloomDMModel.getBlockId(), String.valueOf(bloomDMModel.getBlockletNo())));
0:             Blocklet blocklet = new Blocklet(bloomDMModel.getBlockId(),
0:                 String.valueOf(bloomDMModel.getBlockletNo()));
0:             hitBlocklets.add(blocklet);
0:           } else {
0:             LOGGER.info(String.format(
0:                 "BloomCoarseGrainDataMap: Skip scan block#%s -> blocklet#%s",
0:                 bloomDMModel.getBlockId(), String.valueOf(bloomDMModel.getBlockletNo())));
1:           }
1:         }
1:       }
1:     }
1: 
0:     return hitBlocklets;
1:   }
1: 
0:   private byte[] convertValueToBytes(DataType dataType, Object value) {
0:     try {
0:       if (dataType == DataTypes.STRING) {
0:         if (value instanceof byte[]) {
0:           return (byte[]) value;
0:         } else {
0:           return String.valueOf(value).getBytes("utf-8");
1:         }
0:       } else {
0:         return CarbonUtil.getValueAsBytes(dataType, value);
1:       }
0:     } catch (UnsupportedEncodingException e) {
0:       throw new RuntimeException("Error occurs while converting " + value + " to " + dataType, e);
1:     }
1:   }
1: 
0:   private List<BloomQueryModel> getQueryValue(Expression expression) {
1:     List<BloomQueryModel> queryModels = new ArrayList<BloomQueryModel>();
1:     if (expression instanceof EqualToExpression) {
1:       Expression left = ((EqualToExpression) expression).getLeft();
1:       Expression right = ((EqualToExpression) expression).getRight();
1:       String column;
0:       DataType dataType;
0:       Object value;
1:       if (left instanceof ColumnExpression && right instanceof LiteralExpression) {
1:         column = ((ColumnExpression) left).getColumnName();
0:         if (indexedColumn.contains(column)) {
0:           dataType = ((ColumnExpression) left).getDataType();
0:           value = ((LiteralExpression) right).getLiteralExpValue();
0:           BloomQueryModel bloomQueryModel = new BloomQueryModel(column, dataType, value);
1:           queryModels.add(bloomQueryModel);
1:         }
1:         return queryModels;
1:       } else if (left instanceof LiteralExpression && right instanceof ColumnExpression) {
1:         column = ((ColumnExpression) right).getColumnName();
0:         if (indexedColumn.contains(column)) {
0:           dataType = ((ColumnExpression) right).getDataType();
0:           value = ((LiteralExpression) left).getLiteralExpValue();
0:           BloomQueryModel bloomQueryModel = new BloomQueryModel(column, dataType, value);
1:           queryModels.add(bloomQueryModel);
1:         }
1:         return queryModels;
1:       }
1:     }
1: 
1:     for (Expression child : expression.getChildren()) {
0:       queryModels.addAll(getQueryValue(child));
1:     }
1:     return queryModels;
1:   }
1: 
1:   @Override
1:   public boolean isScanRequired(FilterResolverIntf filterExp) {
1:     return true;
1:   }
1: 
1:   @Override
1:   public void clear() {
0:     bloomIndexList.clear();
0:     bloomIndexList = null;
1:   }
1: 
1:   static class BloomQueryModel {
1:     private String columnName;
0:     private DataType dataType;
0:     private Object filterValue;
1: 
0:     public BloomQueryModel(String columnName, DataType dataType, Object filterValue) {
1:       this.columnName = columnName;
0:       this.dataType = dataType;
1:       this.filterValue = filterValue;
1:     }
1: 
1:     @Override
1:     public String toString() {
1:       final StringBuilder sb = new StringBuilder("BloomQueryModel{");
1:       sb.append("columnName='").append(columnName).append('\'');
0:       sb.append(", dataType=").append(dataType);
0:       sb.append(", filterValue=").append(filterValue);
1:       sb.append('}');
1:       return sb.toString();
1:     }
1:   }
1: }
author:kunal642
-------------------------------------------------------------------------------
commit:7a1d12a
/////////////////////////////////////////////////////////////////////////
1:         FieldConverter fieldConverter = FieldEncoderFactory.getInstance()
1:             .createFieldEncoder(dataField, absoluteTableIdentifier, i, nullFormat, null, false,
0:                 localCaches[i], false, carbonTable.getTablePath());
author:ravipesala
-------------------------------------------------------------------------------
commit:047c502
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.cache.Cache;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.util.bloom.CarbonBloomFilter;
/////////////////////////////////////////////////////////////////////////
1:   private Cache<BloomCacheKeyValue.CacheKey, BloomCacheKeyValue.CacheValue> cache;
1:     if (dataMapModel instanceof BloomDataMapModel) {
1:       BloomDataMapModel model = (BloomDataMapModel) dataMapModel;
1:       this.cache = model.getCache();
0:       this.indexedColumn = model.getIndexedColumnNames();
0:       List<PartitionSpec> partitions) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:       BloomCacheKeyValue.CacheKey cacheKey = new BloomCacheKeyValue.CacheKey(
1:       BloomCacheKeyValue.CacheValue cacheValue = cache.get(cacheKey);
1:       List<CarbonBloomFilter> bloomIndexList = cacheValue.getBloomFilters();
1:       for (CarbonBloomFilter bloomFilter : bloomIndexList) {
0:         boolean scanRequired = bloomFilter.membershipTest(new Key(
1:               String.valueOf(bloomFilter.getBlockletNo())));
0:           Blocklet blocklet = new Blocklet(shardName, String.valueOf(bloomFilter.getBlockletNo()));
1:               String.valueOf(bloomFilter.getBlockletNo())));
/////////////////////////////////////////////////////////////////////////
commit:77a1110
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.util.bloom.Key;
/////////////////////////////////////////////////////////////////////////
0:       List<PartitionSpec> partitions) {
/////////////////////////////////////////////////////////////////////////
0:         boolean scanRequired = bloomDMModel.getBloomFilter().membershipTest(new Key(
0:             convertValueToBytes(bloomQueryModel.dataType, bloomQueryModel.filterValue)));
/////////////////////////////////////////////////////////////////////////
commit:8b33ab2
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private String shardName;
1:   public void init(DataMapModel dataMapModel) throws IOException {
1:     this.shardName = indexPath.getName();
/////////////////////////////////////////////////////////////////////////
0:       String indexfilename = indexFileStatus[i].getPath().getName();
0:       String indexCol =
0:           indexfilename.substring(0, indexfilename.length() - BLOOM_INDEX_SUFFIX.length());
/////////////////////////////////////////////////////////////////////////
0:                 "BloomCoarseGrainDataMap: Need to scan -> blocklet#%s",
0:                 String.valueOf(bloomDMModel.getBlockletNo())));
0:             Blocklet blocklet =
0:                 new Blocklet(shardName, String.valueOf(bloomDMModel.getBlockletNo()));
0:                 "BloomCoarseGrainDataMap: Skip scan -> blocklet#%s",
0:                 String.valueOf(bloomDMModel.getBlockletNo())));
author:akashrn5
-------------------------------------------------------------------------------
commit:07a77fa
/////////////////////////////////////////////////////////////////////////
0: 
1:   @Override
1:   public void finish() {
0: 
0:   }
author:Jacky Li
-------------------------------------------------------------------------------
commit:9db662a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       List<BloomDMModel> models = readBloomIndex(indexFileStatus[i].getPath().toString());
0:       bloomIndexList.addAll(models);
0:       indexCol2BloomDMList.put(indexCol, models);
============================================================================
1:d96f09a: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:d96f09a:  *
1:d96f09a:  *    http://www.apache.org/licenses/LICENSE-2.0
1:d96f09a:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
1:d96f09a:  */
9:d96f09a: 
1:349c59c: package org.apache.carbondata.processing.loading.steps;
1:496cde4: 
1:eaadc88: import java.io.IOException;
1:87dade7: import java.util.ArrayList;
1:d5396b1: import java.util.Arrays;
1:496cde4: import java.util.Iterator;
1:87dade7: import java.util.List;
1:496cde4: 
1:496cde4: import org.apache.carbondata.common.CarbonIterator;
1:dc83b2a: import org.apache.carbondata.core.datastore.row.CarbonRow;
1:d5396b1: import org.apache.carbondata.core.metadata.schema.BucketingInfo;
1:d5396b1: import org.apache.carbondata.core.metadata.schema.SortColumnRangeInfo;
1:d5396b1: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
1:349c59c: import org.apache.carbondata.processing.loading.AbstractDataLoadProcessorStep;
1:349c59c: import org.apache.carbondata.processing.loading.BadRecordsLogger;
1:837fdd2: import org.apache.carbondata.processing.loading.BadRecordsLoggerProvider;
1:349c59c: import org.apache.carbondata.processing.loading.CarbonDataLoadConfiguration;
1:349c59c: import org.apache.carbondata.processing.loading.DataField;
1:d5396b1: import org.apache.carbondata.processing.loading.converter.BadRecordLogHolder;
1:d5396b1: import org.apache.carbondata.processing.loading.converter.FieldConverter;
1:349c59c: import org.apache.carbondata.processing.loading.converter.RowConverter;
1:349c59c: import org.apache.carbondata.processing.loading.converter.impl.RowConverterImpl;
1:f911403: import org.apache.carbondata.processing.loading.exception.CarbonDataLoadingException;
1:d5396b1: import org.apache.carbondata.processing.loading.partition.Partitioner;
1:d5396b1: import org.apache.carbondata.processing.loading.partition.impl.HashPartitionerImpl;
1:d5396b1: import org.apache.carbondata.processing.loading.partition.impl.RangePartitionerImpl;
1:d5396b1: import org.apache.carbondata.processing.loading.partition.impl.RawRowComparator;
1:349c59c: import org.apache.carbondata.processing.loading.row.CarbonRowBatch;
1:837fdd2: import org.apache.carbondata.processing.util.CarbonBadRecordUtil;
1:496cde4: 
1:d5396b1: import org.apache.commons.lang3.StringUtils;
1:d5396b1: 
1:d96f09a: /**
1:d96f09a:  * Replace row data fields with dictionary values if column is configured dictionary encoded.
1:d96f09a:  * And nondictionary columns as well as complex columns will be converted to byte[].
1:d96f09a:  */
1:d96f09a: public class DataConverterProcessorStepImpl extends AbstractDataLoadProcessorStep {
1:496cde4: 
1:87dade7:   private List<RowConverter> converters;
1:d5396b1:   private Partitioner<CarbonRow> partitioner;
1:3251c89:   private BadRecordsLogger badRecordLogger;
1:d5396b1:   private boolean isSortColumnRangeEnabled = false;
1:d5396b1:   private boolean isBucketColumnEnabled = false;
1:496cde4: 
1:d96f09a:   public DataConverterProcessorStepImpl(CarbonDataLoadConfiguration configuration,
1:d96f09a:       AbstractDataLoadProcessorStep child) {
1:d96f09a:     super(configuration, child);
7:496cde4:   }
1:82741c1: 
1:496cde4:   @Override
1:eaadc88:   public void initialize() throws IOException {
1:2b66476:     super.initialize();
1:d96f09a:     child.initialize();
1:87dade7:     converters = new ArrayList<>();
1:837fdd2:     badRecordLogger = BadRecordsLoggerProvider.createBadRecordLogger(configuration);
1:87dade7:     RowConverter converter =
1:87dade7:         new RowConverterImpl(child.getOutput(), configuration, badRecordLogger);
1:b13ead9:     configuration.setCardinalityFinder(converter);
1:87dade7:     converters.add(converter);
1:496cde4:     converter.initialize();
1:d5396b1: 
1:d5396b1:     if (null != configuration.getBucketingInfo()) {
1:d5396b1:       this.isBucketColumnEnabled = true;
1:d5396b1:       initializeBucketColumnPartitioner();
1:d5396b1:     } else if (null != configuration.getSortColumnRangeInfo()) {
1:d5396b1:       this.isSortColumnRangeEnabled = true;
1:d5396b1:       initializeSortColumnRangesPartitioner();
1:d5396b1:     }
1:d5396b1:   }
1:d5396b1: 
1:d5396b1:   /**
1:d5396b1:    * initialize partitioner for bucket column
1:d5396b1:    */
1:d5396b1:   private void initializeBucketColumnPartitioner() {
1:d5396b1:     List<Integer> indexes = new ArrayList<>();
1:d5396b1:     List<ColumnSchema> columnSchemas = new ArrayList<>();
1:d5396b1:     DataField[] inputDataFields = getOutput();
1:d5396b1:     BucketingInfo bucketingInfo = configuration.getBucketingInfo();
1:d5396b1:     for (int i = 0; i < inputDataFields.length; i++) {
1:d5396b1:       for (int j = 0; j < bucketingInfo.getListOfColumns().size(); j++) {
1:d5396b1:         if (inputDataFields[i].getColumn().getColName()
1:d5396b1:             .equals(bucketingInfo.getListOfColumns().get(j).getColumnName())) {
1:d5396b1:           indexes.add(i);
1:d5396b1:           columnSchemas.add(inputDataFields[i].getColumn().getColumnSchema());
1:d5396b1:           break;
1:d5396b1:         }
1:d5396b1:       }
1:d5396b1:     }
1:d5396b1: 
1:d5396b1:     // hash partitioner to dispatch rows by bucket column
1:d5396b1:     this.partitioner =
1:d5396b1:         new HashPartitionerImpl(indexes, columnSchemas, bucketingInfo.getNumOfRanges());
1:d5396b1:   }
1:d5396b1: 
1:d5396b1: 
1:d5396b1:   /**
1:d5396b1:    * initialize partitioner for sort column ranges
1:d5396b1:    */
1:d5396b1:   private void initializeSortColumnRangesPartitioner() {
1:d5396b1:     // convert user specified sort-column ranges
1:d5396b1:     SortColumnRangeInfo sortColumnRangeInfo = configuration.getSortColumnRangeInfo();
1:d5396b1:     int rangeValueCnt = sortColumnRangeInfo.getUserSpecifiedRanges().length;
1:d5396b1:     CarbonRow[] convertedSortColumnRanges = new CarbonRow[rangeValueCnt];
1:d5396b1:     for (int i = 0; i < rangeValueCnt; i++) {
1:d5396b1:       Object[] fakeOriginRow = new Object[configuration.getDataFields().length];
1:d5396b1:       String[] oneBound = StringUtils.splitPreserveAllTokens(
1:d5396b1:           sortColumnRangeInfo.getUserSpecifiedRanges()[i], sortColumnRangeInfo.getSeparator(), -1);
1:d5396b1:       // set the corresponding sort column
1:d5396b1:       int j = 0;
1:d5396b1:       for (int colIdx : sortColumnRangeInfo.getSortColumnIndex()) {
1:d5396b1:         fakeOriginRow[colIdx] = oneBound[j++];
1:d5396b1:       }
1:d5396b1:       CarbonRow fakeCarbonRow = new CarbonRow(fakeOriginRow);
1:d5396b1:       convertFakeRow(fakeCarbonRow, sortColumnRangeInfo);
1:d5396b1:       convertedSortColumnRanges[i] = fakeCarbonRow;
1:d5396b1:     }
1:d5396b1:     // sort the range bounds (sort in carbon is a little different from what we think)
1:d5396b1:     Arrays.sort(convertedSortColumnRanges,
1:d5396b1:         new RawRowComparator(sortColumnRangeInfo.getSortColumnIndex(),
1:d5396b1:             sortColumnRangeInfo.getIsSortColumnNoDict()));
1:d5396b1: 
1:d5396b1:     // range partitioner to dispatch rows by sort columns
1:d5396b1:     this.partitioner = new RangePartitionerImpl(convertedSortColumnRanges,
1:d5396b1:         new RawRowComparator(sortColumnRangeInfo.getSortColumnIndex(),
1:d5396b1:             sortColumnRangeInfo.getIsSortColumnNoDict()));
1:d5396b1:   }
1:d5396b1: 
1:d5396b1:   // only convert sort column fields
1:d5396b1:   private void convertFakeRow(CarbonRow fakeRow, SortColumnRangeInfo sortColumnRangeInfo) {
1:d5396b1:     FieldConverter[] fieldConverters = converters.get(0).getFieldConverters();
1:d5396b1:     BadRecordLogHolder logHolder = new BadRecordLogHolder();
1:d5396b1:     logHolder.setLogged(false);
1:d5396b1:     for (int colIdx : sortColumnRangeInfo.getSortColumnIndex()) {
1:d5396b1:       fieldConverters[colIdx].convert(fakeRow, logHolder);
1:d5396b1:     }
1:39644b5:   }
1:30f575f: 
1:f911403:   @Override public Iterator<CarbonRowBatch>[] execute() throws CarbonDataLoadingException {
1:f911403:     Iterator<CarbonRowBatch>[] childIters = child.execute();
1:f911403:     Iterator<CarbonRowBatch>[] iterators = new Iterator[childIters.length];
1:f911403:     for (int i = 0; i < childIters.length; i++) {
1:f911403:       iterators[i] = getIterator(childIters[i]);
1:f911403:     }
1:f911403:     return iterators;
1:f911403:   }
1:f911403: 
1:496cde4:   /**
1:496cde4:    * Create the iterator using child iterator.
1:496cde4:    *
1:496cde4:    * @param childIter
1:496cde4:    * @return new iterator with step specific processing.
1:496cde4:    */
1:f911403:   private Iterator<CarbonRowBatch> getIterator(final Iterator<CarbonRowBatch> childIter) {
1:496cde4:     return new CarbonIterator<CarbonRowBatch>() {
1:87dade7:       private boolean first = true;
1:87dade7:       private RowConverter localConverter;
1:496cde4:       @Override public boolean hasNext() {
1:87dade7:         if (first) {
1:87dade7:           first = false;
1:87dade7:           localConverter = converters.get(0).createCopyForNewThread();
1:2ec69f6:           synchronized (converters) {
1:2ec69f6:             converters.add(localConverter);
1:2ec69f6:           }
1:82741c1:         }
1:496cde4:         return childIter.hasNext();
1:87dade7:       }
1:496cde4:       @Override public CarbonRowBatch next() {
1:496cde4:         return processRowBatch(childIter.next(), localConverter);
1:30f575f:       }
1:496cde4:     };
1:496cde4:   }
1:496cde4: 
1:496cde4:   /**
1:496cde4:    * Process the batch of rows as per the step logic.
1:496cde4:    *
1:496cde4:    * @param rowBatch
1:496cde4:    * @return processed row.
1:496cde4:    */
1:496cde4:   protected CarbonRowBatch processRowBatch(CarbonRowBatch rowBatch, RowConverter localConverter) {
1:c5aba5f:     while (rowBatch.hasNext()) {
1:95b9208:       CarbonRow convertRow = localConverter.convert(rowBatch.next());
1:2ebfab1:       if (convertRow == null) {
1:2ebfab1:         rowBatch.remove();
1:2ebfab1:       } else {
1:2ebfab1:         if (isSortColumnRangeEnabled || isBucketColumnEnabled) {
1:2ebfab1:           short rangeNumber = (short) partitioner.getPartition(convertRow);
1:2ebfab1:           convertRow.setRangeId(rangeNumber);
1:2ebfab1:         }
1:2ebfab1:         rowBatch.setPreviousRow(convertRow);
1:d5396b1:       }
1:496cde4:     }
1:95b9208:     rowCounter.getAndAdd(rowBatch.getSize());
1:95b9208:     // reuse the origin batch
1:95b9208:     rowBatch.rewind();
1:95b9208:     return rowBatch;
1:496cde4:   }
1:496cde4: 
4:d96f09a:   @Override
1:d96f09a:   public void close() {
1:30f575f:     if (!closed) {
1:3251c89:       if (null != badRecordLogger) {
1:3251c89:         badRecordLogger.closeStreams();
1:837fdd2:         CarbonBadRecordUtil.renameBadRecord(configuration);
1:3251c89:       }
1:30f575f:       super.close();
1:87dade7:       if (converters != null) {
1:87dade7:         for (RowConverter converter : converters) {
1:2ec69f6:           if (null != converter) {
1:2ec69f6:             converter.finish();
1:2ec69f6:           }
1:2a205a5:         }
1:82741c1:       }
1:82741c1:     }
1:82741c1:   }
1:82741c1: 
1:30f575f:   @Override protected String getStepName() {
1:d5396b1:     if (isBucketColumnEnabled) {
1:d5396b1:       return "Data Converter with Bucketing";
1:d5396b1:     } else if (isSortColumnRangeEnabled) {
1:d5396b1:       return "Data Converter with sort column range";
1:d5396b1:     } else {
1:d5396b1:       return "Data Converter";
1:d5396b1:     }
1:87dade7:   }
1:30f575f: }
============================================================================
author:sraghunandan
-------------------------------------------------------------------------------
commit:f911403
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.exception.CarbonDataLoadingException;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   @Override public Iterator<CarbonRowBatch>[] execute() throws CarbonDataLoadingException {
1:     Iterator<CarbonRowBatch>[] childIters = child.execute();
1:     Iterator<CarbonRowBatch>[] iterators = new Iterator[childIters.length];
1:     for (int i = 0; i < childIters.length; i++) {
1:       iterators[i] = getIterator(childIters[i]);
1:     }
1:     return iterators;
1:   }
1: 
1:   private Iterator<CarbonRowBatch> getIterator(final Iterator<CarbonRowBatch> childIter) {
/////////////////////////////////////////////////////////////////////////
author:Geetika Gupta
-------------------------------------------------------------------------------
commit:2ebfab1
/////////////////////////////////////////////////////////////////////////
1:       if (convertRow == null) {
1:         rowBatch.remove();
1:       } else {
1:         if (isSortColumnRangeEnabled || isBucketColumnEnabled) {
1:           short rangeNumber = (short) partitioner.getPartition(convertRow);
1:           convertRow.setRangeId(rangeNumber);
1:         }
1:         rowBatch.setPreviousRow(convertRow);
author:xuchuanyin
-------------------------------------------------------------------------------
commit:d5396b1
/////////////////////////////////////////////////////////////////////////
1: import java.util.Arrays;
1: import org.apache.carbondata.core.metadata.schema.BucketingInfo;
1: import org.apache.carbondata.core.metadata.schema.SortColumnRangeInfo;
1: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
1: import org.apache.carbondata.processing.loading.converter.BadRecordLogHolder;
1: import org.apache.carbondata.processing.loading.converter.FieldConverter;
1: import org.apache.carbondata.processing.loading.partition.Partitioner;
1: import org.apache.carbondata.processing.loading.partition.impl.HashPartitionerImpl;
1: import org.apache.carbondata.processing.loading.partition.impl.RangePartitionerImpl;
1: import org.apache.carbondata.processing.loading.partition.impl.RawRowComparator;
1: import org.apache.commons.lang3.StringUtils;
1: 
/////////////////////////////////////////////////////////////////////////
1:   private Partitioner<CarbonRow> partitioner;
1:   private boolean isSortColumnRangeEnabled = false;
1:   private boolean isBucketColumnEnabled = false;
/////////////////////////////////////////////////////////////////////////
1: 
1:     if (null != configuration.getBucketingInfo()) {
1:       this.isBucketColumnEnabled = true;
1:       initializeBucketColumnPartitioner();
1:     } else if (null != configuration.getSortColumnRangeInfo()) {
1:       this.isSortColumnRangeEnabled = true;
1:       initializeSortColumnRangesPartitioner();
1:     }
1:   }
1: 
1:   /**
1:    * initialize partitioner for bucket column
1:    */
1:   private void initializeBucketColumnPartitioner() {
1:     List<Integer> indexes = new ArrayList<>();
1:     List<ColumnSchema> columnSchemas = new ArrayList<>();
1:     DataField[] inputDataFields = getOutput();
1:     BucketingInfo bucketingInfo = configuration.getBucketingInfo();
1:     for (int i = 0; i < inputDataFields.length; i++) {
1:       for (int j = 0; j < bucketingInfo.getListOfColumns().size(); j++) {
1:         if (inputDataFields[i].getColumn().getColName()
1:             .equals(bucketingInfo.getListOfColumns().get(j).getColumnName())) {
1:           indexes.add(i);
1:           columnSchemas.add(inputDataFields[i].getColumn().getColumnSchema());
1:           break;
1:         }
1:       }
1:     }
1: 
1:     // hash partitioner to dispatch rows by bucket column
1:     this.partitioner =
1:         new HashPartitionerImpl(indexes, columnSchemas, bucketingInfo.getNumOfRanges());
1:   }
1: 
1: 
1:   /**
1:    * initialize partitioner for sort column ranges
1:    */
1:   private void initializeSortColumnRangesPartitioner() {
1:     // convert user specified sort-column ranges
1:     SortColumnRangeInfo sortColumnRangeInfo = configuration.getSortColumnRangeInfo();
1:     int rangeValueCnt = sortColumnRangeInfo.getUserSpecifiedRanges().length;
1:     CarbonRow[] convertedSortColumnRanges = new CarbonRow[rangeValueCnt];
1:     for (int i = 0; i < rangeValueCnt; i++) {
1:       Object[] fakeOriginRow = new Object[configuration.getDataFields().length];
1:       String[] oneBound = StringUtils.splitPreserveAllTokens(
1:           sortColumnRangeInfo.getUserSpecifiedRanges()[i], sortColumnRangeInfo.getSeparator(), -1);
1:       // set the corresponding sort column
1:       int j = 0;
1:       for (int colIdx : sortColumnRangeInfo.getSortColumnIndex()) {
1:         fakeOriginRow[colIdx] = oneBound[j++];
1:       }
1:       CarbonRow fakeCarbonRow = new CarbonRow(fakeOriginRow);
1:       convertFakeRow(fakeCarbonRow, sortColumnRangeInfo);
1:       convertedSortColumnRanges[i] = fakeCarbonRow;
1:     }
1:     // sort the range bounds (sort in carbon is a little different from what we think)
1:     Arrays.sort(convertedSortColumnRanges,
1:         new RawRowComparator(sortColumnRangeInfo.getSortColumnIndex(),
1:             sortColumnRangeInfo.getIsSortColumnNoDict()));
1: 
1:     // range partitioner to dispatch rows by sort columns
1:     this.partitioner = new RangePartitionerImpl(convertedSortColumnRanges,
1:         new RawRowComparator(sortColumnRangeInfo.getSortColumnIndex(),
1:             sortColumnRangeInfo.getIsSortColumnNoDict()));
1:   }
1: 
1:   // only convert sort column fields
1:   private void convertFakeRow(CarbonRow fakeRow, SortColumnRangeInfo sortColumnRangeInfo) {
1:     FieldConverter[] fieldConverters = converters.get(0).getFieldConverters();
1:     BadRecordLogHolder logHolder = new BadRecordLogHolder();
1:     logHolder.setLogged(false);
1:     for (int colIdx : sortColumnRangeInfo.getSortColumnIndex()) {
1:       fieldConverters[colIdx].convert(fakeRow, logHolder);
1:     }
/////////////////////////////////////////////////////////////////////////
0:       if (isSortColumnRangeEnabled || isBucketColumnEnabled) {
0:         short rangeNumber = (short) partitioner.getPartition(convertRow);
0:         convertRow.setRangeId(rangeNumber);
1:       }
/////////////////////////////////////////////////////////////////////////
1:     if (isBucketColumnEnabled) {
1:       return "Data Converter with Bucketing";
1:     } else if (isSortColumnRangeEnabled) {
1:       return "Data Converter with sort column range";
1:     } else {
1:       return "Data Converter";
1:     }
commit:95b9208
/////////////////////////////////////////////////////////////////////////
1:       CarbonRow convertRow = localConverter.convert(rowBatch.next());
0:       rowBatch.setPreviousRow(convertRow);
1:     rowCounter.getAndAdd(rowBatch.getSize());
1:     // reuse the origin batch
1:     rowBatch.rewind();
1:     return rowBatch;
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:837fdd2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.BadRecordsLoggerProvider;
1: import org.apache.carbondata.processing.util.CarbonBadRecordUtil;
/////////////////////////////////////////////////////////////////////////
1:     badRecordLogger = BadRecordsLoggerProvider.createBadRecordLogger(configuration);
/////////////////////////////////////////////////////////////////////////
1:         CarbonBadRecordUtil.renameBadRecord(configuration);
/////////////////////////////////////////////////////////////////////////
commit:39644b5
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.common.constants.LoggerAction;
0: import org.apache.carbondata.core.constants.CarbonLoadOptionConstants;
/////////////////////////////////////////////////////////////////////////
0:         identifier.getTableName() + '_' + System.currentTimeMillis(),
0:         getBadLogStoreLocation(configuration,
0:             identifier.getDatabaseName() + CarbonCommonConstants.FILE_SEPARATOR + identifier
0:                 .getTableName() + CarbonCommonConstants.FILE_SEPARATOR + configuration
0:                 .getSegmentId() + CarbonCommonConstants.FILE_SEPARATOR + configuration.getTaskNo()),
0:   public static String getBadLogStoreLocation(CarbonDataLoadConfiguration configuration,
0:       String storeLocation) {
0:     String badLogStoreLocation = (String) configuration
0:         .getDataLoadProperty(CarbonLoadOptionConstants.CARBON_OPTIONS_BAD_RECORD_PATH);
0:     if (null == badLogStoreLocation) {
0:       badLogStoreLocation =
0:           CarbonProperties.getInstance().getProperty(CarbonCommonConstants.CARBON_BADRECORDS_LOC);
1:     }
/////////////////////////////////////////////////////////////////////////
0:     CarbonDataProcessorUtil.renameBadRecordsFromInProgressToNormal(configuration,
commit:3af2d65
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.util.CarbonDataProcessorUtil;
/////////////////////////////////////////////////////////////////////////
0:         // rename the bad record in progress to normal
0:         CarbonTableIdentifier identifier =
0:             configuration.getTableIdentifier().getCarbonTableIdentifier();
0:         CarbonDataProcessorUtil.renameBadRecordsFromInProgressToNormal(
0:             identifier.getDatabaseName() + File.separator + identifier.getTableName()
0:                 + File.separator + configuration.getSegmentId() + File.separator + configuration
0:                 .getTaskNo());
commit:3251c89
/////////////////////////////////////////////////////////////////////////
1:   private BadRecordsLogger badRecordLogger;
/////////////////////////////////////////////////////////////////////////
0:     badRecordLogger = createBadRecordLogger();
/////////////////////////////////////////////////////////////////////////
0:         identifier.getDatabaseName() + CarbonCommonConstants.FILE_SEPARATOR + identifier
0:             .getTableName() + CarbonCommonConstants.FILE_SEPARATOR + configuration.getSegmentId()
0:             + CarbonCommonConstants.FILE_SEPARATOR + configuration.getTaskNo()),
0:         badRecordsLogRedirect, badRecordsLoggerEnable, badRecordConvertNullDisable, isDataLoadFail);
/////////////////////////////////////////////////////////////////////////
1:       if (null != badRecordLogger) {
1:         badRecordLogger.closeStreams();
1:       }
author:Jacky Li
-------------------------------------------------------------------------------
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.loading.steps;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.AbstractDataLoadProcessorStep;
1: import org.apache.carbondata.processing.loading.BadRecordsLogger;
1: import org.apache.carbondata.processing.loading.CarbonDataLoadConfiguration;
1: import org.apache.carbondata.processing.loading.DataField;
0: import org.apache.carbondata.processing.loading.constants.DataLoadProcessorConstants;
1: import org.apache.carbondata.processing.loading.converter.RowConverter;
1: import org.apache.carbondata.processing.loading.converter.impl.RowConverterImpl;
1: import org.apache.carbondata.processing.loading.row.CarbonRowBatch;
author:kumarvishal
-------------------------------------------------------------------------------
commit:2ec69f6
/////////////////////////////////////////////////////////////////////////
1:           synchronized (converters) {
1:             converters.add(localConverter);
1:           }
/////////////////////////////////////////////////////////////////////////
1:           if (null != converter) {
1:             converter.finish();
1:           }
author:manishgupta88
-------------------------------------------------------------------------------
commit:2a205a5
/////////////////////////////////////////////////////////////////////////
0:         renameBadRecord(badRecordLogger, configuration);
/////////////////////////////////////////////////////////////////////////
0:       renameBadRecord(badRecordLogger, configuration);
0:   private static void renameBadRecord(BadRecordsLogger badRecordLogger,
0:       CarbonDataLoadConfiguration configuration) {
0:     // rename operation should be performed only in case either bad reccords loggers is enabled
0:     // or bad records redirect is enabled
0:     if (badRecordLogger.isBadRecordLoggerEnable() || badRecordLogger.isBadRecordsLogRedirect()) {
0:       // rename the bad record in progress to normal
0:       CarbonTableIdentifier identifier =
0:           configuration.getTableIdentifier().getCarbonTableIdentifier();
0:       CarbonDataProcessorUtil.renameBadRecordsFromInProgressToNormal(configuration,
0:           identifier.getDatabaseName() + CarbonCommonConstants.FILE_SEPARATOR + identifier
0:               .getTableName() + CarbonCommonConstants.FILE_SEPARATOR + configuration.getSegmentId()
0:               + CarbonCommonConstants.FILE_SEPARATOR + configuration.getTaskNo());
1:     }
commit:2b66476
/////////////////////////////////////////////////////////////////////////
1:     super.initialize();
author:Yadong Qi
-------------------------------------------------------------------------------
commit:82741c1
/////////////////////////////////////////////////////////////////////////
0:     badRecordLogger = createBadRecordLogger(configuration);
/////////////////////////////////////////////////////////////////////////
0:   public static BadRecordsLogger createBadRecordLogger(CarbonDataLoadConfiguration configuration) {
/////////////////////////////////////////////////////////////////////////
0:   public static String getBadLogStoreLocation(String storeLocation) {
/////////////////////////////////////////////////////////////////////////
0:         renameBadRecord(configuration);
/////////////////////////////////////////////////////////////////////////
0:   public static void close(BadRecordsLogger badRecordLogger, CarbonDataLoadConfiguration
0:       configuration, RowConverter converter) {
0:     if (badRecordLogger != null) {
0:       badRecordLogger.closeStreams();
0:       renameBadRecord(configuration);
1:     }
0:     if (converter != null) {
0:       converter.finish();
1:     }
1:   }
1: 
0:   private static void renameBadRecord(CarbonDataLoadConfiguration configuration) {
0:     // rename the bad record in progress to normal
0:     CarbonTableIdentifier identifier =
0:         configuration.getTableIdentifier().getCarbonTableIdentifier();
0:     CarbonDataProcessorUtil.renameBadRecordsFromInProgressToNormal(
0:         identifier.getDatabaseName() + File.separator + identifier.getTableName()
0:             + File.separator + configuration.getSegmentId() + File.separator + configuration
0:             .getTaskNo());
1:   }
1: 
author:jackylk
-------------------------------------------------------------------------------
commit:dc83b2a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.row.CarbonRow;
/////////////////////////////////////////////////////////////////////////
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.CarbonTableIdentifier;
commit:eaadc88
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   public void initialize() throws IOException {
author:QiangCai
-------------------------------------------------------------------------------
commit:81149f6
/////////////////////////////////////////////////////////////////////////
0:     return new BadRecordsLogger(identifier.getBadRecordLoggerKey(),
commit:c5aba5f
/////////////////////////////////////////////////////////////////////////
0:     CarbonRowBatch newBatch = new CarbonRowBatch(rowBatch.getSize());
1:     while (rowBatch.hasNext()) {
0:       newBatch.addRow(localConverter.convert(rowBatch.next()));
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:ravipesala
-------------------------------------------------------------------------------
commit:1fa2df9
/////////////////////////////////////////////////////////////////////////
0:           converters.add(localConverter);
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
1:     configuration.setCardinalityFinder(converter);
commit:87dade7
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
1: import java.util.List;
/////////////////////////////////////////////////////////////////////////
1:   private List<RowConverter> converters;
/////////////////////////////////////////////////////////////////////////
1:     converters = new ArrayList<>();
1:     RowConverter converter =
1:         new RowConverterImpl(child.getOutput(), configuration, badRecordLogger);
1:     converters.add(converter);
/////////////////////////////////////////////////////////////////////////
1:       private boolean first = true;
1:       private RowConverter localConverter;
1:         if (first) {
1:           first = false;
1:           localConverter = converters.get(0).createCopyForNewThread();
1:         }
/////////////////////////////////////////////////////////////////////////
1:       if (converters != null) {
1:         for (RowConverter converter : converters) {
0:           converter.finish();
1:         }
commit:30f575f
/////////////////////////////////////////////////////////////////////////
0:     rowCounter.getAndAdd(newBatch.getSize());
/////////////////////////////////////////////////////////////////////////
1:     if (!closed) {
1:       super.close();
0:       if (converter != null) {
0:         converter.finish();
1:       }
1: 
1:   @Override protected String getStepName() {
0:     return "Data Converter";
1:   }
commit:496cde4
/////////////////////////////////////////////////////////////////////////
0: import java.io.File;
1: import java.util.Iterator;
1: 
1: import org.apache.carbondata.common.CarbonIterator;
0: import org.apache.carbondata.core.carbon.CarbonTableIdentifier;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.util.CarbonProperties;
0: import org.apache.carbondata.processing.constants.LoggerAction;
0: import org.apache.carbondata.processing.newflow.constants.DataLoadProcessorConstants;
0: import org.apache.carbondata.processing.newflow.row.CarbonRowBatch;
0: import org.apache.carbondata.processing.surrogatekeysgenerator.csvbased.BadRecordsLogger;
/////////////////////////////////////////////////////////////////////////
0:   private RowConverter converter;
/////////////////////////////////////////////////////////////////////////
0:     BadRecordsLogger badRecordLogger = createBadRecordLogger();
0:     converter = new RowConverterImpl(child.getOutput(), configuration, badRecordLogger);
1:     converter.initialize();
1:   }
1: 
1:   /**
1:    * Create the iterator using child iterator.
1:    *
1:    * @param childIter
1:    * @return new iterator with step specific processing.
1:    */
1:   @Override
0:   protected Iterator<CarbonRowBatch> getIterator(final Iterator<CarbonRowBatch> childIter) {
1:     return new CarbonIterator<CarbonRowBatch>() {
0:       RowConverter localConverter = converter.createCopyForNewThread();
1:       @Override public boolean hasNext() {
1:         return childIter.hasNext();
1:       }
1: 
1:       @Override public CarbonRowBatch next() {
1:         return processRowBatch(childIter.next(), localConverter);
1:       }
1:     };
1:   }
1: 
1:   /**
1:    * Process the batch of rows as per the step logic.
1:    *
1:    * @param rowBatch
1:    * @return processed row.
1:    */
1:   protected CarbonRowBatch processRowBatch(CarbonRowBatch rowBatch, RowConverter localConverter) {
0:     CarbonRowBatch newBatch = new CarbonRowBatch();
0:     Iterator<CarbonRow> batchIterator = rowBatch.getBatchIterator();
0:     while (batchIterator.hasNext()) {
0:       newBatch.addRow(localConverter.convert(batchIterator.next()));
1:     }
0:     return newBatch;
0:     throw new UnsupportedOperationException();
1:   }
1: 
0:   private BadRecordsLogger createBadRecordLogger() {
0:     boolean badRecordsLogRedirect = false;
0:     boolean badRecordConvertNullDisable = false;
0:     boolean badRecordsLoggerEnable = Boolean.parseBoolean(
0:         configuration.getDataLoadProperty(DataLoadProcessorConstants.BAD_RECORDS_LOGGER_ENABLE)
0:             .toString());
0:     Object bad_records_action =
0:         configuration.getDataLoadProperty(DataLoadProcessorConstants.BAD_RECORDS_LOGGER_ACTION)
0:             .toString();
0:     if (null != bad_records_action) {
0:       LoggerAction loggerAction = null;
0:       try {
0:         loggerAction = LoggerAction.valueOf(bad_records_action.toString().toUpperCase());
0:       } catch (IllegalArgumentException e) {
0:         loggerAction = LoggerAction.FORCE;
1:       }
0:       switch (loggerAction) {
0:         case FORCE:
0:           badRecordConvertNullDisable = false;
0:           break;
0:         case REDIRECT:
0:           badRecordsLogRedirect = true;
0:           badRecordConvertNullDisable = true;
0:           break;
0:         case IGNORE:
0:           badRecordsLogRedirect = false;
0:           badRecordConvertNullDisable = true;
0:           break;
1:       }
1:     }
0:     CarbonTableIdentifier identifier =
0:         configuration.getTableIdentifier().getCarbonTableIdentifier();
0:     BadRecordsLogger badRecordsLogger = new BadRecordsLogger(identifier.getBadRecordLoggerKey(),
0:         identifier.getTableName() + '_' + System.currentTimeMillis(), getBadLogStoreLocation(
0:         identifier.getDatabaseName() + File.separator + identifier.getTableName() + File.separator
0:             + configuration.getTaskNo()), badRecordsLogRedirect, badRecordsLoggerEnable,
0:         badRecordConvertNullDisable);
0:     return badRecordsLogger;
1:   }
1: 
0:   private String getBadLogStoreLocation(String storeLocation) {
0:     String badLogStoreLocation =
0:         CarbonProperties.getInstance().getProperty(CarbonCommonConstants.CARBON_BADRECORDS_LOC);
0:     badLogStoreLocation = badLogStoreLocation + File.separator + storeLocation;
1: 
0:     return badLogStoreLocation;
0:     if (converter != null) {
0:       converter.finish();
commit:d96f09a
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.newflow.steps;
1: 
0: import org.apache.carbondata.processing.newflow.AbstractDataLoadProcessorStep;
0: import org.apache.carbondata.processing.newflow.CarbonDataLoadConfiguration;
0: import org.apache.carbondata.processing.newflow.DataField;
0: import org.apache.carbondata.processing.newflow.converter.RowConverter;
0: import org.apache.carbondata.processing.newflow.converter.impl.RowConverterImpl;
0: import org.apache.carbondata.processing.newflow.exception.CarbonDataLoadingException;
0: import org.apache.carbondata.processing.newflow.row.CarbonRow;
1: 
1: /**
1:  * Replace row data fields with dictionary values if column is configured dictionary encoded.
1:  * And nondictionary columns as well as complex columns will be converted to byte[].
1:  */
1: public class DataConverterProcessorStepImpl extends AbstractDataLoadProcessorStep {
1: 
0:   private RowConverter encoder;
1: 
1:   public DataConverterProcessorStepImpl(CarbonDataLoadConfiguration configuration,
1:       AbstractDataLoadProcessorStep child) {
1:     super(configuration, child);
0:   }
1: 
1:   @Override
0:   public DataField[] getOutput() {
0:     return child.getOutput();
0:   }
1: 
1:   @Override
0:   public void initialize() throws CarbonDataLoadingException {
0:     encoder = new RowConverterImpl(child.getOutput(), configuration);
1:     child.initialize();
0:   }
1: 
1:   @Override
0:   protected CarbonRow processRow(CarbonRow row) {
0:     return encoder.convert(row);
0:   }
1: 
1:   @Override
1:   public void close() {
0:     super.close();
0:     if (encoder != null) {
0:       encoder.finish();
0:     }
0:   }
0: }
author:akash
-------------------------------------------------------------------------------
commit:9e11e13
/////////////////////////////////////////////////////////////////////////
0:     boolean isDataLoadFail = false;
/////////////////////////////////////////////////////////////////////////
0:         case FAIL:
0:           isDataLoadFail = true;
0:           break;
/////////////////////////////////////////////////////////////////////////
0:         badRecordConvertNullDisable, isDataLoadFail);
author:anubhav100
-------------------------------------------------------------------------------
commit:d8bbc3c
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       createBadRecordLogger().closeStreams();
============================================================================
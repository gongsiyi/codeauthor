1:cd6a4ff: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
2:cd6a4ff:  *
1:cd6a4ff:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cd6a4ff:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
10:cd6a4ff:  */
1:9f94529: 
1:349c59c: package org.apache.carbondata.processing.sort.sortdata;
1:496cde4: 
1:cd6a4ff: import java.io.DataInputStream;
1:cd6a4ff: import java.io.File;
1:cd6a4ff: import java.io.FileNotFoundException;
1:cd6a4ff: import java.io.IOException;
1:2b41f14: import java.util.Comparator;
1:cd6a4ff: import java.util.concurrent.Callable;
1:cd6a4ff: import java.util.concurrent.ExecutorService;
1:cd6a4ff: import java.util.concurrent.Executors;
1:cd6a4ff: import java.util.concurrent.Future;
61:cd6a4ff: 
1:cd6a4ff: import org.apache.carbondata.common.logging.LogService;
1:cd6a4ff: import org.apache.carbondata.common.logging.LogServiceFactory;
1:cd6a4ff: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:c100251: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonProperties;
1:a734add: import org.apache.carbondata.core.util.CarbonThreadFactory;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonUtil;
1:2b41f14: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1:cd6a4ff: 
1:cd6a4ff: public class SortTempFileChunkHolder implements Comparable<SortTempFileChunkHolder> {
1:cd6a4ff: 
10:cd6a4ff:   /**
1:cd6a4ff:    * LOGGER
1:9f94529:    */
1:cd6a4ff:   private static final LogService LOGGER =
1:cd6a4ff:       LogServiceFactory.getLogService(SortTempFileChunkHolder.class.getName());
1:9f94529: 
1:9f94529:   /**
1:cd6a4ff:    * temp file
1:cd6a4ff:    */
1:cd6a4ff:   private File tempFile;
1:496cde4: 
1:cd6a4ff:   /**
1:cd6a4ff:    * read stream
1:cd6a4ff:    */
1:cd6a4ff:   private DataInputStream stream;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * entry count
1:cd6a4ff:    */
1:cd6a4ff:   private int entryCount;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * number record read
1:cd6a4ff:    */
1:cd6a4ff:   private int numberOfObjectRead;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * return row
1:cd6a4ff:    */
1:2b41f14:   private IntermediateSortTempRow returnRow;
1:c100251:   private int readBufferSize;
1:c100251:   private String compressorName;
1:cd6a4ff: 
1:2b41f14:   private IntermediateSortTempRow[] currentBuffer;
1:cd6a4ff: 
1:2b41f14:   private IntermediateSortTempRow[] backupBuffer;
1:cd6a4ff: 
1:cd6a4ff:   private boolean isBackupFilled;
1:cd6a4ff: 
1:cd6a4ff:   private boolean prefetch;
1:cd6a4ff: 
1:cd6a4ff:   private int bufferSize;
1:cd6a4ff: 
1:cd6a4ff:   private int bufferRowCounter;
1:cd6a4ff: 
1:cd6a4ff:   private ExecutorService executorService;
1:cd6a4ff: 
1:cd6a4ff:   private Future<Void> submit;
1:cd6a4ff: 
1:cd6a4ff:   private int prefetchRecordsProceesed;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * totalRecordFetch
1:cd6a4ff:    */
1:cd6a4ff:   private int totalRecordFetch;
1:2b41f14:   private TableFieldStat tableFieldStat;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:2b41f14:   private Comparator<IntermediateSortTempRow> comparator;
1:f27efb3:   private boolean convertToActualField;
1:cd6a4ff:   /**
1:cd6a4ff:    * Constructor to initialize
1:cd6a4ff:    *
1:cd6a4ff:    * @param tempFile
1:c100251:    * @param sortParameters
1:c100251:    * @param tableName
1:cd6a4ff:    */
1:f27efb3:   public SortTempFileChunkHolder(File tempFile, SortParameters sortParameters, String tableName,
1:f27efb3:       boolean convertToActualField) {
1:cd6a4ff:     // set temp file
1:cd6a4ff:     this.tempFile = tempFile;
1:c100251:     this.readBufferSize = sortParameters.getBufferSize();
1:c100251:     this.compressorName = sortParameters.getSortTempCompressorName();
1:2b41f14:     this.tableFieldStat = new TableFieldStat(sortParameters);
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:2b41f14:     this.comparator = new IntermediateSortTempRowComparator(
1:2b41f14:         tableFieldStat.getIsSortColNoDictFlags());
1:a734add:     this.executorService = Executors
1:a734add:         .newFixedThreadPool(1, new CarbonThreadFactory("SafeSortTempChunkHolderPool:" + tableName));
1:f27efb3:     this.convertToActualField = convertToActualField;
1:496cde4:   }
1:8d8b589: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to initialize
1:21704cf:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException problem while initializing
1:496cde4:    */
1:cd6a4ff:   public void initialize() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     prefetch = Boolean.parseBoolean(CarbonProperties.getInstance()
1:cd6a4ff:         .getProperty(CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH,
1:cd6a4ff:             CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH_DEFAULT));
1:c5aba5f:     bufferSize = Integer.parseInt(CarbonProperties.getInstance()
1:c5aba5f:         .getProperty(CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE,
1:c5aba5f:             CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE_DEFAULT));
1:8d8b589: 
1:cd6a4ff:     initialise();
1:496cde4:   }
1:8d8b589: 
1:cd6a4ff:   private void initialise() throws CarbonSortKeyAndGroupByException {
1:8d8b589:     try {
1:c100251:       stream = FileFactory.getDataInputStream(tempFile.getPath(), FileFactory.FileType.LOCAL,
1:c100251:           readBufferSize, compressorName);
1:cd6a4ff:       this.entryCount = stream.readInt();
1:cd6a4ff:       if (prefetch) {
3:cd6a4ff:         new DataFetcher(false).call();
1:cd6a4ff:         totalRecordFetch += currentBuffer.length;
1:cd6a4ff:         if (totalRecordFetch < this.entryCount) {
1:cd6a4ff:           submit = executorService.submit(new DataFetcher(true));
1:8d8b589:         }
1:8d8b589:       }
1:cd6a4ff:     } catch (FileNotFoundException e) {
2:cd6a4ff:       LOGGER.error(e);
1:cd6a4ff:       throw new CarbonSortKeyAndGroupByException(tempFile + " No Found", e);
1:8d8b589:     } catch (IOException e) {
1:cd6a4ff:       LOGGER.error(e);
1:cd6a4ff:       throw new CarbonSortKeyAndGroupByException(tempFile + " No Found", e);
2:cd6a4ff:     } catch (Exception e) {
1:cd6a4ff:       LOGGER.error(e);
2:cd6a4ff:       throw new CarbonSortKeyAndGroupByException(tempFile + " Problem while reading", e);
1:8d8b589:     }
1:496cde4:   }
1:8d8b589: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to read new row from file
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException problem while reading
1:cd6a4ff:    */
1:cd6a4ff:   public void readRow() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     if (prefetch) {
1:cd6a4ff:       fillDataForPrefetch();
1:8d8b589:     } else {
1:2b41f14:       try {
1:f27efb3:         if (convertToActualField) {
1:f27efb3:           this.returnRow = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:f27efb3:         } else {
1:f27efb3:           this.returnRow = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:f27efb3:         }
1:2b41f14:         this.numberOfObjectRead++;
1:2b41f14:       } catch (IOException e) {
1:2b41f14:         throw new CarbonSortKeyAndGroupByException("Problem while reading rows", e);
1:2b41f14:       }
1:8d8b589:     }
1:8d8b589:   }
1:8d8b589: 
1:cd6a4ff:   private void fillDataForPrefetch() {
2:cd6a4ff:     if (bufferRowCounter >= bufferSize) {
1:cd6a4ff:       if (isBackupFilled) {
2:cd6a4ff:         bufferRowCounter = 0;
1:cd6a4ff:         currentBuffer = backupBuffer;
1:cd6a4ff:         totalRecordFetch += currentBuffer.length;
1:cd6a4ff:         isBackupFilled = false;
1:cd6a4ff:         if (totalRecordFetch < this.entryCount) {
1:cd6a4ff:           submit = executorService.submit(new DataFetcher(true));
1:8d8b589:         }
1:8d8b589:       } else {
1:21704cf:         try {
1:cd6a4ff:           submit.get();
1:cd6a4ff:         } catch (Exception e) {
1:cd6a4ff:           LOGGER.error(e);
1:8d8b589:         }
1:cd6a4ff:         bufferRowCounter = 0;
1:cd6a4ff:         currentBuffer = backupBuffer;
1:cd6a4ff:         isBackupFilled = false;
1:cd6a4ff:         totalRecordFetch += currentBuffer.length;
1:cd6a4ff:         if (totalRecordFetch < this.entryCount) {
1:cd6a4ff:           submit = executorService.submit(new DataFetcher(true));
1:21704cf:         }
1:496cde4:       }
1:496cde4:     }
2:cd6a4ff:     prefetchRecordsProceesed++;
2:cd6a4ff:     returnRow = currentBuffer[bufferRowCounter++];
1:496cde4:   }
1:8d8b589: 
1:cd6a4ff:   /**
1:2b41f14:    * Read a batch of row from stream
1:2b41f14:    *
1:496cde4:    * @return Object[]
1:2b41f14:    * @throws IOException if error occurs while reading from stream
1:cd6a4ff:    */
1:2b41f14:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected) throws IOException {
1:2b41f14:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
1:2b41f14:     for (int i = 0; i < expected; i++) {
1:f27efb3:       if (convertToActualField) {
1:f27efb3:         holders[i] = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:f27efb3:       } else {
1:f27efb3:         holders[i] = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:f27efb3:       }
1:8d8b589:     }
1:2b41f14:     this.numberOfObjectRead += expected;
1:2b41f14:     return holders;
1:8d8b589:   }
1:8d8b589: 
1:496cde4:   /**
1:2b41f14:    * below method will be used to get the sort temp row
1:cd6a4ff:    *
1:cd6a4ff:    * @return row
1:cd6a4ff:    */
1:2b41f14:   public IntermediateSortTempRow getRow() {
1:cd6a4ff:     return this.returnRow;
1:496cde4:   }
1:8d8b589: 
1:cd6a4ff:   /**
1:cd6a4ff:    * below method will be used to check whether any more records are present
1:cd6a4ff:    * in file or not
1:cd6a4ff:    *
1:cd6a4ff:    * @return more row present in file
1:cd6a4ff:    */
1:cd6a4ff:   public boolean hasNext() {
1:c100251:     if (prefetch) {
1:cd6a4ff:       return this.prefetchRecordsProceesed < this.entryCount;
1:496cde4:     }
1:cd6a4ff:     return this.numberOfObjectRead < this.entryCount;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Below method will be used to close streams
1:cd6a4ff:    */
1:cd6a4ff:   public void closeStream() {
1:cd6a4ff:     CarbonUtil.closeStreams(stream);
1:a734add:     if (null != executorService) {
1:a734add:       executorService.shutdownNow();
1:a734add:     }
1:c5aba5f:     this.backupBuffer = null;
1:c5aba5f:     this.currentBuffer = null;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will number of entries
1:cd6a4ff:    *
1:cd6a4ff:    * @return entryCount
1:cd6a4ff:    */
1:cd6a4ff:   public int getEntryCount() {
1:cd6a4ff:     return entryCount;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   @Override public int compareTo(SortTempFileChunkHolder other) {
1:2b41f14:     return comparator.compare(returnRow, other.getRow());
1:8d8b589:   }
1:8d8b589: 
1:cd6a4ff:   @Override public boolean equals(Object obj) {
1:06b0d08:     if (this == obj) {
1:06b0d08:       return true;
1:06b0d08:     }
1:06b0d08: 
1:cd6a4ff:     if (!(obj instanceof SortTempFileChunkHolder)) {
1:cd6a4ff:       return false;
1:496cde4:     }
1:cd6a4ff:     SortTempFileChunkHolder o = (SortTempFileChunkHolder) obj;
1:496cde4: 
1:06b0d08:     return this == o;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   @Override public int hashCode() {
1:cd6a4ff:     int hash = 0;
1:2b41f14:     hash += tableFieldStat.hashCode();
1:cd6a4ff:     hash += tempFile.hashCode();
1:cd6a4ff:     return hash;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   private final class DataFetcher implements Callable<Void> {
1:cd6a4ff:     private boolean isBackUpFilling;
1:496cde4: 
1:cd6a4ff:     private int numberOfRecords;
1:496cde4: 
1:cd6a4ff:     private DataFetcher(boolean backUp) {
1:cd6a4ff:       isBackUpFilling = backUp;
1:cd6a4ff:       calculateNumberOfRecordsToBeFetched();
1:496cde4:     }
1:cd6a4ff: 
1:cd6a4ff:     private void calculateNumberOfRecordsToBeFetched() {
1:cd6a4ff:       int numberOfRecordsLeftToBeRead = entryCount - totalRecordFetch;
1:cd6a4ff:       numberOfRecords =
1:cd6a4ff:           bufferSize < numberOfRecordsLeftToBeRead ? bufferSize : numberOfRecordsLeftToBeRead;
1:496cde4:     }
1:cd6a4ff: 
1:cd6a4ff:     @Override public Void call() throws Exception {
1:496cde4:       try {
1:cd6a4ff:         if (isBackUpFilling) {
1:cd6a4ff:           backupBuffer = prefetchRecordsFromFile(numberOfRecords);
1:cd6a4ff:           isBackupFilled = true;
1:8d8b589:         } else {
1:cd6a4ff:           currentBuffer = prefetchRecordsFromFile(numberOfRecords);
47:cd6a4ff:         }
1:cd6a4ff:       } catch (Exception e) {
1:cd6a4ff:         LOGGER.error(e);
1:cd6a4ff:       }
1:cd6a4ff:       return null;
1:cd6a4ff:     }
1:cd6a4ff: 
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will read the records from sort temp file and keep it in a buffer
1:cd6a4ff:    *
1:2b41f14:    * @param numberOfRecords number of records to be read
1:2b41f14:    * @return batch of intermediate sort temp row
1:2b41f14:    * @throws IOException if error occurs while reading reading records
1:cd6a4ff:    */
1:2b41f14:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
1:2b41f14:       throws IOException {
1:2b41f14:     return readBatchedRowFromStream(numberOfRecords);
1:8d8b589:   }
1:cd6a4ff: }
============================================================================
author:kumarvishal09
-------------------------------------------------------------------------------
commit:f27efb3
/////////////////////////////////////////////////////////////////////////
1:   private boolean convertToActualField;
/////////////////////////////////////////////////////////////////////////
1:   public SortTempFileChunkHolder(File tempFile, SortParameters sortParameters, String tableName,
1:       boolean convertToActualField) {
/////////////////////////////////////////////////////////////////////////
1:     this.convertToActualField = convertToActualField;
/////////////////////////////////////////////////////////////////////////
1:         if (convertToActualField) {
1:           this.returnRow = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:         } else {
1:           this.returnRow = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:         }
/////////////////////////////////////////////////////////////////////////
1:       if (convertToActualField) {
1:         holders[i] = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:       } else {
1:         holders[i] = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:       }
author:xuchuanyin
-------------------------------------------------------------------------------
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
1: import java.util.Comparator;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:   private IntermediateSortTempRow returnRow;
1:   private IntermediateSortTempRow[] currentBuffer;
1:   private IntermediateSortTempRow[] backupBuffer;
/////////////////////////////////////////////////////////////////////////
1:   private TableFieldStat tableFieldStat;
1:   private SortStepRowHandler sortStepRowHandler;
1:   private Comparator<IntermediateSortTempRow> comparator;
/////////////////////////////////////////////////////////////////////////
1:     this.tableFieldStat = new TableFieldStat(sortParameters);
1:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:     this.comparator = new IntermediateSortTempRowComparator(
1:         tableFieldStat.getIsSortColNoDictFlags());
/////////////////////////////////////////////////////////////////////////
1:       try {
0:         this.returnRow = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
1:         this.numberOfObjectRead++;
1:       } catch (IOException e) {
1:         throw new CarbonSortKeyAndGroupByException("Problem while reading rows", e);
1:       }
/////////////////////////////////////////////////////////////////////////
1:    * Read a batch of row from stream
1:    *
1:    * @throws IOException if error occurs while reading from stream
1:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected) throws IOException {
1:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
1:     for (int i = 0; i < expected; i++) {
0:       IntermediateSortTempRow holder
0:           = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:       holders[i] = holder;
1:     this.numberOfObjectRead += expected;
1:     return holders;
1:    * below method will be used to get the sort temp row
1:   public IntermediateSortTempRow getRow() {
/////////////////////////////////////////////////////////////////////////
1:     return comparator.compare(returnRow, other.getRow());
/////////////////////////////////////////////////////////////////////////
1:     hash += tableFieldStat.hashCode();
/////////////////////////////////////////////////////////////////////////
1:    * @param numberOfRecords number of records to be read
1:    * @return batch of intermediate sort temp row
1:    * @throws IOException if error occurs while reading reading records
1:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
1:       throws IOException {
1:     return readBatchedRowFromStream(numberOfRecords);
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
0: import org.apache.carbondata.core.util.ByteUtil.UnsafeComparer;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.core.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:   private Object[] returnRow;
0:   private int dimCnt;
0:   private int noDictDimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private boolean[] isNoDictionarySortColumn;
0:   private DataType[] measureDataTypes;
0:   private Object[][] currentBuffer;
0:   private Object[][] backupBuffer;
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = sortParameters.getDimColCount();
0:     this.noDictDimCnt = sortParameters.getNoDictionaryCount();
0:     this.complexCnt = sortParameters.getComplexDimColCount();
0:     this.measureCnt = sortParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = sortParameters.getNoDictionaryDimnesionColumn();
0:     this.isNoDictionarySortColumn = sortParameters.getNoDictionarySortColumn();
0:     this.measureDataTypes = sortParameters.getMeasureDataType();
1: 
/////////////////////////////////////////////////////////////////////////
0:       this.returnRow = getRowFromStream();
/////////////////////////////////////////////////////////////////////////
0:    * Reads row from file
0:    * @throws CarbonSortKeyAndGroupByException
0:   private Object[] getRowFromStream() throws CarbonSortKeyAndGroupByException {
0:     // create new row of size 3 (1 for dims , 1 for high card , 1 for measures)
1: 
0:     Object[] holder = new Object[3];
0:     int index = 0;
0:     int nonDicIndex = 0;
0:     int[] dim = new int[dimCnt - noDictDimCnt];
0:     byte[][] nonDicArray = new byte[noDictDimCnt + complexCnt][];
0:     Object[] measures = new Object[measureCnt];
1:     try {
0:       // read dimension values
0:       for (int i = 0; i < isNoDictionaryDimensionColumn.length; i++) {
0:         if (isNoDictionaryDimensionColumn[i]) {
0:           short len = stream.readShort();
0:           byte[] array = new byte[len];
0:           stream.readFully(array);
0:           nonDicArray[nonDicIndex++] = array;
1:         } else {
0:           dim[index++] = stream.readInt();
1:         }
1:       }
1: 
0:       for (int i = 0; i < complexCnt; i++) {
0:         short len = stream.readShort();
0:         byte[] array = new byte[len];
0:         stream.readFully(array);
0:         nonDicArray[nonDicIndex++] = array;
1:       }
1: 
0:       index = 0;
0:       // read measure values
0:       for (int i = 0; i < measureCnt; i++) {
0:         if (stream.readByte() == 1) {
0:           DataType dataType = measureDataTypes[i];
0:           if (dataType == DataTypes.BOOLEAN) {
0:             measures[index++] = stream.readBoolean();
0:           } else if (dataType == DataTypes.SHORT) {
0:             measures[index++] = stream.readShort();
0:           } else if (dataType == DataTypes.INT) {
0:             measures[index++] = stream.readInt();
0:           } else if (dataType == DataTypes.LONG) {
0:             measures[index++] = stream.readLong();
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             measures[index++] = stream.readDouble();
0:           } else if (DataTypes.isDecimal(dataType)) {
0:             int len = stream.readInt();
0:             byte[] buff = new byte[len];
0:             stream.readFully(buff);
0:             measures[index++] = DataTypeUtil.byteToBigDecimal(buff);
1:           } else {
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
1:           }
1:         } else {
0:           measures[index++] = null;
1:         }
1:       }
1: 
0:       NonDictionaryUtil.prepareOutObj(holder, dim, nonDicArray, measures);
1: 
0:       // increment number if record read
0:       this.numberOfObjectRead++;
1:     } catch (IOException e) {
0:       LOGGER.error("Problme while reading the madkey fom sort temp file");
0:       throw new CarbonSortKeyAndGroupByException("Problem while reading the sort temp file ", e);
1: 
0:     //return out row
0:     return holder;
0:    * below method will be used to get the row
0:   public Object[] getRow() {
/////////////////////////////////////////////////////////////////////////
0:     int diff = 0;
0:     int index = 0;
0:     int noDictionaryIndex = 0;
0:     int[] leftMdkArray = (int[]) returnRow[0];
0:     int[] rightMdkArray = (int[]) other.returnRow[0];
0:     byte[][] leftNonDictArray = (byte[][]) returnRow[1];
0:     byte[][] rightNonDictArray = (byte[][]) other.returnRow[1];
0:     for (boolean isNoDictionary : isNoDictionarySortColumn) {
0:       if (isNoDictionary) {
0:         diff = UnsafeComparer.INSTANCE
0:             .compareTo(leftNonDictArray[noDictionaryIndex], rightNonDictArray[noDictionaryIndex]);
0:         if (diff != 0) {
0:           return diff;
1:         }
0:         noDictionaryIndex++;
0:       } else {
0:         diff = leftMdkArray[index] - rightMdkArray[index];
0:         if (diff != 0) {
0:           return diff;
1:         }
0:         index++;
1:       }
1: 
1:     }
0:     return diff;
/////////////////////////////////////////////////////////////////////////
0:     hash += 31 * measureCnt;
0:     hash += 31 * dimCnt;
0:     hash += 31 * complexCnt;
/////////////////////////////////////////////////////////////////////////
0:    * @param numberOfRecords
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
0:   private Object[][] prefetchRecordsFromFile(int numberOfRecords)
0:       throws CarbonSortKeyAndGroupByException {
0:     Object[][] records = new Object[numberOfRecords][];
0:     for (int i = 0; i < numberOfRecords; i++) {
0:       records[i] = getRowFromStream();
1:     }
0:     return records;
commit:21704cf
/////////////////////////////////////////////////////////////////////////
0: import java.util.Comparator;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:   private IntermediateSortTempRow returnRow;
0:   private IntermediateSortTempRow[] currentBuffer;
0:   private IntermediateSortTempRow[] backupBuffer;
/////////////////////////////////////////////////////////////////////////
0:   private TableFieldStat tableFieldStat;
0:   private SortStepRowHandler sortStepRowHandler;
0:   private Comparator<IntermediateSortTempRow> comparator;
/////////////////////////////////////////////////////////////////////////
0:     this.tableFieldStat = new TableFieldStat(sortParameters);
0:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
0:     this.comparator = new IntermediateSortTempRowComparator(
0:         tableFieldStat.getIsSortColNoDictFlags());
/////////////////////////////////////////////////////////////////////////
1:       try {
0:         this.returnRow = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:         this.numberOfObjectRead++;
0:       } catch (IOException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problem while reading rows", e);
1:       }
/////////////////////////////////////////////////////////////////////////
0:    * Read a batch of row from stream
1:    *
0:    * @throws IOException if error occurs while reading from stream
0:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected) throws IOException {
0:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
0:     for (int i = 0; i < expected; i++) {
0:       IntermediateSortTempRow holder
0:           = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:       holders[i] = holder;
0:     this.numberOfObjectRead += expected;
0:     return holders;
0:    * below method will be used to get the sort temp row
0:   public IntermediateSortTempRow getRow() {
/////////////////////////////////////////////////////////////////////////
0:     return comparator.compare(returnRow, other.getRow());
/////////////////////////////////////////////////////////////////////////
0:     hash += tableFieldStat.hashCode();
/////////////////////////////////////////////////////////////////////////
0:    * @param numberOfRecords number of records to be read
0:    * @return batch of intermediate sort temp row
0:    * @throws IOException if error occurs while reading reading records
0:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
0:       throws IOException {
0:     return readBatchedRowFromStream(numberOfRecords);
commit:c100251
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
0:   private int dimCnt;
0:   private int noDictDimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private boolean[] isNoDictionarySortColumn;
0:   private DataType[] measureDataTypes;
1:   private int readBufferSize;
1:   private String compressorName;
/////////////////////////////////////////////////////////////////////////
1:    * @param sortParameters
1:    * @param tableName
0:   public SortTempFileChunkHolder(File tempFile, SortParameters sortParameters, String tableName) {
0:     this.dimCnt = sortParameters.getDimColCount();
0:     this.noDictDimCnt = sortParameters.getNoDictionaryCount();
0:     this.complexCnt = sortParameters.getComplexDimColCount();
0:     this.measureCnt = sortParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = sortParameters.getNoDictionaryDimnesionColumn();
0:     this.isNoDictionarySortColumn = sortParameters.getNoDictionarySortColumn();
0:     this.measureDataTypes = sortParameters.getMeasureDataType();
1:     this.readBufferSize = sortParameters.getBufferSize();
1:     this.compressorName = sortParameters.getSortTempCompressorName();
/////////////////////////////////////////////////////////////////////////
1:       stream = FileFactory.getDataInputStream(tempFile.getPath(), FileFactory.FileType.LOCAL,
1:           readBufferSize, compressorName);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     int[] dim = new int[dimCnt - noDictDimCnt];
0:     byte[][] nonDicArray = new byte[noDictDimCnt + complexCnt][];
0:     Object[] measures = new Object[measureCnt];
/////////////////////////////////////////////////////////////////////////
0:       for (int i = 0; i < complexCnt; i++) {
/////////////////////////////////////////////////////////////////////////
0:       for (int i = 0; i < measureCnt; i++) {
/////////////////////////////////////////////////////////////////////////
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
/////////////////////////////////////////////////////////////////////////
1:     if (prefetch) {
/////////////////////////////////////////////////////////////////////////
0:     hash += 31 * measureCnt;
0:     hash += 31 * dimCnt;
0:     hash += 31 * complexCnt;
author:Jacky Li
-------------------------------------------------------------------------------
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:           } else if (DataTypes.isDecimal(dataType)) {
commit:4d70a21
/////////////////////////////////////////////////////////////////////////
0:   private DataType[] measureDataTypes;
/////////////////////////////////////////////////////////////////////////
0:    * @param measureDataTypes
0:       int measureCount, int fileBufferSize, int noDictionaryCount, DataType[] measureDataTypes,
/////////////////////////////////////////////////////////////////////////
0:     this.measureDataTypes = measureDataTypes;
/////////////////////////////////////////////////////////////////////////
0:           DataType dataType = measureDataTypes[i];
/////////////////////////////////////////////////////////////////////////
0:             throw new IllegalArgumentException("unsupported data type:" + measureDataTypes[i]);
commit:956833e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:           DataType dataType = aggType[i];
0:           if (dataType == DataTypes.SHORT) {
0:             measures[index++] = stream.readShort();
0:           } else if (dataType == DataTypes.INT) {
0:             measures[index++] = stream.readInt();
0:           } else if (dataType == DataTypes.LONG) {
0:             measures[index++] = stream.readLong();
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             measures[index++] = stream.readDouble();
0:           } else if (dataType == DataTypes.DECIMAL) {
0:             int len = stream.readInt();
0:             byte[] buff = new byte[len];
0:             stream.readFully(buff);
0:             measures[index++] = DataTypeUtil.byteToBigDecimal(buff);
0:           } else {
0:             throw new IllegalArgumentException("unsupported data type:" + aggType[i]);
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.sort.sortdata;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
author:xubo245
-------------------------------------------------------------------------------
commit:6abdd97
/////////////////////////////////////////////////////////////////////////
0:           if (dataType == DataTypes.BOOLEAN) {
0:             measures[index++] = stream.readBoolean();
0:           } else if (dataType == DataTypes.SHORT) {
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.CarbonThreadFactory;
/////////////////////////////////////////////////////////////////////////
0:       boolean[] isNoDictionaryDimensionColumn, boolean[] isNoDictionarySortColumn,
0:       String tableName) {
/////////////////////////////////////////////////////////////////////////
1:     this.executorService = Executors
1:         .newFixedThreadPool(1, new CarbonThreadFactory("SafeSortTempChunkHolderPool:" + tableName));
/////////////////////////////////////////////////////////////////////////
1:     if (null != executorService) {
1:       executorService.shutdownNow();
1:     }
author:Raghunandan S
-------------------------------------------------------------------------------
commit:06b0d08
/////////////////////////////////////////////////////////////////////////
0:             default:
0:               throw new IllegalArgumentException("unsupported data type:" + aggType[i]);
/////////////////////////////////////////////////////////////////////////
1:     if (this == obj) {
1:       return true;
1:     }
1: 
1:     return this == o;
commit:7422690
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeUtil;
author:jackylk
-------------------------------------------------------------------------------
commit:bc3e684
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.NonDictionaryUtil;
commit:98df130
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
/////////////////////////////////////////////////////////////////////////
0:   private DataType[] aggType;
/////////////////////////////////////////////////////////////////////////
0:       int measureCount, int fileBufferSize, int noDictionaryCount, DataType[] aggType,
/////////////////////////////////////////////////////////////////////////
0:           switch (aggType[i]) {
0:             case SHORT:
0:             case INT:
0:             case LONG:
0:               measures[index++] = stream.readLong();
0:               break;
0:             case DOUBLE:
0:               measures[index++] = stream.readDouble();
0:               break;
0:             case DECIMAL:
0:               int len = stream.readInt();
0:               byte[] buff = new byte[len];
0:               stream.readFully(buff);
0:               measures[index++] = buff;
0:               break;
commit:8cca0af
/////////////////////////////////////////////////////////////////////////
0:           if (aggType[i] == CarbonCommonConstants.DOUBLE_MEASURE) {
author:QiangCai
-------------------------------------------------------------------------------
commit:0158968
/////////////////////////////////////////////////////////////////////////
0:     int[] dim = new int[this.dimensionCount - this.noDictionaryCount];
commit:81149f6
/////////////////////////////////////////////////////////////////////////
0:       this.returnRow = getRowFromStream();
commit:9f94529
/////////////////////////////////////////////////////////////////////////
0:    * to store whether sort column is of dictionary type or not
1:    */
0:   private boolean[] isNoDictionarySortColumn;
1: 
1:   /**
/////////////////////////////////////////////////////////////////////////
0:       boolean[] isNoDictionaryDimensionColumn, boolean[] isNoDictionarySortColumn) {
/////////////////////////////////////////////////////////////////////////
1: 
0:     this.isNoDictionarySortColumn = isNoDictionarySortColumn;
/////////////////////////////////////////////////////////////////////////
0:     for (boolean isNoDictionary : isNoDictionarySortColumn) {
commit:c5aba5f
/////////////////////////////////////////////////////////////////////////
1:     bufferSize = Integer.parseInt(CarbonProperties.getInstance()
1:         .getProperty(CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE,
1:             CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE_DEFAULT));
/////////////////////////////////////////////////////////////////////////
1:     this.backupBuffer = null;
1:     this.currentBuffer = null;
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:ravipesala
-------------------------------------------------------------------------------
commit:9e064ee
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
0:               measures[index++] = DataTypeUtil.byteToBigDecimal(buff);
commit:8b3fa7f
/////////////////////////////////////////////////////////////////////////
0:               measures[index++] = stream.readShort();
0:               break;
0:               measures[index++] = stream.readInt();
0:               break;
commit:e6b6090
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       boolean[] isNoDictionaryDimensionColumn) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   private Object[] getRowFromStream() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:       NonDictionaryUtil.prepareOutObj(holder, dim, finalByteArr, measures);
/////////////////////////////////////////////////////////////////////////
0:       NonDictionaryUtil.prepareOutObj(holder, dim, nonDicArray, measures);
/////////////////////////////////////////////////////////////////////////
0:         NonDictionaryUtil
/////////////////////////////////////////////////////////////////////////
0:         NonDictionaryUtil
/////////////////////////////////////////////////////////////////////////
0:         int dimFieldA = NonDictionaryUtil.getDimension(normalIndex, returnRow);
0:         int dimFieldB = NonDictionaryUtil.getDimension(normalIndex, other.returnRow);
commit:496cde4
/////////////////////////////////////////////////////////////////////////
0:   // TODO temporary configuration, remove after kettle removal
0:   private boolean useKettle;
1: 
/////////////////////////////////////////////////////////////////////////
0:       boolean[] isNoDictionaryDimensionColumn, boolean useKettle) {
/////////////////////////////////////////////////////////////////////////
0:     this.useKettle = useKettle;
/////////////////////////////////////////////////////////////////////////
0:     if (useKettle) {
0:       return getRowFromStreamWithKettle();
0:     } else {
0:       return getRowFromStreamWithOutKettle();
1:     }
1:   }
0:   // TODO remove after kettle flow is removed
0:   private Object[] getRowFromStreamWithKettle() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:    * Reads row from file
1:    * @return Object[]
0:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] getRowFromStreamWithOutKettle() throws CarbonSortKeyAndGroupByException {
0:     // create new row of size 3 (1 for dims , 1 for high card , 1 for measures)
1: 
0:     Object[] holder = new Object[3];
0:     int index = 0;
0:     int nonDicIndex = 0;
0:     int[] dim = new int[this.dimensionCount];
0:     byte[][] nonDicArray = new byte[this.noDictionaryCount + this.complexDimensionCount][];
0:     Object[] measures = new Object[this.measureCount];
1:     try {
0:       // read dimension values
0:       for (int i = 0; i < isNoDictionaryDimensionColumn.length; i++) {
0:         if (isNoDictionaryDimensionColumn[i]) {
0:           short len = stream.readShort();
0:           byte[] array = new byte[len];
0:           stream.readFully(array);
0:           nonDicArray[nonDicIndex++] = array;
0:         } else {
0:           dim[index++] = stream.readInt();
1:         }
1:       }
1: 
0:       for (int i = 0; i < complexDimensionCount; i++) {
0:         short len = stream.readShort();
0:         byte[] array = new byte[len];
0:         stream.readFully(array);
0:         nonDicArray[nonDicIndex++] = array;
1:       }
1: 
0:       index = 0;
0:       // read measure values
0:       for (int i = 0; i < this.measureCount; i++) {
0:         if (stream.readByte() == 1) {
0:           if (aggType[i] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:             measures[index++] = stream.readDouble();
0:           } else if (aggType[i] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:             measures[index++] = stream.readLong();
0:           } else {
0:             int len = stream.readInt();
0:             byte[] buff = new byte[len];
0:             stream.readFully(buff);
0:             measures[index++] = buff;
1:           }
0:         } else {
0:           measures[index++] = null;
1:         }
1:       }
1: 
0:       RemoveDictionaryUtil.prepareOutObj(holder, dim, nonDicArray, measures);
1: 
0:       // increment number if record read
0:       this.numberOfObjectRead++;
0:     } catch (IOException e) {
0:       LOGGER.error("Problme while reading the madkey fom sort temp file");
0:       throw new CarbonSortKeyAndGroupByException("Problem while reading the sort temp file ", e);
1:     }
1: 
0:     //return out row
0:     return holder;
1:   }
1: 
1:   /**
/////////////////////////////////////////////////////////////////////////
0:     if (useKettle) {
0:       return compareWithKettle(other);
0:     } else {
0:       return compareWithOutKettle(other);
1:     }
0:   // TODO Remove after kettle flow is removed.
0:   private int compareWithKettle(SortTempFileChunkHolder other) {
/////////////////////////////////////////////////////////////////////////
0:   private int compareWithOutKettle(SortTempFileChunkHolder other) {
0:     int diff = 0;
0:     int index = 0;
0:     int noDictionaryIndex = 0;
0:     int[] leftMdkArray = (int[]) returnRow[0];
0:     int[] rightMdkArray = (int[]) other.returnRow[0];
0:     byte[][] leftNonDictArray = (byte[][]) returnRow[1];
0:     byte[][] rightNonDictArray = (byte[][]) other.returnRow[1];
0:     for (boolean isNoDictionary : isNoDictionaryDimensionColumn) {
0:       if (isNoDictionary) {
0:         diff = UnsafeComparer.INSTANCE
0:             .compareTo(leftNonDictArray[noDictionaryIndex], rightNonDictArray[noDictionaryIndex]);
0:         if (diff != 0) {
0:           return diff;
1:         }
0:         noDictionaryIndex++;
0:       } else {
0:         diff = leftMdkArray[index] - rightMdkArray[index];
0:         if (diff != 0) {
0:           return diff;
1:         }
0:         index++;
1:       }
1: 
1:     }
0:     return diff;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
0:     return o.compareTo(o) == 0;
commit:cd6a4ff
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.sortandgroupby.sortdata;
1: 
0: import java.io.BufferedInputStream;
1: import java.io.DataInputStream;
1: import java.io.File;
0: import java.io.FileInputStream;
1: import java.io.FileNotFoundException;
1: import java.io.IOException;
0: import java.nio.ByteBuffer;
1: import java.util.concurrent.Callable;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.Future;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.constants.IgnoreDictionary;
0: import org.apache.carbondata.core.util.ByteUtil.UnsafeComparer;
1: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.processing.sortandgroupby.exception.CarbonSortKeyAndGroupByException;
0: import org.apache.carbondata.processing.util.RemoveDictionaryUtil;
1: 
1: public class SortTempFileChunkHolder implements Comparable<SortTempFileChunkHolder> {
1: 
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(SortTempFileChunkHolder.class.getName());
1: 
1:   /**
1:    * temp file
1:    */
1:   private File tempFile;
1: 
1:   /**
1:    * read stream
1:    */
1:   private DataInputStream stream;
1: 
1:   /**
1:    * entry count
1:    */
1:   private int entryCount;
1: 
1:   /**
1:    * number record read
1:    */
1:   private int numberOfObjectRead;
1: 
1:   /**
1:    * return row
1:    */
0:   private Object[] returnRow;
1: 
1:   /**
0:    * number of measures
1:    */
0:   private int measureCount;
1: 
1:   /**
0:    * number of dimensionCount
1:    */
0:   private int dimensionCount;
1: 
1:   /**
0:    * number of complexDimensionCount
1:    */
0:   private int complexDimensionCount;
1: 
1:   /**
0:    * fileBufferSize for file reader stream size
1:    */
0:   private int fileBufferSize;
1: 
0:   private Object[][] currentBuffer;
1: 
0:   private Object[][] backupBuffer;
1: 
1:   private boolean isBackupFilled;
1: 
1:   private boolean prefetch;
1: 
1:   private int bufferSize;
1: 
1:   private int bufferRowCounter;
1: 
1:   private ExecutorService executorService;
1: 
1:   private Future<Void> submit;
1: 
1:   private int prefetchRecordsProceesed;
1: 
1:   /**
0:    * sortTempFileNoOFRecordsInCompression
1:    */
0:   private int sortTempFileNoOFRecordsInCompression;
1: 
1:   /**
0:    * isSortTempFileCompressionEnabled
1:    */
0:   private boolean isSortTempFileCompressionEnabled;
1: 
1:   /**
1:    * totalRecordFetch
1:    */
1:   private int totalRecordFetch;
1: 
0:   private int noDictionaryCount;
1: 
0:   private char[] aggType;
1: 
1:   /**
0:    * to store whether dimension is of dictionary type or not
1:    */
0:   private boolean[] isNoDictionaryDimensionColumn;
1: 
1:   /**
1:    * Constructor to initialize
1:    *
1:    * @param tempFile
0:    * @param dimensionCount
0:    * @param complexDimensionCount
0:    * @param measureCount
0:    * @param fileBufferSize
0:    * @param noDictionaryCount
0:    * @param aggType
0:    * @param isNoDictionaryDimensionColumn
1:    */
0:   public SortTempFileChunkHolder(File tempFile, int dimensionCount, int complexDimensionCount,
0:       int measureCount, int fileBufferSize, int noDictionaryCount, char[] aggType,
0:       boolean[] isNoDictionaryDimensionColumn) {
1:     // set temp file
1:     this.tempFile = tempFile;
1: 
0:     // set measure and dimension count
0:     this.measureCount = measureCount;
0:     this.dimensionCount = dimensionCount;
0:     this.complexDimensionCount = complexDimensionCount;
1: 
0:     this.noDictionaryCount = noDictionaryCount;
0:     // set mdkey length
0:     this.fileBufferSize = fileBufferSize;
0:     this.executorService = Executors.newFixedThreadPool(1);
0:     this.aggType = aggType;
0:     this.isNoDictionaryDimensionColumn = isNoDictionaryDimensionColumn;
1:   }
1: 
1:   /**
1:    * This method will be used to initialize
1:    *
1:    * @throws CarbonSortKeyAndGroupByException problem while initializing
1:    */
1:   public void initialize() throws CarbonSortKeyAndGroupByException {
1:     prefetch = Boolean.parseBoolean(CarbonProperties.getInstance()
1:         .getProperty(CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH,
1:             CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH_DEFAULT));
0:     bufferSize = CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE;
0:     this.isSortTempFileCompressionEnabled = Boolean.parseBoolean(CarbonProperties.getInstance()
0:         .getProperty(CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED,
0:             CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED_DEFAULTVALUE));
0:     if (this.isSortTempFileCompressionEnabled) {
0:       LOGGER.info("Compression was used while writing the sortTempFile");
1:     }
1: 
0:     try {
0:       this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(CarbonProperties.getInstance()
0:           .getProperty(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION,
0:               CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE));
0:       if (this.sortTempFileNoOFRecordsInCompression < 1) {
0:         LOGGER.error("Invalid value for: "
0:             + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:             + ": Only Positive Integer value(greater than zero) is allowed.Default value will"
0:             + " be used");
1: 
0:         this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(
0:             CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:       }
0:     } catch (NumberFormatException e) {
0:       LOGGER.error(
0:           "Invalid value for: " + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:               + ", only Positive Integer value is allowed.Default value will be used");
0:       this.sortTempFileNoOFRecordsInCompression = Integer
0:           .parseInt(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:     }
1: 
1:     initialise();
1:   }
1: 
1:   private void initialise() throws CarbonSortKeyAndGroupByException {
0:     try {
0:       if (isSortTempFileCompressionEnabled) {
0:         this.bufferSize = sortTempFileNoOFRecordsInCompression;
1:       }
0:       stream = new DataInputStream(
0:           new BufferedInputStream(new FileInputStream(tempFile), this.fileBufferSize));
1:       this.entryCount = stream.readInt();
1:       if (prefetch) {
1:         new DataFetcher(false).call();
1:         totalRecordFetch += currentBuffer.length;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
0:       } else {
0:         if (isSortTempFileCompressionEnabled) {
1:           new DataFetcher(false).call();
1:         }
1:       }
1: 
1:     } catch (FileNotFoundException e) {
1:       LOGGER.error(e);
1:       throw new CarbonSortKeyAndGroupByException(tempFile + " No Found", e);
0:     } catch (IOException e) {
1:       LOGGER.error(e);
1:       throw new CarbonSortKeyAndGroupByException(tempFile + " No Found", e);
1:     } catch (Exception e) {
1:       LOGGER.error(e);
1:       throw new CarbonSortKeyAndGroupByException(tempFile + " Problem while reading", e);
1:     }
1:   }
1: 
1:   /**
1:    * This method will be used to read new row from file
1:    *
1:    * @throws CarbonSortKeyAndGroupByException problem while reading
1:    */
1:   public void readRow() throws CarbonSortKeyAndGroupByException {
1:     if (prefetch) {
1:       fillDataForPrefetch();
0:     } else if (isSortTempFileCompressionEnabled) {
1:       if (bufferRowCounter >= bufferSize) {
0:         try {
1:           new DataFetcher(false).call();
1:           bufferRowCounter = 0;
1:         } catch (Exception e) {
1:           LOGGER.error(e);
1:           throw new CarbonSortKeyAndGroupByException(tempFile + " Problem while reading", e);
1:         }
1: 
1:       }
1:       prefetchRecordsProceesed++;
1:       returnRow = currentBuffer[bufferRowCounter++];
0:     } else {
0:       Object[] outRow = getRowFromStream();
0:       this.returnRow = outRow;
1:     }
1:   }
1: 
1:   private void fillDataForPrefetch() {
1:     if (bufferRowCounter >= bufferSize) {
1:       if (isBackupFilled) {
1:         bufferRowCounter = 0;
1:         currentBuffer = backupBuffer;
1:         totalRecordFetch += currentBuffer.length;
1:         isBackupFilled = false;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
0:       } else {
0:         try {
1:           submit.get();
1:         } catch (Exception e) {
1:           LOGGER.error(e);
1:         }
1:         bufferRowCounter = 0;
1:         currentBuffer = backupBuffer;
1:         isBackupFilled = false;
1:         totalRecordFetch += currentBuffer.length;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
1:       }
1:     }
1:     prefetchRecordsProceesed++;
1:     returnRow = currentBuffer[bufferRowCounter++];
1:   }
1: 
1:   /**
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] getRowFromStream() throws CarbonSortKeyAndGroupByException {
0:     // create new row of size 3 (1 for dims , 1 for high card , 1 for measures)
1: 
0:     Object[] holder = new Object[3];
0:     int index = 0;
0:     Integer[] dim = new Integer[this.dimensionCount];
0:     Object[] measures = new Object[this.measureCount];
0:     byte[] finalByteArr = null;
0:     try {
1: 
0:       // read dimension values
1: 
0:       for (int i = 0; i < this.dimensionCount; i++) {
0:         dim[index++] = stream.readInt();
1:       }
1: 
0:       if ((this.noDictionaryCount + this.complexDimensionCount) > 0) {
0:         short lengthOfByteArray = stream.readShort();
0:         ByteBuffer buff = ByteBuffer.allocate(lengthOfByteArray + 2);
0:         buff.putShort(lengthOfByteArray);
0:         byte[] byteArr = new byte[lengthOfByteArray];
0:         stream.readFully(byteArr);
1: 
0:         buff.put(byteArr);
0:         finalByteArr = buff.array();
1: 
1:       }
1: 
0:       index = 0;
0:       // read measure values
0:       for (int i = 0; i < this.measureCount; i++) {
0:         if (stream.readByte() == 1) {
0:           if (aggType[i] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:             measures[index++] = stream.readDouble();
0:           } else if (aggType[i] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:             measures[index++] = stream.readLong();
0:           } else {
0:             int len = stream.readInt();
0:             byte[] buff = new byte[len];
0:             stream.readFully(buff);
0:             measures[index++] = buff;
1:           }
0:         } else {
0:           measures[index++] = null;
1:         }
1:       }
1: 
0:       RemoveDictionaryUtil.prepareOutObj(holder, dim, finalByteArr, measures);
1: 
0:       // increment number if record read
0:       this.numberOfObjectRead++;
0:     } catch (IOException e) {
0:       LOGGER.error("Problme while reading the madkey fom sort temp file");
0:       throw new CarbonSortKeyAndGroupByException("Problem while reading the sort temp file ", e);
1:     }
1: 
0:     //return out row
0:     return holder;
1:   }
1: 
1:   /**
0:    * below method will be used to get the row
1:    *
1:    * @return row
1:    */
0:   public Object[] getRow() {
1:     return this.returnRow;
1:   }
1: 
1:   /**
1:    * below method will be used to check whether any more records are present
1:    * in file or not
1:    *
1:    * @return more row present in file
1:    */
1:   public boolean hasNext() {
0:     if (prefetch || isSortTempFileCompressionEnabled) {
1:       return this.prefetchRecordsProceesed < this.entryCount;
1:     }
1:     return this.numberOfObjectRead < this.entryCount;
1:   }
1: 
1:   /**
1:    * Below method will be used to close streams
1:    */
1:   public void closeStream() {
1:     CarbonUtil.closeStreams(stream);
0:     executorService.shutdown();
1:   }
1: 
1:   /**
1:    * This method will number of entries
1:    *
1:    * @return entryCount
1:    */
1:   public int getEntryCount() {
1:     return entryCount;
1:   }
1: 
1:   @Override public int compareTo(SortTempFileChunkHolder other) {
1: 
0:     return compare(other);
1:   }
1: 
0:   private int compare(SortTempFileChunkHolder other) {
0:     int diff = 0;
1: 
0:     int normalIndex = 0;
0:     int noDictionaryindex = 0;
1: 
0:     for (boolean isNoDictionary : isNoDictionaryDimensionColumn) {
1: 
0:       if (isNoDictionary) {
0:         byte[] byteArr1 = (byte[]) returnRow[IgnoreDictionary.BYTE_ARRAY_INDEX_IN_ROW.getIndex()];
1: 
0:         ByteBuffer buff1 = ByteBuffer.wrap(byteArr1);
1: 
0:         // extract a high card dims from complete byte[].
0:         RemoveDictionaryUtil
0:             .extractSingleHighCardDims(byteArr1, noDictionaryindex, noDictionaryCount, buff1);
1: 
0:         byte[] byteArr2 =
0:             (byte[]) other.returnRow[IgnoreDictionary.BYTE_ARRAY_INDEX_IN_ROW.getIndex()];
1: 
0:         ByteBuffer buff2 = ByteBuffer.wrap(byteArr2);
1: 
0:         // extract a high card dims from complete byte[].
0:         RemoveDictionaryUtil
0:             .extractSingleHighCardDims(byteArr2, noDictionaryindex, noDictionaryCount, buff2);
1: 
0:         int difference = UnsafeComparer.INSTANCE.compareTo(buff1, buff2);
0:         if (difference != 0) {
0:           return difference;
1:         }
0:         noDictionaryindex++;
0:       } else {
0:         int dimFieldA = RemoveDictionaryUtil.getDimension(normalIndex, returnRow);
0:         int dimFieldB = RemoveDictionaryUtil.getDimension(normalIndex, other.returnRow);
0:         diff = dimFieldA - dimFieldB;
0:         if (diff != 0) {
0:           return diff;
1:         }
0:         normalIndex++;
1:       }
1:     }
0:     return diff;
1:   }
1: 
1:   @Override public boolean equals(Object obj) {
1:     if (!(obj instanceof SortTempFileChunkHolder)) {
1:       return false;
1:     }
1:     SortTempFileChunkHolder o = (SortTempFileChunkHolder) obj;
1: 
1: 
1: 
0:     return o.compare(o) == 0;
1:   }
1: 
1:   @Override public int hashCode() {
1:     int hash = 0;
0:     hash += 31 * measureCount;
0:     hash += 31 * dimensionCount;
0:     hash += 31 * complexDimensionCount;
0:     hash += 31 * noDictionaryCount;
1:     hash += tempFile.hashCode();
1:     return hash;
1:   }
1: 
1:   private final class DataFetcher implements Callable<Void> {
1:     private boolean isBackUpFilling;
1: 
1:     private int numberOfRecords;
1: 
1:     private DataFetcher(boolean backUp) {
1:       isBackUpFilling = backUp;
1:       calculateNumberOfRecordsToBeFetched();
1:     }
1: 
1:     private void calculateNumberOfRecordsToBeFetched() {
1:       int numberOfRecordsLeftToBeRead = entryCount - totalRecordFetch;
1:       numberOfRecords =
1:           bufferSize < numberOfRecordsLeftToBeRead ? bufferSize : numberOfRecordsLeftToBeRead;
1:     }
1: 
1:     @Override public Void call() throws Exception {
0:       try {
1:         if (isBackUpFilling) {
1:           backupBuffer = prefetchRecordsFromFile(numberOfRecords);
1:           isBackupFilled = true;
0:         } else {
1:           currentBuffer = prefetchRecordsFromFile(numberOfRecords);
1:         }
1:       } catch (Exception e) {
1:         LOGGER.error(e);
1:       }
1:       return null;
1:     }
1: 
1:   }
1: 
1:   /**
1:    * This method will read the records from sort temp file and keep it in a buffer
1:    *
0:    * @param numberOfRecords
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[][] prefetchRecordsFromFile(int numberOfRecords)
0:       throws CarbonSortKeyAndGroupByException {
0:     Object[][] records = new Object[numberOfRecords][];
0:     for (int i = 0; i < numberOfRecords; i++) {
0:       records[i] = getRowFromStream();
1:     }
0:     return records;
1:   }
1: }
============================================================================
1:2cf1104: /*
1:2cf1104:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:2cf1104:  * contributor license agreements.  See the NOTICE file distributed with
1:2cf1104:  * this work for additional information regarding copyright ownership.
1:2cf1104:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:2cf1104:  * (the "License"); you may not use this file except in compliance with
1:2cf1104:  * the License.  You may obtain a copy of the License at
2:2cf1104:  *
1:2cf1104:  *    http://www.apache.org/licenses/LICENSE-2.0
1:2cf1104:  *
1:2cf1104:  * Unless required by applicable law or agreed to in writing, software
1:2cf1104:  * distributed under the License is distributed on an "AS IS" BASIS,
1:2cf1104:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:2cf1104:  * See the License for the specific language governing permissions and
1:2cf1104:  * limitations under the License.
2:2cf1104:  */
1:2cf1104: package org.apache.carbondata.core.util;
3:2cf1104: 
1:2cf1104: import java.io.IOException;
1:2cf1104: import java.util.ArrayList;
1:2cf1104: import java.util.List;
1:2cf1104: 
1:2cf1104: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:8f1a029: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:2cf1104: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1:2cf1104: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
1:2cf1104: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1:2cf1104: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
1:2cf1104: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
1:b41e48f: import org.apache.carbondata.core.reader.CarbonFooterReaderV3;
1:b41e48f: import org.apache.carbondata.core.reader.CarbonHeaderReader;
1:b41e48f: import org.apache.carbondata.format.FileFooter3;
1:b41e48f: import org.apache.carbondata.format.FileHeader;
1:2cf1104: 
1:8f1a029: import org.apache.hadoop.conf.Configuration;
1:8f1a029: 
1:2cf1104: public class DataFileFooterConverterV3 extends AbstractDataFileFooterConverter {
1:2cf1104: 
1:8f1a029:   public DataFileFooterConverterV3(Configuration configuration) {
1:8f1a029:     super(configuration);
1:8f1a029:   }
1:8f1a029: 
1:8f1a029:   public DataFileFooterConverterV3() {
1:8f1a029:     super(FileFactory.getConfiguration());
1:8f1a029:   }
1:8f1a029: 
2:2cf1104:   /**
1:2cf1104:    * Below method will be used to convert thrift file meta to wrapper file meta
1:2cf1104:    * This method will read the footer from footer offset present in the data file
1:b41e48f:    * 1. It will read the header from carbon data file, header starts from 0 offset
1:b41e48f:    * 2. It will set the stream offset
1:b41e48f:    * 3. It will read the footer data from file
1:b41e48f:    * 4. parse the footer to thrift object
1:b41e48f:    * 5. convert to wrapper object
1:2cf1104:    *
1:2cf1104:    * @param tableBlockInfo
1:2cf1104:    *        table block info
1:2cf1104:    * @return data file footer
1:2cf1104:    */
1:2cf1104:   @Override public DataFileFooter readDataFileFooter(TableBlockInfo tableBlockInfo)
1:2cf1104:       throws IOException {
1:2cf1104:     DataFileFooter dataFileFooter = new DataFileFooter();
1:b41e48f:     CarbonHeaderReader carbonHeaderReader = new CarbonHeaderReader(tableBlockInfo.getFilePath());
1:b41e48f:     FileHeader fileHeader = carbonHeaderReader.readHeader();
1:b41e48f:     CarbonFooterReaderV3 reader =
1:b41e48f:         new CarbonFooterReaderV3(tableBlockInfo.getFilePath(), tableBlockInfo.getBlockOffset());
1:b41e48f:     FileFooter3 footer = reader.readFooterVersion3();
1:b41e48f:     dataFileFooter.setVersionId(ColumnarFormatVersion.valueOf((short) fileHeader.getVersion()));
1:2cf1104:     dataFileFooter.setNumberOfRows(footer.getNum_rows());
1:2cf1104:     dataFileFooter.setSegmentInfo(getSegmentInfo(footer.getSegment_info()));
1:fc1af96:     dataFileFooter.setSchemaUpdatedTimeStamp(fileHeader.getTime_stamp());
1:2cf1104:     List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:b41e48f:     List<org.apache.carbondata.format.ColumnSchema> table_columns = fileHeader.getColumn_schema();
1:2cf1104:     for (int i = 0; i < table_columns.size(); i++) {
1:8896a63:       columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
5:2cf1104:     }
1:2cf1104:     dataFileFooter.setColumnInTable(columnSchemaList);
1:2cf1104:     List<org.apache.carbondata.format.BlockletIndex> leaf_node_indices_Thrift =
1:2cf1104:         footer.getBlocklet_index_list();
1:2cf1104:     List<BlockletIndex> blockletIndexList = new ArrayList<BlockletIndex>();
1:2cf1104:     for (int i = 0; i < leaf_node_indices_Thrift.size(); i++) {
1:2cf1104:       BlockletIndex blockletIndex = getBlockletIndex(leaf_node_indices_Thrift.get(i));
1:2cf1104:       blockletIndexList.add(blockletIndex);
1:2cf1104:     }
1:2cf1104:     List<org.apache.carbondata.format.BlockletInfo3> leaf_node_infos_Thrift =
1:2cf1104:         footer.getBlocklet_info_list3();
1:2cf1104:     List<BlockletInfo> blockletInfoList = new ArrayList<BlockletInfo>();
1:2cf1104:     for (int i = 0; i < leaf_node_infos_Thrift.size(); i++) {
1:2cf1104:       BlockletInfo blockletInfo = getBlockletInfo(leaf_node_infos_Thrift.get(i),
1:1e21cd1:           CarbonUtil.getNumberOfDimensionColumns(columnSchemaList));
1:2cf1104:       blockletInfo.setBlockletIndex(blockletIndexList.get(i));
1:2cf1104:       blockletInfoList.add(blockletInfo);
1:2cf1104:     }
1:2cf1104:     dataFileFooter.setBlockletList(blockletInfoList);
1:2cf1104:     dataFileFooter.setBlockletIndex(getBlockletIndexForDataFileFooter(blockletIndexList));
1:2cf1104:     return dataFileFooter;
1:2cf1104:   }
1:2cf1104: 
1:b681244:   @Override public List<ColumnSchema> getSchema(TableBlockInfo tableBlockInfo) throws IOException {
1:b681244:     CarbonHeaderReader carbonHeaderReader = new CarbonHeaderReader(tableBlockInfo.getFilePath());
1:b681244:     FileHeader fileHeader = carbonHeaderReader.readHeader();
1:b681244:     List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:b681244:     List<org.apache.carbondata.format.ColumnSchema> table_columns = fileHeader.getColumn_schema();
1:b681244:     for (int i = 0; i < table_columns.size(); i++) {
1:8896a63:       columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
1:b681244:     }
1:b681244:     return columnSchemaList;
1:b681244:   }
1:b681244: 
1:2cf1104:   /**
1:2cf1104:    * Below method is to convert the blocklet info of the thrift to wrapper
1:2cf1104:    * blocklet info
1:2cf1104:    *
1:2cf1104:    * @param blockletInfoThrift blocklet info of the thrift
1:2cf1104:    * @return blocklet info wrapper
1:2cf1104:    */
1:1e21cd1:   public BlockletInfo getBlockletInfo(
1:2cf1104:       org.apache.carbondata.format.BlockletInfo3 blockletInfoThrift, int numberOfDimensionColumns) {
1:2cf1104:     BlockletInfo blockletInfo = new BlockletInfo();
1:2cf1104:     List<Long> dimensionColumnChunkOffsets =
1:2cf1104:         blockletInfoThrift.getColumn_data_chunks_offsets().subList(0, numberOfDimensionColumns);
1:2cf1104:     List<Long> measureColumnChunksOffsets = blockletInfoThrift.getColumn_data_chunks_offsets()
1:2cf1104:         .subList(numberOfDimensionColumns,
1:2cf1104:             blockletInfoThrift.getColumn_data_chunks_offsets().size());
1:2cf1104:     List<Integer> dimensionColumnChunkLength =
1:2cf1104:         blockletInfoThrift.getColumn_data_chunks_length().subList(0, numberOfDimensionColumns);
1:2cf1104:     List<Integer> measureColumnChunksLength = blockletInfoThrift.getColumn_data_chunks_length()
1:2cf1104:         .subList(numberOfDimensionColumns,
1:2cf1104:             blockletInfoThrift.getColumn_data_chunks_offsets().size());
1:2cf1104:     blockletInfo.setDimensionChunkOffsets(dimensionColumnChunkOffsets);
1:2cf1104:     blockletInfo.setMeasureChunkOffsets(measureColumnChunksOffsets);
1:2cf1104:     blockletInfo.setDimensionChunksLength(dimensionColumnChunkLength);
1:2cf1104:     blockletInfo.setMeasureChunksLength(measureColumnChunksLength);
1:2cf1104:     blockletInfo.setNumberOfRows(blockletInfoThrift.getNum_rows());
1:2cf1104:     blockletInfo.setDimensionOffset(blockletInfoThrift.getDimension_offsets());
1:2cf1104:     blockletInfo.setMeasureOffsets(blockletInfoThrift.getMeasure_offsets());
1:b41e48f:     blockletInfo.setNumberOfPages(blockletInfoThrift.getNumber_number_of_pages());
1:2cf1104:     return blockletInfo;
1:2cf1104:   }
1:2cf1104: 
1:2cf1104: }
1:2cf1104: 
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
1: 
1:   public DataFileFooterConverterV3(Configuration configuration) {
1:     super(configuration);
1:   }
1: 
1:   public DataFileFooterConverterV3() {
1:     super(FileFactory.getConfiguration());
1:   }
1: 
author:xubo245
-------------------------------------------------------------------------------
commit:8896a63
/////////////////////////////////////////////////////////////////////////
1:       columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
/////////////////////////////////////////////////////////////////////////
1:       columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:1e21cd1
/////////////////////////////////////////////////////////////////////////
1:           CarbonUtil.getNumberOfDimensionColumns(columnSchemaList));
/////////////////////////////////////////////////////////////////////////
1:   public BlockletInfo getBlockletInfo(
/////////////////////////////////////////////////////////////////////////
author:ravipesala
-------------------------------------------------------------------------------
commit:b681244
/////////////////////////////////////////////////////////////////////////
1:   @Override public List<ColumnSchema> getSchema(TableBlockInfo tableBlockInfo) throws IOException {
1:     CarbonHeaderReader carbonHeaderReader = new CarbonHeaderReader(tableBlockInfo.getFilePath());
1:     FileHeader fileHeader = carbonHeaderReader.readHeader();
1:     List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:     List<org.apache.carbondata.format.ColumnSchema> table_columns = fileHeader.getColumn_schema();
1:     for (int i = 0; i < table_columns.size(); i++) {
0:       columnSchemaList.add(thriftColumnSchmeaToWrapperColumnSchema(table_columns.get(i)));
1:     }
1:     return columnSchemaList;
1:   }
1: 
author:manishgupta88
-------------------------------------------------------------------------------
commit:fc1af96
/////////////////////////////////////////////////////////////////////////
1:     dataFileFooter.setSchemaUpdatedTimeStamp(fileHeader.getTime_stamp());
author:kumarvishal
-------------------------------------------------------------------------------
commit:b41e48f
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.reader.CarbonFooterReaderV3;
1: import org.apache.carbondata.core.reader.CarbonHeaderReader;
1: import org.apache.carbondata.format.FileFooter3;
1: import org.apache.carbondata.format.FileHeader;
1:    * 1. It will read the header from carbon data file, header starts from 0 offset
1:    * 2. It will set the stream offset
1:    * 3. It will read the footer data from file
1:    * 4. parse the footer to thrift object
1:    * 5. convert to wrapper object
/////////////////////////////////////////////////////////////////////////
1:     CarbonHeaderReader carbonHeaderReader = new CarbonHeaderReader(tableBlockInfo.getFilePath());
1:     FileHeader fileHeader = carbonHeaderReader.readHeader();
1:     CarbonFooterReaderV3 reader =
1:         new CarbonFooterReaderV3(tableBlockInfo.getFilePath(), tableBlockInfo.getBlockOffset());
1:     FileFooter3 footer = reader.readFooterVersion3();
1:     dataFileFooter.setVersionId(ColumnarFormatVersion.valueOf((short) fileHeader.getVersion()));
1:     List<org.apache.carbondata.format.ColumnSchema> table_columns = fileHeader.getColumn_schema();
/////////////////////////////////////////////////////////////////////////
1:     blockletInfo.setNumberOfPages(blockletInfoThrift.getNumber_number_of_pages());
commit:2cf1104
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.util;
1: 
1: import java.io.IOException;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
1: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
1: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
0: import org.apache.carbondata.core.reader.CarbonFooterReader;
0: import org.apache.carbondata.format.FileFooter;
1: 
1: public class DataFileFooterConverterV3 extends AbstractDataFileFooterConverter {
1: 
1:   /**
1:    * Below method will be used to convert thrift file meta to wrapper file meta
1:    * This method will read the footer from footer offset present in the data file
0:    * 1. It will set the stream offset
0:    * 2. It will read the footer data from file
0:    * 3. parse the footer to thrift object
0:    * 4. convert to wrapper object
1:    *
1:    * @param tableBlockInfo
1:    *        table block info
1:    * @return data file footer
1:    */
1:   @Override public DataFileFooter readDataFileFooter(TableBlockInfo tableBlockInfo)
1:       throws IOException {
1:     DataFileFooter dataFileFooter = new DataFileFooter();
0:     CarbonFooterReader reader =
0:         new CarbonFooterReader(tableBlockInfo.getFilePath(), tableBlockInfo.getBlockOffset());
0:     FileFooter footer = reader.readFooter();
0:     dataFileFooter.setVersionId(ColumnarFormatVersion.valueOf((short) footer.getVersion()));
1:     dataFileFooter.setNumberOfRows(footer.getNum_rows());
1:     dataFileFooter.setSegmentInfo(getSegmentInfo(footer.getSegment_info()));
1:     List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
0:     List<org.apache.carbondata.format.ColumnSchema> table_columns = footer.getTable_columns();
1:     for (int i = 0; i < table_columns.size(); i++) {
0:       columnSchemaList.add(thriftColumnSchmeaToWrapperColumnSchema(table_columns.get(i)));
1:     }
1:     dataFileFooter.setColumnInTable(columnSchemaList);
1: 
1:     List<org.apache.carbondata.format.BlockletIndex> leaf_node_indices_Thrift =
1:         footer.getBlocklet_index_list();
1:     List<BlockletIndex> blockletIndexList = new ArrayList<BlockletIndex>();
1:     for (int i = 0; i < leaf_node_indices_Thrift.size(); i++) {
1:       BlockletIndex blockletIndex = getBlockletIndex(leaf_node_indices_Thrift.get(i));
1:       blockletIndexList.add(blockletIndex);
1:     }
1:     List<org.apache.carbondata.format.BlockletInfo3> leaf_node_infos_Thrift =
1:         footer.getBlocklet_info_list3();
1:     List<BlockletInfo> blockletInfoList = new ArrayList<BlockletInfo>();
1:     for (int i = 0; i < leaf_node_infos_Thrift.size(); i++) {
1:       BlockletInfo blockletInfo = getBlockletInfo(leaf_node_infos_Thrift.get(i),
0:           getNumberOfDimensionColumns(columnSchemaList));
1:       blockletInfo.setBlockletIndex(blockletIndexList.get(i));
1:       blockletInfoList.add(blockletInfo);
1:     }
1:     dataFileFooter.setBlockletList(blockletInfoList);
1:     dataFileFooter.setBlockletIndex(getBlockletIndexForDataFileFooter(blockletIndexList));
1:     return dataFileFooter;
1:   }
1: 
1:   /**
1:    * Below method is to convert the blocklet info of the thrift to wrapper
1:    * blocklet info
1:    *
1:    * @param blockletInfoThrift blocklet info of the thrift
1:    * @return blocklet info wrapper
1:    */
0:   private BlockletInfo getBlockletInfo(
1:       org.apache.carbondata.format.BlockletInfo3 blockletInfoThrift, int numberOfDimensionColumns) {
1:     BlockletInfo blockletInfo = new BlockletInfo();
1:     List<Long> dimensionColumnChunkOffsets =
1:         blockletInfoThrift.getColumn_data_chunks_offsets().subList(0, numberOfDimensionColumns);
1:     List<Long> measureColumnChunksOffsets = blockletInfoThrift.getColumn_data_chunks_offsets()
1:         .subList(numberOfDimensionColumns,
1:             blockletInfoThrift.getColumn_data_chunks_offsets().size());
1:     List<Integer> dimensionColumnChunkLength =
1:         blockletInfoThrift.getColumn_data_chunks_length().subList(0, numberOfDimensionColumns);
1:     List<Integer> measureColumnChunksLength = blockletInfoThrift.getColumn_data_chunks_length()
1:         .subList(numberOfDimensionColumns,
1:             blockletInfoThrift.getColumn_data_chunks_offsets().size());
1:     blockletInfo.setDimensionChunkOffsets(dimensionColumnChunkOffsets);
1:     blockletInfo.setMeasureChunkOffsets(measureColumnChunksOffsets);
1:     blockletInfo.setDimensionChunksLength(dimensionColumnChunkLength);
1:     blockletInfo.setMeasureChunksLength(measureColumnChunksLength);
1:     blockletInfo.setNumberOfRows(blockletInfoThrift.getNum_rows());
1:     blockletInfo.setDimensionOffset(blockletInfoThrift.getDimension_offsets());
1:     blockletInfo.setMeasureOffsets(blockletInfoThrift.getMeasure_offsets());
1:     return blockletInfo;
1:   }
1: 
1:   /**
0:    * Below method will be used to get the number of dimension column
0:    * in carbon column schema
1:    *
0:    * @param columnSchemaList column schema list
0:    * @return number of dimension column
1:    */
0:   private int getNumberOfDimensionColumns(List<ColumnSchema> columnSchemaList) {
0:     int numberOfDimensionColumns = 0;
0:     int previousColumnGroupId = -1;
0:     ColumnSchema columnSchema = null;
0:     for (int i = 0; i < columnSchemaList.size(); i++) {
0:       columnSchema = columnSchemaList.get(i);
0:       if (columnSchema.isDimensionColumn() && columnSchema.isColumnar()) {
0:         numberOfDimensionColumns++;
0:       } else if (columnSchema.isDimensionColumn()) {
0:         if (previousColumnGroupId != columnSchema.getColumnGroupId()) {
0:           previousColumnGroupId = columnSchema.getColumnGroupId();
0:           numberOfDimensionColumns++;
1:         }
0:       } else {
0:         break;
1:       }
1:     }
0:     return numberOfDimensionColumns;
1:   }
1: 
1: }
1: 
============================================================================
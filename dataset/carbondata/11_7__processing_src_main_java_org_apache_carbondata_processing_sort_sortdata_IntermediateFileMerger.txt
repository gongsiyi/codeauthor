1:cd6a4ff: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
3:cd6a4ff:  *
1:cd6a4ff:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cd6a4ff:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
6:cd6a4ff:  */
23:cd6a4ff: 
1:349c59c: package org.apache.carbondata.processing.sort.sortdata;
1:a734add: 
1:cd6a4ff: import java.io.DataOutputStream;
1:cd6a4ff: import java.io.File;
1:cd6a4ff: import java.io.FileNotFoundException;
1:cd6a4ff: import java.io.IOException;
1:cd6a4ff: import java.util.AbstractQueue;
1:7ef9164: import java.util.NoSuchElementException;
1:cd6a4ff: import java.util.PriorityQueue;
1:a734add: import java.util.concurrent.Callable;
1:496cde4: 
1:cd6a4ff: import org.apache.carbondata.common.logging.LogService;
1:cd6a4ff: import org.apache.carbondata.common.logging.LogServiceFactory;
1:c100251: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonUtil;
1:2b41f14: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1:496cde4: 
1:a734add: public class IntermediateFileMerger implements Callable<Void> {
6:cd6a4ff:   /**
1:cd6a4ff:    * LOGGER
1:cd6a4ff:    */
1:cd6a4ff:   private static final LogService LOGGER =
1:cd6a4ff:       LogServiceFactory.getLogService(IntermediateFileMerger.class.getName());
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * recordHolderHeap
1:cd6a4ff:    */
1:cd6a4ff:   private AbstractQueue<SortTempFileChunkHolder> recordHolderHeap;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * fileCounter
1:cd6a4ff:    */
1:cd6a4ff:   private int fileCounter;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * stream
1:cd6a4ff:    */
1:cd6a4ff:   private DataOutputStream stream;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * totalNumberOfRecords
1:cd6a4ff:    */
1:cd6a4ff:   private int totalNumberOfRecords;
1:cd6a4ff: 
1:9aee980:   private SortParameters mergerParameters;
1:9aee980: 
1:9aee980:   private File[] intermediateFiles;
1:9aee980: 
1:9aee980:   private File outPutFile;
1:c100251:   private int writeBufferSize;
1:c100251:   private String compressorName;
1:8d8b589: 
1:a734add:   private Throwable throwable;
1:2b41f14:   private TableFieldStat tableFieldStat;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:cd6a4ff:   /**
1:cd6a4ff:    * IntermediateFileMerger Constructor
1:cd6a4ff:    */
1:9aee980:   public IntermediateFileMerger(SortParameters mergerParameters, File[] intermediateFiles,
1:9aee980:       File outPutFile) {
1:cd6a4ff:     this.mergerParameters = mergerParameters;
1:9aee980:     this.fileCounter = intermediateFiles.length;
1:9aee980:     this.intermediateFiles = intermediateFiles;
1:9aee980:     this.outPutFile = outPutFile;
1:c100251:     this.writeBufferSize = mergerParameters.getBufferSize();
1:c100251:     this.compressorName = mergerParameters.getSortTempCompressorName();
1:2b41f14:     this.tableFieldStat = new TableFieldStat(mergerParameters);
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:496cde4:   }
1:496cde4: 
1:a734add:   @Override public Void call() throws Exception {
1:cd6a4ff:     long intermediateMergeStartTime = System.currentTimeMillis();
1:cd6a4ff:     int fileConterConst = fileCounter;
1:8d8b589:     try {
1:cd6a4ff:       startSorting();
1:cd6a4ff:       initialize();
1:e6b6090:       while (hasNext()) {
1:c100251:         writeDataToFile(next());
1:c100251:       }
1:256dbed:       double intermediateMergeCostTime =
1:256dbed:           (System.currentTimeMillis() - intermediateMergeStartTime) / 1000.0;
1:cd6a4ff:       LOGGER.info("============================== Intermediate Merge of " + fileConterConst +
1:cd6a4ff:           " Sort Temp Files Cost Time: " + intermediateMergeCostTime + "(s)");
1:cd6a4ff:     } catch (Exception e) {
1:cd6a4ff:       LOGGER.error(e, "Problem while intermediate merging");
1:a734add:       clear();
1:a734add:       throwable = e;
1:cd6a4ff:     } finally {
1:cd6a4ff:       CarbonUtil.closeStreams(this.stream);
1:a734add:       if (null == throwable) {
1:496cde4:         try {
1:cd6a4ff:           finish();
1:cd6a4ff:         } catch (CarbonSortKeyAndGroupByException e) {
1:cd6a4ff:           LOGGER.error(e, "Problem while deleting the merge file");
1:a734add:           throwable = e;
1:496cde4:         }
3:8d8b589:       } else {
1:a734add:         if (!outPutFile.delete()) {
1:cd6a4ff:           LOGGER.error("Problem while deleting the merge file");
1:8d8b589:         }
1:8d8b589:       }
1:8d8b589:     }
1:a734add:     if (null != throwable) {
1:a734add:       throw new CarbonSortKeyAndGroupByException(throwable);
1:8d8b589:     }
1:a734add:     return null;
1:8d8b589:   }
1:496cde4: 
1:496cde4:   /**
1:cd6a4ff:    * This method is responsible for initializing the out stream
1:496cde4:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:496cde4:    */
1:cd6a4ff:   private void initialize() throws CarbonSortKeyAndGroupByException {
1:c100251:     try {
1:c100251:       stream = FileFactory.getDataOutputStream(outPutFile.getPath(), FileFactory.FileType.LOCAL,
1:c100251:           writeBufferSize, compressorName);
1:c100251:       this.stream.writeInt(this.totalNumberOfRecords);
1:c100251:     } catch (FileNotFoundException e) {
1:c100251:       throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
1:8d8b589:     } catch (IOException e) {
1:c100251:       throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
1:8d8b589:     }
1:a734add:   }
1:496cde4: 
1:cd6a4ff:   /**
1:2b41f14:    * This method will be used to get the sorted sort temp row from sort temp file
1:cd6a4ff:    *
1:cd6a4ff:    * @return sorted record sorted record
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:2b41f14:   private IntermediateSortTempRow getSortedRecordFromFile()
1:2b41f14:       throws CarbonSortKeyAndGroupByException {
1:2b41f14:     IntermediateSortTempRow row = null;
1:496cde4: 
1:cd6a4ff:     // poll the top object from heap
1:cd6a4ff:     // heap maintains binary tree which is based on heap condition that will
1:cd6a4ff:     // be based on comparator we are passing the heap
1:cd6a4ff:     // when will call poll it will always delete root of the tree and then
1:cd6a4ff:     // it does trickel down operation complexity is log(n)
1:cd6a4ff:     SortTempFileChunkHolder poll = this.recordHolderHeap.poll();
1:cd6a4ff: 
1:cd6a4ff:     // get the row from chunk
1:cd6a4ff:     row = poll.getRow();
1:cd6a4ff: 
1:cd6a4ff:     // check if there no entry present
1:cd6a4ff:     if (!poll.hasNext()) {
1:cd6a4ff:       // if chunk is empty then close the stream
1:cd6a4ff:       poll.closeStream();
1:cd6a4ff: 
1:cd6a4ff:       // change the file counter
1:cd6a4ff:       --this.fileCounter;
1:cd6a4ff: 
1:cd6a4ff:       // reaturn row
1:cd6a4ff:       return row;
1:496cde4:     }
1:cd6a4ff: 
1:cd6a4ff:     // read new row
1:cd6a4ff:     poll.readRow();
1:cd6a4ff: 
1:cd6a4ff:     // add to heap
1:cd6a4ff:     this.recordHolderHeap.add(poll);
1:cd6a4ff: 
1:cd6a4ff:     // return row
1:cd6a4ff:     return row;
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Below method will be used to start storing process This method will get
1:cd6a4ff:    * all the temp files present in sort temp folder then it will create the
1:cd6a4ff:    * record holder heap and then it will read first record from each file and
1:cd6a4ff:    * initialize the heap
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:cd6a4ff:   private void startSorting() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     LOGGER.info("Number of temp file: " + this.fileCounter);
1:cd6a4ff: 
1:cd6a4ff:     // create record holder heap
1:9aee980:     createRecordHolderQueue(intermediateFiles);
1:cd6a4ff: 
1:cd6a4ff:     // iterate over file list and create chunk holder and add to heap
1:cd6a4ff:     LOGGER.info("Started adding first record from each file");
1:cd6a4ff: 
1:cd6a4ff:     SortTempFileChunkHolder sortTempFileChunkHolder = null;
1:cd6a4ff: 
1:9aee980:     for (File tempFile : intermediateFiles) {
1:cd6a4ff:       // create chunk holder
1:cd6a4ff:       sortTempFileChunkHolder =
1:f27efb3:           new SortTempFileChunkHolder(tempFile, mergerParameters, mergerParameters.getTableName(),
1:f27efb3:               false);
1:cd6a4ff: 
1:cd6a4ff:       // initialize
1:cd6a4ff:       sortTempFileChunkHolder.initialize();
1:cd6a4ff:       sortTempFileChunkHolder.readRow();
1:cd6a4ff:       this.totalNumberOfRecords += sortTempFileChunkHolder.getEntryCount();
1:cd6a4ff: 
1:cd6a4ff:       // add to heap
1:cd6a4ff:       this.recordHolderHeap.add(sortTempFileChunkHolder);
1:496cde4:     }
1:cd6a4ff: 
1:2b41f14:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to create the heap which will be used to hold
1:cd6a4ff:    * the chunk of data
1:cd6a4ff:    *
1:cd6a4ff:    * @param listFiles list of temp files
1:cd6a4ff:    */
1:cd6a4ff:   private void createRecordHolderQueue(File[] listFiles) {
1:cd6a4ff:     // creating record holder heap
1:e6b6090:     this.recordHolderHeap = new PriorityQueue<>(listFiles.length);
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:2b41f14:    * This method will be used to get the sorted sort temp row
1:cd6a4ff:    *
1:cd6a4ff:    * @return sorted row
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:2b41f14:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
1:7ef9164:     if (hasNext()) {
1:7ef9164:       return getSortedRecordFromFile();
1:7ef9164:     } else {
1:7ef9164:       throw new NoSuchElementException("No more elements to return");
1:7ef9164:     }
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to check whether any more element is present or
1:cd6a4ff:    * not
1:cd6a4ff:    *
1:cd6a4ff:    * @return more element is present
1:cd6a4ff:    */
1:cd6a4ff:   private boolean hasNext() {
1:cd6a4ff:     return this.fileCounter > 0;
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:496cde4:    * Below method will be used to write data to file
1:496cde4:    *
1:2b41f14:    * @throws IOException problem while writing
1:cd6a4ff:    */
1:2b41f14:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
1:2b41f14:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
1:8d8b589:   }
1:496cde4: 
1:cd6a4ff:   private void finish() throws CarbonSortKeyAndGroupByException {
1:a734add:     clear();
5:cd6a4ff:     try {
1:9aee980:       CarbonUtil.deleteFiles(intermediateFiles);
1:c100251:     } catch (IOException e) {
1:cd6a4ff:       throw new CarbonSortKeyAndGroupByException("Problem while deleting the intermediate files");
1:496cde4:     }
1:496cde4:   }
1:a734add: 
1:a734add:   private void clear() {
1:a734add:     if (recordHolderHeap != null) {
1:a734add:       SortTempFileChunkHolder sortTempFileChunkHolder;
1:a734add:       while (!recordHolderHeap.isEmpty()) {
1:a734add:         sortTempFileChunkHolder = recordHolderHeap.poll();
1:a734add:         if (null != sortTempFileChunkHolder) {
1:a734add:           sortTempFileChunkHolder.closeStream();
1:a734add:         }
1:a734add:       }
1:a734add:     }
1:a734add:     recordHolderHeap = null;
1:a734add:   }
1:496cde4: }
============================================================================
author:kumarvishal09
-------------------------------------------------------------------------------
commit:f27efb3
/////////////////////////////////////////////////////////////////////////
1:           new SortTempFileChunkHolder(tempFile, mergerParameters, mergerParameters.getTableName(),
1:               false);
author:Raghunandan S
-------------------------------------------------------------------------------
commit:7ef9164
/////////////////////////////////////////////////////////////////////////
1: import java.util.NoSuchElementException;
/////////////////////////////////////////////////////////////////////////
1:     if (hasNext()) {
1:       return getSortedRecordFromFile();
1:     } else {
1:       throw new NoSuchElementException("No more elements to return");
1:     }
commit:06b0d08
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: public class IntermediateFileMerger implements Runnable {
/////////////////////////////////////////////////////////////////////////
0:   @Override
0:   public void run() {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             default:
0:               throw new IllegalArgumentException("unsupported data type:" + aggType[counter]);
author:xuchuanyin
-------------------------------------------------------------------------------
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:   private TableFieldStat tableFieldStat;
1:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:     this.tableFieldStat = new TableFieldStat(mergerParameters);
1:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to get the sorted sort temp row from sort temp file
1:   private IntermediateSortTempRow getSortedRecordFromFile()
1:       throws CarbonSortKeyAndGroupByException {
1:     IntermediateSortTempRow row = null;
/////////////////////////////////////////////////////////////////////////
1:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to get the sorted sort temp row
1:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
1:    * @throws IOException problem while writing
1:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
1:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
0: import java.math.BigDecimal;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.core.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:   private int dimCnt;
0:   private int noDictDimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
1: 
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = mergerParameters.getDimColCount();
0:     this.noDictDimCnt = mergerParameters.getNoDictionaryCount();
0:     this.complexCnt = mergerParameters.getComplexDimColCount();
0:     this.measureCnt = mergerParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = mergerParameters.getNoDictionaryDimnesionColumn();
0:     this.measureDataTypes = mergerParameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted record from file
0:   private Object[] getSortedRecordFromFile() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = null;
/////////////////////////////////////////////////////////////////////////
0:     LOGGER.info("Heap Size" + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted row
0:   private Object[] next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:    * @throws CarbonSortKeyAndGroupByException problem while writing
0:   private void writeDataToFile(Object[] row) throws CarbonSortKeyAndGroupByException {
1:     try {
0:       int[] mdkArray = (int[]) row[0];
0:       byte[][] nonDictArray = (byte[][]) row[1];
0:       int mdkIndex = 0;
0:       int nonDictKeyIndex = 0;
0:       // write dictionary and non dictionary dimensions here.
0:       for (boolean nodictinary : isNoDictionaryDimensionColumn) {
0:         if (nodictinary) {
0:           byte[] col = nonDictArray[nonDictKeyIndex++];
0:           stream.writeShort(col.length);
0:           stream.write(col);
1:         } else {
0:           stream.writeInt(mdkArray[mdkIndex++]);
1:         }
1:       }
0:       // write complex
0:       for (; nonDictKeyIndex < noDictDimCnt + complexCnt; nonDictKeyIndex++) {
0:         byte[] col = nonDictArray[nonDictKeyIndex++];
0:         stream.writeShort(col.length);
0:         stream.write(col);
1:       }
0:       // write measure
0:       int fieldIndex = 0;
0:       for (int counter = 0; counter < measureCnt; counter++) {
0:         if (null != NonDictionaryUtil.getMeasure(fieldIndex, row)) {
0:           stream.write((byte) 1);
0:           DataType dataType = measureDataTypes[counter];
0:           if (dataType == DataTypes.BOOLEAN) {
0:             stream.writeBoolean((boolean)NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.SHORT) {
0:             stream.writeShort((short) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.INT) {
0:             stream.writeInt((int) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.LONG) {
0:             stream.writeLong((long) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             stream.writeDouble((Double) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (DataTypes.isDecimal(dataType)) {
0:             byte[] bigDecimalInBytes = DataTypeUtil
0:                 .bigDecimalToByte((BigDecimal) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:             stream.writeInt(bigDecimalInBytes.length);
0:             stream.write(bigDecimalInBytes);
1:           } else {
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
1:           }
1:         } else {
0:           stream.write((byte) 0);
1:         }
0:         fieldIndex++;
1:       }
1:     } catch (IOException e) {
0:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
1:     }
commit:21704cf
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:   private TableFieldStat tableFieldStat;
0:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:     this.tableFieldStat = new TableFieldStat(mergerParameters);
0:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted sort temp row from sort temp file
0:   private IntermediateSortTempRow getSortedRecordFromFile()
0:       throws CarbonSortKeyAndGroupByException {
0:     IntermediateSortTempRow row = null;
/////////////////////////////////////////////////////////////////////////
0:     LOGGER.info("Heap Size: " + this.recordHolderHeap.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted sort temp row
0:   private IntermediateSortTempRow next() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:    * @throws IOException problem while writing
0:   private void writeDataToFile(IntermediateSortTempRow row) throws IOException {
0:     sortStepRowHandler.writeIntermediateSortTempRowToOutputStream(row, stream);
commit:c100251
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
0:   private int dimCnt;
0:   private int noDictDimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
1:   private int writeBufferSize;
1:   private String compressorName;
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = mergerParameters.getDimColCount();
0:     this.noDictDimCnt = mergerParameters.getNoDictionaryCount();
0:     this.complexCnt = mergerParameters.getComplexDimColCount();
0:     this.measureCnt = mergerParameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = mergerParameters.getNoDictionaryDimnesionColumn();
0:     this.measureDataTypes = mergerParameters.getMeasureDataType();
1:     this.writeBufferSize = mergerParameters.getBufferSize();
1:     this.compressorName = mergerParameters.getSortTempCompressorName();
/////////////////////////////////////////////////////////////////////////
1:         writeDataToFile(next());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       stream = FileFactory.getDataOutputStream(outPutFile.getPath(), FileFactory.FileType.LOCAL,
1:           writeBufferSize, compressorName);
1:       this.stream.writeInt(this.totalNumberOfRecords);
1:     } catch (FileNotFoundException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
1:     } catch (IOException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
/////////////////////////////////////////////////////////////////////////
0:           new SortTempFileChunkHolder(tempFile, mergerParameters, mergerParameters.getTableName());
/////////////////////////////////////////////////////////////////////////
0:   private void writeDataToFile(Object[] row) throws CarbonSortKeyAndGroupByException {
0:       for (boolean nodictinary : isNoDictionaryDimensionColumn) {
/////////////////////////////////////////////////////////////////////////
0:       // write complex
0:       for (; nonDictKeyIndex < noDictDimCnt + complexCnt; nonDictKeyIndex++) {
0:         byte[] col = nonDictArray[nonDictKeyIndex++];
0:         stream.writeShort(col.length);
0:         stream.write(col);
1:       }
0:       // write measure
0:       for (int counter = 0; counter < measureCnt; counter++) {
0:           DataType dataType = measureDataTypes[counter];
/////////////////////////////////////////////////////////////////////////
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
author:kunal642
-------------------------------------------------------------------------------
commit:fd28b15
/////////////////////////////////////////////////////////////////////////
0: import java.math.BigDecimal;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
0:             byte[] bigDecimalInBytes = DataTypeUtil
0:                 .bigDecimalToByte((BigDecimal) NonDictionaryUtil.getMeasure(fieldIndex, row));
author:Jacky Li
-------------------------------------------------------------------------------
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:           } else if (DataTypes.isDecimal(dataType)) {
commit:4d70a21
/////////////////////////////////////////////////////////////////////////
0:       DataType[] measureDataType = mergerParameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:           DataType dataType = measureDataType[counter];
/////////////////////////////////////////////////////////////////////////
0:             throw new IllegalArgumentException("unsupported data type:" + measureDataType[counter]);
commit:956833e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:           DataType dataType = aggType[counter];
0:           if (dataType == DataTypes.SHORT) {
0:             stream.writeShort((short) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.INT) {
0:             stream.writeInt((int) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.LONG) {
0:             stream.writeLong((long) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             stream.writeDouble((Double) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.DECIMAL) {
0:             byte[] bigDecimalInBytes = (byte[]) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeInt(bigDecimalInBytes.length);
0:             stream.write(bigDecimalInBytes);
0:           } else {
0:             throw new IllegalArgumentException("unsupported data type:" + aggType[counter]);
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.sort.sortdata;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
author:xubo245
-------------------------------------------------------------------------------
commit:6abdd97
/////////////////////////////////////////////////////////////////////////
0:           if (dataType == DataTypes.BOOLEAN) {
0:             stream.writeBoolean((boolean)NonDictionaryUtil.getMeasure(fieldIndex, row));
0:           } else if (dataType == DataTypes.SHORT) {
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.Callable;
/////////////////////////////////////////////////////////////////////////
1: public class IntermediateFileMerger implements Callable<Void> {
/////////////////////////////////////////////////////////////////////////
1:   private Throwable throwable;
1: 
/////////////////////////////////////////////////////////////////////////
1:   @Override public Void call() throws Exception {
/////////////////////////////////////////////////////////////////////////
1:       clear();
1:       throwable = e;
1:       if (null == throwable) {
1:           throwable = e;
1:         if (!outPutFile.delete()) {
1:     if (null != throwable) {
1:       throw new CarbonSortKeyAndGroupByException(throwable);
1:     }
1:     return null;
/////////////////////////////////////////////////////////////////////////
0:               mergerParameters.getNoDictionarySortColumn(), mergerParameters.getTableName());
/////////////////////////////////////////////////////////////////////////
1:     clear();
1: 
1:   private void clear() {
1:     if (recordHolderHeap != null) {
1:       SortTempFileChunkHolder sortTempFileChunkHolder;
1:       while (!recordHolderHeap.isEmpty()) {
1:         sortTempFileChunkHolder = recordHolderHeap.poll();
1:         if (null != sortTempFileChunkHolder) {
1:           sortTempFileChunkHolder.closeStream();
1:         }
1:       }
1:     }
1:     recordHolderHeap = null;
1:   }
author:jackylk
-------------------------------------------------------------------------------
commit:bc3e684
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.NonDictionaryUtil;
commit:98df130
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
/////////////////////////////////////////////////////////////////////////
0:               mergerParameters.getMeasureDataType(),
0:               mergerParameters.getNoDictionaryDimnesionColumn(),
/////////////////////////////////////////////////////////////////////////
0:       DataType[] aggType = mergerParameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:           switch (aggType[counter]) {
0:             case SHORT:
0:             case INT:
0:             case LONG:
0:               Long val = (Long) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:               stream.writeLong(val);
0:               break;
0:             case DOUBLE:
0:               stream.writeDouble((Double) NonDictionaryUtil.getMeasure(fieldIndex, row));
0:               break;
0:             case DECIMAL:
0:               byte[] bigDecimalInBytes = (byte[]) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:               stream.writeInt(bigDecimalInBytes.length);
0:               stream.write(bigDecimalInBytes);
0:               break;
commit:8cca0af
/////////////////////////////////////////////////////////////////////////
0:           } else if (aggType[counter] == CarbonCommonConstants.DOUBLE_MEASURE) {
commit:eaadc88
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     } catch (IOException e) {
author:anubhav100
-------------------------------------------------------------------------------
commit:700665b
/////////////////////////////////////////////////////////////////////////
0:               stream.writeShort((short)NonDictionaryUtil.getMeasure(fieldIndex, row));
0:               break;
0:               stream.writeInt((int)NonDictionaryUtil.getMeasure(fieldIndex, row));
0:               break;
0:               stream.writeLong((long)NonDictionaryUtil.getMeasure(fieldIndex, row));
author:QiangCai
-------------------------------------------------------------------------------
commit:9f94529
/////////////////////////////////////////////////////////////////////////
0:               mergerParameters.getAggType(), mergerParameters.getNoDictionaryDimnesionColumn(),
0:               mergerParameters.getNoDictionarySortColumn());
commit:256dbed
/////////////////////////////////////////////////////////////////////////
1:       double intermediateMergeCostTime =
1:           (System.currentTimeMillis() - intermediateMergeStartTime) / 1000.0;
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:ravipesala
-------------------------------------------------------------------------------
commit:e6b6090
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       while (hasNext()) {
0:         writeDataTofile(next());
/////////////////////////////////////////////////////////////////////////
0:               mergerParameters.getAggType(), mergerParameters.getNoDictionaryDimnesionColumn());
/////////////////////////////////////////////////////////////////////////
1:     this.recordHolderHeap = new PriorityQueue<>(listFiles.length);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:         stream.writeInt((Integer) NonDictionaryUtil.getDimension(fieldIndex++, row));
0:         stream.write(NonDictionaryUtil.getByteArrayForNoDictionaryCols(row));
0:         if (null != NonDictionaryUtil.getMeasure(fieldIndex, row)) {
0:             Double val = (Double) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             Double val = (Double) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             Long val = (Long) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             byte[] bigDecimalInBytes = (byte[]) NonDictionaryUtil.getMeasure(fieldIndex, row);
/////////////////////////////////////////////////////////////////////////
0:         if (null != NonDictionaryUtil.getMeasure(fieldIndex, row)) {
0:             Double val = (Double) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             Double val = (Double) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             Long val = (Long) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:             byte[] bigDecimalInBytes = (byte[]) NonDictionaryUtil.getMeasure(fieldIndex, row);
commit:496cde4
/////////////////////////////////////////////////////////////////////////
0:   private boolean useKettle;
1: 
0:   private boolean[] noDictionarycolumnMapping;
1: 
/////////////////////////////////////////////////////////////////////////
0:     this.useKettle = mergerParameters.isUseKettle();
0:     noDictionarycolumnMapping = mergerParameters.getNoDictionaryDimnesionColumn();
/////////////////////////////////////////////////////////////////////////
0:       if (useKettle) {
0:         while (hasNext()) {
0:           writeDataTofile(next());
1:         }
0:       } else {
0:         while (hasNext()) {
0:           writeDataTofileWithOutKettle(next());
1:         }
/////////////////////////////////////////////////////////////////////////
0:               mergerParameters.getAggType(), mergerParameters.getNoDictionaryDimnesionColumn(),
0:               mergerParameters.isUseKettle());
/////////////////////////////////////////////////////////////////////////
0:    * TODO Remove it after kettle is removed
1:    *
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * Below method will be used to write data to file
1:    *
0:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
0:   private void writeDataTofileWithOutKettle(Object[] row) throws CarbonSortKeyAndGroupByException {
0:     if (mergerParameters.isSortFileCompressionEnabled() || mergerParameters.isPrefetch()) {
0:       if (entryCount == 0) {
0:         records = new Object[totalSize][];
0:         records[entryCount++] = row;
0:         return;
1:       }
1: 
0:       records[entryCount++] = row;
0:       if (entryCount == totalSize) {
0:         this.writer.writeSortTempFile(records);
0:         entryCount = 0;
0:         records = new Object[totalSize][];
1:       }
0:       return;
1:     }
1:     try {
0:       char[] aggType = mergerParameters.getAggType();
0:       int[] mdkArray = (int[]) row[0];
0:       byte[][] nonDictArray = (byte[][]) row[1];
0:       int mdkIndex = 0;
0:       int nonDictKeyIndex = 0;
0:       // write dictionary and non dictionary dimensions here.
0:       for (boolean nodictinary : noDictionarycolumnMapping) {
0:         if (nodictinary) {
0:           byte[] col = nonDictArray[nonDictKeyIndex++];
0:           stream.writeShort(col.length);
0:           stream.write(col);
0:         } else {
0:           stream.writeInt(mdkArray[mdkIndex++]);
1:         }
1:       }
1: 
0:       int fieldIndex = 0;
0:       for (int counter = 0; counter < mergerParameters.getMeasureColCount(); counter++) {
0:         if (null != RemoveDictionaryUtil.getMeasure(fieldIndex, row)) {
0:           stream.write((byte) 1);
0:           if (aggType[counter] == CarbonCommonConstants.BYTE_VALUE_MEASURE) {
0:             Double val = (Double) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeDouble(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:             Double val = (Double) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeDouble(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:             Long val = (Long) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeLong(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:             byte[] bigDecimalInBytes = (byte[]) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeInt(bigDecimalInBytes.length);
0:             stream.write(bigDecimalInBytes);
1:           }
0:         } else {
0:           stream.write((byte) 0);
1:         }
1: 
0:         fieldIndex++;
1:       }
1: 
0:     } catch (IOException e) {
0:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
1:     }
1:   }
1: 
commit:9aee980
/////////////////////////////////////////////////////////////////////////
1:   private SortParameters mergerParameters;
1: 
1:   private File[] intermediateFiles;
1: 
1:   private File outPutFile;
1:   public IntermediateFileMerger(SortParameters mergerParameters, File[] intermediateFiles,
1:       File outPutFile) {
1:     this.fileCounter = intermediateFiles.length;
1:     this.intermediateFiles = intermediateFiles;
1:     this.outPutFile = outPutFile;
/////////////////////////////////////////////////////////////////////////
0:       if (mergerParameters.isSortFileCompressionEnabled() || mergerParameters.isPrefetch()) {
/////////////////////////////////////////////////////////////////////////
0:         if (outPutFile.delete()) {
/////////////////////////////////////////////////////////////////////////
0:     if (!mergerParameters.isSortFileCompressionEnabled() && !mergerParameters.isPrefetch()) {
0:             new BufferedOutputStream(new FileOutputStream(outPutFile),
/////////////////////////////////////////////////////////////////////////
0:           .getTempSortFileWriter(mergerParameters.isSortFileCompressionEnabled(),
0:       writer.initiaize(outPutFile, totalNumberOfRecords);
0:         totalSize = mergerParameters.getBufferSize();
0:         totalSize = mergerParameters.getSortTempFileNoOFRecordsInCompression();
/////////////////////////////////////////////////////////////////////////
1:     createRecordHolderQueue(intermediateFiles);
1:     for (File tempFile : intermediateFiles) {
0:               mergerParameters.getFileBufferSize(), mergerParameters.getNoDictionaryCount(),
0:               mergerParameters.getAggType(), mergerParameters.getNoDictionaryDimnesionColumn());
/////////////////////////////////////////////////////////////////////////
0:     if (mergerParameters.isSortFileCompressionEnabled() || mergerParameters.isPrefetch()) {
/////////////////////////////////////////////////////////////////////////
1:       CarbonUtil.deleteFiles(intermediateFiles);
commit:cd6a4ff
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.sortandgroupby.sortdata;
1: 
0: import java.io.BufferedOutputStream;
1: import java.io.DataOutputStream;
1: import java.io.File;
1: import java.io.FileNotFoundException;
0: import java.io.FileOutputStream;
1: import java.io.IOException;
1: import java.util.AbstractQueue;
1: import java.util.PriorityQueue;
0: import java.util.concurrent.Callable;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.core.util.CarbonUtilException;
0: import org.apache.carbondata.processing.sortandgroupby.exception.CarbonSortKeyAndGroupByException;
0: import org.apache.carbondata.processing.util.RemoveDictionaryUtil;
1: 
0: public class IntermediateFileMerger implements Callable<Void> {
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(IntermediateFileMerger.class.getName());
1: 
1:   /**
1:    * recordHolderHeap
1:    */
1:   private AbstractQueue<SortTempFileChunkHolder> recordHolderHeap;
1: 
1:   /**
1:    * fileCounter
1:    */
1:   private int fileCounter;
1: 
1:   /**
1:    * stream
1:    */
1:   private DataOutputStream stream;
1: 
1:   /**
1:    * totalNumberOfRecords
1:    */
1:   private int totalNumberOfRecords;
1: 
1:   /**
0:    * records
1:    */
0:   private Object[][] records;
1: 
1:   /**
0:    * entryCount
1:    */
0:   private int entryCount;
1: 
1:   /**
0:    * writer
1:    */
0:   private TempSortFileWriter writer;
1: 
1:   /**
0:    * totalSize
1:    */
0:   private int totalSize;
1: 
0:   private FileMergerParameters mergerParameters;
1: 
1:   /**
1:    * IntermediateFileMerger Constructor
1:    */
0:   public IntermediateFileMerger(FileMergerParameters mergerParameters) {
1:     this.mergerParameters = mergerParameters;
0:     this.fileCounter = mergerParameters.getIntermediateFiles().length;
0:   }
1: 
0:   @Override public Void call() throws Exception {
1:     long intermediateMergeStartTime = System.currentTimeMillis();
1:     int fileConterConst = fileCounter;
0:     boolean isFailed = false;
1:     try {
1:       startSorting();
1:       initialize();
1: 
0:       while (hasNext()) {
0:         writeDataTofile(next());
0:       }
0:       if (mergerParameters.isCompressionEnabled() || mergerParameters.isPrefetch()) {
0:         if (entryCount > 0) {
0:           if (entryCount < totalSize) {
0:             Object[][] temp = new Object[entryCount][];
0:             System.arraycopy(records, 0, temp, 0, entryCount);
0:             records = temp;
0:             this.writer.writeSortTempFile(temp);
0:           } else {
0:             this.writer.writeSortTempFile(records);
0:           }
0:         }
0:       }
0:       double intermediateMergeCostTime = (System.currentTimeMillis() -
0:           intermediateMergeStartTime)/1000.0;
1:       LOGGER.info("============================== Intermediate Merge of " + fileConterConst +
1:           " Sort Temp Files Cost Time: " + intermediateMergeCostTime + "(s)");
1:     } catch (Exception e) {
1:       LOGGER.error(e, "Problem while intermediate merging");
0:       isFailed = true;
1:     } finally {
0:       records = null;
1:       CarbonUtil.closeStreams(this.stream);
0:       if (null != writer) {
0:         writer.finish();
0:       }
0:       if (!isFailed) {
1:         try {
1:           finish();
1:         } catch (CarbonSortKeyAndGroupByException e) {
1:           LOGGER.error(e, "Problem while deleting the merge file");
0:         }
0:       } else {
0:         if (mergerParameters.getOutFile().delete()) {
1:           LOGGER.error("Problem while deleting the merge file");
0:         }
0:       }
0:     }
1: 
0:     return null;
0:   }
1: 
1:   /**
1:    * This method is responsible for initializing the out stream
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   private void initialize() throws CarbonSortKeyAndGroupByException {
0:     if (!mergerParameters.isCompressionEnabled() && !mergerParameters.isPrefetch()) {
1:       try {
0:         this.stream = new DataOutputStream(
0:             new BufferedOutputStream(new FileOutputStream(mergerParameters.getOutFile()),
0:                 mergerParameters.getFileWriteBufferSize()));
0:         this.stream.writeInt(this.totalNumberOfRecords);
0:       } catch (FileNotFoundException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problem while getting the file", e);
0:       } catch (IOException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problem while writing the data to file", e);
0:       }
0:     } else {
0:       writer = TempSortFileWriterFactory.getInstance()
0:           .getTempSortFileWriter(mergerParameters.isCompressionEnabled(),
0:               mergerParameters.getDimColCount(), mergerParameters.getComplexDimColCount(),
0:               mergerParameters.getMeasureColCount(), mergerParameters.getNoDictionaryCount(),
0:               mergerParameters.getFileWriteBufferSize());
0:       writer.initiaize(mergerParameters.getOutFile(), totalNumberOfRecords);
1: 
0:       if (mergerParameters.isPrefetch()) {
0:         totalSize = mergerParameters.getPrefetchBufferSize();
0:       } else {
0:         totalSize = mergerParameters.getNoOfRecordsInCompression();
0:       }
0:     }
0:   }
1: 
1:   /**
0:    * This method will be used to get the sorted record from file
1:    *
1:    * @return sorted record sorted record
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] getSortedRecordFromFile() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = null;
1: 
1:     // poll the top object from heap
1:     // heap maintains binary tree which is based on heap condition that will
1:     // be based on comparator we are passing the heap
1:     // when will call poll it will always delete root of the tree and then
1:     // it does trickel down operation complexity is log(n)
1:     SortTempFileChunkHolder poll = this.recordHolderHeap.poll();
1: 
1:     // get the row from chunk
1:     row = poll.getRow();
1: 
1:     // check if there no entry present
1:     if (!poll.hasNext()) {
1:       // if chunk is empty then close the stream
1:       poll.closeStream();
1: 
1:       // change the file counter
1:       --this.fileCounter;
1: 
1:       // reaturn row
1:       return row;
0:     }
1: 
1:     // read new row
1:     poll.readRow();
1: 
1:     // add to heap
1:     this.recordHolderHeap.add(poll);
1: 
1:     // return row
1:     return row;
0:   }
1: 
1:   /**
1:    * Below method will be used to start storing process This method will get
1:    * all the temp files present in sort temp folder then it will create the
1:    * record holder heap and then it will read first record from each file and
1:    * initialize the heap
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   private void startSorting() throws CarbonSortKeyAndGroupByException {
1:     LOGGER.info("Number of temp file: " + this.fileCounter);
1: 
1:     // create record holder heap
0:     createRecordHolderQueue(mergerParameters.getIntermediateFiles());
1: 
1:     // iterate over file list and create chunk holder and add to heap
1:     LOGGER.info("Started adding first record from each file");
1: 
1:     SortTempFileChunkHolder sortTempFileChunkHolder = null;
1: 
0:     for (File tempFile : mergerParameters.getIntermediateFiles()) {
1:       // create chunk holder
1:       sortTempFileChunkHolder =
0:           new SortTempFileChunkHolder(tempFile, mergerParameters.getDimColCount(),
0:               mergerParameters.getComplexDimColCount(), mergerParameters.getMeasureColCount(),
0:               mergerParameters.getFileReadBufferSize(), mergerParameters.getNoDictionaryCount(),
0:               mergerParameters.getAggType(), mergerParameters.getIsNoDictionaryDimensionColumn());
1: 
1:       // initialize
1:       sortTempFileChunkHolder.initialize();
1:       sortTempFileChunkHolder.readRow();
1:       this.totalNumberOfRecords += sortTempFileChunkHolder.getEntryCount();
1: 
1:       // add to heap
1:       this.recordHolderHeap.add(sortTempFileChunkHolder);
0:     }
1: 
0:     LOGGER.info("Heap Size" + this.recordHolderHeap.size());
0:   }
1: 
1:   /**
1:    * This method will be used to create the heap which will be used to hold
1:    * the chunk of data
1:    *
1:    * @param listFiles list of temp files
1:    */
1:   private void createRecordHolderQueue(File[] listFiles) {
1:     // creating record holder heap
0:     this.recordHolderHeap = new PriorityQueue<SortTempFileChunkHolder>(listFiles.length);
0:   }
1: 
1:   /**
0:    * This method will be used to get the sorted row
1:    *
1:    * @return sorted row
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] next() throws CarbonSortKeyAndGroupByException {
0:     return getSortedRecordFromFile();
0:   }
1: 
1:   /**
1:    * This method will be used to check whether any more element is present or
1:    * not
1:    *
1:    * @return more element is present
1:    */
1:   private boolean hasNext() {
1:     return this.fileCounter > 0;
0:   }
1: 
1:   /**
0:    * Below method will be used to write data to file
1:    *
0:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
0:   private void writeDataTofile(Object[] row) throws CarbonSortKeyAndGroupByException {
0:     if (mergerParameters.isCompressionEnabled() || mergerParameters.isPrefetch()) {
0:       if (entryCount == 0) {
0:         records = new Object[totalSize][];
0:         records[entryCount++] = row;
0:         return;
0:       }
1: 
0:       records[entryCount++] = row;
0:       if (entryCount == totalSize) {
0:         this.writer.writeSortTempFile(records);
0:         entryCount = 0;
0:         records = new Object[totalSize][];
0:       }
0:       return;
0:     }
1:     try {
0:       int fieldIndex = 0;
0:       char[] aggType = mergerParameters.getAggType();
1: 
0:       for (int counter = 0; counter < mergerParameters.getDimColCount(); counter++) {
0:         stream.writeInt((Integer) RemoveDictionaryUtil.getDimension(fieldIndex++, row));
0:       }
1: 
0:       // added for high card also
0:       if ((mergerParameters.getNoDictionaryCount() + mergerParameters
0:           .getComplexDimColCount()) > 0) {
0:         stream.write(RemoveDictionaryUtil.getByteArrayForNoDictionaryCols(row));
0:       }
1: 
0:       fieldIndex = 0;
0:       for (int counter = 0; counter < mergerParameters.getMeasureColCount(); counter++) {
0:         if (null != RemoveDictionaryUtil.getMeasure(fieldIndex, row)) {
0:           stream.write((byte) 1);
0:           if (aggType[counter] == CarbonCommonConstants.BYTE_VALUE_MEASURE) {
0:             Double val = (Double) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeDouble(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:             Double val = (Double) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeDouble(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:             Long val = (Long) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeLong(val);
0:           } else if (aggType[counter] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:             byte[] bigDecimalInBytes = (byte[]) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:             stream.writeInt(bigDecimalInBytes.length);
0:             stream.write(bigDecimalInBytes);
0:           }
0:         } else {
0:           stream.write((byte) 0);
0:         }
1: 
0:         fieldIndex++;
0:       }
1: 
0:     } catch (IOException e) {
0:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
0:     }
0:   }
1: 
1:   private void finish() throws CarbonSortKeyAndGroupByException {
0:     if (recordHolderHeap != null) {
0:       int size = recordHolderHeap.size();
0:       for (int i = 0; i < size; i++) {
0:         recordHolderHeap.poll().closeStream();
0:       }
0:     }
1:     try {
0:       CarbonUtil.deleteFiles(mergerParameters.getIntermediateFiles());
0:     } catch (CarbonUtilException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while deleting the intermediate files");
0:     }
0:   }
0: }
============================================================================
1:353272e: /*
1:353272e:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:353272e:  * contributor license agreements.  See the NOTICE file distributed with
1:353272e:  * this work for additional information regarding copyright ownership.
1:353272e:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:353272e:  * (the "License"); you may not use this file except in compliance with
1:353272e:  * the License.  You may obtain a copy of the License at
1:353272e:  *
1:353272e:  *    http://www.apache.org/licenses/LICENSE-2.0
1:353272e:  *
1:353272e:  * Unless required by applicable law or agreed to in writing, software
1:353272e:  * distributed under the License is distributed on an "AS IS" BASIS,
1:353272e:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:353272e:  * See the License for the specific language governing permissions and
1:353272e:  * limitations under the License.
1:353272e:  */
1:e710339: 
1:353272e: package org.apache.carbondata.processing.store;
11:353272e: 
1:353272e: import java.io.ByteArrayOutputStream;
1:353272e: import java.io.DataOutputStream;
1:353272e: import java.io.IOException;
1:353272e: import java.nio.ByteBuffer;
1:353272e: import java.util.ArrayList;
1:e6a4f64: import java.util.Arrays;
1:8c1ddbf: import java.util.HashMap;
1:353272e: import java.util.List;
1:8c1ddbf: import java.util.Map;
1:353272e: 
1:8c1ddbf: import org.apache.carbondata.core.datastore.ColumnType;
1:9e064ee: import org.apache.carbondata.core.datastore.TableSpec;
1:dc83b2a: import org.apache.carbondata.core.datastore.exception.CarbonDataWriterException;
1:dc83b2a: import org.apache.carbondata.core.datastore.page.ColumnPage;
1:353272e: import org.apache.carbondata.core.datastore.page.ComplexColumnPage;
1:bc3e684: import org.apache.carbondata.core.datastore.page.EncodedTablePage;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.encoding.ColumnPageEncoder;
1:8f08c4a: import org.apache.carbondata.core.datastore.page.encoding.ColumnPageEncoderMeta;
1:8c1ddbf: import org.apache.carbondata.core.datastore.page.encoding.DefaultEncodingFactory;
1:a5af0ff: import org.apache.carbondata.core.datastore.page.encoding.EncodedColumnPage;
1:8c1ddbf: import org.apache.carbondata.core.datastore.page.encoding.EncodingFactory;
1:bc3e684: import org.apache.carbondata.core.datastore.page.key.TablePageKey;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.statistics.KeyPageStatsCollector;
1:dc53dee: import org.apache.carbondata.core.datastore.page.statistics.LVLongStringStatsCollector;
1:dc53dee: import org.apache.carbondata.core.datastore.page.statistics.LVShortStringStatsCollector;
1:bc3e684: import org.apache.carbondata.core.datastore.page.statistics.PrimitivePageStatsCollector;
1:dc83b2a: import org.apache.carbondata.core.datastore.row.CarbonRow;
1:438b442: import org.apache.carbondata.core.datastore.row.ComplexColumnInfo;
1:dc83b2a: import org.apache.carbondata.core.datastore.row.WriteStepRowUtil;
1:353272e: import org.apache.carbondata.core.keygenerator.KeyGenException;
1:e710339: import org.apache.carbondata.core.localdictionary.generator.LocalDictionaryGenerator;
1:7359601: import org.apache.carbondata.core.memory.MemoryException;
1:353272e: import org.apache.carbondata.core.metadata.datatype.DataType;
1:956833e: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:982d03f: import org.apache.carbondata.core.util.DataTypeUtil;
1:f089287: import org.apache.carbondata.processing.datatypes.GenericDataType;
1:7359601: 
1:353272e: /**
1:353272e:  * Represent a page data for all columns, we store its data in columnar layout, so that
1:353272e:  * all processing apply to TablePage can be done in vectorized fashion.
1:353272e:  */
1:dc83b2a: public class TablePage {
1:353272e: 
1:353272e:   // For all dimension and measure columns, we store the column data directly in the page,
1:353272e:   // the length of the page is the number of rows.
1:353272e: 
1:353272e:   // TODO: we should have separate class for key columns so that keys are stored together in
1:353272e:   // one vector to make it efficient for sorting
1:a5af0ff:   private ColumnPage[] dictDimensionPages;
1:a5af0ff:   private ColumnPage[] noDictDimensionPages;
1:e6a4f64:   private ColumnPage[] measurePages;
1:e710339:   private ComplexColumnPage[] complexDimensionPages;
1:dc83b2a: 
1:353272e:   // the num of rows in this page, it must be less than short value (65536)
1:353272e:   private int pageSize;
1:353272e: 
1:353272e:   private CarbonFactDataHandlerModel model;
1:353272e: 
1:bc3e684:   private TablePageKey key;
1:bc3e684: 
1:f089287:   private EncodedTablePage encodedTablePage;
1:f089287: 
1:8c1ddbf:   private EncodingFactory encodingFactory = DefaultEncodingFactory.getInstance();
1:f089287: 
1:f089287:   // true if it is last page of all input rows
1:f089287:   private boolean isLastPage;
1:bc3e684: 
1:8c1ddbf:   // used for complex column to deserilize the byte array in input CarbonRow
1:8c1ddbf:   private Map<Integer, GenericDataType> complexIndexMap = null;
1:8f08c4a:   // name of compressor that used to compress column data,
1:8f08c4a:   // currently all the columns share the same compressor.
1:8f08c4a:   private String columnCompressor;
1:8c1ddbf: 
1:7359601:   TablePage(CarbonFactDataHandlerModel model, int pageSize) throws MemoryException {
1:353272e:     this.model = model;
1:353272e:     this.pageSize = pageSize;
1:edda248:     int numDictDimension = model.getMDKeyGenerator().getDimCount();
1:8c1ddbf:     TableSpec tableSpec = model.getTableSpec();
1:8f08c4a:     this.columnCompressor = model.getColumnCompressor();
1:18dc3ff: 
1:a5af0ff:     dictDimensionPages = new ColumnPage[numDictDimension];
1:a5af0ff:     noDictDimensionPages = new ColumnPage[model.getNoDictionaryCount()];
1:18dc3ff:     int tmpNumDictDimIdx = 0;
1:18dc3ff:     int tmpNumNoDictDimIdx = 0;
1:18dc3ff:     for (int i = 0; i < dictDimensionPages.length + noDictDimensionPages.length; i++) {
1:18dc3ff:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i);
1:18dc3ff:       ColumnType columnType = tableSpec.getDimensionSpec(i).getColumnType();
1:dc53dee:       ColumnPage page;
1:18dc3ff:       if (ColumnType.GLOBAL_DICTIONARY == columnType
1:18dc3ff:           || ColumnType.DIRECT_DICTIONARY == columnType) {
1:8f08c4a:         page = ColumnPage.newPage(
1:8f08c4a:             new ColumnPageEncoderMeta(spec, DataTypes.BYTE_ARRAY, columnCompressor), pageSize);
1:18dc3ff:         page.setStatsCollector(KeyPageStatsCollector.newInstance(DataTypes.BYTE_ARRAY));
1:18dc3ff:         dictDimensionPages[tmpNumDictDimIdx++] = page;
1:dc53dee:       } else {
1:18dc3ff:         // will be encoded using string page
1:e710339:         LocalDictionaryGenerator localDictionaryGenerator =
1:e710339:             model.getColumnLocalDictGenMap().get(spec.getFieldName());
1:e710339:         DataType dataType = DataTypes.STRING;
1:18dc3ff:         if (DataTypes.VARCHAR == spec.getSchemaDataType()) {
1:e710339:           dataType = DataTypes.VARCHAR;
1:e710339:         }
1:8f08c4a:         ColumnPageEncoderMeta columnPageEncoderMeta =
1:8f08c4a:             new ColumnPageEncoderMeta(spec, dataType, columnCompressor);
1:e710339:         if (null != localDictionaryGenerator) {
1:8f08c4a:           page = ColumnPage.newLocalDictPage(
1:8f08c4a:               columnPageEncoderMeta, pageSize, localDictionaryGenerator, false);
1:e710339:         } else {
1:8f08c4a:           page = ColumnPage.newPage(columnPageEncoderMeta, pageSize);
1:e710339:         }
1:e710339:         if (DataTypes.VARCHAR == dataType) {
1:18dc3ff:           page.setStatsCollector(LVLongStringStatsCollector.newInstance());
1:18dc3ff:         } else {
1:18dc3ff:           page.setStatsCollector(LVShortStringStatsCollector.newInstance());
1:18dc3ff:         }
1:18dc3ff:         noDictDimensionPages[tmpNumNoDictDimIdx++] = page;
1:dc53dee:       }
1:bc3e684:     }
1:a5af0ff:     complexDimensionPages = new ComplexColumnPage[model.getComplexColumnCount()];
1:a5af0ff:     for (int i = 0; i < complexDimensionPages.length; i++) {
1:353272e:       // here we still do not the depth of the complex column, it will be initialized when
1:353272e:       // we get the first row.
1:a5af0ff:       complexDimensionPages[i] = null;
1:bc3e684:     }
1:e6a4f64:     measurePages = new ColumnPage[model.getMeasureCount()];
1:353272e:     DataType[] dataTypes = model.getMeasureDataType();
1:e6a4f64:     for (int i = 0; i < measurePages.length; i++) {
1:8f08c4a:       ColumnPageEncoderMeta columnPageEncoderMeta = new ColumnPageEncoderMeta(
1:8f08c4a:           model.getTableSpec().getMeasureSpec(i), dataTypes[i], columnCompressor);
1:e6a4f64:       ColumnPage page;
1:8f08c4a:       if (DataTypes.isDecimal(columnPageEncoderMeta.getSchemaDataType())) {
1:8f08c4a:         page = ColumnPage.newDecimalPage(columnPageEncoderMeta, pageSize);
1:e6a4f64:       } else {
1:8f08c4a:         page = ColumnPage.newPage(columnPageEncoderMeta, pageSize);
1:e6a4f64:       }
1:8f08c4a:       page.setStatsCollector(PrimitivePageStatsCollector.newInstance(dataTypes[i]));
1:e6a4f64:       measurePages[i] = page;
1:bc3e684:     }
1:18dc3ff: 
1:a5af0ff:     boolean hasNoDictionary = noDictDimensionPages.length > 0;
1:40c7e8e:     this.key = new TablePageKey(pageSize, model.getSegmentProperties(), hasNoDictionary);
1:8c1ddbf: 
1:8c1ddbf:     // for complex type, `complexIndexMap` is used in multithread (in multiple Producer),
1:8c1ddbf:     // we need to clone the index map to make it thread safe
1:8c1ddbf:     this.complexIndexMap = new HashMap<>();
1:8c1ddbf:     for (Map.Entry<Integer, GenericDataType> entry: model.getComplexIndexMap().entrySet()) {
1:8c1ddbf:       this.complexIndexMap.put(entry.getKey(), entry.getValue().deepCopy());
1:8c1ddbf:     }
1:bc3e684:   }
1:dc83b2a: 
1:353272e:   /**
1:bc3e684:    * Add one row to the internal store
1:353272e:    *
1:353272e:    * @param rowId Id of the input row
1:353272e:    * @param row   row object
1:353272e:    */
1:edda248:   public void addRow(int rowId, CarbonRow row) throws KeyGenException {
1:bc3e684:     // convert each column category, update key and stats
1:353272e:     byte[] mdk = WriteStepRowUtil.getMdk(row, model.getMDKeyGenerator());
1:bc3e684:     convertToColumnarAndAddToPages(rowId, row, mdk);
1:bc3e684:     key.update(rowId, row, mdk);
1:bc3e684:   }
1:bc3e684: 
1:bc3e684:   // convert the input row object to columnar data and add to column pages
1:bc3e684:   private void convertToColumnarAndAddToPages(int rowId, CarbonRow row, byte[] mdk)
1:bc3e684:       throws KeyGenException {
1:bc3e684:     // 1. convert dictionary columns
1:353272e:     byte[][] keys = model.getSegmentProperties().getFixedLengthKeySplitter().splitKey(mdk);
1:a5af0ff:     for (int i = 0; i < dictDimensionPages.length; i++) {
1:a5af0ff:       dictDimensionPages[i].putData(rowId, keys[i]);
1:bc3e684:     }
1:dc83b2a: 
1:dc53dee:     // 2. convert noDictionary columns and complex columns and varchar columns.
1:a5af0ff:     int noDictionaryCount = noDictDimensionPages.length;
1:a5af0ff:     int complexColumnCount = complexDimensionPages.length;
1:353272e:     if (noDictionaryCount > 0 || complexColumnCount > 0) {
1:dc53dee:       TableSpec tableSpec = model.getTableSpec();
1:353272e:       byte[][] noDictAndComplex = WriteStepRowUtil.getNoDictAndComplexDimension(row);
1:353272e:       for (int i = 0; i < noDictAndComplex.length; i++) {
1:dc53dee:         if (tableSpec.getDimensionSpec(dictDimensionPages.length + i).getSchemaDataType()
1:dc53dee:             == DataTypes.VARCHAR) {
1:dc53dee:           byte[] valueWithLength = addIntLengthToByteArray(noDictAndComplex[i]);
1:dc53dee:           noDictDimensionPages[i].putData(rowId, valueWithLength);
1:dc53dee:         } else if (i < noDictionaryCount) {
1:353272e:           // noDictionary columns, since it is variable length, we need to prepare each
1:dc83b2a:           // element as LV result byte array (first two bytes are the length of the array)
1:dc53dee:           byte[] valueWithLength = addShortLengthToByteArray(noDictAndComplex[i]);
1:a5af0ff:           noDictDimensionPages[i].putData(rowId, valueWithLength);
10:bc3e684:         } else {
1:353272e:           // complex columns
1:353272e:           addComplexColumn(i - noDictionaryCount, rowId, noDictAndComplex[i]);
1:bc3e684:         }
1:bc3e684:       }
1:bc3e684:     }
1:353272e: 
1:353272e:     // 3. convert measure columns
1:353272e:     Object[] measureColumns = WriteStepRowUtil.getMeasure(row);
1:e6a4f64:     for (int i = 0; i < measurePages.length; i++) {
1:353272e:       Object value = measureColumns[i];
1:353272e: 
1:353272e:       // in compaction flow the measure with decimal type will come as Spark decimal.
1:353272e:       // need to convert it to byte array.
1:f209e8e:       if (DataTypes.isDecimal(measurePages[i].getDataType()) &&
1:dc83b2a:           model.isCompactionFlow() &&
1:dc83b2a:           value != null) {
1:982d03f:         value = DataTypeUtil.getDataTypeConverter().convertFromDecimalToBigDecimal(value);
1:bc3e684:       }
1:e6a4f64:       measurePages[i].putData(rowId, value);
1:bc3e684:     }
1:edda248:   }
1:dc83b2a: 
1:353272e:   /**
1:3202cf5:    * add a complex column into internal member complexDimensionPage
1:353272e:    *
1:353272e:    * @param index          index of the complexDimensionPage
1:353272e:    * @param rowId          Id of the input row
1:353272e:    * @param complexColumns byte array the complex columm to be added, extracted of input row
1:353272e:    */
1:353272e:   // TODO: this function should be refactoried, ColumnPage should support complex type encoding
1:353272e:   // directly instead of doing it here
1:353272e:   private void addComplexColumn(int index, int rowId, byte[] complexColumns) {
1:8c1ddbf:     GenericDataType complexDataType = complexIndexMap.get(
1:353272e:         index + model.getPrimitiveDimLens().length);
1:353272e: 
1:353272e:     // initialize the page if first row
1:353272e:     if (rowId == 0) {
1:438b442:       List<ComplexColumnInfo> complexColumnInfoList = new ArrayList<>();
1:438b442:       complexDataType.getComplexColumnInfo(complexColumnInfoList);
1:438b442:       complexDimensionPages[index] = new ComplexColumnPage(complexColumnInfoList);
1:e710339:       try {
1:8f08c4a:         complexDimensionPages[index].initialize(
1:8f08c4a:             model.getColumnLocalDictGenMap(), pageSize, columnCompressor);
1:e710339:       } catch (MemoryException e) {
1:e710339:         throw new RuntimeException(e);
1:e710339:       }
1:edda248:     }
1:353272e: 
1:438b442:     int depthInComplexColumn = complexDimensionPages[index].getComplexColumnIndex();
1:dc83b2a:     // this is the result columnar data which will be added to page,
1:353272e:     // size of this list is the depth of complex column, we will fill it by input data
1:a5af0ff:     List<ArrayList<byte[]>> encodedComplexColumnar = new ArrayList<>(depthInComplexColumn);
1:353272e:     for (int k = 0; k < depthInComplexColumn; k++) {
1:353272e:       encodedComplexColumnar.add(new ArrayList<byte[]>());
1:dc83b2a:     }
1:353272e: 
1:edda248:     // apply the complex type data and fill columnsArray
1:353272e:     try {
1:353272e:       ByteBuffer byteArrayInput = ByteBuffer.wrap(complexColumns);
1:353272e:       ByteArrayOutputStream byteArrayOutput = new ByteArrayOutputStream();
1:353272e:       DataOutputStream dataOutputStream = new DataOutputStream(byteArrayOutput);
1:3202cf5:       complexDataType.parseComplexValue(byteArrayInput, dataOutputStream,
1:353272e:           model.getComplexDimensionKeyGenerator());
1:353272e:       complexDataType.getColumnarDataForComplexType(encodedComplexColumnar,
1:353272e:           ByteBuffer.wrap(byteArrayOutput.toByteArray()));
1:353272e:       byteArrayOutput.close();
1:353272e:     } catch (IOException | KeyGenException e) {
1:353272e:       throw new CarbonDataWriterException("Problem while bit packing and writing complex datatype",
1:353272e:           e);
1:dc83b2a:     }
1:353272e: 
1:353272e:     for (int depth = 0; depth < depthInComplexColumn; depth++) {
1:e710339:       complexDimensionPages[index].putComplexData(depth, encodedComplexColumnar.get(depth));
1:dc83b2a:     }
21:353272e:   }
1:353272e: 
1:7359601:   void freeMemory() {
1:a5af0ff:     for (ColumnPage page : dictDimensionPages) {
1:7359601:       page.freeMemory();
1:7359601:     }
1:a5af0ff:     for (ColumnPage page : noDictDimensionPages) {
1:7359601:       page.freeMemory();
1:7359601:     }
1:e6a4f64:     for (ColumnPage page : measurePages) {
1:7359601:       page.freeMemory();
1:7359601:     }
1:e710339:     for (ComplexColumnPage page : complexDimensionPages) {
1:e710339:       if (null != page) {
1:e710339:         page.freeMemory();
1:e710339:       }
1:e710339:     }
1:7359601:   }
1:7359601: 
1:353272e:   // Adds length as a short element (first 2 bytes) to the head of the input byte array
1:dc53dee:   private byte[] addShortLengthToByteArray(byte[] input) {
1:7359601:     if (input.length > Short.MAX_VALUE) {
1:7359601:       throw new RuntimeException("input data length " + input.length +
1:7359601:           " bytes too long, maximum length supported is " + Short.MAX_VALUE + " bytes");
1:7359601:     }
1:353272e:     byte[] output = new byte[input.length + 2];
1:353272e:     ByteBuffer buffer = ByteBuffer.wrap(output);
1:7359601:     buffer.putShort((short)input.length);
1:353272e:     buffer.put(input, 0, input.length);
1:353272e:     return output;
1:bc3e684:   }
1:353272e: 
1:dc53dee:   // Adds length as a integer element (first 4 bytes) to the head of the input byte array
1:dc53dee:   private byte[] addIntLengthToByteArray(byte[] input) {
1:dc53dee:     byte[] output = new byte[input.length + 4];
1:dc53dee:     ByteBuffer buffer = ByteBuffer.wrap(output);
1:dc53dee:     buffer.putInt(input.length);
1:dc53dee:     buffer.put(input, 0, input.length);
1:dc53dee:     return output;
1:dc53dee:   }
1:dc53dee: 
1:f089287:   void encode() throws KeyGenException, MemoryException, IOException {
1:bc3e684:     // encode dimensions and measure
1:e6a4f64:     EncodedColumnPage[] dimensions = encodeAndCompressDimensions();
1:e6a4f64:     EncodedColumnPage[] measures = encodeAndCompressMeasures();
1:f089287:     this.encodedTablePage = EncodedTablePage.newInstance(pageSize, dimensions, measures, key);
1:bc3e684:   }
1:bc3e684: 
1:f089287:   public EncodedTablePage getEncodedTablePage() {
1:f089287:     return encodedTablePage;
1:f089287:   }
1:353272e: 
1:bc3e684:   // apply measure and set encodedData in `encodedData`
1:e6a4f64:   private EncodedColumnPage[] encodeAndCompressMeasures()
1:bc3e684:       throws MemoryException, IOException {
1:e6a4f64:     EncodedColumnPage[] encodedMeasures = new EncodedColumnPage[measurePages.length];
1:e6a4f64:     for (int i = 0; i < measurePages.length; i++) {
1:8c1ddbf:       ColumnPageEncoder encoder = encodingFactory.createEncoder(
1:e6a4f64:           model.getTableSpec().getMeasureSpec(i), measurePages[i]);
1:e6a4f64:       encodedMeasures[i] = encoder.encode(measurePages[i]);
1:bc3e684:     }
1:bc3e684:     return encodedMeasures;
1:bc3e684:   }
1:bc3e684: 
1:bc3e684:   // apply and compress each dimension, set encoded data in `encodedData`
1:e6a4f64:   private EncodedColumnPage[] encodeAndCompressDimensions()
1:a5af0ff:       throws KeyGenException, IOException, MemoryException {
1:e6a4f64:     List<EncodedColumnPage> encodedDimensions = new ArrayList<>();
1:e6a4f64:     List<EncodedColumnPage> encodedComplexDimenions = new ArrayList<>();
1:a5af0ff:     TableSpec tableSpec = model.getTableSpec();
1:a5af0ff:     int dictIndex = 0;
1:a5af0ff:     int noDictIndex = 0;
1:a5af0ff:     int complexDimIndex = 0;
1:a5af0ff:     int numDimensions = tableSpec.getNumDimensions();
1:a5af0ff:     for (int i = 0; i < numDimensions; i++) {
1:e6a4f64:       ColumnPageEncoder columnPageEncoder;
1:e6a4f64:       EncodedColumnPage encodedPage;
1:8c1ddbf:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i);
1:8c1ddbf:       switch (spec.getColumnType()) {
1:bc3e684:         case GLOBAL_DICTIONARY:
1:bc3e684:         case DIRECT_DICTIONARY:
1:8c1ddbf:           columnPageEncoder = encodingFactory.createEncoder(
1:e6a4f64:               spec,
1:e6a4f64:               dictDimensionPages[dictIndex]);
1:e6a4f64:           encodedPage = columnPageEncoder.encode(dictDimensionPages[dictIndex++]);
1:a5af0ff:           encodedDimensions.add(encodedPage);
2:bc3e684:           break;
1:bc3e684:         case PLAIN_VALUE:
1:8c1ddbf:           columnPageEncoder = encodingFactory.createEncoder(
1:e6a4f64:               spec,
1:e6a4f64:               noDictDimensionPages[noDictIndex]);
1:e6a4f64:           encodedPage = columnPageEncoder.encode(noDictDimensionPages[noDictIndex++]);
1:a5af0ff:           encodedDimensions.add(encodedPage);
1:bc3e684:           break;
1:bc3e684:         case COMPLEX:
1:e6a4f64:           EncodedColumnPage[] encodedPages = ColumnPageEncoder.encodeComplexColumn(
1:a5af0ff:               complexDimensionPages[complexDimIndex++]);
1:e6a4f64:           encodedComplexDimenions.addAll(Arrays.asList(encodedPages));
1:a5af0ff:           break;
1:bb0b347:         default:
1:bb0b347:           throw new IllegalArgumentException("unsupported dimension type:" + spec
1:8c1ddbf:               .getColumnType());
1:a5af0ff:       }
1:bc3e684:     }
1:bc3e684: 
1:a5af0ff:     encodedDimensions.addAll(encodedComplexDimenions);
1:e6a4f64:     return encodedDimensions.toArray(new EncodedColumnPage[encodedDimensions.size()]);
1:bc3e684:   }
1:f089287: 
1:f089287:   /**
1:f089287:    * return column page of specified column name
1:f089287:    */
1:f089287:   public ColumnPage getColumnPage(String columnName) {
1:f089287:     int dictDimensionIndex = -1;
1:f089287:     int noDictDimensionIndex = -1;
1:f089287:     ColumnPage page = null;
1:f089287:     TableSpec spec = model.getTableSpec();
1:f089287:     int numDimensions = spec.getNumDimensions();
1:f089287:     for (int i = 0; i < numDimensions; i++) {
1:8c1ddbf:       ColumnType type = spec.getDimensionSpec(i).getColumnType();
1:8c1ddbf:       if ((type == ColumnType.GLOBAL_DICTIONARY) || (type == ColumnType.DIRECT_DICTIONARY)) {
1:f089287:         page = dictDimensionPages[++dictDimensionIndex];
1:8c1ddbf:       } else if (type == ColumnType.PLAIN_VALUE) {
1:f089287:         page = noDictDimensionPages[++noDictDimensionIndex];
1:f089287:       } else {
1:f089287:         // do not support datamap on complex column
1:f089287:         continue;
1:f089287:       }
1:f089287:       String fieldName = spec.getDimensionSpec(i).getFieldName();
1:f089287:       if (fieldName.equalsIgnoreCase(columnName)) {
1:f089287:         return page;
1:f089287:       }
1:f089287:     }
1:f089287:     int numMeasures = spec.getNumMeasures();
1:f089287:     for (int i = 0; i < numMeasures; i++) {
1:f089287:       String fieldName = spec.getMeasureSpec(i).getFieldName();
1:f089287:       if (fieldName.equalsIgnoreCase(columnName)) {
1:e6a4f64:         return measurePages[i];
1:f089287:       }
1:f089287:     }
1:f089287:     throw new IllegalArgumentException("DataMap: must have '" + columnName + "' column in schema");
1:f089287:   }
1:f089287: 
1:f089287:   public boolean isLastPage() {
1:f089287:     return isLastPage;
1:f089287:   }
1:f089287: 
1:f089287:   public void setIsLastPage(boolean isWriteAll) {
1:f089287:     this.isLastPage = isWriteAll;
1:f089287:   }
1:f089287: 
1:f089287:   public int getPageSize() {
1:f089287:     return pageSize;
1:f089287:   }
1:bc3e684: }
1:dc83b2a: 
1:dc83b2a: 
============================================================================
author:xuchuanyin
-------------------------------------------------------------------------------
commit:8f08c4a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.ColumnPageEncoderMeta;
/////////////////////////////////////////////////////////////////////////
1:   // name of compressor that used to compress column data,
1:   // currently all the columns share the same compressor.
1:   private String columnCompressor;
1:     this.columnCompressor = model.getColumnCompressor();
/////////////////////////////////////////////////////////////////////////
1:         page = ColumnPage.newPage(
1:             new ColumnPageEncoderMeta(spec, DataTypes.BYTE_ARRAY, columnCompressor), pageSize);
/////////////////////////////////////////////////////////////////////////
1:         ColumnPageEncoderMeta columnPageEncoderMeta =
1:             new ColumnPageEncoderMeta(spec, dataType, columnCompressor);
1:           page = ColumnPage.newLocalDictPage(
1:               columnPageEncoderMeta, pageSize, localDictionaryGenerator, false);
1:           page = ColumnPage.newPage(columnPageEncoderMeta, pageSize);
/////////////////////////////////////////////////////////////////////////
1:       ColumnPageEncoderMeta columnPageEncoderMeta = new ColumnPageEncoderMeta(
1:           model.getTableSpec().getMeasureSpec(i), dataTypes[i], columnCompressor);
1:       if (DataTypes.isDecimal(columnPageEncoderMeta.getSchemaDataType())) {
1:         page = ColumnPage.newDecimalPage(columnPageEncoderMeta, pageSize);
1:         page = ColumnPage.newPage(columnPageEncoderMeta, pageSize);
1:       page.setStatsCollector(PrimitivePageStatsCollector.newInstance(dataTypes[i]));
/////////////////////////////////////////////////////////////////////////
1:         complexDimensionPages[index].initialize(
1:             model.getColumnLocalDictGenMap(), pageSize, columnCompressor);
commit:18dc3ff
/////////////////////////////////////////////////////////////////////////
1: 
1:     int tmpNumDictDimIdx = 0;
1:     int tmpNumNoDictDimIdx = 0;
1:     for (int i = 0; i < dictDimensionPages.length + noDictDimensionPages.length; i++) {
1:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i);
1:       ColumnType columnType = tableSpec.getDimensionSpec(i).getColumnType();
1:       if (ColumnType.GLOBAL_DICTIONARY == columnType
1:           || ColumnType.DIRECT_DICTIONARY == columnType) {
0:         page = ColumnPage.newPage(spec, DataTypes.BYTE_ARRAY, pageSize);
1:         page.setStatsCollector(KeyPageStatsCollector.newInstance(DataTypes.BYTE_ARRAY));
1:         dictDimensionPages[tmpNumDictDimIdx++] = page;
1:         if (DataTypes.VARCHAR == spec.getSchemaDataType()) {
0:           page = ColumnPage.newPage(spec, DataTypes.VARCHAR, pageSize);
1:           page.setStatsCollector(LVLongStringStatsCollector.newInstance());
1:         } else {
0:           // In previous implementation, other data types such as string, date and timestamp
1:           // will be encoded using string page
0:           page = ColumnPage.newPage(spec, DataTypes.STRING, pageSize);
1:           page.setStatsCollector(LVShortStringStatsCollector.newInstance());
1:         }
1:         noDictDimensionPages[tmpNumNoDictDimIdx++] = page;
1: 
commit:dc53dee
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.statistics.LVLongStringStatsCollector;
1: import org.apache.carbondata.core.datastore.page.statistics.LVShortStringStatsCollector;
/////////////////////////////////////////////////////////////////////////
1:       ColumnPage page;
0:       if (DataTypes.VARCHAR == spec.getSchemaDataType()) {
0:         page = ColumnPage.newPage(spec, DataTypes.VARCHAR, pageSize);
0:         page.setStatsCollector(LVLongStringStatsCollector.newInstance());
1:       } else {
0:         // In previous implementation, other data types such as string, date and timestamp
0:         // will be encoded using string page
0:         page = ColumnPage.newPage(spec, DataTypes.STRING, pageSize);
0:         page.setStatsCollector(LVShortStringStatsCollector.newInstance());
1:       }
/////////////////////////////////////////////////////////////////////////
1:     // 2. convert noDictionary columns and complex columns and varchar columns.
1:       TableSpec tableSpec = model.getTableSpec();
1:         if (tableSpec.getDimensionSpec(dictDimensionPages.length + i).getSchemaDataType()
1:             == DataTypes.VARCHAR) {
1:           byte[] valueWithLength = addIntLengthToByteArray(noDictAndComplex[i]);
1:           noDictDimensionPages[i].putData(rowId, valueWithLength);
1:         } else if (i < noDictionaryCount) {
1:           byte[] valueWithLength = addShortLengthToByteArray(noDictAndComplex[i]);
/////////////////////////////////////////////////////////////////////////
1:   private byte[] addShortLengthToByteArray(byte[] input) {
/////////////////////////////////////////////////////////////////////////
1:   // Adds length as a integer element (first 4 bytes) to the head of the input byte array
1:   private byte[] addIntLengthToByteArray(byte[] input) {
1:     byte[] output = new byte[input.length + 4];
1:     ByteBuffer buffer = ByteBuffer.wrap(output);
1:     buffer.putInt(input.length);
1:     buffer.put(input, 0, input.length);
1:     return output;
1:   }
1: 
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:438b442
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.row.ComplexColumnInfo;
/////////////////////////////////////////////////////////////////////////
1:       List<ComplexColumnInfo> complexColumnInfoList = new ArrayList<>();
1:       complexDataType.getComplexColumnInfo(complexColumnInfoList);
1:       complexDimensionPages[index] = new ComplexColumnPage(complexColumnInfoList);
0:             .initialize(model.getColumnLocalDictGenMap(), pageSize);
1:     int depthInComplexColumn = complexDimensionPages[index].getComplexColumnIndex();
author:kumarvishal09
-------------------------------------------------------------------------------
commit:3a4b881
/////////////////////////////////////////////////////////////////////////
0:           page = ColumnPage
0:               .newLocalDictPage(spec, dataType, pageSize, localDictionaryGenerator, false);
commit:e710339
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.localdictionary.generator.LocalDictionaryGenerator;
/////////////////////////////////////////////////////////////////////////
1:   private ComplexColumnPage[] complexDimensionPages;
/////////////////////////////////////////////////////////////////////////
0:         // will be encoded using string page
1:         LocalDictionaryGenerator localDictionaryGenerator =
1:             model.getColumnLocalDictGenMap().get(spec.getFieldName());
1:         DataType dataType = DataTypes.STRING;
1:           dataType = DataTypes.VARCHAR;
1:         }
1:         if (null != localDictionaryGenerator) {
0:           page = ColumnPage.newLocalDictPage(spec, dataType, pageSize, localDictionaryGenerator);
1:         } else {
0:           page = ColumnPage.newPage(spec, dataType, pageSize);
1:         }
1:         if (DataTypes.VARCHAR == dataType) {
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:       List<String> columnNames = new ArrayList<>();
0:       complexDataType.getColumnNames(columnNames);
0:       complexDimensionPages[index] = new ComplexColumnPage(complexColumnType);
1:       try {
0:         complexDimensionPages[index]
0:             .initialize(model.getColumnLocalDictGenMap(), columnNames, pageSize);
1:       } catch (MemoryException e) {
1:         throw new RuntimeException(e);
1:       }
/////////////////////////////////////////////////////////////////////////
1:       complexDimensionPages[index].putComplexData(depth, encodedComplexColumnar.get(depth));
/////////////////////////////////////////////////////////////////////////
1:     for (ComplexColumnPage page : complexDimensionPages) {
1:       if (null != page) {
1:         page.freeMemory();
1:       }
1:     }
commit:6297ea0
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       List<ColumnType> complexColumnType = new ArrayList<>();
0:       complexDataType.getChildrenType(complexColumnType);
0:       complexDimensionPages[index] = new ComplexColumnPage(pageSize, complexColumnType);
author:sounakr
-------------------------------------------------------------------------------
commit:3202cf5
/////////////////////////////////////////////////////////////////////////
1:    * add a complex column into internal member complexDimensionPage
/////////////////////////////////////////////////////////////////////////
1:       complexDataType.parseComplexValue(byteArrayInput, dataOutputStream,
author:Jacky Li
-------------------------------------------------------------------------------
commit:982d03f
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
1:         value = DataTypeUtil.getDataTypeConverter().convertFromDecimalToBigDecimal(value);
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:       if (DataTypes.isDecimal(spec.getSchemaDataType())) {
0:           PrimitivePageStatsCollector.newInstance(dataTypes[i]));
/////////////////////////////////////////////////////////////////////////
1:       if (DataTypes.isDecimal(measurePages[i].getDataType()) &&
commit:956833e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:       ColumnPage page = ColumnPage.newPage(spec, DataTypes.BYTE_ARRAY, pageSize);
0:       page.setStatsCollector(KeyPageStatsCollector.newInstance(DataTypes.BYTE_ARRAY));
0:       ColumnPage page = ColumnPage.newPage(spec, DataTypes.STRING, pageSize);
/////////////////////////////////////////////////////////////////////////
0:       if (spec.getSchemaDataType() == DataTypes.DECIMAL) {
/////////////////////////////////////////////////////////////////////////
0:       if (measurePages[i].getDataType() == DataTypes.DECIMAL &&
commit:8c1ddbf
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashMap;
1: import java.util.Map;
1: import org.apache.carbondata.core.datastore.ColumnType;
1: import org.apache.carbondata.core.datastore.page.encoding.DefaultEncodingFactory;
1: import org.apache.carbondata.core.datastore.page.encoding.EncodingFactory;
/////////////////////////////////////////////////////////////////////////
1:   private EncodingFactory encodingFactory = DefaultEncodingFactory.getInstance();
1:   // used for complex column to deserilize the byte array in input CarbonRow
1:   private Map<Integer, GenericDataType> complexIndexMap = null;
1: 
1:     TableSpec tableSpec = model.getTableSpec();
1:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i);
0:       ColumnPage page = ColumnPage.newPage(spec, DataType.BYTE_ARRAY, pageSize);
0:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i + numDictDimension);
0:       ColumnPage page = ColumnPage.newPage(spec, DataType.STRING, pageSize);
/////////////////////////////////////////////////////////////////////////
0:       if (spec.getSchemaDataType() == DataType.DECIMAL) {
0:         page = ColumnPage.newDecimalPage(spec, dataTypes[i], pageSize);
0:         page = ColumnPage.newPage(spec, dataTypes[i], pageSize);
/////////////////////////////////////////////////////////////////////////
1: 
1:     // for complex type, `complexIndexMap` is used in multithread (in multiple Producer),
1:     // we need to clone the index map to make it thread safe
1:     this.complexIndexMap = new HashMap<>();
1:     for (Map.Entry<Integer, GenericDataType> entry: model.getComplexIndexMap().entrySet()) {
1:       this.complexIndexMap.put(entry.getKey(), entry.getValue().deepCopy());
1:     }
/////////////////////////////////////////////////////////////////////////
1:     GenericDataType complexDataType = complexIndexMap.get(
/////////////////////////////////////////////////////////////////////////
1:       ColumnPageEncoder encoder = encodingFactory.createEncoder(
/////////////////////////////////////////////////////////////////////////
1:       switch (spec.getColumnType()) {
1:           columnPageEncoder = encodingFactory.createEncoder(
1:           columnPageEncoder = encodingFactory.createEncoder(
/////////////////////////////////////////////////////////////////////////
1:               .getColumnType());
/////////////////////////////////////////////////////////////////////////
1:       ColumnType type = spec.getDimensionSpec(i).getColumnType();
1:       if ((type == ColumnType.GLOBAL_DICTIONARY) || (type == ColumnType.DIRECT_DICTIONARY)) {
1:       } else if (type == ColumnType.PLAIN_VALUE) {
commit:e6a4f64
/////////////////////////////////////////////////////////////////////////
1: import java.util.Arrays;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.ColumnPageEncoder;
0: import org.apache.carbondata.core.datastore.page.encoding.EncodingStrategyFactory;
1: import org.apache.carbondata.core.datastore.page.statistics.KeyPageStatsCollector;
0: import org.apache.carbondata.core.datastore.page.statistics.LVStringStatsCollector;
/////////////////////////////////////////////////////////////////////////
1:   private ColumnPage[] measurePages;
/////////////////////////////////////////////////////////////////////////
0:   private EncodingStrategy encodingStrategy = EncodingStrategyFactory.getStrategy();
/////////////////////////////////////////////////////////////////////////
0:       ColumnPage page = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize);
0:       page.setStatsCollector(KeyPageStatsCollector.newInstance(DataType.BYTE_ARRAY));
0:       ColumnPage page = ColumnPage.newPage(DataType.STRING, pageSize);
0:       page.setStatsCollector(LVStringStatsCollector.newInstance());
/////////////////////////////////////////////////////////////////////////
1:     measurePages = new ColumnPage[model.getMeasureCount()];
1:     for (int i = 0; i < measurePages.length; i++) {
0:       TableSpec.MeasureSpec spec = model.getTableSpec().getMeasureSpec(i);
1:       ColumnPage page;
0:       if (spec.getDataType() == DataType.DECIMAL) {
0:         page = ColumnPage.newDecimalPage(dataTypes[i], pageSize,
0:             spec.getScale(), spec.getPrecision());
1:       } else {
0:         page = ColumnPage.newPage(dataTypes[i], pageSize);
1:       }
0:       page.setStatsCollector(
0:           PrimitivePageStatsCollector.newInstance(
0:               dataTypes[i], spec.getScale(), spec.getPrecision()));
1:       measurePages[i] = page;
/////////////////////////////////////////////////////////////////////////
1:     for (int i = 0; i < measurePages.length; i++) {
0:       if (measurePages[i].getDataType() == DataType.DECIMAL &&
1:       measurePages[i].putData(rowId, value);
/////////////////////////////////////////////////////////////////////////
1:     for (ColumnPage page : measurePages) {
/////////////////////////////////////////////////////////////////////////
1:     EncodedColumnPage[] dimensions = encodeAndCompressDimensions();
1:     EncodedColumnPage[] measures = encodeAndCompressMeasures();
/////////////////////////////////////////////////////////////////////////
1:   private EncodedColumnPage[] encodeAndCompressMeasures()
1:     EncodedColumnPage[] encodedMeasures = new EncodedColumnPage[measurePages.length];
1:     for (int i = 0; i < measurePages.length; i++) {
0:       ColumnPageEncoder encoder = encodingStrategy.createEncoder(
1:           model.getTableSpec().getMeasureSpec(i), measurePages[i]);
1:       encodedMeasures[i] = encoder.encode(measurePages[i]);
1:   private EncodedColumnPage[] encodeAndCompressDimensions()
1:     List<EncodedColumnPage> encodedDimensions = new ArrayList<>();
1:     List<EncodedColumnPage> encodedComplexDimenions = new ArrayList<>();
1:       ColumnPageEncoder columnPageEncoder;
1:       EncodedColumnPage encodedPage;
0:           columnPageEncoder = encodingStrategy.createEncoder(
1:               spec,
1:               dictDimensionPages[dictIndex]);
1:           encodedPage = columnPageEncoder.encode(dictDimensionPages[dictIndex++]);
0:           columnPageEncoder = encodingStrategy.createEncoder(
1:               spec,
1:               noDictDimensionPages[noDictIndex]);
1:           encodedPage = columnPageEncoder.encode(noDictDimensionPages[noDictIndex++]);
1:           EncodedColumnPage[] encodedPages = ColumnPageEncoder.encodeComplexColumn(
1:           encodedComplexDimenions.addAll(Arrays.asList(encodedPages));
1:     return encodedDimensions.toArray(new EncodedColumnPage[encodedDimensions.size()]);
/////////////////////////////////////////////////////////////////////////
1:         return measurePages[i];
commit:f089287
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.datastore.DimensionType;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.datatypes.GenericDataType;
/////////////////////////////////////////////////////////////////////////
1:   private EncodedTablePage encodedTablePage;
1: 
0:   private EncodingStrategy encodingStrategy = new DefaultEncodingStrategy();
1: 
1:   // true if it is last page of all input rows
1:   private boolean isLastPage;
/////////////////////////////////////////////////////////////////////////
1:   void encode() throws KeyGenException, MemoryException, IOException {
1:     this.encodedTablePage = EncodedTablePage.newInstance(pageSize, dimensions, measures, key);
1:   public EncodedTablePage getEncodedTablePage() {
1:     return encodedTablePage;
1:   }
/////////////////////////////////////////////////////////////////////////
1: 
1:   /**
1:    * return column page of specified column name
1:    */
1:   public ColumnPage getColumnPage(String columnName) {
1:     int dictDimensionIndex = -1;
1:     int noDictDimensionIndex = -1;
1:     ColumnPage page = null;
1:     TableSpec spec = model.getTableSpec();
1:     int numDimensions = spec.getNumDimensions();
1:     for (int i = 0; i < numDimensions; i++) {
0:       DimensionType type = spec.getDimensionSpec(i).getDimensionType();
0:       if ((type == DimensionType.GLOBAL_DICTIONARY) || (type == DimensionType.DIRECT_DICTIONARY)) {
1:         page = dictDimensionPages[++dictDimensionIndex];
0:       } else if (type == DimensionType.PLAIN_VALUE) {
1:         page = noDictDimensionPages[++noDictDimensionIndex];
1:       } else {
1:         // do not support datamap on complex column
1:         continue;
1:       }
1:       String fieldName = spec.getDimensionSpec(i).getFieldName();
1:       if (fieldName.equalsIgnoreCase(columnName)) {
1:         return page;
1:       }
1:     }
1:     int numMeasures = spec.getNumMeasures();
1:     for (int i = 0; i < numMeasures; i++) {
1:       String fieldName = spec.getMeasureSpec(i).getFieldName();
1:       if (fieldName.equalsIgnoreCase(columnName)) {
0:         return measurePage[i];
1:       }
1:     }
1:     throw new IllegalArgumentException("DataMap: must have '" + columnName + "' column in schema");
1:   }
1: 
1:   public boolean isLastPage() {
1:     return isLastPage;
1:   }
1: 
1:   public void setIsLastPage(boolean isWriteAll) {
1:     this.isLastPage = isWriteAll;
1:   }
1: 
1:   public int getPageSize() {
1:     return pageSize;
1:   }
author:Manhua
-------------------------------------------------------------------------------
commit:40c7e8e
/////////////////////////////////////////////////////////////////////////
1:     this.key = new TablePageKey(pageSize, model.getSegmentProperties(), hasNoDictionary);
author:Raghunandan S
-------------------------------------------------------------------------------
commit:bb0b347
/////////////////////////////////////////////////////////////////////////
1:         default:
1:           throw new IllegalArgumentException("unsupported dimension type:" + spec
0:               .getDimensionType());
commit:7422690
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       ColumnPage page = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize, -1, -1);
0:       ColumnPage page = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize, -1, -1);
/////////////////////////////////////////////////////////////////////////
0:       TableSpec.MeasureSpec measureSpec = model.getTableSpec().getMeasureSpec(i);
0:           .newPage(dataTypes[i], pageSize, measureSpec.getScale(), measureSpec.getPrecision());
0:       page.setStatsCollector(PrimitivePageStatsCollector.newInstance(dataTypes[i], pageSize,
0:           measureSpec.getScale(), measureSpec.getPrecision()));
author:jackylk
-------------------------------------------------------------------------------
commit:a5af0ff
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.encoding.EncodedColumnPage;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private ColumnPage[] dictDimensionPages;
1:   private ColumnPage[] noDictDimensionPages;
0:   private ComplexColumnPage[] complexDimensionPages;
/////////////////////////////////////////////////////////////////////////
1:     dictDimensionPages = new ColumnPage[numDictDimension];
1:     for (int i = 0; i < dictDimensionPages.length; i++) {
0:       ColumnPage page = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize);
0:       dictDimensionPages[i] = page;
1:     noDictDimensionPages = new ColumnPage[model.getNoDictionaryCount()];
0:     for (int i = 0; i < noDictDimensionPages.length; i++) {
0:       ColumnPage page = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize);
0:       noDictDimensionPages[i] = page;
1:     complexDimensionPages = new ComplexColumnPage[model.getComplexColumnCount()];
1:     for (int i = 0; i < complexDimensionPages.length; i++) {
1:       complexDimensionPages[i] = null;
/////////////////////////////////////////////////////////////////////////
1:     boolean hasNoDictionary = noDictDimensionPages.length > 0;
/////////////////////////////////////////////////////////////////////////
0:     for (int i = 0; i < dictDimensionPages.length; i++) {
1:       dictDimensionPages[i].putData(rowId, keys[i]);
1:     int noDictionaryCount = noDictDimensionPages.length;
1:     int complexColumnCount = complexDimensionPages.length;
/////////////////////////////////////////////////////////////////////////
1:           noDictDimensionPages[i].putData(rowId, valueWithLength);
/////////////////////////////////////////////////////////////////////////
0:       complexDimensionPages[index] = new ComplexColumnPage(pageSize, depthInComplexColumn);
0:     int depthInComplexColumn = complexDimensionPages[index].getDepth();
1:     List<ArrayList<byte[]>> encodedComplexColumnar = new ArrayList<>(depthInComplexColumn);
/////////////////////////////////////////////////////////////////////////
0:       complexDimensionPages[index].putComplexData(rowId, depth, encodedComplexColumnar.get(depth));
1:     for (ColumnPage page : dictDimensionPages) {
1:     for (ColumnPage page : noDictDimensionPages) {
/////////////////////////////////////////////////////////////////////////
0:       ColumnPageCodec encoder =
0:           encodingStrategy.newCodec((SimpleStatsResult)(measurePage[i].getStatistics()));
1:       throws KeyGenException, IOException, MemoryException {
0:     List<EncodedDimensionPage> encodedDimensions = new ArrayList<>();
0:     List<EncodedDimensionPage> encodedComplexDimenions = new ArrayList<>();
1:     TableSpec tableSpec = model.getTableSpec();
1:     int dictIndex = 0;
1:     int noDictIndex = 0;
1:     int complexDimIndex = 0;
1:     int numDimensions = tableSpec.getNumDimensions();
1:     for (int i = 0; i < numDimensions; i++) {
0:       ColumnPageCodec codec;
0:       EncodedDimensionPage encodedPage;
0:       TableSpec.DimensionSpec spec = tableSpec.getDimensionSpec(i);
0:       switch (spec.getDimensionType()) {
0:           codec = encodingStrategy.newCodec(spec);
0:           encodedPage = (EncodedDimensionPage) codec.encode(dictDimensionPages[dictIndex++]);
1:           encodedDimensions.add(encodedPage);
0:           codec = encodingStrategy.newCodec(spec);
0:           encodedPage = (EncodedDimensionPage) codec.encode(noDictDimensionPages[noDictIndex++]);
1:           encodedDimensions.add(encodedPage);
0:           codec = encodingStrategy.newCodec(spec);
0:           EncodedColumnPage[] encodedPages = codec.encodeComplexColumn(
1:               complexDimensionPages[complexDimIndex++]);
0:           for (EncodedColumnPage page : encodedPages) {
0:             encodedComplexDimenions.add((EncodedDimensionPage) page);
1:           }
1:           break;
1:     encodedDimensions.addAll(encodedComplexDimenions);
0:     return encodedDimensions.toArray(new EncodedDimensionPage[encodedDimensions.size()]);
commit:bc3e684
/////////////////////////////////////////////////////////////////////////
0: import java.util.Iterator;
0: import org.apache.carbondata.core.datastore.DimensionType;
0: import org.apache.carbondata.core.datastore.columnar.BlockIndexerStorageForInt;
0: import org.apache.carbondata.core.datastore.columnar.BlockIndexerStorageForNoInvertedIndexForInt;
0: import org.apache.carbondata.core.datastore.columnar.BlockIndexerStorageForNoInvertedIndexForShort;
0: import org.apache.carbondata.core.datastore.columnar.BlockIndexerStorageForShort;
0: import org.apache.carbondata.core.datastore.columnar.IndexStorage;
0: import org.apache.carbondata.core.datastore.compression.Compressor;
0: import org.apache.carbondata.core.datastore.compression.CompressorFactory;
1: import org.apache.carbondata.core.datastore.page.EncodedTablePage;
0: import org.apache.carbondata.core.datastore.page.encoding.ColumnPageCodec;
0: import org.apache.carbondata.core.datastore.page.encoding.DefaultEncodingStrategy;
0: import org.apache.carbondata.core.datastore.page.encoding.EncodedDimensionPage;
0: import org.apache.carbondata.core.datastore.page.encoding.EncodedMeasurePage;
0: import org.apache.carbondata.core.datastore.page.encoding.EncodingStrategy;
1: import org.apache.carbondata.core.datastore.page.key.TablePageKey;
1: import org.apache.carbondata.core.datastore.page.statistics.PrimitivePageStatsCollector;
0: import org.apache.carbondata.core.datastore.page.statistics.SimpleStatsResult;
0: import org.apache.carbondata.core.datastore.page.statistics.VarLengthPageStatsCollector;
0: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
0: import org.apache.carbondata.core.util.ByteUtil;
0: import org.apache.carbondata.core.util.CarbonProperties;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.util.CarbonDataProcessorUtil;
/////////////////////////////////////////////////////////////////////////
1:   private TablePageKey key;
1: 
0:   private ColumnarFormatVersion version = CarbonProperties.getInstance().getFormatVersion();
1: 
0:       ColumnPage page = ColumnPage.newVarLengthPage(DataType.BYTE_ARRAY, pageSize);
0:       page.setStatsCollector(VarLengthPageStatsCollector.newInstance());
0:       dictDimensionPage[i] = page;
0:       ColumnPage page = ColumnPage.newVarLengthPage(DataType.BYTE_ARRAY, pageSize);
0:       page.setStatsCollector(VarLengthPageStatsCollector.newInstance());
0:       noDictDimensionPage[i] = page;
/////////////////////////////////////////////////////////////////////////
0:       ColumnPage page = ColumnPage
0:       page.setStatsCollector(PrimitivePageStatsCollector.newInstance(dataTypes[i], pageSize));
0:       measurePage[i] = page;
0:     boolean hasNoDictionary = noDictDimensionPage.length > 0;
0:     this.key = new TablePageKey(pageSize, model.getMDKeyGenerator(), model.getSegmentProperties(),
0:         hasNoDictionary);
1:    * Add one row to the internal store
1:     // convert each column category, update key and stats
1:     convertToColumnarAndAddToPages(rowId, row, mdk);
1:     key.update(rowId, row, mdk);
1:   }
1: 
1:   // convert the input row object to columnar data and add to column pages
1:   private void convertToColumnarAndAddToPages(int rowId, CarbonRow row, byte[] mdk)
1:       throws KeyGenException {
1:     // 1. convert dictionary columns
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       complexDimensionPage[index] = new ComplexColumnPage(pageSize, depthInComplexColumn);
0:     int depthInComplexColumn = complexDimensionPage[index].getDepth();
/////////////////////////////////////////////////////////////////////////
0:       complexDimensionPage[index].putComplexData(rowId, depth, encodedComplexColumnar.get(depth));
/////////////////////////////////////////////////////////////////////////
0:   EncodedTablePage encode() throws KeyGenException, MemoryException, IOException {
1:     // encode dimensions and measure
0:     EncodedDimensionPage[] dimensions = encodeAndCompressDimensions();
0:     EncodedMeasurePage[] measures = encodeAndCompressMeasures();
0:     return EncodedTablePage.newInstance(pageSize, dimensions, measures, key);
0:   private EncodingStrategy encodingStrategy = new DefaultEncodingStrategy();
1: 
1:   // apply measure and set encodedData in `encodedData`
0:   private EncodedMeasurePage[] encodeAndCompressMeasures()
1:       throws MemoryException, IOException {
0:     EncodedMeasurePage[] encodedMeasures = new EncodedMeasurePage[measurePage.length];
0:     for (int i = 0; i < measurePage.length; i++) {
0:       SimpleStatsResult stats = (SimpleStatsResult)(measurePage[i].getStatistics());
0:       ColumnPageCodec encoder = encodingStrategy.createCodec(stats);
0:       encodedMeasures[i] = (EncodedMeasurePage) encoder.encode(measurePage[i]);
1:     }
1:     return encodedMeasures;
0:   private IndexStorage encodeAndCompressDictDimension(byte[][] data, boolean isSort,
0:       boolean isUseInvertedIndex, boolean isRleApplicable) throws KeyGenException {
0:     if (isUseInvertedIndex) {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForShort(data, isRleApplicable, false, isSort);
1:       } else {
0:         return new BlockIndexerStorageForInt(data, isRleApplicable, false, isSort);
1:       }
1:     } else {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForNoInvertedIndexForShort(data, false);
1:       } else {
0:         return new BlockIndexerStorageForNoInvertedIndexForInt(data);
1:       }
1:     }
0:   private IndexStorage encodeAndCompressDirectDictDimension(byte[][] data, boolean isSort,
0:       boolean isUseInvertedIndex, boolean isRleApplicable) throws KeyGenException {
0:     if (isUseInvertedIndex) {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForShort(data, isRleApplicable, false, isSort);
1:       } else {
0:         return new BlockIndexerStorageForInt(data, isRleApplicable, false, isSort);
1:       }
1:     } else {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForNoInvertedIndexForShort(data, false);
1:       } else {
0:         return new BlockIndexerStorageForNoInvertedIndexForInt(data);
1:       }
1:     }
0:   private IndexStorage encodeAndCompressComplexDimension(byte[][] data) {
0:     if (version == ColumnarFormatVersion.V3) {
0:       return new BlockIndexerStorageForShort(data, false, false, false);
1:     } else {
0:       return new BlockIndexerStorageForInt(data, false, false, false);
1:     }
0:   private IndexStorage encodeAndCompressNoDictDimension(byte[][] data, boolean isSort,
0:       boolean isUseInvertedIndex, boolean isRleApplicable) {
0:     if (isUseInvertedIndex) {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForShort(data, isRleApplicable, true, isSort);
1:       } else {
0:         return new BlockIndexerStorageForInt(data, isRleApplicable, true, isSort);
1:       }
1:     } else {
0:       if (version == ColumnarFormatVersion.V3) {
0:         return new BlockIndexerStorageForNoInvertedIndexForShort(data, true);
1:       } else {
0:         return new BlockIndexerStorageForNoInvertedIndexForInt(data);
1:       }
1:     }
1:   }
1: 
1:   // apply and compress each dimension, set encoded data in `encodedData`
0:   private EncodedDimensionPage[] encodeAndCompressDimensions()
0:       throws KeyGenException {
0:     TableSpec.DimensionSpec dimensionSpec = model.getTableSpec().getDimensionSpec();
0:     int dictionaryColumnCount = -1;
0:     int noDictionaryColumnCount = -1;
0:     int indexStorageOffset = 0;
0:     IndexStorage[] indexStorages = new IndexStorage[dimensionSpec.getNumExpandedDimensions()];
0:     Compressor compressor = CompressorFactory.getInstance().getCompressor();
0:     EncodedDimensionPage[] compressedColumns = new EncodedDimensionPage[indexStorages.length];
0:     boolean[] isUseInvertedIndex = model.getIsUseInvertedIndex();
0:     for (int i = 0; i < dimensionSpec.getNumSimpleDimensions(); i++) {
0:       ColumnPage page;
0:       byte[] flattened;
0:       boolean isSortColumn = model.isSortColumn(i);
0:       switch (dimensionSpec.getType(i)) {
1:         case GLOBAL_DICTIONARY:
0:           // dictionary dimension
0:           page = dictDimensionPage[++dictionaryColumnCount];
0:           indexStorages[indexStorageOffset] = encodeAndCompressDictDimension(
0:               page.getByteArrayPage(),
0:               isSortColumn,
0:               isUseInvertedIndex[i] & isSortColumn,
0:               CarbonDataProcessorUtil.isRleApplicableForColumn(dimensionSpec.getType(i)));
0:           flattened = ByteUtil.flatten(indexStorages[indexStorageOffset].getDataPage());
1:           break;
1:         case DIRECT_DICTIONARY:
0:           // timestamp and date column
0:           page = dictDimensionPage[++dictionaryColumnCount];
0:           indexStorages[indexStorageOffset] = encodeAndCompressDirectDictDimension(
0:               page.getByteArrayPage(),
0:               isSortColumn,
0:               isUseInvertedIndex[i] & isSortColumn,
0:               CarbonDataProcessorUtil.isRleApplicableForColumn(dimensionSpec.getType(i)));
0:           flattened = ByteUtil.flatten(indexStorages[indexStorageOffset].getDataPage());
1:           break;
1:         case PLAIN_VALUE:
0:           // high cardinality dimension, encoded as plain string
0:           page = noDictDimensionPage[++noDictionaryColumnCount];
0:           indexStorages[indexStorageOffset] = encodeAndCompressNoDictDimension(
0:               page.getByteArrayPage(),
0:               isSortColumn,
0:               isUseInvertedIndex[i] & isSortColumn,
0:               CarbonDataProcessorUtil.isRleApplicableForColumn(dimensionSpec.getType(i)));
0:           flattened = ByteUtil.flatten(indexStorages[indexStorageOffset].getDataPage());
1:           break;
1:         case COMPLEX:
0:           // we need to add complex column at last, so skipping it here
0:           continue;
0:         default:
0:           throw new RuntimeException("unsupported dimension type: " + dimensionSpec.getType(i));
1:       }
0:       byte[] compressedData = compressor.compressByte(flattened);
0:       compressedColumns[indexStorageOffset] = new EncodedDimensionPage(
0:           pageSize, compressedData, indexStorages[indexStorageOffset], dimensionSpec.getType(i));
0:       SimpleStatsResult stats = (SimpleStatsResult) page.getStatistics();
0:       compressedColumns[indexStorageOffset].setNullBitSet(stats.getNullBits());
0:       indexStorageOffset++;
1:     }
1: 
0:     // handle complex type column
0:     for (int i = 0; i < dimensionSpec.getNumComplexDimensions(); i++) {
0:       Iterator<byte[][]> iterator = complexDimensionPage[i].iterator();
0:       while (iterator.hasNext()) {
0:         byte[][] data = iterator.next();
0:         indexStorages[indexStorageOffset] = encodeAndCompressComplexDimension(data);
0:         byte[] flattened = ByteUtil.flatten(data);
0:         byte[] compressedData = compressor.compressByte(flattened);
0:         compressedColumns[indexStorageOffset] = new EncodedDimensionPage(
0:             pageSize, compressedData, indexStorages[indexStorageOffset], DimensionType.COMPLEX);
0:         indexStorageOffset++;
1:       }
1:     }
0:     return compressedColumns;
1:   }
commit:7359601
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.memory.MemoryException;
1: 
/////////////////////////////////////////////////////////////////////////
1:   TablePage(CarbonFactDataHandlerModel model, int pageSize) throws MemoryException {
0:       dictDimensionPage[i] = ColumnPage.newVarLengthPath(DataType.BYTE_ARRAY, pageSize);
0:       noDictDimensionPage[i] = ColumnPage.newVarLengthPath(DataType.BYTE_ARRAY, pageSize);
/////////////////////////////////////////////////////////////////////////
1:   void freeMemory() {
0:     for (ColumnPage page : dictDimensionPage) {
1:       page.freeMemory();
1:     }
0:     for (ColumnPage page : noDictDimensionPage) {
1:       page.freeMemory();
1:     }
0:     for (ColumnPage page : measurePage) {
1:       page.freeMemory();
1:     }
1:   }
1: 
1:     if (input.length > Short.MAX_VALUE) {
1:       throw new RuntimeException("input data length " + input.length +
1:           " bytes too long, maximum length supported is " + Short.MAX_VALUE + " bytes");
1:     }
1:     buffer.putShort((short)input.length);
0:   ColumnPage[] getDictDimensionPage() {
0:   ColumnPage[] getNoDictDimensionPage() {
0:   ComplexColumnPage[] getComplexDimensionPage() {
0:   ColumnPage[] getMeasurePage() {
0:   MeasurePageStatsVO getMeasureStats() {
commit:edda248
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:   private ColumnPage[] dictDimensionPage;
/////////////////////////////////////////////////////////////////////////
0:   public TablePage(CarbonFactDataHandlerModel model, int pageSize) {
1:     int numDictDimension = model.getMDKeyGenerator().getDimCount();
0:     dictDimensionPage = new ColumnPage[numDictDimension];
0:     for (int i = 0; i < dictDimensionPage.length; i++) {
0:       dictDimensionPage[i] = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize);
1:     }
0:       noDictDimensionPage[i] = ColumnPage.newPage(DataType.BYTE_ARRAY, pageSize);
/////////////////////////////////////////////////////////////////////////
0:       measurePage[i] = ColumnPage.newPage(dataTypes[i], pageSize);
/////////////////////////////////////////////////////////////////////////
1:   public void addRow(int rowId, CarbonRow row) throws KeyGenException {
0:     for (int i = 0; i < dictDimensionPage.length; i++) {
0:       dictDimensionPage[i].putData(rowId, keys[i]);
1:     }
/////////////////////////////////////////////////////////////////////////
1:     // apply the complex type data and fill columnsArray
/////////////////////////////////////////////////////////////////////////
0:   public ColumnPage[] getDictDimensionPage() {
0:     return dictDimensionPage;
commit:dc83b2a
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.datastore.GenericDataType;
1: import org.apache.carbondata.core.datastore.exception.CarbonDataWriterException;
1: import org.apache.carbondata.core.datastore.page.ColumnPage;
0: import org.apache.carbondata.core.datastore.page.statistics.MeasurePageStatsVO;
1: import org.apache.carbondata.core.datastore.row.CarbonRow;
1: import org.apache.carbondata.core.datastore.row.WriteStepRowUtil;
/////////////////////////////////////////////////////////////////////////
1: public class TablePage {
/////////////////////////////////////////////////////////////////////////
0:   private ColumnPage[] noDictDimensionPage;
0:   private ColumnPage[] measurePage;
1: 
0:   private MeasurePageStatsVO measurePageStatistics;
/////////////////////////////////////////////////////////////////////////
0:     noDictDimensionPage = new ColumnPage[model.getNoDictionaryCount()];
0:       noDictDimensionPage[i] = new ColumnPage(DataType.STRING, pageSize);
/////////////////////////////////////////////////////////////////////////
0:     measurePage = new ColumnPage[model.getMeasureCount()];
0:       measurePage[i] = new ColumnPage(dataTypes[i], pageSize);
/////////////////////////////////////////////////////////////////////////
1:           // element as LV result byte array (first two bytes are the length of the array)
0:           noDictDimensionPage[i].putData(rowId, valueWithLength);
/////////////////////////////////////////////////////////////////////////
0:       if (measurePage[i].getDataType() == DataType.DECIMAL &&
1:           model.isCompactionFlow() &&
1:           value != null) {
1: 
0:     // update statistics if it is last row
0:     if (rowId + 1 == pageSize) {
0:       this.measurePageStatistics = new MeasurePageStatsVO(measurePage);
1:     }
/////////////////////////////////////////////////////////////////////////
1:     // this is the result columnar data which will be added to page,
/////////////////////////////////////////////////////////////////////////
0:   public ColumnPage[] getNoDictDimensionPage() {
/////////////////////////////////////////////////////////////////////////
0:   public ColumnPage[] getMeasurePage() {
1: 
0:   public MeasurePageStatsVO getMeasureStats() {
0:     return measurePageStatistics;
1:   }
1: 
0:   public int getPageSize() {
0:     return pageSize;
1:   }
1: 
1: 
commit:353272e
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.processing.store;
1: 
1: import java.io.ByteArrayOutputStream;
1: import java.io.DataOutputStream;
1: import java.io.IOException;
0: import java.math.BigDecimal;
1: import java.nio.ByteBuffer;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.core.datastore.page.ComplexColumnPage;
0: import org.apache.carbondata.core.datastore.page.FixLengthColumnPage;
0: import org.apache.carbondata.core.datastore.page.KeyColumnPage;
0: import org.apache.carbondata.core.datastore.page.VarLengthColumnPage;
1: import org.apache.carbondata.core.keygenerator.KeyGenException;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.datatypes.GenericDataType;
0: import org.apache.carbondata.processing.newflow.row.CarbonRow;
0: import org.apache.carbondata.processing.newflow.row.WriteStepRowUtil;
0: import org.apache.carbondata.processing.store.writer.exception.CarbonDataWriterException;
1: 
0: import org.apache.spark.sql.types.Decimal;
1: 
1: /**
1:  * Represent a page data for all columns, we store its data in columnar layout, so that
1:  * all processing apply to TablePage can be done in vectorized fashion.
1:  */
0: class TablePage {
1: 
1:   // For all dimension and measure columns, we store the column data directly in the page,
1:   // the length of the page is the number of rows.
1: 
1:   // TODO: we should have separate class for key columns so that keys are stored together in
1:   // one vector to make it efficient for sorting
0:   private KeyColumnPage keyColumnPage;
0:   private VarLengthColumnPage[] noDictDimensionPage;
0:   private ComplexColumnPage[] complexDimensionPage;
0:   private FixLengthColumnPage[] measurePage;
1: 
1:   // the num of rows in this page, it must be less than short value (65536)
1:   private int pageSize;
1: 
1:   private CarbonFactDataHandlerModel model;
1: 
0:   TablePage(CarbonFactDataHandlerModel model, int pageSize) {
1:     this.model = model;
1:     this.pageSize = pageSize;
0:     keyColumnPage = new KeyColumnPage(pageSize,
0:         model.getSegmentProperties().getDimensionPartitions().length);
0:     noDictDimensionPage = new VarLengthColumnPage[model.getNoDictionaryCount()];
0:     for (int i = 0; i < noDictDimensionPage.length; i++) {
0:       noDictDimensionPage[i] = new VarLengthColumnPage(pageSize);
1:     }
0:     complexDimensionPage = new ComplexColumnPage[model.getComplexColumnCount()];
0:     for (int i = 0; i < complexDimensionPage.length; i++) {
1:       // here we still do not the depth of the complex column, it will be initialized when
1:       // we get the first row.
0:       complexDimensionPage[i] = null;
1:     }
0:     measurePage = new FixLengthColumnPage[model.getMeasureCount()];
1:     DataType[] dataTypes = model.getMeasureDataType();
0:     for (int i = 0; i < measurePage.length; i++) {
0:       measurePage[i] = new FixLengthColumnPage(dataTypes[i], pageSize);
1:     }
1:   }
1: 
1:   /**
0:    * Add one row to the internal store, it will be converted into columnar layout
1:    *
1:    * @param rowId Id of the input row
1:    * @param row   row object
1:    */
0:   void addRow(int rowId, CarbonRow row) throws KeyGenException {
0:     // convert each column category
1: 
0:     // 1. convert dictionary columns
1:     byte[] mdk = WriteStepRowUtil.getMdk(row, model.getMDKeyGenerator());
1:     byte[][] keys = model.getSegmentProperties().getFixedLengthKeySplitter().splitKey(mdk);
0:     keyColumnPage.putKey(rowId, keys);
1: 
0:     // 2. convert noDictionary columns and complex columns.
0:     int noDictionaryCount = noDictDimensionPage.length;
0:     int complexColumnCount = complexDimensionPage.length;
1:     if (noDictionaryCount > 0 || complexColumnCount > 0) {
1:       byte[][] noDictAndComplex = WriteStepRowUtil.getNoDictAndComplexDimension(row);
1:       for (int i = 0; i < noDictAndComplex.length; i++) {
0:         if (i < noDictionaryCount) {
1:           // noDictionary columns, since it is variable length, we need to prepare each
0:           // element as LV encoded byte array (first two bytes are the length of the array)
0:           byte[] valueWithLength = addLengthToByteArray(noDictAndComplex[i]);
0:           noDictDimensionPage[i].putByteArray(rowId, valueWithLength);
0:         } else {
1:           // complex columns
1:           addComplexColumn(i - noDictionaryCount, rowId, noDictAndComplex[i]);
1:         }
1:       }
1:     }
1: 
1:     // 3. convert measure columns
1:     Object[] measureColumns = WriteStepRowUtil.getMeasure(row);
0:     for (int i = 0; i < measurePage.length; i++) {
1:       Object value = measureColumns[i];
1: 
1:       // in compaction flow the measure with decimal type will come as Spark decimal.
1:       // need to convert it to byte array.
0:       if (measurePage[i].getDataType() == DataType.DECIMAL && model.isCompactionFlow()) {
0:         BigDecimal bigDecimal = ((Decimal) value).toJavaBigDecimal();
0:         value = DataTypeUtil.bigDecimalToByte(bigDecimal);
1:       }
0:       measurePage[i].putData(rowId, value);
1:     }
1:   }
1: 
1:   /**
0:    * add a complex column into internal member compleDimensionPage
1:    *
1:    * @param index          index of the complexDimensionPage
1:    * @param rowId          Id of the input row
1:    * @param complexColumns byte array the complex columm to be added, extracted of input row
1:    */
1:   // TODO: this function should be refactoried, ColumnPage should support complex type encoding
1:   // directly instead of doing it here
1:   private void addComplexColumn(int index, int rowId, byte[] complexColumns) {
0:     GenericDataType complexDataType = model.getComplexIndexMap().get(
1:         index + model.getPrimitiveDimLens().length);
1: 
1:     // initialize the page if first row
1:     if (rowId == 0) {
0:       int depthInComplexColumn = complexDataType.getColsCount();
0:       getComplexDimensionPage()[index] = new ComplexColumnPage(pageSize, depthInComplexColumn);
1:     }
1: 
0:     int depthInComplexColumn = getComplexDimensionPage()[index].getDepth();
0:     // this is the encoded columnar data which will be added to page,
1:     // size of this list is the depth of complex column, we will fill it by input data
0:     List<ArrayList<byte[]>> encodedComplexColumnar = new ArrayList<>();
1:     for (int k = 0; k < depthInComplexColumn; k++) {
1:       encodedComplexColumnar.add(new ArrayList<byte[]>());
1:     }
1: 
0:     // encode the complex type data and fill columnsArray
1:     try {
1:       ByteBuffer byteArrayInput = ByteBuffer.wrap(complexColumns);
1:       ByteArrayOutputStream byteArrayOutput = new ByteArrayOutputStream();
1:       DataOutputStream dataOutputStream = new DataOutputStream(byteArrayOutput);
0:       complexDataType.parseAndBitPack(byteArrayInput, dataOutputStream,
1:           model.getComplexDimensionKeyGenerator());
1:       complexDataType.getColumnarDataForComplexType(encodedComplexColumnar,
1:           ByteBuffer.wrap(byteArrayOutput.toByteArray()));
1:       byteArrayOutput.close();
1:     } catch (IOException | KeyGenException e) {
1:       throw new CarbonDataWriterException("Problem while bit packing and writing complex datatype",
1:           e);
1:     }
1: 
1:     for (int depth = 0; depth < depthInComplexColumn; depth++) {
0:       getComplexDimensionPage()[index]
0:           .putComplexData(rowId, depth, encodedComplexColumnar.get(depth));
1:     }
1:   }
1: 
1:   // Adds length as a short element (first 2 bytes) to the head of the input byte array
0:   private byte[] addLengthToByteArray(byte[] input) {
1:     byte[] output = new byte[input.length + 2];
1:     ByteBuffer buffer = ByteBuffer.wrap(output);
0:     buffer.putShort((short) input.length);
1:     buffer.put(input, 0, input.length);
1:     return output;
1:   }
1: 
0:   public KeyColumnPage getKeyColumnPage() {
0:     return keyColumnPage;
1:   }
1: 
0:   public VarLengthColumnPage[] getNoDictDimensionPage() {
0:     return noDictDimensionPage;
1:   }
1: 
0:   public ComplexColumnPage[] getComplexDimensionPage() {
0:     return complexDimensionPage;
1:   }
1: 
0:   public FixLengthColumnPage[] getMeasurePage() {
0:     return measurePage;
1:   }
1: }
author:ravipesala
-------------------------------------------------------------------------------
commit:9e064ee
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.TableSpec;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       dictDimensionPage[i] = ColumnPage.newVarLengthPage(DataType.BYTE_ARRAY, pageSize);
0:       noDictDimensionPage[i] = ColumnPage.newVarLengthPage(DataType.BYTE_ARRAY, pageSize);
/////////////////////////////////////////////////////////////////////////
0:     TableSpec.MeasureSpec measureSpec = model.getTableSpec().getMeasureSpec();
0:       measurePage[i] = ColumnPage
0:           .newPage(dataTypes[i], pageSize, measureSpec.getScale(i), measureSpec.getPrecision(i));
/////////////////////////////////////////////////////////////////////////
0:         value = ((Decimal) value).toJavaBigDecimal();
author:rahulforallp
-------------------------------------------------------------------------------
commit:14eca3d
/////////////////////////////////////////////////////////////////////////
0:       if (null != value && measurePage[i].getDataType() == DataType.DECIMAL && model
0:           .isCompactionFlow()) {
============================================================================
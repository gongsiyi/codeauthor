1:874764f: /*
1:874764f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:874764f:  * contributor license agreements.  See the NOTICE file distributed with
1:874764f:  * this work for additional information regarding copyright ownership.
1:874764f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:874764f:  * (the "License"); you may not use this file except in compliance with
1:874764f:  * the License.  You may obtain a copy of the License at
2:874764f:  *
1:874764f:  *    http://www.apache.org/licenses/LICENSE-2.0
1:874764f:  *
1:874764f:  * Unless required by applicable law or agreed to in writing, software
1:874764f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:874764f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:874764f:  * See the License for the specific language governing permissions and
1:874764f:  * limitations under the License.
2:874764f:  */
5:874764f: 
1:349c59c: package org.apache.carbondata.processing.partition.spliter;
1:874764f: 
1:874764f: import java.io.IOException;
1:874764f: import java.util.List;
1:874764f: import java.util.Map;
1:874764f: 
1:874764f: import org.apache.carbondata.common.CarbonIterator;
1:874764f: import org.apache.carbondata.common.logging.LogService;
1:874764f: import org.apache.carbondata.common.logging.LogServiceFactory;
1:874764f: import org.apache.carbondata.core.cache.dictionary.Dictionary;
1:874764f: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:874764f: import org.apache.carbondata.core.datastore.block.TaskBlockInfo;
1:874764f: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:874764f: import org.apache.carbondata.core.scan.executor.QueryExecutor;
1:874764f: import org.apache.carbondata.core.scan.executor.QueryExecutorFactory;
1:874764f: import org.apache.carbondata.core.scan.executor.exception.QueryExecutionException;
1:874764f: import org.apache.carbondata.core.scan.model.QueryModel;
1:daa6465: import org.apache.carbondata.core.scan.result.RowBatch;
1:874764f: import org.apache.carbondata.core.util.CarbonUtil;
1:874764f: 
1:2a9604c: import org.apache.hadoop.conf.Configuration;
1:2a9604c: 
1:874764f: public abstract class AbstractCarbonQueryExecutor {
1:874764f: 
1:874764f:   private static final LogService LOGGER =
1:874764f:       LogServiceFactory.getLogService(AbstractCarbonQueryExecutor.class.getName());
1:874764f:   protected CarbonTable carbonTable;
1:874764f:   protected QueryModel queryModel;
1:daa6465:   private QueryExecutor queryExecutor;
1:daa6465:   Map<String, TaskBlockInfo> segmentMapping;
1:874764f: 
2:874764f:   /**
1:874764f:    * get executor and execute the query model.
1:874764f:    *
2:874764f:    * @param blockList
2:874764f:    * @return
1:874764f:    */
1:2a9604c:   CarbonIterator<RowBatch> executeBlockList(List<TableBlockInfo> blockList,
1:2a9604c:       Configuration configuration)
1:874764f:       throws QueryExecutionException, IOException {
1:874764f:     queryModel.setTableBlockInfos(blockList);
1:2a9604c:     this.queryExecutor = QueryExecutorFactory.getQueryExecutor(queryModel, configuration);
1:874764f:     return queryExecutor.execute(queryModel);
4:874764f:   }
1:874764f: 
1:874764f:   /**
1:874764f:    * Below method will be used
1:874764f:    * for cleanup
1:874764f:    */
1:874764f:   public void finish() {
1:874764f:     try {
1:874764f:       queryExecutor.finish();
1:874764f:     } catch (QueryExecutionException e) {
1:874764f:       LOGGER.error(e, "Problem while finish: ");
1:874764f:     }
1:874764f:     clearDictionaryFromQueryModel();
1:874764f:   }
1:874764f: 
1:874764f:   /**
1:874764f:    * This method will clear the dictionary access count after its usage is complete so
1:874764f:    * that column can be deleted form LRU cache whenever memory reaches threshold
1:874764f:    */
1:874764f:   private void clearDictionaryFromQueryModel() {
1:874764f:     if (null != queryModel) {
1:874764f:       Map<String, Dictionary> columnToDictionaryMapping = queryModel.getColumnToDictionaryMapping();
1:874764f:       if (null != columnToDictionaryMapping) {
1:874764f:         for (Map.Entry<String, Dictionary> entry : columnToDictionaryMapping.entrySet()) {
1:874764f:           CarbonUtil.clearDictionaryCache(entry.getValue());
1:874764f:         }
1:874764f:       }
1:874764f:     }
1:874764f:   }
1:874764f: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:2a9604c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
1: 
/////////////////////////////////////////////////////////////////////////
1:   CarbonIterator<RowBatch> executeBlockList(List<TableBlockInfo> blockList,
1:       Configuration configuration)
1:     this.queryExecutor = QueryExecutorFactory.getQueryExecutor(queryModel, configuration);
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.result.RowBatch;
/////////////////////////////////////////////////////////////////////////
1:   private QueryExecutor queryExecutor;
1:   Map<String, TaskBlockInfo> segmentMapping;
/////////////////////////////////////////////////////////////////////////
0:   CarbonIterator<RowBatch> executeBlockList(List<TableBlockInfo> blockList)
/////////////////////////////////////////////////////////////////////////
commit:5fc7f06
/////////////////////////////////////////////////////////////////////////
0:         carbonTable.getDimensionByTableName(carbonTable.getTableName());
/////////////////////////////////////////////////////////////////////////
0:         carbonTable.getMeasureByTableName(carbonTable.getTableName());
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.partition.spliter;
author:lionelcao
-------------------------------------------------------------------------------
commit:874764f
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.spliter;
1: 
1: import java.io.IOException;
0: import java.util.ArrayList;
1: import java.util.List;
1: import java.util.Map;
1: 
1: import org.apache.carbondata.common.CarbonIterator;
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
1: import org.apache.carbondata.core.cache.dictionary.Dictionary;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.datastore.block.TaskBlockInfo;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
0: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
0: import org.apache.carbondata.core.metadata.schema.table.column.CarbonMeasure;
1: import org.apache.carbondata.core.scan.executor.QueryExecutor;
1: import org.apache.carbondata.core.scan.executor.QueryExecutorFactory;
1: import org.apache.carbondata.core.scan.executor.exception.QueryExecutionException;
0: import org.apache.carbondata.core.scan.model.QueryDimension;
0: import org.apache.carbondata.core.scan.model.QueryMeasure;
1: import org.apache.carbondata.core.scan.model.QueryModel;
0: import org.apache.carbondata.core.scan.result.BatchResult;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: 
1: public abstract class AbstractCarbonQueryExecutor {
1: 
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(AbstractCarbonQueryExecutor.class.getName());
1:   protected CarbonTable carbonTable;
1:   protected QueryModel queryModel;
0:   protected QueryExecutor queryExecutor;
0:   protected Map<String, TaskBlockInfo> segmentMapping;
1: 
1:   /**
1:    * get executor and execute the query model.
1:    *
1:    * @param blockList
1:    * @return
1:    */
0:   protected CarbonIterator<BatchResult> executeBlockList(List<TableBlockInfo> blockList)
1:       throws QueryExecutionException, IOException {
1:     queryModel.setTableBlockInfos(blockList);
0:     this.queryExecutor = QueryExecutorFactory.getQueryExecutor(queryModel);
1:     return queryExecutor.execute(queryModel);
1:   }
1: 
1:   /**
0:    * Preparing of the query model.
1:    *
1:    * @param blockList
1:    * @return
1:    */
0:   protected QueryModel prepareQueryModel(List<TableBlockInfo> blockList) {
0:     QueryModel model = new QueryModel();
0:     model.setTableBlockInfos(blockList);
0:     model.setForcedDetailRawQuery(true);
0:     model.setFilterExpressionResolverTree(null);
1: 
0:     List<QueryDimension> dims = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1: 
0:     List<CarbonDimension> dimensions =
0:         carbonTable.getDimensionByTableName(carbonTable.getFactTableName());
0:     for (CarbonDimension dim : dimensions) {
0:       // check if dimension is deleted
0:       QueryDimension queryDimension = new QueryDimension(dim.getColName());
0:       queryDimension.setDimension(dim);
0:       dims.add(queryDimension);
1:     }
0:     model.setQueryDimension(dims);
1: 
0:     List<QueryMeasure> msrs = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
0:     List<CarbonMeasure> measures =
0:         carbonTable.getMeasureByTableName(carbonTable.getFactTableName());
0:     for (CarbonMeasure carbonMeasure : measures) {
0:       // check if measure is deleted
0:       QueryMeasure queryMeasure = new QueryMeasure(carbonMeasure.getColName());
0:       queryMeasure.setMeasure(carbonMeasure);
0:       msrs.add(queryMeasure);
1:     }
0:     model.setQueryMeasures(msrs);
0:     model.setQueryId(System.nanoTime() + "");
0:     model.setAbsoluteTableIdentifier(carbonTable.getAbsoluteTableIdentifier());
0:     model.setTable(carbonTable);
0:     return model;
1:   }
1: 
1:   /**
1:    * Below method will be used
1:    * for cleanup
1:    */
1:   public void finish() {
1:     try {
1:       queryExecutor.finish();
1:     } catch (QueryExecutionException e) {
1:       LOGGER.error(e, "Problem while finish: ");
1:     }
1:     clearDictionaryFromQueryModel();
1:   }
1: 
1:   /**
1:    * This method will clear the dictionary access count after its usage is complete so
1:    * that column can be deleted form LRU cache whenever memory reaches threshold
1:    */
1:   private void clearDictionaryFromQueryModel() {
1:     if (null != queryModel) {
1:       Map<String, Dictionary> columnToDictionaryMapping = queryModel.getColumnToDictionaryMapping();
1:       if (null != columnToDictionaryMapping) {
1:         for (Map.Entry<String, Dictionary> entry : columnToDictionaryMapping.entrySet()) {
1:           CarbonUtil.clearDictionaryCache(entry.getValue());
1:         }
1:       }
1:     }
1:   }
1: }
============================================================================
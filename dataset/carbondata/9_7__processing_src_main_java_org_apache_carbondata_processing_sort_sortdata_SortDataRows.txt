1:cd6a4ff: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
4:cd6a4ff:  *
1:cd6a4ff:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cd6a4ff:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
25:cd6a4ff:  */
45:cd6a4ff: 
1:349c59c: package org.apache.carbondata.processing.sort.sortdata;
1:cd6a4ff: 
1:cd6a4ff: import java.io.DataOutputStream;
1:cd6a4ff: import java.io.File;
1:cd6a4ff: import java.io.IOException;
1:2b41f14: import java.nio.ByteBuffer;
1:cd6a4ff: import java.util.Arrays;
1:ded8b41: import java.util.Random;
1:cd6a4ff: import java.util.concurrent.ExecutorService;
1:cd6a4ff: import java.util.concurrent.Executors;
1:cd6a4ff: import java.util.concurrent.Semaphore;
1:cd6a4ff: import java.util.concurrent.TimeUnit;
1:cd6a4ff: 
1:cd6a4ff: import org.apache.carbondata.common.logging.LogService;
1:cd6a4ff: import org.apache.carbondata.common.logging.LogServiceFactory;
1:cd6a4ff: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:c100251: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:8100d94: import org.apache.carbondata.core.util.CarbonProperties;
1:a734add: import org.apache.carbondata.core.util.CarbonThreadFactory;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonUtil;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1:cd6a4ff: import org.apache.carbondata.processing.util.CarbonDataProcessorUtil;
1:cd6a4ff: 
1:cd6a4ff: public class SortDataRows {
25:cd6a4ff:   /**
1:cd6a4ff:    * LOGGER
1:cd6a4ff:    */
1:cd6a4ff:   private static final LogService LOGGER =
1:cd6a4ff:       LogServiceFactory.getLogService(SortDataRows.class.getName());
1:cd6a4ff:   /**
1:cd6a4ff:    * entryCount
1:cd6a4ff:    */
1:cd6a4ff:   private int entryCount;
1:cd6a4ff:   /**
1:cd6a4ff:    * record holder array
1:cd6a4ff:    */
1:cd6a4ff:   private Object[][] recordHolderList;
1:cd6a4ff:   /**
1:cd6a4ff:    * threadStatusObserver
1:cd6a4ff:    */
1:cd6a4ff:   private ThreadStatusObserver threadStatusObserver;
1:cd6a4ff:   /**
1:cd6a4ff:    * executor service for data sort holder
1:cd6a4ff:    */
1:cd6a4ff:   private ExecutorService dataSorterAndWriterExecutorService;
1:cd6a4ff:   /**
1:cd6a4ff:    * semaphore which will used for managing sorted data object arrays
1:cd6a4ff:    */
1:cd6a4ff:   private Semaphore semaphore;
1:8d8b589: 
1:9aee980:   private SortParameters parameters;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:2b41f14:   private ThreadLocal<ByteBuffer> rowBuffer;
1:9aee980:   private int sortBufferSize;
1:cd6a4ff: 
1:9aee980:   private SortIntermediateFileMerger intermediateFileMerger;
1:cd6a4ff: 
1:63434fa:   private final Object addRowsLock = new Object();
1:63434fa: 
1:9aee980:   public SortDataRows(SortParameters parameters,
1:9aee980:       SortIntermediateFileMerger intermediateFileMerger) {
1:9aee980:     this.parameters = parameters;
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
1:9aee980:     this.intermediateFileMerger = intermediateFileMerger;
1:8d8b589: 
1:8100d94:     int batchSize = CarbonProperties.getInstance().getBatchSize();
1:8100d94: 
1:8100d94:     this.sortBufferSize = Math.max(parameters.getSortBufferSize(), batchSize);
1:cd6a4ff:     // observer of writing file in thread
1:cd6a4ff:     this.threadStatusObserver = new ThreadStatusObserver();
1:2b41f14:     this.rowBuffer = new ThreadLocal<ByteBuffer>() {
1:2b41f14:       @Override protected ByteBuffer initialValue() {
1:2b41f14:         byte[] backedArray = new byte[2 * 1024 * 1024];
1:2b41f14:         return ByteBuffer.wrap(backedArray);
1:2b41f14:       }
1:2b41f14:     };
1:21704cf:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to initialize
1:cd6a4ff:    */
1:9aee980:   public void initialize() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff: 
1:cd6a4ff:     // create holder list which will hold incoming rows
1:cd6a4ff:     // size of list will be sort buffer size + 1 to avoid creation of new
1:cd6a4ff:     // array in list array
1:8100d94:     this.recordHolderList = new Object[sortBufferSize][];
1:cd6a4ff:     // Delete if any older file exists in sort temp folder
1:cd6a4ff:     deleteSortLocationIfExists();
1:cd6a4ff: 
1:cd6a4ff:     // create new sort temp directory
1:ded8b41:     CarbonDataProcessorUtil.createLocations(parameters.getTempFileLocation());
1:a734add:     this.dataSorterAndWriterExecutorService = Executors
1:a734add:         .newFixedThreadPool(parameters.getNumberOfCores(),
1:a734add:             new CarbonThreadFactory("SortDataRowPool:" + parameters.getTableName()));
1:9aee980:     semaphore = new Semaphore(parameters.getNumberOfCores());
47:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:63434fa:    * This method will be used to add new row
1:63434fa:    *
1:cd6a4ff:    * @param row new row
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:cd6a4ff:    */
1:cd6a4ff:   public void addRow(Object[] row) throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     // if record holder list size is equal to sort buffer size then it will
1:cd6a4ff:     // sort the list and then write current list data to file
1:cd6a4ff:     int currentSize = entryCount;
1:cd6a4ff: 
1:cd6a4ff:     if (sortBufferSize == currentSize) {
1:4a79a86:       if (LOGGER.isDebugEnabled()) {
1:4a79a86:         LOGGER.debug("************ Writing to temp file ********** ");
1:4a79a86:       }
1:9aee980:       intermediateFileMerger.startMergingIfPossible();
1:cd6a4ff:       Object[][] recordHolderListLocal = recordHolderList;
5:cd6a4ff:       try {
1:cd6a4ff:         semaphore.acquire();
1:06b0d08:         dataSorterAndWriterExecutorService.execute(new DataSorterAndWriter(recordHolderListLocal));
1:cd6a4ff:       } catch (InterruptedException e) {
1:2b41f14:         LOGGER.error(e, "exception occurred while trying to acquire a semaphore lock: ");
1:a734add:         throw new CarbonSortKeyAndGroupByException(e);
1:496cde4:       }
1:cd6a4ff:       // create the new holder Array
2:cd6a4ff:       this.recordHolderList = new Object[this.sortBufferSize][];
1:cd6a4ff:       this.entryCount = 0;
1:496cde4:     }
1:cd6a4ff:     recordHolderList[entryCount++] = row;
1:496cde4:   }
1:496cde4: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to add new row
1:cd6a4ff:    *
1:63434fa:    * @param rowBatch new rowBatch
1:63434fa:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:63434fa:    */
1:63434fa:   public void addRowBatch(Object[][] rowBatch, int size) throws CarbonSortKeyAndGroupByException {
1:63434fa:     // if record holder list size is equal to sort buffer size then it will
1:63434fa:     // sort the list and then write current list data to file
1:63434fa:     synchronized (addRowsLock) {
1:c5aba5f:       int sizeLeft = 0;
1:63434fa:       if (entryCount + size >= sortBufferSize) {
1:4a79a86:         if (LOGGER.isDebugEnabled()) {
1:4a79a86:           LOGGER.debug("************ Writing to temp file ********** ");
1:4a79a86:         }
1:63434fa:         intermediateFileMerger.startMergingIfPossible();
1:63434fa:         Object[][] recordHolderListLocal = recordHolderList;
1:2b41f14:         sizeLeft = sortBufferSize - entryCount;
1:63434fa:         if (sizeLeft > 0) {
1:63434fa:           System.arraycopy(rowBatch, 0, recordHolderListLocal, entryCount, sizeLeft);
1:63434fa:         }
1:63434fa:         try {
1:013db60:           semaphore.acquire();
1:06b0d08:           dataSorterAndWriterExecutorService
1:06b0d08:               .execute(new DataSorterAndWriter(recordHolderListLocal));
1:63434fa:         } catch (Exception e) {
1:63434fa:           LOGGER.error(
1:63434fa:               "exception occurred while trying to acquire a semaphore lock: " + e.getMessage());
1:63434fa:           throw new CarbonSortKeyAndGroupByException(e);
1:63434fa:         }
1:63434fa:         // create the new holder Array
1:63434fa:         this.recordHolderList = new Object[this.sortBufferSize][];
1:63434fa:         this.entryCount = 0;
1:63434fa:         size = size - sizeLeft;
1:63434fa:         if (size == 0) {
1:63434fa:           return;
1:63434fa:         }
1:63434fa:       }
1:c5aba5f:       System.arraycopy(rowBatch, sizeLeft, recordHolderList, entryCount, size);
1:63434fa:       entryCount += size;
1:63434fa:     }
1:63434fa:   }
1:63434fa: 
1:63434fa:   /**
1:cd6a4ff:    * Below method will be used to start storing process This method will get
1:cd6a4ff:    * all the temp files present in sort temp folder then it will create the
1:cd6a4ff:    * record holder heap and then it will read first record from each file and
1:cd6a4ff:    * initialize the heap
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:cd6a4ff:   public void startSorting() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     LOGGER.info("File based sorting will be used");
1:cd6a4ff:     if (this.entryCount > 0) {
1:cd6a4ff:       Object[][] toSort;
1:cd6a4ff:       toSort = new Object[entryCount][];
1:cd6a4ff:       System.arraycopy(recordHolderList, 0, toSort, 0, entryCount);
1:9f94529:       if (parameters.getNumberOfNoDictSortColumns() > 0) {
1:9f94529:         Arrays.sort(toSort, new NewRowComparator(parameters.getNoDictionarySortColumn()));
2:8d8b589:       } else {
1:9f94529:         Arrays.sort(toSort, new NewRowComparatorForNormalDims(parameters.getNumberOfSortColumns()));
1:496cde4:       }
1:cd6a4ff:       recordHolderList = toSort;
1:cd6a4ff: 
1:ded8b41:       // create new file and choose folder randomly
1:ded8b41:       String[] tmpLocation = parameters.getTempFileLocation();
1:ded8b41:       String locationChosen = tmpLocation[new Random().nextInt(tmpLocation.length)];
1:d5396b1:       File file = new File(locationChosen + File.separator + parameters.getTableName()
1:d5396b1:           + '_' + parameters.getRangeId() + '_' + System.nanoTime()
1:d5396b1:           + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
1:c100251:       writeDataToFile(recordHolderList, this.entryCount, file);
1:496cde4:     }
1:8d8b589: 
1:cd6a4ff:     startFileBasedMerge();
1:cd6a4ff:     this.recordHolderList = null;
1:496cde4:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:2b41f14:    * Below method will be used to write data to sort temp file
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:cd6a4ff:    */
1:c100251:   private void writeDataToFile(Object[][] recordHolderList, int entryCountLocal, File file)
1:496cde4:       throws CarbonSortKeyAndGroupByException {
1:496cde4:     DataOutputStream stream = null;
1:496cde4:     try {
1:496cde4:       // open stream
1:c100251:       stream = FileFactory.getDataOutputStream(file.getPath(), FileFactory.FileType.LOCAL,
1:c100251:           parameters.getFileWriteBufferSize(), parameters.getSortTempCompressorName());
1:496cde4:       // write number of entries to the file
1:496cde4:       stream.writeInt(entryCountLocal);
1:496cde4:       for (int i = 0; i < entryCountLocal; i++) {
1:2b41f14:         sortStepRowHandler.writeRawRowAsIntermediateSortTempRowToOutputStream(
1:2b41f14:             recordHolderList[i], stream, rowBuffer.get());
1:8d8b589:       }
1:496cde4:     } catch (IOException e) {
1:496cde4:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
1:496cde4:     } finally {
1:496cde4:       // close streams
1:496cde4:       CarbonUtil.closeStreams(stream);
1:8d8b589:     }
1:8d8b589:   }
1:496cde4: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to delete sort temp location is it is exites
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:2b41f14:   private void deleteSortLocationIfExists() throws CarbonSortKeyAndGroupByException {
1:9aee980:     CarbonDataProcessorUtil.deleteSortLocationIfExists(parameters.getTempFileLocation());
1:8d8b589:   }
1:9aee980: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Below method will be used to start file based merge
1:cd6a4ff:    *
1:cd6a4ff:    * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:    */
1:cd6a4ff:   private void startFileBasedMerge() throws CarbonSortKeyAndGroupByException {
1:cd6a4ff:     try {
1:cd6a4ff:       dataSorterAndWriterExecutorService.shutdown();
1:cd6a4ff:       dataSorterAndWriterExecutorService.awaitTermination(2, TimeUnit.DAYS);
1:cd6a4ff:     } catch (InterruptedException e) {
1:cd6a4ff:       throw new CarbonSortKeyAndGroupByException("Problem while shutdown the server ", e);
1:8d8b589:     }
1:8d8b589:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Observer class for thread execution
1:cd6a4ff:    * In case of any failure we need stop all the running thread
1:cd6a4ff:    */
1:cd6a4ff:   private class ThreadStatusObserver {
1:cd6a4ff:     /**
1:cd6a4ff:      * Below method will be called if any thread fails during execution
1:cd6a4ff:      *
1:cd6a4ff:      * @param exception
1:cd6a4ff:      * @throws CarbonSortKeyAndGroupByException
1:cd6a4ff:      */
1:cd6a4ff:     public void notifyFailed(Throwable exception) throws CarbonSortKeyAndGroupByException {
1:a734add:       close();
1:9aee980:       parameters.getObserver().setFailed(true);
1:cd6a4ff:       LOGGER.error(exception);
1:cd6a4ff:       throw new CarbonSortKeyAndGroupByException(exception);
1:496cde4:     }
1:496cde4:   }
1:cd6a4ff: 
1:a734add:   public void close() {
1:a734add:     if (null != dataSorterAndWriterExecutorService && !dataSorterAndWriterExecutorService
1:a734add:         .isShutdown()) {
1:a734add:       dataSorterAndWriterExecutorService.shutdownNow();
1:a734add:     }
1:a734add:     intermediateFileMerger.close();
1:a734add:   }
1:a734add: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This class is responsible for sorting and writing the object
1:cd6a4ff:    * array which holds the records equal to given array size
1:cd6a4ff:    */
1:06b0d08:   private class DataSorterAndWriter implements Runnable {
1:cd6a4ff:     private Object[][] recordHolderArray;
1:cd6a4ff: 
1:cd6a4ff:     public DataSorterAndWriter(Object[][] recordHolderArray) {
1:cd6a4ff:       this.recordHolderArray = recordHolderArray;
1:496cde4:     }
1:cd6a4ff: 
1:06b0d08:     @Override
1:06b0d08:     public void run() {
1:cd6a4ff:       try {
1:cd6a4ff:         long startTime = System.currentTimeMillis();
1:9f94529:         if (parameters.getNumberOfNoDictSortColumns() > 0) {
1:e6b6090:           Arrays.sort(recordHolderArray,
1:9f94529:               new NewRowComparator(parameters.getNoDictionarySortColumn()));
1:8d8b589:         } else {
1:e6b6090:           Arrays.sort(recordHolderArray,
1:9f94529:               new NewRowComparatorForNormalDims(parameters.getNumberOfSortColumns()));
1:496cde4:         }
1:496cde4: 
1:ded8b41:         // create a new file and choose folder randomly every time
1:ded8b41:         String[] tmpFileLocation = parameters.getTempFileLocation();
1:ded8b41:         String locationChosen = tmpFileLocation[new Random().nextInt(tmpFileLocation.length)];
1:cd6a4ff:         File sortTempFile = new File(
1:d5396b1:             locationChosen + File.separator + parameters.getTableName()
1:d5396b1:                 + '_' + parameters.getRangeId() + '_' + System.nanoTime()
1:d5396b1:                 + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
1:c100251:         writeDataToFile(recordHolderArray, recordHolderArray.length, sortTempFile);
1:cd6a4ff:         // add sort temp filename to and arrayList. When the list size reaches 20 then
1:cd6a4ff:         // intermediate merging of sort temp files will be triggered
1:9aee980:         intermediateFileMerger.addFileToMerge(sortTempFile);
1:cd6a4ff:         LOGGER.info("Time taken to sort and write sort temp file " + sortTempFile + " is: " + (
1:2b41f14:             System.currentTimeMillis() - startTime) + ", sort temp file size in MB is "
1:2b41f14:             + sortTempFile.length() * 0.1 * 10 / 1024 / 1024);
1:cd6a4ff:       } catch (Throwable e) {
1:06b0d08:         try {
1:06b0d08:           threadStatusObserver.notifyFailed(e);
1:06b0d08:         } catch (CarbonSortKeyAndGroupByException ex) {
1:06b0d08:           LOGGER.error(ex);
1:06b0d08:         }
3:cd6a4ff:       } finally {
1:cd6a4ff:         semaphore.release();
1:496cde4:       }
1:496cde4:     }
1:496cde4:   }
1:496cde4: }
1:cd6a4ff: 
============================================================================
author:xuchuanyin
-------------------------------------------------------------------------------
commit:d5396b1
/////////////////////////////////////////////////////////////////////////
1:       File file = new File(locationChosen + File.separator + parameters.getTableName()
1:           + '_' + parameters.getRangeId() + '_' + System.nanoTime()
1:           + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
/////////////////////////////////////////////////////////////////////////
1:             locationChosen + File.separator + parameters.getTableName()
1:                 + '_' + parameters.getRangeId() + '_' + System.nanoTime()
1:                 + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
1: import java.nio.ByteBuffer;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:   private SortStepRowHandler sortStepRowHandler;
1:   private ThreadLocal<ByteBuffer> rowBuffer;
/////////////////////////////////////////////////////////////////////////
1:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
/////////////////////////////////////////////////////////////////////////
1:     this.rowBuffer = new ThreadLocal<ByteBuffer>() {
1:       @Override protected ByteBuffer initialValue() {
1:         byte[] backedArray = new byte[2 * 1024 * 1024];
1:         return ByteBuffer.wrap(backedArray);
1:       }
1:     };
/////////////////////////////////////////////////////////////////////////
1:         LOGGER.error(e, "exception occurred while trying to acquire a semaphore lock: ");
/////////////////////////////////////////////////////////////////////////
1:         sizeLeft = sortBufferSize - entryCount;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:    * Below method will be used to write data to sort temp file
/////////////////////////////////////////////////////////////////////////
1:         sortStepRowHandler.writeRawRowAsIntermediateSortTempRowToOutputStream(
1:             recordHolderList[i], stream, rowBuffer.get());
/////////////////////////////////////////////////////////////////////////
1:   private void deleteSortLocationIfExists() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
1:             System.currentTimeMillis() - startTime) + ", sort temp file size in MB is "
1:             + sortTempFile.length() * 0.1 * 10 / 1024 / 1024);
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
0: import java.math.BigDecimal;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
0: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         LOGGER.error(e,
0:             "exception occurred while trying to acquire a semaphore lock: ");
/////////////////////////////////////////////////////////////////////////
0:         sizeLeft = sortBufferSize - entryCount ;
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:    * Below method will be used to write data to file
/////////////////////////////////////////////////////////////////////////
0:       int complexDimColCount = parameters.getComplexDimColCount();
0:       int dimColCount = parameters.getDimColCount() + complexDimColCount;
0:       DataType[] type = parameters.getMeasureDataType();
0:       boolean[] noDictionaryDimnesionMapping = parameters.getNoDictionaryDimnesionColumn();
0:       Object[] row = null;
0:         // get row from record holder list
0:         row = recordHolderList[i];
0:         int dimCount = 0;
0:         // write dictionary and non dictionary dimensions here.
0:         for (; dimCount < noDictionaryDimnesionMapping.length; dimCount++) {
0:           if (noDictionaryDimnesionMapping[dimCount]) {
0:             byte[] col = (byte[]) row[dimCount];
0:             stream.writeShort(col.length);
0:             stream.write(col);
1:           } else {
0:             stream.writeInt((int)row[dimCount]);
1:           }
1:         }
0:         // write complex dimensions here.
0:         for (; dimCount < dimColCount; dimCount++) {
0:           byte[] value = (byte[])row[dimCount];
0:           stream.writeShort(value.length);
0:           stream.write(value);
1:         }
0:         // as measures are stored in separate array.
0:         for (int mesCount = 0;
0:              mesCount < parameters.getMeasureColCount(); mesCount++) {
0:           Object value = row[mesCount + dimColCount];
0:           if (null != value) {
0:             stream.write((byte) 1);
0:             DataType dataType = type[mesCount];
0:             if (dataType == DataTypes.BOOLEAN) {
0:               stream.writeBoolean((boolean) value);
0:             } else if (dataType == DataTypes.SHORT) {
0:               stream.writeShort((Short) value);
0:             } else if (dataType == DataTypes.INT) {
0:               stream.writeInt((Integer) value);
0:             } else if (dataType == DataTypes.LONG) {
0:               stream.writeLong((Long) value);
0:             } else if (dataType == DataTypes.DOUBLE) {
0:               stream.writeDouble((Double) value);
0:             } else if (DataTypes.isDecimal(dataType)) {
0:               BigDecimal val = (BigDecimal) value;
0:               byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:               stream.writeInt(bigDecimalInBytes.length);
0:               stream.write(bigDecimalInBytes);
1:             } else {
0:               throw new IllegalArgumentException("unsupported data type:" + type[mesCount]);
1:             }
1:           } else {
0:             stream.write((byte) 0);
1:           }
1:         }
/////////////////////////////////////////////////////////////////////////
0:   public void deleteSortLocationIfExists() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:             System.currentTimeMillis() - startTime));
commit:21704cf
/////////////////////////////////////////////////////////////////////////
0: import java.nio.ByteBuffer;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:   private SortStepRowHandler sortStepRowHandler;
0:   private ThreadLocal<ByteBuffer> rowBuffer;
/////////////////////////////////////////////////////////////////////////
0:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
/////////////////////////////////////////////////////////////////////////
0:     this.rowBuffer = new ThreadLocal<ByteBuffer>() {
0:       @Override protected ByteBuffer initialValue() {
0:         byte[] backedArray = new byte[2 * 1024 * 1024];
0:         return ByteBuffer.wrap(backedArray);
1:       }
0:     };
/////////////////////////////////////////////////////////////////////////
0:         LOGGER.error(e, "exception occurred while trying to acquire a semaphore lock: ");
/////////////////////////////////////////////////////////////////////////
0:         sizeLeft = sortBufferSize - entryCount;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:    * Below method will be used to write data to sort temp file
/////////////////////////////////////////////////////////////////////////
0:         sortStepRowHandler.writeRawRowAsIntermediateSortTempRowToOutputStream(
0:             recordHolderList[i], stream, rowBuffer.get());
/////////////////////////////////////////////////////////////////////////
0:   private void deleteSortLocationIfExists() throws CarbonSortKeyAndGroupByException {
/////////////////////////////////////////////////////////////////////////
0:             System.currentTimeMillis() - startTime) + ", sort temp file size in MB is "
0:             + sortTempFile.length() * 0.1 * 10 / 1024 / 1024);
commit:c100251
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
1:       writeDataToFile(recordHolderList, this.entryCount, file);
/////////////////////////////////////////////////////////////////////////
1:   private void writeDataToFile(Object[][] recordHolderList, int entryCountLocal, File file)
1:       stream = FileFactory.getDataOutputStream(file.getPath(), FileFactory.FileType.LOCAL,
1:           parameters.getFileWriteBufferSize(), parameters.getSortTempCompressorName());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         writeDataToFile(recordHolderArray, recordHolderArray.length, sortTempFile);
commit:ded8b41
/////////////////////////////////////////////////////////////////////////
1: import java.util.Random;
/////////////////////////////////////////////////////////////////////////
1:     CarbonDataProcessorUtil.createLocations(parameters.getTempFileLocation());
/////////////////////////////////////////////////////////////////////////
1:       // create new file and choose folder randomly
1:       String[] tmpLocation = parameters.getTempFileLocation();
1:       String locationChosen = tmpLocation[new Random().nextInt(tmpLocation.length)];
0:           locationChosen + File.separator + parameters.getTableName() +
/////////////////////////////////////////////////////////////////////////
1:         // create a new file and choose folder randomly every time
1:         String[] tmpFileLocation = parameters.getTempFileLocation();
1:         String locationChosen = tmpFileLocation[new Random().nextInt(tmpFileLocation.length)];
0:             locationChosen + File.separator + parameters.getTableName() + System
author:Jacky Li
-------------------------------------------------------------------------------
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:             } else if (DataTypes.isDecimal(dataType)) {
commit:956833e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:             DataType dataType = type[mesCount];
0:             if (dataType == DataTypes.SHORT) {
0:               stream.writeShort((Short) value);
0:             } else if (dataType == DataTypes.INT) {
0:               stream.writeInt((Integer) value);
0:             } else if (dataType == DataTypes.LONG) {
0:               stream.writeLong((Long) value);
0:             } else if (dataType == DataTypes.DOUBLE) {
0:               stream.writeDouble((Double) value);
0:             } else if (dataType == DataTypes.DECIMAL) {
0:               BigDecimal val = (BigDecimal) value;
0:               byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:               stream.writeInt(bigDecimalInBytes.length);
0:               stream.write(bigDecimalInBytes);
0:             } else {
0:               throw new IllegalArgumentException("unsupported data type:" + type[mesCount]);
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.sort.sortdata;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
author:xubo245
-------------------------------------------------------------------------------
commit:6abdd97
/////////////////////////////////////////////////////////////////////////
0:             if (dataType == DataTypes.BOOLEAN) {
0:               stream.writeBoolean((boolean) value);
0:             } else if (dataType == DataTypes.SHORT) {
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.CarbonThreadFactory;
/////////////////////////////////////////////////////////////////////////
1:     this.dataSorterAndWriterExecutorService = Executors
1:         .newFixedThreadPool(parameters.getNumberOfCores(),
1:             new CarbonThreadFactory("SortDataRowPool:" + parameters.getTableName()));
/////////////////////////////////////////////////////////////////////////
0:         LOGGER.error(e,
0:             "exception occurred while trying to acquire a semaphore lock: ");
1:         throw new CarbonSortKeyAndGroupByException(e);
/////////////////////////////////////////////////////////////////////////
1:       close();
1:   public void close() {
1:     if (null != dataSorterAndWriterExecutorService && !dataSorterAndWriterExecutorService
1:         .isShutdown()) {
1:       dataSorterAndWriterExecutorService.shutdownNow();
1:     }
1:     intermediateFileMerger.close();
1:   }
1: 
author:Raghunandan S
-------------------------------------------------------------------------------
commit:06b0d08
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         dataSorterAndWriterExecutorService.execute(new DataSorterAndWriter(recordHolderListLocal));
/////////////////////////////////////////////////////////////////////////
1:           dataSorterAndWriterExecutorService
1:               .execute(new DataSorterAndWriter(recordHolderListLocal));
/////////////////////////////////////////////////////////////////////////
0:               default:
0:                 throw new IllegalArgumentException("unsupported data type:" + type[mesCount]);
/////////////////////////////////////////////////////////////////////////
1:   private class DataSorterAndWriter implements Runnable {
1:     @Override
1:     public void run() {
/////////////////////////////////////////////////////////////////////////
1:         try {
1:           threadStatusObserver.notifyFailed(e);
1:         } catch (CarbonSortKeyAndGroupByException ex) {
1:           LOGGER.error(ex);
1:         }
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:4a79a86
/////////////////////////////////////////////////////////////////////////
1:       if (LOGGER.isDebugEnabled()) {
1:         LOGGER.debug("************ Writing to temp file ********** ");
1:       }
/////////////////////////////////////////////////////////////////////////
1:         if (LOGGER.isDebugEnabled()) {
1:           LOGGER.debug("************ Writing to temp file ********** ");
1:         }
author:ravipesala
-------------------------------------------------------------------------------
commit:8b3fa7f
/////////////////////////////////////////////////////////////////////////
0:                 stream.writeShort((Short) value);
0:                 break;
0:                 stream.writeInt((Integer) value);
0:                 break;
commit:013db60
/////////////////////////////////////////////////////////////////////////
1:           semaphore.acquire();
commit:e6b6090
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       if (parameters.getNoDictionaryCount() > 0) {
0:         Arrays.sort(toSort, new NewRowComparator(parameters.getNoDictionaryDimnesionColumn()));
0:         Arrays.sort(toSort, new NewRowComparatorForNormalDims(parameters.getDimColCount()));
/////////////////////////////////////////////////////////////////////////
0:     writeData(recordHolderList, entryCountLocal, file);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         if (parameters.getNoDictionaryCount() > 0) {
1:           Arrays.sort(recordHolderArray,
0:               new NewRowComparator(parameters.getNoDictionaryDimnesionColumn()));
1:           Arrays.sort(recordHolderArray,
0:               new NewRowComparatorForNormalDims(parameters.getDimColCount()));
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:           stream.writeInt(NonDictionaryUtil.getDimension(fieldIndex++, row));
0:           stream.write(NonDictionaryUtil.getByteArrayForNoDictionaryCols(row));
0:           if (null != NonDictionaryUtil.getMeasure(fieldIndex, row)) {
0:               Double val = (Double) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:               Long val = (Long) NonDictionaryUtil.getMeasure(fieldIndex, row);
0:               BigDecimal val = (BigDecimal) NonDictionaryUtil.getMeasure(fieldIndex, row);
commit:8100d94
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.CarbonProperties;
/////////////////////////////////////////////////////////////////////////
1:     int batchSize = CarbonProperties.getInstance().getBatchSize();
1: 
1:     this.sortBufferSize = Math.max(parameters.getSortBufferSize(), batchSize);
/////////////////////////////////////////////////////////////////////////
1:     this.recordHolderList = new Object[sortBufferSize][];
commit:63434fa
/////////////////////////////////////////////////////////////////////////
1:   private final Object addRowsLock = new Object();
1: 
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to add new row
1:    *
1:    * @param rowBatch new rowBatch
1:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
1:   public void addRowBatch(Object[][] rowBatch, int size) throws CarbonSortKeyAndGroupByException {
1:     // if record holder list size is equal to sort buffer size then it will
1:     // sort the list and then write current list data to file
1:     synchronized (addRowsLock) {
1:       if (entryCount + size >= sortBufferSize) {
0:         LOGGER.debug("************ Writing to temp file ********** ");
1:         intermediateFileMerger.startMergingIfPossible();
1:         Object[][] recordHolderListLocal = recordHolderList;
0:         int sizeLeft = sortBufferSize - entryCount ;
1:         if (sizeLeft > 0) {
1:           System.arraycopy(rowBatch, 0, recordHolderListLocal, entryCount, sizeLeft);
1:         }
1:         try {
0:           dataSorterAndWriterExecutorService.submit(new DataSorterAndWriter(recordHolderListLocal));
1:         } catch (Exception e) {
1:           LOGGER.error(
1:               "exception occurred while trying to acquire a semaphore lock: " + e.getMessage());
1:           throw new CarbonSortKeyAndGroupByException(e);
1:         }
1:         // create the new holder Array
1:         this.recordHolderList = new Object[this.sortBufferSize][];
1:         this.entryCount = 0;
1:         size = size - sizeLeft;
1:         if (size == 0) {
1:           return;
1:         }
1:       }
0:       System.arraycopy(rowBatch, 0, recordHolderList, entryCount, size);
1:       entryCount += size;
1:     }
1:   }
1: 
1:   /**
commit:496cde4
/////////////////////////////////////////////////////////////////////////
0:       if (parameters.isUseKettle()) {
0:         if (parameters.getNoDictionaryCount() > 0) {
0:           Arrays.sort(toSort, new RowComparator(parameters.getNoDictionaryDimnesionColumn(),
0:               parameters.getNoDictionaryCount()));
0:         } else {
0:           Arrays.sort(toSort, new RowComparatorForNormalDims(parameters.getDimColCount()));
1:         }
0:         if (parameters.getNoDictionaryCount() > 0) {
0:           Arrays.sort(toSort, new NewRowComparator(parameters.getNoDictionaryDimnesionColumn()));
0:         } else {
0:           Arrays.sort(toSort, new NewRowComparatorForNormalDims(parameters.getDimColCount()));
1:         }
/////////////////////////////////////////////////////////////////////////
0:     if (parameters.isUseKettle()) {
0:       writeData(recordHolderList, entryCountLocal, file);
0:     } else {
0:       writeDataWithOutKettle(recordHolderList, entryCountLocal, file);
1:     }
/////////////////////////////////////////////////////////////////////////
0:   // TODO Remove it after kettle got removed
/////////////////////////////////////////////////////////////////////////
0:   private void writeDataWithOutKettle(Object[][] recordHolderList, int entryCountLocal, File file)
1:       throws CarbonSortKeyAndGroupByException {
1:     DataOutputStream stream = null;
1:     try {
1:       // open stream
0:       stream = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(file),
0:           parameters.getFileWriteBufferSize()));
1: 
1:       // write number of entries to the file
1:       stream.writeInt(entryCountLocal);
0:       int complexDimColCount = parameters.getComplexDimColCount();
0:       int dimColCount = parameters.getDimColCount() + complexDimColCount;
0:       char[] aggType = parameters.getAggType();
0:       boolean[] noDictionaryDimnesionMapping = parameters.getNoDictionaryDimnesionColumn();
0:       Object[] row = null;
1:       for (int i = 0; i < entryCountLocal; i++) {
0:         // get row from record holder list
0:         row = recordHolderList[i];
0:         int dimCount = 0;
0:         // write dictionary and non dictionary dimensions here.
0:         for (; dimCount < noDictionaryDimnesionMapping.length; dimCount++) {
0:           if (noDictionaryDimnesionMapping[dimCount]) {
0:             byte[] col = (byte[]) row[dimCount];
0:             stream.writeShort(col.length);
0:             stream.write(col);
0:           } else {
0:             stream.writeInt((int)row[dimCount]);
1:           }
1:         }
0:         // write complex dimensions here.
0:         for (; dimCount < dimColCount; dimCount++) {
0:           byte[] value = (byte[])row[dimCount];
0:           stream.writeShort(value.length);
0:           stream.write(value);
1:         }
0:         // as measures are stored in separate array.
0:         for (int mesCount = 0;
0:              mesCount < parameters.getMeasureColCount(); mesCount++) {
0:           Object value = row[mesCount + dimColCount];
0:           if (null != value) {
0:             stream.write((byte) 1);
0:             if (aggType[mesCount] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:               Double val = (Double) value;
0:               stream.writeDouble(val);
0:             } else if (aggType[mesCount] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:               Long val = (Long) value;
0:               stream.writeLong(val);
0:             } else if (aggType[mesCount] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:               BigDecimal val = (BigDecimal) value;
0:               byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:               stream.writeInt(bigDecimalInBytes.length);
0:               stream.write(bigDecimalInBytes);
1:             }
0:           } else {
0:             stream.write((byte) 0);
1:           }
1:         }
1:       }
1:     } catch (IOException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
1:     } finally {
1:       // close streams
1:       CarbonUtil.closeStreams(stream);
1:     }
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
0:         if (parameters.isUseKettle()) {
0:           if (parameters.getNoDictionaryCount() > 0) {
0:             Arrays.sort(recordHolderArray,
0:                 new RowComparator(parameters.getNoDictionaryDimnesionColumn(),
0:                     parameters.getNoDictionaryCount()));
0:           } else {
0:             Arrays.sort(recordHolderArray,
0:                 new RowComparatorForNormalDims(parameters.getDimColCount()));
1:           }
0:           if (parameters.getNoDictionaryCount() > 0) {
0:             Arrays.sort(recordHolderArray,
0:                 new NewRowComparator(parameters.getNoDictionaryDimnesionColumn()));
0:           } else {
0:             Arrays.sort(recordHolderArray,
0:                 new NewRowComparatorForNormalDims(parameters.getDimColCount()));
1:           }
1: 
commit:9aee980
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private SortParameters parameters;
1:   private int sortBufferSize;
1:   private SortIntermediateFileMerger intermediateFileMerger;
1:   public SortDataRows(SortParameters parameters,
1:       SortIntermediateFileMerger intermediateFileMerger) {
1:     this.parameters = parameters;
1:     this.intermediateFileMerger = intermediateFileMerger;
0:     this.sortBufferSize = parameters.getSortBufferSize();
1:   public void initialize() throws CarbonSortKeyAndGroupByException {
0:     this.recordHolderList = new Object[parameters.getSortBufferSize()][];
0:     if (!new File(parameters.getTempFileLocation()).mkdirs()) {
0:     this.dataSorterAndWriterExecutorService =
0:         Executors.newFixedThreadPool(parameters.getNumberOfCores());
1:     semaphore = new Semaphore(parameters.getNumberOfCores());
/////////////////////////////////////////////////////////////////////////
1:       intermediateFileMerger.startMergingIfPossible();
/////////////////////////////////////////////////////////////////////////
0:       if (parameters.getNoDictionaryCount() > 0) {
0:         Arrays.sort(toSort, new RowComparator(parameters.getNoDictionaryDimnesionColumn(),
0:             parameters.getNoDictionaryCount()));
0:         Arrays.sort(toSort, new RowComparatorForNormalDims(parameters.getDimColCount()));
0:       File file = new File(
0:           parameters.getTempFileLocation() + File.separator + parameters.getTableName() +
0:               System.nanoTime() + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
/////////////////////////////////////////////////////////////////////////
0:     if (parameters.isSortFileCompressionEnabled() || parameters.isPrefetch()) {
/////////////////////////////////////////////////////////////////////////
0:       if (writer != null) {
/////////////////////////////////////////////////////////////////////////
0:       stream = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(file),
0:           parameters.getFileWriteBufferSize()));
0:       int dimColCount = parameters.getDimColCount();
0:       int combinedDimCount = parameters.getNoDictionaryCount() + parameters.getComplexDimColCount();
0:       char[] aggType = parameters.getAggType();
0:         for (int dimCount = 0; dimCount < dimColCount; dimCount++) {
1: 
0:         if (combinedDimCount > 0) {
0:         for (int mesCount = 0; mesCount < parameters.getMeasureColCount(); mesCount++) {
/////////////////////////////////////////////////////////////////////////
0:         .getTempSortFileWriter(parameters.isSortFileCompressionEnabled(),
0:             parameters.getDimColCount(), parameters.getComplexDimColCount(),
0:             parameters.getMeasureColCount(), parameters.getNoDictionaryCount(),
0:             parameters.getFileWriteBufferSize());
0:     if (parameters.isPrefetch() && !parameters.isSortFileCompressionEnabled()) {
0:       chunkWriter = new SortTempFileChunkWriter(writer, parameters.getBufferSize());
0:       chunkWriter =
0:           new SortTempFileChunkWriter(writer, parameters.getSortTempFileNoOFRecordsInCompression());
1:     CarbonDataProcessorUtil.deleteSortLocationIfExists(parameters.getTempFileLocation());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       intermediateFileMerger.close();
1:       parameters.getObserver().setFailed(true);
/////////////////////////////////////////////////////////////////////////
0:         if (parameters.getNoDictionaryCount() > 0) {
0:               new RowComparator(parameters.getNoDictionaryDimnesionColumn(),
0:                   parameters.getNoDictionaryCount()));
0:           Arrays
0:               .sort(recordHolderArray, new RowComparatorForNormalDims(parameters.getDimColCount()));
0:             parameters.getTempFileLocation() + File.separator + parameters.getTableName() + System
0:                 .nanoTime() + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
1:         intermediateFileMerger.addFileToMerge(sortTempFile);
commit:cd6a4ff
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.sortandgroupby.sortdata;
1: 
0: import java.io.BufferedOutputStream;
1: import java.io.DataOutputStream;
1: import java.io.File;
0: import java.io.FileOutputStream;
1: import java.io.IOException;
0: import java.math.BigDecimal;
0: import java.util.ArrayList;
1: import java.util.Arrays;
0: import java.util.List;
0: import java.util.concurrent.Callable;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.Semaphore;
1: import java.util.concurrent.TimeUnit;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.carbon.metadata.CarbonMetadata;
0: import org.apache.carbondata.core.carbon.metadata.schema.table.CarbonTable;
0: import org.apache.carbondata.core.carbon.metadata.schema.table.column.CarbonMeasure;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.schema.metadata.SortObserver;
0: import org.apache.carbondata.processing.sortandgroupby.exception.CarbonSortKeyAndGroupByException;
1: import org.apache.carbondata.processing.util.CarbonDataProcessorUtil;
0: import org.apache.carbondata.processing.util.RemoveDictionaryUtil;
1: 
1: public class SortDataRows {
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(SortDataRows.class.getName());
1:   /**
0:    * lockObject
1:    */
0:   private final Object lockObject = new Object();
1:   /**
0:    * tempFileLocation
1:    */
0:   private String tempFileLocation;
1:   /**
1:    * entryCount
1:    */
1:   private int entryCount;
1:   /**
0:    * sortBufferSize
1:    */
0:   private int sortBufferSize;
1:   /**
1:    * record holder array
1:    */
1:   private Object[][] recordHolderList;
1:   /**
0:    * measure count
1:    */
0:   private int measureColCount;
1:   /**
0:    * measure count
1:    */
0:   private int dimColCount;
1:   /**
0:    * measure count
1:    */
0:   private int complexDimColCount;
1:   /**
0:    * fileBufferSize
1:    */
0:   private int fileBufferSize;
1:   /**
0:    * numberOfIntermediateFileToBeMerged
1:    */
0:   private int numberOfIntermediateFileToBeMerged;
1:   /**
0:    * executorService
1:    */
0:   private ExecutorService executorService;
1:   /**
0:    * fileWriteBufferSize
1:    */
0:   private int fileWriteBufferSize;
1:   /**
0:    * procFiles
1:    */
0:   private List<File> procFiles;
1:   /**
0:    * observer
1:    */
0:   private SortObserver observer;
1:   /**
1:    * threadStatusObserver
1:    */
1:   private ThreadStatusObserver threadStatusObserver;
1:   /**
0:    * sortTempFileNoOFRecordsInCompression
1:    */
0:   private int sortTempFileNoOFRecordsInCompression;
1:   /**
0:    * isSortTempFileCompressionEnabled
1:    */
0:   private boolean isSortFileCompressionEnabled;
1:   /**
0:    * prefetch
1:    */
0:   private boolean prefetch;
1:   /**
0:    * bufferSize
1:    */
0:   private int bufferSize;
0:   private String databaseName;
0:   private String tableName;
1: 
0:   private char[] aggType;
1: 
1:   /**
0:    * To know how many columns are of high cardinality.
1:    */
0:   private int noDictionaryCount;
1:   /**
0:    * partitionID
1:    */
0:   private String partitionID;
1:   /**
0:    * Id of the load folder
1:    */
0:   private String segmentId;
1:   /**
0:    * task id, each spark task has a unique id
1:    */
0:   private String taskNo;
1: 
1:   /**
0:    * This will tell whether dimension is dictionary or not.
1:    */
0:   private boolean[] noDictionaryDimnesionColumn;
1:   /**
1:    * executor service for data sort holder
1:    */
1:   private ExecutorService dataSorterAndWriterExecutorService;
1:   /**
1:    * semaphore which will used for managing sorted data object arrays
1:    */
1:   private Semaphore semaphore;
1: 
0:   public SortDataRows(String tableName, int dimColCount, int complexDimColCount,
0:       int measureColCount, SortObserver observer, int noDictionaryCount, String partitionID,
0:       String segmentId, String taskNo, boolean[] noDictionaryColMaping) {
0:     // set table name
0:     this.tableName = tableName;
0:     this.partitionID = partitionID;
0:     this.segmentId = segmentId;
0:     this.taskNo = taskNo;
0:     // set measure count
0:     this.measureColCount = measureColCount;
1: 
0:     this.dimColCount = dimColCount;
1: 
0:     this.noDictionaryCount = noDictionaryCount;
0:     this.complexDimColCount = complexDimColCount;
0:     this.noDictionaryDimnesionColumn = noDictionaryColMaping;
1: 
0:     // processed file list
0:     this.procFiles = new ArrayList<File>(CarbonCommonConstants.CONSTANT_SIZE_TEN);
1: 
0:     // observer for main sorting
0:     this.observer = observer;
1: 
1:     // observer of writing file in thread
1:     this.threadStatusObserver = new ThreadStatusObserver();
0:     this.aggType = new char[measureColCount];
1:   }
1: 
1:   /**
1:    * This method will be used to initialize
1:    */
0:   public void initialize(String databaseName, String tableName)
0:       throws CarbonSortKeyAndGroupByException {
0:     this.databaseName = databaseName;
0:     this.tableName = tableName;
1: 
0:     CarbonProperties carbonProperties = CarbonProperties.getInstance();
0:     setSortConfiguration(carbonProperties);
1: 
1:     // create holder list which will hold incoming rows
1:     // size of list will be sort buffer size + 1 to avoid creation of new
1:     // array in list array
1:     this.recordHolderList = new Object[this.sortBufferSize][];
0:     updateSortTempFileLocation();
1: 
1:     // Delete if any older file exists in sort temp folder
1:     deleteSortLocationIfExists();
1: 
1:     // create new sort temp directory
0:     if (!new File(this.tempFileLocation).mkdirs()) {
0:       LOGGER.info("Sort Temp Location Already Exists");
1:     }
0:     int numberOfCores = 0;
1:     try {
0:       numberOfCores = Integer.parseInt(CarbonProperties.getInstance()
0:           .getProperty(CarbonCommonConstants.NUM_CORES_LOADING,
0:               CarbonCommonConstants.NUM_CORES_DEFAULT_VAL));
0:       numberOfCores = numberOfCores / 2;
0:     } catch (NumberFormatException exc) {
0:       numberOfCores = Integer.parseInt(CarbonCommonConstants.NUM_CORES_DEFAULT_VAL);
1:     }
0:     this.executorService = Executors.newFixedThreadPool(numberOfCores);
0:     this.dataSorterAndWriterExecutorService = Executors.newFixedThreadPool(numberOfCores);
0:     semaphore = new Semaphore(numberOfCores);
0:     this.fileWriteBufferSize = Integer.parseInt(carbonProperties
0:         .getProperty(CarbonCommonConstants.CARBON_SORT_FILE_WRITE_BUFFER_SIZE,
0:             CarbonCommonConstants.CARBON_SORT_FILE_WRITE_BUFFER_SIZE_DEFAULT_VALUE));
1: 
0:     this.isSortFileCompressionEnabled = Boolean.parseBoolean(carbonProperties
0:         .getProperty(CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED,
0:             CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED_DEFAULTVALUE));
1: 
1:     try {
0:       this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(carbonProperties
0:           .getProperty(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION,
0:               CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE));
0:       if (this.sortTempFileNoOFRecordsInCompression < 1) {
0:         LOGGER.error("Invalid value for: "
0:             + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:             + ":Only Positive Integer value(greater than zero) is allowed.Default value will "
0:             + "be used");
1: 
0:         this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(
0:             CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:       }
0:     } catch (NumberFormatException e) {
0:       LOGGER.error(
0:           "Invalid value for: " + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:               + ", only Positive Integer value is allowed. Default value will be used");
1: 
0:       this.sortTempFileNoOFRecordsInCompression = Integer
0:           .parseInt(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:     }
1: 
0:     if (isSortFileCompressionEnabled) {
0:       LOGGER.info("Compression will be used for writing the sort temp File");
1:     }
1: 
0:     prefetch = CarbonCommonConstants.CARBON_PREFETCH_IN_MERGE_VALUE;
0:     bufferSize = CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE;
1: 
0:     initAggType();
1:   }
1: 
0:   private void initAggType() {
0:     Arrays.fill(aggType, 'n');
0:     CarbonTable carbonTable = CarbonMetadata.getInstance()
0:         .getCarbonTable(databaseName + CarbonCommonConstants.UNDERSCORE + tableName);
0:     List<CarbonMeasure> measures = carbonTable.getMeasureByTableName(tableName);
0:     for (int i = 0; i < measureColCount; i++) {
0:       aggType[i] = DataTypeUtil.getAggType(measures.get(i).getDataType());
1:     }
1:   }
1: 
1:   /**
1:    * This method will be used to add new row
1:    *
1:    * @param row new row
1:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
1:   public void addRow(Object[] row) throws CarbonSortKeyAndGroupByException {
1:     // if record holder list size is equal to sort buffer size then it will
1:     // sort the list and then write current list data to file
1:     int currentSize = entryCount;
1: 
1:     if (sortBufferSize == currentSize) {
0:       LOGGER.debug("************ Writing to temp file ********** ");
1: 
0:       File[] fileList;
0:       if (procFiles.size() >= numberOfIntermediateFileToBeMerged) {
0:         synchronized (lockObject) {
0:           fileList = procFiles.toArray(new File[procFiles.size()]);
0:           this.procFiles = new ArrayList<File>(1);
1:         }
1: 
0:         LOGGER.debug("Sumitting request for intermediate merging no of files: " + fileList.length);
0:         startIntermediateMerging(fileList);
1:       }
1:       Object[][] recordHolderListLocal = recordHolderList;
1:       try {
1:         semaphore.acquire();
0:         dataSorterAndWriterExecutorService.submit(new DataSorterAndWriter(recordHolderListLocal));
1:       } catch (InterruptedException e) {
0:         LOGGER.error(
0:             "exception occurred while trying to acquire a semaphore lock: " + e.getMessage());
0:         throw new CarbonSortKeyAndGroupByException(e.getMessage());
1:       }
1:       // create the new holder Array
1:       this.recordHolderList = new Object[this.sortBufferSize][];
1:       this.entryCount = 0;
1:     }
1:     recordHolderList[entryCount++] = row;
1:   }
1: 
1:   /**
1:    * Below method will be used to start storing process This method will get
1:    * all the temp files present in sort temp folder then it will create the
1:    * record holder heap and then it will read first record from each file and
1:    * initialize the heap
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   public void startSorting() throws CarbonSortKeyAndGroupByException {
1:     LOGGER.info("File based sorting will be used");
1:     if (this.entryCount > 0) {
1:       Object[][] toSort;
1:       toSort = new Object[entryCount][];
1:       System.arraycopy(recordHolderList, 0, toSort, 0, entryCount);
1: 
0:       if (noDictionaryCount > 0) {
0:         Arrays.sort(toSort, new RowComparator(noDictionaryDimnesionColumn, noDictionaryCount));
0:       } else {
1: 
0:         Arrays.sort(toSort, new RowComparatorForNormalDims(this.dimColCount));
1:       }
1:       recordHolderList = toSort;
1: 
0:       // create new file
0:       File file =
0:           new File(this.tempFileLocation + File.separator + this.tableName + System.nanoTime() +
0:               CarbonCommonConstants.SORT_TEMP_FILE_EXT);
0:       writeDataTofile(recordHolderList, this.entryCount, file);
1: 
1:     }
1: 
1:     startFileBasedMerge();
0:     procFiles = null;
1:     this.recordHolderList = null;
1:   }
1: 
1:   /**
0:    * Below method will be used to write data to file
1:    *
1:    * @throws CarbonSortKeyAndGroupByException problem while writing
1:    */
0:   private void writeDataTofile(Object[][] recordHolderList, int entryCountLocal, File file)
0:       throws CarbonSortKeyAndGroupByException {
0:     // stream
0:     if (isSortFileCompressionEnabled || prefetch) {
0:       writeSortTempFile(recordHolderList, entryCountLocal, file);
0:       return;
1:     }
0:     writeData(recordHolderList, entryCountLocal, file);
1:   }
1: 
0:   private void writeSortTempFile(Object[][] recordHolderList, int entryCountLocal, File file)
0:       throws CarbonSortKeyAndGroupByException {
0:     TempSortFileWriter writer = null;
1: 
1:     try {
0:       writer = getWriter();
0:       writer.initiaize(file, entryCountLocal);
0:       writer.writeSortTempFile(recordHolderList);
0:     } catch (CarbonSortKeyAndGroupByException e) {
0:       LOGGER.error(e, "Problem while writing the sort temp file");
0:       throw e;
1:     } finally {
0:       if(writer != null) {
0:         writer.finish();
1:       }
1:     }
1:   }
1: 
0:   private void writeData(Object[][] recordHolderList, int entryCountLocal, File file)
0:       throws CarbonSortKeyAndGroupByException {
0:     DataOutputStream stream = null;
1:     try {
0:       // open stream
0:       stream = new DataOutputStream(
0:           new BufferedOutputStream(new FileOutputStream(file), fileWriteBufferSize));
1: 
0:       // write number of entries to the file
0:       stream.writeInt(entryCountLocal);
0:       Object[] row = null;
0:       for (int i = 0; i < entryCountLocal; i++) {
0:         // get row from record holder list
0:         row = recordHolderList[i];
0:         int fieldIndex = 0;
1: 
0:         for (int dimCount = 0; dimCount < this.dimColCount; dimCount++) {
0:           stream.writeInt(RemoveDictionaryUtil.getDimension(fieldIndex++, row));
1:         }
1: 
0:         // if any high cardinality dims are present then write it to the file.
0:         if ((this.noDictionaryCount + this.complexDimColCount) > 0) {
0:           stream.write(RemoveDictionaryUtil.getByteArrayForNoDictionaryCols(row));
1:         }
1: 
0:         // as measures are stored in separate array.
0:         fieldIndex = 0;
0:         for (int mesCount = 0; mesCount < this.measureColCount; mesCount++) {
0:           if (null != RemoveDictionaryUtil.getMeasure(fieldIndex, row)) {
0:             stream.write((byte) 1);
0:             if (aggType[mesCount] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:               Double val = (Double) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:               stream.writeDouble(val);
0:             } else if (aggType[mesCount] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:               Long val = (Long) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:               stream.writeLong(val);
0:             } else if (aggType[mesCount] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:               BigDecimal val = (BigDecimal) RemoveDictionaryUtil.getMeasure(fieldIndex, row);
0:               byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:               stream.writeInt(bigDecimalInBytes.length);
0:               stream.write(bigDecimalInBytes);
1:             }
0:           } else {
0:             stream.write((byte) 0);
1:           }
0:           fieldIndex++;
1:         }
1:       }
0:     } catch (IOException e) {
0:       throw new CarbonSortKeyAndGroupByException("Problem while writing the file", e);
1:     } finally {
0:       // close streams
0:       CarbonUtil.closeStreams(stream);
1:     }
1:   }
1: 
0:   private TempSortFileWriter getWriter() {
0:     TempSortFileWriter chunkWriter = null;
0:     TempSortFileWriter writer = TempSortFileWriterFactory.getInstance()
0:         .getTempSortFileWriter(isSortFileCompressionEnabled, dimColCount, complexDimColCount,
0:             measureColCount, noDictionaryCount, fileWriteBufferSize);
1: 
0:     if (prefetch && !isSortFileCompressionEnabled) {
0:       chunkWriter = new SortTempFileChunkWriter(writer, bufferSize);
0:     } else {
0:       chunkWriter = new SortTempFileChunkWriter(writer, sortTempFileNoOFRecordsInCompression);
1:     }
1: 
0:     return chunkWriter;
1:   }
1: 
1:   /**
0:    * Below method will be used to start the intermediate file merging
1:    *
0:    * @param intermediateFiles
1:    */
0:   private void startIntermediateMerging(File[] intermediateFiles) {
0:     File file = new File(this.tempFileLocation + File.separator + this.tableName + System.nanoTime()
0:         + CarbonCommonConstants.MERGERD_EXTENSION);
1: 
0:     FileMergerParameters parameters = new FileMergerParameters();
0:     parameters.setIsNoDictionaryDimensionColumn(noDictionaryDimnesionColumn);
0:     parameters.setDimColCount(dimColCount);
0:     parameters.setComplexDimColCount(complexDimColCount);
0:     parameters.setMeasureColCount(measureColCount);
0:     parameters.setIntermediateFiles(intermediateFiles);
0:     parameters.setFileReadBufferSize(fileBufferSize);
0:     parameters.setFileWriteBufferSize(fileBufferSize);
0:     parameters.setOutFile(file);
0:     parameters.setCompressionEnabled(isSortFileCompressionEnabled);
0:     parameters.setNoOfRecordsInCompression(sortTempFileNoOFRecordsInCompression);
0:     parameters.setPrefetch(prefetch);
0:     parameters.setPrefetchBufferSize(bufferSize);
0:     parameters.setAggType(aggType);
0:     parameters.setNoDictionaryCount(noDictionaryCount);
1: 
0:     IntermediateFileMerger merger = new IntermediateFileMerger(parameters);
0:     executorService.submit(merger);
1:   }
1: 
1:   /**
0:    * This method will be used to get the sort configuration
1:    *
0:    * @param instance
1:    */
0:   private void setSortConfiguration(CarbonProperties instance) {
0:     // get sort buffer size
0:     this.sortBufferSize = Integer.parseInt(instance
0:         .getProperty(CarbonCommonConstants.SORT_SIZE, CarbonCommonConstants.SORT_SIZE_DEFAULT_VAL));
0:     LOGGER.info("Sort size for table: " + this.sortBufferSize);
0:     // set number of intermedaite file to merge
0:     this.numberOfIntermediateFileToBeMerged = Integer.parseInt(instance
0:         .getProperty(CarbonCommonConstants.SORT_INTERMEDIATE_FILES_LIMIT,
0:             CarbonCommonConstants.SORT_INTERMEDIATE_FILES_LIMIT_DEFAULT_VALUE));
1: 
0:     LOGGER.info(
0:         "Number of intermediate file to be merged: " + this.numberOfIntermediateFileToBeMerged);
1: 
0:     // get file buffer size
0:     this.fileBufferSize = CarbonDataProcessorUtil
0:         .getFileBufferSize(this.numberOfIntermediateFileToBeMerged, CarbonProperties.getInstance(),
0:             CarbonCommonConstants.CONSTANT_SIZE_TEN);
1: 
0:     LOGGER.info("File Buffer Size: " + this.fileBufferSize);
1:   }
1: 
1:   /**
0:    * This will be used to get the sort temo location
1:    *
1:    */
0:   private void updateSortTempFileLocation() {
0:     String carbonDataDirectoryPath = CarbonDataProcessorUtil
0:         .getLocalDataFolderLocation(databaseName, tableName, taskNo, partitionID,
0:             segmentId, false);
0:     this.tempFileLocation =
0:         carbonDataDirectoryPath + File.separator + CarbonCommonConstants.SORT_TEMP_FILE_LOCATION;
0:     LOGGER.info("temp file location" + this.tempFileLocation);
1:   }
1: 
1:   /**
1:    * This method will be used to delete sort temp location is it is exites
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   public void deleteSortLocationIfExists() throws CarbonSortKeyAndGroupByException {
0:     CarbonDataProcessorUtil.deleteSortLocationIfExists(this.tempFileLocation);
1:   }
1: 
1:   /**
1:    * Below method will be used to start file based merge
1:    *
1:    * @throws CarbonSortKeyAndGroupByException
1:    */
1:   private void startFileBasedMerge() throws CarbonSortKeyAndGroupByException {
1:     try {
0:       executorService.shutdown();
0:       executorService.awaitTermination(2, TimeUnit.DAYS);
1:       dataSorterAndWriterExecutorService.shutdown();
1:       dataSorterAndWriterExecutorService.awaitTermination(2, TimeUnit.DAYS);
1:     } catch (InterruptedException e) {
1:       throw new CarbonSortKeyAndGroupByException("Problem while shutdown the server ", e);
1:     }
1:   }
1: 
1:   /**
1:    * Observer class for thread execution
1:    * In case of any failure we need stop all the running thread
1:    */
1:   private class ThreadStatusObserver {
1:     /**
1:      * Below method will be called if any thread fails during execution
1:      *
1:      * @param exception
1:      * @throws CarbonSortKeyAndGroupByException
1:      */
1:     public void notifyFailed(Throwable exception) throws CarbonSortKeyAndGroupByException {
0:       dataSorterAndWriterExecutorService.shutdownNow();
0:       executorService.shutdownNow();
0:       observer.setFailed(true);
1:       LOGGER.error(exception);
1:       throw new CarbonSortKeyAndGroupByException(exception);
1:     }
1:   }
1: 
1:   /**
1:    * This class is responsible for sorting and writing the object
1:    * array which holds the records equal to given array size
1:    */
0:   private class DataSorterAndWriter implements Callable<Void> {
1:     private Object[][] recordHolderArray;
1: 
1:     public DataSorterAndWriter(Object[][] recordHolderArray) {
1:       this.recordHolderArray = recordHolderArray;
1:     }
1: 
0:     @Override public Void call() throws Exception {
1:       try {
1:         long startTime = System.currentTimeMillis();
0:         if (noDictionaryCount > 0) {
0:           Arrays.sort(recordHolderArray,
0:               new RowComparator(noDictionaryDimnesionColumn, noDictionaryCount));
0:         } else {
0:           Arrays.sort(recordHolderArray, new RowComparatorForNormalDims(dimColCount));
1:         }
0:         // create a new file every time
1:         File sortTempFile = new File(
0:             tempFileLocation + File.separator + tableName + System.nanoTime()
0:                 + CarbonCommonConstants.SORT_TEMP_FILE_EXT);
0:         writeDataTofile(recordHolderArray, recordHolderArray.length, sortTempFile);
1:         // add sort temp filename to and arrayList. When the list size reaches 20 then
1:         // intermediate merging of sort temp files will be triggered
0:         synchronized (lockObject) {
0:           procFiles.add(sortTempFile);
1:         }
1:         LOGGER.info("Time taken to sort and write sort temp file " + sortTempFile + " is: " + (
0:             System.currentTimeMillis() - startTime));
1:       } catch (Throwable e) {
0:         threadStatusObserver.notifyFailed(e);
1:       } finally {
1:         semaphore.release();
1:       }
0:       return null;
1:     }
1:   }
1: }
1: 
author:jackylk
-------------------------------------------------------------------------------
commit:98df130
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
/////////////////////////////////////////////////////////////////////////
0:       DataType[] type = parameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:             switch (type[mesCount]) {
0:               case SHORT:
0:               case INT:
0:               case LONG:
0:                 stream.writeLong((Long) value);
0:                 break;
0:               case DOUBLE:
0:                 stream.writeDouble((Double) value);
0:                 break;
0:               case DECIMAL:
0:                 BigDecimal val = (BigDecimal) value;
0:                 byte[] bigDecimalInBytes = DataTypeUtil.bigDecimalToByte(val);
0:                 stream.writeInt(bigDecimalInBytes.length);
0:                 stream.write(bigDecimalInBytes);
0:                 break;
commit:8cca0af
/////////////////////////////////////////////////////////////////////////
0:             if (aggType[mesCount] == CarbonCommonConstants.DOUBLE_MEASURE) {
author:QiangCai
-------------------------------------------------------------------------------
commit:9f94529
/////////////////////////////////////////////////////////////////////////
1:       if (parameters.getNumberOfNoDictSortColumns() > 0) {
1:         Arrays.sort(toSort, new NewRowComparator(parameters.getNoDictionarySortColumn()));
1:         Arrays.sort(toSort, new NewRowComparatorForNormalDims(parameters.getNumberOfSortColumns()));
/////////////////////////////////////////////////////////////////////////
1:         if (parameters.getNumberOfNoDictSortColumns() > 0) {
1:               new NewRowComparator(parameters.getNoDictionarySortColumn()));
1:               new NewRowComparatorForNormalDims(parameters.getNumberOfSortColumns()));
commit:c5aba5f
/////////////////////////////////////////////////////////////////////////
1:       int sizeLeft = 0;
0:         sizeLeft = sortBufferSize - entryCount ;
/////////////////////////////////////////////////////////////////////////
1:       System.arraycopy(rowBatch, sizeLeft, recordHolderList, entryCount, size);
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
============================================================================
1:1d827c7: /*
1:1d827c7:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:1d827c7:  * contributor license agreements.  See the NOTICE file distributed with
1:1d827c7:  * this work for additional information regarding copyright ownership.
1:1d827c7:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:1d827c7:  * (the "License"); you may not use this file except in compliance with
1:1d827c7:  * the License.  You may obtain a copy of the License at
1:1d827c7:  *
1:1d827c7:  *    http://www.apache.org/licenses/LICENSE-2.0
1:1d827c7:  *
1:1d827c7:  * Unless required by applicable law or agreed to in writing, software
1:1d827c7:  * distributed under the License is distributed on an "AS IS" BASIS,
1:1d827c7:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:1d827c7:  * See the License for the specific language governing permissions and
1:1d827c7:  * limitations under the License.
1:1d827c7:  */
1:1d827c7: 
1:1d827c7: package org.apache.carbondata.sdk.file;
1:1d827c7: 
1:1d827c7: import java.io.IOException;
1:1d827c7: import java.util.Random;
1:1d827c7: import java.util.UUID;
1:1d827c7: 
1:1d827c7: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:1d827c7: import org.apache.carbondata.hadoop.api.CarbonTableOutputFormat;
1:859d71c: import org.apache.carbondata.hadoop.internal.ObjectArrayWritable;
1:1d827c7: import org.apache.carbondata.processing.loading.model.CarbonLoadModel;
1:1d827c7: 
1:1d827c7: import org.apache.hadoop.conf.Configuration;
1:1d827c7: import org.apache.hadoop.io.NullWritable;
1:1d827c7: import org.apache.hadoop.mapreduce.JobID;
1:1d827c7: import org.apache.hadoop.mapreduce.RecordWriter;
1:1d827c7: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1:1d827c7: import org.apache.hadoop.mapreduce.TaskAttemptID;
1:1d827c7: import org.apache.hadoop.mapreduce.TaskID;
1:1d827c7: import org.apache.hadoop.mapreduce.TaskType;
1:1d827c7: import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl;
1:1d827c7: 
1:1d827c7: /**
1:1d827c7:  * Implementation to write rows in CSV format to carbondata file.
1:1d827c7:  */
1:e72bfd1: @InterfaceAudience.Internal
1:1d827c7: class CSVCarbonWriter extends CarbonWriter {
1:1d827c7: 
1:859d71c:   private RecordWriter<NullWritable, ObjectArrayWritable> recordWriter;
1:1d827c7:   private TaskAttemptContext context;
1:859d71c:   private ObjectArrayWritable writable;
1:1d827c7: 
1:8f1a029:   CSVCarbonWriter(CarbonLoadModel loadModel, Configuration hadoopConf) throws IOException {
1:1d827c7:     CarbonTableOutputFormat.setLoadModel(hadoopConf, loadModel);
1:1d827c7:     CarbonTableOutputFormat format = new CarbonTableOutputFormat();
1:1d827c7:     JobID jobId = new JobID(UUID.randomUUID().toString(), 0);
1:1d827c7:     Random random = new Random();
1:1d827c7:     TaskID task = new TaskID(jobId, TaskType.MAP, random.nextInt());
1:1d827c7:     TaskAttemptID attemptID = new TaskAttemptID(task, random.nextInt());
1:1d827c7:     TaskAttemptContextImpl context = new TaskAttemptContextImpl(hadoopConf, attemptID);
1:1d827c7:     this.recordWriter = format.getRecordWriter(context);
1:1d827c7:     this.context = context;
1:859d71c:     this.writable = new ObjectArrayWritable();
1:1d827c7:   }
1:1d827c7: 
1:1d827c7:   /**
1:1d827c7:    * Write single row data, input row is of type String[]
1:1d827c7:    */
1:1d827c7:   @Override
1:1d827c7:   public void write(Object object) throws IOException {
1:1d827c7:     try {
1:3ea2a1d:       writable.set((String[]) object);
1:1d827c7:       recordWriter.write(NullWritable.get(), writable);
1:3ea2a1d:     } catch (Exception e) {
1:1d827c7:       throw new IOException(e);
1:1d827c7:     }
1:1d827c7:   }
1:1d827c7: 
1:1d827c7:   /**
1:1d827c7:    * Flush and close the writer
1:1d827c7:    */
1:1d827c7:   @Override
1:1d827c7:   public void close() throws IOException {
1:1d827c7:     try {
1:1d827c7:       recordWriter.close(context);
2:1d827c7:     } catch (InterruptedException e) {
1:1d827c7:       throw new IOException(e);
1:1d827c7:     }
1:1d827c7:   }
1:1d827c7: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1:   CSVCarbonWriter(CarbonLoadModel loadModel, Configuration hadoopConf) throws IOException {
author:manishgupta88
-------------------------------------------------------------------------------
commit:fe436c3
/////////////////////////////////////////////////////////////////////////
author:BJangir
-------------------------------------------------------------------------------
commit:3ea2a1d
/////////////////////////////////////////////////////////////////////////
1:       writable.set((String[]) object);
1:     } catch (Exception e) {
0:       close();
author:xuchuanyin
-------------------------------------------------------------------------------
commit:859d71c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.hadoop.internal.ObjectArrayWritable;
/////////////////////////////////////////////////////////////////////////
1:   private RecordWriter<NullWritable, ObjectArrayWritable> recordWriter;
1:   private ObjectArrayWritable writable;
/////////////////////////////////////////////////////////////////////////
1:     this.writable = new ObjectArrayWritable();
author:Jacky Li
-------------------------------------------------------------------------------
commit:e72bfd1
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: @InterfaceAudience.Internal
commit:1d827c7
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.sdk.file;
1: 
1: import java.io.IOException;
1: import java.util.Random;
1: import java.util.UUID;
1: 
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
0: import org.apache.carbondata.common.annotations.InterfaceStability;
1: import org.apache.carbondata.hadoop.api.CarbonTableOutputFormat;
0: import org.apache.carbondata.processing.loading.csvinput.StringArrayWritable;
1: import org.apache.carbondata.processing.loading.model.CarbonLoadModel;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.io.NullWritable;
1: import org.apache.hadoop.mapreduce.JobID;
1: import org.apache.hadoop.mapreduce.RecordWriter;
1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1: import org.apache.hadoop.mapreduce.TaskAttemptID;
1: import org.apache.hadoop.mapreduce.TaskID;
1: import org.apache.hadoop.mapreduce.TaskType;
1: import org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl;
1: 
1: /**
1:  * Implementation to write rows in CSV format to carbondata file.
1:  */
0: @InterfaceAudience.Developer
0: @InterfaceStability.Unstable
1: class CSVCarbonWriter extends CarbonWriter {
1: 
0:   private RecordWriter<NullWritable, StringArrayWritable> recordWriter;
1:   private TaskAttemptContext context;
0:   private StringArrayWritable writable;
1: 
0:   CSVCarbonWriter(CarbonLoadModel loadModel) throws IOException {
0:     Configuration hadoopConf = new Configuration();
1:     CarbonTableOutputFormat.setLoadModel(hadoopConf, loadModel);
1:     CarbonTableOutputFormat format = new CarbonTableOutputFormat();
1:     JobID jobId = new JobID(UUID.randomUUID().toString(), 0);
1:     Random random = new Random();
1:     TaskID task = new TaskID(jobId, TaskType.MAP, random.nextInt());
1:     TaskAttemptID attemptID = new TaskAttemptID(task, random.nextInt());
1:     TaskAttemptContextImpl context = new TaskAttemptContextImpl(hadoopConf, attemptID);
1:     this.recordWriter = format.getRecordWriter(context);
1:     this.context = context;
0:     this.writable = new StringArrayWritable();
1:   }
1: 
1:   /**
1:    * Write single row data, input row is of type String[]
1:    */
1:   @Override
1:   public void write(Object object) throws IOException {
0:     writable.set((String[]) object);
1:     try {
1:       recordWriter.write(NullWritable.get(), writable);
1:     } catch (InterruptedException e) {
1:       throw new IOException(e);
1:     }
1:   }
1: 
1:   /**
1:    * Flush and close the writer
1:    */
1:   @Override
1:   public void close() throws IOException {
1:     try {
1:       recordWriter.close(context);
1:     } catch (InterruptedException e) {
1:       throw new IOException(e);
1:     }
1:   }
1: }
============================================================================
1:b681244: /*
1:b681244:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b681244:  * contributor license agreements.  See the NOTICE file distributed with
1:b681244:  * this work for additional information regarding copyright ownership.
1:b681244:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b681244:  * (the "License"); you may not use this file except in compliance with
1:b681244:  * the License.  You may obtain a copy of the License at
1:b681244:  *
1:b681244:  *    http://www.apache.org/licenses/LICENSE-2.0
1:b681244:  *
1:b681244:  * Unless required by applicable law or agreed to in writing, software
1:b681244:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b681244:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b681244:  * See the License for the specific language governing permissions and
1:b681244:  * limitations under the License.
1:b681244:  */
1:b681244: package org.apache.carbondata.core.indexstore.blockletindex;
1:b681244: 
1:b681244: import java.io.IOException;
1:b681244: import java.util.List;
1:b681244: 
1:0bbfa85: import org.apache.carbondata.core.constants.CarbonV3DataFormatConstants;
1:1202e20: import org.apache.carbondata.core.constants.CarbonVersionConstants;
1:d35fbaf: import org.apache.carbondata.core.datamap.dev.BlockletSerializer;
1:fc2a7eb: import org.apache.carbondata.core.datamap.dev.fgdatamap.FineGrainBlocklet;
1:b681244: import org.apache.carbondata.core.datastore.DataRefNode;
1:daa6465: import org.apache.carbondata.core.datastore.FileReader;
1:b681244: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:b681244: import org.apache.carbondata.core.datastore.chunk.impl.DimensionRawColumnChunk;
1:b681244: import org.apache.carbondata.core.datastore.chunk.impl.MeasureRawColumnChunk;
1:b681244: import org.apache.carbondata.core.datastore.chunk.reader.CarbonDataReaderFactory;
1:b681244: import org.apache.carbondata.core.datastore.chunk.reader.DimensionColumnChunkReader;
1:b681244: import org.apache.carbondata.core.datastore.chunk.reader.MeasureColumnChunkReader;
1:133b303: import org.apache.carbondata.core.indexstore.BlockletDetailInfo;
1:b681244: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1:d1d726a: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
1:4589ac5: import org.apache.carbondata.core.util.BitSetGroup;
1:b681244: 
1:b681244: /**
1:b681244:  * wrapper for blocklet data map data
1:b681244:  */
1:daa6465: public class BlockletDataRefNode implements DataRefNode {
1:b681244: 
1:b681244:   private List<TableBlockInfo> blockInfos;
1:b681244: 
1:b681244:   private int index;
1:b681244: 
1:b681244:   private int[] dimensionLens;
1:b681244: 
1:d35fbaf:   private BlockletSerializer blockletSerializer;
1:d35fbaf: 
1:daa6465:   BlockletDataRefNode(List<TableBlockInfo> blockInfos, int index, int[] dimensionLens) {
1:b681244:     this.blockInfos = blockInfos;
1:133b303:     // Update row count and page count to blocklet info
1:0bbfa85:     for (TableBlockInfo blockInfo : blockInfos) {
1:133b303:       BlockletDetailInfo detailInfo = blockInfo.getDetailInfo();
1:133b303:       detailInfo.getBlockletInfo().setNumberOfRows(detailInfo.getRowCount());
1:133b303:       detailInfo.getBlockletInfo().setNumberOfPages(detailInfo.getPagesCount());
1:0c8fa59:       detailInfo.setBlockletId(blockInfo.getDetailInfo().getBlockletId());
1:0bbfa85:       int[] pageRowCount = new int[detailInfo.getPagesCount()];
1:1202e20:       int numberOfPagesCompletelyFilled = detailInfo.getRowCount();
1:1202e20:       // no. of rows to a page is 120000 in V2 and 32000 in V3, same is handled to get the number
1:1202e20:       // of pages filled
1:8d3e8b8:       int lastPageRowCount;
1:8d3e8b8:       int fullyFilledRowsCount;
1:8d3e8b8:       if (blockInfo.getVersion() == ColumnarFormatVersion.V2
1:8d3e8b8:           || blockInfo.getVersion() == ColumnarFormatVersion.V1) {
1:1202e20:         numberOfPagesCompletelyFilled /=
1:1202e20:             CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:8d3e8b8:         lastPageRowCount = detailInfo.getRowCount()
1:8d3e8b8:             % CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:8d3e8b8:         fullyFilledRowsCount =
1:8d3e8b8:             CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:1202e20:       } else {
1:1202e20:         numberOfPagesCompletelyFilled /=
1:1202e20:             CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:8d3e8b8:         lastPageRowCount = detailInfo.getRowCount()
1:8d3e8b8:             % CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:8d3e8b8:         fullyFilledRowsCount =
1:0bbfa85:             CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:1202e20:       }
1:8d3e8b8:       for (int i = 0; i < numberOfPagesCompletelyFilled; i++) {
1:8d3e8b8:         pageRowCount[i] = fullyFilledRowsCount;
1:8d3e8b8:       }
1:0bbfa85:       if (lastPageRowCount > 0) {
1:0bbfa85:         pageRowCount[pageRowCount.length - 1] = lastPageRowCount;
1:1248bd4:       }
1:0bbfa85:       detailInfo.getBlockletInfo().setNumberOfRowsPerPage(pageRowCount);
1:0bbfa85:     }
1:b681244:     this.index = index;
1:b681244:     this.dimensionLens = dimensionLens;
1:d35fbaf:     this.blockletSerializer = new BlockletSerializer();
1:b681244:   }
1:b681244: 
1:b681244:   @Override public DataRefNode getNextDataRefNode() {
1:b681244:     if (index + 1 < blockInfos.size()) {
1:daa6465:       return new BlockletDataRefNode(blockInfos, index + 1, dimensionLens);
1:b681244:     }
1:b681244:     return null;
1:b681244:   }
1:b681244: 
1:daa6465:   @Override public int numRows() {
1:b681244:     return blockInfos.get(index).getDetailInfo().getRowCount();
1:b681244:   }
1:b681244: 
1:daa6465:   @Override public long nodeIndex() {
1:b681244:     return index;
1:b681244:   }
1:b681244: 
1:daa6465:   @Override public short blockletIndex() {
1:daa6465:     return blockInfos.get(index).getDetailInfo().getBlockletId();
1:b681244:   }
1:b681244: 
1:d35fbaf:   @Override
1:d1d726a:   public byte[][] getColumnsMaxValue() {
1:d1d726a:     BlockletIndex blockletIndex =
1:d1d726a:         blockInfos.get(index).getDetailInfo().getBlockletInfo().getBlockletIndex();
1:d1d726a:     // In case of blocklet distribution this will be null
1:d1d726a:     if (null != blockletIndex) {
1:d1d726a:       return blockletIndex.getMinMaxIndex().getMaxValues();
1:b681244:     }
1:b681244:     return null;
1:d1d726a:   }
1:b681244: 
1:b681244:   @Override
1:d1d726a:   public byte[][] getColumnsMinValue() {
1:d1d726a:     BlockletIndex blockletIndex =
1:d1d726a:         blockInfos.get(index).getDetailInfo().getBlockletInfo().getBlockletIndex();
1:d1d726a:     // In case of blocklet distribution this will be null
1:d1d726a:     if (null != blockletIndex) {
1:d1d726a:       return blockletIndex.getMinMaxIndex().getMinValues();
1:d1d726a:     }
1:b681244:     return null;
1:0bbfa85:   }
1:b681244: 
2:d1d726a:   @Override
1:daa6465:   public DimensionRawColumnChunk[] readDimensionChunks(FileReader fileReader, int[][] blockIndexes)
1:b681244:       throws IOException {
1:d509f17:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader(fileReader);
1:b681244:     return dimensionChunksReader.readRawDimensionChunks(fileReader, blockIndexes);
1:b681244:   }
1:b681244: 
1:b681244:   @Override
1:daa6465:   public DimensionRawColumnChunk readDimensionChunk(FileReader fileReader, int columnIndex)
1:b681244:       throws IOException {
1:d509f17:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader(fileReader);
1:daa6465:     return dimensionChunksReader.readRawDimensionChunk(fileReader, columnIndex);
1:b681244:   }
1:b681244: 
1:b681244:   @Override
1:daa6465:   public MeasureRawColumnChunk[] readMeasureChunks(FileReader fileReader, int[][] columnIndexRange)
1:b681244:       throws IOException {
1:d509f17:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader(fileReader);
1:1248bd4:     MeasureRawColumnChunk[] measureRawColumnChunks =
1:daa6465:         measureColumnChunkReader.readRawMeasureChunks(fileReader, columnIndexRange);
1:1248bd4:     updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunks);
1:1248bd4:     return measureRawColumnChunks;
1:b681244:   }
1:b681244: 
1:daa6465:   @Override public MeasureRawColumnChunk readMeasureChunk(FileReader fileReader, int columnIndex)
1:b681244:       throws IOException {
1:d509f17:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader(fileReader);
1:1248bd4:     MeasureRawColumnChunk measureRawColumnChunk =
1:daa6465:         measureColumnChunkReader.readRawMeasureChunk(fileReader, columnIndex);
1:1248bd4:     updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunk);
1:1248bd4:     return measureRawColumnChunk;
1:b681244:   }
1:b681244: 
1:1248bd4:   /**
1:1248bd4:    * This method is written specifically for old store wherein the measure min and max values
1:1248bd4:    * are written opposite (i.e min in place of max and amx in place of min). Due to this computing
1:1248bd4:    * f measure filter with current code is impacted. In order to sync with current min and
1:1248bd4:    * max values only in case old store and measures is reversed
1:1248bd4:    *
1:1248bd4:    * @param measureRawColumnChunk
1:1248bd4:    */
1:1248bd4:   private void updateMeasureRawColumnChunkMinMaxValues(
1:1248bd4:       MeasureRawColumnChunk measureRawColumnChunk) {
1:1248bd4:     if (blockInfos.get(index).isDataBlockFromOldStore()) {
1:1248bd4:       byte[][] maxValues = measureRawColumnChunk.getMaxValues();
1:1248bd4:       byte[][] minValues = measureRawColumnChunk.getMinValues();
1:1248bd4:       measureRawColumnChunk.setMaxValues(minValues);
1:1248bd4:       measureRawColumnChunk.setMinValues(maxValues);
1:b681244:     }
1:1248bd4:   }
1:b681244: 
1:1248bd4:   private void updateMeasureRawColumnChunkMinMaxValues(
1:1248bd4:       MeasureRawColumnChunk[] measureRawColumnChunks) {
1:1248bd4:     if (blockInfos.get(index).isDataBlockFromOldStore()) {
1:1248bd4:       for (int i = 0; i < measureRawColumnChunks.length; i++) {
1:1248bd4:         if (null != measureRawColumnChunks[i]) {
1:1248bd4:           updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunks[i]);
1:1248bd4:         }
1:1248bd4:       }
1:1248bd4:     }
1:1248bd4:   }
1:1248bd4: 
1:daa6465:   private DimensionColumnChunkReader getDimensionColumnChunkReader(FileReader fileReader) {
1:b681244:     ColumnarFormatVersion version =
1:b681244:         ColumnarFormatVersion.valueOf(blockInfos.get(index).getDetailInfo().getVersionNumber());
1:d509f17:     if (fileReader.isReadPageByPage()) {
1:d509f17:       return CarbonDataReaderFactory.getInstance().getDimensionColumnChunkReader(version,
1:d509f17:           blockInfos.get(index).getDetailInfo().getBlockletInfo(), dimensionLens,
1:d509f17:           blockInfos.get(index).getFilePath(), true);
1:d509f17:     } else {
1:d509f17:       return CarbonDataReaderFactory.getInstance().getDimensionColumnChunkReader(version,
1:d509f17:           blockInfos.get(index).getDetailInfo().getBlockletInfo(), dimensionLens,
1:d509f17:           blockInfos.get(index).getFilePath(), false);
1:d509f17:     }
1:b681244:   }
1:b681244: 
1:daa6465:   private MeasureColumnChunkReader getMeasureColumnChunkReader(FileReader fileReader) {
1:b681244:     ColumnarFormatVersion version =
1:b681244:         ColumnarFormatVersion.valueOf(blockInfos.get(index).getDetailInfo().getVersionNumber());
1:d509f17:     if (fileReader.isReadPageByPage()) {
1:d509f17:       return CarbonDataReaderFactory.getInstance().getMeasureColumnChunkReader(version,
1:910d496:           blockInfos.get(index).getDetailInfo().getBlockletInfo(),
1:d509f17:           blockInfos.get(index).getFilePath(), true);
1:d509f17:     } else {
1:d509f17:       return CarbonDataReaderFactory.getInstance().getMeasureColumnChunkReader(version,
2:d509f17:           blockInfos.get(index).getDetailInfo().getBlockletInfo(),
1:d509f17:           blockInfos.get(index).getFilePath(), false);
1:d509f17:     }
1:b681244:   }
1:b681244: 
1:b681244:   @Override
1:d35fbaf:   public int numberOfPages() {
1:b681244:     return blockInfos.get(index).getDetailInfo().getPagesCount();
1:b681244:   }
1:b681244: 
1:d35fbaf:   @Override
1:d35fbaf:   public BitSetGroup getIndexedData() {
1:d35fbaf:     String dataMapWriterPath = blockInfos.get(index).getDataMapWriterPath();
1:d35fbaf:     if (dataMapWriterPath != null) {
1:d35fbaf:       try {
1:d35fbaf:         FineGrainBlocklet blocklet = blockletSerializer.deserializeBlocklet(dataMapWriterPath);
1:d35fbaf:         return blocklet.getBitSetGroup(numberOfPages());
1:d35fbaf:       } catch (IOException e) {
1:d35fbaf:         return null;
1:d35fbaf:       }
1:d35fbaf:     } else {
1:d35fbaf:       return null;
1:d35fbaf:     }
1:d35fbaf:   }
1:d35fbaf: 
1:d35fbaf:   @Override
1:d35fbaf:   public int getPageRowCount(int pageNumber) {
1:0bbfa85:     return blockInfos.get(index).getDetailInfo().getBlockletInfo()
1:0bbfa85:         .getNumberOfRowsPerPage()[pageNumber];
1:b681244:   }
1:b681244: 
1:b681244:   public int numberOfNodes() {
1:b681244:     return blockInfos.size();
1:b681244:   }
1:1248bd4: 
1:f635106:   public List<TableBlockInfo> getBlockInfos() {
1:f635106:     return blockInfos;
1:b681244:   }
1:f635106: }
============================================================================
author:dhatchayani
-------------------------------------------------------------------------------
commit:8d3e8b8
/////////////////////////////////////////////////////////////////////////
1:       int lastPageRowCount;
1:       int fullyFilledRowsCount;
1:       if (blockInfo.getVersion() == ColumnarFormatVersion.V2
1:           || blockInfo.getVersion() == ColumnarFormatVersion.V1) {
1:         lastPageRowCount = detailInfo.getRowCount()
1:             % CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:         fullyFilledRowsCount =
1:             CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:         lastPageRowCount = detailInfo.getRowCount()
1:             % CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:         fullyFilledRowsCount =
1:       for (int i = 0; i < numberOfPagesCompletelyFilled; i++) {
1:         pageRowCount[i] = fullyFilledRowsCount;
1:       }
author:Jacky Li
-------------------------------------------------------------------------------
commit:fc2a7eb
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.dev.fgdatamap.FineGrainBlocklet;
/////////////////////////////////////////////////////////////////////////
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.FileReader;
/////////////////////////////////////////////////////////////////////////
1: public class BlockletDataRefNode implements DataRefNode {
/////////////////////////////////////////////////////////////////////////
1:   BlockletDataRefNode(List<TableBlockInfo> blockInfos, int index, int[] dimensionLens) {
/////////////////////////////////////////////////////////////////////////
1:       return new BlockletDataRefNode(blockInfos, index + 1, dimensionLens);
1:   @Override public int numRows() {
1:   @Override public long nodeIndex() {
1:   @Override public short blockletIndex() {
1:     return blockInfos.get(index).getDetailInfo().getBlockletId();
/////////////////////////////////////////////////////////////////////////
1:   public DimensionRawColumnChunk[] readDimensionChunks(FileReader fileReader, int[][] blockIndexes)
1:   public DimensionRawColumnChunk readDimensionChunk(FileReader fileReader, int columnIndex)
1:     return dimensionChunksReader.readRawDimensionChunk(fileReader, columnIndex);
1:   public MeasureRawColumnChunk[] readMeasureChunks(FileReader fileReader, int[][] columnIndexRange)
1:         measureColumnChunkReader.readRawMeasureChunks(fileReader, columnIndexRange);
1:   @Override public MeasureRawColumnChunk readMeasureChunk(FileReader fileReader, int columnIndex)
1:         measureColumnChunkReader.readRawMeasureChunk(fileReader, columnIndex);
/////////////////////////////////////////////////////////////////////////
1:   private DimensionColumnChunkReader getDimensionColumnChunkReader(FileReader fileReader) {
/////////////////////////////////////////////////////////////////////////
1:   private MeasureColumnChunkReader getMeasureColumnChunkReader(FileReader fileReader) {
/////////////////////////////////////////////////////////////////////////
author:xuchuanyin
-------------------------------------------------------------------------------
commit:4589ac5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.BitSetGroup;
commit:910d496
/////////////////////////////////////////////////////////////////////////
0:     return CarbonDataReaderFactory.getInstance().getDimensionColumnChunkReader(
0:         version,
1:         blockInfos.get(index).getDetailInfo().getBlockletInfo(),
0:         dimensionLens,
0:         blockInfos.get(index).getFilePath());
author:ravipesala
-------------------------------------------------------------------------------
commit:d35fbaf
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.dev.BlockletSerializer;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.indexstore.FineGrainBlocklet;
0: import org.apache.carbondata.core.util.BitSetGroup;
/////////////////////////////////////////////////////////////////////////
1:   private BlockletSerializer blockletSerializer;
1: 
/////////////////////////////////////////////////////////////////////////
1:     this.blockletSerializer = new BlockletSerializer();
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   public int numberOfPages() {
1:   @Override
1:   public BitSetGroup getIndexedData() {
1:     String dataMapWriterPath = blockInfos.get(index).getDataMapWriterPath();
1:     if (dataMapWriterPath != null) {
1:       try {
1:         FineGrainBlocklet blocklet = blockletSerializer.deserializeBlocklet(dataMapWriterPath);
1:         return blocklet.getBitSetGroup(numberOfPages());
1:       } catch (IOException e) {
1:         return null;
1:       }
1:     } else {
1:       return null;
1:     }
1:   }
1: 
1:   @Override
1:   public int getPageRowCount(int pageNumber) {
commit:d509f17
/////////////////////////////////////////////////////////////////////////
1:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader(fileReader);
1:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader(fileReader);
1:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader(fileReader);
1:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader(fileReader);
0:   private DimensionColumnChunkReader getDimensionColumnChunkReader(FileHolder fileReader) {
1:     if (fileReader.isReadPageByPage()) {
1:       return CarbonDataReaderFactory.getInstance().getDimensionColumnChunkReader(version,
1:           blockInfos.get(index).getDetailInfo().getBlockletInfo(), dimensionLens,
1:           blockInfos.get(index).getFilePath(), true);
1:     } else {
1:       return CarbonDataReaderFactory.getInstance().getDimensionColumnChunkReader(version,
1:           blockInfos.get(index).getDetailInfo().getBlockletInfo(), dimensionLens,
1:           blockInfos.get(index).getFilePath(), false);
1:     }
0:   private MeasureColumnChunkReader getMeasureColumnChunkReader(FileHolder fileReader) {
1:     if (fileReader.isReadPageByPage()) {
1:       return CarbonDataReaderFactory.getInstance().getMeasureColumnChunkReader(version,
1:           blockInfos.get(index).getDetailInfo().getBlockletInfo(),
1:           blockInfos.get(index).getFilePath(), true);
1:     } else {
1:       return CarbonDataReaderFactory.getInstance().getMeasureColumnChunkReader(version,
1:           blockInfos.get(index).getDetailInfo().getBlockletInfo(),
1:           blockInfos.get(index).getFilePath(), false);
1:     }
commit:b681244
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.indexstore.blockletindex;
1: 
1: import java.io.IOException;
1: import java.util.List;
1: 
0: import org.apache.carbondata.core.cache.update.BlockletLevelDeleteDeltaDataCache;
1: import org.apache.carbondata.core.datastore.DataRefNode;
0: import org.apache.carbondata.core.datastore.FileHolder;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.datastore.chunk.impl.DimensionRawColumnChunk;
1: import org.apache.carbondata.core.datastore.chunk.impl.MeasureRawColumnChunk;
1: import org.apache.carbondata.core.datastore.chunk.reader.CarbonDataReaderFactory;
1: import org.apache.carbondata.core.datastore.chunk.reader.DimensionColumnChunkReader;
1: import org.apache.carbondata.core.datastore.chunk.reader.MeasureColumnChunkReader;
1: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1: 
1: /**
1:  * wrapper for blocklet data map data
1:  */
0: public class BlockletDataRefNodeWrapper implements DataRefNode {
1: 
1:   private List<TableBlockInfo> blockInfos;
1: 
1:   private int index;
1: 
1:   private int[] dimensionLens;
1: 
0:   private BlockletLevelDeleteDeltaDataCache deleteDeltaDataCache;
1: 
0:   public BlockletDataRefNodeWrapper(List<TableBlockInfo> blockInfos, int index,
0:       int[] dimensionLens) {
1:     this.blockInfos = blockInfos;
1:     this.index = index;
1:     this.dimensionLens = dimensionLens;
1:   }
1: 
1:   @Override public DataRefNode getNextDataRefNode() {
1:     if (index + 1 < blockInfos.size()) {
0:       new BlockletDataRefNodeWrapper(blockInfos, index + 1, dimensionLens);
1:     }
1:     return null;
1:   }
1: 
0:   @Override public int nodeSize() {
1:     return blockInfos.get(index).getDetailInfo().getRowCount();
1:   }
1: 
0:   @Override public long nodeNumber() {
1:     return index;
1:   }
1: 
0:   @Override public byte[][] getColumnsMaxValue() {
1:     return null;
1:   }
1: 
0:   @Override public byte[][] getColumnsMinValue() {
1:     return null;
1:   }
1: 
1:   @Override
0:   public DimensionRawColumnChunk[] getDimensionChunks(FileHolder fileReader, int[][] blockIndexes)
1:       throws IOException {
0:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader();
1:     return dimensionChunksReader.readRawDimensionChunks(fileReader, blockIndexes);
1:   }
1: 
1:   @Override
0:   public DimensionRawColumnChunk getDimensionChunk(FileHolder fileReader, int blockIndexes)
1:       throws IOException {
0:     DimensionColumnChunkReader dimensionChunksReader = getDimensionColumnChunkReader();
0:     return dimensionChunksReader.readRawDimensionChunk(fileReader, blockIndexes);
1:   }
1: 
1:   @Override
0:   public MeasureRawColumnChunk[] getMeasureChunks(FileHolder fileReader, int[][] blockIndexes)
1:       throws IOException {
0:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader();
0:     return measureColumnChunkReader.readRawMeasureChunks(fileReader, blockIndexes);
1:   }
1: 
0:   @Override public MeasureRawColumnChunk getMeasureChunk(FileHolder fileReader, int blockIndex)
1:       throws IOException {
0:     MeasureColumnChunkReader measureColumnChunkReader = getMeasureColumnChunkReader();
0:     return measureColumnChunkReader.readRawMeasureChunk(fileReader, blockIndex);
1:   }
1: 
0:   private DimensionColumnChunkReader getDimensionColumnChunkReader() throws IOException {
1:     ColumnarFormatVersion version =
1:         ColumnarFormatVersion.valueOf(blockInfos.get(index).getDetailInfo().getVersionNumber());
0:     DimensionColumnChunkReader dimensionColumnChunkReader = CarbonDataReaderFactory.getInstance()
0:         .getDimensionColumnChunkReader(version,
0:             blockInfos.get(index).getDetailInfo().getBlockletInfo(), dimensionLens,
0:             blockInfos.get(index).getFilePath());
0:     return dimensionColumnChunkReader;
1:   }
1: 
0:   private MeasureColumnChunkReader getMeasureColumnChunkReader() throws IOException {
1:     ColumnarFormatVersion version =
1:         ColumnarFormatVersion.valueOf(blockInfos.get(index).getDetailInfo().getVersionNumber());
0:     return CarbonDataReaderFactory.getInstance().getMeasureColumnChunkReader(version,
0:         blockInfos.get(index).getDetailInfo().getBlockletInfo(),
0:         blockInfos.get(index).getFilePath());
1:   }
1: 
1:   @Override
0:   public void setDeleteDeltaDataCache(BlockletLevelDeleteDeltaDataCache deleteDeltaDataCache) {
0:     this.deleteDeltaDataCache = deleteDeltaDataCache;
1:   }
1: 
0:   @Override public BlockletLevelDeleteDeltaDataCache getDeleteDeltaDataCache() {
0:     return deleteDeltaDataCache;
1:   }
1: 
0:   @Override public int numberOfPages() {
1:     return blockInfos.get(index).getDetailInfo().getPagesCount();
1:   }
1: 
1:   public int numberOfNodes() {
1:     return blockInfos.size();
1:   }
1: }
author:akashrn5
-------------------------------------------------------------------------------
commit:1202e20
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.constants.CarbonVersionConstants;
/////////////////////////////////////////////////////////////////////////
1:       int numberOfPagesCompletelyFilled = detailInfo.getRowCount();
1:       // no. of rows to a page is 120000 in V2 and 32000 in V3, same is handled to get the number
1:       // of pages filled
0:       if (blockInfo.getVersion() == ColumnarFormatVersion.V2) {
1:         numberOfPagesCompletelyFilled /=
1:             CarbonVersionConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT_V2;
1:       } else {
1:         numberOfPagesCompletelyFilled /=
1:             CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:       }
author:manishgupta88
-------------------------------------------------------------------------------
commit:1248bd4
/////////////////////////////////////////////////////////////////////////
1:     MeasureRawColumnChunk[] measureRawColumnChunks =
0:         measureColumnChunkReader.readRawMeasureChunks(fileReader, blockIndexes);
1:     updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunks);
1:     return measureRawColumnChunks;
1:     MeasureRawColumnChunk measureRawColumnChunk =
0:         measureColumnChunkReader.readRawMeasureChunk(fileReader, blockIndex);
1:     updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunk);
1:     return measureRawColumnChunk;
1:   }
1: 
1:   /**
1:    * This method is written specifically for old store wherein the measure min and max values
1:    * are written opposite (i.e min in place of max and amx in place of min). Due to this computing
1:    * f measure filter with current code is impacted. In order to sync with current min and
1:    * max values only in case old store and measures is reversed
1:    *
1:    * @param measureRawColumnChunk
1:    */
1:   private void updateMeasureRawColumnChunkMinMaxValues(
1:       MeasureRawColumnChunk measureRawColumnChunk) {
1:     if (blockInfos.get(index).isDataBlockFromOldStore()) {
1:       byte[][] maxValues = measureRawColumnChunk.getMaxValues();
1:       byte[][] minValues = measureRawColumnChunk.getMinValues();
1:       measureRawColumnChunk.setMaxValues(minValues);
1:       measureRawColumnChunk.setMinValues(maxValues);
1:     }
1:   }
1: 
1:   private void updateMeasureRawColumnChunkMinMaxValues(
1:       MeasureRawColumnChunk[] measureRawColumnChunks) {
1:     if (blockInfos.get(index).isDataBlockFromOldStore()) {
1:       for (int i = 0; i < measureRawColumnChunks.length; i++) {
1:         if (null != measureRawColumnChunks[i]) {
1:           updateMeasureRawColumnChunkMinMaxValues(measureRawColumnChunks[i]);
1:         }
1:       }
1:     }
commit:d1d726a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   public byte[][] getColumnsMaxValue() {
1:     BlockletIndex blockletIndex =
1:         blockInfos.get(index).getDetailInfo().getBlockletInfo().getBlockletIndex();
1:     // In case of blocklet distribution this will be null
1:     if (null != blockletIndex) {
1:       return blockletIndex.getMinMaxIndex().getMaxValues();
1:     }
1:   @Override
1:   public byte[][] getColumnsMinValue() {
1:     BlockletIndex blockletIndex =
1:         blockInfos.get(index).getDetailInfo().getBlockletInfo().getBlockletIndex();
1:     // In case of blocklet distribution this will be null
1:     if (null != blockletIndex) {
1:       return blockletIndex.getMinMaxIndex().getMinValues();
1:     }
commit:f635106
/////////////////////////////////////////////////////////////////////////
0: 
1:   public List<TableBlockInfo> getBlockInfos() {
1:     return blockInfos;
1:   }
commit:0bbfa85
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.constants.CarbonV3DataFormatConstants;
/////////////////////////////////////////////////////////////////////////
1:     for (TableBlockInfo blockInfo : blockInfos) {
1:       int[] pageRowCount = new int[detailInfo.getPagesCount()];
0:       int numberOfPagesCompletelyFilled = detailInfo.getRowCount()
0:           / CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
0:       int lastPageRowCount = detailInfo.getRowCount()
0:           % CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
0:       for (int i = 0; i < numberOfPagesCompletelyFilled; i++) {
0:         pageRowCount[i] =
1:             CarbonV3DataFormatConstants.NUMBER_OF_ROWS_PER_BLOCKLET_COLUMN_PAGE_DEFAULT;
1:       }
1:       if (lastPageRowCount > 0) {
1:         pageRowCount[pageRowCount.length - 1] = lastPageRowCount;
1:       }
1:       detailInfo.getBlockletInfo().setNumberOfRowsPerPage(pageRowCount);
/////////////////////////////////////////////////////////////////////////
0:   @Override public int getPageRowCount(int pageNumber) {
1:     return blockInfos.get(index).getDetailInfo().getBlockletInfo()
1:         .getNumberOfRowsPerPage()[pageNumber];
0:   }
0: 
author:anubhav100
-------------------------------------------------------------------------------
commit:0c8fa59
/////////////////////////////////////////////////////////////////////////
1:       detailInfo.setBlockletId(blockInfo.getDetailInfo().getBlockletId());
/////////////////////////////////////////////////////////////////////////
0:   @Override public String blockletId() {
0:     return blockInfos.get(index).getDetailInfo().getBlockletId().toString();
0:   }
0: 
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:133b303
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.indexstore.BlockletDetailInfo;
/////////////////////////////////////////////////////////////////////////
1:     // Update row count and page count to blocklet info
0:     for (TableBlockInfo blockInfo: blockInfos) {
1:       BlockletDetailInfo detailInfo = blockInfo.getDetailInfo();
1:       detailInfo.getBlockletInfo().setNumberOfRows(detailInfo.getRowCount());
1:       detailInfo.getBlockletInfo().setNumberOfPages(detailInfo.getPagesCount());
0:     }
author:sraghunandan
-------------------------------------------------------------------------------
commit:500654e
/////////////////////////////////////////////////////////////////////////
0:       return new BlockletDataRefNodeWrapper(blockInfos, index + 1, dimensionLens);
============================================================================
3:eac0369: /*
1:9008ade: 
1:345de35:    Derby - Class org.apache.derby.impl.store.raw.data.RAFContainer
1:bb8f25a: 
1:270a34d:    Licensed to the Apache Software Foundation (ASF) under one or more
1:270a34d:    contributor license agreements.  See the NOTICE file distributed with
1:270a34d:    this work for additional information regarding copyright ownership.
1:270a34d:    The ASF licenses this file to you under the Apache License, Version 2.0
1:270a34d:    (the "License"); you may not use this file except in compliance with
1:270a34d:    the License.  You may obtain a copy of the License at
1:345de35: 
1:345de35:       http://www.apache.org/licenses/LICENSE-2.0
1:345de35: 
1:345de35:    Unless required by applicable law or agreed to in writing, software
1:345de35:    distributed under the License is distributed on an "AS IS" BASIS,
1:345de35:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:345de35:    See the License for the specific language governing permissions and
1:345de35:    limitations under the License.
1:345de35: 
12:eac0369:  */
1:345de35: 
1:eac0369: package org.apache.derby.impl.store.raw.data;
71:eac0369: 
1:eac0369: import org.apache.derby.iapi.reference.SQLState;
1:eac0369: 
1:7e51e9d: import org.apache.derby.shared.common.sanity.SanityManager;
1:eac0369: import org.apache.derby.iapi.services.io.FormatIdUtil;
1:eac0369: 
1:bb8f25a: import org.apache.derby.iapi.util.InterruptStatus;
1:bb8f25a: import org.apache.derby.iapi.util.InterruptDetectedException;
1:bb8f25a: 
1:eac0369: import org.apache.derby.iapi.error.StandardException;
1:eac0369: 
1:eac0369: import org.apache.derby.iapi.store.raw.ContainerHandle;
1:eac0369: import org.apache.derby.iapi.store.raw.ContainerKey;
1:eac0369: import org.apache.derby.iapi.store.raw.log.LogInstant;
1:eac0369: 
1:eac0369: import org.apache.derby.io.StorageFile;
1:eac0369: import org.apache.derby.io.StorageRandomAccessFile;
1:25f99f5: import org.apache.derby.iapi.services.io.FileUtil;
1:eac0369: 
1:eac0369: import java.io.IOException;
1:25f99f5: import java.io.File;
1:3c7c740: import java.io.FileNotFoundException;
1:25f99f5: import java.io.RandomAccessFile;
1:eac0369: import java.security.AccessController;
1:6d4d95d: import java.security.PrivilegedAction;
1:eac0369: import java.security.PrivilegedExceptionAction;
1:eac0369: import java.security.PrivilegedActionException;
1:eac0369: 
1:bf643fd: /**
1:eac0369: 	RAFContainer (short for RandomAccessFileContainer) is a concrete subclass of FileContainer
1:eac0369: 	for FileContainers which are implemented on java.io.RandomAccessFile.
1:bb8f25a: */
1:bb8f25a: 
1:7e7a589: class RAFContainer extends FileContainer implements PrivilegedExceptionAction<Object>
1:25f99f5: {
1:eac0369: 
1:eac0369: 	/*
1:eac0369: 	 * Immutable fields
1:eac0369: 	 */
1:eac0369: 	protected StorageRandomAccessFile fileData;
1:eac0369: 
1:eac0369: 	/* 
1:eac0369: 	** Mutable fields, only valid when the identity is valid.
1:eac0369: 	*/
1:eac0369: 	protected boolean			needsSync;
1:eac0369: 
1:eac0369:     /* privileged actions */
1:eac0369:     private int actionCode;
1:eac0369:     private static final int GET_FILE_NAME_ACTION = 1;
1:eac0369:     private static final int CREATE_CONTAINER_ACTION = 2;
1:eac0369:     private static final int REMOVE_FILE_ACTION = 3;
1:eac0369:     private static final int OPEN_CONTAINER_ACTION = 4;
1:eac0369:     private static final int STUBBIFY_ACTION = 5;
1:e910eee:     private static final int GET_RANDOM_ACCESS_FILE_ACTION = 7;
1:08b4ed5:     private static final int REOPEN_CONTAINER_ACTION = 8;
1:eac0369:     private ContainerKey actionIdentity;
1:eac0369:     private boolean actionStub;
1:eac0369:     private boolean actionErrorOK;
1:eac0369:     private boolean actionTryAlternatePath;
1:eac0369:     private StorageFile actionFile;
1:eac0369:     private LogInstant actionInstant;
1:25f99f5: 
1:25f99f5: 	private boolean inBackup = false;
1:25f99f5: 	private boolean inRemove = false;
1:26c2de4:         private String fileName;
1:a2f90d4: 
1:a2f90d4: 
1:eac0369: 	/*
1:eac0369: 	 * Constructors
1:a2f90d4: 	 */
1:a2f90d4: 
1:7a92d1f: 	RAFContainer(BaseDataFileFactory factory) {
1:eac0369: 		super(factory);
1:25f99f5: 	}
1:bf643fd: 
1:eac0369: 	/*
1:eac0369: 	** Methods overriding super-class
1:25f99f5: 	*/
1:a2f90d4: 
1:eac0369: 	synchronized public boolean isDirty() {
1:eac0369: 		return super.isDirty() || needsSync;
1:25f99f5: 	}
1:25f99f5: 
1:eac0369: 	/*
1:eac0369: 	** Container creation, opening, and closing
1:eac0369: 	*/
1:25f99f5: 
1:6d4d95d: 	/**
1:eac0369: 		Remove the container
1:25f99f5: 
1:94f158a: 		@exception StandardException Standard Derby error policy
1:eac0369: 	*/
1:eac0369: 	protected void removeContainer(LogInstant instant, boolean leaveStub)
1:25f99f5: 		 throws StandardException
1:25f99f5: 	{
1:25f99f5: 
1:4f7eee8: 		try {
1:25f99f5: 			synchronized(this)
1:25f99f5: 			{
1:25f99f5: 				inRemove = true;
1:25f99f5: 				// wait until the thread that is doing the backup stops 
1:25f99f5: 				// before proceeding with the remove.
1:25f99f5: 				while(inBackup)
1:25f99f5: 				{
1:25f99f5: 					try	{
1:25f99f5: 						wait();
1:a2f90d4: 					}
1:25f99f5: 					catch (InterruptedException ie)
1:25f99f5: 					{
1:bb8f25a:                         InterruptStatus.setInterrupted();
1:a2f90d4: 					}	
1:a2f90d4: 				}
1:a2f90d4: 			}
1:a2f90d4: 
1:eac0369: 		// discard all of my pages in the cache
1:eac0369: 		pageCache.discard(identity);
1:eac0369: 		stubbify(instant);
1:25f99f5: 		}finally
1:25f99f5: 		{	
1:25f99f5: 			synchronized(this) {
1:25f99f5: 				inRemove = false;
1:25f99f5: 				notifyAll();
1:25f99f5: 			}
1:25f99f5: 		}
1:25f99f5: 
1:eac0369: 		// RESOLVE: leaveStub false
1:25f99f5: 	}
1:25f99f5: 
1:55a6cdc: 	void closeContainer() {
1:25f99f5: 
1:eac0369: 		if (fileData != null) {
1:a2f90d4: 			try {
1:eac0369: 				fileData.close();
1:25f99f5: 			} catch (IOException ioe) {
1:25f99f5: 			} finally {
1:25f99f5: 
1:eac0369: 				fileData = null;
1:25f99f5: 			}
1:25f99f5: 		}
1:25f99f5: 	}
1:25f99f5: 
1:25f99f5: 
1:eac0369: 	/*
1:eac0369: 	** Methods used solely by StoredPage
1:25f99f5: 	*/
1:25f99f5: 
1:1318511: 	/**
1:eac0369: 		Read a page into the supplied array.
1:01a4f9b: 
1:eac0369: 		<BR> MT - thread safe
1:eac0369: 		@exception IOException exception reading page
1:94f158a: 		@exception StandardException Standard Derby error policy
1:eac0369: 	*/
1:eac0369: 	protected void readPage(long pageNumber, byte[] pageData)
1:eac0369: 		 throws IOException, StandardException
1:25f99f5: 	{
1:bf643fd: 		if (SanityManager.DEBUG) {
1:eac0369: 			SanityManager.ASSERT(!getCommittedDropState());
1:a2f90d4: 		}
1:ae71c74: 
2:eac0369: 		long pageOffset = pageNumber * pageSize;
1:ae71c74: 
1:f0cd4bf: 		synchronized (this) {
1:25f99f5: 
1:f0cd4bf: 			fileData.seek(pageOffset);
1:f0cd4bf: 
1:f0cd4bf: 			fileData.readFully(pageData, 0, pageSize);
1:a2f90d4: 		}
1:25f99f5: 
1:eac0369: 		if (dataFactory.databaseEncrypted() &&
1:eac0369: 			pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1:25f99f5: 		{
1:eac0369: 			decryptPage(pageData, pageSize);
1:25f99f5: 		}
1:25f99f5: 	}
1:25f99f5: 
1:bf643fd: 	/**
1:eac0369: 		Write a page from the supplied array.
1:25f99f5: 
1:eac0369: 		<BR> MT - thread safe
1:eac0369: 
1:94f158a: 		@exception StandardException Standard Derby error policy
1:eac0369: 		@exception IOException IO error accessing page
1:eac0369: 	*/
1:eac0369: 	protected void writePage(long pageNumber, byte[] pageData, boolean syncPage)
1:eac0369: 		 throws IOException, StandardException
1:25f99f5: 	{
1:eac0369: 		synchronized(this)
1:25f99f5: 		{
1:eac0369: 
1:25f99f5: 			if (getCommittedDropState())
1:0a625f3:             {
1:0a625f3:                 // committed and dropped, do nothing.
1:0a625f3:                 // This file container may only be a stub
1:25f99f5: 
1:0a625f3: 				return;
1:0a625f3:             }
1:0a625f3: 
1:0a625f3:             ///////////////////////////////////////////////////
1:0a625f3:             //
1:0a625f3:             // RESOLVE: right now, no logical -> physical mapping.
1:0a625f3:             // We can calculate the offset.  In the future, we may need to
1:0a625f3:             // look at the allocation page or the in memory translation table
1:0a625f3:             // to figure out where the page should go
1:0a625f3:             //
1:0a625f3:             /////////////////////////////////////////////////
1:25f99f5: 
1:25f99f5: 			long pageOffset = pageNumber * pageSize;
1:eac0369: 
1:0a625f3:             byte [] encryptionBuf = null; 
1:0a625f3:             if (dataFactory.databaseEncrypted() 
1:0a625f3:                 && pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1:0a625f3:             {
1:0a625f3:                 // We cannot encrypt the page in place because pageData is
1:0a625f3:                 // still being accessed as clear text.  The encryption
1:0a625f3:                 // buffer is shared by all who access this container and can
1:0a625f3:                 // only be used within the synchronized block.
1:0a625f3: 
1:0a625f3:                 encryptionBuf = getEncryptionBuffer();
1:0a625f3:             }
1:0a625f3: 
1:0a625f3:             byte[] dataToWrite = 
1:0a625f3:                 updatePageArray(pageNumber, pageData, encryptionBuf, false);
1:0a625f3: 
1:25f99f5: 			try
1:3c7c740: 			{
1:a2f90d4: 				fileData.seek(pageOffset);
1:eac0369: 
1:bf643fd: 				/**
1:eac0369: 					On EPOC (www.symbian.com) a seek beyond the end of
1:eac0369: 					a file just moves the file pointer to the end of the file.
1:eac0369: 
1:eac0369: 				*/
1:eac0369: 				if (fileData.getFilePointer() != pageOffset)
1:eac0369: 					padFile(fileData, pageOffset);
1:bf643fd: 
3:eac0369: 				dataFactory.writeInProgress();
1:bb8f25a: 				try
1:25f99f5: 				{
1:eac0369: 					fileData.write(dataToWrite, 0, pageSize);
1:bf643fd: 				}
1:25f99f5: 				finally
1:25f99f5: 				{
2:eac0369: 					dataFactory.writeFinished();
1:25f99f5: 				}
1:25f99f5: 			}
1:eac0369: 			catch (IOException ioe)
1:25f99f5: 			{
1:eac0369: 				// On some platforms, if we seek beyond the end of file, or try
1:eac0369: 				// to write beyond the end of file (not appending to it, but
1:eac0369: 				// skipping some bytes), it will give IOException.
1:eac0369: 				// Try writing zeros from the current end of file to pageOffset
1:eac0369: 				// and see if we can then do the seek/write.  The difference
1:eac0369: 				// between pageOffset and current end of file is almost always
1:eac0369: 				// going to be the multiple of pageSize
1:bf643fd: 
1:eac0369: 				if (!padFile(fileData, pageOffset))
1:eac0369: 					throw ioe;	// not writing beyond EOF, rethrow exception
1:eac0369: 
1:eac0369: 				if (SanityManager.DEBUG)
1:0a625f3:                 {
1:0a625f3: 					SanityManager.ASSERT(
1:0a625f3:                         fileData.length() >= pageOffset,
1:0a625f3:                         "failed to blank filled missing pages");
1:0a625f3:                 }
1:0a625f3: 
1:25f99f5: 				fileData.seek(pageOffset);
1:eac0369: 				dataFactory.writeInProgress();
5:eac0369: 				try
1:25f99f5: 				{
1:0a625f3: 					fileData.write(dataToWrite, 0, pageSize);
1:25f99f5: 				}
4:eac0369: 				finally
1:bd018fd: 				{
1:eac0369: 					dataFactory.writeFinished();
1:25f99f5: 				}
1:25f99f5: 			}
1:eac0369: 
1:eac0369: 			if (syncPage)
1:bb8f25a: 			{
1:eac0369: 				dataFactory.writeInProgress();
1:eac0369: 				try
33:eac0369: 				{
1:3108420:                     if (!dataFactory.dataNotSyncedAtAllocation)
1:a552fe6:                         fileData.sync();
1:25f99f5: 				}
1:eac0369: 				finally
1:eac0369: 				{
1:eac0369: 					dataFactory.writeFinished();
1:25f99f5: 				}
1:25f99f5: 			}
4:eac0369: 			else
1:eac0369:             {
1:eac0369: 				needsSync = true;
1:d203eea:             }
1:01a4f9b: 		}
1:eac0369: 
1:bb8f25a: 	}
1:eac0369: 
1:25f99f5:     /**
1:d203eea:      * Updates the page array with container header if the page is a first
1:d203eea:      * allocation page and encrypts the page data if the database is encrypted.
1:bf643fd:      *
1:bf643fd:      * @param pageNumber the page number of the page
1:bf643fd:      * @param pageData  byte array that has the actual page data.
1:d203eea:      * @param encryptionBuf buffer that is used to store encrypted version of
1:d203eea:      *      the page, or {@code null} if encryption is to be skipped
1:d203eea:      * @param encryptWithNewEngine whether to use the new encryption engine for
1:d203eea:      *      encryption (only considered if {@code encryptionBuf != null})
1:bf643fd:      * @return byte array of the the page data as it should be on the disk.
1:bf643fd:      */
1:55a6cdc:     protected byte[] updatePageArray(long pageNumber, 
1:bf643fd:                                    byte[] pageData, 
1:ae71c74:                                    byte[] encryptionBuf, 
1:ae71c74:                                    boolean encryptWithNewEngine) 
1:bf643fd:         throws StandardException, IOException
1:bf643fd:     {
1:bf643fd:         if (pageNumber == FIRST_ALLOC_PAGE_NUMBER)
1:bf643fd:         {
1:bf643fd:             // write header into the alloc page array regardless of dirty
1:bf643fd:             // bit because the alloc page have zero'ed out the borrowed
1:bf643fd:             // space
1:30c9f82:             writeHeader(getIdentity(), pageData);
1:bf643fd: 
1:0a625f3:             if (SanityManager.DEBUG) 
1:0a625f3:             {
1:bf643fd:                 if (FormatIdUtil.readFormatIdInteger(pageData) != AllocPage.FORMAT_NUMBER)
1:bf643fd:                     SanityManager.THROWASSERT(
1:bf643fd:                             "expect " +
1:bf643fd:                             AllocPage.FORMAT_NUMBER +
1:bf643fd:                             "got " +
1:bf643fd:                             FormatIdUtil.readFormatIdInteger(pageData));
1:bf643fd:             }
1:bf643fd: 
1:bf643fd:             return pageData;
1:bf643fd: 
1:0a625f3:         } 
1:0a625f3:         else 
1:0a625f3:         {
1:d203eea:             if (encryptionBuf != null &&
1:d203eea:                     (dataFactory.databaseEncrypted() || encryptWithNewEngine))
1:bf643fd:             {
1:ae71c74:                 return encryptPage(pageData, 
1:ae71c74:                                    pageSize, 
1:ae71c74:                                    encryptionBuf, 
1:ae71c74:                                    encryptWithNewEngine);
1:0a625f3:             } 
1:0a625f3:             else
1:0a625f3:             {
1:bf643fd:                 return pageData;
1:0a625f3:             }
1:bf643fd:         }
1:bf643fd:     }
1:bf643fd: 
1:bf643fd: 
1:a2f90d4: 	/**
1:eac0369: 		Pad the file upto the passed in page offset.
1:eac0369: 		Returns true if the file needed padding.
1:bf643fd: 	*/
1:ae71c74: 
1:eac0369: 	private boolean padFile(StorageRandomAccessFile file, long pageOffset)
1:eac0369: 		throws IOException, StandardException {
1:ae71c74: 
1:eac0369: 		long currentEOF = file.length();
1:eac0369: 		if (currentEOF >= pageOffset)
1:eac0369: 			return false;
1:ae71c74: 
1:eac0369: 		// all objects in java are by definition initialized
1:eac0369: 		byte zero[] = new byte[pageSize];
1:eac0369: 
1:eac0369: 		file.seek(currentEOF);
1:eac0369: 
1:eac0369: 		while(currentEOF < pageOffset)
1:bf643fd: 		{
1:eac0369: 			dataFactory.writeInProgress();
1:eac0369: 			try
1:ae71c74: 			{
1:eac0369: 				long len = pageOffset - currentEOF;
1:eac0369: 				if (len > pageSize)
1:eac0369: 					len = pageSize;
1:eac0369: 
1:eac0369: 				file.write(zero, 0, (int) len);
1:a2f90d4: 			}
1:eac0369: 			finally
1:ae71c74: 			{
1:eac0369: 				dataFactory.writeFinished();
1:a2f90d4: 			}
1:eac0369: 			currentEOF += pageSize;
1:a2f90d4: 		}
1:eac0369: 
1:eac0369: 		return true;
1:a2f90d4: 	}
1:bd018fd: 
1:f57b07d:     /**
1:f57b07d:      * Clean the container.
1:f57b07d:      * <p>
1:f57b07d:      * Write out the container header and sync all dirty pages of this
1:f57b07d:      * container to disk before returning.
1:f57b07d:      * <p>
1:f57b07d:      * checkpoint calls this interface through callbacks by telling
1:f57b07d:      * the cache manager to clean all containers in the open container
1:f57b07d:      * cache.  This sync of the file happens as part of writing and then
1:f57b07d:      * syncing the container header in writeRAFHeader().
1:f57b07d:      * <p>
1:f57b07d:      *
1:d59cfb4:      * @param forRemove Is clean called because container is being removed?
1:f57b07d:      *
1:f57b07d: 	 * @exception  StandardException  Standard exception policy.
1:f57b07d:      **/
1:eac0369: 	public void clean(boolean forRemove) throws StandardException
1:eac0369: 	{
1:eac0369: 		boolean waited = false;
1:eac0369: 
1:bb8f25a:         // If interrupt recovery is in progress (NIO), we must expect to
1:bb8f25a:         // release our monitor on "this" and to retry writeRAFHeader, so be
1:bb8f25a:         // prepared to retry.
1:6e61723:         boolean success = false;
1:abf8151:         int maxTries = InterruptStatus.MAX_INTERRUPT_RETRIES;
1:eac0369: 
1:6e61723:         while (!success) {
1:6e61723:             success = true;
1:eac0369: 
1:a2f90d4:             synchronized (this) {
1:eac0369: 
1:bb8f25a:                 // committed and dropped, do nothing.
1:bb8f25a:                 // This file container has already been stubbified
1:bb8f25a:                 if (getCommittedDropState()) {
1:bb8f25a:                     clearDirty();
1:bb8f25a:                     return;
1:a2f90d4:                 }
1:bb8f25a: 
1:bb8f25a:                 // The container is about to change, need to wait till it is
1:bb8f25a:                 // really changed.  We are in the predirty state only for the
1:bb8f25a:                 // duration where the log record that changed the container has
1:bb8f25a:                 // been sent to the log and before the change actually
1:bb8f25a:                 // happened.
1:bb8f25a:                 while(preDirty == true)
1:6e61723:                 {
1:bb8f25a:                     waited = true;
1:6e61723:                     try
1:bb8f25a:                     {
1:25f99f5:                         wait();
1:a2f90d4:                     }
1:25f99f5:                     catch (InterruptedException ie)
1:bb8f25a:                     {
1:bb8f25a:                         InterruptStatus.setInterrupted();
1:6e61723:                     }
1:6e61723:                 }
1:bb8f25a: 
1:bb8f25a:                 if (waited)
1:bb8f25a:                 {
1:bb8f25a:                     // someone else may have stubbified this while we waited
1:bb8f25a:                     if (getCommittedDropState())
1:bb8f25a:                     {
1:bb8f25a:                         clearDirty();
1:bb8f25a:                         return;
1:bb8f25a:                     }
1:bb8f25a:                 }
1:eac0369: 
1:eac0369: 
1:bb8f25a:                 if (forRemove) {
1:eac0369: 
1:bb8f25a:                     //              removeFile()
1:bb8f25a:                     //              clearDirty();
1:eac0369: 
1:bb8f25a:                 } else if (isDirty()) {
1:eac0369: 
1:a2f90d4:                     try {
1:eac0369: 
1:bb8f25a:                         // Cannot get the alloc page and write it out because
1:bb8f25a:                         // in order to do so, the alloc page will need to find
1:bb8f25a:                         // this container object.  But this container object is
1:bb8f25a:                         // in the middle of being cleaned and may not be
1:bb8f25a:                         // 'found' and we will hang.
1:6e61723:                         //
1:bb8f25a:                         // Instead, just clobber the container info, which is
1:bb8f25a:                         // checksum'ed seperately from the alloc page
1:bb8f25a:                         //
1:30c9f82:                         writeRAFHeader(
1:30c9f82:                             getIdentity(),
1:30c9f82:                             fileData,
1:bb8f25a:                             false,  // don't create, container exists
1:bb8f25a:                             true);  // syncfile
1:eac0369: 
1:bb8f25a:                         clearDirty();
1:eac0369: 
1:bb8f25a:                     } catch (InterruptDetectedException e) {
1:6e61723:                         if (--maxTries > 0) {
1:6e61723:                             success = false;
1:bb8f25a: 
1:bb8f25a:                             // Wait a bit so recovery can take place before
1:bb8f25a:                             // we re-grab monitor on "this" (which recovery
1:bb8f25a:                             // needs) and retry writeRAFHeader.
1:a2f90d4:                             try {
1:abf8151:                                 Thread.sleep(
1:abf8151:                                     InterruptStatus.INTERRUPT_RETRY_SLEEP);
1:bb8f25a:                             } catch (InterruptedException ee) {
1:bb8f25a:                                 // This thread received an interrupt as
1:bb8f25a:                                 // well, make a note.
1:6e61723:                                 InterruptStatus.setInterrupted();
1:bb8f25a:                             }
1:bb8f25a: 
1:bb8f25a:                             continue; // retry write of RAFHeader
3:25f99f5:                         } else {
1:bb8f25a:                             // We have tried for a minute, not sure what's
1:bb8f25a:                             // going on, so to be on safe side we can't
1:bb8f25a:                             // continue
1:bb8f25a:                             throw StandardException.newException(
1:bb8f25a:                                 SQLState.FILE_IO_INTERRUPTED, e);
1:bb8f25a:                         }
1:b7f22c3:                     } catch (IOException ioe) {
1:bb8f25a: 
1:bb8f25a:                         throw dataFactory.markCorrupt(
1:bb8f25a:                             StandardException.newException(
1:26c2de4:                                 SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:26c2de4:                                 getIdentity() != null ?
1:26c2de4:                                 getIdentity().toString() : "unknown",
1:26c2de4:                                 "clean", fileName));
1:bb8f25a:                     }
1:bb8f25a:                 }
1:bb8f25a:             }
1:bb8f25a:         }
1:bb8f25a: 	}
1:eac0369: 
1:eac0369: 	private void clearDirty() {
1:eac0369: 		isDirty = false;
1:eac0369: 		needsSync = false;
1:bb8f25a: 	}
1:eac0369: 
1:eac0369: 
1:25f99f5: 	/**
1:eac0369: 		Preallocate some pages if need be
1:a2f90d4: 	*/
1:eac0369: 	protected int preAllocate(long lastPreallocPagenum, 
1:eac0369: 							  int preAllocSize)
1:eac0369: 	{  
1:eac0369: 	
1:eac0369: 		/* we had a condition here , that looks at the file size before
1:eac0369: 		 * preallocation to handle the optimization cases like , we 
1:eac0369: 		 * preallocated the space and then crashed, as we don;t log the 
1:eac0369: 		 * preallocated length, we don't have updated value until AlocExtent
1:eac0369: 		 * page get flushed to the disk. only way to find out that the pages
1:eac0369: 		 * we want already exist  is to look at the file length.
1:eac0369: 		 * Althought it was nice thing to do, we had bug no: 3813 from
1:eac0369: 		 * customer , who for some unexplainable reasons he gets lots of
1:eac0369: 		 * junk at the end of the file. As junk is not initialized with
1:eac0369: 		 * format-ID , we get into recovery problem.
1:eac0369: 		 * To avoid such unforseen conditions, removed the file size check 
1:eac0369: 		 * condition , as it is better not to fail in recovery than 
1:eac0369: 		 * losing some special case performance improvement.
1:eac0369: 		 */
1:eac0369:   
1:eac0369: 		int n = doPreAllocatePages(lastPreallocPagenum, preAllocSize); 
1:eac0369: 
1:eac0369: 		if (n > 0)				// sync the file
1:eac0369: 		{
1:eac0369: 			synchronized(this)
1:eac0369: 			{
1:eac0369: 				boolean inwrite = false;
1:eac0369: 				try
1:eac0369: 				{
1:6e61723: 					dataFactory.writeInProgress();
1:eac0369: 					inwrite = true;
1:eac0369: 
1:3108420:                     if (!dataFactory.dataNotSyncedAtAllocation)
1:a552fe6:                         fileData.sync();
1:3108420:   				}
1:eac0369: 				catch (IOException ioe)
1:eac0369: 				{
1:eac0369: 					// The disk may have run out of space. 
1:eac0369: 					// Don't error out in pre-allocation since the user may not
1:eac0369: 					// actually need this page.
1:eac0369: 					n = 0;
1:bb8f25a: 				}
1:eac0369: 				catch (StandardException se)
1:eac0369: 				{
1:eac0369: 					// some problem calling writeInProgress
1:eac0369: 					n = 0;
81:eac0369: 				}
1:6e61723: 				finally
1:eac0369: 				{
1:eac0369: 					if (inwrite)
1:eac0369: 						dataFactory.writeFinished();
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return n;
1:eac0369: 	}
1:bbc927c: 
1:bbc927c:     /**
1:20bc69f:      * Truncate pages of a container.
1:bbc927c:      * <p>
1:20bc69f:      * Truncate all pages from lastValidPagenum+1 through the end of the file.
1:bbc927c:      * <p>
1:a2f90d4:      *
1:20bc69f:      * @param lastValidPagenum  The page number of the last valid page of the
1:20bc69f:      *                          file.  All pages after this one are truncated.
1:25f99f5:      *
1:bbc927c: 	 * @exception  StandardException  Standard exception policy.
1:bbc927c:      **/
1:bbc927c: 	protected void truncatePages(
1:bbc927c:     long lastValidPagenum)
1:06dbbcf:         throws StandardException
1:bbc927c: 	{  
1:06dbbcf: 
1:bbc927c: 
1:bbc927c:         synchronized(this)
1:bbc927c:         {
1:bbc927c:             boolean inwrite = false;
1:bbc927c:             try
1:bbc927c:             {
1:bbc927c:                 dataFactory.writeInProgress();
1:bbc927c:                 inwrite = true;
1:eac0369: 
1:bbc927c:                 fileData.setLength((lastValidPagenum + 1) * pageSize);
1:bbc927c:             }
1:bbc927c:             catch (IOException ioe)
1:bbc927c:             {
1:bbc927c:                 // The disk may have run out of space. 
1:bbc927c:                 // Don't error out in un-allocation since application can
1:bbc927c:                 // still function even if allocation fails.
1:bbc927c:             }
1:bbc927c:             catch (StandardException se)
1:bbc927c:             {
1:bbc927c:                 // some problem calling writeInProgress
1:bbc927c:             }
1:bbc927c:             finally
1:bbc927c:             {
1:bbc927c:                 if (inwrite)
1:bbc927c:                     dataFactory.writeFinished();
1:bbc927c:             }
1:bbc927c:         }
1:bbc927c: 
1:bbc927c: 		return;
1:bbc927c: 	}
1:bbc927c: 
1:eac0369: 
1:bb8f25a: 	/**
1:eac0369: 		Write the header of a random access file and sync it
1:eac0369: 		@param create if true, the container is being created
1:eac0369: 				if false, the container already exist
1:eac0369: 		@param syncFile if true, sync the file
1:eac0369: 	*/
1:30c9f82:     private void writeRAFHeader(
1:30c9f82:     Object                  identity,
1:30c9f82:     StorageRandomAccessFile file, 
1:30c9f82:     boolean                 create, 
1:eac0369: 								boolean syncFile) 
1:eac0369: 		 throws IOException, StandardException
1:eac0369: 	{
1:eac0369: 		byte[] epage;
1:eac0369: 		if (create)
1:eac0369: 		{
1:eac0369: 			// the file doesn't exist yet, get an embryonic page buffer
1:9b54b81: 
1:9b54b81:             // Allocating AllocPage.MAX_BORROWED_SPACE bytes for the
1:9b54b81:             // embryonic page should be enough, but we want to leave
1:9b54b81:             // the end of the file at a page boundary. This is to work
1:9b54b81:             // around bugs in the EPOC jvm where a seek beyond the end
1:9b54b81:             // of a file does not throw an exception but just moves
1:9b54b81:             // the offset to the end of the file. This only occurs
1:9b54b81:             // when the second page is written after the header has
1:9b54b81:             // been written, ending up with the page at the incorrect
1:9b54b81:             // offset.
1:9b54b81: 
1:9b54b81:             epage = new byte[pageSize];
1:eac0369: 		}
1:eac0369: 		else
1:eac0369: 		{
1:b44572f: 			epage = getEmbryonicPage(file, FIRST_ALLOC_PAGE_OFFSET);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// need to check for frozen state
1:eac0369: 
1:30c9f82:         writeHeader(identity, file, create, epage);
1:eac0369: 
1:eac0369: 		if (syncFile)
1:eac0369: 		{
1:eac0369: 			dataFactory.writeInProgress();
1:eac0369: 			try
1:eac0369: 			{
1:3108420:                 if (!dataFactory.dataNotSyncedAtCheckpoint)
1:a552fe6:                    file.sync();
1:3108420: 
1:eac0369: 			}
1:eac0369: 			finally
1:eac0369: 			{
1:eac0369: 				dataFactory.writeFinished();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:ae71c74: 	/**
1:eac0369: 		flush the cache to ensure all of my pages are written to disk
1:eac0369: 
1:94f158a: 		@exception StandardException Standard Derby error policy
1:eac0369: 	*/
1:eac0369: 	protected void flushAll() throws StandardException {
1:eac0369: 
1:eac0369: 		pageCache.clean(identity);
1:eac0369: 
1:eac0369: 		// now clean myself which will sync all my pages.
1:eac0369: 		clean(false);
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:7a92d1f: 	 synchronized StorageFile getFileName(ContainerKey identity, boolean stub,
1:eac0369: 											 boolean errorOK, boolean tryAlternatePath)
1:ae71c74: 		 throws StandardException
1:eac0369: 	 {
1:eac0369:          // RESOLVE - READ ONLY
1:eac0369: 
1:eac0369:          actionCode = GET_FILE_NAME_ACTION;
1:eac0369:          actionIdentity = identity;
1:eac0369:          actionStub = stub;
1:eac0369:          actionErrorOK = errorOK;
1:eac0369:          actionTryAlternatePath = tryAlternatePath;
1:eac0369:          try
1:eac0369:          {
1:eac0369:              return (StorageFile) AccessController.doPrivileged( this);
1:eac0369:          }
1:25f99f5:          catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
2:eac0369:          finally{ actionIdentity = null; }
1:eac0369: 	 }
1:eac0369: 
1:eac0369:     protected StorageFile privGetFileName(ContainerKey identity, boolean stub,
1:eac0369:                                     boolean errorOK, boolean tryAlternatePath)
1:25f99f5:         throws StandardException
1:eac0369:     {
1:eac0369:         StorageFile container = dataFactory.getContainerPath( identity, stub);
1:eac0369: 
1:eac0369:         // retry with small case 'c' and 'd'
1:eac0369:         // bug fix for track 3444
1:eac0369:         if (!container.exists() && tryAlternatePath)
1:eac0369:         {
1:eac0369:             container = dataFactory.getAlternateContainerPath( identity, stub);
1:eac0369:         }
1:eac0369: 
1:eac0369:         if (!container.exists()) {
1:eac0369: 
1:eac0369:             StorageFile directory = container.getParentDir();
1:eac0369: 
1:eac0369:             if (!directory.exists())
1:eac0369:             {
1:eac0369:                 // make sure only 1 thread can create a segment at one time
1:eac0369:                 synchronized(dataFactory)
1:eac0369:                 {
1:eac0369:                     if (!directory.exists())
1:eac0369:                     {
1:eac0369:                         if (!directory.mkdirs())
1:eac0369:                         {
1:eac0369:                             if (errorOK)
1:eac0369:                             {
2:eac0369:                                 return null;
1:eac0369:                             }
1:eac0369:                             else
1:eac0369:                             {
1:79d6448:                                 throw StandardException.newException(
1:eac0369:                                     SQLState.FILE_CANNOT_CREATE_SEGMENT,
1:eac0369:                                     directory);
1:eac0369:                             }
1:eac0369:                         }
1:dc43cf8: 
1:a2f90d4:                         try {
1:4f7eee8:                             directory.limitAccessToOwner();
1:4f7eee8:                         } catch (IOException ioe) {
1:4f7eee8:                             if (errorOK) {
1:4f7eee8:                                 return null;
1:4f7eee8:                             } else {
1:4f7eee8:                                 throw StandardException.newException(
1:4f7eee8:                                         SQLState.FILE_CANNOT_CREATE_SEGMENT,
1:4f7eee8:                                         ioe, directory);
1:4f7eee8:                             }
1:4f7eee8:                         }
1:eac0369:                     }
1:eac0369:                 }
1:eac0369:             }
1:eac0369:         }
1:e910eee: 
1:eac0369:         return container;
1:eac0369:     } // end of privGetFileName
1:eac0369: 
1:eac0369: 
1:7a92d1f: 	synchronized void createContainer(ContainerKey newIdentity)
5:eac0369:         throws StandardException
1:eac0369:     {
1:eac0369: 
1:a2f90d4: 		if (SanityManager.DEBUG) {
1:eac0369: 			if ((spareSpace < 0) || (spareSpace > 100))
1:eac0369: 				SanityManager.THROWASSERT("invalid spare space " + spareSpace);
1:eac0369: 		}
1:eac0369: 
1:eac0369:         actionCode = CREATE_CONTAINER_ACTION;
1:eac0369:         actionIdentity = newIdentity;
1:eac0369:         try
1:eac0369:         {
1:eac0369:             AccessController.doPrivileged( this);
1:bb8f25a:         }
3:eac0369:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:eac0369:         finally{ actionIdentity = null; }
1:eac0369:     } // end of createContainer
1:6d4d95d: 
1:6d4d95d:     /**
1:6d4d95d:      * Copy the contents of a {@code StorageFile} to a {@code java.io.File}.
1:6d4d95d:      *
1:6d4d95d:      * @param from the file to copy from
1:6d4d95d:      * @param to the file to copy to
1:6d4d95d:      * @throws StandardException if the copying failed
1:6d4d95d:      */
1:6d4d95d:     private void copyFile(final StorageFile from, final File to)
1:6d4d95d:             throws StandardException {
1:bb5be6f:         PrivilegedAction<Boolean> pa = () ->
1:bb5be6f:                 FileUtil.copyFile(dataFactory.getStorageFactory(), from, to);
1:bb5be6f:         boolean success = AccessController.doPrivileged(pa);
1:bb5be6f:         if (!success) {
1:6d4d95d:             throw StandardException.newException(
1:6d4d95d:                     SQLState.RAWSTORE_ERROR_COPYING_FILE,
1:6d4d95d:                     from, to);
1:6d4d95d:         }
1:6d4d95d:     }
1:6d4d95d: 
1:6d4d95d:     /**
1:6d4d95d:      * Remove a file.
1:6d4d95d:      * @param file the file to remove
1:6d4d95d:      * @throws StandardException if the file could not be removed
1:6d4d95d:      */
1:6d4d95d:     private void removeFile(final File file) throws StandardException {
1:bb5be6f:         PrivilegedAction<Boolean> pa = () -> !file.exists() || file.delete();
1:bb5be6f:         boolean success = AccessController.doPrivileged(pa);
1:bb5be6f:         if (!success) {
1:6d4d95d:             throw StandardException.newException(
1:6d4d95d:                     SQLState.UNABLE_TO_DELETE_FILE, file);
1:6d4d95d:         }
1:6d4d95d:     }
1:6d4d95d: 
1:7a92d1f: 	synchronized boolean removeFile(StorageFile file)
1:e910eee:         throws SecurityException, StandardException
1:e910eee:     {
1:eac0369:         actionCode = REMOVE_FILE_ACTION;
1:eac0369:         actionFile = file;
1:eac0369:         try
1:e910eee:         {
2:eac0369:             return AccessController.doPrivileged( this) != null;
1:01a4f9b:         }
1:eac0369:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:eac0369:         finally{ actionFile = null; }
1:eac0369:     } // end of removeFile
1:01a4f9b: 
1:eac0369:     private boolean privRemoveFile(StorageFile file)
1:eac0369:         throws StandardException
1:eac0369:     {
1:6e61723: 		closeContainer();
1:bb8f25a: 
1:eac0369: 		dataFactory.writeInProgress();
1:eac0369: 		try
1:eac0369: 		{
1:f9f4d94:             if (file.exists())
1:eac0369:                 return file.delete();
1:e910eee: 		}
1:eac0369: 		finally
1:eac0369: 		{
1:eac0369: 			dataFactory.writeFinished();
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return true;
1:eac0369:     } // end of privRemoveFile
1:eac0369: 
1:eac0369: 
1:bd018fd:     synchronized boolean openContainer(ContainerKey newIdentity)
2:01a4f9b:             throws StandardException {
1:eac0369:         actionCode = OPEN_CONTAINER_ACTION;
1:eac0369:         actionIdentity = newIdentity;
1:eac0369:         try
1:eac0369:         {
1:08b4ed5:             return AccessController.doPrivileged( this) != null;
1:eac0369:         }
1:08b4ed5:         catch( PrivilegedActionException pae) {
1:c33b0cf:             closeContainer();
1:c33b0cf:             throw (StandardException) pae.getException();
1:c33b0cf:         }
1:c33b0cf:         catch (RuntimeException e) {
1:c33b0cf:             closeContainer();
1:c33b0cf:             throw e;
1:bd018fd:         }
1:c33b0cf:         finally
1:c33b0cf:         {
1:08b4ed5:             actionIdentity = null;
1:08b4ed5:         }
1:08b4ed5:     }
1:bd018fd: 
1:08b4ed5:     /**
1:08b4ed5:      * Only used by RAFContainer4 (NIO) to reopen RAF when its channel gets
1:08b4ed5:      * closed due to interrupts.
1:25f99f5:      *
1:08b4ed5:      * @param currentIdentity
1:08b4ed5:      * @throws StandardException standard exception policy
1:08b4ed5:      */
1:08b4ed5:     protected synchronized void reopenContainer(ContainerKey currentIdentity)
1:08b4ed5:             throws StandardException {
1:08b4ed5: 
1:08b4ed5:         actionCode = REOPEN_CONTAINER_ACTION;
1:08b4ed5:         actionIdentity = currentIdentity;
1:08b4ed5: 
1:a2f90d4:         try {
1:25f99f5:             AccessController.doPrivileged(this);
1:08b4ed5:         } catch (PrivilegedActionException pae) {
1:08b4ed5:             closeContainer();
1:08b4ed5:             throw (StandardException) pae.getException();
1:08b4ed5:         } catch (RuntimeException e) {
1:08b4ed5:             closeContainer();
1:08b4ed5:             throw e;
1:a2f90d4:         } finally {
1:08b4ed5:             actionIdentity = null;
1:c33b0cf:         }
1:c33b0cf:     }
1:bd018fd: 
1:7a92d1f: 	private synchronized void stubbify(LogInstant instant)
1:eac0369:         throws StandardException
1:eac0369: 	{
1:eac0369:          // update header, synchronized this in case the cache is cleaning
1:eac0369:          // this container at the same time.  Make sure the clean and
1:eac0369:          // stubbify is mutually exclusive.
1:eac0369:          setDroppedState(true);
1:eac0369:          setCommittedDropState(true);
1:eac0369: 
1:eac0369: 		 // The whole container should be shrunk into a 'stub'.
1:eac0369: 		 // If the file system supports truncation, we can just truncate the
1:eac0369: 		 // file after the header.  Since it doesn't, we need to write out a
1:eac0369: 		 // seperate file (the stub), then reset fileData to point to that,
1:eac0369: 		 // then remove the current file.
1:bd018fd: 		 //
1:eac0369: 		 // There may still be dirty pages that belongs to this file which are
1:eac0369: 		 // still in the page cache.  They need not really
1:eac0369: 		 // be written since they don't really exist anymore
1:bb8f25a: 		 //
1:eac0369: 		 // there are 3 pieces of information on disk :
1:eac0369: 		 // 1) the log operation that caused this file to be stubbified
1:eac0369: 		 // 2) the stub
1:eac0369: 		 // 3) the file
8:eac0369: 		 //
1:eac0369: 		 // The order of event, as far as persisent store is concerned, is
1:eac0369: 		 // A) stub shows up
1:eac0369: 		 // B) the file disappear
1:eac0369: 		 // C) the log operation got flushed
1:eac0369: 		 // (B and C may swap order)
1:eac0369: 		 //
1:eac0369: 		 // If neither A or B happens (we crashed before the sync call),
1:eac0369: 		 // then nothing happened.
1:eac0369: 		 //
1:eac0369: 		 // if A happened but B and C did not, then when we recover, we will not
1:eac0369: 		 // know the file has been stubbified.  Hopefully, it will be stubbified
1:eac0369: 		 // again if the post-commit queue manager is alerted to the fact.
1:eac0369: 		 //
1:eac0369: 		 // if A and B happened but C did not, then the file is stubbified but
1:eac0369: 		 // there is no log record to indicate that.  This is undesirable but
1:eac0369: 		 // still safe because the only time we stubbify is on a post commit
1:eac0369: 		 // operation, i.e., either a create container has rolled back or a
1:eac0369: 		 // dropped container has committed.  We end up having a a container
1:eac0369: 		 // stub which behaves the same as a dropped container - only that all
1:eac0369: 		 // the redo work is unnecessary because we 'know' it will
1:eac0369: 		 // eventually be dropped and committed.
1:eac0369: 		 //
1:eac0369: 		 // If A and C happened and not B, then during redo, this stubbify
1:eac0369: 		 // routine will be called again and the file will be deleted again
1:eac0369: 		 //
1:eac0369: 		 // The reason why A has to be sync'ed out is that we don't want B to
1:eac0369: 		 // happen but A did not and the system crashed.  Then we are left
1:eac0369: 		 // with neither the file nor the stub and maybe even no log record.
1:eac0369: 		 // Then the system is not recoverable.
1:eac0369: 
1:eac0369: 		actionIdentity = (ContainerKey)getIdentity();
1:eac0369:         actionInstant = instant;
1:eac0369:         actionCode = STUBBIFY_ACTION;
1:eac0369:         try
1:eac0369:         {
1:eac0369:             AccessController.doPrivileged( this);
1:e910eee:         }
1:eac0369:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:eac0369:         finally
1:eac0369:         {
1:c33b0cf:             actionIdentity = null;
1:eac0369:             actionInstant = null;
1:eac0369:         }
1:eac0369:     }
1:eac0369: 
10:eac0369:     /**
1:bf643fd:      * Backup the  container.
1:bf643fd:      *
1:bf643fd:      * The container is written to the backup by reading  the pages
1:bf643fd:      * through the page cache, and then writing into the backup container.
1:bf643fd:      * If the container is dropped(commitetd drop), only container stub is
1:bf643fd:      * copied to the  backup using simple file copy. 
1:bf643fd:      * 
1:bf643fd:      * MT - 
1:bf643fd:      * At any given time only one backup thread is allowed, but when backup in 
1:bf643fd:      * progress DML/DDL operations can run in parallel. Pages are latched while 
1:bf643fd:      * writing them to the backup to avoid copying partial changes to the pages.
1:bf643fd:      * Online backup does not acquire any user level locks , so users can drop
1:bf643fd:      * tables when backup is in progress. So it is possible that Container 
1:bf643fd:      * Removal request can come in when container backup is in progress.  
1:25f99f5: 	 * This case is handled by using the synchronization on this object monitor 
1:bf643fd: 	 * and using inRemove and inBackup flags. Conatiner removal checks if backup
1:bf643fd:      * is in progress and wait for the backup to yield to continue the removal. 
1:bf643fd:      * Basic idea is to give preference to remove by stopping the backup of the 
1:bf643fd:      * container temporarily,  when the remove container is requested by another 
1:bf643fd:      * thread. Generally, it takes more  time to backup a regular container than 
1:bf643fd:      * the stub becuase  stub is just one page. After each page copy, a check is
1:bf643fd:      * made to find  if a remove is requested and if it is then backup of the 
1:bf643fd:      * container is aborted and the backup thread puts itself into the wait state until
1:25f99f5: 	 * remove  request thread notifies that the remove is complete. When 
1:bf643fd: 	 * remove request compeletes stub is copied into the backup.
1:25f99f5: 	 * 
1:bf643fd:      * Compress is blocked when backup is in progesss, so truncation of the
1:bf643fd:      * container can not happen when backup is in progess. No need to
1:bf643fd:      * synchronize backup of the container with truncation. 
1:bf643fd:      * 
1:bf643fd:      * 
1:bf643fd:      * @param handle the container handle.
1:bf643fd:      * @param backupLocation location of the backup container. 
1:bf643fd:      * @exception StandardException Derby Standard error policy
1:bf643fd:      *
1:bf643fd:      */
1:6d4d95d:     protected void backupContainer(BaseContainerHandle handle,
1:6d4d95d:                                    String backupLocation)
1:bf643fd:         throws StandardException 
1:bf643fd:     {
1:bf643fd:         boolean backupCompleted = false;
1:bf643fd:         File backupFile = null;
1:bf643fd:         RandomAccessFile backupRaf = null;
1:bf643fd:         boolean isStub = false;
1:bf643fd:         BasePage page = null; 
1:ae71c74: 
1:bf643fd:         while(!backupCompleted) {
1:bf643fd:             try {
1:ae71c74: 
1:bf643fd:                 synchronized (this) {
1:bf643fd:                     // wait if some one is removing the 
1:bf643fd:                     // container because of a drop.
1:bf643fd:                     while (inRemove)
1:bf643fd:                     {
1:bf643fd:                         try	{
1:bf643fd:                             wait();
1:bf643fd:                         }
1:bf643fd:                         catch (InterruptedException ie)
1:bf643fd:                         {
1:bb8f25a:                             InterruptStatus.setInterrupted();
1:bf643fd:                         }	
1:bf643fd:                     }
1:bf643fd: 
1:bf643fd:                     if (getCommittedDropState())
1:bf643fd:                         isStub = true;
1:bf643fd:                     inBackup = true;
1:bf643fd:                 }
1:ae71c74: 			
1:bf643fd:                 // create container at the backup location.
1:bf643fd:                 if (isStub) {
1:bf643fd:                     // get the stub ( it is a committted drop table container )
1:6d4d95d:                     StorageFile file = getFileName((ContainerKey)getIdentity(),
1:bf643fd:                                                        true, false, true);
1:bf643fd:                     backupFile = new File(backupLocation, file.getName());
1:25f99f5: 
1:25f99f5: 					// directly copy the stub to the backup 
1:6d4d95d:                     copyFile(file, backupFile);
1:bf643fd:                 }else {
1:bf643fd:                     // regular container file 
1:bf643fd:                     long lastPageNumber= getLastPageNumber(handle);
1:6700e19:                     if (lastPageNumber == ContainerHandle.INVALID_PAGE_NUMBER) {
1:6700e19:                         // last page number is invalid if there are no pages in
1:6700e19:                         // the container yet. No need to backup this container, 
1:6700e19:                         // this container creation is yet to complete.The reason
1:6700e19:                         // backup is getting called on such a container is 
1:6700e19:                         // because container handle appears in the cache after 
1:6700e19:                         // the file is created on the disk but before it's 
1:6700e19:                         // first page is allocated. 
1:6700e19:                         return;
1:6700e19:                     }
1:6700e19: 
1:6700e19:                     StorageFile file = 
1:6d4d95d:                         getFileName(
1:6700e19:                             (ContainerKey)getIdentity(), false, false, true);
1:6700e19: 
1:6700e19:                     backupFile = new File(backupLocation , file.getName());
1:6d4d95d:                     backupRaf  = getRandomAccessFile(backupFile);
1:bf643fd: 
1:bf643fd:                     byte[] encryptionBuf = null;
1:bf643fd:                     if (dataFactory.databaseEncrypted()) {
1:bf643fd:                         // Backup uses seperate encryption buffer to encrypt the
1:6700e19:                         // page instead of encryption buffer used by the regular
1:6700e19:                         // conatiner writes. Otherwise writes to the backup 
1:bf643fd:                         // has to be synchronized with regualar database writes
1:bf643fd:                         // because backup can run in parallel to container
1:bf643fd:                         // writes.
1:bf643fd:                         encryptionBuf = new byte[pageSize];
1:bf643fd:                     }
1:bf643fd: 
1:6700e19:                     // copy all the pages of the container from the database 
1:6700e19:                     // to the backup location by reading through the page cache.
1:bf643fd:                     for (long pageNumber = FIRST_ALLOC_PAGE_NUMBER; 
1:bf643fd:                          pageNumber <= lastPageNumber; pageNumber++) {
1:ae71c74:                         page = getLatchedPage(handle, pageNumber);
1:bf643fd:                         
1:bf643fd:                         // update the page array before writing to the disk 
1:bf643fd:                         // with container header and encrypt it if the database 
1:bf643fd:                         // is encrypted. 
1:bf643fd:                         
1:30c9f82:                         byte[] dataToWrite = 
1:30c9f82:                             updatePageArray(
1:30c9f82:                                 pageNumber, 
1:bf643fd:                                                              page.getPageArray(), 
1:30c9f82:                                 encryptionBuf, 
1:30c9f82:                                 false);
1:bf643fd:                         backupRaf.write(dataToWrite, 0, pageSize);
1:bf643fd: 
1:bf643fd:                         // unlatch releases page from cache, see 
1:bf643fd:                         // StoredPage.releaseExclusive()
1:bf643fd:                         page.unlatch();
1:bf643fd:                         page = null;
1:bf643fd: 
1:bf643fd:                         // check if some one wants to commit drop the table while
1:bf643fd:                         // conatiner is being written to the backup. If so,
1:bf643fd:                         // abort  the backup and restart it once the drop 
1:bf643fd:                         // is complete.
1:25f99f5: 
1:25f99f5: 						synchronized (this)
1:bf643fd: 						{
1:25f99f5: 							if (inRemove) {
1:bf643fd: 								break; 
1:bf643fd: 							}
1:25f99f5: 						}
1:25f99f5: 					}
1:25f99f5: 				}	
1:bf643fd: 
1:bf643fd:                 // sync and close the backup conatiner. Incase of a stub, 
1:bf643fd:                 // it is already synced and closed while doing the copy.
1:bf643fd:                 if(!isStub) {
1:bf643fd:                     backupRaf.getFD().sync();
1:bf643fd:                     backupRaf.close();
1:bf643fd:                     backupRaf = null;
1:bf643fd:                 }
1:bf643fd:                 
1:bf643fd:                 // backup of the conatiner is complete. 
1:bf643fd:                 backupCompleted = true;
1:bf643fd: 
1:bf643fd:             }catch (IOException ioe) {
1:bf643fd:                 throw StandardException.newException(
1:bf643fd:                                                 SQLState.BACKUP_FILE_IO_ERROR, 
1:bf643fd:                                                 ioe, 
2:bf643fd:                                                 backupFile);
1:bf643fd:             } finally {
1:bf643fd:                 synchronized (this) {
1:bf643fd:                     inBackup = false;
1:bf643fd:                     notifyAll();
1:bf643fd:                 }
1:bf643fd: 
1:bf643fd:                 if (page != null) {
1:bf643fd:                     page.unlatch();
1:bf643fd:                     page = null;
1:bf643fd:                 }
1:bf643fd: 
1:bf643fd:                 // if backup of container is not complete, close the file
1:bf643fd:                 // handles and  remove the container file from the backup 
1:bf643fd:                 // if it exists
1:bf643fd:                 if (!backupCompleted && backupFile != null) 
1:bf643fd:                 {
1:bf643fd:                     if (backupRaf != null) 
1:bf643fd:                     {
1:25f99f5: 						try {
1:bf643fd:                             backupRaf.close();
1:bf643fd:                             backupRaf = null;
1:bf643fd:                         } catch (IOException ioe){
1:bf643fd:                             throw StandardException.newException(
1:bf643fd:                                             SQLState.BACKUP_FILE_IO_ERROR, 
1:bf643fd:                                             ioe, 
1:bf643fd:                                             backupFile);
1:25f99f5:                         }
1:25f99f5:                     }
1:25f99f5: 
1:6d4d95d:                     removeFile(backupFile);
1:25f99f5:                 } 
1:25f99f5:             }
1:25f99f5:         }
1:25f99f5:     }
1:25f99f5: 
1:25f99f5: 
1:25f99f5: 
1:25f99f5: 
1:eac0369:     /**
1:89a6625:      * Creates encrypted or decrypted version of the container.
1:25f99f5:      *
1:89a6625:      * Reads all the pages of the container from the original container
1:d203eea:      * through the page cache, then either encrypts page data with the new
1:d203eea:      * encryption mechanism or leaves the page data un-encrypted, and finally
1:d203eea:      * writes the data to the specified new container file.
1:89a6625:      * <p>
1:89a6625:      * The encryption and decryption engines used to carry out the
1:89a6625:      * cryptographic operation(s) are configured through the raw store, and
1:d203eea:      * accessed via the data factory. Note that the pages have already been
1:d203eea:      * decrypted before being put into the page cache.
3:bbc927c:      *
1:89a6625:      * @param handle the container handle
1:89a6625:      * @param newFilePath file to store the new version of the container in
1:d203eea:      * @param doEncrypt tells whether to encrypt or not
1:ae71c74:      * @exception StandardException Derby Standard error policy
1:ae71c74:      */
1:89a6625:     protected void encryptOrDecryptContainer(BaseContainerHandle handle,
1:89a6625:                                              String newFilePath,
1:89a6625:                                              boolean doEncrypt)
1:25f99f5:         throws StandardException 
1:25f99f5:     {
1:ae71c74:         BasePage page = null; 
1:ae71c74:         StorageFile newFile = 
1:ae71c74:             dataFactory.getStorageFactory().newStorageFile(newFilePath);
1:79d6448:         StorageRandomAccessFile newRaf = null;
1:25f99f5:         try {
1:25f99f5:             long lastPageNumber= getLastPageNumber(handle);
1:25f99f5:  
1:6d4d95d:             newRaf = getRandomAccessFile(newFile);
1:25f99f5: 
1:ae71c74:             byte[] encryptionBuf = null;
1:d203eea:             if (doEncrypt) {
1:d203eea:                 encryptionBuf = new byte[pageSize];
1:25f99f5:             }
1:25f99f5: 
1:d203eea:             // Copy all the pages from the current container to the new
1:d203eea:             // container file after processing the pages.
1:25f99f5:             for (long pageNumber = FIRST_ALLOC_PAGE_NUMBER; 
1:ae71c74:                  pageNumber <= lastPageNumber; pageNumber++) 
1:25f99f5:             {
1:25f99f5: 
1:ae71c74:                 page = getLatchedPage(handle, pageNumber);
1:25f99f5:                         
1:d203eea:                 // Update the page array before writing to the disk.
1:d203eea:                 // An update consists of adding the container header, or
1:d203eea:                 // (re-)encrypting the data.
1:bf643fd:                 byte[] dataToWrite = updatePageArray(pageNumber, 
1:ae71c74:                                                      page.getPageArray(), 
1:ae71c74:                                                      encryptionBuf, 
1:ae71c74:                                                      true);
1:ae71c74:                 newRaf.write(dataToWrite, 0, pageSize);
1:25f99f5: 
1:ae71c74:                 // unlatch releases page from cache.
1:25f99f5:                 page.unlatch();
1:ae71c74:                 page = null;
1:bf643fd:             }
1:25f99f5: 
1:79d6448:             // sync the new version of the container.
1:a552fe6:             newRaf.sync();
1:ae71c74:             newRaf.close();
1:79d6448:             newRaf = null;
1:79d6448:             
1:ae71c74:         }catch (IOException ioe) {
1:bf643fd:             throw StandardException.newException(
1:26c2de4:                                     SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:26c2de4:                                     getIdentity() != null ?
1:26c2de4:                                         getIdentity().toString() : "unknown",
1:d203eea:                                     doEncrypt ? "encrypt" : "decrypt",
1:d203eea:                                     newFilePath);
1:25f99f5:         } finally {
1:ae71c74: 
1:ae71c74:             if (page != null) {
2:ae71c74:                 page.unlatch();
1:ae71c74:                 page = null;
1:bf643fd:             }
1:ae71c74:             
1:79d6448:             if (newRaf != null) {
1:25f99f5:                 try {
1:79d6448:                     newRaf.close();
1:79d6448:                 }catch (IOException ioe) 
1:bf643fd:                 {
1:79d6448:                     newRaf = null;
1:bf643fd:                     throw StandardException.newException(
1:26c2de4:                                     SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:26c2de4:                                     getIdentity() != null ?
1:26c2de4:                                         getIdentity().toString() : "unknown",
1:d203eea:                                     doEncrypt ?
1:d203eea:                                         "encrypt-close" : "decrypt-close",
1:d203eea:                                     newFilePath);
1:bf643fd:                 }
1:bf643fd:             }
1:bf643fd:         }
1:bf643fd:     }
1:ae71c74: 
1:eac0369:     /**
1:6d4d95d:      * Get a RandomAccessFile for accessing a file in read-write mode.
1:6d4d95d:      * @param file the file to access
1:6d4d95d:      * @return a RandomAccessFile
1:6d4d95d:      * @throws FileNotFoundException if {@code file} cannot be opened in
1:6d4d95d:      * read-write mode
1:4f7eee8:      * @throws IOException if some other I/O error happens
1:6d4d95d:      */
1:6d4d95d:     private RandomAccessFile getRandomAccessFile(final File file)
1:4f7eee8:             throws IOException {
1:6d4d95d:         try {
1:7e7a589:             return AccessController.doPrivileged(
1:7e7a589:                 new PrivilegedExceptionAction<RandomAccessFile>() {
1:4f7eee8:                     public RandomAccessFile run() throws IOException {
1:6d4d95d:                         boolean preExisting = file.exists();
1:6d4d95d:                         RandomAccessFile raf = new RandomAccessFile(file, "rw");
1:6d4d95d:                         if (!preExisting) {
1:6d4d95d:                             FileUtil.limitAccessToOwner(file);
1:6d4d95d:                         }
1:6d4d95d:                         return raf;
1:6d4d95d:                     }
2:6d4d95d:                 });
1:6d4d95d:         } catch (PrivilegedActionException pae) {
1:4f7eee8:             throw (IOException) pae.getCause();
1:6d4d95d:         }
1:6d4d95d:     }
1:6d4d95d: 
1:6d4d95d:     synchronized StorageRandomAccessFile getRandomAccessFile(StorageFile file)
1:eac0369:         throws SecurityException, StandardException
1:25f99f5:     {
1:e910eee:         actionCode = GET_RANDOM_ACCESS_FILE_ACTION;
1:e910eee:         actionFile = file;
1:e910eee:         try
1:79d6448:         {
1:e910eee:             return (StorageRandomAccessFile)AccessController.doPrivileged(this);
1:6d4d95d:         }
1:e910eee:         catch( PrivilegedActionException pae){ 
1:e910eee:             throw (StandardException) pae.getException();
1:6d4d95d:         }
1:e910eee:         finally{ actionFile = null; }
1:bf643fd:     }
1:e910eee: 
1:e910eee: 
1:ae71c74: 
1:eac0369:      // PrivilegedExceptionAction method
1:3c7c740:     public Object run() throws StandardException
1:eac0369:      {
1:eac0369:          switch( actionCode)
1:eac0369:          {
1:eac0369:          case GET_FILE_NAME_ACTION:
1:eac0369:              return privGetFileName( actionIdentity, actionStub, actionErrorOK, actionTryAlternatePath);
1:ae71c74: 
1:eac0369:          case CREATE_CONTAINER_ACTION:
1:eac0369:          {
1:eac0369:              StorageFile file = privGetFileName( actionIdentity, false, false, false);
1:ae71c74: 
1:25f99f5:              try {
1:eac0369:                  if (file.exists()) {
1:eac0369:                      // note I'm left in the no-identity state as fillInIdentity()
1:eac0369:                      // hasn't been called.
1:eac0369:                      throw StandardException.newException( SQLState.FILE_EXISTS, file);
1:25f99f5:                  }
4:eac0369:              } catch (SecurityException se) {
2:eac0369:                  throw StandardException.newException( SQLState.FILE_CREATE, se, file);
1:25f99f5:              }
1:eac0369: 
1:25f99f5:              try {
1:eac0369: 
1:b7f22c3:                  // OK not to force WAL here, in fact, this operation
1:b7f22c3:                  // preceeds the creation of the log record to ensure
1:b7f22c3:                  // sufficient space.
1:eac0369: 
1:b7f22c3:                  dataFactory.writeInProgress();
1:b7f22c3:                  try
1:eac0369:                      {
1:6e61723:                          fileData = file.getRandomAccessFile( "rw");
1:dc43cf8:                          file.limitAccessToOwner();
1:25f99f5:                      }
1:b7f22c3:                  finally
1:6e61723:                      {
1:6e61723:                          dataFactory.writeFinished();
1:25f99f5:                      }
1:eac0369: 
1:b7f22c3:                  // This container format specifies that the first page is
1:b7f22c3:                  // an allocation page and the container information is
1:b7f22c3:                  // stored within it.  The allocation page needs to be
1:b7f22c3:                  // somewhat formatted because if the system crashed after
1:b7f22c3:                  // the create container log operation is written, it needs
1:b7f22c3:                  // to be well formed enough to get the container
1:b7f22c3:                  // information back out of it.
1:b7f22c3:                  //
1:30c9f82:                  // Don't try to go thru the page cache here because the
1:b7f22c3:                  // container object cannot be found in the container cache
1:b7f22c3:                  // at this point yet.  However, if we use the page cache
1:b7f22c3:                  // to store the first allocation page, then in order to
1:b7f22c3:                  // write itself out, it needs to ask the container to do
1:b7f22c3:                  // so, which is going to create a deadlock.  The
1:b7f22c3:                  // allocation page cannot write itself out without going
1:b7f22c3:                  // thru the container because it doesn't know where its
1:b7f22c3:                  // offset is.  Here we effectively hardwire page 0 at
1:b7f22c3:                  // offset 0 of the container file to be the first
1:b7f22c3:                  // allocation page.
1:6e61723: 
1:30c9f82:                  // create an embryonic page - if this is not a temporary
1:30c9f82:                  // container, synchronously write out the file header.
1:eac0369: 
1:b7f22c3:                  canUpdate = true; // Need to set it now. After writeRAFHeader
1:b7f22c3:                                    // may be too late in case that method's IO
1:b7f22c3:                                    // is interrupted and container needs
1:b7f22c3:                                    // reopening. To get the correct "rw" mode
1:b7f22c3:                                    // we need canUpdate to be true.
1:eac0369: 
1:30c9f82:                  writeRAFHeader(
1:30c9f82:                      actionIdentity, fileData, true,
1:30c9f82:                      (actionIdentity.getSegmentId() !=
1:30c9f82:                       ContainerHandle.TEMPORARY_SEGMENT));
1:6e61723: 
1:25f99f5:              } catch (IOException ioe) {
1:eac0369: 
1:b7f22c3:                  canUpdate = false;
1:eac0369: 
1:b7f22c3:                  boolean fileDeleted;
1:b7f22c3:                  try {
1:b7f22c3:                      fileDeleted = privRemoveFile(file);
1:b7f22c3:                  } catch (SecurityException se) {
1:25f99f5:                      throw StandardException.newException(
1:b7f22c3:                          SQLState.FILE_CREATE_NO_CLEANUP,
1:b7f22c3:                          ioe,
1:b7f22c3:                          file,
1:b7f22c3:                          se.toString());
1:25f99f5:                  }
1:b7f22c3: 
1:b7f22c3:                  if (!fileDeleted) {
1:b7f22c3:                      throw StandardException.newException(
1:b7f22c3:                          SQLState.FILE_CREATE_NO_CLEANUP,
1:b7f22c3:                          ioe,
1:b7f22c3:                          file,
1:b7f22c3:                          ioe.toString());
1:25f99f5:                  }
1:b7f22c3: 
1:b7f22c3:                  throw StandardException.newException(
1:b7f22c3:                      SQLState.FILE_CREATE, ioe, file);
1:25f99f5:              }
1:6e61723: 
1:eac0369:              return null;
1:eac0369:          } // end of case CREATE_CONTAINER_ACTION
1:eac0369: 
1:eac0369:          case REMOVE_FILE_ACTION:
1:eac0369:              return privRemoveFile( actionFile) ? this : null;
1:eac0369: 
1:eac0369:          case OPEN_CONTAINER_ACTION:
1:eac0369:          {
1:eac0369:              boolean isStub = false;	// is this a stub?
1:eac0369: 
1:eac0369:              StorageFile file = privGetFileName( actionIdentity, false, true, true);
1:eac0369:              if (file == null)
1:eac0369:                  return null;
1:eac0369: 
1:b7f22c3:              try {
1:eac0369:                  if (!file.exists()) {
1:eac0369: 
1:eac0369:                      // file does not exist, may be it has been stubbified
1:eac0369:                      file = privGetFileName( actionIdentity, true, true, true);
1:eac0369:                      if (!file.exists())
1:eac0369:                          return null;
1:25f99f5:                      isStub = true;
1:89a6625:                  }
1:6e61723:              } catch (SecurityException se) {
1:6e61723:                  throw StandardException.newException(
1:eac0369:                      SQLState.DATA_UNEXPECTED_EXCEPTION, se);
1:b7f22c3:              }
1:eac0369: 
1:eac0369:              canUpdate = false;
1:08b4ed5:              try {
1:eac0369:                  if (!dataFactory.isReadOnly() && file.canWrite())
2:eac0369:                      canUpdate = true;
1:eac0369:              } catch (SecurityException se) {
1:eac0369:                  // just means we can't write to it.
1:6e61723:              }
1:26c2de4:              fileName = file.toString();
1:eac0369: 
2:6e61723:              try {
1:eac0369: 
1:eac0369:                  fileData = file.getRandomAccessFile(canUpdate ? "rw" : "r");
1:01a4f9b: 
1:b44572f:                  readHeader(getEmbryonicPage(fileData,
1:b44572f:                                              FIRST_ALLOC_PAGE_OFFSET));
1:08b4ed5:                  
1:eac0369:                  if (SanityManager.DEBUG)
1:eac0369:                  {
1:eac0369:                      if (isStub)
1:eac0369:                          SanityManager.ASSERT(getDroppedState() && getCommittedDropState(),
1:eac0369:                                               "a stub failed to set drop state");
1:6e61723:                  }
1:01a4f9b: 
1:25f99f5:              } catch (IOException ioe) {
1:eac0369: 
1:eac0369:                  if (isStub)
1:eac0369:                  {
1:75fb1cf:                      throw dataFactory.
1:75fb1cf:                          markCorrupt(StandardException.
1:75fb1cf:                                      newException(SQLState.
1:26c2de4:                                              FILE_CONTAINER_EXCEPTION, ioe,
1:26c2de4:                                              getIdentity() != null ?
1:26c2de4:                                                  getIdentity().toString() :
1:26c2de4:                                                  "unknown",
1:26c2de4:                                              "read", fileName));
1:6e61723:                  }
1:eac0369: 
1:eac0369:                  // maybe it is being stubbified... try that
1:f9f4d94:                  StorageFile stub = 
1:f9f4d94:                      privGetFileName(actionIdentity, true, true, true);
1:f9f4d94: 
1:eac0369:                  if (stub.exists())
1:eac0369:                  {
1:eac0369:                      try
1:eac0369:                      {
1:f9f4d94:                          boolean delete_status = privRemoveFile(file);
1:eac0369:                          if (SanityManager.DEBUG)
1:f9f4d94:                          {
1:f9f4d94:                              if (!delete_status)
1:f9f4d94:                              {
1:a2f90d4:                                  SanityManager.THROWASSERT(
1:f9f4d94:                                      "delete of file (" + file + ") failed.");
1:f9f4d94:                              }
1:f9f4d94:                          }
1:eac0369: 
1:f9f4d94:                          fileData = 
1:f9f4d94:                              stub.getRandomAccessFile(canUpdate ? "rw" : "r");
1:eac0369: 
1:b44572f:                          readHeader(getEmbryonicPage(fileData,
1:b44572f:                                                      FIRST_ALLOC_PAGE_OFFSET));
1:6e61723:                      }
1:eac0369:                      catch (IOException ioe2)
1:eac0369:                      {
1:75fb1cf:                          throw dataFactory.
1:75fb1cf:                              markCorrupt(StandardException.
1:75fb1cf:                                          newException(SQLState.
1:75fb1cf:                                                       FILE_CONTAINER_EXCEPTION,
1:26c2de4:                                              ioe2,
1:26c2de4:                                              getIdentity() != null ?
1:26c2de4:                                                  getIdentity().toString() :
1:26c2de4:                                                  "unknown",
1:26c2de4:                                              "delete-stub", fileName));
1:01a4f9b:                      }
1:eac0369: 
1:eac0369:                      // RESOLVE: this is a temporary hack
1:eac0369: 
1:e910eee:                  }
1:eac0369:                  else
1:75fb1cf:                      throw dataFactory.
1:75fb1cf:                          markCorrupt(StandardException.
1:75fb1cf:                                      newException(SQLState.
1:26c2de4:                                                   FILE_CONTAINER_EXCEPTION, ioe,
1:26c2de4:                                              getIdentity() != null ?
1:26c2de4:                                                  getIdentity().toString() :
1:26c2de4:                                                  "unknown",
1:26c2de4:                                              "read", fileName));
1:ae71c74:              }
1:eac0369: 
1:eac0369:              return this;
1:eac0369:          } // end of case OPEN_CONTAINER_ACTION
1:08b4ed5:          case REOPEN_CONTAINER_ACTION:
1:08b4ed5:          {
1:08b4ed5:              StorageFile file =
1:08b4ed5:                  privGetFileName( actionIdentity, false, true, true);
1:08b4ed5: 
2:25f99f5:              synchronized (this) {
1:08b4ed5:                  try {
1:08b4ed5:                      fileData =
1:08b4ed5:                          file.getRandomAccessFile(canUpdate ? "rw" : "r");
1:08b4ed5:                  } catch (FileNotFoundException ioe) {
1:08b4ed5:                      throw dataFactory.
1:08b4ed5:                          markCorrupt(
1:08b4ed5:                              StandardException.newException(
1:08b4ed5:                                  SQLState.FILE_CONTAINER_EXCEPTION,
1:08b4ed5:                                  ioe,
1:08b4ed5:                                  (getIdentity() != null ?
1:08b4ed5:                                   getIdentity().toString() :
1:08b4ed5:                                   "unknown"),
1:08b4ed5:                                  "read",
1:08b4ed5:                                  fileName));
1:08b4ed5:                  }
1:08b4ed5:              }
1:08b4ed5: 
1:08b4ed5:              return this;
1:08b4ed5:          }
1:79d6448: 
1:eac0369:          case STUBBIFY_ACTION:
1:eac0369:          {
1:eac0369:              StorageFile file = privGetFileName( actionIdentity, false, false, true);
1:eac0369:              StorageFile stub = privGetFileName( actionIdentity, true, false, false);
1:ae71c74: 
1:eac0369:              StorageRandomAccessFile stubData = null;
1:eac0369: 
1:eac0369:              try
1:eac0369:              {
1:eac0369:                  // !!!!!
1:eac0369:                  // bumpContainerVersion();
1:eac0369:                  //
1:eac0369:                  // do NOT bump the container version.  We WANT the stubbify
1:eac0369:                  // operation to get redone every time.  This is because this
1:eac0369:                  // operation first writes out the stub and then remove the
1:eac0369:                  // container file.  If we bump the version, then the stub will
1:eac0369:                  // contain the new version.  And if the system crashes right then,
1:eac0369:                  // then we will skip the whole operation during redo even though
1:eac0369:                  // the container file may not have been removed.  Since we don't
1:eac0369:                  // want to have the remove happen before the stub is written, we
1:eac0369:                  // cannot sync it and therefore cannot be sure the remove
1:eac0369:                  // happened before the system crashed.
1:eac0369: 
1:eac0369:                  if (!stub.exists())
1:eac0369:                  {
1:eac0369:                      // write the header to the stub
1:eac0369:                      stubData = stub.getRandomAccessFile( "rw");
1:dc43cf8:                      stub.limitAccessToOwner();
1:eac0369: 
1:30c9f82:                      writeRAFHeader(
1:30c9f82:                         actionIdentity,
1:30c9f82:                         stubData,
1:eac0369:                                     true, /* create */
1:eac0369:                                     true); /* sync */
1:eac0369: 
1:eac0369:                      stubData.close();
1:eac0369:                      stubData = null;
1:79d6448:                  }
1:eac0369: 
1:eac0369: 
1:eac0369:                  // Force WAL and check for database corruption before removing file.
1:eac0369:                  // This is one operation where the container is changed on disk
1:eac0369:                  // directly without going thru the container cache, which otherwise
1:eac0369:                  // would have force WAL.  Take care of it here.
1:eac0369:                  dataFactory.flush(actionInstant);
1:eac0369: 
1:eac0369:                  // try to remove the container file
1:eac0369:                  // fileDate is not null only if we are redoing a removeContainer
1:eac0369:                  // (stubbify) operation.  Then fileData acutally is opened against
1:eac0369:                  // the stub and the original container file does not exist.
1:eac0369:                  // Then we need to close it here because this method is called by
1:eac0369:                  // cache.remove and nobody will be able to see fileData after this.
2:eac0369:                  privRemoveFile(file);
1:eac0369: 
1:79d6448:              }
1:eac0369:              catch (SecurityException se)
1:eac0369:              {
1:75fb1cf:                  throw StandardException.
1:75fb1cf:                      newException(SQLState.FILE_CANNOT_REMOVE_FILE, se, file, 
1:6e61723:                                   se.toString());
1:ae71c74:              }
1:eac0369:              catch (IOException ioe)
1:eac0369:              {
1:eac0369:                  // exception thrown while in creating the stub.  Remove the
1:eac0369:                  // (half-baked) stub
1:eac0369:                  try
1:eac0369:                  {
1:eac0369:                      if (stubData != null)
1:eac0369:                      {
1:eac0369:                          stubData.close();
1:eac0369:                          stub.delete();
1:eac0369:                          stubData = null;
1:ae71c74:                      }
1:eac0369: 
1:eac0369:                      if (fileData != null)
1:eac0369:                      {
1:eac0369:                          fileData.close();
1:eac0369:                          fileData = null;
1:ae71c74:                      }
1:eac0369:                  }
1:eac0369:                  catch (IOException ioe2)
1:eac0369:                  {
1:6e61723:                      throw StandardException.newException(
1:75fb1cf:                          SQLState.FILE_CANNOT_REMOVE_FILE, ioe2, file, ioe.toString());
1:eac0369:                  }
1:eac0369:                  catch (SecurityException se)
1:eac0369:                  {
1:6e61723:                      throw StandardException.newException(
1:d976a70:                          SQLState.FILE_CANNOT_REMOVE_FILE, se, file, se.toString());
1:eac0369:                  }
1:eac0369:              }
1:eac0369: 	
1:eac0369:              //let the data factory know about this the stub file;It
1:eac0369:              // could  remove when next checkpoint occurs if it's not necessary for recovery
1:eac0369:              dataFactory.stubFileToRemoveAfterCheckPoint(stub,actionInstant, getIdentity());
1:25f99f5:              return null;
1:eac0369:          } // end of case STUBBIFY_ACTION
1:25f99f5: 
1:e910eee:          case GET_RANDOM_ACCESS_FILE_ACTION: {
1:3c7c740:              try
1:3c7c740:              {
1:dc43cf8:                  boolean exists = actionFile.exists();
1:dc43cf8:                  Object result = actionFile.getRandomAccessFile("rw");
1:dc43cf8: 
1:dc43cf8:                  if (!exists) {
1:dc43cf8:                      actionFile.limitAccessToOwner();
1:3c7c740:                  }
1:dc43cf8: 
1:dc43cf8:                  return result;
1:3c7c740:              }
1:4f7eee8:              catch (IOException ioe)
1:eac0369:              {
1:3c7c740:                  throw StandardException.newException(
1:4f7eee8:                      SQLState.FILE_CREATE, ioe, actionFile.getPath());
1:dc43cf8:              }
1:25f99f5: 		 } // end of case BACKUP_CONTAINER_ACTION
1:25f99f5: 
1:e910eee: 		 
1:25f99f5: 		 } // end of switch
1:eac0369:          return null;
1:25f99f5: 
1:eac0369:      } // end of run
1:eac0369: }
============================================================================
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:bb5be6f
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         PrivilegedAction<Boolean> pa = () ->
1:                 FileUtil.copyFile(dataFactory.getStorageFactory(), from, to);
1:         boolean success = AccessController.doPrivileged(pa);
1:         if (!success) {
/////////////////////////////////////////////////////////////////////////
1:         PrivilegedAction<Boolean> pa = () -> !file.exists() || file.delete();
1:         boolean success = AccessController.doPrivileged(pa);
1:         if (!success) {
commit:4f7eee8
/////////////////////////////////////////////////////////////////////////
1:                         try {
1:                             directory.limitAccessToOwner();
1:                         } catch (IOException ioe) {
1:                             if (errorOK) {
1:                                 return null;
1:                             } else {
1:                                 throw StandardException.newException(
1:                                         SQLState.FILE_CANNOT_CREATE_SEGMENT,
1:                                         ioe, directory);
1:                             }
1:                         }
/////////////////////////////////////////////////////////////////////////
1:      * @throws IOException if some other I/O error happens
1:             throws IOException {
1:                     public RandomAccessFile run() throws IOException {
/////////////////////////////////////////////////////////////////////////
1:             throw (IOException) pae.getCause();
/////////////////////////////////////////////////////////////////////////
1:              catch (IOException ioe)
1:                      SQLState.FILE_CREATE, ioe, actionFile.getPath());
commit:6d4d95d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.util.ReuseFactory;
/////////////////////////////////////////////////////////////////////////
1: import java.security.PrivilegedAction;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Copy the contents of a {@code StorageFile} to a {@code java.io.File}.
1:      *
1:      * @param from the file to copy from
1:      * @param to the file to copy to
1:      * @throws StandardException if the copying failed
1:      */
1:     private void copyFile(final StorageFile from, final File to)
1:             throws StandardException {
0:         Boolean success = (Boolean) AccessController.doPrivileged(
0:                 new PrivilegedAction() {
0:                     public Object run() {
0:                         return ReuseFactory.getBoolean(FileUtil.copyFile(
0:                                 dataFactory.getStorageFactory(), from, to));
1:                     }
1:                 });
1: 
0:         if (!success.booleanValue()) {
1:             throw StandardException.newException(
1:                     SQLState.RAWSTORE_ERROR_COPYING_FILE,
1:                     from, to);
1:         }
1:     }
1: 
1:     /**
1:      * Remove a file.
1:      * @param file the file to remove
1:      * @throws StandardException if the file could not be removed
1:      */
1:     private void removeFile(final File file) throws StandardException {
0:         Boolean success = (Boolean) AccessController.doPrivileged(
0:             new PrivilegedAction() {
0:                 public Object run() {
0:                     return ReuseFactory.getBoolean(
0:                             !file.exists() || file.delete());
1:                 }
1:         });
1: 
0:         if (!success.booleanValue()) {
1:             throw StandardException.newException(
1:                     SQLState.UNABLE_TO_DELETE_FILE, file);
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     protected void backupContainer(BaseContainerHandle handle,
1:                                    String backupLocation)
/////////////////////////////////////////////////////////////////////////
1:                     StorageFile file = getFileName((ContainerKey)getIdentity(),
1:                     copyFile(file, backupFile);
/////////////////////////////////////////////////////////////////////////
1:                         getFileName(
1:                     backupRaf  = getRandomAccessFile(backupFile);
/////////////////////////////////////////////////////////////////////////
1:                     removeFile(backupFile);
/////////////////////////////////////////////////////////////////////////
1:             newRaf = getRandomAccessFile(newFile);
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Get a RandomAccessFile for accessing a file in read-write mode.
1:      * @param file the file to access
1:      * @return a RandomAccessFile
1:      * @throws FileNotFoundException if {@code file} cannot be opened in
1:      * read-write mode
1:      */
1:     private RandomAccessFile getRandomAccessFile(final File file)
0:             throws FileNotFoundException {
1:         try {
0:             return (RandomAccessFile) AccessController.doPrivileged(
0:                 new PrivilegedExceptionAction() {
0:                     public Object run() throws FileNotFoundException {
1:                         boolean preExisting = file.exists();
1:                         RandomAccessFile raf = new RandomAccessFile(file, "rw");
1:                         if (!preExisting) {
1:                             FileUtil.limitAccessToOwner(file);
1:                         }
1:                         return raf;
1:                     }
0:                 });
1:         } catch (PrivilegedActionException pae) {
0:             throw (FileNotFoundException) pae.getCause();
1:         }
1:     }
1:     synchronized StorageRandomAccessFile getRandomAccessFile(StorageFile file)
/////////////////////////////////////////////////////////////////////////
commit:c6ca304
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:3c7c740
/////////////////////////////////////////////////////////////////////////
1: import java.io.FileNotFoundException;
/////////////////////////////////////////////////////////////////////////
1:     public Object run() throws StandardException
/////////////////////////////////////////////////////////////////////////
1:              try
1:              {
0:                  return actionFile.getRandomAccessFile("rw");
1:              }
0:              catch (FileNotFoundException fnfe)
1:              {
1:                  throw StandardException.newException(
0:                      SQLState.FILE_CREATE, fnfe, actionFile.getPath());
1:              }
commit:9b54b81
/////////////////////////////////////////////////////////////////////////
1: 
1:             // Allocating AllocPage.MAX_BORROWED_SPACE bytes for the
1:             // embryonic page should be enough, but we want to leave
1:             // the end of the file at a page boundary. This is to work
1:             // around bugs in the EPOC jvm where a seek beyond the end
1:             // of a file does not throw an exception but just moves
1:             // the offset to the end of the file. This only occurs
1:             // when the second page is written after the header has
1:             // been written, ending up with the page at the incorrect
1:             // offset.
1: 
1:             epage = new byte[pageSize];
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:b44572f
/////////////////////////////////////////////////////////////////////////
1: 			epage = getEmbryonicPage(file, FIRST_ALLOC_PAGE_OFFSET);
/////////////////////////////////////////////////////////////////////////
1:                  readHeader(getEmbryonicPage(fileData,
1:                                              FIRST_ALLOC_PAGE_OFFSET));
/////////////////////////////////////////////////////////////////////////
1:                          readHeader(getEmbryonicPage(fileData,
1:                                                      FIRST_ALLOC_PAGE_OFFSET));
commit:1318511
/////////////////////////////////////////////////////////////////////////
1: 	/**
commit:f0cd4bf
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 		synchronized (this) {
1: 			fileData.seek(pageOffset);
1: 
1: 			fileData.readFully(pageData, 0, pageSize);
commit:55a6cdc
/////////////////////////////////////////////////////////////////////////
1: 	void closeContainer() {
/////////////////////////////////////////////////////////////////////////
1:     protected byte[] updatePageArray(long pageNumber, 
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.sanity.SanityManager;
commit:26c2de4
/////////////////////////////////////////////////////////////////////////
1:         private String fileName;
/////////////////////////////////////////////////////////////////////////
1:                             SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:                             getIdentity() != null ?
1:                                getIdentity().toString() : "unknown",
1:                             "clean", fileName));
/////////////////////////////////////////////////////////////////////////
1:                                     SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:                                     getIdentity() != null ?
1:                                         getIdentity().toString() : "unknown",
0:                                     "encrypt", newFilePath);
/////////////////////////////////////////////////////////////////////////
1:                                     SQLState.FILE_CONTAINER_EXCEPTION, ioe,
1:                                     getIdentity() != null ?
1:                                         getIdentity().toString() : "unknown",
0:                                     "encrypt-close", newFilePath);
/////////////////////////////////////////////////////////////////////////
1:              fileName = file.toString();
/////////////////////////////////////////////////////////////////////////
1:                                              FILE_CONTAINER_EXCEPTION, ioe,
1:                                              getIdentity() != null ?
1:                                                  getIdentity().toString() :
1:                                                  "unknown",
1:                                              "read", fileName));
/////////////////////////////////////////////////////////////////////////
1:                                              ioe2,
1:                                              getIdentity() != null ?
1:                                                  getIdentity().toString() :
1:                                                  "unknown",
1:                                              "delete-stub", fileName));
/////////////////////////////////////////////////////////////////////////
1:                                                   FILE_CONTAINER_EXCEPTION, ioe,
1:                                              getIdentity() != null ?
1:                                                  getIdentity().toString() :
1:                                                  "unknown",
1:                                              "read", fileName));
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:7e7a589
/////////////////////////////////////////////////////////////////////////
1: class RAFContainer extends FileContainer implements PrivilegedExceptionAction<Object>
/////////////////////////////////////////////////////////////////////////
0:         Boolean success = AccessController.doPrivileged(
0:                 new PrivilegedAction<Boolean>() {
0:                     public Boolean run() {
/////////////////////////////////////////////////////////////////////////
0:         Boolean success = AccessController.doPrivileged(
0:             new PrivilegedAction<Boolean>() {
0:                 public Boolean run() {
/////////////////////////////////////////////////////////////////////////
1:             return AccessController.doPrivileged(
1:                 new PrivilegedExceptionAction<RandomAccessFile>() {
0:                     public RandomAccessFile run() throws FileNotFoundException {
commit:270a34d
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:d976a70
/////////////////////////////////////////////////////////////////////////
1:                          SQLState.FILE_CANNOT_REMOVE_FILE, se, file, se.toString());
commit:30c9f82
/////////////////////////////////////////////////////////////////////////
1:             writeHeader(getIdentity(), pageData);
/////////////////////////////////////////////////////////////////////////
1:                     writeRAFHeader(
1:                         getIdentity(),
1:                         fileData,
/////////////////////////////////////////////////////////////////////////
1:     private void writeRAFHeader(
1:     Object                  identity,
1:     StorageRandomAccessFile file, 
1:     boolean                 create, 
/////////////////////////////////////////////////////////////////////////
1:         writeHeader(identity, file, create, epage);
/////////////////////////////////////////////////////////////////////////
1:                         byte[] dataToWrite = 
1:                             updatePageArray(
1:                                 pageNumber, 
1:                                 encryptionBuf, 
1:                                 false);
/////////////////////////////////////////////////////////////////////////
0:                  // allocation page and the container information is stored 
0:                  // within it.  The allocation page needs to be somewhat 
0:                  // formatted because if the system crashed after the create 
0:                  // container log operation is written, it needs to be well 
0:                  // formed enough to get the container information back out of
0:                  // it.
1:                  // Don't try to go thru the page cache here because the 
0:                  // container object cannot be found in the container cache at
0:                  // this point yet.  However, if we use the page cache to store
0:                  // the first allocation page, then in order to write itself 
0:                  // out, it needs to ask the container to do so, which is going
0:                  // to create a deadlock.  The allocation page cannot write 
0:                  // itself out without going thru the container because it 
0:                  // doesn't know where its offset is.  Here we effectively 
0:                  // hardwire page 0 at offset 0 of the container file to be 
0:                  // the first allocation page.
1:                  // create an embryonic page - if this is not a temporary 
1:                  // container, synchronously write out the file header.
1:                  writeRAFHeader(
1:                      actionIdentity, fileData, true, 
1:                      (actionIdentity.getSegmentId() != 
1:                           ContainerHandle.TEMPORARY_SEGMENT));
/////////////////////////////////////////////////////////////////////////
1:                      writeRAFHeader(
1:                         actionIdentity,
1:                         stubData,
commit:0a625f3
/////////////////////////////////////////////////////////////////////////
1:             {
1:                 // committed and dropped, do nothing.
1:                 // This file container may only be a stub
1: 				return;
1:             }
1: 
1:             ///////////////////////////////////////////////////
1:             //
1:             // RESOLVE: right now, no logical -> physical mapping.
1:             // We can calculate the offset.  In the future, we may need to
1:             // look at the allocation page or the in memory translation table
1:             // to figure out where the page should go
1:             //
1:             /////////////////////////////////////////////////
1:             byte [] encryptionBuf = null; 
1:             if (dataFactory.databaseEncrypted() 
1:                 && pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1:             {
1:                 // We cannot encrypt the page in place because pageData is
1:                 // still being accessed as clear text.  The encryption
1:                 // buffer is shared by all who access this container and can
1:                 // only be used within the synchronized block.
1: 
1:                 encryptionBuf = getEncryptionBuffer();
1:             }
1: 
1:             byte[] dataToWrite = 
1:                 updatePageArray(pageNumber, pageData, encryptionBuf, false);
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                 {
1: 					SanityManager.ASSERT(
1:                         fileData.length() >= pageOffset,
1:                         "failed to blank filled missing pages");
1:                 }
1: 
1: 					fileData.write(dataToWrite, 0, pageSize);
/////////////////////////////////////////////////////////////////////////
1:             if (SanityManager.DEBUG) 
1:             {
/////////////////////////////////////////////////////////////////////////
1:         } 
1:         else 
1:             {
1:             } 
1:             else
1:             {
1:             }
commit:d59cfb4
/////////////////////////////////////////////////////////////////////////
1:      * @param forRemove Is clean called because container is being removed?
commit:f57b07d
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Clean the container.
1:      * <p>
1:      * Write out the container header and sync all dirty pages of this
1:      * container to disk before returning.
1:      * <p>
1:      * checkpoint calls this interface through callbacks by telling
1:      * the cache manager to clean all containers in the open container
1:      * cache.  This sync of the file happens as part of writing and then
1:      * syncing the container header in writeRAFHeader().
1:      * <p>
1:      *
0:      * @param boolean Is clean called because container is being removed?
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
commit:6700e19
/////////////////////////////////////////////////////////////////////////
1:                     if (lastPageNumber == ContainerHandle.INVALID_PAGE_NUMBER) {
1:                         // last page number is invalid if there are no pages in
1:                         // the container yet. No need to backup this container, 
1:                         // this container creation is yet to complete.The reason
1:                         // backup is getting called on such a container is 
1:                         // because container handle appears in the cache after 
1:                         // the file is created on the disk but before it's 
1:                         // first page is allocated. 
1:                         return;
1:                     }
1: 
1:                     StorageFile file = 
0:                         privGetFileName(
1:                             (ContainerKey)getIdentity(), false, false, true);
1: 
1:                     backupFile = new File(backupLocation , file.getName());
0:                     backupRaf  = new RandomAccessFile(backupFile,  "rw");
1:                         // page instead of encryption buffer used by the regular
1:                         // conatiner writes. Otherwise writes to the backup 
1:                     // copy all the pages of the container from the database 
1:                     // to the backup location by reading through the page cache.
commit:bf643fd
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 byte [] encryptionBuf = null; 
0:                 if (dataFactory.databaseEncrypted() 
1: 
0:                     encryptionBuf = getEncryptionBuffer();
1:                 }
1: 
1: 				byte[] dataToWrite = updatePageArray(pageNumber, 
0:                                                      pageData, 
0:                                                      encryptionBuf);
/////////////////////////////////////////////////////////////////////////
1:     /**
0:      * Update the page array with container header if the page is a first alloc
0:      * page and encrypt the page data if the database is encrypted.  
1:      * @param pageNumber the page number of the page
1:      * @param pageData  byte array that has the actual page data.
0:      * @param encryptionBuf buffer that is used to store encryted version of the
0:      * page.
1:      * @return byte array of the the page data as it should be on the disk.
1:      */
0:     private byte[] updatePageArray(long pageNumber, 
1:                                    byte[] pageData, 
0:                                    byte[] encryptionBuf) 
1:         throws StandardException, IOException
1:     {
1:         if (pageNumber == FIRST_ALLOC_PAGE_NUMBER)
1:         {
1:             // write header into the alloc page array regardless of dirty
1:             // bit because the alloc page have zero'ed out the borrowed
1:             // space
0:             writeHeader(pageData);
1: 
1:             if (SanityManager.DEBUG) {
1:                 if (FormatIdUtil.readFormatIdInteger(pageData) != AllocPage.FORMAT_NUMBER)
1:                     SanityManager.THROWASSERT(
1:                             "expect " +
1:                             AllocPage.FORMAT_NUMBER +
1:                             "got " +
1:                             FormatIdUtil.readFormatIdInteger(pageData));
1:             }
1: 
1:             return pageData;
1: 
0:         } else 
1:         {
0:             if (dataFactory.databaseEncrypted()) 
1:            {
0:                 return encryptPage(pageData, pageSize, encryptionBuf);
0:             } else
1:                 return pageData;
1:         }
1:     }
1: 
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Backup the  container.
1:      * 
1:      * @param handle the container handle.
1:      * @param backupLocation location of the backup container. 
0:      * @exception StandardException Standard Derby error policy 
1:      */
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
0:      * Backup the  container.
1:      *
1:      * The container is written to the backup by reading  the pages
1:      * through the page cache, and then writing into the backup container.
1:      * If the container is dropped(commitetd drop), only container stub is
1:      * copied to the  backup using simple file copy. 
1:      * 
1:      * MT - 
1:      * At any given time only one backup thread is allowed, but when backup in 
1:      * progress DML/DDL operations can run in parallel. Pages are latched while 
1:      * writing them to the backup to avoid copying partial changes to the pages.
1:      * Online backup does not acquire any user level locks , so users can drop
1:      * tables when backup is in progress. So it is possible that Container 
1:      * Removal request can come in when container backup is in progress.  
1: 	 * and using inRemove and inBackup flags. Conatiner removal checks if backup
1:      * is in progress and wait for the backup to yield to continue the removal. 
1:      * Basic idea is to give preference to remove by stopping the backup of the 
1:      * container temporarily,  when the remove container is requested by another 
1:      * thread. Generally, it takes more  time to backup a regular container than 
1:      * the stub becuase  stub is just one page. After each page copy, a check is
1:      * made to find  if a remove is requested and if it is then backup of the 
1:      * container is aborted and the backup thread puts itself into the wait state until
1: 	 * remove request compeletes stub is copied into the backup.
1:      * Compress is blocked when backup is in progesss, so truncation of the
1:      * container can not happen when backup is in progess. No need to
1:      * synchronize backup of the container with truncation. 
1:      * 
1:      * 
0:      * @param handle the container handle.
0:      * @param backupLocation location of the backup container. 
1:      * @exception StandardException Derby Standard error policy
1:      *
1:      */
0:     private void privBackupContainer(BaseContainerHandle handle,	
0:                                      String backupLocation)
1:         throws StandardException 
1:     {
1:         boolean backupCompleted = false;
1:         File backupFile = null;
1:         RandomAccessFile backupRaf = null;
1:         boolean isStub = false;
1:         BasePage page = null; 
1:         while(!backupCompleted) {
1:             try {
1:                 synchronized (this) {
1:                     // wait if some one is removing the 
1:                     // container because of a drop.
1:                     while (inRemove)
1:                     {
1:                         try	{
1:                             wait();
1:                         }
1:                         catch (InterruptedException ie)
1:                         {
0:                             throw StandardException.interrupt(ie);
1:                         }	
1:                     }
1: 
1:                     if (getCommittedDropState())
1:                         isStub = true;
1:                     inBackup = true;
1:                 }
1:                 // create container at the backup location.
1:                 if (isStub) {
1:                     // get the stub ( it is a committted drop table container )
0:                     StorageFile file = privGetFileName((ContainerKey)getIdentity(), 
1:                                                        true, false, true);
1:                     backupFile = new File(backupLocation, file.getName());
0: 					if(!FileUtil.copyFile(dataFactory.getStorageFactory(), 
0:                                           file, backupFile))
1:                     {
1:                         throw StandardException.newException(
0:                                               SQLState.RAWSTORE_ERROR_COPYING_FILE,
0:                                               file, backupFile);
1:                     }
1:                 }else {
1:                     // regular container file 
0:                     StorageFile file = privGetFileName((ContainerKey)getIdentity(), 
0:                                                        false, false, true);
0:                     backupFile = new File(backupLocation , file.getName());
0:                     backupRaf = new RandomAccessFile(backupFile,  "rw");
0: 					// copy all the pages of the container from the database 
0:                     // to the backup location by reading through the page cache.
1:                     
1:                     long lastPageNumber= getLastPageNumber(handle);
1:                     byte[] encryptionBuf = null;
1:                     if (dataFactory.databaseEncrypted()) {
1:                         // Backup uses seperate encryption buffer to encrypt the
0:                         // page instead of encryption buffer used by the regular conatiner
0:                         // writes. Otherwise writes to the backup 
1:                         // has to be synchronized with regualar database writes
1:                         // because backup can run in parallel to container
1:                         // writes.
1:                         encryptionBuf = new byte[pageSize];
1:                     }
1: 
1:                     for (long pageNumber = FIRST_ALLOC_PAGE_NUMBER; 
1:                          pageNumber <= lastPageNumber; pageNumber++) {
0:                         page = getPageForBackup(handle, pageNumber);
1:                         
1:                         // update the page array before writing to the disk 
1:                         // with container header and encrypt it if the database 
1:                         // is encrypted. 
1:                         
0:                         byte[] dataToWrite = updatePageArray(pageNumber, 
1:                                                              page.getPageArray(), 
0:                                                              encryptionBuf);
1:                         backupRaf.write(dataToWrite, 0, pageSize);
1: 
1:                         // unlatch releases page from cache, see 
1:                         // StoredPage.releaseExclusive()
1:                         page.unlatch();
1:                         page = null;
1: 
1:                         // check if some one wants to commit drop the table while
1:                         // conatiner is being written to the backup. If so,
1:                         // abort  the backup and restart it once the drop 
1:                         // is complete.
1: 								break; 
1: 
1:                 // sync and close the backup conatiner. Incase of a stub, 
1:                 // it is already synced and closed while doing the copy.
1:                 if(!isStub) {
1:                     backupRaf.getFD().sync();
1:                     backupRaf.close();
1:                     backupRaf = null;
1:                 }
1:                 
1:                 // backup of the conatiner is complete. 
1:                 backupCompleted = true;
1: 
1:             }catch (IOException ioe) {
1:                 throw StandardException.newException(
1:                                                 SQLState.BACKUP_FILE_IO_ERROR, 
1:                                                 ioe, 
1:                                                 backupFile);
1:             } finally {
1:                 synchronized (this) {
1:                     inBackup = false;
1:                     notifyAll();
1:                 }
1: 
1:                 if (page != null) {
1:                     page.unlatch();
1:                     page = null;
1:                 }
1: 
1:                 // if backup of container is not complete, close the file
1:                 // handles and  remove the container file from the backup 
1:                 // if it exists
1:                 if (!backupCompleted && backupFile != null) 
1:                 {
1:                     if (backupRaf != null) 
1:                     {
1:                             backupRaf.close();
1:                             backupRaf = null;
1:                         } catch (IOException ioe){
1:                             throw StandardException.newException(
1:                                             SQLState.BACKUP_FILE_IO_ERROR, 
1:                                             ioe, 
1:                                             backupFile);
1:                         }
1:                     }
0:                     if(backupFile.exists()) 
1:                     {
0:                         if (!backupFile.delete())
1:                             throw StandardException.newException(
0:                                                 SQLState.UNABLE_TO_DELETE_FILE, 
1:                                                 backupFile);
1:                     }
1:                 } 
1:             }
1:         }
1:     }
commit:9008ade
/////////////////////////////////////////////////////////////////////////
0: 				// couldn't construct the lock, fall back to old behaviour
1: 
0: 				hasJava5FairLocks = false;
/////////////////////////////////////////////////////////////////////////
0: 				// Something bad happened while trying to lock the
0: 				// region. Since the locking is not required for
0: 				// anything other than ensuring fairness, it is ok to
0: 				// fall back to pre-1.5 behaviour.
0: 				hasJava5FairLocks = false;
/////////////////////////////////////////////////////////////////////////
0: 					// An error occurred while unlocking the
0: 					// region. The region might still be locked, so
0: 					// we'd better stop using this kind of
0: 					// locking. There will be no loss of
0: 					// functionality, only a possible loss of
0: 					// fairness.
0: 					hasJava5FairLocks = false;
commit:a2f90d4
/////////////////////////////////////////////////////////////////////////
0: import java.lang.reflect.Method;
0: import java.lang.reflect.Constructor;
/////////////////////////////////////////////////////////////////////////
0: 	/* Fields with references to classes and methods in ReentrantLock
0: 	 * introduced in Java 1.5. Reflection is used to only use these
0:      * interfaces if they exist.
1:      * 
1:      */
0: 	private static Class fairLockClass;
0: 	private static Constructor fairLockConstructor;
0: 	private static Method lock;
0: 	private static Method unlock;
0: 	private static boolean hasJava5FairLocks = false;
1: 
0: 	// Use reflection to find the constructor, lock() and unlock() in
0: 	// java.util.concurrent.locks.ReentrantLock. If the class and its
0: 	// methods are found, hasJava5FairLocks will be true and fair
0: 	// locking can be used.
0: 	static {
1: 		try {
0: 			fairLockClass = 
0:                 Class.forName("java.util.concurrent.locks.ReentrantLock");
1: 
0: 			fairLockConstructor = 
0:                 fairLockClass.getConstructor(new Class[] { Boolean.TYPE });
1: 
0: 			lock   = fairLockClass.getMethod("lock",   new Class[0]);
0: 			unlock = fairLockClass.getMethod("unlock", new Class[0]);
0: 			hasJava5FairLocks = true;
1: 		}
0: 		catch (NoSuchMethodException nsme) {}
0: 		catch (ClassNotFoundException cnfe) {}
1: 	}
1: 
1: 	/**
0: 	 * Object of type java.util.concurrent.locks.ReentrantLock. It is
0: 	 * used to prevent starvation when many threads are reading from
0: 	 * the same file.
1: 	 */
0: 	private Object fairLock;
/////////////////////////////////////////////////////////////////////////
1: 
0: 		// If Java 1.5 fair locks are available, construct one.
0: 		if (hasJava5FairLocks) {
1: 			try {
0: 				// construct a lock with fairness set to true
0: 				fairLock = 
0:                     fairLockConstructor.newInstance(
0:                         new Object[] { Boolean.TRUE });
0: 			} catch (Exception e) {
1: 				if (SanityManager.DEBUG) {
1: 					SanityManager.THROWASSERT(
0:                         "failed constructing ReentrantLock", e);
1: 				}
1: 			}
1: 		}
/////////////////////////////////////////////////////////////////////////
0: 		// Use Java 1.5 fair locks if they are available.
0: 		if (hasJava5FairLocks) {
1: 			try {
0: 				lock.invoke(fairLock, null);
0: 			} catch (Exception e) {
0: 				if (SanityManager.DEBUG) {
0: 					SanityManager.THROWASSERT(
0:                         "failed invoking ReentrantLock.lock()", e);
1: 				}
1: 			}
1: 		}
1: 		try {
0: 			// Starvation might occur at this point if many threads
0: 			// are waiting for the monitor. This section is therefore
0: 			// surrounded by calls to ReentrantLock.lock()/unlock() if
0: 			// we are running Java 1.5 or higher.
1: 			synchronized (this) {
1: 				fileData.seek(pageOffset);
0: 				fileData.readFully(pageData, 0, pageSize);
1: 			}
1: 		} finally {
0: 			// Unlock this section.
0: 			if (hasJava5FairLocks) {
1: 				try {
0: 					unlock.invoke(fairLock, null);
0: 				} catch (Exception e) {
0: 					if (SanityManager.DEBUG) {
0: 						SanityManager.THROWASSERT(
0:                             "failed invoking ReentrantLock.unlock()", e);
1: 					}
1: 				}
1: 			}
commit:f9f4d94
/////////////////////////////////////////////////////////////////////////
1:             if (file.exists())
/////////////////////////////////////////////////////////////////////////
1:                  StorageFile stub = 
1:                      privGetFileName(actionIdentity, true, true, true);
1: 
1:                          boolean delete_status = privRemoveFile(file);
1:                          {
1:                              if (!delete_status)
1:                              {
0:                                  SanityManager.THROWASSERT(
1:                                      "delete of file (" + file + ") failed.");
1:                              }
1:                          }
1:                          fileData = 
1:                              stub.getRandomAccessFile(canUpdate ? "rw" : "r");
commit:7739ad6
/////////////////////////////////////////////////////////////////////////
0:                           "expect " +
0:                           AllocPage.FORMAT_NUMBER +
0:                           "got " +
0:                           FormatIdUtil.readFormatIdInteger(pageData));
/////////////////////////////////////////////////////////////////////////
0: 			backupRaf.seek(pageOffset);
commit:25f99f5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.services.io.FileUtil;
1: import java.io.File;
1: import java.io.RandomAccessFile;
/////////////////////////////////////////////////////////////////////////
0: 	private static final int BACKUP_CONTAINER_ACTION = 6;
0: 	private String actionBackupLocation;
0: 	private BaseContainerHandle actionContainerHandle;
1: 
1: 	private boolean inBackup = false;
1: 	private boolean inRemove = false;
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 		try {
1: 			synchronized(this)
1: 			{
1: 				inRemove = true;
1: 				// wait until the thread that is doing the backup stops 
1: 				// before proceeding with the remove.
1: 				while(inBackup)
1: 				{
1: 					try	{
1: 						wait();
1: 					}
1: 					catch (InterruptedException ie)
1: 					{
0: 						throw StandardException.interrupt(ie);
1: 					}	
1: 				}
1: 			}
1: 
1: 		}finally
1: 		{	
1: 			synchronized(this) {
1: 				inRemove = false;
1: 				notifyAll();
1: 			}
1: 		}
/////////////////////////////////////////////////////////////////////////
0: 			// wait until the thread that is doing the backup completes it
0: 			// before truncting the container. 
0: 			while(inBackup)
1: 			{
0: 				try	{
1: 					wait();
1: 				}
1: 				catch (InterruptedException ie)
1: 				{
0: 					throw StandardException.interrupt(ie);
1: 				}	
1: 			}
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 		
1: 	/**
0: 	   backup the  container.
0: 	   @exception StandardException Standard Cloudscape error policy 
1: 	*/
0: 	protected void backupContainer(BaseContainerHandle handle,	String backupLocation)
1: 	    throws StandardException 
1: 	{
0: 		actionContainerHandle = handle;
0:         actionBackupLocation = backupLocation;
0:         actionCode = BACKUP_CONTAINER_ACTION;
1:         try
1:         {
1:             AccessController.doPrivileged(this);
1:         }
1:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:         finally
1:         {
0:             actionContainerHandle = null;
0:             actionBackupLocation = null;
1:         }
1: 	}
1: 
1: 	/**
0: 	 * Backup the  container.
1: 	 *
0: 	 * The container is backed up by reading all the pages through the page cache,
0: 	 * and then writing to the backup container if it not a committed drop
0: 	 * container. If the container is commited dropped one, stub is copied
0: 	 * to the backup using simple file copy. 
1: 	 *
0: 	 * MT scenarios:
0: 	 * 1) Remove and backup running in parallel thread:
0: 	 * The trickey case is if a request to remove the container(because of a
0: 	 * commited drop) comes when the conatiner backup is in progress. 
1: 	 * This case is handled by using the synchronization on this object monitor 
0: 	 * and using inRemove and inBackup flags.  Basic idea is to give 
0: 	 * preference to remove by stopping the backup of the container temporarily,
0: 	 * when  the remove container is requested by another thread. Generally,  it takes
0: 	 * more  time to backup a regular container than the stub becuase 
0: 	 * stub is just one page. After each page copy, a check is made to find 
0: 	 * if a remove is requested and if it is then backup of the container is
0: 	 * aborted and the backup thread puts itself into the wait state until
1: 	 * remove  request thread notifies that the remove is complete. When 
0: 	 * remove request compeletes stub is copies into the backup.
1: 	 * 
0: 	 * 2) Truncate and backup running in parallel:
0: 	 * Truncate will wait if the backup is in progress. Truncate does not
0: 	 * release the montitor until it is complete , backup can not start 
0: 	 * until it acquires, so if truncate is running, it has to release
0: 	 * the monitor before backup can proceed.
1: 	 * 
0:  	 * @exception StandardException Standard Cloudscape error policy 
1: 	*/
0: 	private void privBackupContainer(BaseContainerHandle handle,	String backupLocation)
1: 	    throws StandardException 
1: 	{
0: 		boolean done = true;
0: 		File backupFile = null;
0: 		RandomAccessFile backupRaf = null;
0: 		boolean isStub = false;
0: 		do {
1: 			try {
1: 
1: 				synchronized (this) {
0: 					// wait if some one is removing the container because of a drop.
0: 					while (inRemove)
1: 					{
0: 						try	{
0: 							wait();
1: 						}
0: 						catch (InterruptedException ie)
1: 						{
0: 							throw StandardException.interrupt(ie);
1: 						}	
1: 					}
1: 
1: 					if (getCommittedDropState())
1: 						isStub = true;
0: 					inBackup = true;
1: 				}
1: 			
0: 				// create container at the backup location.
0: 				if (isStub) {
0: 					// get the stub ( it is a committted drop table container )
0: 					StorageFile file = privGetFileName((ContainerKey)getIdentity(), true, false, true);
0: 					backupFile = new File(backupLocation, file.getName());
1: 
1: 					// directly copy the stub to the backup 
0: 					if(!FileUtil.copyFile(dataFactory.getStorageFactory(), file, backupFile))
1: 					{
0: 						throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,
0: 															 file, backupFile);
1: 					}
1: 				} else {
0: 					// regular container file 
0: 					StorageFile file = privGetFileName((ContainerKey)getIdentity(), false, false, true);
0: 					try{
0: 						backupFile = new File(backupLocation , file.getName());
0: 						backupRaf = new RandomAccessFile(backupFile,  "rw");
1: 					} catch (IOException ioe) {
0: 						throw StandardException.newException( SQLState.FILE_CREATE, ioe, backupFile);
1: 					}
1: 
0: 					// copy all the pages of the container from the database to the
0: 					// backup location by reading through the pahe cache.
1: 				
1: 					long lastPageNumber= getLastPageNumber(handle);
1: 					for (long pageNumber = FIRST_ALLOC_PAGE_NUMBER; 
0: 						 pageNumber <= lastPageNumber; pageNumber++) {
0: 						BasePage page = getPageForBackup(handle, pageNumber);
0: 						byte[] pageData = page.getPageArray();
0: 						writeToBackup(backupRaf, pageNumber, pageData);
0: 						// unlatch releases page from cache, see StoredPage.releaseExclusive()
1: 						page.unlatch();
1: 
0: 						// check if some one wants to commit drop the table while
0: 						// being backedup. If so, abort the backup and restart it 
0: 						// once the drop is complete.
1: 
1: 						synchronized (this)
1: 						{
1: 							if (inRemove) {
0: 								done = false;
0: 								break;
1: 							}
1: 						}
1: 					}
1: 				}	
1: 			} finally {
1: 				synchronized (this) {
0: 					inBackup = false;
0: 					notifyAll();
1: 				}
1: 			
0: 				// if backup of container is not complete, remove the container
0: 				// from the backup.
0: 				if (!done && backupFile != null) {
0: 					if (backupRaf != null) {
1: 						try {
0: 							backupRaf.close();
0: 							backupRaf = null;
0: 						} catch (IOException ioe){};
1: 					
1: 					}
0: 					if(backupFile.exists())
0: 						if (!backupFile.delete())
0: 							throw StandardException.newException(SQLState.UNABLE_TO_DELETE_FILE, 
0: 																 backupFile);
1: 				} else {
0: 					// close the backup conatiner.
0: 					// incase of a stub, it is already closed 
0: 					// while doing the copy.
0: 					if(!isStub) {
0: 						if (backupRaf != null) {
1: 							try {
0: 								backupRaf.getFD().sync();
0: 								backupRaf.close();
1: 							} catch (IOException ioe) {
1: 							} finally {
0: 								backupRaf = null;
1: 							}
1: 						}	
1: 					}
1: 				}
1: 			}
1: 	
0: 		} while (!done);
1: 	}
1: 
1: 
0: 	// write the page to the backup location.
0: 	private  void writeToBackup(RandomAccessFile backupRaf, long pageNumber, byte[] pageData) 
1: 		throws StandardException
1: 	{
0: 		byte[] dataToWrite;
1: 		
1: 		try {
0: 			if (pageNumber == FIRST_ALLOC_PAGE_NUMBER)
1: 			{
0: 				// write header into the alloc page array regardless of dirty
0: 				// bit because the alloc page have zero'ed out the borrowed
0: 				// space
0: 				writeHeader(pageData);
1: 
0: 				if (SanityManager.DEBUG) {
0: 					if (FormatIdUtil.readFormatIdInteger(pageData) != AllocPage.FORMAT_NUMBER)
0: 						SanityManager.THROWASSERT(
0: 												  "expect " +
0: 												  AllocPage.FORMAT_NUMBER +
0: 												  "got " +
0: 												  FormatIdUtil.readFormatIdInteger(pageData));
1: 				}
1: 
1: 			}
1: 
0: 			if (dataFactory.databaseEncrypted() 
0: 				&& pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1: 			{
0: 				// We cannot encrypt the page in place because pageData is
0: 				// still being accessed as clear text.  The encryption
0: 				// buffer is shared by all who access this container and can
0: 				// only be used within the synchronized block.
0: 				dataToWrite = encryptPage(pageData, pageSize);
1: 			} else {
0: 				dataToWrite = pageData;
1: 			}
1: 			
1: 			long pageOffset = pageNumber * pageSize;
1: 			fileData.seek(pageOffset);
0: 			backupRaf.write(dataToWrite, 0, pageSize);
1: 
1: 		} catch (IOException ioe) {
0: 			// page cannot be written to the backup
1: 			throw StandardException.newException(
0:                     SQLState.FILE_WRITE_PAGE_EXCEPTION, 
0:                     ioe, getIdentity() + ":" + pageNumber);
1: 		}
1: 	}
1: 	
1: 
/////////////////////////////////////////////////////////////////////////
1: 		 
0: 		 case BACKUP_CONTAINER_ACTION: {
0: 			 privBackupContainer(actionContainerHandle, actionBackupLocation);
1: 			 return null;
1: 		 } // end of case BACKUP_CONTAINER_ACTION
1: 		 
1: 		 } // end of switch
1: 
commit:3108420
/////////////////////////////////////////////////////////////////////////
1:                     if (!dataFactory.dataNotSyncedAtAllocation)
/////////////////////////////////////////////////////////////////////////
1:                     if (!dataFactory.dataNotSyncedAtAllocation)
0:                         fileData.sync(false);
1:   				}
/////////////////////////////////////////////////////////////////////////
1:                 if (!dataFactory.dataNotSyncedAtCheckpoint)
0:                    file.sync(false);
1: 
commit:06dbbcf
/////////////////////////////////////////////////////////////////////////
1:         throws StandardException
1: 
commit:20bc69f
/////////////////////////////////////////////////////////////////////////
1:      * Truncate pages of a container.
1:      * Truncate all pages from lastValidPagenum+1 through the end of the file.
1:      * @param lastValidPagenum  The page number of the last valid page of the
1:      *                          file.  All pages after this one are truncated.
commit:bbc927c
/////////////////////////////////////////////////////////////////////////
1:     /**
0:      * Short one line description of routine.
1:      * <p>
0:      * Longer descrption of routine.
1:      * <p>
1:      *
0: 	 * @return The identifier to be used to open the conglomerate later.
1:      *
0:      * @param param1 param1 does this.
0:      * @param param2 param2 does this.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	protected void truncatePages(
1:     long lastValidPagenum)
1: 	{  
0: 		// int n = doTruncatePages(lastValidPagenum); 
1: 
1:         synchronized(this)
1:         {
1:             boolean inwrite = false;
1:             try
1:             {
1:                 dataFactory.writeInProgress();
1:                 inwrite = true;
1: 
1:                 fileData.setLength((lastValidPagenum + 1) * pageSize);
1:             }
1:             catch (IOException ioe)
1:             {
1:                 // The disk may have run out of space. 
1:                 // Don't error out in un-allocation since application can
1:                 // still function even if allocation fails.
1:             }
1:             catch (StandardException se)
1:             {
1:                 // some problem calling writeInProgress
1:             }
1:             finally
1:             {
1:                 if (inwrite)
1:                     dataFactory.writeFinished();
1:             }
1:         }
1: 
1: 		return;
1: 	}
1: 
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:d203eea
/////////////////////////////////////////////////////////////////////////
1:      * Updates the page array with container header if the page is a first
1:      * allocation page and encrypts the page data if the database is encrypted.
0:      *
1:      * @param encryptionBuf buffer that is used to store encrypted version of
1:      *      the page, or {@code null} if encryption is to be skipped
1:      * @param encryptWithNewEngine whether to use the new encryption engine for
1:      *      encryption (only considered if {@code encryptionBuf != null})
/////////////////////////////////////////////////////////////////////////
1:             if (encryptionBuf != null &&
1:                     (dataFactory.databaseEncrypted() || encryptWithNewEngine))
/////////////////////////////////////////////////////////////////////////
1:      * through the page cache, then either encrypts page data with the new
1:      * encryption mechanism or leaves the page data un-encrypted, and finally
1:      * writes the data to the specified new container file.
1:      * accessed via the data factory. Note that the pages have already been
1:      * decrypted before being put into the page cache.
1:      * @param doEncrypt tells whether to encrypt or not
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             if (doEncrypt) {
1:                 encryptionBuf = new byte[pageSize];
1:             }
1:             // Copy all the pages from the current container to the new
1:             // container file after processing the pages.
1:                 // Update the page array before writing to the disk.
1:                 // An update consists of adding the container header, or
1:                 // (re-)encrypting the data.
/////////////////////////////////////////////////////////////////////////
1:                                     doEncrypt ? "encrypt" : "decrypt",
1:                                     newFilePath);
/////////////////////////////////////////////////////////////////////////
1:                                     doEncrypt ?
1:                                         "encrypt-close" : "decrypt-close",
1:                                     newFilePath);
commit:89a6625
/////////////////////////////////////////////////////////////////////////
1:      * Creates encrypted or decrypted version of the container.
1:      * Reads all the pages of the container from the original container
0:      * through the page cache, then either encrypts each page data with the new
0:      * encryption mechanism or decrypts the page data, and finally writes the
0:      * data to the specified new container file.
1:      * <p>
1:      * The encryption and decryption engines used to carry out the
1:      * cryptographic operation(s) are configured through the raw store, and
0:      * accessed via the data factory.
0:      *
1:      * @param handle the container handle
1:      * @param newFilePath file to store the new version of the container in
0:      * @param doEncrypt tells whether to encrypt or decrypt
1:     protected void encryptOrDecryptContainer(BaseContainerHandle handle,
1:                                              String newFilePath,
1:                                              boolean doEncrypt)
0:         // TEMPORARY FOR DERBY-5792
0:         if (!doEncrypt) {
0:             throw new UnsupportedOperationException("not yet implemented");
1:         }
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:abf8151
/////////////////////////////////////////////////////////////////////////
1:         int maxTries = InterruptStatus.MAX_INTERRUPT_RETRIES;
/////////////////////////////////////////////////////////////////////////
1:                                 Thread.sleep(
1:                                     InterruptStatus.INTERRUPT_RETRY_SLEEP);
commit:dc43cf8
/////////////////////////////////////////////////////////////////////////
1: 
0:                         directory.limitAccessToOwner();
/////////////////////////////////////////////////////////////////////////
0:                     FileUtil.limitAccessToOwner(backupFile);
/////////////////////////////////////////////////////////////////////////
1:                          file.limitAccessToOwner();
/////////////////////////////////////////////////////////////////////////
1:                      stub.limitAccessToOwner();
/////////////////////////////////////////////////////////////////////////
1:                  boolean exists = actionFile.exists();
1:                  Object result = actionFile.getRandomAccessFile("rw");
1: 
1:                  if (!exists) {
1:                      actionFile.limitAccessToOwner();
1:                  }
1: 
1:                  return result;
commit:b7f22c3
/////////////////////////////////////////////////////////////////////////
1:              try {
1:                  // OK not to force WAL here, in fact, this operation
1:                  // preceeds the creation of the log record to ensure
1:                  // sufficient space.
1:                  dataFactory.writeInProgress();
1:                  try
1:                  finally
1:                  // This container format specifies that the first page is
1:                  // an allocation page and the container information is
1:                  // stored within it.  The allocation page needs to be
1:                  // somewhat formatted because if the system crashed after
1:                  // the create container log operation is written, it needs
1:                  // to be well formed enough to get the container
1:                  // information back out of it.
1:                  //
0:                  // Don't try to go thru the page cache here because the
1:                  // container object cannot be found in the container cache
1:                  // at this point yet.  However, if we use the page cache
1:                  // to store the first allocation page, then in order to
1:                  // write itself out, it needs to ask the container to do
1:                  // so, which is going to create a deadlock.  The
1:                  // allocation page cannot write itself out without going
1:                  // thru the container because it doesn't know where its
1:                  // offset is.  Here we effectively hardwire page 0 at
1:                  // offset 0 of the container file to be the first
1:                  // allocation page.
0:                  // create an embryonic page - if this is not a temporary
0:                  // container, synchronously write out the file header.
1:                  canUpdate = true; // Need to set it now. After writeRAFHeader
1:                                    // may be too late in case that method's IO
1:                                    // is interrupted and container needs
1:                                    // reopening. To get the correct "rw" mode
1:                                    // we need canUpdate to be true.
0:                  writeRAFHeader(
0:                      actionIdentity, fileData, true,
0:                      (actionIdentity.getSegmentId() !=
0:                       ContainerHandle.TEMPORARY_SEGMENT));
1:              } catch (IOException ioe) {
1:                  canUpdate = false;
1:                  boolean fileDeleted;
1:                  try {
1:                      fileDeleted = privRemoveFile(file);
1:                  } catch (SecurityException se) {
1:                          SQLState.FILE_CREATE_NO_CLEANUP,
1:                          ioe,
1:                          file,
1:                          se.toString());
1: 
1:                  if (!fileDeleted) {
1:                      throw StandardException.newException(
1:                          SQLState.FILE_CREATE_NO_CLEANUP,
1:                          ioe,
1:                          file,
1:                          ioe.toString());
1:                  }
1: 
1:                  throw StandardException.newException(
1:                      SQLState.FILE_CREATE, ioe, file);
commit:08b4ed5
/////////////////////////////////////////////////////////////////////////
1:     private static final int REOPEN_CONTAINER_ACTION = 8;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             return AccessController.doPrivileged( this) != null;
1:         catch( PrivilegedActionException pae) {
/////////////////////////////////////////////////////////////////////////
1:             actionIdentity = null;
1:         }
1:     }
1:     /**
1:      * Only used by RAFContainer4 (NIO) to reopen RAF when its channel gets
1:      * closed due to interrupts.
0:      *
1:      * @param currentIdentity
1:      * @throws StandardException standard exception policy
1:      */
1:     protected synchronized void reopenContainer(ContainerKey currentIdentity)
1:             throws StandardException {
1: 
1:         actionCode = REOPEN_CONTAINER_ACTION;
1:         actionIdentity = currentIdentity;
1: 
1:         try {
0:             AccessController.doPrivileged(this);
1:         } catch (PrivilegedActionException pae) {
1:             closeContainer();
1:             throw (StandardException) pae.getException();
1:         } catch (RuntimeException e) {
1:             closeContainer();
1:             throw e;
0:         } finally {
1:             actionIdentity = null;
/////////////////////////////////////////////////////////////////////////
0:                  readHeader(getEmbryonicPage(fileData,
0:                                              FIRST_ALLOC_PAGE_OFFSET));
1:                  
/////////////////////////////////////////////////////////////////////////
1:          case REOPEN_CONTAINER_ACTION:
1:          {
1:              StorageFile file =
1:                  privGetFileName( actionIdentity, false, true, true);
1: 
0:              synchronized (this) {
1:                  try {
1:                      fileData =
1:                          file.getRandomAccessFile(canUpdate ? "rw" : "r");
1:                  } catch (FileNotFoundException ioe) {
1:                      throw dataFactory.
1:                          markCorrupt(
1:                              StandardException.newException(
1:                                  SQLState.FILE_CONTAINER_EXCEPTION,
1:                                  ioe,
1:                                  (getIdentity() != null ?
1:                                   getIdentity().toString() :
1:                                   "unknown"),
1:                                  "read",
1:                                  fileName));
1:                  }
1:              }
1: 
1:              return this;
1:          }
commit:6e61723
/////////////////////////////////////////////////////////////////////////
1:              boolean success = false;
0:              int maxTries = MAX_INTERRUPT_RETRIES;
1:              while (!success) {
1:                  success = true;
1:                  try {
0:                      // OK not to force WAL here, in fact, this operation
0:                      // preceeds the creation of the log record to ensure
0:                      // sufficient space.
1:                      dataFactory.writeInProgress();
1:                      try
1:                      {
1:                          fileData = file.getRandomAccessFile( "rw");
1:                      }
1:                      finally
1:                      {
1:                          dataFactory.writeFinished();
1:                      }
0:                      // This container format specifies that the first page is
0:                      // an allocation page and the container information is
0:                      // stored within it.  The allocation page needs to be
0:                      // somewhat formatted because if the system crashed after
0:                      // the create container log operation is written, it needs
0:                      // to be well formed enough to get the container
0:                      // information back out of it.
1:                      //
0:                      // Don't try to go thru the page cache here because the
0:                      // container object cannot be found in the container cache
0:                      // at this point yet.  However, if we use the page cache
0:                      // to store the first allocation page, then in order to
0:                      // write itself out, it needs to ask the container to do
0:                      // so, which is going to create a deadlock.  The
0:                      // allocation page cannot write itself out without going
0:                      // thru the container because it doesn't know where its
0:                      // offset is.  Here we effectively hardwire page 0 at
0:                      // offset 0 of the container file to be the first
0:                      // allocation page.
1: 
0:                      // create an embryonic page - if this is not a temporary
0:                      // container, synchronously write out the file header.
0:                      writeRAFHeader(
0:                          actionIdentity, fileData, true,
0:                          (actionIdentity.getSegmentId() !=
0:                  } catch (IOException ioe) {
0:                      Class clazz = ioe.getClass();
0:                      // test with reflection since NIO is not in Foundation 1.1
0:                      if (clazz.getName().equals(
0:                              "java.nio.channels.ClosedByInterruptException") ||
0:                          clazz.getName().equals( // Java NIO Bug 6979009:
0:                              "java.nio.channels.AsynchronousCloseException")) {
1:                          if (--maxTries > 0) {
1:                              success = false;
1:                              InterruptStatus.setInterrupted();
1:                              closeContainer();
0:                              continue;
1:                          }
1:                      }
0:                      boolean fileDeleted;
1:                      try {
0:                          fileDeleted = privRemoveFile(file);
1:                      } catch (SecurityException se) {
1:                          throw StandardException.newException(
0:                              SQLState.FILE_CREATE_NO_CLEANUP,
0:                              ioe,
0:                              file,
1:                              se.toString());
1:                      }
1: 
0:                      if (!fileDeleted) {
1:                          throw StandardException.newException(
0:                              SQLState.FILE_CREATE_NO_CLEANUP,
0:                              ioe,
0:                              file,
0:                              ioe.toString());
1:                      }
1: 
1:                      throw StandardException.newException(
0:                          SQLState.FILE_CREATE, ioe, file);
commit:5d97422
/////////////////////////////////////////////////////////////////////////
0:                                 Thread.sleep(INTERRUPT_RETRY_SLEEP);
commit:a552fe6
/////////////////////////////////////////////////////////////////////////
1:                         fileData.sync();
/////////////////////////////////////////////////////////////////////////
1:                         fileData.sync();
/////////////////////////////////////////////////////////////////////////
1:                    file.sync();
/////////////////////////////////////////////////////////////////////////
1:             newRaf.sync();
commit:01a4f9b
/////////////////////////////////////////////////////////////////////////
0:     private boolean reopen;
/////////////////////////////////////////////////////////////////////////
1:             throws StandardException {
0:         return openContainerMinion(newIdentity, false);
1:     }
1: 
0:     synchronized boolean reopenContainer(ContainerKey newIdentity)
1:             throws StandardException {
0:         return openContainerMinion(newIdentity, true);
1:     }
1: 
0:     private boolean openContainerMinion(
0:         ContainerKey newIdentity,
0:         boolean doReopen) throws StandardException
0:         reopen = doReopen;
/////////////////////////////////////////////////////////////////////////
1: 
0:                  if (!reopen) {
0:                      // under reopen: can give race condition or if we
0:                      // synchronize access, deadlock, so skip, we know
0:                      // what's there anyway.
0:                      readHeader(getEmbryonicPage(fileData,
0:                                                  FIRST_ALLOC_PAGE_OFFSET));
1:                  }
1: 
commit:bd018fd
/////////////////////////////////////////////////////////////////////////
0:     protected ContainerKey idAPriori = null;
1: 
1:     synchronized boolean openContainer(ContainerKey newIdentity)
0:         boolean success = false;
0:         idAPriori = currentIdentity;
1: 
0:             currentIdentity = newIdentity;
0:             // NIO: We need to set currentIdentity before we try to open, in
0:             // case we need its value to perform a recovery in the case of an
0:             // interrupt during readEmbryonicPage as part of
0:             // OPEN_CONTAINER_ACTION.  Note that this gives a recursive call to
0:             // openContainer.
1:             //
0:             // If we don't succeed in opening, we reset currentIdentity to its
0:             // a priori value.
0:             success = AccessController.doPrivileged(this) != null;
0:             idAPriori = currentIdentity;
/////////////////////////////////////////////////////////////////////////
1:         {
0:             if (!success) {
0:                 currentIdentity = idAPriori;
1:             }
1: 
commit:bb8f25a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.util.InterruptStatus;
1: import org.apache.derby.iapi.util.InterruptDetectedException;
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
0:      * Identity of this container. Make it visible to RAFContainer4, which may
0:      * need to reopen the container after interrupts due to a NIO channel being
0:      * closed by the interrupt.
1:      */
0:     protected ContainerKey currentIdentity;
1: 
/////////////////////////////////////////////////////////////////////////
1:                         InterruptStatus.setInterrupted();
/////////////////////////////////////////////////////////////////////////
1:         // If interrupt recovery is in progress (NIO), we must expect to
1:         // release our monitor on "this" and to retry writeRAFHeader, so be
1:         // prepared to retry.
0:         boolean success = false;
0:         int maxTries = MAX_INTERRUPT_RETRIES; // ca 60s = (120 * 0.5s)
0:         while (!success) {
0:             success = true;
0:             synchronized (this) {
1:                 // committed and dropped, do nothing.
1:                 // This file container has already been stubbified
1:                 if (getCommittedDropState()) {
1:                     clearDirty();
1:                     return;
1:                 }
1: 
1:                 // The container is about to change, need to wait till it is
1:                 // really changed.  We are in the predirty state only for the
1:                 // duration where the log record that changed the container has
1:                 // been sent to the log and before the change actually
1:                 // happened.
1:                 while(preDirty == true)
1:                 {
1:                     waited = true;
1:                     try
1:                     {
0:                         wait();
1:                     }
0:                     catch (InterruptedException ie)
1:                     {
1:                         InterruptStatus.setInterrupted();
1:                     }
1:                 }
1: 
1:                 if (waited)
1:                 {
1:                     // someone else may have stubbified this while we waited
1:                     if (getCommittedDropState())
1:                     {
1:                         clearDirty();
1:                         return;
1:                     }
1:                 }
1:                 if (forRemove) {
1:                     //              removeFile()
1:                     //              clearDirty();
1:                 } else if (isDirty()) {
0:                     try {
1:                         // Cannot get the alloc page and write it out because
1:                         // in order to do so, the alloc page will need to find
1:                         // this container object.  But this container object is
1:                         // in the middle of being cleaned and may not be
1:                         // 'found' and we will hang.
1:                         //
1:                         // Instead, just clobber the container info, which is
1:                         // checksum'ed seperately from the alloc page
1:                         //
0:                         writeRAFHeader(
0:                             getIdentity(),
0:                             fileData,
1:                             false,  // don't create, container exists
1:                             true);  // syncfile
1:                         clearDirty();
1:                     } catch (InterruptDetectedException e) {
0:                         if (--maxTries > 0) {
0:                             success = false;
1: 
1:                             // Wait a bit so recovery can take place before
1:                             // we re-grab monitor on "this" (which recovery
1:                             // needs) and retry writeRAFHeader.
0:                             try {
0:                                 Thread.sleep(500); // 0.5s
1:                             } catch (InterruptedException ee) {
1:                                 // This thread received an interrupt as
1:                                 // well, make a note.
1:                                 InterruptStatus.setInterrupted();
1:                             }
1: 
1:                             continue; // retry write of RAFHeader
0:                         } else {
1:                             // We have tried for a minute, not sure what's
1:                             // going on, so to be on safe side we can't
1:                             // continue
1:                             throw StandardException.newException(
1:                                 SQLState.FILE_IO_INTERRUPTED, e);
1:                         }
0:                     } catch (IOException ioe) {
1: 
1:                         throw dataFactory.markCorrupt(
1:                             StandardException.newException(
0:                                 SQLState.FILE_CONTAINER_EXCEPTION, ioe,
0:                                 getIdentity() != null ?
0:                                 getIdentity().toString() : "unknown",
0:                                 "clean", fileName));
1:                     }
1:                 }
1:             }
1:         }
/////////////////////////////////////////////////////////////////////////
0:             currentIdentity = newIdentity;
/////////////////////////////////////////////////////////////////////////
0:             boolean success = AccessController.doPrivileged(this) != null;
0:             if (success) {
0:                 currentIdentity = newIdentity;
1:             }
1: 
0:             return success;
/////////////////////////////////////////////////////////////////////////
0:                             InterruptStatus.setInterrupted();
author:Myrna van Lunteren
-------------------------------------------------------------------------------
commit:c33b0cf
/////////////////////////////////////////////////////////////////////////
0:         catch( PrivilegedActionException pae) { 
1:             closeContainer();
1:             throw (StandardException) pae.getException();
1:         }
1:         catch (RuntimeException e) {
1:             closeContainer();
1:             throw e;
1:         }
1:         finally
1:         { 
1:             actionIdentity = null; 
1:         }
author:Samuel Andrew McIntyre
-------------------------------------------------------------------------------
commit:94f158a
/////////////////////////////////////////////////////////////////////////
1: 		@exception StandardException Standard Derby error policy
/////////////////////////////////////////////////////////////////////////
1: 		@exception StandardException Standard Derby error policy
/////////////////////////////////////////////////////////////////////////
1: 		@exception StandardException Standard Derby error policy
/////////////////////////////////////////////////////////////////////////
1: 		@exception StandardException Standard Derby error policy
/////////////////////////////////////////////////////////////////////////
0: 		@exception StandardException Standard Derby error policy
/////////////////////////////////////////////////////////////////////////
0: 		@exception StandardException Standard Derby error policy
author:Suresh Thalamati
-------------------------------------------------------------------------------
commit:79d6448
/////////////////////////////////////////////////////////////////////////
1:         StorageRandomAccessFile newRaf = null;
0:             newRaf = privGetRandomAccessFile(newFile);
/////////////////////////////////////////////////////////////////////////
1:             // sync the new version of the container.
0:             newRaf.sync(true);
1:             newRaf = null;
/////////////////////////////////////////////////////////////////////////
1:             
1:             if (newRaf != null) {
0:                 try {
1:                     newRaf.close();
1:                 }catch (IOException ioe) 
1:                 {
1:                     newRaf = null;
1:                     throw StandardException.newException(
0:                                     SQLState.FILE_CONTAINER_EXCEPTION, 
0:                                     ioe, 
0:                                     newFile);
1:                     
1:                 }
1:             }
commit:e910eee
/////////////////////////////////////////////////////////////////////////
1:     private static final int GET_RANDOM_ACCESS_FILE_ACTION = 7;
/////////////////////////////////////////////////////////////////////////
0:             StorageRandomAccessFile newRaf = privGetRandomAccessFile(newFile);
/////////////////////////////////////////////////////////////////////////
0:     synchronized StorageRandomAccessFile privGetRandomAccessFile(StorageFile file)
1:         throws SecurityException, StandardException
1:     {
1:         actionCode = GET_RANDOM_ACCESS_FILE_ACTION;
1:         actionFile = file;
1:         try
1:         {
1:             return (StorageRandomAccessFile)AccessController.doPrivileged(this);
1:         }
1:         catch( PrivilegedActionException pae){ 
1:             throw (StandardException) pae.getException();
1:         }
1:         finally{ actionFile = null; }
1:     }
1: 
1: 
0:     public Object run() throws StandardException, IOException
/////////////////////////////////////////////////////////////////////////
1: 
1:          case GET_RANDOM_ACCESS_FILE_ACTION: {
0:              return actionFile.getRandomAccessFile("rw");
0: 		 } // end of case BACKUP_CONTAINER_ACTION
1: 
author:Satheesh E. Bandaram
-------------------------------------------------------------------------------
commit:ae71c74
/////////////////////////////////////////////////////////////////////////
1:                                                      encryptionBuf, 
0:                                                      false);
/////////////////////////////////////////////////////////////////////////
1:                                    byte[] encryptionBuf, 
1:                                    boolean encryptWithNewEngine) 
/////////////////////////////////////////////////////////////////////////
0:             if (dataFactory.databaseEncrypted() || encryptWithNewEngine) 
1:                 return encryptPage(pageData, 
1:                                    pageSize, 
1:                                    encryptionBuf, 
1:                                    encryptWithNewEngine);
/////////////////////////////////////////////////////////////////////////
1:                         page = getLatchedPage(handle, pageNumber);
/////////////////////////////////////////////////////////////////////////
0:                                                              encryptionBuf, false);
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:     /**
0:      * Create encrypted version of the  container with the 
0:      * user specified encryption properties. 
0:      * 
0:      * Read all the pages of the container from the original container 
0:      * through the page cache, encrypt each page data with new encryption 
0:      * mechanism and  write to the specified container file.
0:      *
0:      * @param handle the container handle.
0:      * @param newFilePath file to store the new encrypted version of 
0:      *                    the container
1:      * @exception StandardException Derby Standard error policy
0:      *
1:      */
0:     protected void encryptContainer(BaseContainerHandle handle, 
0:                                     String newFilePath)	
1:         throws StandardException 
1:     {
1:         BasePage page = null; 
1:         StorageFile newFile = 
1:             dataFactory.getStorageFactory().newStorageFile(newFilePath);
0:         try {
0:             long lastPageNumber= getLastPageNumber(handle);
1:  
0:             StorageRandomAccessFile newRaf = newFile.getRandomAccessFile("rw");
1: 
1:             byte[] encryptionBuf = null;
0:             encryptionBuf = new byte[pageSize];
1: 
0:             // copy all the pages from the current container to the 
0:             // new container file after encryting the pages. 
0:             for (long pageNumber = FIRST_ALLOC_PAGE_NUMBER; 
1:                  pageNumber <= lastPageNumber; pageNumber++) 
1:             {
1: 
1:                 page = getLatchedPage(handle, pageNumber);
1:                         
0:                 // update the page array before writing to the disk 
0:                 // with container header and encrypt it.
1:                         
0:                 byte[] dataToWrite = updatePageArray(pageNumber, 
1:                                                      page.getPageArray(), 
0:                                                      encryptionBuf, 
1:                                                      true);
1:                 newRaf.write(dataToWrite, 0, pageSize);
1: 
1:                 // unlatch releases page from cache.
1:                 page.unlatch();
1:                 page = null;
1:             }
1: 
1:             newRaf.close();
1:             
1:         }catch (IOException ioe) {
0:             throw StandardException.newException(
0:                                     SQLState.FILE_CONTAINER_EXCEPTION, 
0:                                     ioe, 
0:                                     newFile);
0:         } finally {
1: 
1:             if (page != null) {
1:                 page.unlatch();
1:                 page = null;
1:             }
1:         }
1:     }
1: 
1: 
1: 
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
author:David Van Couvering
-------------------------------------------------------------------------------
commit:75fb1cf
/////////////////////////////////////////////////////////////////////////
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, se.toString());
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, ioe.toString());
/////////////////////////////////////////////////////////////////////////
1:                      throw dataFactory.
1:                          markCorrupt(StandardException.
1:                                      newException(SQLState.
1:                                                   FILE_CONTAINER_EXCEPTION, 
0:                                                   ioe, this));
/////////////////////////////////////////////////////////////////////////
1:                          throw dataFactory.
1:                              markCorrupt(StandardException.
1:                                          newException(SQLState.
0:                                                       FILE_CONTAINER_EXCEPTION,
0:                                                       ioe2, this));
1:                      throw dataFactory.
1:                          markCorrupt(StandardException.
1:                                      newException(SQLState.
0:                                                   FILE_CONTAINER_EXCEPTION,
0:                                                   ioe, this));
/////////////////////////////////////////////////////////////////////////
1:                  throw StandardException.
1:                      newException(SQLState.FILE_CANNOT_REMOVE_FILE, se, file, 
0:                                   se.toString());
/////////////////////////////////////////////////////////////////////////
1:                          SQLState.FILE_CANNOT_REMOVE_FILE, ioe2, file, ioe.toString());
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:7a92d1f
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: class RAFContainer extends FileContainer implements PrivilegedExceptionAction
/////////////////////////////////////////////////////////////////////////
1: 	RAFContainer(BaseDataFileFactory factory) {
/////////////////////////////////////////////////////////////////////////
0: 	final void closeContainer() {
/////////////////////////////////////////////////////////////////////////
1: 	 synchronized StorageFile getFileName(ContainerKey identity, boolean stub,
/////////////////////////////////////////////////////////////////////////
1: 	synchronized void createContainer(ContainerKey newIdentity)
/////////////////////////////////////////////////////////////////////////
1: 	synchronized boolean removeFile(StorageFile file)
/////////////////////////////////////////////////////////////////////////
0: 	synchronized boolean openContainer(ContainerKey newIdentity)
/////////////////////////////////////////////////////////////////////////
1: 	private synchronized void stubbify(LogInstant instant)
commit:345de35
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derby.impl.store.raw.data.RAFContainer
1: 
0:    Copyright 1997, 2004 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
commit:c6ad534
/////////////////////////////////////////////////////////////////////////
commit:eac0369
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.store.raw.data
0:    (C) Copyright IBM Corp. 1997, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
1: 
1:  */
1: 
1: package org.apache.derby.impl.store.raw.data;
1: 
1: import org.apache.derby.iapi.reference.SQLState;
0: import org.apache.derby.impl.store.raw.data.BaseContainer;
0: import org.apache.derby.impl.store.raw.data.BaseContainerHandle;
0: import org.apache.derby.impl.store.raw.data.BasePage;
1: 
0: import org.apache.derby.iapi.services.cache.Cacheable;
0: import org.apache.derby.iapi.services.context.ContextService;
0: import org.apache.derby.iapi.services.monitor.Monitor;
0: import org.apache.derby.iapi.services.diag.Performance;
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: import org.apache.derby.iapi.services.io.FormatIdUtil;
1: 
1: import org.apache.derby.iapi.error.StandardException;
1: 
1: import org.apache.derby.iapi.store.raw.ContainerHandle;
1: import org.apache.derby.iapi.store.raw.ContainerKey;
0: import org.apache.derby.iapi.store.raw.Loggable;
1: import org.apache.derby.iapi.store.raw.log.LogInstant;
0: import org.apache.derby.iapi.store.raw.xact.RawTransaction;
1: 
0: import org.apache.derby.io.StorageFactory;
0: import org.apache.derby.io.WritableStorageFactory;
1: import org.apache.derby.io.StorageFile;
1: import org.apache.derby.io.StorageRandomAccessFile;
1: 
0: import java.util.Vector;
1: 
0: import java.io.DataInput;
1: import java.io.IOException;
1: 
1: import java.security.AccessController;
0: import java.security.PrivilegedAction;
1: import java.security.PrivilegedExceptionAction;
1: import java.security.PrivilegedActionException;
1: 
1: /**
1: 	RAFContainer (short for RandomAccessFileContainer) is a concrete subclass of FileContainer
1: 	for FileContainers which are implemented on java.io.RandomAccessFile.
1: */
1: 
0: public class RAFContainer extends FileContainer implements PrivilegedExceptionAction
1: {
1: 	/**
0: 		IBM Copyright &copy notice.
1: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1997_2004;
1: 
1: 	/*
1: 	 * Immutable fields
1: 	 */
1: 	protected StorageRandomAccessFile fileData;
1: 
1: 	/* 
1: 	** Mutable fields, only valid when the identity is valid.
1: 	*/
1: 	protected boolean			needsSync;
1: 
1:     /* privileged actions */
1:     private int actionCode;
1:     private static final int GET_FILE_NAME_ACTION = 1;
1:     private static final int CREATE_CONTAINER_ACTION = 2;
1:     private static final int REMOVE_FILE_ACTION = 3;
1:     private static final int OPEN_CONTAINER_ACTION = 4;
1:     private static final int STUBBIFY_ACTION = 5;
1:     private ContainerKey actionIdentity;
1:     private boolean actionStub;
1:     private boolean actionErrorOK;
1:     private boolean actionTryAlternatePath;
1:     private StorageFile actionFile;
1:     private LogInstant actionInstant;
1:     
1: 	/*
1: 	 * Constructors
1: 	 */
1: 
0: 	protected RAFContainer(BaseDataFileFactory factory) {
1: 		super(factory);
1: 	}
1: 
1: 	/*
1: 	** Methods overriding super-class
1: 	*/
1: 
1: 	synchronized public boolean isDirty() {
1: 		return super.isDirty() || needsSync;
1: 	}
1: 
1: 	/*
0: 	** Methods of Cacheable
1: 	*/
1: 
1: 	/**
0: 		Set container's identity
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
0: 	public Cacheable setIdentity(Object key) throws StandardException {
1: 
0: 		ContainerKey newIdentity = (ContainerKey) key;
1: 
0: 		// if this is an open for a temp container then return an object of that type
0: 		if (newIdentity.getSegmentId() == ContainerHandle.TEMPORARY_SEGMENT) {
1: 
0: 			TempRAFContainer tmpContainer = new TempRAFContainer(dataFactory);
0: 			return tmpContainer.setIdent(newIdentity);
1: 		}
1: 
0: 		return setIdent(newIdentity);
1: 	}
1: 
1: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
1: 	 */
0: 	public Cacheable createIdentity(Object key, Object createParameter) throws StandardException {
1: 
0: 		ContainerKey newIdentity = (ContainerKey) key;
1: 
0: 		if (newIdentity.getSegmentId() == ContainerHandle.TEMPORARY_SEGMENT) {
0: 			TempRAFContainer tmpContainer = new TempRAFContainer(dataFactory);
0: 			return tmpContainer.createIdent(newIdentity, createParameter);
1: 		}
1: 
0: 		return createIdent(newIdentity, createParameter);
1: 	}
1: 
1: 
1: 	/*
1: 	** Container creation, opening, and closing
1: 	*/
1: 
1: 	/**
1: 		Remove the container
1: 
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
1: 	protected void removeContainer(LogInstant instant, boolean leaveStub)
1: 		 throws StandardException
1: 	{
1: 		// discard all of my pages in the cache
1: 		pageCache.discard(identity);
1: 		stubbify(instant);
1: 
1: 		// RESOLVE: leaveStub false
1: 	}
1: 
0: 	protected final void closeContainer() {
1: 
1: 		if (fileData != null) {
0: 			try {
1: 				fileData.close();
0: 			} catch (IOException ioe) {
0: 			} finally {
1: 
1: 				fileData = null;
1: 			}
1: 		}
1: 	}
1: 
1: 
1: 	/*
1: 	** Methods used solely by StoredPage
1: 	*/
1: 
1: 	/**
1: 		Read a page into the supplied array.
1: 
1: 		<BR> MT - thread safe
1: 		@exception IOException exception reading page
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
1: 	protected void readPage(long pageNumber, byte[] pageData)
1: 		 throws IOException, StandardException
1: 	{
0: 		if (SanityManager.DEBUG) {
1: 			SanityManager.ASSERT(!getCommittedDropState());
1: 		}
1: 
1: 		long pageOffset = pageNumber * pageSize;
1: 
0: 		synchronized (this) {
1: 
0: 			fileData.seek(pageOffset);
1: 
0: 			fileData.readFully(pageData, 0, pageSize);
1: 		}
1: 
1: 		if (dataFactory.databaseEncrypted() &&
1: 			pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1: 		{
1: 			decryptPage(pageData, pageSize);
1: 		}
1: 	}
1: 
1: 	/**
1: 		Write a page from the supplied array.
1: 
1: 		<BR> MT - thread safe
1: 
0: 		@exception StandardException Standard Cloudscape error policy
1: 		@exception IOException IO error accessing page
1: 	*/
1: 	protected void writePage(long pageNumber, byte[] pageData, boolean syncPage)
1: 		 throws IOException, StandardException
1: 	{
1: 		synchronized(this)
1: 		{
1: 
0: 			// committed and dropped, do nothing.
0: 			// This file container may only be a stub
0: 			if (getCommittedDropState())
0: 				return;
1: 
0: 			if (pageNumber == FIRST_ALLOC_PAGE_NUMBER)
1: 			{
0: 				// write header into the alloc page array regardless of dirty
0: 				// bit because the alloc page have zero'ed out the borrowed
0: 				// space
0: 				writeHeader(pageData);
1: 
0: 				if (SanityManager.DEBUG) {
0: 					if (FormatIdUtil.readFormatIdInteger(pageData) != AllocPage.FORMAT_NUMBER)
0: 						SanityManager.THROWASSERT(
0: 							"expect " +
0: 							AllocPage.FORMAT_NUMBER +
0: 							"got " +
0: 							FormatIdUtil.readFormatIdInteger(pageData));
1: 				}
1: 
1: 			}
1: 
0: 		///////////////////////////////////////////////////
1: 		//
0: 		// RESOLVE: right now, no logical -> physical mapping.
0: 		// We can calculate the offset.  In the future, we may need to
0: 		// look at the allocation page or the in memory translation table
0: 		// to figure out where the page should go
1: 		//
0: 		/////////////////////////////////////////////////
1: 
1: 			long pageOffset = pageNumber * pageSize;
1: 
1: 			try
1: 			{
0: 				fileData.seek(pageOffset);
1: 
1: 				/**
1: 					On EPOC (www.symbian.com) a seek beyond the end of
1: 					a file just moves the file pointer to the end of the file.
1: 
1: 				*/
1: 				if (fileData.getFilePointer() != pageOffset)
1: 					padFile(fileData, pageOffset);
1: 
0: 				byte[] dataToWrite;
1: 
0: 				if (dataFactory.databaseEncrypted() 
0: 					&& pageNumber != FIRST_ALLOC_PAGE_NUMBER)
1: 				{
0: 					// We cannot encrypt the page in place because pageData is
0: 					// still being accessed as clear text.  The encryption
0: 					// buffer is shared by all who access this container and can
0: 					// only be used within the synchronized block.
0: 					dataToWrite = encryptPage(pageData, pageSize);
0: 				} else {
0: 					dataToWrite = pageData;
1: 				}
1: 
1: 				dataFactory.writeInProgress();
1: 				try
1: 				{
1: 					fileData.write(dataToWrite, 0, pageSize);
1: 				}
1: 				finally
1: 				{
1: 					dataFactory.writeFinished();
1: 				}
1: 			}
1: 			catch (IOException ioe)
1: 			{
1: 				// On some platforms, if we seek beyond the end of file, or try
1: 				// to write beyond the end of file (not appending to it, but
1: 				// skipping some bytes), it will give IOException.
1: 				// Try writing zeros from the current end of file to pageOffset
1: 				// and see if we can then do the seek/write.  The difference
1: 				// between pageOffset and current end of file is almost always
1: 				// going to be the multiple of pageSize
1: 
1: 				if (!padFile(fileData, pageOffset))
1: 					throw ioe;	// not writing beyond EOF, rethrow exception
1: 
1: 				if (SanityManager.DEBUG)
0: 					SanityManager.ASSERT(fileData.length() >= pageOffset,
0: 										 "failed to blank filled missing pages");
0: 				fileData.seek(pageOffset);
1: 				dataFactory.writeInProgress();
1: 				try
1: 				{
0: 					fileData.write(pageData, 0, pageSize);
1: 				}
1: 				finally
1: 				{
1: 					dataFactory.writeFinished();
1: 				}
1: 			}
1: 
1: 			if (syncPage)
1: 			{
1: 				dataFactory.writeInProgress();
1: 				try
1: 				{
0:                     if (Performance.MEASURE)
1:                     {
0:                         if (!dataFactory.dataNotSyncedAtAllocation)
0:                             fileData.sync( false);
1:                     }
1:                     else
1:                     {
0:                         fileData.sync( false);
1:                     }
1: 				}
1: 				finally
1: 				{
1: 					dataFactory.writeFinished();
1: 				}
1: 			}
1: 			else
1:             {
1: 				needsSync = true;
1:             }
1: 		}
1: 
1: 	}
1: 
1: 	/**
1: 		Pad the file upto the passed in page offset.
1: 		Returns true if the file needed padding.
1: 	*/
1: 
1: 	private boolean padFile(StorageRandomAccessFile file, long pageOffset)
1: 		throws IOException, StandardException {
1: 
1: 		long currentEOF = file.length();
1: 		if (currentEOF >= pageOffset)
1: 			return false;
1: 
1: 		// all objects in java are by definition initialized
1: 		byte zero[] = new byte[pageSize];
1: 
1: 		file.seek(currentEOF);
1: 
1: 		while(currentEOF < pageOffset)
1: 		{
1: 			dataFactory.writeInProgress();
1: 			try
1: 			{
1: 				long len = pageOffset - currentEOF;
1: 				if (len > pageSize)
1: 					len = pageSize;
1: 
1: 				file.write(zero, 0, (int) len);
1: 			}
1: 			finally
1: 			{
1: 				dataFactory.writeFinished();
1: 			}
1: 			currentEOF += pageSize;
1: 		}
1: 
1: 		return true;
1: 	}
1: 
1: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
1: 	public void clean(boolean forRemove) throws StandardException
1: 	{
1: 		boolean waited = false;
1: 
0: 		synchronized (this) {
1: 
0: 			// committed and dropped, do nothing.  
0: 			// This file container has already been stubbified
0: 			if (getCommittedDropState()) {
0: 				clearDirty();
0: 				return;
1: 			}
1: 
0: 			// The container is about to change, need to wait till it is really
0: 			// changed.  We are in the predirty state only for the duration
0: 			// where the log record that changed the container has been sent to
0: 			// the log and before the change actually happened.
0: 			while(preDirty == true)
1: 			{
0: 				waited = true;
1: 				try
1: 				{
0: 					wait();
1: 				}
0: 				catch (InterruptedException ie)
1: 				{
0: 					throw StandardException.interrupt(ie);
1: 				}
1: 			}
1: 
0: 			if (waited)
1: 			{
0: 				// someone else may have stubbified this while we waited 
0: 				if (getCommittedDropState())
1: 				{
0: 					clearDirty();
0: 					return;
1: 				}
1: 			}
1: 
1: 
0: 			if (forRemove) {
1: 
0: 				//				removeFile()
0: 				//				clearDirty();
1: 
0: 			} else if (isDirty()) {
1:  
0: 				try {
1: 
0: 					// Cannot get the alloc page and write it out
0: 					// because in order to do so, the alloc page will need to 
0: 					// find this container object.  But this container object
0: 					// is in the middle of being cleaned and may not be 
0: 					// 'found' and we will hang.
1: 					//
0: 					// Instead, just clobber the container info, which is 
0: 					// checksum'ed seperately from the alloc page
1: 					//
0: 					writeRAFHeader(fileData,
0: 								   false,  // don't create, container exists 
0: 								   true);  // syncfile
1: 
0: 					clearDirty();
1: 
0: 				} catch (IOException ioe) {
1: 
0: 					throw dataFactory.markCorrupt(
0:                         StandardException.newException(
0:                             SQLState.FILE_CONTAINER_EXCEPTION, ioe, this));
1: 				}
1: 			}
1: 		}
1: 	}
1: 
1: 	private void clearDirty() {
1: 		isDirty = false;
1: 		needsSync = false;
1: 	}
1: 
1: 
1: 	/**
1: 		Preallocate some pages if need be
1: 	*/
1: 	protected int preAllocate(long lastPreallocPagenum, 
1: 							  int preAllocSize)
1: 	{  
1: 	
1: 		/* we had a condition here , that looks at the file size before
1: 		 * preallocation to handle the optimization cases like , we 
1: 		 * preallocated the space and then crashed, as we don;t log the 
1: 		 * preallocated length, we don't have updated value until AlocExtent
1: 		 * page get flushed to the disk. only way to find out that the pages
1: 		 * we want already exist  is to look at the file length.
1: 		 * Althought it was nice thing to do, we had bug no: 3813 from
1: 		 * customer , who for some unexplainable reasons he gets lots of
1: 		 * junk at the end of the file. As junk is not initialized with
1: 		 * format-ID , we get into recovery problem.
1: 		 * To avoid such unforseen conditions, removed the file size check 
1: 		 * condition , as it is better not to fail in recovery than 
1: 		 * losing some special case performance improvement.
1: 		 */
1:   
1: 		int n = doPreAllocatePages(lastPreallocPagenum, preAllocSize); 
1: 
1: 		if (n > 0)				// sync the file
1: 		{
1: 			synchronized(this)
1: 			{
1: 				boolean inwrite = false;
1: 				try
1: 				{
1: 					dataFactory.writeInProgress();
1: 					inwrite = true;
1: 
0:                     if (Performance.MEASURE)
1:                     {
0:                         if (!dataFactory.dataNotSyncedAtAllocation)
0:                             fileData.sync( false);
1:                     }
1:                     else
1:                     {
0:                         fileData.sync( false);
1:                     }
1: 				}
1: 				catch (IOException ioe)
1: 				{
1: 					// The disk may have run out of space. 
1: 					// Don't error out in pre-allocation since the user may not
1: 					// actually need this page.
1: 					n = 0;
1: 				}
1: 				catch (StandardException se)
1: 				{
1: 					// some problem calling writeInProgress
1: 					n = 0;
1: 				}
1: 				finally
1: 				{
1: 					if (inwrite)
1: 						dataFactory.writeFinished();
1: 				}
1: 			}
1: 		}
1: 
1: 		return n;
1: 	}
1: 
1: 
1: 	/*
1: 		Write the header of a random access file and sync it
1: 		@param create if true, the container is being created
1: 				if false, the container already exist
1: 		@param syncFile if true, sync the file
1: 	*/
0: 	private void writeRAFHeader(StorageRandomAccessFile file, boolean create, 
1: 								boolean syncFile) 
1: 		 throws IOException, StandardException
1: 	{
1: 		byte[] epage;
1: 		if (create)
1: 		{
1: 			// the file doesn't exist yet, get an embryonic page buffer
0: 			epage = getEmbryonicPage((DataInput)null); 
1: 		}
1: 		else
1: 		{
0: 			file.seek(FIRST_ALLOC_PAGE_OFFSET);
0: 			epage = getEmbryonicPage(file);
1: 		}
1: 
1: 		// need to check for frozen state
1: 
1: 
0: 		file.seek(FIRST_ALLOC_PAGE_OFFSET);
0: 		writeHeader(file, create, epage);
1: 
0: 		// leave the end of the file at a page boundry. This
0: 		// is to work around bugs in the EPOC jvm where a seek
0: 		// beyond the end of a file does not throw an exception
0: 		// but just moves the offset to the end of the file. This only
0: 		// occurs when the second page is written after the header has
0: 		// been written, ending up with the page at the incorrect offset.
0: 		if (create) {
0: 			padFile(file, pageSize);
1: 		}
1: 
1: 		if (syncFile)
1: 		{
1: 			dataFactory.writeInProgress();
1: 			try
1: 			{
0:                 if (Performance.MEASURE)
1:                 {
0:                     if (!dataFactory.dataNotSyncedAtCheckpoint)
0:                         file.sync( false);
1:                 }
1:                 else
1:                 {
0:                     file.sync( false);
1:                 }
1: 			}
1: 			finally
1: 			{
1: 				dataFactory.writeFinished();
1: 			}
1: 		}
1: 
0: 		epage = null;
1: 	}
1: 
1: 	/**
1: 		flush the cache to ensure all of my pages are written to disk
1: 
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
1: 	protected void flushAll() throws StandardException {
1: 
1: 		pageCache.clean(identity);
1: 
1: 		// now clean myself which will sync all my pages.
1: 		clean(false);
1: 	}
1: 
1: 
0: 	 protected synchronized StorageFile getFileName(ContainerKey identity, boolean stub,
1: 											 boolean errorOK, boolean tryAlternatePath)
1: 		 throws StandardException
1: 	 {
1:          // RESOLVE - READ ONLY
1: 
1:          actionCode = GET_FILE_NAME_ACTION;
1:          actionIdentity = identity;
1:          actionStub = stub;
1:          actionErrorOK = errorOK;
1:          actionTryAlternatePath = tryAlternatePath;
1:          try
1:          {
1:              return (StorageFile) AccessController.doPrivileged( this);
1:          }
1:          catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:          finally{ actionIdentity = null; }
1: 	 }
1: 
1:     protected StorageFile privGetFileName(ContainerKey identity, boolean stub,
1:                                     boolean errorOK, boolean tryAlternatePath)
1:         throws StandardException
1:     {
1:         StorageFile container = dataFactory.getContainerPath( identity, stub);
1: 
1:         // retry with small case 'c' and 'd'
1:         // bug fix for track 3444
1:         if (!container.exists() && tryAlternatePath)
1:         {
1:             container = dataFactory.getAlternateContainerPath( identity, stub);
1:         }
1: 
1:         if (!container.exists()) {
1: 
1:             StorageFile directory = container.getParentDir();
1: 
1:             if (!directory.exists())
1:             {
1:                 // make sure only 1 thread can create a segment at one time
1:                 synchronized(dataFactory)
1:                 {
1:                     if (!directory.exists())
1:                     {
1:                         if (!directory.mkdirs())
1:                         {
1:                             if (errorOK)
1:                             {
1:                                 return null;
1:                             }
1:                             else
1:                             {
0:                                 throw StandardException.newException(
1:                                     SQLState.FILE_CANNOT_CREATE_SEGMENT,
1:                                     directory);
1:                             }
1:                         }
1:                     }
1:                 }
1:             }
1:         }
1: 
1:         return container;
1:     } // end of privGetFileName
1: 
1: 
0: 	protected synchronized void createContainer(ContainerKey newIdentity)
1:         throws StandardException
1:     {
1: 
0: 		if (SanityManager.DEBUG) {
1: 			if ((spareSpace < 0) || (spareSpace > 100))
1: 				SanityManager.THROWASSERT("invalid spare space " + spareSpace);
1: 		}
1: 
1:         actionCode = CREATE_CONTAINER_ACTION;
1:         actionIdentity = newIdentity;
1:         try
1:         {
1:             AccessController.doPrivileged( this);
1:         }
1:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:         finally{ actionIdentity = null; }
1:     } // end of createContainer
1: 
0: 	protected synchronized boolean removeFile(StorageFile file)
1:         throws SecurityException, StandardException
1:     {
1:         actionCode = REMOVE_FILE_ACTION;
1:         actionFile = file;
1:         try
1:         {
1:             return AccessController.doPrivileged( this) != null;
1:         }
1:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:         finally{ actionFile = null; }
1:     } // end of removeFile
1: 
1:     private boolean privRemoveFile(StorageFile file)
1:         throws StandardException
1:     {
0: 		closeContainer();
1: 
1: 		dataFactory.writeInProgress();
1: 		try
1: 		{
0:             if( file.exists())
1:                 return file.delete();
1: 		}
1: 		finally
1: 		{
1: 			dataFactory.writeFinished();
1: 		}
1: 
1: 		return true;
1:     } // end of privRemoveFile
1: 
0: 	protected synchronized boolean openContainer(ContainerKey newIdentity)
1:         throws StandardException
1:     {
1:         actionCode = OPEN_CONTAINER_ACTION;
1:         actionIdentity = newIdentity;
1:         try
1:         {
1:             return AccessController.doPrivileged( this) != null;
1:         }
1:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:         finally{ actionIdentity = null; }
1:     }
1: 
0: 	protected synchronized void stubbify(LogInstant instant)
1:         throws StandardException
1: 	{
1:          // update header, synchronized this in case the cache is cleaning
1:          // this container at the same time.  Make sure the clean and
1:          // stubbify is mutually exclusive.
1:          setDroppedState(true);
1:          setCommittedDropState(true);
1: 
1: 		 // The whole container should be shrunk into a 'stub'.
1: 		 // If the file system supports truncation, we can just truncate the
1: 		 // file after the header.  Since it doesn't, we need to write out a
1: 		 // seperate file (the stub), then reset fileData to point to that,
1: 		 // then remove the current file.
1: 		 //
1: 		 // There may still be dirty pages that belongs to this file which are
1: 		 // still in the page cache.  They need not really
1: 		 // be written since they don't really exist anymore
1: 		 //
1: 		 // there are 3 pieces of information on disk :
1: 		 // 1) the log operation that caused this file to be stubbified
1: 		 // 2) the stub
1: 		 // 3) the file
1: 		 //
1: 		 // The order of event, as far as persisent store is concerned, is
1: 		 // A) stub shows up
1: 		 // B) the file disappear
1: 		 // C) the log operation got flushed
1: 		 // (B and C may swap order)
1: 		 //
1: 		 // If neither A or B happens (we crashed before the sync call),
1: 		 // then nothing happened.
1: 		 //
1: 		 // if A happened but B and C did not, then when we recover, we will not
1: 		 // know the file has been stubbified.  Hopefully, it will be stubbified
1: 		 // again if the post-commit queue manager is alerted to the fact.
1: 		 //
1: 		 // if A and B happened but C did not, then the file is stubbified but
1: 		 // there is no log record to indicate that.  This is undesirable but
1: 		 // still safe because the only time we stubbify is on a post commit
1: 		 // operation, i.e., either a create container has rolled back or a
1: 		 // dropped container has committed.  We end up having a a container
1: 		 // stub which behaves the same as a dropped container - only that all
1: 		 // the redo work is unnecessary because we 'know' it will
1: 		 // eventually be dropped and committed.
1: 		 //
1: 		 // If A and C happened and not B, then during redo, this stubbify
1: 		 // routine will be called again and the file will be deleted again
1: 		 //
1: 		 // The reason why A has to be sync'ed out is that we don't want B to
1: 		 // happen but A did not and the system crashed.  Then we are left
1: 		 // with neither the file nor the stub and maybe even no log record.
1: 		 // Then the system is not recoverable.
1: 
1: 		actionIdentity = (ContainerKey)getIdentity();
1:         actionInstant = instant;
1:         actionCode = STUBBIFY_ACTION;
1:         try
1:         {
1:             AccessController.doPrivileged( this);
1:         }
1:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
1:         finally
1:         {
0:             actionIdentity = null;
1:             actionInstant = null;
1:         }
1:     }
1: 
1:      // PrivilegedExceptionAction method
0:      public Object run() throws StandardException
1:      {
1:          switch( actionCode)
1:          {
1:          case GET_FILE_NAME_ACTION:
1:              return privGetFileName( actionIdentity, actionStub, actionErrorOK, actionTryAlternatePath);
1: 
1:          case CREATE_CONTAINER_ACTION:
1:          {
1:              StorageFile file = privGetFileName( actionIdentity, false, false, false);
1: 
0:              try {
1:                  if (file.exists()) {
1:                      // note I'm left in the no-identity state as fillInIdentity()
1:                      // hasn't been called.
1:                      throw StandardException.newException( SQLState.FILE_EXISTS, file);
1:                  }
1:              } catch (SecurityException se) {
1:                  throw StandardException.newException( SQLState.FILE_CREATE, se, file);
1:              }
1: 
0:              try {
1: 
0:                  // OK not to force WAL here, in fact, this operation preceeds the
0:                  // creation of the log record to ensure sufficient space.
1: 
1:                  dataFactory.writeInProgress();
1:                  try
1:                  {
0:                      fileData = file.getRandomAccessFile( "rw");
1:                  }
1:                  finally
1:                  {
1:                      dataFactory.writeFinished();
1:                  }
1: 
0:                  // This container format specifies that the first page is an
0:                  // allocation page and the container information is stored within
0:                  // it.  The allocation page needs to be somewhat formatted
0:                  // because if the system crashed after the create container log
0:                  // operation is written, it needs to be well formed enough to get
0:                  // the container information back out of it.
1:                  //
0:                  // Don't try to go thru the page cache here because the container
0:                  // object cannot be found in the container cache at this point
0:                  // yet.  However, if we use the page cache to store the first
0:                  // allocation page, then in order to write itself out, it needs to
0:                  // ask the container to do so, which is going to create a
0:                  // deadlock.  The allocation page cannot write itself out without
0:                  // going thru the container because it doesn't know where its
0:                  // offset is.  Here we effectively hardwired page 0 at offset 0 of
0:                  // the container file to be the first allocation page.
1: 
0:                  // create an embryonic page - if this is not a temporary container,
0:                  // synchronously write out the file header.
0:                  writeRAFHeader(fileData, true,
0:                                 (actionIdentity.getSegmentId() != ContainerHandle.TEMPORARY_SEGMENT));
1: 
1:              } catch (SecurityException se) {
1: 
0:                  // only thrown by the RandomeAccessFile constructor,
0:                  // so the file won't exist
1:                  throw StandardException.newException( SQLState.FILE_CREATE, se, file);
1: 
0:              } catch (IOException ioe) {
1: 
0:                  boolean fileDeleted;
0:                  try {
0:                      fileDeleted = privRemoveFile(file);
1:                  } catch (SecurityException se) {
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, se);
1:                  }
1: 
0:                  if (!fileDeleted) {
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, null);
1:                  }
1: 
0:                  throw StandardException.newException( SQLState.FILE_CREATE, ioe, file);
1:              }
1: 
1:              canUpdate = true;
1:              return null;
1:          } // end of case CREATE_CONTAINER_ACTION
1: 
1:          case REMOVE_FILE_ACTION:
1:              return privRemoveFile( actionFile) ? this : null;
1: 
1:          case OPEN_CONTAINER_ACTION:
1:          {
1:              boolean isStub = false;	// is this a stub?
1: 
1:              StorageFile file = privGetFileName( actionIdentity, false, true, true);
1:              if (file == null)
1:                  return null;
1: 
0:              try {
1:                  if (!file.exists()) {
1: 
1:                      // file does not exist, may be it has been stubbified
1:                      file = privGetFileName( actionIdentity, true, true, true);
1:                      if (!file.exists())
1:                          return null;
0:                      isStub = true;
1:                  }
1:              } catch (SecurityException se) {
0:                  throw StandardException.newException(
1:                      SQLState.DATA_UNEXPECTED_EXCEPTION, se);
1:              }
1: 
1:              canUpdate = false;
0:              try {
1:                  if (!dataFactory.isReadOnly() && file.canWrite())
1:                      canUpdate = true;
1:              } catch (SecurityException se) {
1:                  // just means we can't write to it.
1:              }
1: 
0:              try {
1: 
1:                  fileData = file.getRandomAccessFile(canUpdate ? "rw" : "r");
0:                  fileData.seek(FIRST_ALLOC_PAGE_OFFSET);
0:                  readHeader(fileData);
1: 
1:                  if (SanityManager.DEBUG)
1:                  {
1:                      if (isStub)
1:                          SanityManager.ASSERT(getDroppedState() && getCommittedDropState(),
1:                                               "a stub failed to set drop state");
1:                  }
1: 
0:              } catch (IOException ioe) {
1: 
1:                  if (isStub)
1:                  {
0:                      throw dataFactory.markCorrupt(
0:                          StandardException.newException(
0:                              SQLState.FILE_CONTAINER_EXCEPTION, ioe, this, ioe));
1:                  }
1: 
1:                  // maybe it is being stubbified... try that
0:                  StorageFile stub = privGetFileName( actionIdentity, true, true, true);
1:                  if (stub.exists())
1:                  {
1:                      try
1:                      {
1:                          if (SanityManager.DEBUG)
0:                              SanityManager.DEBUG_PRINT("RAFContainer",
0:                                                        "removing file because we opened it while it is being stubbified");
1: 
1:                          privRemoveFile(file);
1: 
0:                          fileData = stub.getRandomAccessFile(canUpdate ? "rw" : "r");
0:                          readHeader(fileData);
1:                      }
1:                      catch (IOException ioe2)
1:                      {
0:                          throw dataFactory.markCorrupt(
0:                              StandardException.newException(
0:                                  SQLState.FILE_CONTAINER_EXCEPTION, ioe2, this, ioe2));
1:                      }
1: 
1:                      // RESOLVE: this is a temporary hack
1: 
1:                  }
1:                  else
0:                      throw dataFactory.markCorrupt(
0:                          StandardException.newException(
0:                              SQLState.FILE_CONTAINER_EXCEPTION, ioe, this, ioe));
1:              }
1: 
1:              return this;
1:          } // end of case OPEN_CONTAINER_ACTION
1: 
1:          case STUBBIFY_ACTION:
1:          {
1:              StorageFile file = privGetFileName( actionIdentity, false, false, true);
1:              StorageFile stub = privGetFileName( actionIdentity, true, false, false);
1: 
1:              StorageRandomAccessFile stubData = null;
1: 
1:              try
1:              {
1:                  // !!!!!
1:                  // bumpContainerVersion();
1:                  //
1:                  // do NOT bump the container version.  We WANT the stubbify
1:                  // operation to get redone every time.  This is because this
1:                  // operation first writes out the stub and then remove the
1:                  // container file.  If we bump the version, then the stub will
1:                  // contain the new version.  And if the system crashes right then,
1:                  // then we will skip the whole operation during redo even though
1:                  // the container file may not have been removed.  Since we don't
1:                  // want to have the remove happen before the stub is written, we
1:                  // cannot sync it and therefore cannot be sure the remove
1:                  // happened before the system crashed.
1: 
1:                  if (!stub.exists())
1:                  {
1:                      // write the header to the stub
1:                      stubData = stub.getRandomAccessFile( "rw");
1: 
0:                      writeRAFHeader(stubData,
1:                                     true, /* create */
1:                                     true); /* sync */
1: 
1:                      stubData.close();
1:                      stubData = null;
1:                  }
1: 
1: 
1:                  // Force WAL and check for database corruption before removing file.
1:                  // This is one operation where the container is changed on disk
1:                  // directly without going thru the container cache, which otherwise
1:                  // would have force WAL.  Take care of it here.
1:                  dataFactory.flush(actionInstant);
1: 
1:                  // try to remove the container file
1:                  // fileDate is not null only if we are redoing a removeContainer
1:                  // (stubbify) operation.  Then fileData acutally is opened against
1:                  // the stub and the original container file does not exist.
1:                  // Then we need to close it here because this method is called by
1:                  // cache.remove and nobody will be able to see fileData after this.
1:                  privRemoveFile(file);
1: 
1:              }
1:              catch (SecurityException se)
1:              {
0:                  throw StandardException.newException(
0:                      SQLState.FILE_CANNOT_REMOVE_FILE, se, file, se);
1:              }
1:              catch (IOException ioe)
1:              {
1:                  // exception thrown while in creating the stub.  Remove the
1:                  // (half-baked) stub
1:                  try
1:                  {
1:                      if (stubData != null)
1:                      {
1:                          stubData.close();
1:                          stub.delete();
1:                          stubData = null;
1:                      }
1: 
1:                      if (fileData != null)
1:                      {
1:                          fileData.close();
1:                          fileData = null;
1:                      }
1:                  }
1:                  catch (IOException ioe2)
1:                  {
0:                      throw StandardException.newException(
0:                          SQLState.FILE_CANNOT_REMOVE_FILE, ioe2, file, ioe);
1:                  }
1:                  catch (SecurityException se)
1:                  {
0:                      throw StandardException.newException(
0:                          SQLState.FILE_CANNOT_REMOVE_FILE, se, file, stub);
1:                  }
1:              }
1: 	
1:              //let the data factory know about this the stub file;It
1:              // could  remove when next checkpoint occurs if it's not necessary for recovery
1:              dataFactory.stubFileToRemoveAfterCheckPoint(stub,actionInstant, getIdentity());
1:              return null;
1:          } // end of case STUBBIFY_ACTION
1:          }
1:          return null;
1:      } // end of run
1: }
author:Ken Coar
-------------------------------------------------------------------------------
commit:95e7b46
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.store.raw.data
0:    (C) Copyright IBM Corp. 1997, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
0: 
0:  */
0: 
0: package org.apache.derby.impl.store.raw.data;
0: 
0: import org.apache.derby.iapi.reference.SQLState;
0: import org.apache.derby.impl.store.raw.data.BaseContainer;
0: import org.apache.derby.impl.store.raw.data.BaseContainerHandle;
0: import org.apache.derby.impl.store.raw.data.BasePage;
0: 
0: import org.apache.derby.iapi.services.cache.Cacheable;
0: import org.apache.derby.iapi.services.context.ContextService;
0: import org.apache.derby.iapi.services.monitor.Monitor;
0: import org.apache.derby.iapi.services.diag.Performance;
0: import org.apache.derby.iapi.services.sanity.SanityManager;
0: import org.apache.derby.iapi.services.io.FormatIdUtil;
0: 
0: import org.apache.derby.iapi.error.StandardException;
0: 
0: import org.apache.derby.iapi.store.raw.ContainerHandle;
0: import org.apache.derby.iapi.store.raw.ContainerKey;
0: import org.apache.derby.iapi.store.raw.Loggable;
0: import org.apache.derby.iapi.store.raw.log.LogInstant;
0: import org.apache.derby.iapi.store.raw.xact.RawTransaction;
0: 
0: import org.apache.derby.io.StorageFactory;
0: import org.apache.derby.io.WritableStorageFactory;
0: import org.apache.derby.io.StorageFile;
0: import org.apache.derby.io.StorageRandomAccessFile;
0: 
0: import java.util.Vector;
0: 
0: import java.io.DataInput;
0: import java.io.IOException;
0: 
0: import java.security.AccessController;
0: import java.security.PrivilegedAction;
0: import java.security.PrivilegedExceptionAction;
0: import java.security.PrivilegedActionException;
0: 
0: /**
0: 	RAFContainer (short for RandomAccessFileContainer) is a concrete subclass of FileContainer
0: 	for FileContainers which are implemented on java.io.RandomAccessFile.
0: */
0: 
0: public class RAFContainer extends FileContainer implements PrivilegedExceptionAction
0: {
0: 	/**
0: 		IBM Copyright &copy notice.
0: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1997_2004;
0: 
0: 	/*
0: 	 * Immutable fields
0: 	 */
0: 	protected StorageRandomAccessFile fileData;
0: 
0: 	/* 
0: 	** Mutable fields, only valid when the identity is valid.
0: 	*/
0: 	protected boolean			needsSync;
0: 
0:     /* privileged actions */
0:     private int actionCode;
0:     private static final int GET_FILE_NAME_ACTION = 1;
0:     private static final int CREATE_CONTAINER_ACTION = 2;
0:     private static final int REMOVE_FILE_ACTION = 3;
0:     private static final int OPEN_CONTAINER_ACTION = 4;
0:     private static final int STUBBIFY_ACTION = 5;
0:     private ContainerKey actionIdentity;
0:     private boolean actionStub;
0:     private boolean actionErrorOK;
0:     private boolean actionTryAlternatePath;
0:     private StorageFile actionFile;
0:     private LogInstant actionInstant;
0:     
0: 	/*
0: 	 * Constructors
0: 	 */
0: 
0: 	protected RAFContainer(BaseDataFileFactory factory) {
0: 		super(factory);
0: 	}
0: 
0: 	/*
0: 	** Methods overriding super-class
0: 	*/
0: 
0: 	synchronized public boolean isDirty() {
0: 		return super.isDirty() || needsSync;
0: 	}
0: 
0: 	/*
0: 	** Methods of Cacheable
0: 	*/
0: 
0: 	/**
0: 		Set container's identity
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	public Cacheable setIdentity(Object key) throws StandardException {
0: 
0: 		ContainerKey newIdentity = (ContainerKey) key;
0: 
0: 		// if this is an open for a temp container then return an object of that type
0: 		if (newIdentity.getSegmentId() == ContainerHandle.TEMPORARY_SEGMENT) {
0: 
0: 			TempRAFContainer tmpContainer = new TempRAFContainer(dataFactory);
0: 			return tmpContainer.setIdent(newIdentity);
0: 		}
0: 
0: 		return setIdent(newIdentity);
0: 	}
0: 
0: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
0: 	 */
0: 	public Cacheable createIdentity(Object key, Object createParameter) throws StandardException {
0: 
0: 		ContainerKey newIdentity = (ContainerKey) key;
0: 
0: 		if (newIdentity.getSegmentId() == ContainerHandle.TEMPORARY_SEGMENT) {
0: 			TempRAFContainer tmpContainer = new TempRAFContainer(dataFactory);
0: 			return tmpContainer.createIdent(newIdentity, createParameter);
0: 		}
0: 
0: 		return createIdent(newIdentity, createParameter);
0: 	}
0: 
0: 
0: 	/*
0: 	** Container creation, opening, and closing
0: 	*/
0: 
0: 	/**
0: 		Remove the container
0: 
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	protected void removeContainer(LogInstant instant, boolean leaveStub)
0: 		 throws StandardException
0: 	{
0: 		// discard all of my pages in the cache
0: 		pageCache.discard(identity);
0: 		stubbify(instant);
0: 
0: 		// RESOLVE: leaveStub false
0: 	}
0: 
0: 	protected final void closeContainer() {
0: 
0: 		if (fileData != null) {
0: 			try {
0: 				fileData.close();
0: 			} catch (IOException ioe) {
0: 			} finally {
0: 
0: 				fileData = null;
0: 			}
0: 		}
0: 	}
0: 
0: 
0: 	/*
0: 	** Methods used solely by StoredPage
0: 	*/
0: 
0: 	/**
0: 		Read a page into the supplied array.
0: 
0: 		<BR> MT - thread safe
0: 		@exception IOException exception reading page
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	protected void readPage(long pageNumber, byte[] pageData)
0: 		 throws IOException, StandardException
0: 	{
0: 		if (SanityManager.DEBUG) {
0: 			SanityManager.ASSERT(!getCommittedDropState());
0: 		}
0: 
0: 		long pageOffset = pageNumber * pageSize;
0: 
0: 		synchronized (this) {
0: 
0: 			fileData.seek(pageOffset);
0: 
0: 			fileData.readFully(pageData, 0, pageSize);
0: 		}
0: 
0: 		if (dataFactory.databaseEncrypted() &&
0: 			pageNumber != FIRST_ALLOC_PAGE_NUMBER)
0: 		{
0: 			decryptPage(pageData, pageSize);
0: 		}
0: 	}
0: 
0: 	/**
0: 		Write a page from the supplied array.
0: 
0: 		<BR> MT - thread safe
0: 
0: 		@exception StandardException Standard Cloudscape error policy
0: 		@exception IOException IO error accessing page
0: 	*/
0: 	protected void writePage(long pageNumber, byte[] pageData, boolean syncPage)
0: 		 throws IOException, StandardException
0: 	{
0: 		synchronized(this)
0: 		{
0: 
0: 			// committed and dropped, do nothing.
0: 			// This file container may only be a stub
0: 			if (getCommittedDropState())
0: 				return;
0: 
0: 			if (pageNumber == FIRST_ALLOC_PAGE_NUMBER)
0: 			{
0: 				// write header into the alloc page array regardless of dirty
0: 				// bit because the alloc page have zero'ed out the borrowed
0: 				// space
0: 				writeHeader(pageData);
0: 
0: 				if (SanityManager.DEBUG) {
0: 					if (FormatIdUtil.readFormatIdInteger(pageData) != AllocPage.FORMAT_NUMBER)
0: 						SanityManager.THROWASSERT(
0: 							"expect " +
0: 							AllocPage.FORMAT_NUMBER +
0: 							"got " +
0: 							FormatIdUtil.readFormatIdInteger(pageData));
0: 				}
0: 
0: 			}
0: 
0: 		///////////////////////////////////////////////////
0: 		//
0: 		// RESOLVE: right now, no logical -> physical mapping.
0: 		// We can calculate the offset.  In the future, we may need to
0: 		// look at the allocation page or the in memory translation table
0: 		// to figure out where the page should go
0: 		//
0: 		/////////////////////////////////////////////////
0: 
0: 			long pageOffset = pageNumber * pageSize;
0: 
0: 			try
0: 			{
0: 				fileData.seek(pageOffset);
0: 
0: 				/**
0: 					On EPOC (www.symbian.com) a seek beyond the end of
0: 					a file just moves the file pointer to the end of the file.
0: 
0: 				*/
0: 				if (fileData.getFilePointer() != pageOffset)
0: 					padFile(fileData, pageOffset);
0: 
0: 				byte[] dataToWrite;
0: 
0: 				if (dataFactory.databaseEncrypted() 
0: 					&& pageNumber != FIRST_ALLOC_PAGE_NUMBER)
0: 				{
0: 					// We cannot encrypt the page in place because pageData is
0: 					// still being accessed as clear text.  The encryption
0: 					// buffer is shared by all who access this container and can
0: 					// only be used within the synchronized block.
0: 					dataToWrite = encryptPage(pageData, pageSize);
0: 				} else {
0: 					dataToWrite = pageData;
0: 				}
0: 
0: 				dataFactory.writeInProgress();
0: 				try
0: 				{
0: 					fileData.write(dataToWrite, 0, pageSize);
0: 				}
0: 				finally
0: 				{
0: 					dataFactory.writeFinished();
0: 				}
0: 			}
0: 			catch (IOException ioe)
0: 			{
0: 				// On some platforms, if we seek beyond the end of file, or try
0: 				// to write beyond the end of file (not appending to it, but
0: 				// skipping some bytes), it will give IOException.
0: 				// Try writing zeros from the current end of file to pageOffset
0: 				// and see if we can then do the seek/write.  The difference
0: 				// between pageOffset and current end of file is almost always
0: 				// going to be the multiple of pageSize
0: 
0: 				if (!padFile(fileData, pageOffset))
0: 					throw ioe;	// not writing beyond EOF, rethrow exception
0: 
0: 				if (SanityManager.DEBUG)
0: 					SanityManager.ASSERT(fileData.length() >= pageOffset,
0: 										 "failed to blank filled missing pages");
0: 				fileData.seek(pageOffset);
0: 				dataFactory.writeInProgress();
0: 				try
0: 				{
0: 					fileData.write(pageData, 0, pageSize);
0: 				}
0: 				finally
0: 				{
0: 					dataFactory.writeFinished();
0: 				}
0: 			}
0: 
0: 			if (syncPage)
0: 			{
0: 				dataFactory.writeInProgress();
0: 				try
0: 				{
0:                     if (Performance.MEASURE)
0:                     {
0:                         if (!dataFactory.dataNotSyncedAtAllocation)
0:                             fileData.sync( false);
0:                     }
0:                     else
0:                     {
0:                         fileData.sync( false);
0:                     }
0: 				}
0: 				finally
0: 				{
0: 					dataFactory.writeFinished();
0: 				}
0: 			}
0: 			else
0:             {
0: 				needsSync = true;
0:             }
0: 		}
0: 
0: 	}
0: 
0: 	/**
0: 		Pad the file upto the passed in page offset.
0: 		Returns true if the file needed padding.
0: 	*/
0: 
0: 	private boolean padFile(StorageRandomAccessFile file, long pageOffset)
0: 		throws IOException, StandardException {
0: 
0: 		long currentEOF = file.length();
0: 		if (currentEOF >= pageOffset)
0: 			return false;
0: 
0: 		// all objects in java are by definition initialized
0: 		byte zero[] = new byte[pageSize];
0: 
0: 		file.seek(currentEOF);
0: 
0: 		while(currentEOF < pageOffset)
0: 		{
0: 			dataFactory.writeInProgress();
0: 			try
0: 			{
0: 				long len = pageOffset - currentEOF;
0: 				if (len > pageSize)
0: 					len = pageSize;
0: 
0: 				file.write(zero, 0, (int) len);
0: 			}
0: 			finally
0: 			{
0: 				dataFactory.writeFinished();
0: 			}
0: 			currentEOF += pageSize;
0: 		}
0: 
0: 		return true;
0: 	}
0: 
0: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	public void clean(boolean forRemove) throws StandardException
0: 	{
0: 		boolean waited = false;
0: 
0: 		synchronized (this) {
0: 
0: 			// committed and dropped, do nothing.  
0: 			// This file container has already been stubbified
0: 			if (getCommittedDropState()) {
0: 				clearDirty();
0: 				return;
0: 			}
0: 
0: 			// The container is about to change, need to wait till it is really
0: 			// changed.  We are in the predirty state only for the duration
0: 			// where the log record that changed the container has been sent to
0: 			// the log and before the change actually happened.
0: 			while(preDirty == true)
0: 			{
0: 				waited = true;
0: 				try
0: 				{
0: 					wait();
0: 				}
0: 				catch (InterruptedException ie)
0: 				{
0: 					throw StandardException.interrupt(ie);
0: 				}
0: 			}
0: 
0: 			if (waited)
0: 			{
0: 				// someone else may have stubbified this while we waited 
0: 				if (getCommittedDropState())
0: 				{
0: 					clearDirty();
0: 					return;
0: 				}
0: 			}
0: 
0: 
0: 			if (forRemove) {
0: 
0: 				//				removeFile()
0: 				//				clearDirty();
0: 
0: 			} else if (isDirty()) {
0:  
0: 				try {
0: 
0: 					// Cannot get the alloc page and write it out
0: 					// because in order to do so, the alloc page will need to 
0: 					// find this container object.  But this container object
0: 					// is in the middle of being cleaned and may not be 
0: 					// 'found' and we will hang.
0: 					//
0: 					// Instead, just clobber the container info, which is 
0: 					// checksum'ed seperately from the alloc page
0: 					//
0: 					writeRAFHeader(fileData,
0: 								   false,  // don't create, container exists 
0: 								   true);  // syncfile
0: 
0: 					clearDirty();
0: 
0: 				} catch (IOException ioe) {
0: 
0: 					throw dataFactory.markCorrupt(
0:                         StandardException.newException(
0:                             SQLState.FILE_CONTAINER_EXCEPTION, ioe, this));
0: 				}
0: 			}
0: 		}
0: 	}
0: 
0: 	private void clearDirty() {
0: 		isDirty = false;
0: 		needsSync = false;
0: 	}
0: 
0: 
0: 	/**
0: 		Preallocate some pages if need be
0: 	*/
0: 	protected int preAllocate(long lastPreallocPagenum, 
0: 							  int preAllocSize)
0: 	{  
0: 	
0: 		/* we had a condition here , that looks at the file size before
0: 		 * preallocation to handle the optimization cases like , we 
0: 		 * preallocated the space and then crashed, as we don;t log the 
0: 		 * preallocated length, we don't have updated value until AlocExtent
0: 		 * page get flushed to the disk. only way to find out that the pages
0: 		 * we want already exist  is to look at the file length.
0: 		 * Althought it was nice thing to do, we had bug no: 3813 from
0: 		 * customer , who for some unexplainable reasons he gets lots of
0: 		 * junk at the end of the file. As junk is not initialized with
0: 		 * format-ID , we get into recovery problem.
0: 		 * To avoid such unforseen conditions, removed the file size check 
0: 		 * condition , as it is better not to fail in recovery than 
0: 		 * losing some special case performance improvement.
0: 		 */
0:   
0: 		int n = doPreAllocatePages(lastPreallocPagenum, preAllocSize); 
0: 
0: 		if (n > 0)				// sync the file
0: 		{
0: 			synchronized(this)
0: 			{
0: 				boolean inwrite = false;
0: 				try
0: 				{
0: 					dataFactory.writeInProgress();
0: 					inwrite = true;
0: 
0:                     if (Performance.MEASURE)
0:                     {
0:                         if (!dataFactory.dataNotSyncedAtAllocation)
0:                             fileData.sync( false);
0:                     }
0:                     else
0:                     {
0:                         fileData.sync( false);
0:                     }
0: 				}
0: 				catch (IOException ioe)
0: 				{
0: 					// The disk may have run out of space. 
0: 					// Don't error out in pre-allocation since the user may not
0: 					// actually need this page.
0: 					n = 0;
0: 				}
0: 				catch (StandardException se)
0: 				{
0: 					// some problem calling writeInProgress
0: 					n = 0;
0: 				}
0: 				finally
0: 				{
0: 					if (inwrite)
0: 						dataFactory.writeFinished();
0: 				}
0: 			}
0: 		}
0: 
0: 		return n;
0: 	}
0: 
0: 
0: 	/*
0: 		Write the header of a random access file and sync it
0: 		@param create if true, the container is being created
0: 				if false, the container already exist
0: 		@param syncFile if true, sync the file
0: 	*/
0: 	private void writeRAFHeader(StorageRandomAccessFile file, boolean create, 
0: 								boolean syncFile) 
0: 		 throws IOException, StandardException
0: 	{
0: 		byte[] epage;
0: 		if (create)
0: 		{
0: 			// the file doesn't exist yet, get an embryonic page buffer
0: 			epage = getEmbryonicPage((DataInput)null); 
0: 		}
0: 		else
0: 		{
0: 			file.seek(FIRST_ALLOC_PAGE_OFFSET);
0: 			epage = getEmbryonicPage(file);
0: 		}
0: 
0: 		// need to check for frozen state
0: 
0: 
0: 		file.seek(FIRST_ALLOC_PAGE_OFFSET);
0: 		writeHeader(file, create, epage);
0: 
0: 		// leave the end of the file at a page boundry. This
0: 		// is to work around bugs in the EPOC jvm where a seek
0: 		// beyond the end of a file does not throw an exception
0: 		// but just moves the offset to the end of the file. This only
0: 		// occurs when the second page is written after the header has
0: 		// been written, ending up with the page at the incorrect offset.
0: 		if (create) {
0: 			padFile(file, pageSize);
0: 		}
0: 
0: 		if (syncFile)
0: 		{
0: 			dataFactory.writeInProgress();
0: 			try
0: 			{
0:                 if (Performance.MEASURE)
0:                 {
0:                     if (!dataFactory.dataNotSyncedAtCheckpoint)
0:                         file.sync( false);
0:                 }
0:                 else
0:                 {
0:                     file.sync( false);
0:                 }
0: 			}
0: 			finally
0: 			{
0: 				dataFactory.writeFinished();
0: 			}
0: 		}
0: 
0: 		epage = null;
0: 	}
0: 
0: 	/**
0: 		flush the cache to ensure all of my pages are written to disk
0: 
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	protected void flushAll() throws StandardException {
0: 
0: 		pageCache.clean(identity);
0: 
0: 		// now clean myself which will sync all my pages.
0: 		clean(false);
0: 	}
0: 
0: 
0: 	 protected synchronized StorageFile getFileName(ContainerKey identity, boolean stub,
0: 											 boolean errorOK, boolean tryAlternatePath)
0: 		 throws StandardException
0: 	 {
0:          // RESOLVE - READ ONLY
0: 
0:          actionCode = GET_FILE_NAME_ACTION;
0:          actionIdentity = identity;
0:          actionStub = stub;
0:          actionErrorOK = errorOK;
0:          actionTryAlternatePath = tryAlternatePath;
0:          try
0:          {
0:              return (StorageFile) AccessController.doPrivileged( this);
0:          }
0:          catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
0:          finally{ actionIdentity = null; }
0: 	 }
0: 
0:     protected StorageFile privGetFileName(ContainerKey identity, boolean stub,
0:                                     boolean errorOK, boolean tryAlternatePath)
0:         throws StandardException
0:     {
0:         StorageFile container = dataFactory.getContainerPath( identity, stub);
0: 
0:         // retry with small case 'c' and 'd'
0:         // bug fix for track 3444
0:         if (!container.exists() && tryAlternatePath)
0:         {
0:             container = dataFactory.getAlternateContainerPath( identity, stub);
0:         }
0: 
0:         if (!container.exists()) {
0: 
0:             StorageFile directory = container.getParentDir();
0: 
0:             if (!directory.exists())
0:             {
0:                 // make sure only 1 thread can create a segment at one time
0:                 synchronized(dataFactory)
0:                 {
0:                     if (!directory.exists())
0:                     {
0:                         if (!directory.mkdirs())
0:                         {
0:                             if (errorOK)
0:                             {
0:                                 return null;
0:                             }
0:                             else
0:                             {
0:                                 throw StandardException.newException(
0:                                     SQLState.FILE_CANNOT_CREATE_SEGMENT,
0:                                     directory);
0:                             }
0:                         }
0:                     }
0:                 }
0:             }
0:         }
0: 
0:         return container;
0:     } // end of privGetFileName
0: 
0: 
0: 	protected synchronized void createContainer(ContainerKey newIdentity)
0:         throws StandardException
0:     {
0: 
0: 		if (SanityManager.DEBUG) {
0: 			if ((spareSpace < 0) || (spareSpace > 100))
0: 				SanityManager.THROWASSERT("invalid spare space " + spareSpace);
0: 		}
0: 
0:         actionCode = CREATE_CONTAINER_ACTION;
0:         actionIdentity = newIdentity;
0:         try
0:         {
0:             AccessController.doPrivileged( this);
0:         }
0:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
0:         finally{ actionIdentity = null; }
0:     } // end of createContainer
0: 
0: 	protected synchronized boolean removeFile(StorageFile file)
0:         throws SecurityException, StandardException
0:     {
0:         actionCode = REMOVE_FILE_ACTION;
0:         actionFile = file;
0:         try
0:         {
0:             return AccessController.doPrivileged( this) != null;
0:         }
0:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
0:         finally{ actionFile = null; }
0:     } // end of removeFile
0: 
0:     private boolean privRemoveFile(StorageFile file)
0:         throws StandardException
0:     {
0: 		closeContainer();
0: 
0: 		dataFactory.writeInProgress();
0: 		try
0: 		{
0:             if( file.exists())
0:                 return file.delete();
0: 		}
0: 		finally
0: 		{
0: 			dataFactory.writeFinished();
0: 		}
0: 
0: 		return true;
0:     } // end of privRemoveFile
0: 
0: 	protected synchronized boolean openContainer(ContainerKey newIdentity)
0:         throws StandardException
0:     {
0:         actionCode = OPEN_CONTAINER_ACTION;
0:         actionIdentity = newIdentity;
0:         try
0:         {
0:             return AccessController.doPrivileged( this) != null;
0:         }
0:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
0:         finally{ actionIdentity = null; }
0:     }
0: 
0: 	protected synchronized void stubbify(LogInstant instant)
0:         throws StandardException
0: 	{
0:          // update header, synchronized this in case the cache is cleaning
0:          // this container at the same time.  Make sure the clean and
0:          // stubbify is mutually exclusive.
0:          setDroppedState(true);
0:          setCommittedDropState(true);
0: 
0: 		 // The whole container should be shrunk into a 'stub'.
0: 		 // If the file system supports truncation, we can just truncate the
0: 		 // file after the header.  Since it doesn't, we need to write out a
0: 		 // seperate file (the stub), then reset fileData to point to that,
0: 		 // then remove the current file.
0: 		 //
0: 		 // There may still be dirty pages that belongs to this file which are
0: 		 // still in the page cache.  They need not really
0: 		 // be written since they don't really exist anymore
0: 		 //
0: 		 // there are 3 pieces of information on disk :
0: 		 // 1) the log operation that caused this file to be stubbified
0: 		 // 2) the stub
0: 		 // 3) the file
0: 		 //
0: 		 // The order of event, as far as persisent store is concerned, is
0: 		 // A) stub shows up
0: 		 // B) the file disappear
0: 		 // C) the log operation got flushed
0: 		 // (B and C may swap order)
0: 		 //
0: 		 // If neither A or B happens (we crashed before the sync call),
0: 		 // then nothing happened.
0: 		 //
0: 		 // if A happened but B and C did not, then when we recover, we will not
0: 		 // know the file has been stubbified.  Hopefully, it will be stubbified
0: 		 // again if the post-commit queue manager is alerted to the fact.
0: 		 //
0: 		 // if A and B happened but C did not, then the file is stubbified but
0: 		 // there is no log record to indicate that.  This is undesirable but
0: 		 // still safe because the only time we stubbify is on a post commit
0: 		 // operation, i.e., either a create container has rolled back or a
0: 		 // dropped container has committed.  We end up having a a container
0: 		 // stub which behaves the same as a dropped container - only that all
0: 		 // the redo work is unnecessary because we 'know' it will
0: 		 // eventually be dropped and committed.
0: 		 //
0: 		 // If A and C happened and not B, then during redo, this stubbify
0: 		 // routine will be called again and the file will be deleted again
0: 		 //
0: 		 // The reason why A has to be sync'ed out is that we don't want B to
0: 		 // happen but A did not and the system crashed.  Then we are left
0: 		 // with neither the file nor the stub and maybe even no log record.
0: 		 // Then the system is not recoverable.
0: 
0: 		actionIdentity = (ContainerKey)getIdentity();
0:         actionInstant = instant;
0:         actionCode = STUBBIFY_ACTION;
0:         try
0:         {
0:             AccessController.doPrivileged( this);
0:         }
0:         catch( PrivilegedActionException pae){ throw (StandardException) pae.getException();}
0:         finally
0:         {
0:             actionIdentity = null;
0:             actionInstant = null;
0:         }
0:     }
0: 
0:      // PrivilegedExceptionAction method
0:      public Object run() throws StandardException
0:      {
0:          switch( actionCode)
0:          {
0:          case GET_FILE_NAME_ACTION:
0:              return privGetFileName( actionIdentity, actionStub, actionErrorOK, actionTryAlternatePath);
0: 
0:          case CREATE_CONTAINER_ACTION:
0:          {
0:              StorageFile file = privGetFileName( actionIdentity, false, false, false);
0: 
0:              try {
0:                  if (file.exists()) {
0:                      // note I'm left in the no-identity state as fillInIdentity()
0:                      // hasn't been called.
0:                      throw StandardException.newException( SQLState.FILE_EXISTS, file);
0:                  }
0:              } catch (SecurityException se) {
0:                  throw StandardException.newException( SQLState.FILE_CREATE, se, file);
0:              }
0: 
0:              try {
0: 
0:                  // OK not to force WAL here, in fact, this operation preceeds the
0:                  // creation of the log record to ensure sufficient space.
0: 
0:                  dataFactory.writeInProgress();
0:                  try
0:                  {
0:                      fileData = file.getRandomAccessFile( "rw");
0:                  }
0:                  finally
0:                  {
0:                      dataFactory.writeFinished();
0:                  }
0: 
0:                  // This container format specifies that the first page is an
0:                  // allocation page and the container information is stored within
0:                  // it.  The allocation page needs to be somewhat formatted
0:                  // because if the system crashed after the create container log
0:                  // operation is written, it needs to be well formed enough to get
0:                  // the container information back out of it.
0:                  //
0:                  // Don't try to go thru the page cache here because the container
0:                  // object cannot be found in the container cache at this point
0:                  // yet.  However, if we use the page cache to store the first
0:                  // allocation page, then in order to write itself out, it needs to
0:                  // ask the container to do so, which is going to create a
0:                  // deadlock.  The allocation page cannot write itself out without
0:                  // going thru the container because it doesn't know where its
0:                  // offset is.  Here we effectively hardwired page 0 at offset 0 of
0:                  // the container file to be the first allocation page.
0: 
0:                  // create an embryonic page - if this is not a temporary container,
0:                  // synchronously write out the file header.
0:                  writeRAFHeader(fileData, true,
0:                                 (actionIdentity.getSegmentId() != ContainerHandle.TEMPORARY_SEGMENT));
0: 
0:              } catch (SecurityException se) {
0: 
0:                  // only thrown by the RandomeAccessFile constructor,
0:                  // so the file won't exist
0:                  throw StandardException.newException( SQLState.FILE_CREATE, se, file);
0: 
0:              } catch (IOException ioe) {
0: 
0:                  boolean fileDeleted;
0:                  try {
0:                      fileDeleted = privRemoveFile(file);
0:                  } catch (SecurityException se) {
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, se);
0:                  }
0: 
0:                  if (!fileDeleted) {
0:                      throw StandardException.newException( SQLState.FILE_CREATE_NO_CLEANUP, ioe, file, null);
0:                  }
0: 
0:                  throw StandardException.newException( SQLState.FILE_CREATE, ioe, file);
0:              }
0: 
0:              canUpdate = true;
0:              return null;
0:          } // end of case CREATE_CONTAINER_ACTION
0: 
0:          case REMOVE_FILE_ACTION:
0:              return privRemoveFile( actionFile) ? this : null;
0: 
0:          case OPEN_CONTAINER_ACTION:
0:          {
0:              boolean isStub = false;	// is this a stub?
0: 
0:              StorageFile file = privGetFileName( actionIdentity, false, true, true);
0:              if (file == null)
0:                  return null;
0: 
0:              try {
0:                  if (!file.exists()) {
0: 
0:                      // file does not exist, may be it has been stubbified
0:                      file = privGetFileName( actionIdentity, true, true, true);
0:                      if (!file.exists())
0:                          return null;
0:                      isStub = true;
0:                  }
0:              } catch (SecurityException se) {
0:                  throw StandardException.newException(
0:                      SQLState.DATA_UNEXPECTED_EXCEPTION, se);
0:              }
0: 
0:              canUpdate = false;
0:              try {
0:                  if (!dataFactory.isReadOnly() && file.canWrite())
0:                      canUpdate = true;
0:              } catch (SecurityException se) {
0:                  // just means we can't write to it.
0:              }
0: 
0:              try {
0: 
0:                  fileData = file.getRandomAccessFile(canUpdate ? "rw" : "r");
0:                  fileData.seek(FIRST_ALLOC_PAGE_OFFSET);
0:                  readHeader(fileData);
0: 
0:                  if (SanityManager.DEBUG)
0:                  {
0:                      if (isStub)
0:                          SanityManager.ASSERT(getDroppedState() && getCommittedDropState(),
0:                                               "a stub failed to set drop state");
0:                  }
0: 
0:              } catch (IOException ioe) {
0: 
0:                  if (isStub)
0:                  {
0:                      throw dataFactory.markCorrupt(
0:                          StandardException.newException(
0:                              SQLState.FILE_CONTAINER_EXCEPTION, ioe, this, ioe));
0:                  }
0: 
0:                  // maybe it is being stubbified... try that
0:                  StorageFile stub = privGetFileName( actionIdentity, true, true, true);
0:                  if (stub.exists())
0:                  {
0:                      try
0:                      {
0:                          if (SanityManager.DEBUG)
0:                              SanityManager.DEBUG_PRINT("RAFContainer",
0:                                                        "removing file because we opened it while it is being stubbified");
0: 
0:                          privRemoveFile(file);
0: 
0:                          fileData = stub.getRandomAccessFile(canUpdate ? "rw" : "r");
0:                          readHeader(fileData);
0:                      }
0:                      catch (IOException ioe2)
0:                      {
0:                          throw dataFactory.markCorrupt(
0:                              StandardException.newException(
0:                                  SQLState.FILE_CONTAINER_EXCEPTION, ioe2, this, ioe2));
0:                      }
0: 
0:                      // RESOLVE: this is a temporary hack
0: 
0:                  }
0:                  else
0:                      throw dataFactory.markCorrupt(
0:                          StandardException.newException(
0:                              SQLState.FILE_CONTAINER_EXCEPTION, ioe, this, ioe));
0:              }
0: 
0:              return this;
0:          } // end of case OPEN_CONTAINER_ACTION
0: 
0:          case STUBBIFY_ACTION:
0:          {
0:              StorageFile file = privGetFileName( actionIdentity, false, false, true);
0:              StorageFile stub = privGetFileName( actionIdentity, true, false, false);
0: 
0:              StorageRandomAccessFile stubData = null;
0: 
0:              try
0:              {
0:                  // !!!!!
0:                  // bumpContainerVersion();
0:                  //
0:                  // do NOT bump the container version.  We WANT the stubbify
0:                  // operation to get redone every time.  This is because this
0:                  // operation first writes out the stub and then remove the
0:                  // container file.  If we bump the version, then the stub will
0:                  // contain the new version.  And if the system crashes right then,
0:                  // then we will skip the whole operation during redo even though
0:                  // the container file may not have been removed.  Since we don't
0:                  // want to have the remove happen before the stub is written, we
0:                  // cannot sync it and therefore cannot be sure the remove
0:                  // happened before the system crashed.
0: 
0:                  if (!stub.exists())
0:                  {
0:                      // write the header to the stub
0:                      stubData = stub.getRandomAccessFile( "rw");
0: 
0:                      writeRAFHeader(stubData,
0:                                     true, /* create */
0:                                     true); /* sync */
0: 
0:                      stubData.close();
0:                      stubData = null;
0:                  }
0: 
0: 
0:                  // Force WAL and check for database corruption before removing file.
0:                  // This is one operation where the container is changed on disk
0:                  // directly without going thru the container cache, which otherwise
0:                  // would have force WAL.  Take care of it here.
0:                  dataFactory.flush(actionInstant);
0: 
0:                  // try to remove the container file
0:                  // fileDate is not null only if we are redoing a removeContainer
0:                  // (stubbify) operation.  Then fileData acutally is opened against
0:                  // the stub and the original container file does not exist.
0:                  // Then we need to close it here because this method is called by
0:                  // cache.remove and nobody will be able to see fileData after this.
0:                  privRemoveFile(file);
0: 
0:              }
0:              catch (SecurityException se)
0:              {
0:                  throw StandardException.newException(
0:                      SQLState.FILE_CANNOT_REMOVE_FILE, se, file, se);
0:              }
0:              catch (IOException ioe)
0:              {
0:                  // exception thrown while in creating the stub.  Remove the
0:                  // (half-baked) stub
0:                  try
0:                  {
0:                      if (stubData != null)
0:                      {
0:                          stubData.close();
0:                          stub.delete();
0:                          stubData = null;
0:                      }
0: 
0:                      if (fileData != null)
0:                      {
0:                          fileData.close();
0:                          fileData = null;
0:                      }
0:                  }
0:                  catch (IOException ioe2)
0:                  {
0:                      throw StandardException.newException(
0:                          SQLState.FILE_CANNOT_REMOVE_FILE, ioe2, file, ioe);
0:                  }
0:                  catch (SecurityException se)
0:                  {
0:                      throw StandardException.newException(
0:                          SQLState.FILE_CANNOT_REMOVE_FILE, se, file, stub);
0:                  }
0:              }
0: 	
0:              //let the data factory know about this the stub file;It
0:              // could  remove when next checkpoint occurs if it's not necessary for recovery
0:              dataFactory.stubFileToRemoveAfterCheckPoint(stub,actionInstant, getIdentity());
0:              return null;
0:          } // end of case STUBBIFY_ACTION
0:          }
0:          return null;
0:      } // end of run
0: }
============================================================================
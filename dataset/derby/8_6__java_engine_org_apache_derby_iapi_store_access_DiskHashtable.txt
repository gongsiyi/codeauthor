1:b223f72: /*
3:b223f72: 
1:b223f72:    Derby - Class org.apache.derby.iapi.store.access.DiskHashtable
1:b223f72: 
1:75c7276:    Licensed to the Apache Software Foundation (ASF) under one or more
1:75c7276:    contributor license agreements.  See the NOTICE file distributed with
1:75c7276:    this work for additional information regarding copyright ownership.
1:75c7276:    The ASF licenses this file to you under the Apache License, Version 2.0
1:75c7276:    (the "License"); you may not use this file except in compliance with
1:75c7276:    the License.  You may obtain a copy of the License at
1:b223f72: 
1:b223f72:       http://www.apache.org/licenses/LICENSE-2.0
1:b223f72: 
1:b223f72:    Unless required by applicable law or agreed to in writing, software
1:b223f72:    distributed under the License is distributed on an "AS IS" BASIS,
1:b223f72:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b223f72:    See the License for the specific language governing permissions and
1:b223f72:    limitations under the License.
1:b223f72: 
1:b223f72:  */
1:b223f72: package org.apache.derby.iapi.store.access;
1:b223f72: 
1:a0dbbd7: import java.security.AccessController;
1:a0dbbd7: import java.security.PrivilegedAction;
1:e76d29e: import java.util.ArrayList;
1:b223f72: import java.util.Enumeration;
1:e76d29e: import java.util.List;
1:b223f72: import java.util.NoSuchElementException;
1:b223f72: import java.util.Properties;
1:1e762f5: import org.apache.derby.shared.common.reference.SQLState;
1:b223f72: import org.apache.derby.iapi.error.StandardException;
1:b223f72: import org.apache.derby.iapi.types.DataValueDescriptor;
1:b223f72: import org.apache.derby.iapi.types.SQLInteger;
1:b223f72: import org.apache.derby.iapi.types.RowLocation;
1:b61f876: import org.apache.derby.iapi.types.StringDataValue;
1:b61f876: 
1:a0dbbd7: import org.apache.derby.iapi.services.context.Context;
1:b223f72: import org.apache.derby.iapi.services.context.ContextService;
1:b61f876: import org.apache.derby.iapi.services.io.FormatableBitSet;
1:7e51e9d: import org.apache.derby.shared.common.sanity.SanityManager;
1:b223f72: 
1:b61f876: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1:b61f876: 
1:b223f72: /**
1:801c515:  * This class is used by BackingStoreHashtable when the BackingStoreHashtable 
1:801c515:  * must spill to disk.  It implements the methods of a hash table: put, get, 
1:801c515:  * remove, elements, however it is not implemented as a hash table. In order to
1:801c515:  * minimize the amount of unique code it is implemented using a Btree and a 
1:801c515:  * heap conglomerate. The Btree indexes the hash code of the row key. The 
1:801c515:  * actual key may be too long for our Btree implementation.
1:b223f72:  *
1:b223f72:  * Created: Fri Jan 28 13:58:03 2005
1:b223f72:  *
1:b223f72:  * @version 1.0
1:b223f72:  */
1:b223f72: 
1:b223f72: public class DiskHashtable 
1:b223f72: {
1:801c515:     private final long                    rowConglomerateId;
1:801c515:     private       ConglomerateController  rowConglomerate;
1:801c515:     private final long                    btreeConglomerateId;
1:801c515:     private       ConglomerateController  btreeConglomerate;
1:801c515:     private final DataValueDescriptor[]   btreeRow;
1:801c515:     private final int[]                   key_column_numbers;
1:801c515:     private final boolean                 remove_duplicates;
1:801c515:     private final TransactionController   tc;
1:801c515:     private final DataValueDescriptor[]   row;
1:801c515:     private final DataValueDescriptor[]   scanKey = { new SQLInteger()};
1:801c515:     private int                           size;
1:801c515:     private boolean                       keepStatistics;
1:1e762f5:     private final boolean                 keepAfterCommit;
1:b223f72: 
1:b223f72:     /**
1:b223f72:      * Creates a new <code>DiskHashtable</code> instance.
1:b223f72:      *
1:b223f72:      * @param tc
1:801c515:      * @param template              An array of DataValueDescriptors that 
1:801c515:      *                              serves as a template for the rows.
1:801c515:      * @param key_column_numbers    The indexes of the key columns (0 based)
1:801c515:      * @param remove_duplicates     If true then rows with duplicate keys are 
1:801c515:      *                              removed.
1:801c515:      * @param keepAfterCommit       If true then the hash table is kept after 
1:801c515:      *                              a commit
1:b223f72:      */
1:801c515:     public DiskHashtable( 
1:801c515:     TransactionController   tc,
1:801c515:     DataValueDescriptor[]   template,
1:b61f876:     int[]                   collation_ids,
1:801c515:     int[]                   key_column_numbers,
1:801c515:     boolean                 remove_duplicates,
1:801c515:     boolean                 keepAfterCommit)
1:b223f72:         throws StandardException
1:b223f72:     {
1:801c515:         this.tc                         = tc;
1:801c515:         this.key_column_numbers         = key_column_numbers;
1:801c515:         this.remove_duplicates          = remove_duplicates;
1:1e762f5:         this.keepAfterCommit            = keepAfterCommit;
1:801c515:         LanguageConnectionContext lcc   = (LanguageConnectionContext)
1:a0dbbd7:             getContextOrNull(
1:801c515:                 LanguageConnectionContext.CONTEXT_ID);
1:801c515: 
1:b223f72:         keepStatistics = (lcc != null) && lcc.getRunTimeStatisticsMode();
1:801c515: 
1:801c515:         // Create template row used for creating the conglomerate and 
1:801c515:         // fetching rows.
1:801c515:         row = new DataValueDescriptor[template.length];
1:b223f72:         for( int i = 0; i < row.length; i++)
1:801c515:         {
1:b223f72:             row[i] = template[i].getNewNull();
1:801c515: 
1:801c515:             if (SanityManager.DEBUG)
1:801c515:             {
1:801c515:                 // must have an object template for all cols in hash overflow.
1:801c515:                 SanityManager.ASSERT(
1:801c515:                     row[i] != null, 
1:801c515:                     "Template for the hash table must have non-null object");
1:801c515:             }
1:801c515:         }
1:801c515: 
1:801c515:         int tempFlags = 
1:801c515:             keepAfterCommit ? 
1:801c515:             (TransactionController.IS_TEMPORARY | 
1:801c515:              TransactionController.IS_KEPT) : 
1:801c515:             TransactionController.IS_TEMPORARY;
1:b223f72:         
1:801c515:         // create the "base" table of the hash overflow.
1:801c515:         rowConglomerateId = 
1:801c515:             tc.createConglomerate( 
1:801c515:                 "heap",
1:801c515:                 template,
1:801c515:                 (ColumnOrdering[]) null,
1:b61f876:                 collation_ids,
1:801c515:                 (Properties) null,
1:801c515:                 tempFlags);
1:b223f72: 
1:801c515:         // open the "base" table of the hash overflow.
1:801c515:         rowConglomerate = 
1:801c515:             tc.openConglomerate( 
1:801c515:                 rowConglomerateId,
1:801c515:                 keepAfterCommit,
1:801c515:                 TransactionController.OPENMODE_FORUPDATE,
1:801c515:                 TransactionController.MODE_TABLE,
1:801c515:                 TransactionController.ISOLATION_NOLOCK/* Single thread only */);
1:801c515: 
1:801c515:         // create the index on the "hash" base table.  The key of the index
1:801c515:         // is the hash code of the row key.  The second column is the 
1:801c515:         // RowLocation of the row in the "base" table of the hash overflow.
1:801c515:         btreeRow = 
1:801c515:             new DataValueDescriptor[] 
1:801c515:                 { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
1:801c515: 
1:b223f72:         Properties btreeProps = new Properties();
1:b223f72: 
1:801c515:         btreeProps.put("baseConglomerateId", 
1:801c515:                 String.valueOf(rowConglomerateId));
1:801c515:         btreeProps.put("rowLocationColumn",  
1:801c515:                 "1");
1:801c515:         btreeProps.put("allowDuplicates",    
1:801c515:                 "false"); // Because the row location is part of the key
1:801c515:         btreeProps.put("nKeyFields",         
1:801c515:                 "2"); // Include the row location column
1:801c515:         btreeProps.put("nUniqueColumns",     
1:801c515:                 "2"); // Include the row location column
1:801c515:         btreeProps.put("maintainParentLinks", 
1:801c515:                 "false");
1:b61f876: 
1:b61f876:         // default collation is used for hash code and row location
1:b61f876:         int[] index_collation_ids = 
1:b61f876:             {StringDataValue.COLLATION_TYPE_UCS_BASIC,
1:b61f876:              StringDataValue.COLLATION_TYPE_UCS_BASIC};
1:b61f876: 
1:801c515:         btreeConglomerateId = 
1:801c515:             tc.createConglomerate( 
1:801c515:                 "BTREE",
1:801c515:                 btreeRow,
1:801c515:                 (ColumnOrdering[]) null,
1:b61f876:                 index_collation_ids,
1:801c515:                 btreeProps,
1:801c515:                 tempFlags);
1:801c515: 
1:801c515:         // open the "index" of the hash overflow.
1:801c515:         btreeConglomerate = 
1:801c515:             tc.openConglomerate( 
1:801c515:                 btreeConglomerateId,
1:801c515:                 keepAfterCommit,
1:801c515:                 TransactionController.OPENMODE_FORUPDATE,
1:801c515:                 TransactionController.MODE_TABLE,
1:801c515:                 TransactionController.ISOLATION_NOLOCK /*Single thread only*/ );
1:801c515: 
1:b223f72:     } // end of constructor
1:b223f72: 
1:b223f72:     public void close() throws StandardException
1:b223f72:     {
1:b223f72:         btreeConglomerate.close();
1:b223f72:         rowConglomerate.close();
1:b223f72:         tc.dropConglomerate( btreeConglomerateId);
1:b223f72:         tc.dropConglomerate( rowConglomerateId);
1:b223f72:     } // end of close
1:b223f72:     
1:b223f72:     /**
1:b223f72:      * Put a new row in the overflow structure.
1:b223f72:      *
1:b223f72:      * @param row The row to be inserted.
1:b223f72:      *
1:801c515:      * @return true  if the row was added,
1:801c515:      *         false if it was not added (because it was a duplicate and we 
1:801c515:      *               are eliminating duplicates).
1:b223f72:      *
1:b223f72:      * @exception StandardException standard error policy
1:b223f72:      */
1:801c515:     public boolean put(Object key, Object[] row)
1:b223f72:         throws StandardException
1:b223f72:     {
1:b223f72:         boolean isDuplicate = false;
1:801c515:         if (remove_duplicates || keepStatistics)
1:b223f72:         {
1:b223f72:             // Go to the work of finding out whether it is a duplicate
1:801c515:             isDuplicate = (getRemove(key, false, true) != null);
1:801c515:             if (remove_duplicates && isDuplicate)
1:b223f72:                 return false;
1:b223f72:         }
1:801c515: 
1:801c515:         // insert the row into the "base" conglomerate.
1:801c515:         rowConglomerate.insertAndFetchLocation( 
1:801c515:             (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
1:801c515: 
1:801c515:         // create index row from hashcode and rowlocation just inserted, and
1:801c515:         // insert index row into index.
1:b223f72:         btreeRow[0].setValue( key.hashCode());
1:b223f72:         btreeConglomerate.insert( btreeRow);
1:801c515: 
1:801c515:         if (keepStatistics && !isDuplicate)
1:b223f72:             size++;
1:801c515: 
1:b223f72:         return true;
1:801c515: 
1:b223f72:     } // end of put
1:b223f72: 
1:b223f72:     /**
1:b223f72:      * Get a row from the overflow structure.
1:b223f72:      *
1:801c515:      * @param key If the rows only have one key column then the key value. 
1:801c515:      *            If there is more than one key column then a KeyHasher
1:b223f72:      *
1:b223f72:      * @return null if there is no corresponding row,
1:801c515:      *         the row (DataValueDescriptor[]) if there is exactly one row 
1:801c515:      *         with the key, or
1:b223f72:      *         a Vector of all the rows with the key if there is more than one.
1:b223f72:      *
1:b223f72:      * @exception StandardException
1:b223f72:      */
1:801c515:     public Object get(Object key)
1:b223f72:         throws StandardException
1:b223f72:     {
1:801c515:         return getRemove(key, false, false);
1:b223f72:     }
1:b223f72: 
1:801c515:     private Object getRemove(Object key, boolean remove, boolean existenceOnly)
1:b223f72:         throws StandardException
1:b223f72:     {
1:b223f72:         int hashCode = key.hashCode();
1:b223f72:         int rowCount = 0;
1:e76d29e:         DataValueDescriptor[] firstRow = null;
1:e76d29e:         List<DataValueDescriptor[]> allRows = null;
1:b223f72: 
1:b223f72:         scanKey[0].setValue( hashCode);
1:801c515:         ScanController scan = 
1:801c515:             tc.openScan( 
1:801c515:                 btreeConglomerateId,
1:801c515:                 false, // do not hold
1:801c515:                 remove ? TransactionController.OPENMODE_FORUPDATE : 0,
1:801c515:                 TransactionController.MODE_TABLE,
1:801c515:                 TransactionController.ISOLATION_READ_UNCOMMITTED,
1:801c515:                 null, // Scan all the columns
1:801c515:                 scanKey,
1:801c515:                 ScanController.GE,
1:801c515:                 (Qualifier[][]) null,
1:801c515:                 scanKey,
1:801c515:                 ScanController.GT);
1:b223f72:         try
1:b223f72:         {
1:801c515:             while (scan.fetchNext(btreeRow))
1:b223f72:             {
1:801c515:                 if (rowConglomerate.fetch(
1:801c515:                         (RowLocation) btreeRow[1], 
1:801c515:                         row, 
1:801c515:                         (FormatableBitSet) null /* all columns */)
1:b223f72:                     && rowMatches( row, key))
1:b223f72:                 {
1:b223f72:                     if( existenceOnly)
1:b223f72:                         return this;
1:b223f72: 
1:e76d29e:                     DataValueDescriptor[] clonedRow =
1:e76d29e:                             BackingStoreHashtable.shallowCloneRow(row);
1:e76d29e: 
1:b223f72:                     rowCount++;
1:801c515:                     if( rowCount == 1)
1:b7c1f3b:                     {
1:801c515:                         // if there is only one matching row just return row. 
1:e76d29e:                         firstRow = clonedRow;
1:801c515:                     }
2:b223f72:                     else 
1:b223f72:                     {
1:e76d29e:                         // If there is more than one row, return a list of
1:801c515:                         // the rows.
1:801c515:                         //
1:e76d29e:                         if (allRows == null)
1:b223f72:                         {
1:801c515:                             // convert the "single" row retrieved from the
1:801c515:                             // first trip in the loop, to a vector with the
1:801c515:                             // first two rows.
1:e76d29e:                             allRows = new ArrayList<DataValueDescriptor[]>(2);
1:e76d29e:                             allRows.add(firstRow);
1:b223f72:                         }
1:e76d29e:                         allRows.add(clonedRow);
1:b223f72:                     }
1:b223f72:                     if( remove)
1:b223f72:                     {
1:b223f72:                         rowConglomerate.delete( (RowLocation) btreeRow[1]);
1:b223f72:                         scan.delete();
1:b223f72:                         size--;
1:b223f72:                     }
1:b223f72:                     if( remove_duplicates)
1:b223f72:                         // This must be the only row with the key
1:e76d29e:                         return clonedRow;
1:b223f72:                 }
1:b223f72:             }
1:b223f72:         }
1:b223f72:         finally
1:b223f72:         {
1:b223f72:             scan.close();
1:b223f72:         }
1:e76d29e: 
1:e76d29e:         if (allRows == null) {
1:e76d29e:             // No duplicates. Return the single row, or null if no row was
1:e76d29e:             // found for the given key.
1:e76d29e:             return firstRow;
1:e76d29e:         } else {
1:e76d29e:             // Return list of all duplicate values.
1:e76d29e:             return allRows;
1:e76d29e:         }
1:b223f72:     } // end of getRemove
1:b223f72: 
1:b223f72: 
1:801c515:     private boolean rowMatches( 
1:801c515:     DataValueDescriptor[] row,
1:801c515:     Object                key)
1:b223f72:     {
1:b223f72:         if( key_column_numbers.length == 1)
1:b223f72:             return row[ key_column_numbers[0]].equals( key);
1:b223f72: 
1:b223f72:         KeyHasher kh = (KeyHasher) key;
1:b223f72:         for( int i = 0; i < key_column_numbers.length; i++)
1:b223f72:         {
1:b223f72:             if( ! row[ key_column_numbers[i]].equals( kh.getObject(i)))
1:b223f72:                 return false;
1:b223f72:         }
1:b223f72:         return true;
1:b223f72:     } // end of rowMatches
1:b223f72: 
1:b223f72:     /**
1:b223f72:      * remove all rows with a given key from the hash table.
1:b223f72:      *
1:b223f72:      * @param key          The key of the rows to remove.
1:b223f72:      *
1:b223f72:      * @return The removed row(s).
1:b223f72:      *
1:b223f72: 	 * @exception  StandardException  Standard exception policy.
1:b223f72:      **/
1:b223f72:     public Object remove( Object key)
1:b223f72: 		throws StandardException
1:b223f72:     {
1:b223f72:         return getRemove( key, true, false);
1:b223f72:     } // end of remove
1:b223f72: 
1:b223f72:     /**
1:b223f72:      * @return The number of rows in the hash table
1:b223f72:      */
1:b223f72:     public int size()
1:b223f72:     {
1:b223f72:         return size;
1:b223f72:     }
1:b223f72:     
1:b223f72:     /**
1:b223f72:      * Return an Enumeration that can be used to scan entire table.
1:b223f72:      * <p>
1:b223f72:      * RESOLVE - is it worth it to support this routine?
1:b223f72:      *
1:b223f72: 	 * @return The Enumeration.
1:b223f72:      *
1:b223f72: 	 * @exception  StandardException  Standard exception policy.
1:b223f72:      **/
1:073b862:     public Enumeration<Object> elements()
1:b223f72:         throws StandardException
1:b223f72:     {
1:b223f72:         return new ElementEnum();
1:b223f72:     }
1:a0dbbd7: 
1:b223f72:     
1:a0dbbd7:     /**
1:a0dbbd7:      * Privileged lookup of a Context. Must be private so that user code
1:a0dbbd7:      * can't call this entry point.
1:a0dbbd7:      */
1:a0dbbd7:     private  static  Context    getContextOrNull( final String contextID )
1:a0dbbd7:     {
1:a0dbbd7:         if ( System.getSecurityManager() == null )
1:a0dbbd7:         {
1:a0dbbd7:             return ContextService.getContextOrNull( contextID );
1:a0dbbd7:         }
1:a0dbbd7:         else
1:a0dbbd7:         {
1:a0dbbd7:             return AccessController.doPrivileged
1:a0dbbd7:                 (
1:a0dbbd7:                  new PrivilegedAction<Context>()
1:a0dbbd7:                  {
1:a0dbbd7:                      public Context run()
1:a0dbbd7:                      {
1:a0dbbd7:                          return ContextService.getContextOrNull( contextID );
1:a0dbbd7:                      }
1:a0dbbd7:                  }
1:a0dbbd7:                  );
1:a0dbbd7:         }
1:a0dbbd7:     }
1:a0dbbd7: 
1:073b862:     private class ElementEnum implements Enumeration<Object>
1:b223f72:     {
1:b223f72:         private ScanController scan;
1:b223f72:         private boolean hasMore;
1:1e762f5:         private RowLocation rowloc;
1:b223f72: 
1:b223f72:         ElementEnum()
1:b223f72:         {
1:b223f72:             try
1:b223f72:             {
1:b223f72:                 scan = tc.openScan( rowConglomerateId,
1:1e762f5:                                     keepAfterCommit,
1:b223f72:                                     0, // read only
4:b223f72:                                     TransactionController.MODE_TABLE,
1:b223f72:                                     TransactionController.ISOLATION_NOLOCK,
1:b223f72:                                     (FormatableBitSet) null, // all columns
1:b223f72:                                     (DataValueDescriptor[]) null, // no start key
1:b223f72:                                     0, // no start key operator
2:b223f72:                                     (Qualifier[][]) null,
1:b223f72:                                     (DataValueDescriptor[]) null, // no stop key
1:b223f72:                                     0 /* no stop key operator */);
1:b223f72:                 hasMore = scan.next();
1:b223f72:                 if( ! hasMore)
1:b223f72:                 {
1:b223f72:                     scan.close();
1:b223f72:                     scan = null;
1:1e762f5:                 } else if (keepAfterCommit) {
1:1e762f5:                     rowloc = rowConglomerate.newRowLocationTemplate();
1:1e762f5:                     scan.fetchLocation(rowloc);
1:b223f72:                 }
1:b223f72:             }
1:b223f72:             catch( StandardException se)
1:b223f72:             {
1:b223f72:                 hasMore = false;
1:b223f72:                 if( scan != null)
1:b223f72:                 {
1:b223f72:                     try
1:b223f72:                     {
1:b223f72:                         scan.close();
1:b223f72:                     }
1:b223f72:                     catch( StandardException se1){};
1:b223f72:                     scan = null;
1:b223f72:                 }
1:b223f72:             }
1:b223f72:         } // end of constructor
1:b223f72: 
1:b223f72:         public boolean hasMoreElements()
1:b223f72:         {
1:b223f72:             return hasMore;
1:b223f72:         }
1:b223f72: 
1:b223f72:         public Object nextElement()
1:b223f72:         {
1:b223f72:             if( ! hasMore)
1:b223f72:                 throw new NoSuchElementException();
1:b223f72:             try
1:b223f72:             {
1:1e762f5:                 if (scan.isHeldAfterCommit()) {
1:1e762f5:                     // automatically reopens scan:
1:1e762f5:                     if (!scan.positionAtRowLocation(rowloc)) {
1:1e762f5:                         // Will not happen unless compress of this table
1:1e762f5:                         // has invalidated the row location. Possible?
1:1e762f5:                         throw StandardException.
1:1e762f5:                             newException(SQLState.NO_CURRENT_ROW);
1:1e762f5:                     }
1:1e762f5:                 }
1:1e762f5: 
1:1e762f5:                 scan.fetch(row);
1:1e762f5: 
1:b7c1f3b:                 Object retValue =  BackingStoreHashtable.shallowCloneRow( row);
1:b223f72:                 hasMore = scan.next();
1:1e762f5: 
1:b223f72:                 if( ! hasMore)
1:b223f72:                 {
1:b223f72:                     scan.close();
1:b223f72:                     scan = null;
1:1e762f5:                 } else if (keepAfterCommit) {
1:1e762f5:                     scan.fetchLocation(rowloc);
1:b223f72:                 }
1:b223f72: 
3:b223f72:                 return retValue;
1:b223f72:             }
1:b223f72:             catch( StandardException se)
1:b223f72:             {
1:b223f72:                 if( scan != null)
1:b223f72:                 {
1:b223f72:                     try
1:b223f72:                     {
1:b223f72:                         scan.close();
1:b223f72:                     }
1:b223f72:                     catch( StandardException se1){};
1:b223f72:                     scan = null;
1:b223f72:                 }
1:b223f72:                 throw new NoSuchElementException();
1:b223f72:             }
1:b223f72:         } // end of nextElement
1:b223f72:     } // end of class ElementEnum
1:b223f72: }
============================================================================
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:a0dbbd7
/////////////////////////////////////////////////////////////////////////
1: import java.security.AccessController;
1: import java.security.PrivilegedAction;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.services.context.Context;
/////////////////////////////////////////////////////////////////////////
1:             getContextOrNull(
/////////////////////////////////////////////////////////////////////////
1:     
1:     /**
1:      * Privileged lookup of a Context. Must be private so that user code
1:      * can't call this entry point.
1:      */
1:     private  static  Context    getContextOrNull( final String contextID )
1:     {
1:         if ( System.getSecurityManager() == null )
1:         {
1:             return ContextService.getContextOrNull( contextID );
1:         }
1:         else
1:         {
1:             return AccessController.doPrivileged
1:                 (
1:                  new PrivilegedAction<Context>()
1:                  {
1:                      public Context run()
1:                      {
1:                          return ContextService.getContextOrNull( contextID );
1:                      }
1:                  }
1:                  );
1:         }
1:     }
1: 
commit:073b862
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("unchecked")
/////////////////////////////////////////////////////////////////////////
0:                         Vector<Object> v;
0:                             v = new Vector<Object>( 2);
0:                             v = (Vector<Object>) retValue;
/////////////////////////////////////////////////////////////////////////
1:     public Enumeration<Object> elements()
1:     private class ElementEnum implements Enumeration<Object>
commit:75c7276
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.sanity.SanityManager;
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:e76d29e
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
1: import java.util.List;
/////////////////////////////////////////////////////////////////////////
1:         DataValueDescriptor[] firstRow = null;
1:         List<DataValueDescriptor[]> allRows = null;
/////////////////////////////////////////////////////////////////////////
1:                     DataValueDescriptor[] clonedRow =
1:                             BackingStoreHashtable.shallowCloneRow(row);
1: 
1:                         firstRow = clonedRow;
1:                         // If there is more than one row, return a list of
1:                         if (allRows == null)
1:                             allRows = new ArrayList<DataValueDescriptor[]>(2);
1:                             allRows.add(firstRow);
1:                         allRows.add(clonedRow);
/////////////////////////////////////////////////////////////////////////
1:                         return clonedRow;
/////////////////////////////////////////////////////////////////////////
1: 
1:         if (allRows == null) {
1:             // No duplicates. Return the single row, or null if no row was
1:             // found for the given key.
1:             return firstRow;
1:         } else {
1:             // Return list of all duplicate values.
1:             return allRows;
1:         }
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:1e762f5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.reference.SQLState;
/////////////////////////////////////////////////////////////////////////
1:     private final boolean                 keepAfterCommit;
/////////////////////////////////////////////////////////////////////////
1:         this.keepAfterCommit            = keepAfterCommit;
/////////////////////////////////////////////////////////////////////////
1:         private RowLocation rowloc;
1:                                     keepAfterCommit,
/////////////////////////////////////////////////////////////////////////
1:                 } else if (keepAfterCommit) {
1:                     rowloc = rowConglomerate.newRowLocationTemplate();
1:                     scan.fetchLocation(rowloc);
/////////////////////////////////////////////////////////////////////////
1:                 if (scan.isHeldAfterCommit()) {
1:                     // automatically reopens scan:
1:                     if (!scan.positionAtRowLocation(rowloc)) {
1:                         // Will not happen unless compress of this table
1:                         // has invalidated the row location. Possible?
1:                         throw StandardException.
1:                             newException(SQLState.NO_CURRENT_ROW);
1:                     }
1:                 }
1: 
1:                 scan.fetch(row);
1: 
1: 
1:                 } else if (keepAfterCommit) {
1:                     scan.fetchLocation(rowloc);
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:b61f876
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.types.StringDataValue;
1: 
1: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1: 
/////////////////////////////////////////////////////////////////////////
1:     int[]                   collation_ids,
/////////////////////////////////////////////////////////////////////////
1:                 collation_ids,
/////////////////////////////////////////////////////////////////////////
1: 
1:         // default collation is used for hash code and row location
1:         int[] index_collation_ids = 
1:             {StringDataValue.COLLATION_TYPE_UCS_BASIC,
1:              StringDataValue.COLLATION_TYPE_UCS_BASIC};
1: 
1:                 index_collation_ids,
commit:801c515
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1:  * This class is used by BackingStoreHashtable when the BackingStoreHashtable 
1:  * must spill to disk.  It implements the methods of a hash table: put, get, 
1:  * remove, elements, however it is not implemented as a hash table. In order to
1:  * minimize the amount of unique code it is implemented using a Btree and a 
1:  * heap conglomerate. The Btree indexes the hash code of the row key. The 
1:  * actual key may be too long for our Btree implementation.
/////////////////////////////////////////////////////////////////////////
1:     private final long                    rowConglomerateId;
1:     private       ConglomerateController  rowConglomerate;
1:     private final long                    btreeConglomerateId;
1:     private       ConglomerateController  btreeConglomerate;
1:     private final DataValueDescriptor[]   btreeRow;
1:     private final int[]                   key_column_numbers;
1:     private final boolean                 remove_duplicates;
1:     private final TransactionController   tc;
1:     private final DataValueDescriptor[]   row;
1:     private final DataValueDescriptor[]   scanKey = { new SQLInteger()};
1:     private int                           size;
1:     private boolean                       keepStatistics;
1:      * @param template              An array of DataValueDescriptors that 
1:      *                              serves as a template for the rows.
1:      * @param key_column_numbers    The indexes of the key columns (0 based)
1:      * @param remove_duplicates     If true then rows with duplicate keys are 
1:      *                              removed.
1:      * @param keepAfterCommit       If true then the hash table is kept after 
1:      *                              a commit
1:     public DiskHashtable( 
1:     TransactionController   tc,
1:     DataValueDescriptor[]   template,
1:     int[]                   key_column_numbers,
1:     boolean                 remove_duplicates,
1:     boolean                 keepAfterCommit)
1:         this.tc                         = tc;
1:         this.key_column_numbers         = key_column_numbers;
1:         this.remove_duplicates          = remove_duplicates;
1:         LanguageConnectionContext lcc   = (LanguageConnectionContext)
0:             ContextService.getContextOrNull(
1:                 LanguageConnectionContext.CONTEXT_ID);
1: 
1: 
1:         // Create template row used for creating the conglomerate and 
1:         // fetching rows.
1:         row = new DataValueDescriptor[template.length];
1:         {
1: 
1:             if (SanityManager.DEBUG)
1:             {
1:                 // must have an object template for all cols in hash overflow.
1:                 SanityManager.ASSERT(
1:                     row[i] != null, 
1:                     "Template for the hash table must have non-null object");
1:             }
1:         }
1: 
1:         int tempFlags = 
1:             keepAfterCommit ? 
1:             (TransactionController.IS_TEMPORARY | 
1:              TransactionController.IS_KEPT) : 
1:             TransactionController.IS_TEMPORARY;
1:         // create the "base" table of the hash overflow.
1:         rowConglomerateId = 
1:             tc.createConglomerate( 
1:                 "heap",
1:                 template,
1:                 (ColumnOrdering[]) null,
1:                 (Properties) null,
1:                 tempFlags);
1:         // open the "base" table of the hash overflow.
1:         rowConglomerate = 
1:             tc.openConglomerate( 
1:                 rowConglomerateId,
1:                 keepAfterCommit,
1:                 TransactionController.OPENMODE_FORUPDATE,
1:                 TransactionController.MODE_TABLE,
1:                 TransactionController.ISOLATION_NOLOCK/* Single thread only */);
1: 
1:         // create the index on the "hash" base table.  The key of the index
1:         // is the hash code of the row key.  The second column is the 
1:         // RowLocation of the row in the "base" table of the hash overflow.
1:         btreeRow = 
1:             new DataValueDescriptor[] 
1:                 { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
1: 
1:         btreeProps.put("baseConglomerateId", 
1:                 String.valueOf(rowConglomerateId));
1:         btreeProps.put("rowLocationColumn",  
1:                 "1");
1:         btreeProps.put("allowDuplicates",    
1:                 "false"); // Because the row location is part of the key
1:         btreeProps.put("nKeyFields",         
1:                 "2"); // Include the row location column
1:         btreeProps.put("nUniqueColumns",     
1:                 "2"); // Include the row location column
1:         btreeProps.put("maintainParentLinks", 
1:                 "false");
1:         btreeConglomerateId = 
1:             tc.createConglomerate( 
1:                 "BTREE",
1:                 btreeRow,
1:                 (ColumnOrdering[]) null,
1:                 btreeProps,
1:                 tempFlags);
1: 
1:         // open the "index" of the hash overflow.
1:         btreeConglomerate = 
1:             tc.openConglomerate( 
1:                 btreeConglomerateId,
1:                 keepAfterCommit,
1:                 TransactionController.OPENMODE_FORUPDATE,
1:                 TransactionController.MODE_TABLE,
1:                 TransactionController.ISOLATION_NOLOCK /*Single thread only*/ );
1: 
/////////////////////////////////////////////////////////////////////////
1:      * @return true  if the row was added,
1:      *         false if it was not added (because it was a duplicate and we 
1:      *               are eliminating duplicates).
1:     public boolean put(Object key, Object[] row)
1:         if (remove_duplicates || keepStatistics)
1:             isDuplicate = (getRemove(key, false, true) != null);
1:             if (remove_duplicates && isDuplicate)
1: 
1:         // insert the row into the "base" conglomerate.
1:         rowConglomerate.insertAndFetchLocation( 
1:             (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
1: 
1:         // create index row from hashcode and rowlocation just inserted, and
1:         // insert index row into index.
1: 
1:         if (keepStatistics && !isDuplicate)
1: 
1: 
1:      * @param key If the rows only have one key column then the key value. 
1:      *            If there is more than one key column then a KeyHasher
1:      *         the row (DataValueDescriptor[]) if there is exactly one row 
1:      *         with the key, or
1:     public Object get(Object key)
1:         return getRemove(key, false, false);
1:     private Object getRemove(Object key, boolean remove, boolean existenceOnly)
/////////////////////////////////////////////////////////////////////////
1:         ScanController scan = 
1:             tc.openScan( 
1:                 btreeConglomerateId,
1:                 false, // do not hold
1:                 remove ? TransactionController.OPENMODE_FORUPDATE : 0,
1:                 TransactionController.MODE_TABLE,
1:                 TransactionController.ISOLATION_READ_UNCOMMITTED,
1:                 null, // Scan all the columns
1:                 scanKey,
1:                 ScanController.GE,
1:                 (Qualifier[][]) null,
1:                 scanKey,
1:                 ScanController.GT);
1:             while (scan.fetchNext(btreeRow))
1:                 if (rowConglomerate.fetch(
1:                         (RowLocation) btreeRow[1], 
1:                         row, 
1:                         (FormatableBitSet) null /* all columns */)
1:                     if( rowCount == 1)
1:                         // if there is only one matching row just return row. 
0:                         retValue = BackingStoreHashtable.shallowCloneRow( row);
1:                     }
0:                         // if there is more than one row, return a vector of
1:                         // the rows.
1:                         //
1:                             // convert the "single" row retrieved from the
1:                             // first trip in the loop, to a vector with the
1:                             // first two rows.
/////////////////////////////////////////////////////////////////////////
1:     private boolean rowMatches( 
1:     DataValueDescriptor[] row,
1:     Object                key)
commit:f2ee915
/////////////////////////////////////////////////////////////////////////
commit:b223f72
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
1:    Derby - Class org.apache.derby.iapi.store.access.DiskHashtable
1: 
0:    Copyright 2005 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
1: 
1:  */
1: 
1: package org.apache.derby.iapi.store.access;
1: 
1: import java.util.Enumeration;
1: import java.util.NoSuchElementException;
1: import java.util.Properties;
0: import java.util.Vector;
1: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: import org.apache.derby.iapi.types.DataValueDescriptor;
1: import org.apache.derby.iapi.types.SQLInteger;
0: import org.apache.derby.impl.store.access.heap.HeapRowLocation;
1: import org.apache.derby.iapi.types.RowLocation;
1: import org.apache.derby.iapi.services.context.ContextService;
0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1: 
1: /**
0:  * This class is used by BackingStoreHashtable when the BackingStoreHashtable must spill to disk.
0:  * It implements the methods of a hash table: put, get, remove, elements, however it is not implemented
0:  * as a hash table. In order to minimize the amount of unique code it is implemented using a Btree and a heap
0:  * conglomerate. The Btree indexes the hash code of the row key. The actual key may be too long for
0:  * our Btree implementation.
1:  *
1:  * Created: Fri Jan 28 13:58:03 2005
1:  *
0:  * @author <a href="mailto:klebanof@us.ibm.com">Jack Klebanoff</a>
1:  * @version 1.0
1:  */
1: 
1: public class DiskHashtable 
1: {
0:     private final long rowConglomerateId;
0:     private ConglomerateController rowConglomerate;
0:     private final long btreeConglomerateId;
0:     private ConglomerateController btreeConglomerate;
0:     private final DataValueDescriptor[] btreeRow;
0:     private final int[] key_column_numbers;
0:     private final boolean remove_duplicates;
0:     private final TransactionController tc;
0:     private final DataValueDescriptor[] row;
0:     private final DataValueDescriptor[] scanKey = { new SQLInteger()};
0:     private int size;
0:     private boolean keepStatistics;
1: 
1:     /**
1:      * Creates a new <code>DiskHashtable</code> instance.
1:      *
1:      * @param tc
0:      * @param template An array of DataValueDescriptors that serves as a template for the rows.
0:      * @param key_column_numbers The indexes of the key columns (0 based)
0:      * @param remove_duplicates If true then rows with duplicate keys are removed
0:      * @param keepAfterCommit If true then the hash table is kept after a commit
1:      */
0:     public DiskHashtable( TransactionController tc,
0:                           DataValueDescriptor[] template,
0:                           int[] key_column_numbers,
0:                           boolean remove_duplicates,
0:                           boolean keepAfterCommit)
1:         throws StandardException
1:     {
0:         this.tc = tc;
0:         this.key_column_numbers = key_column_numbers;
0:         this.remove_duplicates = remove_duplicates;
0:         LanguageConnectionContext lcc = (LanguageConnectionContext)
0: 				ContextService.getContextOrNull(LanguageConnectionContext.CONTEXT_ID);
1:         keepStatistics = (lcc != null) && lcc.getRunTimeStatisticsMode();
0:         row = new DataValueDescriptor[ template.length];
1:         for( int i = 0; i < row.length; i++)
1:             row[i] = template[i].getNewNull();
0:         int tempFlags = keepAfterCommit ? (TransactionController.IS_TEMPORARY | TransactionController.IS_KEPT)
0:           : TransactionController.IS_TEMPORARY;
1:         
0:         rowConglomerateId = tc.createConglomerate( "heap",
0:                                                    template,
0:                                                    (ColumnOrdering[]) null,
0:                                                    (Properties) null,
0:                                                    tempFlags);
0:         rowConglomerate = tc.openConglomerate( rowConglomerateId,
0:                                                keepAfterCommit,
0:                                                TransactionController.OPENMODE_FORUPDATE,
1:                                                TransactionController.MODE_TABLE,
0:                                                TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
1: 
0:         btreeRow = new DataValueDescriptor[] { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
1:         Properties btreeProps = new Properties();
0:         btreeProps.put( "baseConglomerateId", String.valueOf( rowConglomerateId));
0:         btreeProps.put( "rowLocationColumn", "1");
0:         btreeProps.put( "allowDuplicates", "false"); // Because the row location is part of the key
0:         btreeProps.put( "nKeyFields", "2"); // Include the row location column
0:         btreeProps.put( "nUniqueColumns", "2"); // Include the row location column
0:         btreeProps.put( "maintainParentLinks", "false");
0:         btreeConglomerateId = tc.createConglomerate( "BTREE",
0:                                                      btreeRow,
0:                                                      (ColumnOrdering[]) null,
0:                                                      btreeProps,
0:                                                      tempFlags);
1: 
0:         btreeConglomerate = tc.openConglomerate( btreeConglomerateId,
0:                                                  keepAfterCommit,
0:                                                  TransactionController.OPENMODE_FORUPDATE,
1:                                                  TransactionController.MODE_TABLE,
0:                                                  TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
1:     } // end of constructor
1: 
1:     public void close() throws StandardException
1:     {
1:         btreeConglomerate.close();
1:         rowConglomerate.close();
1:         tc.dropConglomerate( btreeConglomerateId);
1:         tc.dropConglomerate( rowConglomerateId);
1:     } // end of close
1:     
1:     /**
1:      * Put a new row in the overflow structure.
1:      *
1:      * @param row The row to be inserted.
0:      * @param hashCode The row's hash code.
1:      *
0:      * @return true if the row was added,
0:      *         false if it was not added (because it was a duplicate and we are eliminating duplicates).
1:      *
1:      * @exception StandardException standard error policy
1:      */
0:     public boolean put( Object key, Object[] row)
1:         throws StandardException
1:     {
1:         boolean isDuplicate = false;
0:         if( remove_duplicates || keepStatistics)
1:         {
1:             // Go to the work of finding out whether it is a duplicate
0:             isDuplicate = (getRemove( key, false, true) != null);
0:             if( remove_duplicates && isDuplicate)
1:                 return false;
1:         }
0:         rowConglomerate.insertAndFetchLocation( (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
1:         btreeRow[0].setValue( key.hashCode());
1:         btreeConglomerate.insert( btreeRow);
0:         if( keepStatistics && !isDuplicate)
1:             size++;
1:         return true;
1:     } // end of put
1: 
1:     /**
1:      * Get a row from the overflow structure.
1:      *
0:      * @param key If the rows only have one key column then the key value. If there is more than one
0:      *            key column then a KeyHasher
1:      *
1:      * @return null if there is no corresponding row,
0:      *         the row (DataValueDescriptor[]) if there is exactly one row with the key
1:      *         a Vector of all the rows with the key if there is more than one.
1:      *
1:      * @exception StandardException
1:      */
0:     public Object get( Object key)
1:         throws StandardException
1:     {
0:         return getRemove( key, false, false);
1:     }
1: 
0:     private Object getRemove( Object key, boolean remove, boolean existenceOnly)
1:         throws StandardException
1:     {
1:         int hashCode = key.hashCode();
1:         int rowCount = 0;
0:         Object retValue = null;
1: 
1:         scanKey[0].setValue( hashCode);
0:         ScanController scan = tc.openScan( btreeConglomerateId,
0:                                            false, // do not hold
0:                                            remove ? TransactionController.OPENMODE_FORUPDATE : 0,
1:                                            TransactionController.MODE_TABLE,
0:                                            TransactionController.ISOLATION_READ_UNCOMMITTED,
0:                                            null, // Scan all the columns
0:                                            scanKey,
0:                                            ScanController.GE,
1:                                            (Qualifier[][]) null,
0:                                            scanKey,
0:                                            ScanController.GT);
1:         try
1:         {
0:             while( scan.fetchNext( btreeRow))
1:             {
0:                 if( rowConglomerate.fetch( (RowLocation) btreeRow[1], row, (FormatableBitSet) null /* all columns */)
1:                     && rowMatches( row, key))
1:                 {
1:                     if( existenceOnly)
1:                         return this;
1: 
1:                     rowCount++;
0:                     if( rowCount == 1)
0:                         retValue = BackingStoreHashtable.cloneRow( row);
1:                     else 
1:                     {
0:                         Vector v;
0:                         if( rowCount == 2)
1:                         {
0:                             v = new Vector( 2);
0:                             v.add( retValue);
0:                             retValue = v;
1:                         }
1:                         else
0:                             v = (Vector) retValue;
0:                         v.add( BackingStoreHashtable.cloneRow( row));
1:                     }
1:                     if( remove)
1:                     {
1:                         rowConglomerate.delete( (RowLocation) btreeRow[1]);
1:                         scan.delete();
1:                         size--;
1:                     }
1:                     if( remove_duplicates)
1:                         // This must be the only row with the key
1:                         return retValue;
1:                 }
1:             }
1:         }
1:         finally
1:         {
1:             scan.close();
1:         }
1:         return retValue;
1:     } // end of getRemove
1: 
1: 
0:     private boolean rowMatches( DataValueDescriptor[] row,
0:                                 Object key)
1:     {
1:         if( key_column_numbers.length == 1)
1:             return row[ key_column_numbers[0]].equals( key);
1: 
1:         KeyHasher kh = (KeyHasher) key;
1:         for( int i = 0; i < key_column_numbers.length; i++)
1:         {
1:             if( ! row[ key_column_numbers[i]].equals( kh.getObject(i)))
1:                 return false;
1:         }
1:         return true;
1:     } // end of rowMatches
1: 
1:     /**
1:      * remove all rows with a given key from the hash table.
1:      *
1:      * @param key          The key of the rows to remove.
1:      *
1:      * @return The removed row(s).
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1:     public Object remove( Object key)
1: 		throws StandardException
1:     {
1:         return getRemove( key, true, false);
1:     } // end of remove
1: 
1:     /**
1:      * @return The number of rows in the hash table
1:      */
1:     public int size()
1:     {
1:         return size;
1:     }
1:     
1:     /**
1:      * Return an Enumeration that can be used to scan entire table.
1:      * <p>
1:      * RESOLVE - is it worth it to support this routine?
1:      *
1: 	 * @return The Enumeration.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
0:     public Enumeration elements()
1:         throws StandardException
1:     {
1:         return new ElementEnum();
1:     }
1: 
0:     private class ElementEnum implements Enumeration
1:     {
1:         private ScanController scan;
1:         private boolean hasMore;
1: 
1:         ElementEnum()
1:         {
1:             try
1:             {
1:                 scan = tc.openScan( rowConglomerateId,
0:                                     false, // do not hold
1:                                     0, // read only
1:                                     TransactionController.MODE_TABLE,
1:                                     TransactionController.ISOLATION_NOLOCK,
1:                                     (FormatableBitSet) null, // all columns
1:                                     (DataValueDescriptor[]) null, // no start key
1:                                     0, // no start key operator
1:                                     (Qualifier[][]) null,
1:                                     (DataValueDescriptor[]) null, // no stop key
1:                                     0 /* no stop key operator */);
1:                 hasMore = scan.next();
1:                 if( ! hasMore)
1:                 {
1:                     scan.close();
1:                     scan = null;
1:                 }
1:             }
1:             catch( StandardException se)
1:             {
1:                 hasMore = false;
1:                 if( scan != null)
1:                 {
1:                     try
1:                     {
1:                         scan.close();
1:                     }
1:                     catch( StandardException se1){};
1:                     scan = null;
1:                 }
1:             }
1:         } // end of constructor
1: 
1:         public boolean hasMoreElements()
1:         {
1:             return hasMore;
1:         }
1: 
1:         public Object nextElement()
1:         {
1:             if( ! hasMore)
1:                 throw new NoSuchElementException();
1:             try
1:             {
0:                 scan.fetch( row);
0:                 Object retValue =  BackingStoreHashtable.cloneRow( row);
1:                 hasMore = scan.next();
1:                 if( ! hasMore)
1:                 {
1:                     scan.close();
1:                     scan = null;
1:                 }
1: 
1:                 return retValue;
1:             }
1:             catch( StandardException se)
1:             {
1:                 if( scan != null)
1:                 {
1:                     try
1:                     {
1:                         scan.close();
1:                     }
1:                     catch( StandardException se1){};
1:                     scan = null;
1:                 }
1:                 throw new NoSuchElementException();
1:             }
1:         } // end of nextElement
1:     } // end of class ElementEnum
1: }
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:6c9dac8
/////////////////////////////////////////////////////////////////////////
author:Andreas Korneliussen
-------------------------------------------------------------------------------
commit:b7c1f3b
/////////////////////////////////////////////////////////////////////////
0:                     if( rowCount == 1) 
1:                     {
0:                         retValue = BackingStoreHashtable.shallowCloneRow( row);                        
0:                     } 
/////////////////////////////////////////////////////////////////////////
0:                         {
0:                         }
0:                         v.add( BackingStoreHashtable.shallowCloneRow( row));
/////////////////////////////////////////////////////////////////////////
1:                 Object retValue =  BackingStoreHashtable.shallowCloneRow( row);
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Derby - Class org.apache.derby.iapi.store.access.DiskHashtable
0: 
0:    Copyright 2005 The Apache Software Foundation or its licensors, as applicable.
0: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
0: 
0:       http://www.apache.org/licenses/LICENSE-2.0
0: 
0:    Unless required by applicable law or agreed to in writing, software
0:    distributed under the License is distributed on an "AS IS" BASIS,
0:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:    See the License for the specific language governing permissions and
0:    limitations under the License.
0: 
0:  */
0: 
0: package org.apache.derby.iapi.store.access;
0: 
0: import java.util.Enumeration;
0: import java.util.NoSuchElementException;
0: import java.util.Properties;
0: import java.util.Vector;
0: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
0: import org.apache.derby.iapi.types.DataValueDescriptor;
0: import org.apache.derby.iapi.types.SQLInteger;
0: import org.apache.derby.impl.store.access.heap.HeapRowLocation;
0: import org.apache.derby.iapi.types.RowLocation;
0: import org.apache.derby.iapi.services.context.ContextService;
0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
0: 
0: /**
0:  * This class is used by BackingStoreHashtable when the BackingStoreHashtable must spill to disk.
0:  * It implements the methods of a hash table: put, get, remove, elements, however it is not implemented
0:  * as a hash table. In order to minimize the amount of unique code it is implemented using a Btree and a heap
0:  * conglomerate. The Btree indexes the hash code of the row key. The actual key may be too long for
0:  * our Btree implementation.
0:  *
0:  * Created: Fri Jan 28 13:58:03 2005
0:  *
0:  * @author <a href="mailto:klebanof@us.ibm.com">Jack Klebanoff</a>
0:  * @version 1.0
0:  */
0: 
0: public class DiskHashtable 
0: {
0:     private final long rowConglomerateId;
0:     private ConglomerateController rowConglomerate;
0:     private final long btreeConglomerateId;
0:     private ConglomerateController btreeConglomerate;
0:     private final DataValueDescriptor[] btreeRow;
0:     private final int[] key_column_numbers;
0:     private final boolean remove_duplicates;
0:     private final TransactionController tc;
0:     private final DataValueDescriptor[] row;
0:     private final DataValueDescriptor[] scanKey = { new SQLInteger()};
0:     private int size;
0:     private boolean keepStatistics;
0: 
0:     /**
0:      * Creates a new <code>DiskHashtable</code> instance.
0:      *
0:      * @param tc
0:      * @param template An array of DataValueDescriptors that serves as a template for the rows.
0:      * @param key_column_numbers The indexes of the key columns (0 based)
0:      * @param remove_duplicates If true then rows with duplicate keys are removed
0:      * @param keepAfterCommit If true then the hash table is kept after a commit
0:      */
0:     public DiskHashtable( TransactionController tc,
0:                           DataValueDescriptor[] template,
0:                           int[] key_column_numbers,
0:                           boolean remove_duplicates,
0:                           boolean keepAfterCommit)
0:         throws StandardException
0:     {
0:         this.tc = tc;
0:         this.key_column_numbers = key_column_numbers;
0:         this.remove_duplicates = remove_duplicates;
0:         LanguageConnectionContext lcc = (LanguageConnectionContext)
0: 				ContextService.getContextOrNull(LanguageConnectionContext.CONTEXT_ID);
0:         keepStatistics = (lcc != null) && lcc.getRunTimeStatisticsMode();
0:         row = new DataValueDescriptor[ template.length];
0:         for( int i = 0; i < row.length; i++)
0:             row[i] = template[i].getNewNull();
0:         int tempFlags = keepAfterCommit ? (TransactionController.IS_TEMPORARY | TransactionController.IS_KEPT)
0:           : TransactionController.IS_TEMPORARY;
0:         
0:         rowConglomerateId = tc.createConglomerate( "heap",
0:                                                    template,
0:                                                    (ColumnOrdering[]) null,
0:                                                    (Properties) null,
0:                                                    tempFlags);
0:         rowConglomerate = tc.openConglomerate( rowConglomerateId,
0:                                                keepAfterCommit,
0:                                                TransactionController.OPENMODE_FORUPDATE,
0:                                                TransactionController.MODE_TABLE,
0:                                                TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
0: 
0:         btreeRow = new DataValueDescriptor[] { new SQLInteger(), rowConglomerate.newRowLocationTemplate()};
0:         Properties btreeProps = new Properties();
0:         btreeProps.put( "baseConglomerateId", String.valueOf( rowConglomerateId));
0:         btreeProps.put( "rowLocationColumn", "1");
0:         btreeProps.put( "allowDuplicates", "false"); // Because the row location is part of the key
0:         btreeProps.put( "nKeyFields", "2"); // Include the row location column
0:         btreeProps.put( "nUniqueColumns", "2"); // Include the row location column
0:         btreeProps.put( "maintainParentLinks", "false");
0:         btreeConglomerateId = tc.createConglomerate( "BTREE",
0:                                                      btreeRow,
0:                                                      (ColumnOrdering[]) null,
0:                                                      btreeProps,
0:                                                      tempFlags);
0: 
0:         btreeConglomerate = tc.openConglomerate( btreeConglomerateId,
0:                                                  keepAfterCommit,
0:                                                  TransactionController.OPENMODE_FORUPDATE,
0:                                                  TransactionController.MODE_TABLE,
0:                                                  TransactionController.ISOLATION_NOLOCK /* Single thread only */ );
0:     } // end of constructor
0: 
0:     public void close() throws StandardException
0:     {
0:         btreeConglomerate.close();
0:         rowConglomerate.close();
0:         tc.dropConglomerate( btreeConglomerateId);
0:         tc.dropConglomerate( rowConglomerateId);
0:     } // end of close
0:     
0:     /**
0:      * Put a new row in the overflow structure.
0:      *
0:      * @param row The row to be inserted.
0:      *
0:      * @return true if the row was added,
0:      *         false if it was not added (because it was a duplicate and we are eliminating duplicates).
0:      *
0:      * @exception StandardException standard error policy
0:      */
0:     public boolean put( Object key, Object[] row)
0:         throws StandardException
0:     {
0:         boolean isDuplicate = false;
0:         if( remove_duplicates || keepStatistics)
0:         {
0:             // Go to the work of finding out whether it is a duplicate
0:             isDuplicate = (getRemove( key, false, true) != null);
0:             if( remove_duplicates && isDuplicate)
0:                 return false;
0:         }
0:         rowConglomerate.insertAndFetchLocation( (DataValueDescriptor[]) row, (RowLocation) btreeRow[1]);
0:         btreeRow[0].setValue( key.hashCode());
0:         btreeConglomerate.insert( btreeRow);
0:         if( keepStatistics && !isDuplicate)
0:             size++;
0:         return true;
0:     } // end of put
0: 
0:     /**
0:      * Get a row from the overflow structure.
0:      *
0:      * @param key If the rows only have one key column then the key value. If there is more than one
0:      *            key column then a KeyHasher
0:      *
0:      * @return null if there is no corresponding row,
0:      *         the row (DataValueDescriptor[]) if there is exactly one row with the key
0:      *         a Vector of all the rows with the key if there is more than one.
0:      *
0:      * @exception StandardException
0:      */
0:     public Object get( Object key)
0:         throws StandardException
0:     {
0:         return getRemove( key, false, false);
0:     }
0: 
0:     private Object getRemove( Object key, boolean remove, boolean existenceOnly)
0:         throws StandardException
0:     {
0:         int hashCode = key.hashCode();
0:         int rowCount = 0;
0:         Object retValue = null;
0: 
0:         scanKey[0].setValue( hashCode);
0:         ScanController scan = tc.openScan( btreeConglomerateId,
0:                                            false, // do not hold
0:                                            remove ? TransactionController.OPENMODE_FORUPDATE : 0,
0:                                            TransactionController.MODE_TABLE,
0:                                            TransactionController.ISOLATION_READ_UNCOMMITTED,
0:                                            null, // Scan all the columns
0:                                            scanKey,
0:                                            ScanController.GE,
0:                                            (Qualifier[][]) null,
0:                                            scanKey,
0:                                            ScanController.GT);
0:         try
0:         {
0:             while( scan.fetchNext( btreeRow))
0:             {
0:                 if( rowConglomerate.fetch( (RowLocation) btreeRow[1], row, (FormatableBitSet) null /* all columns */)
0:                     && rowMatches( row, key))
0:                 {
0:                     if( existenceOnly)
0:                         return this;
0: 
0:                     rowCount++;
0:                     if( rowCount == 1)
0:                         retValue = BackingStoreHashtable.cloneRow( row);
0:                     else 
0:                     {
0:                         Vector v;
0:                         if( rowCount == 2)
0:                         {
0:                             v = new Vector( 2);
0:                             v.add( retValue);
0:                             retValue = v;
0:                         }
0:                         else
0:                             v = (Vector) retValue;
0:                         v.add( BackingStoreHashtable.cloneRow( row));
0:                     }
0:                     if( remove)
0:                     {
0:                         rowConglomerate.delete( (RowLocation) btreeRow[1]);
0:                         scan.delete();
0:                         size--;
0:                     }
0:                     if( remove_duplicates)
0:                         // This must be the only row with the key
0:                         return retValue;
0:                 }
0:             }
0:         }
0:         finally
0:         {
0:             scan.close();
0:         }
0:         return retValue;
0:     } // end of getRemove
0: 
0: 
0:     private boolean rowMatches( DataValueDescriptor[] row,
0:                                 Object key)
0:     {
0:         if( key_column_numbers.length == 1)
0:             return row[ key_column_numbers[0]].equals( key);
0: 
0:         KeyHasher kh = (KeyHasher) key;
0:         for( int i = 0; i < key_column_numbers.length; i++)
0:         {
0:             if( ! row[ key_column_numbers[i]].equals( kh.getObject(i)))
0:                 return false;
0:         }
0:         return true;
0:     } // end of rowMatches
0: 
0:     /**
0:      * remove all rows with a given key from the hash table.
0:      *
0:      * @param key          The key of the rows to remove.
0:      *
0:      * @return The removed row(s).
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0:     public Object remove( Object key)
0: 		throws StandardException
0:     {
0:         return getRemove( key, true, false);
0:     } // end of remove
0: 
0:     /**
0:      * @return The number of rows in the hash table
0:      */
0:     public int size()
0:     {
0:         return size;
0:     }
0:     
0:     /**
0:      * Return an Enumeration that can be used to scan entire table.
0:      * <p>
0:      * RESOLVE - is it worth it to support this routine?
0:      *
0: 	 * @return The Enumeration.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0:     public Enumeration elements()
0:         throws StandardException
0:     {
0:         return new ElementEnum();
0:     }
0: 
0:     private class ElementEnum implements Enumeration
0:     {
0:         private ScanController scan;
0:         private boolean hasMore;
0: 
0:         ElementEnum()
0:         {
0:             try
0:             {
0:                 scan = tc.openScan( rowConglomerateId,
0:                                     false, // do not hold
0:                                     0, // read only
0:                                     TransactionController.MODE_TABLE,
0:                                     TransactionController.ISOLATION_NOLOCK,
0:                                     (FormatableBitSet) null, // all columns
0:                                     (DataValueDescriptor[]) null, // no start key
0:                                     0, // no start key operator
0:                                     (Qualifier[][]) null,
0:                                     (DataValueDescriptor[]) null, // no stop key
0:                                     0 /* no stop key operator */);
0:                 hasMore = scan.next();
0:                 if( ! hasMore)
0:                 {
0:                     scan.close();
0:                     scan = null;
0:                 }
0:             }
0:             catch( StandardException se)
0:             {
0:                 hasMore = false;
0:                 if( scan != null)
0:                 {
0:                     try
0:                     {
0:                         scan.close();
0:                     }
0:                     catch( StandardException se1){};
0:                     scan = null;
0:                 }
0:             }
0:         } // end of constructor
0: 
0:         public boolean hasMoreElements()
0:         {
0:             return hasMore;
0:         }
0: 
0:         public Object nextElement()
0:         {
0:             if( ! hasMore)
0:                 throw new NoSuchElementException();
0:             try
0:             {
0:                 scan.fetch( row);
0:                 Object retValue =  BackingStoreHashtable.cloneRow( row);
0:                 hasMore = scan.next();
0:                 if( ! hasMore)
0:                 {
0:                     scan.close();
0:                     scan = null;
0:                 }
0: 
0:                 return retValue;
0:             }
0:             catch( StandardException se)
0:             {
0:                 if( scan != null)
0:                 {
0:                     try
0:                     {
0:                         scan.close();
0:                     }
0:                     catch( StandardException se1){};
0:                     scan = null;
0:                 }
0:                 throw new NoSuchElementException();
0:             }
0:         } // end of nextElement
0:     } // end of class ElementEnum
0: }
============================================================================
1:121a532: package org.apache.derbyTesting.functionTests.tests.store;
5:121a532: 
1:121a532: import java.sql.CallableStatement;
1:121a532: import java.sql.Connection;
1:121a532: import java.sql.PreparedStatement;
1:121a532: import java.sql.SQLException;
1:1ae02c9: import java.sql.Statement;
1:1ae02c9: import java.util.Arrays;
1:1ae02c9: import junit.framework.Test;
1:1ae02c9: import org.apache.derbyTesting.junit.BaseTestSuite;
1:1ae02c9: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1:1ae02c9: import org.apache.derbyTesting.junit.DatabasePropertyTestSetup;
1:121a532: 
1:121a532: 
1:121a532: /*
1:121a532: Class org.apache.derbyTesting.functionTests.tests.store.Derby4923Test
1:121a532: 
1:121a532: Licensed to the Apache Software Foundation (ASF) under one or more
1:121a532: contributor license agreements.  See the NOTICE file distributed with
1:121a532: this work for additional information regarding copyright ownership.
1:121a532: The ASF licenses this file to you under the Apache License, Version 2.0
1:121a532: (the "License"); you may not use this file except in compliance with
1:121a532: the License.  You may obtain a copy of the License at
1:121a532: 
1:121a532:    http://www.apache.org/licenses/LICENSE-2.0
1:121a532: 
1:121a532: Unless required by applicable law or agreed to in writing, software
1:121a532: distributed under the License is distributed on an "AS IS" BASIS,
1:121a532: WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:121a532: See the License for the specific language governing permissions and
1:121a532: limitations under the License.
1:121a532: 
1:121a532: */
1:121a532: 
1:121a532: 
1:121a532: /**
1:121a532: 
1:121a532: Test to reproduce DERBY-4923, An expanding update to the 2nd piece of a long
1:121a532: row which is on a page with 0 bytes free fails with an nospc.U error.  The
1:121a532: code should always reserve enough space in this case to in the worst case
1:121a532: change the row piece to another long pointer to another page.
1:121a532: 
1:121a532: **/
1:121a532: 
1:121a532: public class Derby4923Test extends StoreBaseTest
1:121a532: {
1:121a532:     /**************************************************************************
1:121a532:      * Fields of the class
1:121a532:      **************************************************************************
1:121a532:      */
1:121a532: 
1:121a532:     /**************************************************************************
1:121a532:      * Constructors for This class:
1:121a532:      **************************************************************************
1:121a532:      */
1:121a532: 
1:121a532:     /**************************************************************************
1:121a532:      * Private/Protected methods of This class:
1:121a532:      **************************************************************************
1:121a532:      */
1:121a532: 
1:121a532:     /**************************************************************************
1:121a532:      * Public Methods of This class:
1:121a532:      **************************************************************************
1:121a532:      */
1:121a532: 
1:121a532:     /**************************************************************************
1:121a532:      * Public Methods of XXXX class:
1:121a532:      **************************************************************************
1:121a532:      */
1:121a532: 
1:121a532:     public Derby4923Test(String name) 
1:121a532:     {
1:121a532:         super(name);
1:121a532:     }
1:121a532: 
1:121a532:     
1:121a532:     /**
1:121a532:      * DERBY-4923 test case
1:121a532:      * <p>
1:121a532:      * The update error occurs with the following:
1:121a532:      *   o update of a long row which requires an update on it's overflow page
1:121a532:      *   o 4k page
1:121a532:      *   o the long row has 2 pieces, the second is a blob column and is 
1:121a532:      *     located on an overflow page.
1:121a532:      *   o the overflow page has no space on the page.
1:121a532:      *   o the row id's are large enough such that they require 2 bytes to 
1:121a532:      *     store (ie. greater than 64)
1:121a532:      *   o the piece located on the page already takes up the minimum size
1:121a532:      *     allowed for a row piece on an overflow page.
1:121a532:      *
1:121a532:      *
1:121a532:      * In order to get to this one needs multiple rows on the overflow page,
1:121a532:      * so that they can eat up the free space on the page.  The original user
1:121a532:      * report gave me multiple occurences of the issue.  It always was
1:121a532:      * on a overflow page that was full (sometimes 2 and 3 rows).  The reported
1:121a532:      * case was 4k pages and I was not able to reproduce on 32k.  The updage
1:121a532:      * of the blob column was greater than 4k.
1:121a532:      *
1:121a532:      * The test does the following:
1:121a532:      * o drop/create table
1:121a532:      * o insert 2000 small rows which will fill up a few pages with rows and
1:121a532:      *   make the next record id on those rows bigger than 64.
1:121a532:      * o delete all those rows.
1:121a532:      * o run compress to reclaim the space on all the pages and free up the 
1:121a532:      *   pages so they can be used for overflow pages.
1:121a532:      * o insert 3 short rows that will all end up on same main page.
1:121a532:      * o expand row 1 so that it takes up most of main page.
1:121a532:      * o update row 2 such that it becomes a long row with just the blob column
1:121a532:      *   on an overflow page.  And subsequently shrink the overflow portion
1:121a532:      *   such that it takes the minimum space allowed on an overflow page.
1:121a532:      *   end up on same overflow page.
1:121a532:      * o update row 3 such that it becomes a long row with overflow on same 
1:121a532:      *   page as row 2 with just the blob column
1:121a532:      *   on an overflow page.  Use a length so that it uses all free space on 
1:121a532:      *   the overflow page.
1:121a532:      * o Now update row 2 blob to make it bigger than 4k which causes the
1:121a532:      *   bug.
1:121a532:      **/
1:121a532:     public void testDERBY_4923()
1:121a532:         throws SQLException, java.lang.InterruptedException
1:121a532:     {
1:121a532: 
1:121a532:         // page 0 - container info/bit map, does not affect test
1:121a532: 
1:121a532:         // page 1 - 
1:121a532:         // row on it that can never be deleted so this page never can be
1:121a532:         // made free.
1:121a532: 
1:121a532:         Statement stmt = createStatement();
1:121a532: 
1:121a532:         PreparedStatement insert_stmt = 
1:121a532:             prepareStatement("INSERT INTO TESTBADUPDATE VALUES(?, ?)");
1:121a532: 
1:121a532:         PreparedStatement delete_stmt = 
1:121a532:             prepareStatement("DELETE FROM TESTBADUPDATE");
1:121a532: 
1:121a532:         PreparedStatement update_stmt = 
1:121a532:             prepareStatement("UPDATE TESTBADUPDATE set value = ? where id = ?");
1:121a532: 
1:121a532:         // insert a bunch of rows to use up record id's on pages and then delete
1:121a532:         // them all so that free pages have large record ids.
1:121a532:         //
1:121a532: 
1:121a532:         byte[] pad_blob = new byte[1];
1:121a532:         for (int i = 1000; i < 2000; i++)
1:121a532:         {
1:121a532:             insert_stmt.setInt(     1, i);
1:121a532:             insert_stmt.setBytes(   2, pad_blob);
1:121a532:             insert_stmt.executeUpdate();
1:121a532:         }
1:121a532:         commit();
1:121a532:         delete_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532:         // reclaim all the space from the deletes but don't shrink the file
1:121a532:         // as we want pages left with big record id's.
1:121a532:         callCompress(
1:121a532:             stmt.getConnection(),
1:121a532:             "APP",
1:121a532:             "TESTBADUPDATE",
1:121a532:             true,
1:121a532:             true,
1:121a532:             false,
1:121a532:             true);
1:121a532:         commit();
1:121a532: 
1:121a532:         // insert 3 rows that will fit on same main page.
1:121a532:         pad_blob = new byte[1];
1:121a532: 
1:121a532:         for (int i = 1; i < 4; i++)
1:121a532:         {
1:121a532:             insert_stmt.setInt(     1, i);
1:121a532:             insert_stmt.setBytes(   2, pad_blob);
1:121a532:             insert_stmt.executeUpdate();
1:121a532:         }
1:121a532: 
1:121a532:         commit();
1:121a532: 
1:121a532:         // expand row id 1 such that it fills most of the page
1:121a532: 
1:121a532:         pad_blob = new byte[3000];
1:121a532:         Arrays.fill(pad_blob, (byte) 0x70);
1:121a532:         update_stmt.setBytes(   1, pad_blob);
1:121a532:         update_stmt.setInt(     2, 1);
1:121a532:         update_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532: 
1:121a532:         // now expand rows 2 and 3 each becomes a "long row", with
1:121a532:         // first column on main page with a pointer to overflow page, and each
1:121a532:         // 2nd column exists in full on the overflow page.  Want
1:121a532:         // each overflow to end up on same page.  
1:121a532:         //
1:121a532: 
1:121a532:         // xpand row 2 so it becomes a long row and then shrink the space back
1:121a532:         // on overflow page.
1:121a532:         pad_blob = new byte[1500];
1:121a532:         Arrays.fill(pad_blob, (byte) 0x70);
1:121a532:         update_stmt.setBytes(   1, pad_blob);
1:121a532:         update_stmt.setInt(     2, 2);
1:121a532:         update_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532:         pad_blob = new byte[4];
1:121a532:         Arrays.fill(pad_blob, (byte) 0x70);
1:121a532:         update_stmt.setBytes(   1, pad_blob);
1:121a532:         update_stmt.setInt(     2, 2);
1:121a532:         update_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532:         /*
1:121a532:         callCompress(
1:121a532:             stmt.getConnection(),
1:121a532:             "APP",
1:121a532:             "TESTBADUPDATE",
1:121a532:             true,
1:121a532:             true,
1:121a532:             false,
1:121a532:             true);
1:121a532:         */
1:121a532: 
1:121a532:         // xpand row 3 so it becomes a long row and fills the overflow page
1:121a532:         // on overflow page.
1:121a532:         pad_blob = new byte[3988];
1:121a532:         Arrays.fill(pad_blob, (byte) 0x70);
1:121a532:         update_stmt.setBytes(   1, pad_blob);
1:121a532:         update_stmt.setInt(     2, 3);
1:121a532:         update_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532:         // see if we can update the column of row 2 to expand it, this causes
1:121a532:         // the bug.
1:121a532:         pad_blob = new byte[19680];
1:121a532:         Arrays.fill(pad_blob, (byte) 0x70);
1:121a532:         update_stmt.setBytes(   1, pad_blob);
1:121a532:         update_stmt.setInt(     2, 2);
1:121a532:         update_stmt.executeUpdate();
1:121a532:         commit();
1:121a532: 
1:121a532:         stmt.close();
1:121a532:         insert_stmt.close();
1:121a532:         update_stmt.close();
1:121a532:     }
1:121a532: 
1:121a532: 
1:121a532:     /**
1:121a532:      * call SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE() system procedure.
1:121a532:      * <p>
1:121a532:      * Utility test function to call the system procedure.
1:121a532:      *
1:121a532:      **/
1:121a532:     private void callCompress(
1:121a532:     Connection  conn,
1:121a532:     String      schemaName,
1:121a532:     String      tableName,
1:121a532:     boolean     purgeRows,
1:121a532:     boolean     defragmentRows,
1:121a532:     boolean     truncateEnd,
1:121a532:     boolean     commit_operation)
1:121a532:         throws SQLException
1:121a532:     {
1:121a532:         CallableStatement cstmt = 
1:121a532:             conn.prepareCall(
1:121a532:                 "call SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE(?, ?, ?, ?, ?)");
1:121a532:         cstmt.setString(1, schemaName);
1:121a532:         cstmt.setString(2, tableName);
1:121a532:         cstmt.setInt   (3, purgeRows      ? 1 : 0);
1:121a532:         cstmt.setInt   (4, defragmentRows ? 1 : 0);
1:121a532:         cstmt.setInt   (5, truncateEnd    ? 1 : 0);
1:121a532: 
1:121a532:         cstmt.execute();
1:121a532: 
1:121a532:         if (commit_operation)
1:121a532:             conn.commit();
1:121a532:     }
1:121a532: 
1:121a532:     
1:121a532:     protected static Test baseSuite(String name) 
1:121a532:     {
1:1ae02c9:         BaseTestSuite suite = new BaseTestSuite(name);
1:121a532:         suite.addTestSuite(Derby4923Test.class);
1:121a532:         return new CleanDatabaseTestSetup(
1:121a532:                 DatabasePropertyTestSetup.setLockTimeouts(suite, 2, 4)) 
1:121a532:         {
1:121a532:             /**
1:121a532:              * Creates the tables used in the test cases.
1:121a532:              * @exception SQLException if a database error occurs
1:121a532:              */
1:121a532:             protected void decorateSQL(Statement stmt) throws SQLException
1:121a532:             {
1:121a532:                 Connection conn = stmt.getConnection();
1:121a532: 
1:121a532:                 CallableStatement cSt = 
1:121a532:                     conn.prepareCall(
1:121a532:                         "call SYSCS_UTIL.SYSCS_SET_DATABASE_PROPERTY(" +
1:121a532:                         "'derby.storage.pageSize', '4096')");
1:121a532:                 cSt.execute();
1:121a532: 
1:121a532:                 // create a table, with pagesize setting it will be 4k page size
1:121a532:                 stmt.executeUpdate(
1:121a532:                     "CREATE TABLE TESTBADUPDATE (id int, value blob(1M))");
1:121a532: 
1:121a532: 
1:121a532:                 conn.setAutoCommit(false);
1:121a532:             }
1:121a532:         };
1:121a532:     }
1:121a532: 
1:121a532:     public static Test suite() 
1:121a532:     {
1:1ae02c9:         BaseTestSuite suite = new BaseTestSuite("Derby4923Test");
1:121a532:         suite.addTest(baseSuite("Derby4923Test:embedded"));
1:121a532:         return suite;
1:121a532:     }
1:121a532: }
============================================================================
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:1ae02c9
/////////////////////////////////////////////////////////////////////////
1: import java.sql.Statement;
1: import java.util.Arrays;
1: import junit.framework.Test;
1: import org.apache.derbyTesting.junit.BaseTestSuite;
1: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1: import org.apache.derbyTesting.junit.DatabasePropertyTestSetup;
/////////////////////////////////////////////////////////////////////////
1:         BaseTestSuite suite = new BaseTestSuite(name);
/////////////////////////////////////////////////////////////////////////
1:         BaseTestSuite suite = new BaseTestSuite("Derby4923Test");
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:121a532
/////////////////////////////////////////////////////////////////////////
1: package org.apache.derbyTesting.functionTests.tests.store;
1: 
0: import org.apache.derbyTesting.junit.BaseJDBCTestCase;
0: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
0: import org.apache.derbyTesting.junit.DatabasePropertyTestSetup;
0: import org.apache.derbyTesting.junit.JDBC;
0: import org.apache.derbyTesting.junit.TestConfiguration;
1: 
0: import org.apache.derby.shared.common.sanity.SanityManager;
1: 
0: import junit.framework.Assert;
0: import junit.framework.Test;
0: import junit.framework.TestSuite;
1: 
0: import java.util.Arrays;
1: 
1: import java.sql.CallableStatement;
1: import java.sql.Connection;
1: import java.sql.PreparedStatement;
0: import java.sql.ResultSet;
0: import java.sql.Statement;
1: import java.sql.SQLException;
1: 
1: 
1: /*
1: Class org.apache.derbyTesting.functionTests.tests.store.Derby4923Test
1: 
1: Licensed to the Apache Software Foundation (ASF) under one or more
1: contributor license agreements.  See the NOTICE file distributed with
1: this work for additional information regarding copyright ownership.
1: The ASF licenses this file to you under the Apache License, Version 2.0
1: (the "License"); you may not use this file except in compliance with
1: the License.  You may obtain a copy of the License at
1: 
1:    http://www.apache.org/licenses/LICENSE-2.0
1: 
1: Unless required by applicable law or agreed to in writing, software
1: distributed under the License is distributed on an "AS IS" BASIS,
1: WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1: See the License for the specific language governing permissions and
1: limitations under the License.
1: 
1: */
1: 
1: 
1: /**
1: 
1: Test to reproduce DERBY-4923, An expanding update to the 2nd piece of a long
1: row which is on a page with 0 bytes free fails with an nospc.U error.  The
1: code should always reserve enough space in this case to in the worst case
1: change the row piece to another long pointer to another page.
1: 
1: **/
1: 
1: public class Derby4923Test extends StoreBaseTest
1: {
1:     /**************************************************************************
1:      * Fields of the class
1:      **************************************************************************
1:      */
1: 
1:     /**************************************************************************
1:      * Constructors for This class:
1:      **************************************************************************
1:      */
1: 
1:     /**************************************************************************
1:      * Private/Protected methods of This class:
1:      **************************************************************************
1:      */
1: 
1:     /**************************************************************************
1:      * Public Methods of This class:
1:      **************************************************************************
1:      */
1: 
1:     /**************************************************************************
1:      * Public Methods of XXXX class:
1:      **************************************************************************
1:      */
1: 
1:     public Derby4923Test(String name) 
1:     {
1:         super(name);
1:     }
1: 
1:     
1:     /**
1:      * DERBY-4923 test case
1:      * <p>
1:      * The update error occurs with the following:
1:      *   o update of a long row which requires an update on it's overflow page
1:      *   o 4k page
1:      *   o the long row has 2 pieces, the second is a blob column and is 
1:      *     located on an overflow page.
1:      *   o the overflow page has no space on the page.
1:      *   o the row id's are large enough such that they require 2 bytes to 
1:      *     store (ie. greater than 64)
1:      *   o the piece located on the page already takes up the minimum size
1:      *     allowed for a row piece on an overflow page.
1:      *
1:      *
1:      * In order to get to this one needs multiple rows on the overflow page,
1:      * so that they can eat up the free space on the page.  The original user
1:      * report gave me multiple occurences of the issue.  It always was
1:      * on a overflow page that was full (sometimes 2 and 3 rows).  The reported
1:      * case was 4k pages and I was not able to reproduce on 32k.  The updage
1:      * of the blob column was greater than 4k.
1:      *
1:      * The test does the following:
1:      * o drop/create table
1:      * o insert 2000 small rows which will fill up a few pages with rows and
1:      *   make the next record id on those rows bigger than 64.
1:      * o delete all those rows.
1:      * o run compress to reclaim the space on all the pages and free up the 
1:      *   pages so they can be used for overflow pages.
1:      * o insert 3 short rows that will all end up on same main page.
1:      * o expand row 1 so that it takes up most of main page.
1:      * o update row 2 such that it becomes a long row with just the blob column
1:      *   on an overflow page.  And subsequently shrink the overflow portion
1:      *   such that it takes the minimum space allowed on an overflow page.
1:      *   end up on same overflow page.
1:      * o update row 3 such that it becomes a long row with overflow on same 
1:      *   page as row 2 with just the blob column
1:      *   on an overflow page.  Use a length so that it uses all free space on 
1:      *   the overflow page.
1:      * o Now update row 2 blob to make it bigger than 4k which causes the
1:      *   bug.
1:      **/
1:     public void testDERBY_4923()
1:         throws SQLException, java.lang.InterruptedException
1:     {
1: 
1:         // page 0 - container info/bit map, does not affect test
1: 
1:         // page 1 - 
1:         // row on it that can never be deleted so this page never can be
1:         // made free.
1: 
1:         Statement stmt = createStatement();
1: 
1:         PreparedStatement insert_stmt = 
1:             prepareStatement("INSERT INTO TESTBADUPDATE VALUES(?, ?)");
1: 
1:         PreparedStatement delete_stmt = 
1:             prepareStatement("DELETE FROM TESTBADUPDATE");
1: 
1:         PreparedStatement update_stmt = 
1:             prepareStatement("UPDATE TESTBADUPDATE set value = ? where id = ?");
1: 
1:         // insert a bunch of rows to use up record id's on pages and then delete
1:         // them all so that free pages have large record ids.
1:         //
1: 
1:         byte[] pad_blob = new byte[1];
1:         for (int i = 1000; i < 2000; i++)
1:         {
1:             insert_stmt.setInt(     1, i);
1:             insert_stmt.setBytes(   2, pad_blob);
1:             insert_stmt.executeUpdate();
1:         }
1:         commit();
1:         delete_stmt.executeUpdate();
1:         commit();
1: 
1:         // reclaim all the space from the deletes but don't shrink the file
1:         // as we want pages left with big record id's.
1:         callCompress(
1:             stmt.getConnection(),
1:             "APP",
1:             "TESTBADUPDATE",
1:             true,
1:             true,
1:             false,
1:             true);
1:         commit();
1: 
1:         // insert 3 rows that will fit on same main page.
1:         pad_blob = new byte[1];
1: 
1:         for (int i = 1; i < 4; i++)
1:         {
1:             insert_stmt.setInt(     1, i);
1:             insert_stmt.setBytes(   2, pad_blob);
1:             insert_stmt.executeUpdate();
1:         }
1: 
1:         commit();
1: 
1:         // expand row id 1 such that it fills most of the page
1: 
1:         pad_blob = new byte[3000];
1:         Arrays.fill(pad_blob, (byte) 0x70);
1:         update_stmt.setBytes(   1, pad_blob);
1:         update_stmt.setInt(     2, 1);
1:         update_stmt.executeUpdate();
1:         commit();
1: 
1: 
1:         // now expand rows 2 and 3 each becomes a "long row", with
1:         // first column on main page with a pointer to overflow page, and each
1:         // 2nd column exists in full on the overflow page.  Want
1:         // each overflow to end up on same page.  
1:         //
1: 
1:         // xpand row 2 so it becomes a long row and then shrink the space back
1:         // on overflow page.
1:         pad_blob = new byte[1500];
1:         Arrays.fill(pad_blob, (byte) 0x70);
1:         update_stmt.setBytes(   1, pad_blob);
1:         update_stmt.setInt(     2, 2);
1:         update_stmt.executeUpdate();
1:         commit();
1: 
1:         pad_blob = new byte[4];
1:         Arrays.fill(pad_blob, (byte) 0x70);
1:         update_stmt.setBytes(   1, pad_blob);
1:         update_stmt.setInt(     2, 2);
1:         update_stmt.executeUpdate();
1:         commit();
1: 
1:         /*
1:         callCompress(
1:             stmt.getConnection(),
1:             "APP",
1:             "TESTBADUPDATE",
1:             true,
1:             true,
1:             false,
1:             true);
1:         */
1: 
1:         // xpand row 3 so it becomes a long row and fills the overflow page
1:         // on overflow page.
1:         pad_blob = new byte[3988];
1:         Arrays.fill(pad_blob, (byte) 0x70);
1:         update_stmt.setBytes(   1, pad_blob);
1:         update_stmt.setInt(     2, 3);
1:         update_stmt.executeUpdate();
1:         commit();
1: 
1:         // see if we can update the column of row 2 to expand it, this causes
1:         // the bug.
1:         pad_blob = new byte[19680];
1:         Arrays.fill(pad_blob, (byte) 0x70);
1:         update_stmt.setBytes(   1, pad_blob);
1:         update_stmt.setInt(     2, 2);
1:         update_stmt.executeUpdate();
1:         commit();
1: 
1:         stmt.close();
1:         insert_stmt.close();
1:         update_stmt.close();
1:     }
1: 
1: 
1:     /**
1:      * call SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE() system procedure.
1:      * <p>
1:      * Utility test function to call the system procedure.
1:      *
1:      **/
1:     private void callCompress(
1:     Connection  conn,
1:     String      schemaName,
1:     String      tableName,
1:     boolean     purgeRows,
1:     boolean     defragmentRows,
1:     boolean     truncateEnd,
1:     boolean     commit_operation)
1:         throws SQLException
1:     {
1:         CallableStatement cstmt = 
1:             conn.prepareCall(
1:                 "call SYSCS_UTIL.SYSCS_INPLACE_COMPRESS_TABLE(?, ?, ?, ?, ?)");
1:         cstmt.setString(1, schemaName);
1:         cstmt.setString(2, tableName);
1:         cstmt.setInt   (3, purgeRows      ? 1 : 0);
1:         cstmt.setInt   (4, defragmentRows ? 1 : 0);
1:         cstmt.setInt   (5, truncateEnd    ? 1 : 0);
1: 
1:         cstmt.execute();
1: 
1:         if (commit_operation)
1:             conn.commit();
1:     }
1: 
1:     
1:     protected static Test baseSuite(String name) 
1:     {
0:         TestSuite suite = new TestSuite(name);
1:         suite.addTestSuite(Derby4923Test.class);
1:         return new CleanDatabaseTestSetup(
1:                 DatabasePropertyTestSetup.setLockTimeouts(suite, 2, 4)) 
1:         {
1:             /**
1:              * Creates the tables used in the test cases.
1:              * @exception SQLException if a database error occurs
1:              */
1:             protected void decorateSQL(Statement stmt) throws SQLException
1:             {
1:                 Connection conn = stmt.getConnection();
1: 
1:                 CallableStatement cSt = 
1:                     conn.prepareCall(
1:                         "call SYSCS_UTIL.SYSCS_SET_DATABASE_PROPERTY(" +
1:                         "'derby.storage.pageSize', '4096')");
1:                 cSt.execute();
1: 
1:                 // create a table, with pagesize setting it will be 4k page size
1:                 stmt.executeUpdate(
1:                     "CREATE TABLE TESTBADUPDATE (id int, value blob(1M))");
1: 
1: 
1:                 conn.setAutoCommit(false);
1:             }
1:         };
1:     }
1: 
1:     public static Test suite() 
1:     {
0:         TestSuite suite = new TestSuite("Derby4923Test");
1:         suite.addTest(baseSuite("Derby4923Test:embedded"));
1:         return suite;
1:     }
1: }
============================================================================
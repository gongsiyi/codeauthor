1:eac0369: /*
1:345de35: 
1:345de35:    Derby - Class org.apache.derby.impl.sql.execute.DeleteCascadeResultSet
1:345de35: 
1:f6123ee:    Licensed to the Apache Software Foundation (ASF) under one or more
1:f6123ee:    contributor license agreements.  See the NOTICE file distributed with
1:f6123ee:    this work for additional information regarding copyright ownership.
1:f6123ee:    The ASF licenses this file to you under the Apache License, Version 2.0
1:f6123ee:    (the "License"); you may not use this file except in compliance with
1:f6123ee:    the License.  You may obtain a copy of the License at
1:345de35: 
1:345de35:       http://www.apache.org/licenses/LICENSE-2.0
1:345de35: 
1:345de35:    Unless required by applicable law or agreed to in writing, software
1:345de35:    distributed under the License is distributed on an "AS IS" BASIS,
1:345de35:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:345de35:    See the License for the specific language governing permissions and
1:345de35:    limitations under the License.
6:eac0369: 
2:eac0369:  */
1:eac0369: 
1:eac0369: package org.apache.derby.impl.sql.execute;
1:eac0369: 
1:45da2f5: import java.util.Enumeration;
1:45da2f5: import java.util.HashMap;
1:45da2f5: import java.util.Vector;
1:45da2f5: import org.apache.derby.catalog.UUID;
1:eac0369: import org.apache.derby.iapi.error.StandardException;
1:45da2f5: import org.apache.derby.iapi.reference.SQLState;
1:eac0369: import org.apache.derby.iapi.sql.Activation;
1:eac0369: import org.apache.derby.iapi.sql.ResultSet;
1:45da2f5: import org.apache.derby.iapi.sql.execute.ConstantAction;
1:45da2f5: import org.apache.derby.iapi.sql.execute.CursorResultSet;
1:eac0369: import org.apache.derby.iapi.sql.execute.ExecRow;
1:45da2f5: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
1:eac0369: import org.apache.derby.iapi.sql.execute.TemporaryRowHolder;
1:45da2f5: import org.apache.derby.iapi.store.access.StaticCompiledOpenConglomInfo;
1:eac0369: 
2:eac0369: /**
1:eac0369:  * Delete the rows from the specified  base table and executes delete/update
1:eac0369:  * on dependent tables depending on the referential actions specified.
1:eac0369:  * Note:(beetle:5197) Dependent Resultsets of DeleteCascade Resultset can  in
1:eac0369:  * any one of the multiple resultsets generated for the same table because of
1:eac0369:  * multiple foreign key relationship to  the same table. At the bind time ,
1:eac0369:  * dependents are binded only once per table.
1:eac0369:  * We can not depend on mainNodeTable Flag to fire actions on dependents,
1:eac0369:  * it should be done based on whether the resultset has dependent resultsets or not.
1:eac0369:  *
1:eac0369:  */
1:ca6ed17: class DeleteCascadeResultSet extends DeleteResultSet
1:eac0369: {
1:eac0369: 
1:ca6ed17:     ResultSet[] dependentResultSets;
1:eac0369: 	private int noDependents =0;
1:45da2f5:     private final String resultSetId;
1:eac0369: 	private boolean mainNodeForTable = true;
1:eac0369: 	private boolean affectedRows = false;
1:eac0369: 	private int tempRowHolderId; //this result sets temporary row holder id 
1:eac0369: 
1:eac0369:     /*
1:eac0369:      * class interface
1:eac0369: 	 * @exception StandardException		Thrown on error
1:eac0369:      */
1:c69c8b0:     public DeleteCascadeResultSet
1:eac0369: 	(
1:eac0369: 		NoPutResultSet		source,
1:eac0369: 		Activation			activation,
1:eac0369: 		int 				constantActionItem,
1:eac0369: 		ResultSet[]			dependentResultSets,
1:eac0369: 		String  	        resultSetId
1:eac0369: 	)
1:eac0369: 		throws StandardException
1:eac0369:     {
1:eac0369: 
1:eac0369: 		super(source,
1:eac0369: 			  ((constantActionItem == -1) ?activation.getConstantAction() :
1:eac0369: 			  (ConstantAction)activation.getPreparedStatement().getSavedObject(constantActionItem)),
1:eac0369: 			  activation);
1:eac0369: 
1:c69c8b0: 		ConstantAction passedInConstantAction;
1:c69c8b0: 		if(constantActionItem == -1)
1:c69c8b0: 			passedInConstantAction = activation.getConstantAction(); //root table
1:c69c8b0: 		else
1:eac0369: 		{
1:c69c8b0: 			passedInConstantAction = 
1:c69c8b0: 				(ConstantAction) activation.getPreparedStatement().getSavedObject(constantActionItem);
1:eac0369: 			resultDescription = constants.resultDescription;
1:eac0369: 		}
1:eac0369: 		cascadeDelete = true;
1:eac0369: 		this.resultSetId = resultSetId;
1:eac0369: 		
1:eac0369: 		if(dependentResultSets != null)
1:eac0369: 		{
1:eac0369: 			noDependents = dependentResultSets.length;
1:eac0369: 			this.dependentResultSets = dependentResultSets;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 	/**
1:94f158a: 		@exception StandardException Standard Derby error policy
1:eac0369: 	*/
1:801cf0d:     @Override
1:801cf0d:     @SuppressWarnings({"UseOfObsoleteCollectionType", "empty-statement"})
1:eac0369: 	public void open() throws StandardException
1:eac0369: 	{
1:eac0369: 
1:eac0369: 
1:eac0369: 		try{
1:eac0369: 			setup();
1:eac0369: 			if(isMultipleDeletePathsExist())
1:eac0369: 			{
1:eac0369: 				setRowHoldersTypeToUniqueStream();
1:eac0369: 				//collect until there are no more rows to found
1:801cf0d:                 while(collectAffectedRows(false)) {};
1:eac0369: 			}else
1:eac0369: 			{
1:eac0369: 				collectAffectedRows(false);
1:eac0369: 			}
1:eac0369: 			if (! affectedRows)
1:eac0369: 			{
1:eac0369: 				activation.addWarning(
1:eac0369: 							StandardException.newWarning(
1:eac0369: 								SQLState.LANG_NO_ROW_FOUND));
1:eac0369: 			}
1:eac0369: 
1:45da2f5:             runFkChecker(true); // check for only RESTRICT referential
1:18a6fb2:                                       // action rule violations
1:45da2f5:             HashMap<String,String> mntHashTable =
1:45da2f5:                 new HashMap<String,String>(); // Hash table to identify multiple
1:45da2f5:                                               // node for same table cases.
1:eac0369: 			mergeRowHolders(mntHashTable);
1:eac0369: 			fireBeforeTriggers(mntHashTable);
1:45da2f5:             deleteDeferredRows();
1:45da2f5:             runFkChecker(false); // check for all constraint violations
1:eac0369: 			rowChangerFinish();
1:eac0369: 			fireAfterTriggers();
1:eac0369: 		}finally
1:eac0369: 		{
1:67549f0: 			cleanUp();
1:67549f0: 
1:eac0369: 			//clear the parent result sets hash table
1:eac0369: 			activation.clearParentResultSets();
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		endTime = getCurrentTimeMillis();
1:eac0369: 
1:eac0369:     }
1:eac0369: 	
1:eac0369: 
1:eac0369: 	/**
1:eac0369: 	 *Gathers the rows that needs to be deleted/updated 
1:eac0369: 	 *and creates a temporary resulsets that will be passed
1:eac0369: 	 *as source to its  dependent result sets.
1:eac0369: 	 */
1:801cf0d:     @Override @SuppressWarnings("UseOfObsoleteCollectionType")
1:eac0369: 	void  setup() throws StandardException
1:eac0369: 	{
1:eac0369: 
1:eac0369: 		/* Cache query plan text for source, before it gets blown away */
1:eac0369: 		if (lcc.getRunTimeStatisticsMode())
1:eac0369: 		{
1:eac0369: 			/* savedSource nulled after run time statistics generation */
1:eac0369: 			savedSource = source;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		super.setup();
1:eac0369: 		activation.setParentResultSet(rowHolder, resultSetId);
1:801cf0d:         Vector<TemporaryRowHolder> sVector =
1:801cf0d:                 activation.getParentResultSet(resultSetId);
1:eac0369: 		tempRowHolderId = sVector.size() -1;
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).setup();
1:eac0369: 			}else
1:eac0369: 			{
1:eac0369: 				((DeleteCascadeResultSet) dependentResultSets[i]).setup();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 	boolean  collectAffectedRows(boolean rowsFound) throws StandardException
1:eac0369: 	{
1:eac0369: 		if(super.collectAffectedRows())
1:eac0369: 		{
1:eac0369: 			affectedRows = true;
1:eac0369: 			rowsFound = true;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				if(((UpdateResultSet)dependentResultSets[i]).collectAffectedRows())
1:eac0369: 					rowsFound = true;
1:eac0369: 			}else
1:eac0369: 			{
1:eac0369: 				if(((DeleteCascadeResultSet)
1:eac0369: 					dependentResultSets[i]).collectAffectedRows(rowsFound))
1:eac0369: 					rowsFound = true;
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return rowsFound;
1:eac0369: 	}
1:eac0369: 
1:45da2f5:     void fireBeforeTriggers(HashMap<String, String> msht)
1:45da2f5:             throws StandardException
1:eac0369: 	{
1:eac0369: 		if(!mainNodeForTable) 
1:eac0369: 		{
1:eac0369: 			/*to handle case where no table node had qualified rows, in which case no node for
1:eac0369: 			 * the table get marked as mainNodeFor table , one way to identify
1:eac0369: 			 * such case is to look at the mutinode hash table and see if the result id exist ,
1:eac0369: 			 *if it does not means none of the table nodes resulsets got marked
1:eac0369: 			 * as main node for table. If that is the case we mark this
1:eac0369: 			 * resultset as mainNodeTable and put entry in the hash table.
1:eac0369: 			 */
1:eac0369: 			if(!msht.containsKey(resultSetId))
1:eac0369: 			{
1:eac0369: 				mainNodeForTable = true;
1:eac0369: 				msht.put(resultSetId, resultSetId);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 		
1:eac0369: 		//execute the before triggers on the dependents
1:eac0369: 		//Defect 5743: Before enabling BEFORE triggers, check DB2 behavior.
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).fireBeforeTriggers();
1:eac0369: 			}
1:eac0369: 			else{
1:eac0369: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireBeforeTriggers(msht);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		//If there is more than one node for the same table
1:eac0369: 		//only one node fires the triggers
1:eac0369: 		if(mainNodeForTable && constants.deferred)
1:eac0369: 			super.fireBeforeTriggers();
1:eac0369: 	}
1:eac0369: 
1:801cf0d:     @Override
1:eac0369:     void fireAfterTriggers() throws StandardException
1:eac0369: 	{
1:eac0369: 		//fire the After Triggers on the dependent tables, if any rows changed
1:eac0369: 		for(int i=0 ; i<noDependents && affectedRows; i++){
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).fireAfterTriggers();
1:eac0369: 			}
1:eac0369: 			else{
1:eac0369: 
1:eac0369: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireAfterTriggers();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		//If there is more than one node for the same table
1:eac0369: 		//, we let only one node fire the triggers.
1:eac0369: 		if(mainNodeForTable && constants.deferred)
1:eac0369: 			super.fireAfterTriggers();
1:eac0369: 	}
1:eac0369: 
1:801cf0d:     @Override
1:eac0369: 	void deleteDeferredRows() throws StandardException
1:eac0369: 	{
1:eac0369: 		
1:eac0369: 		//delete the rows in the  dependents tables
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).updateDeferredRows();
1:eac0369: 			}
1:eac0369: 			else{
1:eac0369: 				((DeleteCascadeResultSet)dependentResultSets[i]).deleteDeferredRows();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 			
1:eac0369: 		//If there is more than one node for the same table
1:eac0369: 		//only one node deletes all the rows.
1:eac0369: 		if(mainNodeForTable)
1:eac0369: 			super.deleteDeferredRows();
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	
1:801cf0d:     @Override
1:45da2f5:     void runFkChecker(boolean restrictCheckOnly)
1:18a6fb2:             throws StandardException
1:eac0369: 	{
1:eac0369: 
1:eac0369: 		//run the Foreign key or primary key Checker on the dependent tables
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{		
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:18a6fb2:                 ((UpdateResultSet) dependentResultSets[i]).runChecker(
1:45da2f5:                     restrictCheckOnly);
1:eac0369: 			}
1:eac0369: 			else{
1:18a6fb2:                 ((DeleteCascadeResultSet)dependentResultSets[i]).runFkChecker(
1:45da2f5:                     restrictCheckOnly);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		//If there  is more than one node for the same table
1:eac0369: 		//only one node does all foreign key checks.
1:eac0369: 		if(mainNodeForTable)
1:45da2f5:             super.runFkChecker(restrictCheckOnly);
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:801cf0d:     @Override
1:eac0369: 	public void cleanUp() throws StandardException
1:eac0369: 	{
1:eac0369: 
1:eac0369: 		super.cleanUp();
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).cleanUp();
1:eac0369: 			}else
1:eac0369: 			{
1:eac0369: 				((DeleteCascadeResultSet) dependentResultSets[i]).cleanUp();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 		
1:eac0369: 		endTime = getCurrentTimeMillis();
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 	private void rowChangerFinish() throws StandardException
1:eac0369: 	{
1:eac0369: 
1:eac0369: 		rc.finish();
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				((UpdateResultSet) dependentResultSets[i]).rowChangerFinish();
1:eac0369: 			}else
1:eac0369: 			{
1:eac0369: 				((DeleteCascadeResultSet) dependentResultSets[i]).rowChangerFinish();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 	//if there is more than one node for the same table, copy the rows
1:eac0369: 	// into one node , so that we don't fire trigger more than once.
1:45da2f5:     private void mergeRowHolders(HashMap<String, String> msht)
1:45da2f5:             throws StandardException
1:eac0369: 	{
1:eac0369: 		if(msht.containsKey(resultSetId) || rowCount ==0)
1:eac0369: 		{
1:eac0369: 			//there is already another resultset node that is marked as main
1:eac0369: 			//node for this table or this resultset has no rows qualified.
1:eac0369: 			//when none of the  resultset nodes for the table has any rows then
1:eac0369: 			//we mark them as one them as main node in fireBeforeTriggers().
1:eac0369: 			mainNodeForTable = false;
1:eac0369: 		}else
1:eac0369: 		{
1:eac0369: 			mergeResultSets();
1:eac0369: 			mainNodeForTable = true;
1:eac0369: 			msht.put(resultSetId, resultSetId);
1:eac0369: 		}
1:eac0369: 		
1:eac0369: 		for(int i =0 ; i < noDependents; i++)
1:eac0369: 		{		
1:eac0369: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1:eac0369: 			{
1:eac0369: 				return; 
1:eac0369: 			}
1:eac0369: 			else{
1:eac0369: 				((DeleteCascadeResultSet)dependentResultSets[i]).mergeRowHolders(msht);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:801cf0d:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:eac0369: 	private void mergeResultSets() throws StandardException
1:eac0369: 	{
1:801cf0d:         Vector<TemporaryRowHolder>
1:801cf0d:                 sVector = activation.getParentResultSet(resultSetId);
1:801cf0d:         int size = sVector.size();
1:eac0369: 		// if there is more than one source, we need to merge them into onc
1:eac0369: 		// temporary result set.
2:eac0369: 		if(size > 1)
1:eac0369: 		{
1:801cf0d:             ExecRow row;
1:eac0369: 			int rowHolderId = 0 ;
1:eac0369: 			//copy all the vallues in the result set to the current resultset row holder
1:eac0369: 			while(rowHolderId <  size)
1:eac0369: 			{
1:eac0369: 				if(rowHolderId == tempRowHolderId )
1:eac0369: 				{
1:eac0369: 					//skipping the row holder that  we are copying the rows into.
1:eac0369: 					rowHolderId++;
1:eac0369: 					continue;
1:eac0369: 				}
1:801cf0d:                 TemporaryRowHolder
1:801cf0d:                         currentRowHolder = sVector.elementAt(rowHolderId);
1:eac0369: 				CursorResultSet rs = currentRowHolder.getResultSet();
1:eac0369: 				rs.open();
1:eac0369: 				while ((row = rs.getNextRow()) != null)
1:eac0369: 				{
1:eac0369: 					rowHolder.insert(row);
1:eac0369: 				}
1:eac0369: 				rs.close();
1:eac0369: 				rowHolderId++;
1:eac0369: 			}
1:eac0369: 			
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:801cf0d:     @Override
1:eac0369: 	public void finish() throws StandardException {
1:eac0369: 		super.finish();
1:eac0369: 		
1:eac0369: 		//clear the parent result sets hash table
1:eac0369: 		//This is necessary in case if we hit any error conditions
1:eac0369: 		activation.clearParentResultSets();
1:eac0369: 	}
1:eac0369: 
1:eac0369: 
1:eac0369: 	/* check whether we have mutiple path delete scenario, if
1:eac0369: 	** find any retun true.	Multiple delete paths exist if we find more than
1:eac0369: 	** one parent source resultset for a table involved in the delete cascade
1:eac0369: 	**/
1:801cf0d:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:eac0369: 	private boolean isMultipleDeletePathsExist()
1:eac0369: 	{
1:801cf0d:         for (Enumeration<String> e = activation.getParentResultSetKeys() ;
1:801cf0d:              e.hasMoreElements() ;)
1:eac0369: 		{
1:801cf0d:             String rsId  = e.nextElement();
1:801cf0d:             Vector<TemporaryRowHolder>
1:801cf0d:                     sVector = activation.getParentResultSet(rsId);
1:801cf0d: 
1:801cf0d:             if(sVector.size() > 1)
1:eac0369: 			{
1:eac0369: 				return true;
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 		return false;
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	/*
1:eac0369: 	**Incases where we have multiple paths we could get the same
1:eac0369: 	**rows to be deleted  mutiple time and also in case of cycles
1:eac0369: 	**there might be new rows getting added to the row holders through
1:eac0369: 	**multiple iterations. To handle these case we set the temporary row holders
1:eac0369: 	** to be  'uniqStream' type.
1:eac0369: 	**/
1:801cf0d:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:eac0369: 	private void setRowHoldersTypeToUniqueStream()
1:eac0369: 	{
1:801cf0d:         for (Enumeration<String> e = activation.getParentResultSetKeys() ;
1:801cf0d:              e.hasMoreElements() ;)
1:eac0369: 		{
1:801cf0d:             String rsId  = e.nextElement();
1:801cf0d:             Vector<TemporaryRowHolder>
1:801cf0d:                     sVector = activation.getParentResultSet(rsId);
3:eac0369: 			int size = sVector.size();
1:eac0369: 			int rowHolderId = 0 ;
1:eac0369: 			while(rowHolderId <  size)
1:eac0369: 			{
1:801cf0d:                 TemporaryRowHolder
1:801cf0d:                         currentRowHolder = sVector.elementAt(rowHolderId);
1:eac0369: 				currentRowHolder.setRowHolderTypeToUniqueStream();
1:eac0369: 				rowHolderId++;
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: }
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
1:eac0369: 
============================================================================
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:45da2f5
/////////////////////////////////////////////////////////////////////////
1: import java.util.Enumeration;
1: import java.util.HashMap;
1: import java.util.Vector;
1: import org.apache.derby.catalog.UUID;
1: import org.apache.derby.iapi.reference.SQLState;
1: import org.apache.derby.iapi.sql.execute.ConstantAction;
1: import org.apache.derby.iapi.sql.execute.CursorResultSet;
1: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
1: import org.apache.derby.iapi.store.access.StaticCompiledOpenConglomInfo;
/////////////////////////////////////////////////////////////////////////
1:     private final String resultSetId;
/////////////////////////////////////////////////////////////////////////
1:             runFkChecker(true); // check for only RESTRICT referential
1:             HashMap<String,String> mntHashTable =
1:                 new HashMap<String,String>(); // Hash table to identify multiple
1:                                               // node for same table cases.
1:             deleteDeferredRows();
1:             runFkChecker(false); // check for all constraint violations
/////////////////////////////////////////////////////////////////////////
1:     void fireBeforeTriggers(HashMap<String, String> msht)
1:             throws StandardException
/////////////////////////////////////////////////////////////////////////
1:     void runFkChecker(boolean restrictCheckOnly)
/////////////////////////////////////////////////////////////////////////
1:                     restrictCheckOnly);
1:                     restrictCheckOnly);
1:             super.runFkChecker(restrictCheckOnly);
/////////////////////////////////////////////////////////////////////////
1:     private void mergeRowHolders(HashMap<String, String> msht)
1:             throws StandardException
commit:18a6fb2
/////////////////////////////////////////////////////////////////////////
0:             runFkChecker(true, true); // check for only RESTRICT referential
1:                                       // action rule violations
0:             runFkChecker(false, false); // check for all constraint violations
/////////////////////////////////////////////////////////////////////////
0:     void runFkChecker(boolean restrictCheckOnly, boolean postCheck)
1:             throws StandardException
/////////////////////////////////////////////////////////////////////////
1:                 ((UpdateResultSet) dependentResultSets[i]).runChecker(
0:                     restrictCheckOnly, postCheck);
1:                 ((DeleteCascadeResultSet)dependentResultSets[i]).runFkChecker(
0:                     restrictCheckOnly, postCheck);
0:             super.runFkChecker(restrictCheckOnly, postCheck);
commit:801cf0d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     @Override
1:     @SuppressWarnings({"UseOfObsoleteCollectionType", "empty-statement"})
/////////////////////////////////////////////////////////////////////////
1:                 while(collectAffectedRows(false)) {};
/////////////////////////////////////////////////////////////////////////
1:     @Override @SuppressWarnings("UseOfObsoleteCollectionType")
/////////////////////////////////////////////////////////////////////////
1:         Vector<TemporaryRowHolder> sVector =
1:                 activation.getParentResultSet(resultSetId);
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("UseOfObsoleteCollectionType")
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("UseOfObsoleteCollectionType")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:         Vector<TemporaryRowHolder>
1:                 sVector = activation.getParentResultSet(resultSetId);
1:         int size = sVector.size();
1:             ExecRow row;
/////////////////////////////////////////////////////////////////////////
1:                 TemporaryRowHolder
1:                         currentRowHolder = sVector.elementAt(rowHolderId);
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:         for (Enumeration<String> e = activation.getParentResultSetKeys() ;
1:              e.hasMoreElements() ;)
1:             String rsId  = e.nextElement();
1:             Vector<TemporaryRowHolder>
1:                     sVector = activation.getParentResultSet(rsId);
1: 
1:             if(sVector.size() > 1)
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("UseOfObsoleteCollectionType")
1:         for (Enumeration<String> e = activation.getParentResultSetKeys() ;
1:              e.hasMoreElements() ;)
1:             String rsId  = e.nextElement();
1:             Vector<TemporaryRowHolder>
1:                     sVector = activation.getParentResultSet(rsId);
1:                 TemporaryRowHolder
1:                         currentRowHolder = sVector.elementAt(rowHolderId);
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:71c8e86
/////////////////////////////////////////////////////////////////////////
0: 			Hashtable<String,String> mntHashTable = new Hashtable<String,String>(); //Hash Table to identify  mutiple node for same table cases. 
/////////////////////////////////////////////////////////////////////////
0: 	void fireBeforeTriggers(Hashtable<String,String> msht) throws StandardException
/////////////////////////////////////////////////////////////////////////
0: 	private void mergeRowHolders(Hashtable<String,String> msht) throws StandardException
commit:706f2eb
/////////////////////////////////////////////////////////////////////////
0: 		for (Enumeration e = activation.getParentResultSetKeys() ; e.hasMoreElements() ;) 
/////////////////////////////////////////////////////////////////////////
0: 		for (Enumeration e = activation.getParentResultSetKeys() ; e.hasMoreElements() ;) 
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:ca6ed17
/////////////////////////////////////////////////////////////////////////
1: class DeleteCascadeResultSet extends DeleteResultSet
1:     ResultSet[] dependentResultSets;
commit:c69c8b0
/////////////////////////////////////////////////////////////////////////
0: public class DeleteCascadeResultSet extends DeleteResultSet
0: 	private CursorResultSet parentSource;
0: 	private FKInfo parentFKInfo;
0: 	private long fkIndexConglomNumber;
/////////////////////////////////////////////////////////////////////////
1:     public DeleteCascadeResultSet
/////////////////////////////////////////////////////////////////////////
1: 		ConstantAction passedInConstantAction;
1: 		if(constantActionItem == -1)
1: 			passedInConstantAction = activation.getConstantAction(); //root table
1: 		else
1: 			passedInConstantAction = 
1: 				(ConstantAction) activation.getPreparedStatement().getSavedObject(constantActionItem);
commit:67549f0
/////////////////////////////////////////////////////////////////////////
1: 			cleanUp();
1: 
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:51572c8
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 		if(constantActionItem != -1)
commit:88bb146
/////////////////////////////////////////////////////////////////////////
0: class DeleteCascadeResultSet extends DeleteResultSet
/////////////////////////////////////////////////////////////////////////
0:     DeleteCascadeResultSet
commit:345de35
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derby.impl.sql.execute.DeleteCascadeResultSet
1: 
0:    Copyright 2002, 2004 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
commit:61070a6
/////////////////////////////////////////////////////////////////////////
commit:eac0369
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 2002, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
1: 
1:  */
1: 
1: package org.apache.derby.impl.sql.execute;
1: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
0: import org.apache.derby.iapi.sql.execute.CursorResultSet;
0: import org.apache.derby.iapi.sql.execute.RowChanger;
0: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
1: import org.apache.derby.iapi.sql.Activation;
0: import org.apache.derby.iapi.sql.ResultDescription;
0: import org.apache.derby.iapi.types.DataValueDescriptor;
1: import org.apache.derby.iapi.sql.ResultSet;
0: import org.apache.derby.iapi.store.access.ConglomerateController;
0: import org.apache.derby.iapi.store.access.TransactionController;
1: import org.apache.derby.iapi.sql.execute.ExecRow;
1: import org.apache.derby.iapi.sql.execute.TemporaryRowHolder;
1: 
0: import org.apache.derby.iapi.reference.SQLState;
1: 
0: import java.util.Vector;
0: import java.util.Hashtable;
0: import java.util.Enumeration;
1: 
1: /**
1:  * Delete the rows from the specified  base table and executes delete/update
1:  * on dependent tables depending on the referential actions specified.
1:  * Note:(beetle:5197) Dependent Resultsets of DeleteCascade Resultset can  in
1:  * any one of the multiple resultsets generated for the same table because of
1:  * multiple foreign key relationship to  the same table. At the bind time ,
1:  * dependents are binded only once per table.
1:  * We can not depend on mainNodeTable Flag to fire actions on dependents,
1:  * it should be done based on whether the resultset has dependent resultsets or not.
1:  *
1:  */
0: public class DeleteCascadeResultSet extends DeleteResultSet
1: {
1: 	/**
0: 		IBM Copyright &copy notice.
1: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_2002_2004;
1: 
1: 
0: 	public ResultSet[] dependentResultSets;
1: 	private int noDependents =0;
0: 	private CursorResultSet parentSource;
0: 	private FKInfo parentFKInfo;
0: 	private long fkIndexConglomNumber;
0: 	private String resultSetId;
1: 	private boolean mainNodeForTable = true;
1: 	private boolean affectedRows = false;
1: 	private int tempRowHolderId; //this result sets temporary row holder id 
1: 
1:     /*
1:      * class interface
1: 	 * @exception StandardException		Thrown on error
1:      */
0:     public DeleteCascadeResultSet
1: 	(
1: 		NoPutResultSet		source,
1: 		Activation			activation,
1: 		int 				constantActionItem,
1: 		ResultSet[]			dependentResultSets,
1: 		String  	        resultSetId
1: 	)
1: 		throws StandardException
1:     {
1: 
1: 		super(source,
1: 			  ((constantActionItem == -1) ?activation.getConstantAction() :
1: 			  (ConstantAction)activation.getPreparedStatement().getSavedObject(constantActionItem)),
1: 			  activation);
1: 
0: 		ConstantAction passedInConstantAction;
0: 		if(constantActionItem == -1)
0: 			passedInConstantAction = activation.getConstantAction(); //root table
0: 		else
1: 		{
0: 			passedInConstantAction = 
0: 				(ConstantAction) activation.getPreparedStatement().getSavedObject(constantActionItem);
1: 			resultDescription = constants.resultDescription;
1: 		}
1: 		cascadeDelete = true;
1: 		this.resultSetId = resultSetId;
1: 		
1: 		if(dependentResultSets != null)
1: 		{
1: 			noDependents = dependentResultSets.length;
1: 			this.dependentResultSets = dependentResultSets;
1: 		}
1: 
1: 	}
1: 
1: 
1: 
1: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
1: 	*/
1: 	public void open() throws StandardException
1: 	{
1: 
1: 
1: 		try{
1: 			setup();
1: 			if(isMultipleDeletePathsExist())
1: 			{
1: 				setRowHoldersTypeToUniqueStream();
1: 				//collect until there are no more rows to found
0: 				while(collectAffectedRows(false));
1: 			}else
1: 			{
1: 				collectAffectedRows(false);
1: 			}
1: 			if (! affectedRows)
1: 			{
1: 				activation.addWarning(
1: 							StandardException.newWarning(
1: 								SQLState.LANG_NO_ROW_FOUND));
1: 			}
1: 
0: 			runFkChecker(true); //check for only RESTRICT referential action rule violations
0: 			Hashtable mntHashTable = new Hashtable(); //Hash Table to identify  mutiple node for same table cases. 
1: 			mergeRowHolders(mntHashTable);
1: 			fireBeforeTriggers(mntHashTable);
0: 			deleteDeferredRows();
0: 			runFkChecker(false); //check for all constraint violations
1: 			rowChangerFinish();
1: 			fireAfterTriggers();
0: 			cleanUp();
1: 		}finally
1: 		{
1: 			//clear the parent result sets hash table
1: 			activation.clearParentResultSets();
1: 		}
1: 
1: 		endTime = getCurrentTimeMillis();
1: 
1:     }
1: 	
1: 
1: 	/**
1: 	 *Gathers the rows that needs to be deleted/updated 
1: 	 *and creates a temporary resulsets that will be passed
1: 	 *as source to its  dependent result sets.
1: 	 */
1: 	void  setup() throws StandardException
1: 	{
1: 
1: 		/* Cache query plan text for source, before it gets blown away */
1: 		if (lcc.getRunTimeStatisticsMode())
1: 		{
1: 			/* savedSource nulled after run time statistics generation */
1: 			savedSource = source;
1: 		}
1: 
1: 		super.setup();
1: 		activation.setParentResultSet(rowHolder, resultSetId);
0: 		Vector sVector = (Vector) activation.getParentResultSet(resultSetId);
1: 		tempRowHolderId = sVector.size() -1;
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).setup();
1: 			}else
1: 			{
1: 				((DeleteCascadeResultSet) dependentResultSets[i]).setup();
1: 			}
1: 		}
1: 
1: 	}
1: 
1: 
1: 	boolean  collectAffectedRows(boolean rowsFound) throws StandardException
1: 	{
1: 		if(super.collectAffectedRows())
1: 		{
1: 			affectedRows = true;
1: 			rowsFound = true;
1: 		}
1: 
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				if(((UpdateResultSet)dependentResultSets[i]).collectAffectedRows())
1: 					rowsFound = true;
1: 			}else
1: 			{
1: 				if(((DeleteCascadeResultSet)
1: 					dependentResultSets[i]).collectAffectedRows(rowsFound))
1: 					rowsFound = true;
1: 			}
1: 		}
1: 
1: 		return rowsFound;
1: 	}
1: 
1: 
0: 	void fireBeforeTriggers(Hashtable msht) throws StandardException
1: 	{
1: 		if(!mainNodeForTable) 
1: 		{
1: 			/*to handle case where no table node had qualified rows, in which case no node for
1: 			 * the table get marked as mainNodeFor table , one way to identify
1: 			 * such case is to look at the mutinode hash table and see if the result id exist ,
1: 			 *if it does not means none of the table nodes resulsets got marked
1: 			 * as main node for table. If that is the case we mark this
1: 			 * resultset as mainNodeTable and put entry in the hash table.
1: 			 */
1: 			if(!msht.containsKey(resultSetId))
1: 			{
1: 				mainNodeForTable = true;
1: 				msht.put(resultSetId, resultSetId);
1: 			}
1: 		}
1: 		
1: 		//execute the before triggers on the dependents
1: 		//Defect 5743: Before enabling BEFORE triggers, check DB2 behavior.
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).fireBeforeTriggers();
1: 			}
1: 			else{
1: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireBeforeTriggers(msht);
1: 			}
1: 		}
1: 
1: 		//If there is more than one node for the same table
1: 		//only one node fires the triggers
1: 		if(mainNodeForTable && constants.deferred)
1: 			super.fireBeforeTriggers();
1: 	}
1: 
1:     void fireAfterTriggers() throws StandardException
1: 	{
1: 		//fire the After Triggers on the dependent tables, if any rows changed
1: 		for(int i=0 ; i<noDependents && affectedRows; i++){
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).fireAfterTriggers();
1: 			}
1: 			else{
1: 
1: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireAfterTriggers();
1: 			}
1: 		}
1: 
1: 		//If there is more than one node for the same table
1: 		//, we let only one node fire the triggers.
1: 		if(mainNodeForTable && constants.deferred)
1: 			super.fireAfterTriggers();
1: 	}
1: 
1: 	void deleteDeferredRows() throws StandardException
1: 	{
1: 		
1: 		//delete the rows in the  dependents tables
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).updateDeferredRows();
1: 			}
1: 			else{
1: 				((DeleteCascadeResultSet)dependentResultSets[i]).deleteDeferredRows();
1: 			}
1: 		}
1: 
1: 			
1: 		//If there is more than one node for the same table
1: 		//only one node deletes all the rows.
1: 		if(mainNodeForTable)
1: 			super.deleteDeferredRows();
1: 	}
1: 
1: 	
0: 	void runFkChecker(boolean restrictCheckOnly) throws StandardException
1: 	{
1: 
1: 		//run the Foreign key or primary key Checker on the dependent tables
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{		
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).runChecker(restrictCheckOnly);
1: 			}
1: 			else{
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).runFkChecker(restrictCheckOnly);
1: 			}
1: 		}
1: 
1: 		//If there  is more than one node for the same table
1: 		//only one node does all foreign key checks.
1: 		if(mainNodeForTable)
0: 			super.runFkChecker(restrictCheckOnly);
1: 	}
1: 
1: 
1: 	public void cleanUp() throws StandardException
1: 	{
1: 
1: 		super.cleanUp();
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).cleanUp();
1: 			}else
1: 			{
1: 				((DeleteCascadeResultSet) dependentResultSets[i]).cleanUp();
1: 			}
1: 		}
1: 		
1: 		endTime = getCurrentTimeMillis();
1: 	}
1: 
1: 
1: 	private void rowChangerFinish() throws StandardException
1: 	{
1: 
1: 		rc.finish();
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				((UpdateResultSet) dependentResultSets[i]).rowChangerFinish();
1: 			}else
1: 			{
1: 				((DeleteCascadeResultSet) dependentResultSets[i]).rowChangerFinish();
1: 			}
1: 		}
1: 	}
1: 
1: 
1: 
1: 	//if there is more than one node for the same table, copy the rows
1: 	// into one node , so that we don't fire trigger more than once.
0: 	private void mergeRowHolders(Hashtable msht) throws StandardException
1: 	{
1: 		if(msht.containsKey(resultSetId) || rowCount ==0)
1: 		{
1: 			//there is already another resultset node that is marked as main
1: 			//node for this table or this resultset has no rows qualified.
1: 			//when none of the  resultset nodes for the table has any rows then
1: 			//we mark them as one them as main node in fireBeforeTriggers().
1: 			mainNodeForTable = false;
1: 		}else
1: 		{
1: 			mergeResultSets();
1: 			mainNodeForTable = true;
1: 			msht.put(resultSetId, resultSetId);
1: 		}
1: 		
1: 		for(int i =0 ; i < noDependents; i++)
1: 		{		
1: 			if(dependentResultSets[i] instanceof UpdateResultSet)
1: 			{
1: 				return; 
1: 			}
1: 			else{
1: 				((DeleteCascadeResultSet)dependentResultSets[i]).mergeRowHolders(msht);
1: 			}
1: 		}
1: 	}
1: 
1: 
1: 
1: 	private void mergeResultSets() throws StandardException
1: 	{
0: 		Vector sVector = (Vector) activation.getParentResultSet(resultSetId);
1: 		int size = sVector.size();
1: 		// if there is more than one source, we need to merge them into onc
1: 		// temporary result set.
1: 		if(size > 1)
1: 		{
0: 			ExecRow		row = null;
1: 			int rowHolderId = 0 ;
1: 			//copy all the vallues in the result set to the current resultset row holder
1: 			while(rowHolderId <  size)
1: 			{
1: 				if(rowHolderId == tempRowHolderId )
1: 				{
1: 					//skipping the row holder that  we are copying the rows into.
1: 					rowHolderId++;
1: 					continue;
1: 				}
0: 				TemporaryRowHolder currentRowHolder = (TemporaryRowHolder)sVector.elementAt(rowHolderId);	
1: 				CursorResultSet rs = currentRowHolder.getResultSet();
1: 				rs.open();
1: 				while ((row = rs.getNextRow()) != null)
1: 				{
1: 					rowHolder.insert(row);
1: 				}
1: 				rs.close();
1: 				rowHolderId++;
1: 			}
1: 			
1: 		}
1: 	}
1: 
1: 
1: 	public void finish() throws StandardException {
1: 		super.finish();
1: 		
1: 		//clear the parent result sets hash table
1: 		//This is necessary in case if we hit any error conditions
1: 		activation.clearParentResultSets();
1: 	}
1: 
1: 
1: 	/* check whether we have mutiple path delete scenario, if
1: 	** find any retun true.	Multiple delete paths exist if we find more than
1: 	** one parent source resultset for a table involved in the delete cascade
1: 	**/
1: 	private boolean isMultipleDeletePathsExist()
1: 	{
0: 		Hashtable parentResultSets = activation.getParentResultSets();
0: 		for (Enumeration e = parentResultSets.keys() ; e.hasMoreElements() ;) 
1: 		{
0: 			String rsId  = (String) e.nextElement();
0: 			Vector sVector = (Vector) activation.getParentResultSet(rsId);
1: 			int size = sVector.size();
1: 			if(size > 1)
1: 			{
1: 				return true;
1: 			}
1: 		}
1: 		return false;
1: 	}
1: 
1: 	/*
1: 	**Incases where we have multiple paths we could get the same
1: 	**rows to be deleted  mutiple time and also in case of cycles
1: 	**there might be new rows getting added to the row holders through
1: 	**multiple iterations. To handle these case we set the temporary row holders
1: 	** to be  'uniqStream' type.
1: 	**/
1: 	private void setRowHoldersTypeToUniqueStream()
1: 	{
0: 		Hashtable parentResultSets = activation.getParentResultSets();
0: 		for (Enumeration e = parentResultSets.keys() ; e.hasMoreElements() ;) 
1: 		{
0: 			String rsId  = (String) e.nextElement();
0: 			Vector sVector = (Vector) activation.getParentResultSet(rsId);
1: 			int size = sVector.size();
1: 			int rowHolderId = 0 ;
1: 			while(rowHolderId <  size)
1: 			{
0: 				TemporaryRowHolder currentRowHolder = (TemporaryRowHolder)sVector.elementAt(rowHolderId);	
1: 				currentRowHolder.setRowHolderTypeToUniqueStream();
1: 				rowHolderId++;
1: 			}
1: 		}
1: 	}
1: 
1: }
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
author:Samuel Andrew McIntyre
-------------------------------------------------------------------------------
commit:94f158a
/////////////////////////////////////////////////////////////////////////
1: 		@exception StandardException Standard Derby error policy
author:David Van Couvering
-------------------------------------------------------------------------------
commit:f6123ee
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
author:Ken Coar
-------------------------------------------------------------------------------
commit:95e7b46
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 2002, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
0: 
0:  */
0: 
0: package org.apache.derby.impl.sql.execute;
0: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
0: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
0: import org.apache.derby.iapi.sql.execute.CursorResultSet;
0: import org.apache.derby.iapi.sql.execute.RowChanger;
0: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
0: import org.apache.derby.iapi.sql.Activation;
0: import org.apache.derby.iapi.sql.ResultDescription;
0: import org.apache.derby.iapi.types.DataValueDescriptor;
0: import org.apache.derby.iapi.sql.ResultSet;
0: import org.apache.derby.iapi.store.access.ConglomerateController;
0: import org.apache.derby.iapi.store.access.TransactionController;
0: import org.apache.derby.iapi.sql.execute.ExecRow;
0: import org.apache.derby.iapi.sql.execute.TemporaryRowHolder;
0: 
0: import org.apache.derby.iapi.reference.SQLState;
0: 
0: import java.util.Vector;
0: import java.util.Hashtable;
0: import java.util.Enumeration;
0: 
0: /**
0:  * Delete the rows from the specified  base table and executes delete/update
0:  * on dependent tables depending on the referential actions specified.
0:  * Note:(beetle:5197) Dependent Resultsets of DeleteCascade Resultset can  in
0:  * any one of the multiple resultsets generated for the same table because of
0:  * multiple foreign key relationship to  the same table. At the bind time ,
0:  * dependents are binded only once per table.
0:  * We can not depend on mainNodeTable Flag to fire actions on dependents,
0:  * it should be done based on whether the resultset has dependent resultsets or not.
0:  *
0:  */
0: public class DeleteCascadeResultSet extends DeleteResultSet
0: {
0: 	/**
0: 		IBM Copyright &copy notice.
0: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_2002_2004;
0: 
0: 
0: 	public ResultSet[] dependentResultSets;
0: 	private int noDependents =0;
0: 	private CursorResultSet parentSource;
0: 	private FKInfo parentFKInfo;
0: 	private long fkIndexConglomNumber;
0: 	private String resultSetId;
0: 	private boolean mainNodeForTable = true;
0: 	private boolean affectedRows = false;
0: 	private int tempRowHolderId; //this result sets temporary row holder id 
0: 
0:     /*
0:      * class interface
0: 	 * @exception StandardException		Thrown on error
0:      */
0:     public DeleteCascadeResultSet
0: 	(
0: 		NoPutResultSet		source,
0: 		Activation			activation,
0: 		int 				constantActionItem,
0: 		ResultSet[]			dependentResultSets,
0: 		String  	        resultSetId
0: 	)
0: 		throws StandardException
0:     {
0: 
0: 		super(source,
0: 			  ((constantActionItem == -1) ?activation.getConstantAction() :
0: 			  (ConstantAction)activation.getPreparedStatement().getSavedObject(constantActionItem)),
0: 			  activation);
0: 
0: 		ConstantAction passedInConstantAction;
0: 		if(constantActionItem == -1)
0: 			passedInConstantAction = activation.getConstantAction(); //root table
0: 		else
0: 		{
0: 			passedInConstantAction = 
0: 				(ConstantAction) activation.getPreparedStatement().getSavedObject(constantActionItem);
0: 			resultDescription = constants.resultDescription;
0: 		}
0: 		cascadeDelete = true;
0: 		this.resultSetId = resultSetId;
0: 		
0: 		if(dependentResultSets != null)
0: 		{
0: 			noDependents = dependentResultSets.length;
0: 			this.dependentResultSets = dependentResultSets;
0: 		}
0: 
0: 	}
0: 
0: 
0: 
0: 	/**
0: 		@exception StandardException Standard Cloudscape error policy
0: 	*/
0: 	public void open() throws StandardException
0: 	{
0: 
0: 
0: 		try{
0: 			setup();
0: 			if(isMultipleDeletePathsExist())
0: 			{
0: 				setRowHoldersTypeToUniqueStream();
0: 				//collect until there are no more rows to found
0: 				while(collectAffectedRows(false));
0: 			}else
0: 			{
0: 				collectAffectedRows(false);
0: 			}
0: 			if (! affectedRows)
0: 			{
0: 				activation.addWarning(
0: 							StandardException.newWarning(
0: 								SQLState.LANG_NO_ROW_FOUND));
0: 			}
0: 
0: 			runFkChecker(true); //check for only RESTRICT referential action rule violations
0: 			Hashtable mntHashTable = new Hashtable(); //Hash Table to identify  mutiple node for same table cases. 
0: 			mergeRowHolders(mntHashTable);
0: 			fireBeforeTriggers(mntHashTable);
0: 			deleteDeferredRows();
0: 			runFkChecker(false); //check for all constraint violations
0: 			rowChangerFinish();
0: 			fireAfterTriggers();
0: 			cleanUp();
0: 		}finally
0: 		{
0: 			//clear the parent result sets hash table
0: 			activation.clearParentResultSets();
0: 		}
0: 
0: 		endTime = getCurrentTimeMillis();
0: 
0:     }
0: 	
0: 
0: 	/**
0: 	 *Gathers the rows that needs to be deleted/updated 
0: 	 *and creates a temporary resulsets that will be passed
0: 	 *as source to its  dependent result sets.
0: 	 */
0: 	void  setup() throws StandardException
0: 	{
0: 
0: 		/* Cache query plan text for source, before it gets blown away */
0: 		if (lcc.getRunTimeStatisticsMode())
0: 		{
0: 			/* savedSource nulled after run time statistics generation */
0: 			savedSource = source;
0: 		}
0: 
0: 		super.setup();
0: 		activation.setParentResultSet(rowHolder, resultSetId);
0: 		Vector sVector = (Vector) activation.getParentResultSet(resultSetId);
0: 		tempRowHolderId = sVector.size() -1;
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).setup();
0: 			}else
0: 			{
0: 				((DeleteCascadeResultSet) dependentResultSets[i]).setup();
0: 			}
0: 		}
0: 
0: 	}
0: 
0: 
0: 	boolean  collectAffectedRows(boolean rowsFound) throws StandardException
0: 	{
0: 		if(super.collectAffectedRows())
0: 		{
0: 			affectedRows = true;
0: 			rowsFound = true;
0: 		}
0: 
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				if(((UpdateResultSet)dependentResultSets[i]).collectAffectedRows())
0: 					rowsFound = true;
0: 			}else
0: 			{
0: 				if(((DeleteCascadeResultSet)
0: 					dependentResultSets[i]).collectAffectedRows(rowsFound))
0: 					rowsFound = true;
0: 			}
0: 		}
0: 
0: 		return rowsFound;
0: 	}
0: 
0: 
0: 	void fireBeforeTriggers(Hashtable msht) throws StandardException
0: 	{
0: 		if(!mainNodeForTable) 
0: 		{
0: 			/*to handle case where no table node had qualified rows, in which case no node for
0: 			 * the table get marked as mainNodeFor table , one way to identify
0: 			 * such case is to look at the mutinode hash table and see if the result id exist ,
0: 			 *if it does not means none of the table nodes resulsets got marked
0: 			 * as main node for table. If that is the case we mark this
0: 			 * resultset as mainNodeTable and put entry in the hash table.
0: 			 */
0: 			if(!msht.containsKey(resultSetId))
0: 			{
0: 				mainNodeForTable = true;
0: 				msht.put(resultSetId, resultSetId);
0: 			}
0: 		}
0: 		
0: 		//execute the before triggers on the dependents
0: 		//Defect 5743: Before enabling BEFORE triggers, check DB2 behavior.
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).fireBeforeTriggers();
0: 			}
0: 			else{
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireBeforeTriggers(msht);
0: 			}
0: 		}
0: 
0: 		//If there is more than one node for the same table
0: 		//only one node fires the triggers
0: 		if(mainNodeForTable && constants.deferred)
0: 			super.fireBeforeTriggers();
0: 	}
0: 
0:     void fireAfterTriggers() throws StandardException
0: 	{
0: 		//fire the After Triggers on the dependent tables, if any rows changed
0: 		for(int i=0 ; i<noDependents && affectedRows; i++){
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).fireAfterTriggers();
0: 			}
0: 			else{
0: 
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).fireAfterTriggers();
0: 			}
0: 		}
0: 
0: 		//If there is more than one node for the same table
0: 		//, we let only one node fire the triggers.
0: 		if(mainNodeForTable && constants.deferred)
0: 			super.fireAfterTriggers();
0: 	}
0: 
0: 	void deleteDeferredRows() throws StandardException
0: 	{
0: 		
0: 		//delete the rows in the  dependents tables
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).updateDeferredRows();
0: 			}
0: 			else{
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).deleteDeferredRows();
0: 			}
0: 		}
0: 
0: 			
0: 		//If there is more than one node for the same table
0: 		//only one node deletes all the rows.
0: 		if(mainNodeForTable)
0: 			super.deleteDeferredRows();
0: 	}
0: 
0: 	
0: 	void runFkChecker(boolean restrictCheckOnly) throws StandardException
0: 	{
0: 
0: 		//run the Foreign key or primary key Checker on the dependent tables
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{		
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).runChecker(restrictCheckOnly);
0: 			}
0: 			else{
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).runFkChecker(restrictCheckOnly);
0: 			}
0: 		}
0: 
0: 		//If there  is more than one node for the same table
0: 		//only one node does all foreign key checks.
0: 		if(mainNodeForTable)
0: 			super.runFkChecker(restrictCheckOnly);
0: 	}
0: 
0: 
0: 	public void cleanUp() throws StandardException
0: 	{
0: 
0: 		super.cleanUp();
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).cleanUp();
0: 			}else
0: 			{
0: 				((DeleteCascadeResultSet) dependentResultSets[i]).cleanUp();
0: 			}
0: 		}
0: 		
0: 		endTime = getCurrentTimeMillis();
0: 	}
0: 
0: 
0: 	private void rowChangerFinish() throws StandardException
0: 	{
0: 
0: 		rc.finish();
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				((UpdateResultSet) dependentResultSets[i]).rowChangerFinish();
0: 			}else
0: 			{
0: 				((DeleteCascadeResultSet) dependentResultSets[i]).rowChangerFinish();
0: 			}
0: 		}
0: 	}
0: 
0: 
0: 
0: 	//if there is more than one node for the same table, copy the rows
0: 	// into one node , so that we don't fire trigger more than once.
0: 	private void mergeRowHolders(Hashtable msht) throws StandardException
0: 	{
0: 		if(msht.containsKey(resultSetId) || rowCount ==0)
0: 		{
0: 			//there is already another resultset node that is marked as main
0: 			//node for this table or this resultset has no rows qualified.
0: 			//when none of the  resultset nodes for the table has any rows then
0: 			//we mark them as one them as main node in fireBeforeTriggers().
0: 			mainNodeForTable = false;
0: 		}else
0: 		{
0: 			mergeResultSets();
0: 			mainNodeForTable = true;
0: 			msht.put(resultSetId, resultSetId);
0: 		}
0: 		
0: 		for(int i =0 ; i < noDependents; i++)
0: 		{		
0: 			if(dependentResultSets[i] instanceof UpdateResultSet)
0: 			{
0: 				return; 
0: 			}
0: 			else{
0: 				((DeleteCascadeResultSet)dependentResultSets[i]).mergeRowHolders(msht);
0: 			}
0: 		}
0: 	}
0: 
0: 
0: 
0: 	private void mergeResultSets() throws StandardException
0: 	{
0: 		Vector sVector = (Vector) activation.getParentResultSet(resultSetId);
0: 		int size = sVector.size();
0: 		// if there is more than one source, we need to merge them into onc
0: 		// temporary result set.
0: 		if(size > 1)
0: 		{
0: 			ExecRow		row = null;
0: 			int rowHolderId = 0 ;
0: 			//copy all the vallues in the result set to the current resultset row holder
0: 			while(rowHolderId <  size)
0: 			{
0: 				if(rowHolderId == tempRowHolderId )
0: 				{
0: 					//skipping the row holder that  we are copying the rows into.
0: 					rowHolderId++;
0: 					continue;
0: 				}
0: 				TemporaryRowHolder currentRowHolder = (TemporaryRowHolder)sVector.elementAt(rowHolderId);	
0: 				CursorResultSet rs = currentRowHolder.getResultSet();
0: 				rs.open();
0: 				while ((row = rs.getNextRow()) != null)
0: 				{
0: 					rowHolder.insert(row);
0: 				}
0: 				rs.close();
0: 				rowHolderId++;
0: 			}
0: 			
0: 		}
0: 	}
0: 
0: 
0: 	public void finish() throws StandardException {
0: 		super.finish();
0: 		
0: 		//clear the parent result sets hash table
0: 		//This is necessary in case if we hit any error conditions
0: 		activation.clearParentResultSets();
0: 	}
0: 
0: 
0: 	/* check whether we have mutiple path delete scenario, if
0: 	** find any retun true.	Multiple delete paths exist if we find more than
0: 	** one parent source resultset for a table involved in the delete cascade
0: 	**/
0: 	private boolean isMultipleDeletePathsExist()
0: 	{
0: 		Hashtable parentResultSets = activation.getParentResultSets();
0: 		for (Enumeration e = parentResultSets.keys() ; e.hasMoreElements() ;) 
0: 		{
0: 			String rsId  = (String) e.nextElement();
0: 			Vector sVector = (Vector) activation.getParentResultSet(rsId);
0: 			int size = sVector.size();
0: 			if(size > 1)
0: 			{
0: 				return true;
0: 			}
0: 		}
0: 		return false;
0: 	}
0: 
0: 	/*
0: 	**Incases where we have multiple paths we could get the same
0: 	**rows to be deleted  mutiple time and also in case of cycles
0: 	**there might be new rows getting added to the row holders through
0: 	**multiple iterations. To handle these case we set the temporary row holders
0: 	** to be  'uniqStream' type.
0: 	**/
0: 	private void setRowHoldersTypeToUniqueStream()
0: 	{
0: 		Hashtable parentResultSets = activation.getParentResultSets();
0: 		for (Enumeration e = parentResultSets.keys() ; e.hasMoreElements() ;) 
0: 		{
0: 			String rsId  = (String) e.nextElement();
0: 			Vector sVector = (Vector) activation.getParentResultSet(rsId);
0: 			int size = sVector.size();
0: 			int rowHolderId = 0 ;
0: 			while(rowHolderId <  size)
0: 			{
0: 				TemporaryRowHolder currentRowHolder = (TemporaryRowHolder)sVector.elementAt(rowHolderId);	
0: 				currentRowHolder.setRowHolderTypeToUniqueStream();
0: 				rowHolderId++;
0: 			}
0: 		}
0: 	}
0: 
0: }
0: 
0: 
0: 
0: 
0: 
0: 
0: 
0: 
0: 
0: 
0: 
0: 
============================================================================
1:f8fd911: /*
1:f8fd911:  *
1:f8fd911:  * Derby - Class JDBCPerfTestCase
1:f8fd911:  *
1:f8fd911:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:f8fd911:  * contributor license agreements.  See the NOTICE file distributed with
1:f8fd911:  * this work for additional information regarding copyright ownership.
1:f8fd911:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:f8fd911:  * (the "License"); you may not use this file except in compliance with
1:f8fd911:  * the License.  You may obtain a copy of the License at
1:f8fd911:  *
1:f8fd911:  *    http://www.apache.org/licenses/LICENSE-2.0
1:f8fd911:  *
1:f8fd911:  * Unless required by applicable law or agreed to in writing, 
1:f8fd911:  * software distributed under the License is distributed on an 
1:f8fd911:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, 
1:f8fd911:  * either express or implied. See the License for the specific 
1:f8fd911:  * language governing permissions and limitations under the License.
1:f8fd911:  */
1:f8fd911: package org.apache.derbyTesting.junit;
2:f8fd911: 
1:f8fd911: 
1:f8fd911: /**
1:f8fd911:  * Base Class for performance tests. It is useful for a performance test
1:f8fd911:  * framework to have ability to run a test for I iterations , and repeat the
1:f8fd911:  * test R times. This class provides this functionality of timing the test for I
1:f8fd911:  * iterations and repeating the test in the same jvm for R number of
1:f8fd911:  * times. 
1:f8fd911:  * 
1:f8fd911:  * For JDBCPerfTestCase with R repeats and I iterations
1:f8fd911:  * 
1:f8fd911:  * This cycle is repeated R times 
1:f8fd911:  * {
1:f8fd911:  *    setUp run once 
1:f8fd911:  *    fixture method is run I times(and timed) 
1:f8fd911:  *    tearDown is run once
1:f8fd911:  * }
1:f8fd911:  *
1:f8fd911:  * 
1:f8fd911:  * Results are printed out to System.out currently. For each repeat of the test, 
1:f8fd911:  * the elapsed time is printed out and after R repeats of the test, the average
1:f8fd911:  * elapsed time is also printed.
1:f8fd911:  *  
1:dbed020:  * If  a test has R repeats and (R&gt;1), then the average elapsed time of the
1:f8fd911:  * (R-1) runs is printed out and the timing info collected as part of the first 
1:f8fd911:  * testrun is ignored. 
1:f8fd911:  * If R=1, then the average elapsed time prints time for that
1:f8fd911:  * only run. 
1:f8fd911:  * 
1:f8fd911:  * To see the current output that is printed out, see methods runBare() and 
1:f8fd911:  * runTest()
1:f8fd911:  * 
1:f8fd911:  * To write a performance test, extend the JDBCPerfTestCase 
1:f8fd911:  * In the example below, ScanCoveredIdxTest is a performance test that 
1:f8fd911:  * extends JDBCPerfTestCase. See below code snippet on how 
1:f8fd911:  * these tests will be added/used.  
1:f8fd911:  * <CODE>
1:f8fd911:  *  // Add a test fixture 'scanAllRows' in ScanCoveredIdxTest 
1:f8fd911:  *  // and to run this test for 100 iterations and to 
1:f8fd911:  *  // repeat the test 4 times.
1:f8fd911:  *  int iterations = 100; 
1:f8fd911:  *  int repeats = 4; 
1:1ae02c9:  *  BaseTestSuite suite = new BaseTestSuite();
1:f8fd911:  *  suite.addTest(new ScanCoveredIdxTest("scanAllRows",iterations,repeats));
1:f8fd911:  * 
1:f8fd911:  *  // To add client tests. 
1:1ae02c9:  * BaseTestSuite client = new BaseTestSuite("Client");
1:f8fd911:  * client.addTest(new ScanCoveredIdxTest("scanAllRows",iterations,repeats));
1:f8fd911:  * client.addTest(new ScanCoveredIdxTest("scanAndRetrieveAllRows",iterations,repeats));
1:f8fd911:  * 
1:f8fd911:  * // This will add the server decorator that will start the
1:f8fd911:  * // server on setUp of the suite and stop server on tearDown 
1:f8fd911:  * // of the suite.
1:f8fd911:  * suite.addTest(TestConfiguration.clientServerDecorator(client));
1:f8fd911:  * </CODE>
1:f8fd911:  * 
1:f8fd911:  * Some improvement areas/ideas: 
1:f8fd911:  * -- Can we use TestResult ,and our own TestRunner to improve on how the 
1:f8fd911:  * results are reported.  
1:f8fd911:  * -- write the perf results to a file that can be easily consumed for reporting purposes
1:f8fd911:  * and further analysis against different builds.
1:f8fd911:  * -- Maybe even write the results out in xml format,and then using xsl the results
1:f8fd911:  * could be rendered into html reports
1:f8fd911:  */
1:f8fd911: public class JDBCPerfTestCase extends BaseJDBCTestCase {
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * store timing information
1:f8fd911:      */
1:f8fd911:     private long startTime,endTime;
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * Store info on how many times the test fixture should be run
1:f8fd911:      * also see runTest() on how iterations is used 
1:f8fd911:      */
1:f8fd911:     private int iterations = 1;
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * Store info on how many times should the test be repeated
1:f8fd911:      * default value is 1
1:f8fd911:      */
1:f8fd911:     private int repeats = 1;
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * Hold the elapsedtime info for the testRun
1:f8fd911:      * given by testRunNum
1:f8fd911:      */
1:f8fd911:     private int testRunNum = 0;
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * store the elapsed time info for the test runs.
1:f8fd911:      */
1:f8fd911:     private long[] runs;
1:f8fd911:     
1:f8fd911:     
1:f8fd911:     public JDBCPerfTestCase(String name)
1:f8fd911:     {
1:f8fd911:         super(name);
1:f8fd911:         runs = new long[repeats];
1:f8fd911:     }
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * @param name testname
1:f8fd911:      * @param iterations iterations of the test to measure at one shot.
1:f8fd911:      * @param repeats is the number of times the entire test be repeated
1:f8fd911:      * @see JDBCPerfTestCase  class level comments
1:f8fd911:      */
1:f8fd911:     public JDBCPerfTestCase(String name,int iterations, int repeats)
1:f8fd911:     {
1:f8fd911:         super(name);
1:f8fd911:         this.iterations = iterations;
1:f8fd911:         this.repeats = repeats;
1:f8fd911:         runs = new long[repeats];
1:f8fd911: 
1:f8fd911:     }
1:f8fd911:     
1:f8fd911:   
1:f8fd911:     /**
1:f8fd911:      * runBare, do the whole thing - setup, runTest, cleanup
1:f8fd911:      * 'repeats' times.
1:f8fd911:      * If test was run for more than one time, then ignore the 
1:f8fd911:      * first testrun results and print the average elapsed time 
1:f8fd911:      * for the remaining runs.  
1:f8fd911:      */
1:ade6fcf:     protected void runBareOverridable() throws Throwable
1:f8fd911:     {
1:f8fd911:         for (int i = 0; i < repeats; i++)
1:f8fd911:         {
1:f8fd911:             println("Repeat ="+i);
1:ade6fcf:             super.runBareOverridable();
1:f8fd911:             testRunNum++;
1:f8fd911:         }
1:f8fd911:         
1:24f9f14:         // For a single run no point in printing a summary that's
1:24f9f14:         // identical to the one run output.
1:24f9f14:         if (repeats == 1 && iterations == 1)
1:24f9f14:             return;
1:24f9f14:         
1:f8fd911:         long total=0;
1:f8fd911:         
1:f8fd911:         if ( repeats > 1) 
1:f8fd911:             for (int i = 1; i < repeats; i++)
1:f8fd911:                 total += runs[i];
1:f8fd911:         else
1:f8fd911:             total = runs[0];
1:f8fd911: 
1:c3bf4ea:         System.out.println("Test-" + getName() +
1:c3bf4ea:                 ": framework:"+ getTestConfiguration().getJDBCClient().getName()+
1:c3bf4ea:                 ":iterations: " + iterations
1:f8fd911:                 + " : Avg elapsedTime(ms): " + 
1:f8fd911:                 total / (repeats > 1 ? (long) (repeats - 1) : (long) repeats));
1:f8fd911:     }
1:f8fd911:     
1:f8fd911:     /**
1:f8fd911:      * Overrides runTest from TestCase, in order to gather 
1:f8fd911:      * elapsed time information. 
1:f8fd911:      * Run the testfixture for 'iterations' times and store the time 
1:f8fd911:      * taken for the particular testrun and print it to System.out
1:f8fd911:      * Note: this method will NOT time the setUp or tearDown methods 
1:f8fd911:      */
1:f8fd911:     protected void runTest() throws Throwable {
1:f8fd911:         startTime = System.currentTimeMillis();
1:f8fd911:         for (int j = 0; j < iterations; j++) 
1:f8fd911:             super.runTest();
1:f8fd911:         endTime = System.currentTimeMillis();
1:f8fd911:         runs[testRunNum] = (endTime-startTime);
1:c3bf4ea:         System.out.println("Test-" + getName() + 
1:c3bf4ea:                 ": framework:"+ getTestConfiguration().getJDBCClient().getName()+
1:c3bf4ea:                 ": run#" + testRunNum
1:f8fd911:                 + " iterations: " + iterations + " : elapsedTime(ms): "
1:f8fd911:                 + (endTime - startTime));
1:f8fd911:     }
1:f8fd911: }
============================================================================
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:dbed020
/////////////////////////////////////////////////////////////////////////
1:  * If  a test has R repeats and (R&gt;1), then the average elapsed time of the
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:1ae02c9
/////////////////////////////////////////////////////////////////////////
1:  *  BaseTestSuite suite = new BaseTestSuite();
1:  * BaseTestSuite client = new BaseTestSuite("Client");
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:ade6fcf
/////////////////////////////////////////////////////////////////////////
1:     protected void runBareOverridable() throws Throwable
1:             super.runBareOverridable();
commit:c3bf4ea
/////////////////////////////////////////////////////////////////////////
1:         System.out.println("Test-" + getName() +
1:                 ": framework:"+ getTestConfiguration().getJDBCClient().getName()+
1:                 ":iterations: " + iterations
/////////////////////////////////////////////////////////////////////////
1:         System.out.println("Test-" + getName() + 
1:                 ": framework:"+ getTestConfiguration().getJDBCClient().getName()+
1:                 ": run#" + testRunNum
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:24f9f14
/////////////////////////////////////////////////////////////////////////
1:         // For a single run no point in printing a summary that's
1:         // identical to the one run output.
1:         if (repeats == 1 && iterations == 1)
1:             return;
1:         
commit:f8fd911
/////////////////////////////////////////////////////////////////////////
1: /*
1:  *
1:  * Derby - Class JDBCPerfTestCase
1:  *
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, 
1:  * software distributed under the License is distributed on an 
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, 
1:  * either express or implied. See the License for the specific 
1:  * language governing permissions and limitations under the License.
1:  */
1: package org.apache.derbyTesting.junit;
1: 
1: 
1: /**
1:  * Base Class for performance tests. It is useful for a performance test
1:  * framework to have ability to run a test for I iterations , and repeat the
1:  * test R times. This class provides this functionality of timing the test for I
1:  * iterations and repeating the test in the same jvm for R number of
1:  * times. 
1:  * 
1:  * For JDBCPerfTestCase with R repeats and I iterations
1:  * 
1:  * This cycle is repeated R times 
1:  * {
1:  *    setUp run once 
1:  *    fixture method is run I times(and timed) 
1:  *    tearDown is run once
1:  * }
1:  *
1:  * 
1:  * Results are printed out to System.out currently. For each repeat of the test, 
1:  * the elapsed time is printed out and after R repeats of the test, the average
1:  * elapsed time is also printed.
1:  *  
0:  * If  a test has R repeats and (R>1), then the average elapsed time of the
1:  * (R-1) runs is printed out and the timing info collected as part of the first 
1:  * testrun is ignored. 
1:  * If R=1, then the average elapsed time prints time for that
1:  * only run. 
1:  * 
1:  * To see the current output that is printed out, see methods runBare() and 
1:  * runTest()
1:  * 
1:  * To write a performance test, extend the JDBCPerfTestCase 
1:  * In the example below, ScanCoveredIdxTest is a performance test that 
1:  * extends JDBCPerfTestCase. See below code snippet on how 
1:  * these tests will be added/used.  
1:  * <CODE>
1:  *  // Add a test fixture 'scanAllRows' in ScanCoveredIdxTest 
1:  *  // and to run this test for 100 iterations and to 
1:  *  // repeat the test 4 times.
1:  *  int iterations = 100; 
1:  *  int repeats = 4; 
0:  *  TestSuite suite = new TestSuite();
1:  *  suite.addTest(new ScanCoveredIdxTest("scanAllRows",iterations,repeats));
1:  * 
1:  *  // To add client tests. 
0:  * TestSuite client = new TestSuite("Client");
1:  * client.addTest(new ScanCoveredIdxTest("scanAllRows",iterations,repeats));
1:  * client.addTest(new ScanCoveredIdxTest("scanAndRetrieveAllRows",iterations,repeats));
1:  * 
1:  * // This will add the server decorator that will start the
1:  * // server on setUp of the suite and stop server on tearDown 
1:  * // of the suite.
1:  * suite.addTest(TestConfiguration.clientServerDecorator(client));
1:  * </CODE>
1:  * 
1:  * Some improvement areas/ideas: 
1:  * -- Can we use TestResult ,and our own TestRunner to improve on how the 
1:  * results are reported.  
1:  * -- write the perf results to a file that can be easily consumed for reporting purposes
1:  * and further analysis against different builds.
1:  * -- Maybe even write the results out in xml format,and then using xsl the results
1:  * could be rendered into html reports
1:  */
1: public class JDBCPerfTestCase extends BaseJDBCTestCase {
1:     
1:     /**
1:      * store timing information
1:      */
1:     private long startTime,endTime;
1:     
1:     /**
1:      * Store info on how many times the test fixture should be run
1:      * also see runTest() on how iterations is used 
1:      */
1:     private int iterations = 1;
1:     
1:     /**
1:      * Store info on how many times should the test be repeated
1:      * default value is 1
1:      */
1:     private int repeats = 1;
1:     
1:     /**
1:      * Hold the elapsedtime info for the testRun
1:      * given by testRunNum
1:      */
1:     private int testRunNum = 0;
1:     
1:     /**
1:      * store the elapsed time info for the test runs.
1:      */
1:     private long[] runs;
1:     
1:     
1:     public JDBCPerfTestCase(String name)
1:     {
1:         super(name);
1:         runs = new long[repeats];
1:     }
1:     
1:     /**
1:      * @param name testname
1:      * @param iterations iterations of the test to measure at one shot.
1:      * @param repeats is the number of times the entire test be repeated
1:      * @see JDBCPerfTestCase  class level comments
1:      */
1:     public JDBCPerfTestCase(String name,int iterations, int repeats)
1:     {
1:         super(name);
1:         this.iterations = iterations;
1:         this.repeats = repeats;
1:         runs = new long[repeats];
1: 
1:     }
1:     
1:   
1:     /**
1:      * runBare, do the whole thing - setup, runTest, cleanup
1:      * 'repeats' times.
1:      * If test was run for more than one time, then ignore the 
1:      * first testrun results and print the average elapsed time 
1:      * for the remaining runs.  
1:      */
0:     public void runBare() throws Throwable
1:     {
1:         for (int i = 0; i < repeats; i++)
1:         {
1:             println("Repeat ="+i);
0:             super.runBare();
1:             testRunNum++;
1:         }
1:         
1:         long total=0;
1:         
1:         if ( repeats > 1) 
1:             for (int i = 1; i < repeats; i++)
1:                 total += runs[i];
1:         else
1:             total = runs[0];
1: 
0:         System.out.println("Test-" + getName() + ":iterations: " + iterations
1:                 + " : Avg elapsedTime(ms): " + 
1:                 total / (repeats > 1 ? (long) (repeats - 1) : (long) repeats));
1:     }
1:     
1:     /**
1:      * Overrides runTest from TestCase, in order to gather 
1:      * elapsed time information. 
1:      * Run the testfixture for 'iterations' times and store the time 
1:      * taken for the particular testrun and print it to System.out
1:      * Note: this method will NOT time the setUp or tearDown methods 
1:      */
1:     protected void runTest() throws Throwable {
1:         startTime = System.currentTimeMillis();
1:         for (int j = 0; j < iterations; j++) 
1:             super.runTest();
1:         endTime = System.currentTimeMillis();
1:         runs[testRunNum] = (endTime-startTime);
0:         System.out.println("Test-" + getName() + ": run#" + testRunNum
1:                 + " iterations: " + iterations + " : elapsedTime(ms): "
1:                 + (endTime - startTime));
1:         
1:     }
1: }
============================================================================
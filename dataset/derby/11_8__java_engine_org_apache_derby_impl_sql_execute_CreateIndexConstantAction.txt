1:eac0369: /*
1:cf87079: 
1:345de35:    Derby - Class org.apache.derby.impl.sql.execute.CreateIndexConstantAction
1:345de35: 
1:f6123ee:    Licensed to the Apache Software Foundation (ASF) under one or more
1:f6123ee:    contributor license agreements.  See the NOTICE file distributed with
1:f6123ee:    this work for additional information regarding copyright ownership.
1:f6123ee:    The ASF licenses this file to you under the Apache License, Version 2.0
1:f6123ee:    (the "License"); you may not use this file except in compliance with
1:f6123ee:    the License.  You may obtain a copy of the License at
1:345de35: 
1:345de35:       http://www.apache.org/licenses/LICENSE-2.0
1:345de35: 
1:345de35:    Unless required by applicable law or agreed to in writing, software
1:345de35:    distributed under the License is distributed on an "AS IS" BASIS,
1:345de35:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:345de35:    See the License for the specific language governing permissions and
1:345de35:    limitations under the License.
1:345de35: 
6:eac0369:  */
21:eac0369: 
1:eac0369: package org.apache.derby.impl.sql.execute;
1:eac0369: 
1:1e2aae0: import java.util.Properties;
1:1e2aae0: import org.apache.derby.catalog.UUID;
1:1e2aae0: import org.apache.derby.catalog.types.StatisticsImpl;
1:1e2aae0: import org.apache.derby.iapi.error.StandardException;
1:1e2aae0: import org.apache.derby.iapi.reference.SQLState;
1:1e2aae0: import org.apache.derby.iapi.services.io.FormatableBitSet;
1:eac0369: import org.apache.derby.iapi.services.loader.ClassFactory;
1:1e2aae0: import org.apache.derby.iapi.sql.Activation;
1:1e2aae0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1:1e2aae0: import org.apache.derby.iapi.sql.depend.DependencyManager;
2:eac0369: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptor;
1:eac0369: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptorList;
1:eac0369: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptor;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptorList;
1:eac0369: import org.apache.derby.iapi.sql.dictionary.ConstraintDescriptor;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.DataDescriptorGenerator;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.IndexRowGenerator;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.SchemaDescriptor;
1:eac0369: import org.apache.derby.iapi.sql.dictionary.StatisticsDescriptor;
1:1e2aae0: import org.apache.derby.iapi.sql.dictionary.TableDescriptor;
1:1e2aae0: import org.apache.derby.iapi.sql.execute.ConstantAction;
1:1e2aae0: import org.apache.derby.iapi.sql.execute.ExecIndexRow;
1:1e2aae0: import org.apache.derby.iapi.sql.execute.ExecRow;
1:28e234d: import org.apache.derby.iapi.store.access.AccessFactoryGlobals;
1:eac0369: import org.apache.derby.iapi.store.access.ColumnOrdering;
1:eac0369: import org.apache.derby.iapi.store.access.ConglomerateController;
1:eac0369: import org.apache.derby.iapi.store.access.GroupFetchScanController;
1:eac0369: import org.apache.derby.iapi.store.access.RowLocationRetRowSource;
1:eac0369: import org.apache.derby.iapi.store.access.SortController;
1:1e2aae0: import org.apache.derby.iapi.store.access.SortObserver;
1:eac0369: import org.apache.derby.iapi.store.access.TransactionController;
1:1e2aae0: import org.apache.derby.iapi.types.DataTypeDescriptor;
1:eac0369: import org.apache.derby.iapi.types.DataValueDescriptor;
1:1e2aae0: import org.apache.derby.iapi.types.RowLocation;
1:1e2aae0: import org.apache.derby.iapi.types.TypeId;
1:bce78c9: import org.apache.derby.impl.services.daemon.IndexStatisticsDaemonImpl;
1:0c5bc3a: import org.apache.derby.shared.common.sanity.SanityManager;
1:bce78c9: 
1:cf87079: /**
1:1429957:  * ConstantAction to create an index either through
1:1429957:  * a CREATE INDEX statement or as a backing index to
1:1429957:  * a constraint.
1:eac0369:  */
1:eac0369: 
1:eac0369: class CreateIndexConstantAction extends IndexConstantAction
4:eac0369: {
1:1b41764:     /**
1:1b41764:      * Is this for a CREATE TABLE, i.e. it is
1:1b41764:      * for a constraint declared in a CREATE TABLE
1:1b41764:      * statement that requires a backing index.
1:1b41764:      */
1:1b41764:     private final boolean forCreateTable;
1:eac0369: 
1:eac0369: 	private boolean			unique;
1:28e234d: 	private boolean			uniqueWithDuplicateNulls;
1:0c5bc3a: 
1:0c5bc3a:     /**
1:0c5bc3a:      * The index represents a PRIMARY KEY or a UNIQUE NOT NULL constraint which
1:0c5bc3a:      * is deferrable.
1:0c5bc3a:      * {@code true} implies {@code unique == false} and
1:0c5bc3a:      * {@code uniqueWithDuplicateNulls == false} and
1:0c5bc3a:      * {@code hasDeferrableChecking == true}.
1:0c5bc3a:      */
1:0c5bc3a:     private boolean         uniqueDeferrable;
1:0c5bc3a: 
1:0c5bc3a:     /**
1:0c5bc3a:      * The index duplicate checking is deferrable. {@code true} implies {@code
1:0c5bc3a:      * unique == false} and {@code (uniqueDeferrable ||
1:0c5bc3a:      * uniqueWithDuplicateNulls)}.
1:0c5bc3a:      *
1:0c5bc3a:      */
1:0c5bc3a:     private final boolean   hasDeferrableChecking;
1:0c5bc3a: 
1:0c5bc3a:     /**
1:0c5bc3a:      * Used to determine sorting behavior for existing rows if any
1:0c5bc3a:      */
1:0c5bc3a:     private final boolean   initiallyDeferred;
1:0c5bc3a: 
1:2db96c5:     /**
1:2db96c5:      * The constraint type, see 
1:2db96c5:      * {@link org.apache.derby.iapi.sql.dictionary.DataDictionary} 
1:2db96c5:      * definition of constants.
1:2db96c5:      */
1:2db96c5:     private final int       constraintType;
1:2db96c5:     
1:eac0369: 	private String			indexType;
1:eac0369: 	private String[]		columnNames;
1:eac0369: 	private boolean[]		isAscending;
1:eac0369: 	private boolean			isConstraint;
1:eac0369: 	private UUID			conglomerateUUID;
1:eac0369: 	private Properties		properties;
1:eac0369: 
1:eac0369: 	private ExecRow indexTemplateRow;
1:eac0369: 
1:cf87079: 	/** Conglomerate number for the conglomerate created by this
1:cf87079: 	 * constant action; -1L if this constant action has not been
1:cf87079: 	 * executed.  If this constant action doesn't actually create
1:cf87079: 	 * a new conglomerate--which can happen if it finds an existing
1:cf87079: 	 * conglomerate that satisfies all of the criteria--then this
1:cf87079: 	 * field will hold the conglomerate number of whatever existing
1:cf87079: 	 * conglomerate was found.
1:cf87079: 	 */
1:cf87079: 	private long conglomId;
1:cf87079: 
1:cf87079: 	/** Conglomerate number of the physical conglomerate that we
1:cf87079: 	 * will "replace" using this constant action.  That is, if
1:cf87079: 	 * the purpose of this constant action is to create a new physical
1:cf87079: 	 * conglomerate to replace a dropped physical conglomerate, then
1:cf87079: 	 * this field holds the conglomerate number of the dropped physical
1:cf87079: 	 * conglomerate. If -1L then we are not replacing a conglomerate,
1:cf87079: 	 * we're simply creating a new index (and backing physical
1:cf87079: 	 * conglomerate) as normal.
1:cf87079: 	 */
1:cf87079: 	private long droppedConglomNum;
1:eac0369: 
1:eac0369: 	// CONSTRUCTORS
3:eac0369: 	/**
1:28e234d:      * 	Make the ConstantAction to create an index.
1:28e234d:      * 
1:28e234d:      * @param forCreateTable                Being executed within a CREATE TABLE
1:28e234d:      *                                      statement
1:28e234d:      * @param unique		                True means it will be a unique index
1:435735b:      * @param uniqueWithDuplicateNulls      True means index check and disallow
1:28e234d:      *                                      any duplicate key if key has no 
1:28e234d:      *                                      column with a null value.  If any 
1:28e234d:      *                                      column in the key has a null value,
1:28e234d:      *                                      no checking is done and insert will
1:28e234d:      *                                      always succeed.
1:0c5bc3a:      * @param hasDeferrableChecking         True means this index backs a
1:0c5bc3a:      *                                      deferrable constraint. isConstraint
1:0c5bc3a:      *                                      will be true.
1:0c5bc3a:      * @param initiallyDeferred             True means the index represents
1:0c5bc3a:      *                                      a deferred constraint. Implies
1:0c5bc3a:      *                                      hasDeferrableChecking.
1:28e234d:      * @param indexType	                    type of index (BTREE, for example)
1:28e234d:      * @param schemaName	                schema that table (and index) 
1:28e234d:      *                                      lives in.
1:28e234d:      * @param indexName	                    Name of the index
1:28e234d:      * @param tableName	                    Name of table the index will be on
1:28e234d:      * @param tableId		                UUID of table
1:28e234d:      * @param columnNames	                Names of the columns in the index, 
1:28e234d:      *                                      in order
1:28e234d:      * @param isAscending	                Array of booleans telling asc/desc 
1:28e234d:      *                                      on each column
1:28e234d:      * @param isConstraint	                TRUE if index is backing up a 
1:28e234d:      *                                      constraint, else FALSE
1:28e234d:      * @param conglomerateUUID	            ID of conglomerate
1:28e234d:      * @param properties	                The optional properties list 
1:28e234d:      *                                      associated with the index.
1:28e234d:      */
1:eac0369: 	CreateIndexConstantAction(
1:28e234d:             boolean         forCreateTable,
1:28e234d:             boolean			unique,
1:28e234d:             boolean			uniqueWithDuplicateNulls,
1:0c5bc3a:             boolean         hasDeferrableChecking,
1:0c5bc3a:             boolean         initiallyDeferred,
1:2db96c5:             int             constraintType,
1:28e234d:             String			indexType,
1:28e234d:             String			schemaName,
1:28e234d:             String			indexName,
1:28e234d:             String			tableName,
1:28e234d:             UUID			tableId,
1:28e234d:             String[]		columnNames,
1:28e234d:             boolean[]		isAscending,
1:28e234d:             boolean			isConstraint,
1:28e234d:             UUID			conglomerateUUID,
1:28e234d:             Properties		properties)
1:eac0369: 	{
1:eac0369: 		super(tableId, indexName, tableName, schemaName);
1:435735b: 
1:435735b:         this.forCreateTable             = forCreateTable;
1:0c5bc3a:         this.unique                     = unique && !hasDeferrableChecking;
1:435735b: 		this.uniqueWithDuplicateNulls   = uniqueWithDuplicateNulls;
1:0c5bc3a:         this.hasDeferrableChecking      = hasDeferrableChecking;
1:0c5bc3a:         this.initiallyDeferred          = initiallyDeferred;
1:2db96c5:         this.constraintType             = constraintType;
1:0c5bc3a:         this.uniqueDeferrable           = unique && hasDeferrableChecking;
1:435735b: 		this.indexType                  = indexType;
1:435735b: 		this.columnNames                = columnNames;
1:435735b: 		this.isAscending                = isAscending;
1:435735b: 		this.isConstraint               = isConstraint;
1:435735b: 		this.conglomerateUUID           = conglomerateUUID;
1:435735b: 		this.properties                 = properties;
1:435735b: 		this.conglomId                  = -1L;
1:435735b: 		this.droppedConglomNum          = -1L;
1:cf87079: 	}
1:28e234d: 
1:bce78c9: 	/**
1:cf87079: 	 * Make a ConstantAction that creates a new physical conglomerate
1:cf87079: 	 * based on index information stored in the received descriptors.
1:cf87079: 	 * Assumption is that the received ConglomerateDescriptor is still
1:cf87079: 	 * valid (meaning it has corresponding entries in the system tables
1:cf87079: 	 * and it describes some constraint/index that has _not_ been
1:cf87079: 	 * dropped--though the physical conglomerate underneath has).
1:cf87079: 	 *
1:cf87079: 	 * This constructor is used in cases where the physical conglomerate
1:cf87079: 	 * for an index has been dropped but the index still exists. That
1:cf87079: 	 * can happen if multiple indexes share a physical conglomerate but
1:cf87079: 	 * then the conglomerate is dropped as part of "drop index" processing
1:cf87079: 	 * for one of the indexes. (Note that "indexes" here includes indexes
1:cf87079: 	 * which were created to back constraints.) In that case we have to
1:cf87079: 	 * create a new conglomerate to satisfy the remaining sharing indexes,
1:cf87079: 	 * so that's what we're here for.  See ConglomerateDescriptor.drop()
1:cf87079: 	 * for details on when that is necessary.
1:cf87079: 	 */
1:cf87079: 	CreateIndexConstantAction(ConglomerateDescriptor srcCD,
1:cf87079: 		TableDescriptor td, Properties properties)
1:cf87079: 	{
1:cf87079: 		super(td.getUUID(),
1:cf87079: 			srcCD.getConglomerateName(), td.getName(), td.getSchemaName());
1:cf87079: 
1:cf87079: 		this.forCreateTable = false;
1:cf87079: 
1:cf87079: 		/* We get here when a conglomerate has been dropped and we
1:cf87079: 		 * need to create (or find) another one to fill its place.
1:cf87079: 		 * At this point the received conglomerate descriptor still
1:cf87079: 		 * references the old (dropped) conglomerate, so we can
1:cf87079: 		 * pull the conglomerate number from there.
1:cf87079: 		 */
1:cf87079: 		this.droppedConglomNum = srcCD.getConglomerateNumber();
1:cf87079: 
1:cf87079: 		/* Plug in the rest of the information from the received
1:cf87079: 		 * descriptors.
1:cf87079: 		 */
1:cf87079: 		IndexRowGenerator irg = srcCD.getIndexDescriptor();
1:cf87079: 		this.unique = irg.isUnique();
1:477fd5e: 		this.uniqueWithDuplicateNulls = irg.isUniqueWithDuplicateNulls();
1:0c5bc3a:         this.hasDeferrableChecking = false; // N/A such indexes are not shared
1:0c5bc3a:         this.uniqueDeferrable = false;      // N/A
1:0c5bc3a:         this.initiallyDeferred = false;     // N/A
1:2db96c5:         this.constraintType = -1;           // N/A
1:cf87079: 		this.indexType = irg.indexType();
1:cf87079: 		this.columnNames = srcCD.getColumnNames();
1:cf87079: 		this.isAscending = irg.isAscending();
1:cf87079: 		this.isConstraint = srcCD.isConstraint();
1:cf87079: 		this.conglomerateUUID = srcCD.getUUID();
1:cf87079: 		this.properties = properties;
2:cf87079: 		this.conglomId = -1L;
1:cf87079: 
1:cf87079: 		/* The ConglomerateDescriptor may not know the names of
1:cf87079: 		 * the columns it includes.  If that's true (which seems
1:cf87079: 		 * to be the more common case) then we have to build the
1:cf87079: 		 * list of ColumnNames ourselves.
1:cf87079: 		 */
1:cf87079: 		if (columnNames == null)
1:cf87079: 		{
1:cf87079: 			int [] baseCols = irg.baseColumnPositions();
1:cf87079: 			columnNames = new String[baseCols.length];
1:cf87079: 			ColumnDescriptorList colDL = td.getColumnDescriptorList();
1:cf87079: 			for (int i = 0; i < baseCols.length; i++)
1:cf87079: 			{
1:cf87079: 				columnNames[i] =
1:cf87079: 					colDL.elementAt(baseCols[i]-1).getColumnName();
1:cf87079: 			}
1:cf87079: 		}
5:eac0369: 	}
1:eac0369:         
1:eac0369: 	///////////////////////////////////////////////
1:eac0369: 	//
1:eac0369: 	// OBJECT SHADOWS
1:eac0369: 	//
1:eac0369: 	///////////////////////////////////////////////
1:801cf0d:     @Override
1:eac0369: 	public	String	toString()
1:eac0369: 	{
1:eac0369: 		// Do not put this under SanityManager.DEBUG - it is needed for
1:eac0369: 		// error reporting.
1:eac0369: 		return "CREATE INDEX " + indexName;
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	// INTERFACE METHODS
1:eac0369: 
1:eac0369: 
1:eac0369: 	/**
1:1429957: 	 *	This is the guts of the Execution-time logic for 
1:1429957:      *  creating an index.
1:1429957:      *
1:1429957:      *  <P>
1:1429957:      *  A index is represented as:
1:1429957:      *  <UL>
1:1429957:      *  <LI> ConglomerateDescriptor.
1:1429957:      *  </UL>
1:1429957:      *  No dependencies are created.
1:1429957:    	 *
1:1429957:      *  @see ConglomerateDescriptor
1:1429957:      *  @see SchemaDescriptor
1:eac0369: 	 *	@see ConstantAction#executeConstantAction
6:eac0369: 	 *
1:eac0369: 	 * @exception StandardException		Thrown on failure
1:eac0369: 	 */
1:eac0369: 	public void	executeConstantAction( Activation activation )
2:eac0369: 						throws StandardException
1:eac0369: 	{
1:eac0369: 		TableDescriptor 			td;
1:eac0369: 		UUID 						toid;
1:eac0369: 		ColumnDescriptor			columnDescriptor;
1:eac0369: 		int[]						baseColumnPositions;
1:eac0369: 		IndexRowGenerator			indexRowGenerator = null;
1:eac0369: 		ExecRow[]					baseRows;
1:eac0369: 		ExecIndexRow[]				indexRows;
1:eac0369: 		ExecRow[]					compactBaseRows;
1:eac0369: 		GroupFetchScanController    scan;
1:eac0369: 		RowLocationRetRowSource	    rowSource;
1:eac0369: 		long						sortId;
1:eac0369: 		int							maxBaseColumnPosition = -1;
1:eac0369: 
1:eac0369: 		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
1:eac0369: 		DataDictionary dd = lcc.getDataDictionary();
1:eac0369: 		DependencyManager dm = dd.getDependencyManager();
1:eac0369: 		TransactionController tc = lcc.getTransactionExecute();
1:eac0369: 
1:eac0369: 		/*
1:eac0369: 		** Inform the data dictionary that we are about to write to it.
1:eac0369: 		** There are several calls to data dictionary "get" methods here
1:eac0369: 		** that might be done in "read" mode in the data dictionary, but
1:eac0369: 		** it seemed safer to do this whole operation in "write" mode.
1:eac0369: 		**
1:eac0369: 		** We tell the data dictionary we're done writing at the end of
1:eac0369: 		** the transaction.
1:eac0369: 		*/
1:eac0369: 		dd.startWriting(lcc);
1:eac0369: 
1:eac0369: 		/*
1:eac0369: 		** If the schema descriptor is null, then
1:eac0369: 		** we must have just read ourselves in.  
1:eac0369: 		** So we will get the corresponding schema
1:eac0369: 		** descriptor from the data dictionary.
1:eac0369: 		*/
1:eac0369: 		SchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;
1:eac0369: 
1:eac0369: 
1:eac0369: 		/* Get the table descriptor. */
1:eac0369: 		/* See if we can get the TableDescriptor 
1:eac0369: 		 * from the Activation.  (Will be there
1:eac0369: 		 * for backing indexes.)
1:eac0369: 		 */
1:eac0369: 		td = activation.getDDLTableDescriptor();
1:eac0369: 
1:eac0369: 		if (td == null)
1:eac0369: 		{
1:eac0369: 			/* tableId will be non-null if adding an index to
1:eac0369: 			 * an existing table (as opposed to creating a
1:eac0369: 			 * table with a constraint with a backing index).
1:eac0369: 			 */
1:eac0369: 			if (tableId != null)
1:eac0369: 			{
1:eac0369: 				td = dd.getTableDescriptor(tableId);
1:eac0369: 			}
1:eac0369: 			else
1:eac0369: 			{
1:0978789: 				td = dd.getTableDescriptor(tableName, sd, tc);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		if (td == null)
1:eac0369: 		{
1:eac0369: 			throw StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, 
1:eac0369: 						indexName, tableName);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		if (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)
1:eac0369: 		{
1:eac0369: 			throw StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, 
1:eac0369: 						indexName, tableName);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		/* Get a shared table lock on the table. We need to lock table before
1:eac0369: 		 * invalidate dependents, otherwise, we may interfere with the
1:eac0369: 		 * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/
1:eac0369: 		 * docs/language/SolutionsToConcurrencyIssues.txt (point f).
1:eac0369: 		 */
1:eac0369: 		lockTableForDDL(tc, td.getHeapConglomerateId(), false);
1:eac0369: 
1:eac0369: 		// invalidate any prepared statements that
1:eac0369: 		// depended on this table (including this one)
1:eac0369: 		if (! forCreateTable)
1:eac0369: 		{
1:eac0369: 			dm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// Translate the base column names to column positions
1:eac0369: 		baseColumnPositions = new int[columnNames.length];
1:eac0369: 		for (int i = 0; i < columnNames.length; i++)
1:eac0369: 		{
1:eac0369: 			// Look up the column in the data dictionary
1:eac0369: 			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
1:eac0369: 			if (columnDescriptor == null)
1:eac0369: 			{
1:eac0369: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, 
1:eac0369: 															columnNames[i],
1:eac0369: 															tableName);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			TypeId typeId = columnDescriptor.getType().getTypeId();
1:eac0369: 
1:eac0369: 			// Don't allow a column to be created on a non-orderable type
1:eac0369: 			ClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();
1:eac0369: 			boolean isIndexable = typeId.orderable(cf);
1:eac0369: 
1:eac0369: 			if (isIndexable && typeId.userType()) {
1:eac0369: 				String userClass = typeId.getCorrespondingJavaTypeName();
1:eac0369: 
1:eac0369: 				// Don't allow indexes to be created on classes that
1:eac0369: 				// are loaded from the database. This is because recovery
1:eac0369: 				// won't be able to see the class and it will need it to
1:eac0369: 				// run the compare method.
1:eac0369: 				try {
1:eac0369: 					if (cf.isApplicationClass(cf.loadApplicationClass(userClass)))
1:eac0369: 						isIndexable = false;
1:eac0369: 				} catch (ClassNotFoundException cnfe) {
1:eac0369: 					// shouldn't happen as we just check the class is orderable
1:eac0369: 					isIndexable = false;
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			if (!isIndexable) {
1:eac0369: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, 
1:eac0369: 					typeId.getSQLTypeName());
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// Remember the position in the base table of each column
1:eac0369: 			baseColumnPositions[i] = columnDescriptor.getPosition();
1:eac0369: 
1:eac0369: 			if (maxBaseColumnPosition < baseColumnPositions[i])
1:eac0369: 				maxBaseColumnPosition = baseColumnPositions[i];
1:eac0369: 		}
1:eac0369: 
1:cf87079: 		/* The code below tries to determine if the index that we're about
1:cf87079: 		 * to create can "share" a conglomerate with an existing index.
1:cf87079: 		 * If so, we will use a single physical conglomerate--namely, the
1:cf87079: 		 * one that already exists--to support both indexes. I.e. we will
1:cf87079: 		 * *not* create a new conglomerate as part of this constant action.
1:0c5bc3a:          *
1:0c5bc3a:          * Deferrable constraints are backed by indexes that are *not* shared
1:0c5bc3a:          * since they use physically non-unique indexes and as such are
1:0c5bc3a:          * different from indexes used to represent non-deferrable
1:0c5bc3a:          * constraints.
1:cf87079: 		 */ 
1:cf87079: 
1:eac0369: 		// check if we have similar indices already for this table
1:eac0369: 		ConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();
1:cf87079: 		boolean shareExisting = false;
1:eac0369: 		for (int i = 0; i < congDescs.length; i++)
1:eac0369: 		{
1:eac0369: 			ConglomerateDescriptor cd = congDescs[i];
1:eac0369: 			if ( ! cd.isIndex())
1:eac0369: 				continue;
1:cf87079: 
1:cf87079: 			if (droppedConglomNum == cd.getConglomerateNumber())
1:cf87079: 			{
1:cf87079: 				/* We can't share with any conglomerate descriptor
1:cf87079: 				 * whose conglomerate number matches the dropped
1:cf87079: 				 * conglomerate number, because that descriptor's
1:cf87079: 				 * backing conglomerate was dropped, as well.  If
1:cf87079: 				 * we're going to share, we have to share with a
1:cf87079: 				 * descriptor whose backing physical conglomerate
1:cf87079: 				 * is still around.
1:cf87079: 				 */
1:cf87079: 				continue;
1:cf87079: 			}
1:cf87079: 
1:eac0369: 			IndexRowGenerator irg = cd.getIndexDescriptor();
1:eac0369: 			int[] bcps = irg.baseColumnPositions();
1:eac0369: 			boolean[] ia = irg.isAscending();
1:eac0369: 			int j = 0;
1:eac0369: 
1:cf87079: 			/* The conditions which allow an index to share an existing
1:cf87079: 			 * conglomerate are as follows:
1:cf87079: 			 *
1:eac0369: 			 * 1. the set of columns (both key and include columns) and their 
1:eac0369: 			 *  order in the index is the same as that of an existing index AND 
1:477fd5e: 			 *
1:eac0369: 			 * 2. the ordering attributes are the same AND 
1:477fd5e: 			 *
1:477fd5e: 			 * 3. one of the following is true:
1:477fd5e: 			 *    a) the existing index is unique, OR
1:477fd5e: 			 *    b) the existing index is non-unique with uniqueWhenNotNulls
1:477fd5e: 			 *       set to TRUE and the index being created is non-unique, OR
1:477fd5e: 			 *    c) both the existing index and the one being created are
1:477fd5e: 			 *       non-unique and have uniqueWithDuplicateNulls set to FALSE.
1:0c5bc3a:              *
1:0c5bc3a:              * 4. hasDeferrableChecking is FALSE.
1:0c5bc3a:              */
1:0c5bc3a:             boolean possibleShare =
1:0c5bc3a:                     (irg.isUnique() || !unique) &&
1:0c5bc3a:                     (bcps.length == baseColumnPositions.length) &&
1:0c5bc3a:                     !hasDeferrableChecking;
1:eac0369: 
1:477fd5e: 			//check if existing index is non unique and uniqueWithDuplicateNulls
1:477fd5e: 			//is set to true (backing index for unique constraint)
1:477fd5e: 			if (possibleShare && !irg.isUnique ())
1:477fd5e: 			{
1:477fd5e: 				/* If the existing index has uniqueWithDuplicateNulls set to
1:477fd5e: 				 * TRUE it can be shared by other non-unique indexes; otherwise
1:477fd5e: 				 * the existing non-unique index has uniqueWithDuplicateNulls
1:477fd5e: 				 * set to FALSE, which means the new non-unique conglomerate
1:477fd5e: 				 * can only share if it has uniqueWithDuplicateNulls set to
1:477fd5e: 				 * FALSE, as well.
1:477fd5e: 				 */
1:477fd5e: 				possibleShare = (irg.isUniqueWithDuplicateNulls() ||
1:477fd5e: 								! uniqueWithDuplicateNulls);
1:477fd5e: 			}
1:477fd5e: 
1:cf87079: 			if (possibleShare && indexType.equals(irg.indexType()))
1:eac0369: 			{
1:eac0369: 				for (; j < bcps.length; j++)
1:eac0369: 				{
1:eac0369: 					if ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))
1:eac0369: 						break;
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 
1:cf87079: 			if (j == baseColumnPositions.length)	// share
1:eac0369: 			{
1:eac0369: 				/*
1:eac0369: 				 * Don't allow users to create a duplicate index. Allow if being done internally
1:eac0369: 				 * for a constraint
1:cf87079: 				 */
1:eac0369: 				if (!isConstraint)
1:eac0369: 				{
1:eac0369: 					activation.addWarning(
1:eac0369: 							StandardException.newWarning(
1:eac0369: 								SQLState.LANG_INDEX_DUPLICATE,
1:75d58b2: 								indexName,
1:eac0369: 								cd.getConglomerateName()));
1:eac0369: 
1:eac0369: 					return;
1:eac0369: 				}
1:eac0369: 
1:cf87079: 				/* Sharing indexes share the physical conglomerate
1:cf87079: 				 * underneath, so pull the conglomerate number from
1:cf87079: 				 * the existing conglomerate descriptor.
1:cf87079: 				 */
1:eac0369: 				conglomId = cd.getConglomerateNumber();
1:cf87079: 
1:cf87079: 				/* We create a new IndexRowGenerator because certain
1:cf87079: 				 * attributes--esp. uniqueness--may be different between
1:cf87079: 				 * the index we're creating and the conglomerate that
1:cf87079: 				 * already exists.  I.e. even though we're sharing a
1:cf87079: 				 * conglomerate, the new index is not necessarily
1:cf87079: 				 * identical to the existing conglomerate. We have to
1:cf87079: 				 * keep track of that info so that if we later drop
1:cf87079: 				 * the shared physical conglomerate, we can figure out
1:cf87079: 				 * what this index (the one we're creating now) is
1:cf87079: 				 * really supposed to look like.
1:cf87079: 				 */
1:cf87079: 				indexRowGenerator =
1:cf87079: 					new IndexRowGenerator(
1:477fd5e: 						indexType, unique, uniqueWithDuplicateNulls,
1:0c5bc3a:                         false, // uniqueDeferrable
1:0c5bc3a:                         false, // deferrable indexes are not shared
1:28e234d: 						baseColumnPositions,
1:28e234d: 						isAscending,
1:cf87079: 						baseColumnPositions.length);
1:cf87079: 
1:e1d51e3: 				//DERBY-655 and DERBY-1343  
1:cf87079: 				// Sharing indexes will have unique logical conglomerate UUIDs.
1:e1d51e3: 				conglomerateUUID = dd.getUUIDFactory().createUUID();
1:cf87079: 				shareExisting = true;
1:eac0369: 				break;
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:cf87079: 		/* If we have a droppedConglomNum then the index we're about to
1:cf87079: 		 * "create" already exists--i.e. it has an index descriptor and
1:cf87079: 		 * the corresponding information is already in the system catalogs.
1:cf87079: 		 * The only thing we're missing, then, is the physical conglomerate
1:cf87079: 		 * to back the index (because the old conglomerate was dropped).
1:cf87079: 		 */
1:cf87079: 		boolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);
1:cf87079: 
1:eac0369: 		/* If this index already has an essentially same one, we share the
1:eac0369: 		 * conglomerate with the old one, and just simply add a descriptor
1:cf87079: 		 * entry into SYSCONGLOMERATES--unless we already have a descriptor,
1:cf87079: 		 * in which case we don't even need to do that.
1:eac0369: 		 */
1:eac0369: 		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
1:cf87079: 		if (shareExisting && !alreadyHaveConglomDescriptor)
1:eac0369: 		{
2:eac0369: 			ConglomerateDescriptor cgd =
2:eac0369: 				ddg.newConglomerateDescriptor(conglomId, indexName, true,
2:eac0369: 										  indexRowGenerator, isConstraint,
2:eac0369: 										  conglomerateUUID, td.getUUID(), sd.getUUID() );
2:eac0369: 			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
1:eac0369: 			// add newly added conglomerate to the list of conglomerate 
1:eac0369: 			// descriptors in the td.
1:eac0369: 			ConglomerateDescriptorList cdl = 
1:eac0369: 				td.getConglomerateDescriptorList();
2:eac0369: 			cdl.add(cgd);
1:eac0369: 
1:eac0369: 			// can't just return yet, need to get member "indexTemplateRow"
1:eac0369: 			// because create constraint may use it
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// Describe the properties of the index to the store using Properties
1:eac0369: 		// RESOLVE: The following properties assume a BTREE index.
1:eac0369: 		Properties	indexProperties;
1:eac0369: 		
1:eac0369: 		if (properties != null)
1:eac0369: 		{
1:eac0369: 			indexProperties = properties;
1:eac0369: 		}
1:eac0369: 		else
1:eac0369: 		{
1:eac0369: 			indexProperties = new Properties();
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// Tell it the conglomerate id of the base table
1:eac0369: 		indexProperties.put("baseConglomerateId",
1:eac0369: 							Long.toString(td.getHeapConglomerateId()));
1:28e234d:         
1:0c5bc3a:         if (uniqueWithDuplicateNulls && !hasDeferrableChecking)
1:28e234d:         {
1:bce78c9:             if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
1:28e234d:             {
1:28e234d: 				indexProperties.put(
1:28e234d:                     "uniqueWithDuplicateNulls", Boolean.toString(true));
1:28e234d: 			}
1:28e234d: 			else 
1:28e234d:             {
1:28e234d: 				// for lower version of DD there is no unique with nulls 
1:28e234d:                 // index creating a unique index instead.
2:28e234d: 				if (uniqueWithDuplicateNulls) 
1:28e234d:                 {
1:28e234d: 					unique = true;
1:28e234d: 				}
1:28e234d: 			}
1:28e234d: 		}
1:eac0369: 
1:eac0369: 		// All indexes are unique because they contain the RowLocation.
1:eac0369: 		// The number of uniqueness columns must include the RowLocation
1:eac0369: 		// if the user did not specify a unique index.
1:eac0369: 		indexProperties.put("nUniqueColumns",
1:eac0369: 					Integer.toString(unique ? baseColumnPositions.length :
1:eac0369: 												baseColumnPositions.length + 1)
1:eac0369: 							);
1:eac0369: 		// By convention, the row location column is the last column
1:eac0369: 		indexProperties.put("rowLocationColumn",
1:eac0369: 							Integer.toString(baseColumnPositions.length));
1:eac0369: 
1:eac0369: 		// For now, all columns are key fields, including the RowLocation
1:eac0369: 		indexProperties.put("nKeyFields",
1:eac0369: 							Integer.toString(baseColumnPositions.length + 1));
1:eac0369: 
1:eac0369: 		// For now, assume that all index columns are ordered columns
1:cf87079: 		if (! shareExisting)
1:28e234d: 		{
1:bce78c9:             if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
1:eac0369:             {
1:28e234d:                 indexRowGenerator = new IndexRowGenerator(
1:2db96c5:                         indexType, 
1:2db96c5:                         unique, 
1:2db96c5:                         uniqueWithDuplicateNulls,
1:2db96c5:                         uniqueDeferrable,
1:2db96c5:                         (hasDeferrableChecking && 
1:2db96c5:                          constraintType != DataDictionary.FOREIGNKEY_CONSTRAINT),
1:2db96c5:                         baseColumnPositions,
1:2db96c5:                         isAscending,
1:2db96c5:                         baseColumnPositions.length);
1:28e234d: 			}
1:28e234d: 			else 
1:28e234d:             {
1:28e234d: 				indexRowGenerator = new IndexRowGenerator(
1:28e234d:                                             indexType, 
2:28e234d:                                             unique,
1:0c5bc3a:                                             false,
1:0c5bc3a:                                             false,
1:0c5bc3a:                                             false,
1:28e234d:                                             baseColumnPositions,
1:28e234d:                                             isAscending,
1:28e234d:                                             baseColumnPositions.length);
1:28e234d: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		/* Now add the rows from the base table to the conglomerate.
1:eac0369: 		 * We do this by scanning the base table and inserting the
1:eac0369: 		 * rows into a sorter before inserting from the sorter
1:eac0369: 		 * into the index.  This gives us better performance
1:eac0369: 		 * and a more compact index.
1:eac0369: 		 */
1:eac0369: 
1:eac0369: 		rowSource = null;
1:eac0369: 		sortId = 0;
1:eac0369: 		boolean needToDropSort = false;	// set to true once the sorter is created
1:eac0369: 
1:eac0369: 		/* bulkFetchSIze will be 16 (for now) unless
1:eac0369: 		 * we are creating the table in which case it
1:eac0369: 		 * will be 1.  Too hard to remove scan when
1:eac0369: 		 * creating index on new table, so minimize
1:eac0369: 		 * work where we can.
1:eac0369: 		 */
1:eac0369: 		int bulkFetchSize = (forCreateTable) ? 1 : 16;	
1:eac0369: 		int numColumns = td.getNumberOfColumns();
1:eac0369: 		int approximateRowSize = 0;
1:eac0369: 
1:eac0369: 		// Create the FormatableBitSet for mapping the partial to full base row
1:eac0369: 		FormatableBitSet bitSet = new FormatableBitSet(numColumns+1);
1:eac0369: 		for (int index = 0; index < baseColumnPositions.length; index++)
1:eac0369: 		{
1:eac0369: 			bitSet.set(baseColumnPositions[index]);
1:eac0369: 		}
1:eac0369: 		FormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);
1:eac0369: 
1:eac0369: 		// Start by opening a full scan on the base table.
1:eac0369: 		scan = tc.openGroupFetchScan(
1:eac0369:                             td.getHeapConglomerateId(),
1:eac0369: 							false,	// hold
1:eac0369: 							0,	// open base table read only
1:eac0369:                             TransactionController.MODE_TABLE,
1:eac0369:                             TransactionController.ISOLATION_SERIALIZABLE,
1:eac0369: 							zeroBasedBitSet,    // all fields as objects
1:eac0369: 							(DataValueDescriptor[]) null,	// startKeyValue
1:eac0369: 							0,		// not used when giving null start posn.
1:eac0369: 							null,	// qualifier
1:eac0369: 							(DataValueDescriptor[]) null,	// stopKeyValue
1:eac0369: 							0);		// not used when giving null stop posn.
1:eac0369: 
1:eac0369: 		// Create an array to put base row template
1:eac0369: 		baseRows = new ExecRow[bulkFetchSize];
1:eac0369: 		indexRows = new ExecIndexRow[bulkFetchSize];
1:eac0369: 		compactBaseRows = new ExecRow[bulkFetchSize];
1:eac0369: 
1:eac0369: 		try
1:eac0369: 		{
1:eac0369: 			// Create the array of base row template
1:eac0369: 			for (int i = 0; i < bulkFetchSize; i++)
1:eac0369: 			{
1:eac0369: 				// create a base row template
1:eac0369: 				baseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);
1:eac0369: 
1:eac0369: 				// create an index row template
1:eac0369: 				indexRows[i] = indexRowGenerator.getIndexRowTemplate();
1:eac0369: 
1:eac0369: 				// create a compact base row template
1:eac0369: 				compactBaseRows[i] = activation.getExecutionFactory().getValueRow(
1:28e234d: 													baseColumnPositions.length);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			indexTemplateRow = indexRows[0];
1:eac0369: 
1:eac0369: 			// Fill the partial row with nulls of the correct type
1:eac0369: 			ColumnDescriptorList cdl = td.getColumnDescriptorList();
1:eac0369: 			int					 cdlSize = cdl.size();
1:eac0369: 			for (int index = 0, numSet = 0; index < cdlSize; index++)
1:eac0369: 			{
1:eac0369: 				if (! zeroBasedBitSet.get(index))
1:eac0369: 				{
1:eac0369: 					continue;
1:eac0369: 				}
1:eac0369: 				numSet++;
1:801cf0d:                 ColumnDescriptor cd = cdl.elementAt(index);
1:eac0369: 				DataTypeDescriptor dts = cd.getType();
1:eac0369: 
1:eac0369: 
1:eac0369: 				for (int i = 0; i < bulkFetchSize; i++)
1:eac0369: 				{
1:eac0369: 					// Put the column in both the compact and sparse base rows
1:eac0369: 					baseRows[i].setColumn(index + 1,
1:eac0369: 								  dts.getNull());
1:eac0369: 					compactBaseRows[i].setColumn(numSet,
1:eac0369: 								  baseRows[i].getColumn(index + 1));
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// Calculate the approximate row size for the index row
1:eac0369: 				approximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// Get an array of RowLocation template
1:eac0369: 			RowLocation rl[] = new RowLocation[bulkFetchSize];
1:eac0369: 			for (int i = 0; i < bulkFetchSize; i++)
1:eac0369: 			{
1:eac0369: 				rl[i] = scan.newRowLocationTemplate();
1:eac0369: 
1:eac0369: 				// Get an index row based on the base row
1:eac0369: 				indexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);
1:eac0369: 			}
1:eac0369: 
1:cf87079: 			/* now that we got indexTemplateRow, done for sharing index
1:eac0369: 			 */
1:cf87079: 			if (shareExisting)
1:eac0369: 				return;
1:eac0369: 
1:eac0369: 			/* For non-unique indexes, we order by all columns + the RID.
1:eac0369: 			 * For unique indexes, we just order by the columns.
1:eac0369: 			 * We create a unique index observer for unique indexes
1:eac0369: 			 * so that we can catch duplicate key.
1:eac0369: 			 * We create a basic sort observer for non-unique indexes
1:eac0369: 			 * so that we can reuse the wrappers during an external
1:eac0369: 			 * sort.
1:eac0369: 			 */
1:0efe521: 			int             numColumnOrderings;
1:801cf0d:             SortObserver    sortObserver;
1:0efe521:             Properties      sortProperties = null;
1:0c5bc3a:             if (unique || uniqueWithDuplicateNulls || uniqueDeferrable)
1:eac0369: 			{
1:0efe521: 				// if the index is a constraint, use constraintname in 
1:0efe521:                 // possible error message
1:eac0369: 				String indexOrConstraintName = indexName;
1:eac0369: 				if  (conglomerateUUID != null)
1:eac0369: 				{
1:0efe521: 					ConglomerateDescriptor cd = 
1:0efe521:                         dd.getConglomerateDescriptor(conglomerateUUID);
1:0efe521: 					if ((isConstraint) && 
1:0efe521:                         (cd != null && cd.getUUID() != null && td != null))
1:eac0369: 					{
1:0efe521: 						ConstraintDescriptor conDesc = 
1:0efe521:                             dd.getConstraintDescriptor(td, cd.getUUID());
1:eac0369: 						indexOrConstraintName = conDesc.getConstraintName();
1:eac0369: 					}
1:eac0369: 				}
1:28e234d: 
1:0c5bc3a:                 if (unique || uniqueDeferrable)
1:28e234d: 				{
1:0c5bc3a:                     numColumnOrderings = unique ? baseColumnPositions.length :
1:0c5bc3a:                             baseColumnPositions.length + 1;
1:28e234d: 
1:af1c18c:                     sortObserver = new UniqueIndexSortObserver(
1:af1c18c:                         lcc,
1:f6d02c9:                         constraintID,
1:af1c18c:                         true,
1:af1c18c:                         uniqueDeferrable,
1:af1c18c:                         initiallyDeferred,
1:af1c18c:                         indexOrConstraintName,
1:af1c18c:                         indexTemplateRow,
1:af1c18c:                         true,
1:af1c18c:                         td.getName());
1:28e234d: 				}
1:28e234d: 				else 
1:28e234d:                 {
1:28e234d:                     // unique with duplicate nulls allowed.
1:28e234d: 
1:28e234d: 					numColumnOrderings = baseColumnPositions.length + 1;
1:28e234d: 
1:0efe521:                     // tell transaction controller to use the unique with 
1:0efe521:                     // duplicate nulls sorter, when making createSort() call.
1:0efe521: 					sortProperties = new Properties();
1:0efe521: 					sortProperties.put(
1:28e234d:                         AccessFactoryGlobals.IMPL_TYPE, 
1:28e234d:                         AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);
1:28e234d: 					//use sort operator which treats nulls unequal
2:28e234d: 					sortObserver = 
1:28e234d:                         new UniqueWithDuplicateNullsIndexSortObserver(
1:af1c18c:                             lcc,
1:f6d02c9:                             constraintID,
1:af1c18c:                             true,
1:2db96c5:                             (hasDeferrableChecking && 
1:2db96c5:                             constraintType != DataDictionary.FOREIGNKEY_CONSTRAINT),
1:af1c18c:                             initiallyDeferred,
1:af1c18c:                             indexOrConstraintName,
1:af1c18c:                             indexTemplateRow,
1:af1c18c:                             true,
1:af1c18c:                             td.getName());
1:28e234d: 				}
1:eac0369: 			}
1:eac0369: 			else
1:eac0369: 			{
1:eac0369: 				numColumnOrderings = baseColumnPositions.length + 1;
1:eac0369: 				sortObserver = new BasicSortObserver(true, false, 
2:28e234d: 													 indexTemplateRow,
1:eac0369: 													 true);
1:eac0369: 			}
1:b61f876: 
1:eac0369: 			ColumnOrdering[]	order = new ColumnOrdering[numColumnOrderings];
1:eac0369: 			for (int i=0; i < numColumnOrderings; i++) 
1:eac0369: 			{
1:b61f876: 				order[i] = 
1:b61f876:                     new IndexColumnOrder(
1:b61f876:                         i, 
1:b61f876:                         unique || i < numColumnOrderings - 1 ? 
1:b61f876:                             isAscending[i] : true);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// create the sorter
1:801cf0d:             sortId = tc.createSort(sortProperties,
1:eac0369: 					indexTemplateRow.getRowArrayClone(),
1:eac0369: 					order,
1:eac0369: 					sortObserver,
1:eac0369: 					false,			// not in order
1:eac0369: 					scan.getEstimatedRowCount(),
1:eac0369: 					approximateRowSize	// est row size, -1 means no idea	
1:eac0369: 					);
1:eac0369: 
1:eac0369: 			needToDropSort = true;
1:eac0369: 
1:eac0369: 			// Populate sorter and get the output of the sorter into a row
1:eac0369: 			// source.  The sorter has the indexed columns only and the columns
1:eac0369: 			// are in the correct order. 
1:eac0369: 			rowSource = loadSorter(baseRows, indexRows, tc,
1:eac0369: 								   scan, sortId, rl);
1:eac0369: 
1:b61f876: 			conglomId = 
1:b61f876:                 tc.createAndLoadConglomerate(
1:28e234d: 					indexType,
1:eac0369: 					indexTemplateRow.getRowArray(),	// index row template
1:eac0369: 					order, //colums sort order
1:f767f68:                     indexRowGenerator.getColumnCollationIds(
1:f767f68:                         td.getColumnDescriptorList()),
1:eac0369: 					indexProperties,
1:eac0369: 					TransactionController.IS_DEFAULT, // not temporary
1:eac0369: 					rowSource,
1:eac0369: 					(long[]) null);
1:0c5bc3a: 
1:0c5bc3a: 		}
1:eac0369: 		finally
1:eac0369: 		{
1:eac0369: 
1:eac0369: 			/* close the table scan */
2:eac0369: 			if (scan != null)
2:eac0369: 				scan.close();
1:eac0369: 
1:eac0369: 			/* close the sorter row source before throwing exception */
1:eac0369: 			if (rowSource != null)
1:eac0369: 				rowSource.closeRowSource();
1:eac0369: 
1:eac0369: 			/*
1:eac0369: 			** drop the sort so that intermediate external sort run can be
1:eac0369: 			** removed from disk
1:eac0369: 			*/
1:eac0369: 			if (needToDropSort)
1:eac0369: 			 	tc.dropSort(sortId);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		ConglomerateController indexController =
1:eac0369: 			tc.openConglomerate(
1:eac0369:                 conglomId, false, 0, TransactionController.MODE_TABLE,
1:eac0369:                 TransactionController.ISOLATION_SERIALIZABLE);
1:eac0369: 
1:eac0369: 		// Check to make sure that the conglomerate can be used as an index
1:eac0369: 		if ( ! indexController.isKeyed())
1:eac0369: 		{
2:eac0369: 			indexController.close();
1:eac0369: 			throw StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,
1:eac0369: 														   indexType);
1:eac0369: 		}
1:eac0369: 		indexController.close();
1:eac0369: 
1:eac0369: 		//
1:cf87079: 		// Create a conglomerate descriptor with the conglomId filled
1:cf87079: 		// in and add it--if we don't have one already.
1:eac0369: 		//
1:cf87079: 		if (!alreadyHaveConglomDescriptor)
1:cf87079: 		{
1:cf87079: 			ConglomerateDescriptor cgd =
1:cf87079: 				ddg.newConglomerateDescriptor(
1:cf87079: 					conglomId, indexName, true,
1:cf87079: 					indexRowGenerator, isConstraint,
1:cf87079: 					conglomerateUUID, td.getUUID(), sd.getUUID() );
1:eac0369: 
1:cf87079: 			dd.addDescriptor(cgd, sd,
1:cf87079: 				DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
1:eac0369: 
1:cf87079: 			// add newly added conglomerate to the list of conglomerate
1:cf87079: 			// descriptors in the td.
1:cf87079: 			ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
1:cf87079: 			cdl.add(cgd);
1:eac0369: 
1:cf87079: 			/* Since we created a new conglomerate descriptor, load
1:cf87079: 			 * its UUID into the corresponding field, to ensure that
1:cf87079: 			 * it is properly set in the StatisticsDescriptor created
1:cf87079: 			 * below.
1:cf87079: 			 */
1:cf87079: 			conglomerateUUID = cgd.getUUID();
1:cf87079: 		}
1:eac0369: 
1:eac0369: 		CardinalityCounter cCount = (CardinalityCounter)rowSource;
1:bce78c9: 
1:bce78c9:         long numRows = cCount.getRowCount();
1:bce78c9:         if (addStatistics(dd, indexRowGenerator, numRows))
1:eac0369: 		{
1:eac0369: 			long[] c = cCount.getCardinality();
1:eac0369: 			for (int i = 0; i < c.length; i++)
1:eac0369: 			{
1:eac0369: 				StatisticsDescriptor statDesc = 
1:cf87079: 					new StatisticsDescriptor(dd,
1:cf87079: 						dd.getUUIDFactory().createUUID(),
1:cf87079: 						conglomerateUUID, td.getUUID(), "I",
1:cf87079: 						new StatisticsImpl(numRows, c[i]), i + 1);
1:cf87079: 
1:eac0369: 				dd.addDescriptor(statDesc, null, 
1:eac0369: 								 DataDictionary.SYSSTATISTICS_CATALOG_NUM,
1:eac0369: 								 true, tc);
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:bce78c9:      * Determines if a statistics entry is to be added for the index.
1:bce78c9:      * <p>
1:bce78c9:      * As an optimization, it may be better to not write a statistics entry to
1:bce78c9:      * SYS.SYSSTATISTICS. If it isn't needed by Derby as part of query
1:bce78c9:      * optimization there is no reason to spend resources keeping the
1:bce78c9:      * statistics up to date.
1:bce78c9:      *
1:bce78c9:      * @param dd the data dictionary
1:bce78c9:      * @param irg the index row generator
1:bce78c9:      * @param numRows the number of rows in the index
1:bce78c9:      * @return {@code true} if statistics should be written to
1:bce78c9:      *      SYS.SYSSTATISTICS, {@code false} otherwise.
1:bce78c9:      * @throws StandardException if accessing the data dictionary fails
1:bce78c9:      */
1:bce78c9:     private boolean addStatistics(DataDictionary dd,
1:bce78c9:                                   IndexRowGenerator irg,
1:bce78c9:                                   long numRows)
1:bce78c9:             throws StandardException {
1:bce78c9:         boolean add = (numRows > 0);
1:bce78c9:         if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_9, null) &&
1:bce78c9:                 // This horrible piece of code will hopefully go away soon!
1:bce78c9:                ((IndexStatisticsDaemonImpl)dd.getIndexStatsRefresher(false)).
1:bce78c9:                     skipDisposableStats) {
1:bce78c9:             if (add && irg.isUnique() && irg.numberOfOrderedColumns() == 1) {
1:bce78c9:                 // Do not add statistics for single-column unique indexes.
1:bce78c9:                 add = false;
1:bce78c9:             }
1:bce78c9:         }
1:bce78c9:         return add;
1:bce78c9:     }
1:bce78c9: 
1:eac0369: 	// CLASS METHODS
1:eac0369: 	
1:eac0369: 	///////////////////////////////////////////////////////////////////////
1:eac0369: 	//
1:eac0369: 	//	GETTERs called by CreateConstraint
1:eac0369: 	//
1:eac0369: 	///////////////////////////////////////////////////////////////////////
1:eac0369: 	ExecRow getIndexTemplateRow()
1:eac0369: 	{
1:eac0369: 		return indexTemplateRow;
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	/**
1:cf87079: 	 * Get the conglomerate number for the conglomerate that was
1:cf87079: 	 * created by this constant action.  Will return -1L if the
1:cf87079: 	 * constant action has not yet been executed.  This is used
1:cf87079: 	 * for updating conglomerate descriptors which share a
1:cf87079: 	 * conglomerate that has been dropped, in which case those
1:cf87079: 	 * "sharing" descriptors need to point to the newly-created
1:cf87079: 	 * conglomerate (the newly-created conglomerate replaces
1:cf87079: 	 * the dropped one).
1:cf87079: 	 */
1:cf87079: 	long getCreatedConglomNumber()
1:cf87079: 	{
1:cf87079: 		if (SanityManager.DEBUG)
1:cf87079: 		{
1:cf87079: 			if (conglomId == -1L)
1:cf87079: 			{
1:cf87079: 				SanityManager.THROWASSERT(
1:cf87079: 					"Called getCreatedConglomNumber() on a CreateIndex" +
1:cf87079: 					"ConstantAction before the action was executed.");
1:cf87079: 			}
1:cf87079: 		}
1:cf87079: 
1:cf87079: 		return conglomId;
1:cf87079: 	}
1:cf87079: 
1:cf87079: 	/**
1:cf87079: 	 * If the purpose of this constant action was to "replace" a
1:cf87079: 	 * dropped physical conglomerate, then this method returns the
1:cf87079: 	 * conglomerate number of the dropped conglomerate.  Otherwise
1:cf87079: 	 * this method will end up returning -1.
1:cf87079: 	 */
1:cf87079: 	long getReplacedConglomNumber()
1:cf87079: 	{
1:cf87079: 		return droppedConglomNum;
1:cf87079: 	}
1:cf87079: 
1:cf87079: 	/**
1:cf87079: 	 * Get the UUID for the conglomerate descriptor that was created
1:cf87079: 	 * (or re-used) by this constant action.
1:cf87079: 	 */
1:cf87079: 	UUID getCreatedUUID()
1:cf87079: 	{
1:cf87079: 		return conglomerateUUID;
1:cf87079: 	}
1:cf87079: 
1:cf87079: 	/**
1:eac0369: 	 * Scan the base conglomerate and insert the keys into a sorter,
1:eac0369: 	 * returning a rowSource on the sorter. 
1:eac0369: 	 *
1:eac0369: 	 * @return RowSource on the sorted index keys.
1:eac0369: 	 *
1:eac0369: 	 * @exception StandardException					thrown on error
1:eac0369: 	 */
1:eac0369: 	private RowLocationRetRowSource loadSorter(ExecRow[] baseRows,
1:eac0369: 								               ExecIndexRow[] indexRows, 
1:eac0369: 								               TransactionController tc,
1:eac0369: 								               GroupFetchScanController scan,
1:eac0369: 								               long sortId,
1:eac0369: 								               RowLocation rl[])
1:eac0369: 		throws StandardException
1:eac0369: 	{
1:eac0369: 		SortController		sorter;
1:eac0369: 		long				rowCount = 0;
1:eac0369: 
1:eac0369: 		sorter = tc.openSort(sortId);
1:eac0369: 
1:eac0369: 		try
1:eac0369: 		{
1:eac0369: 			// Step through all the rows in the base table
1:eac0369: 			// prepare an array or rows for bulk fetch
1:eac0369: 			int bulkFetchSize = baseRows.length;
1:eac0369: 
1:eac0369: 			if (SanityManager.DEBUG)
1:eac0369: 			{
1:eac0369: 				SanityManager.ASSERT(bulkFetchSize == indexRows.length, 
1:eac0369: 					"number of base rows and index rows does not match");
1:eac0369: 				SanityManager.ASSERT(bulkFetchSize == rl.length,
1:eac0369: 					"number of base rows and row locations does not match");
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			DataValueDescriptor[][] baseRowArray = new DataValueDescriptor[bulkFetchSize][];
1:eac0369: 
1:eac0369: 			for (int i = 0; i < bulkFetchSize; i++)
1:eac0369: 				baseRowArray[i] = baseRows[i].getRowArray();
1:eac0369: 
1:eac0369: 			// rl[i] and baseRowArray[i] and indexRows[i] are all tied up
1:eac0369: 			// beneath the surface.  Fetching the base row and row location
1:eac0369: 			// from the table scan will automagically set up the indexRow
1:eac0369: 			// fetchNextGroup will return how many rows are actually fetched.
1:801cf0d:             int bulkFetched;
1:eac0369: 
1:eac0369: 			while ((bulkFetched = scan.fetchNextGroup(baseRowArray, rl)) > 0)
1:eac0369: 			{
1:eac0369: 				for (int i = 0; i < bulkFetched; i++)
1:eac0369: 				{
1:eac0369: 					sorter.insert(indexRows[i].getRowArray());
1:eac0369: 					rowCount++;
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			/*
1:eac0369: 			** We've just done a full scan on the heap, so set the number
1:eac0369: 			** of rows so the optimizer will have an accurate count.
1:eac0369: 			*/
1:eac0369: 			scan.setEstimatedRowCount(rowCount);
1:eac0369: 		}
1:eac0369: 		finally
1:eac0369: 		{
1:8417890: 			sorter.completedInserts();
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return new CardinalityCounter(tc.openSortRowSource(sortId));
1:eac0369: 	}
1:eac0369: }
1:eac0369: 
============================================================================
author:Mamta Satoor
-------------------------------------------------------------------------------
commit:75d58b2
/////////////////////////////////////////////////////////////////////////
1: 								indexName,
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:f6d02c9
/////////////////////////////////////////////////////////////////////////
1:                         constraintID,
/////////////////////////////////////////////////////////////////////////
1:                             constraintID,
/////////////////////////////////////////////////////////////////////////
commit:2db96c5
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * The constraint type, see 
1:      * {@link org.apache.derby.iapi.sql.dictionary.DataDictionary} 
1:      * definition of constants.
1:      */
1:     private final int       constraintType;
1:     
/////////////////////////////////////////////////////////////////////////
1:             int             constraintType,
/////////////////////////////////////////////////////////////////////////
1:         this.constraintType             = constraintType;
/////////////////////////////////////////////////////////////////////////
1:         this.constraintType = -1;           // N/A
/////////////////////////////////////////////////////////////////////////
1:                         indexType, 
1:                         unique, 
1:                         uniqueWithDuplicateNulls,
1:                         uniqueDeferrable,
1:                         (hasDeferrableChecking && 
1:                          constraintType != DataDictionary.FOREIGNKEY_CONSTRAINT),
1:                         baseColumnPositions,
1:                         isAscending,
1:                         baseColumnPositions.length);
/////////////////////////////////////////////////////////////////////////
1:                             (hasDeferrableChecking && 
1:                             constraintType != DataDictionary.FOREIGNKEY_CONSTRAINT),
commit:af1c18c
/////////////////////////////////////////////////////////////////////////
1:                     sortObserver = new UniqueIndexSortObserver(
0:                         tc,
1:                         lcc,
0:                         DeferredConstraintsMemory.UNDEFINED_CONGLOMERATE,
1:                         true,
1:                         uniqueDeferrable,
1:                         initiallyDeferred,
1:                         indexOrConstraintName,
1:                         indexTemplateRow,
1:                         true,
1:                         td.getName());
/////////////////////////////////////////////////////////////////////////
0:                             tc,
1:                             lcc,
0:                             DeferredConstraintsMemory.UNDEFINED_CONGLOMERATE,
1:                             true,
0:                             hasDeferrableChecking,
1:                             initiallyDeferred,
1:                             indexOrConstraintName,
1:                             indexTemplateRow,
1:                             true,
1:                             td.getName());
/////////////////////////////////////////////////////////////////////////
0:                 DeferredConstraintsMemory.associateDuplicatesWithConglomerate(
commit:0c5bc3a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.sanity.SanityManager;
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * The index represents a PRIMARY KEY or a UNIQUE NOT NULL constraint which
1:      * is deferrable.
1:      * {@code true} implies {@code unique == false} and
1:      * {@code uniqueWithDuplicateNulls == false} and
1:      * {@code hasDeferrableChecking == true}.
1:      */
1:     private boolean         uniqueDeferrable;
1: 
1:     /**
1:      * The index duplicate checking is deferrable. {@code true} implies {@code
1:      * unique == false} and {@code (uniqueDeferrable ||
1:      * uniqueWithDuplicateNulls)}.
1:      *
1:      */
1:     private final boolean   hasDeferrableChecking;
1: 
1:     /**
1:      * Used to determine sorting behavior for existing rows if any
1:      */
1:     private final boolean   initiallyDeferred;
1: 
/////////////////////////////////////////////////////////////////////////
1:      * @param hasDeferrableChecking         True means this index backs a
1:      *                                      deferrable constraint. isConstraint
1:      *                                      will be true.
1:      * @param initiallyDeferred             True means the index represents
1:      *                                      a deferred constraint. Implies
1:      *                                      hasDeferrableChecking.
/////////////////////////////////////////////////////////////////////////
1:             boolean         hasDeferrableChecking,
1:             boolean         initiallyDeferred,
/////////////////////////////////////////////////////////////////////////
1:         this.unique                     = unique && !hasDeferrableChecking;
1:         this.hasDeferrableChecking      = hasDeferrableChecking;
1:         this.initiallyDeferred          = initiallyDeferred;
1:         this.uniqueDeferrable           = unique && hasDeferrableChecking;
/////////////////////////////////////////////////////////////////////////
1:         this.hasDeferrableChecking = false; // N/A such indexes are not shared
1:         this.uniqueDeferrable = false;      // N/A
1:         this.initiallyDeferred = false;     // N/A
/////////////////////////////////////////////////////////////////////////
1:          *
1:          * Deferrable constraints are backed by indexes that are *not* shared
1:          * since they use physically non-unique indexes and as such are
1:          * different from indexes used to represent non-deferrable
1:          * constraints.
/////////////////////////////////////////////////////////////////////////
1:              *
1:              * 4. hasDeferrableChecking is FALSE.
1:              */
1:             boolean possibleShare =
1:                     (irg.isUnique() || !unique) &&
1:                     (bcps.length == baseColumnPositions.length) &&
1:                     !hasDeferrableChecking;
/////////////////////////////////////////////////////////////////////////
1:                         false, // uniqueDeferrable
1:                         false, // deferrable indexes are not shared
/////////////////////////////////////////////////////////////////////////
1:         if (uniqueWithDuplicateNulls && !hasDeferrableChecking)
/////////////////////////////////////////////////////////////////////////
0:                                             uniqueDeferrable,
0:                                             hasDeferrableChecking,
/////////////////////////////////////////////////////////////////////////
1:                                             false,
1:                                             false,
1:                                             false,
/////////////////////////////////////////////////////////////////////////
1:             if (unique || uniqueWithDuplicateNulls || uniqueDeferrable)
/////////////////////////////////////////////////////////////////////////
1:                 if (unique || uniqueDeferrable)
1:                     numColumnOrderings = unique ? baseColumnPositions.length :
1:                             baseColumnPositions.length + 1;
0:                                 tc,
0:                                 lcc,
0:                                 DeferredDuplicates.UNDEFINED_CONGLOMERATE,
0:                                 uniqueDeferrable,
0:                                 initiallyDeferred,
/////////////////////////////////////////////////////////////////////////
0:                                 tc,
0:                                 lcc,
0:                                 DeferredDuplicates.UNDEFINED_CONGLOMERATE,
0:                                 hasDeferrableChecking,
0:                                 initiallyDeferred,
/////////////////////////////////////////////////////////////////////////
1: 
0:             if (initiallyDeferred) {
0:                 DeferredDuplicates.associateDuplicatesWithConglomerate(
0:                     lcc, conglomId);
1:             }
commit:801cf0d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:                 ColumnDescriptor cd = cdl.elementAt(index);
/////////////////////////////////////////////////////////////////////////
1:             SortObserver    sortObserver;
/////////////////////////////////////////////////////////////////////////
1:             sortId = tc.createSort(sortProperties,
/////////////////////////////////////////////////////////////////////////
1:             int bulkFetched;
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.shared.common.sanity.SanityManager;
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:bce78c9
/////////////////////////////////////////////////////////////////////////
0: // Used only to access a debug flag, will be removed or replaced.
1: import org.apache.derby.impl.services.daemon.IndexStatisticsDaemonImpl;
1: 
/////////////////////////////////////////////////////////////////////////
1:             if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
/////////////////////////////////////////////////////////////////////////
1:             if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_4, null))
/////////////////////////////////////////////////////////////////////////
1: 
1:         long numRows = cCount.getRowCount();
1:         if (addStatistics(dd, indexRowGenerator, numRows))
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Determines if a statistics entry is to be added for the index.
1:      * <p>
1:      * As an optimization, it may be better to not write a statistics entry to
1:      * SYS.SYSSTATISTICS. If it isn't needed by Derby as part of query
1:      * optimization there is no reason to spend resources keeping the
1:      * statistics up to date.
1:      *
1:      * @param dd the data dictionary
1:      * @param irg the index row generator
1:      * @param numRows the number of rows in the index
1:      * @return {@code true} if statistics should be written to
1:      *      SYS.SYSSTATISTICS, {@code false} otherwise.
1:      * @throws StandardException if accessing the data dictionary fails
1:      */
1:     private boolean addStatistics(DataDictionary dd,
1:                                   IndexRowGenerator irg,
1:                                   long numRows)
1:             throws StandardException {
1:         boolean add = (numRows > 0);
1:         if (dd.checkVersion(DataDictionary.DD_VERSION_DERBY_10_9, null) &&
1:                 // This horrible piece of code will hopefully go away soon!
1:                ((IndexStatisticsDaemonImpl)dd.getIndexStatsRefresher(false)).
1:                     skipDisposableStats) {
1:             if (add && irg.isUnique() && irg.numberOfOrderedColumns() == 1) {
1:                 // Do not add statistics for single-column unique indexes.
1:                 add = false;
1:             }
1:         }
1:         return add;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
commit:6c9dac8
/////////////////////////////////////////////////////////////////////////
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:435735b
/////////////////////////////////////////////////////////////////////////
1:      * @param uniqueWithDuplicateNulls      True means index check and disallow
/////////////////////////////////////////////////////////////////////////
1: 
1:         this.forCreateTable             = forCreateTable;
0: 		this.unique                     = unique;
1: 		this.uniqueWithDuplicateNulls   = uniqueWithDuplicateNulls;
1: 		this.indexType                  = indexType;
1: 		this.columnNames                = columnNames;
1: 		this.isAscending                = isAscending;
1: 		this.isConstraint               = isConstraint;
1: 		this.conglomerateUUID           = conglomerateUUID;
1: 		this.properties                 = properties;
1: 		this.conglomId                  = -1L;
1: 		this.droppedConglomNum          = -1L;
commit:0efe521
/////////////////////////////////////////////////////////////////////////
1: 			int             numColumnOrderings;
0: 			SortObserver    sortObserver   = null;
1:             Properties      sortProperties = null;
1: 				// if the index is a constraint, use constraintname in 
1:                 // possible error message
1: 					ConglomerateDescriptor cd = 
1:                         dd.getConglomerateDescriptor(conglomerateUUID);
1: 					if ((isConstraint) && 
1:                         (cd != null && cd.getUUID() != null && td != null))
1: 						ConstraintDescriptor conDesc = 
1:                             dd.getConstraintDescriptor(td, cd.getUUID());
/////////////////////////////////////////////////////////////////////////
1:                     // tell transaction controller to use the unique with 
1:                     // duplicate nulls sorter, when making createSort() call.
1: 					sortProperties = new Properties();
1: 					sortProperties.put(
/////////////////////////////////////////////////////////////////////////
0: 			sortId = tc.createSort((Properties)sortProperties, 
commit:28e234d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.store.access.AccessFactoryGlobals;
/////////////////////////////////////////////////////////////////////////
1: 	private boolean			uniqueWithDuplicateNulls;
/////////////////////////////////////////////////////////////////////////
1:      * 	Make the ConstantAction to create an index.
1:      * 
1:      * @param forCreateTable                Being executed within a CREATE TABLE
1:      *                                      statement
1:      * @param unique		                True means it will be a unique index
0:      * @param isUniqueWithDuplicateNulls    True means index check and disallow
1:      *                                      any duplicate key if key has no 
1:      *                                      column with a null value.  If any 
1:      *                                      column in the key has a null value,
1:      *                                      no checking is done and insert will
1:      *                                      always succeed.
1:      * @param indexType	                    type of index (BTREE, for example)
1:      * @param schemaName	                schema that table (and index) 
1:      *                                      lives in.
1:      * @param indexName	                    Name of the index
1:      * @param tableName	                    Name of table the index will be on
1:      * @param tableId		                UUID of table
1:      * @param columnNames	                Names of the columns in the index, 
1:      *                                      in order
1:      * @param isAscending	                Array of booleans telling asc/desc 
1:      *                                      on each column
1:      * @param isConstraint	                TRUE if index is backing up a 
1:      *                                      constraint, else FALSE
1:      * @param conglomerateUUID	            ID of conglomerate
1:      * @param properties	                The optional properties list 
1:      *                                      associated with the index.
1:      */
1:             boolean         forCreateTable,
1:             boolean			unique,
1:             boolean			uniqueWithDuplicateNulls,
1:             String			indexType,
1:             String			schemaName,
1:             String			indexName,
1:             String			tableName,
1:             UUID			tableId,
1:             String[]		columnNames,
1:             boolean[]		isAscending,
1:             boolean			isConstraint,
1:             UUID			conglomerateUUID,
1:             Properties		properties)
0: 		this.uniqueWithDuplicateNulls = uniqueWithDuplicateNulls;
/////////////////////////////////////////////////////////////////////////
1:         
/////////////////////////////////////////////////////////////////////////
1:         
1: 		if (uniqueWithDuplicateNulls) 
1:         {
0: 			if (lcc.getDataDictionary().checkVersion(
0: 				DataDictionary.DD_VERSION_DERBY_10_4, null)) 
1:             {
1: 				indexProperties.put(
1:                     "uniqueWithDuplicateNulls", Boolean.toString(true));
1: 			}
1: 			else 
1:             {
1: 				// for lower version of DD there is no unique with nulls 
1:                 // index creating a unique index instead.
1: 				if (uniqueWithDuplicateNulls) 
1:                 {
1: 					unique = true;
1: 				}
1: 			}
1: 		}
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 			if (lcc.getDataDictionary().checkVersion(
0: 					DataDictionary.DD_VERSION_DERBY_10_4, null)) 
1:             {
1:                 indexRowGenerator = new IndexRowGenerator(
1:                                             indexType, 
1:                                             unique, 
0:                                             uniqueWithDuplicateNulls,
1:                                             baseColumnPositions,
1:                                             isAscending,
1:                                             baseColumnPositions.length);
1: 			}
1: 			else 
1:             {
1: 				indexRowGenerator = new IndexRowGenerator(
1:                                             indexType, 
1:                                             unique,
1:                                             baseColumnPositions,
1:                                             isAscending,
1:                                             baseColumnPositions.length);
1: 			}
/////////////////////////////////////////////////////////////////////////
0: 			if (unique || uniqueWithDuplicateNulls)
/////////////////////////////////////////////////////////////////////////
1: 
0: 				if (unique) 
1: 				{
0:                     numColumnOrderings = baseColumnPositions.length;
1: 
1: 					sortObserver = 
0:                         new UniqueIndexSortObserver(
0:                                 true, 
0:                                 isConstraint, 
0:                                 indexOrConstraintName,
1:                                 indexTemplateRow,
0:                                 true,
0:                                 td.getName());
1: 				}
1: 				else 
1:                 {
1:                     // unique with duplicate nulls allowed.
1: 
1: 					numColumnOrderings = baseColumnPositions.length + 1;
1: 
0: 					properties = new Properties();
0: 					properties.put(
1:                         AccessFactoryGlobals.IMPL_TYPE, 
1:                         AccessFactoryGlobals.SORT_UNIQUEWITHDUPLICATENULLS_EXTERNAL);
1: 					//use sort operator which treats nulls unequal
1: 					sortObserver = 
1:                         new UniqueWithDuplicateNullsIndexSortObserver(
0:                                 true, 
0:                                 isConstraint, 
0:                                 indexOrConstraintName,
1:                                 indexTemplateRow,
0:                                 true,
0:                                 td.getName());
1: 				}
/////////////////////////////////////////////////////////////////////////
0: 			sortId = tc.createSort((Properties)properties, 
commit:f767f68
/////////////////////////////////////////////////////////////////////////
1:                     indexRowGenerator.getColumnCollationIds(
1:                         td.getColumnDescriptorList()),
commit:b61f876
/////////////////////////////////////////////////////////////////////////
1: 
1: 				order[i] = 
1:                     new IndexColumnOrder(
1:                         i, 
1:                         unique || i < numColumnOrderings - 1 ? 
1:                             isAscending[i] : true);
/////////////////////////////////////////////////////////////////////////
1: 			conglomId = 
1:                 tc.createAndLoadConglomerate(
0:                     null,  // TODO-COLLATION, implement non-default collation
author:Army
-------------------------------------------------------------------------------
commit:477fd5e
/////////////////////////////////////////////////////////////////////////
1: 		this.uniqueWithDuplicateNulls = irg.isUniqueWithDuplicateNulls();
/////////////////////////////////////////////////////////////////////////
1: 			 *
1: 			 *
1: 			 * 3. one of the following is true:
1: 			 *    a) the existing index is unique, OR
1: 			 *    b) the existing index is non-unique with uniqueWhenNotNulls
1: 			 *       set to TRUE and the index being created is non-unique, OR
1: 			 *    c) both the existing index and the one being created are
1: 			 *       non-unique and have uniqueWithDuplicateNulls set to FALSE.
1: 			//check if existing index is non unique and uniqueWithDuplicateNulls
1: 			//is set to true (backing index for unique constraint)
1: 			if (possibleShare && !irg.isUnique ())
1: 			{
1: 				/* If the existing index has uniqueWithDuplicateNulls set to
1: 				 * TRUE it can be shared by other non-unique indexes; otherwise
1: 				 * the existing non-unique index has uniqueWithDuplicateNulls
1: 				 * set to FALSE, which means the new non-unique conglomerate
1: 				 * can only share if it has uniqueWithDuplicateNulls set to
1: 				 * FALSE, as well.
1: 				 */
1: 				possibleShare = (irg.isUniqueWithDuplicateNulls() ||
1: 								! uniqueWithDuplicateNulls);
1: 			}
1: 
/////////////////////////////////////////////////////////////////////////
1: 						indexType, unique, uniqueWithDuplicateNulls,
commit:cf87079
/////////////////////////////////////////////////////////////////////////
1: 	/** Conglomerate number for the conglomerate created by this
1: 	 * constant action; -1L if this constant action has not been
1: 	 * executed.  If this constant action doesn't actually create
1: 	 * a new conglomerate--which can happen if it finds an existing
1: 	 * conglomerate that satisfies all of the criteria--then this
1: 	 * field will hold the conglomerate number of whatever existing
1: 	 * conglomerate was found.
1: 	 */
1: 	private long conglomId;
1: 
1: 	/** Conglomerate number of the physical conglomerate that we
1: 	 * will "replace" using this constant action.  That is, if
1: 	 * the purpose of this constant action is to create a new physical
1: 	 * conglomerate to replace a dropped physical conglomerate, then
1: 	 * this field holds the conglomerate number of the dropped physical
1: 	 * conglomerate. If -1L then we are not replacing a conglomerate,
1: 	 * we're simply creating a new index (and backing physical
1: 	 * conglomerate) as normal.
1: 	 */
1: 	private long droppedConglomNum;
/////////////////////////////////////////////////////////////////////////
1: 		this.conglomId = -1L;
0: 		this.droppedConglomNum = -1L;
1: 	}
1: 
1: 	/**
1: 	 * Make a ConstantAction that creates a new physical conglomerate
1: 	 * based on index information stored in the received descriptors.
1: 	 * Assumption is that the received ConglomerateDescriptor is still
1: 	 * valid (meaning it has corresponding entries in the system tables
1: 	 * and it describes some constraint/index that has _not_ been
1: 	 * dropped--though the physical conglomerate underneath has).
1: 	 *
1: 	 * This constructor is used in cases where the physical conglomerate
1: 	 * for an index has been dropped but the index still exists. That
1: 	 * can happen if multiple indexes share a physical conglomerate but
1: 	 * then the conglomerate is dropped as part of "drop index" processing
1: 	 * for one of the indexes. (Note that "indexes" here includes indexes
1: 	 * which were created to back constraints.) In that case we have to
1: 	 * create a new conglomerate to satisfy the remaining sharing indexes,
1: 	 * so that's what we're here for.  See ConglomerateDescriptor.drop()
1: 	 * for details on when that is necessary.
1: 	 */
1: 	CreateIndexConstantAction(ConglomerateDescriptor srcCD,
1: 		TableDescriptor td, Properties properties)
1: 	{
1: 		super(td.getUUID(),
1: 			srcCD.getConglomerateName(), td.getName(), td.getSchemaName());
1: 
1: 		this.forCreateTable = false;
1: 
1: 		/* We get here when a conglomerate has been dropped and we
1: 		 * need to create (or find) another one to fill its place.
1: 		 * At this point the received conglomerate descriptor still
1: 		 * references the old (dropped) conglomerate, so we can
1: 		 * pull the conglomerate number from there.
1: 		 */
1: 		this.droppedConglomNum = srcCD.getConglomerateNumber();
1: 
1: 		/* Plug in the rest of the information from the received
1: 		 * descriptors.
1: 		 */
1: 		IndexRowGenerator irg = srcCD.getIndexDescriptor();
1: 		this.unique = irg.isUnique();
1: 		this.indexType = irg.indexType();
1: 		this.columnNames = srcCD.getColumnNames();
1: 		this.isAscending = irg.isAscending();
1: 		this.isConstraint = srcCD.isConstraint();
1: 		this.conglomerateUUID = srcCD.getUUID();
1: 		this.properties = properties;
1: 		this.conglomId = -1L;
1: 
1: 		/* The ConglomerateDescriptor may not know the names of
1: 		 * the columns it includes.  If that's true (which seems
1: 		 * to be the more common case) then we have to build the
1: 		 * list of ColumnNames ourselves.
1: 		 */
1: 		if (columnNames == null)
1: 		{
1: 			int [] baseCols = irg.baseColumnPositions();
1: 			columnNames = new String[baseCols.length];
1: 			ColumnDescriptorList colDL = td.getColumnDescriptorList();
1: 			for (int i = 0; i < baseCols.length; i++)
1: 			{
1: 				columnNames[i] =
1: 					colDL.elementAt(baseCols[i]-1).getColumnName();
1: 			}
1: 		}
/////////////////////////////////////////////////////////////////////////
1: 		/* The code below tries to determine if the index that we're about
1: 		 * to create can "share" a conglomerate with an existing index.
1: 		 * If so, we will use a single physical conglomerate--namely, the
1: 		 * one that already exists--to support both indexes. I.e. we will
1: 		 * *not* create a new conglomerate as part of this constant action.
1: 		 */ 
1: 
1: 		boolean shareExisting = false;
1: 
1: 			if (droppedConglomNum == cd.getConglomerateNumber())
1: 			{
1: 				/* We can't share with any conglomerate descriptor
1: 				 * whose conglomerate number matches the dropped
1: 				 * conglomerate number, because that descriptor's
1: 				 * backing conglomerate was dropped, as well.  If
1: 				 * we're going to share, we have to share with a
1: 				 * descriptor whose backing physical conglomerate
1: 				 * is still around.
1: 				 */
1: 				continue;
1: 			}
1: 
1: 			/* The conditions which allow an index to share an existing
1: 			 * conglomerate are as follows:
1: 			 *
1: 			 */ 
0: 			boolean possibleShare = (irg.isUnique() || !unique) &&
0: 			    (bcps.length == baseColumnPositions.length);
1: 			if (possibleShare && indexType.equals(irg.indexType()))
/////////////////////////////////////////////////////////////////////////
1: 			if (j == baseColumnPositions.length)	// share
/////////////////////////////////////////////////////////////////////////
1: 				/* Sharing indexes share the physical conglomerate
1: 				 * underneath, so pull the conglomerate number from
1: 				 * the existing conglomerate descriptor.
1: 				 */
1: 
1: 				/* We create a new IndexRowGenerator because certain
1: 				 * attributes--esp. uniqueness--may be different between
1: 				 * the index we're creating and the conglomerate that
1: 				 * already exists.  I.e. even though we're sharing a
1: 				 * conglomerate, the new index is not necessarily
1: 				 * identical to the existing conglomerate. We have to
1: 				 * keep track of that info so that if we later drop
1: 				 * the shared physical conglomerate, we can figure out
1: 				 * what this index (the one we're creating now) is
1: 				 * really supposed to look like.
1: 				 */
1: 				indexRowGenerator =
1: 					new IndexRowGenerator(
0: 						indexType, unique,
0: 						baseColumnPositions,
0: 						isAscending,
1: 						baseColumnPositions.length);
1: 
1: 				// Sharing indexes will have unique logical conglomerate UUIDs.
1: 				shareExisting = true;
1: 		/* If we have a droppedConglomNum then the index we're about to
1: 		 * "create" already exists--i.e. it has an index descriptor and
1: 		 * the corresponding information is already in the system catalogs.
1: 		 * The only thing we're missing, then, is the physical conglomerate
1: 		 * to back the index (because the old conglomerate was dropped).
1: 		 */
1: 		boolean alreadyHaveConglomDescriptor = (droppedConglomNum > -1L);
1: 
1: 		 * entry into SYSCONGLOMERATES--unless we already have a descriptor,
1: 		 * in which case we don't even need to do that.
1: 		if (shareExisting && !alreadyHaveConglomDescriptor)
/////////////////////////////////////////////////////////////////////////
1: 		if (! shareExisting)
/////////////////////////////////////////////////////////////////////////
1: 			/* now that we got indexTemplateRow, done for sharing index
1: 			if (shareExisting)
/////////////////////////////////////////////////////////////////////////
1: 		// Create a conglomerate descriptor with the conglomId filled
1: 		// in and add it--if we don't have one already.
1: 		if (!alreadyHaveConglomDescriptor)
1: 		{
1: 			ConglomerateDescriptor cgd =
1: 				ddg.newConglomerateDescriptor(
1: 					conglomId, indexName, true,
1: 					indexRowGenerator, isConstraint,
1: 					conglomerateUUID, td.getUUID(), sd.getUUID() );
1: 			dd.addDescriptor(cgd, sd,
1: 				DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
1: 			// add newly added conglomerate to the list of conglomerate
1: 			// descriptors in the td.
1: 			ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
1: 			cdl.add(cgd);
1: 			/* Since we created a new conglomerate descriptor, load
1: 			 * its UUID into the corresponding field, to ensure that
1: 			 * it is properly set in the StatisticsDescriptor created
1: 			 * below.
1: 			 */
1: 			conglomerateUUID = cgd.getUUID();
1: 		}
/////////////////////////////////////////////////////////////////////////
1: 					new StatisticsDescriptor(dd,
1: 						dd.getUUIDFactory().createUUID(),
1: 						conglomerateUUID, td.getUUID(), "I",
1: 						new StatisticsImpl(numRows, c[i]), i + 1);
1: 
/////////////////////////////////////////////////////////////////////////
1: 	 * Get the conglomerate number for the conglomerate that was
1: 	 * created by this constant action.  Will return -1L if the
1: 	 * constant action has not yet been executed.  This is used
1: 	 * for updating conglomerate descriptors which share a
1: 	 * conglomerate that has been dropped, in which case those
1: 	 * "sharing" descriptors need to point to the newly-created
1: 	 * conglomerate (the newly-created conglomerate replaces
1: 	 * the dropped one).
1: 	 */
1: 	long getCreatedConglomNumber()
1: 	{
1: 		if (SanityManager.DEBUG)
1: 		{
1: 			if (conglomId == -1L)
1: 			{
1: 				SanityManager.THROWASSERT(
1: 					"Called getCreatedConglomNumber() on a CreateIndex" +
1: 					"ConstantAction before the action was executed.");
1: 			}
1: 		}
1: 
1: 		return conglomId;
1: 	}
1: 
1: 	/**
1: 	 * If the purpose of this constant action was to "replace" a
1: 	 * dropped physical conglomerate, then this method returns the
1: 	 * conglomerate number of the dropped conglomerate.  Otherwise
1: 	 * this method will end up returning -1.
1: 	 */
1: 	long getReplacedConglomNumber()
1: 	{
1: 		return droppedConglomNum;
1: 	}
1: 
1: 	/**
1: 	 * Get the UUID for the conglomerate descriptor that was created
1: 	 * (or re-used) by this constant action.
1: 	 */
1: 	UUID getCreatedUUID()
1: 	{
1: 		return conglomerateUUID;
1: 	}
1: 
1: 	/**
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:1b41764
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Is this for a CREATE TABLE, i.e. it is
1:      * for a constraint declared in a CREATE TABLE
1:      * statement that requires a backing index.
1:      */
1:     private final boolean forCreateTable;
/////////////////////////////////////////////////////////////////////////
0:      *  @param forCreateTable Being executed within a CREATE TABLE statement
/////////////////////////////////////////////////////////////////////////
0:             boolean forCreateTable,
/////////////////////////////////////////////////////////////////////////
0:         this.forCreateTable = forCreateTable;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:0978789
/////////////////////////////////////////////////////////////////////////
1: 				td = dd.getTableDescriptor(tableName, sd, tc);
commit:8417890
/////////////////////////////////////////////////////////////////////////
1: 			sorter.completedInserts();
commit:1429957
/////////////////////////////////////////////////////////////////////////
1:  * ConstantAction to create an index either through
1:  * a CREATE INDEX statement or as a backing index to
1:  * a constraint.
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 	 *	Make the ConstantAction to create an index.
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 	 *	This is the guts of the Execution-time logic for 
1:      *  creating an index.
1:      *
1:      *  <P>
1:      *  A index is represented as:
1:      *  <UL>
1:      *  <LI> ConglomerateDescriptor.
1:      *  </UL>
1:      *  No dependencies are created.
1:    	 *
1:      *  @see ConglomerateDescriptor
1:      *  @see SchemaDescriptor
/////////////////////////////////////////////////////////////////////////
0:         long conglomId = 0;
commit:1e2aae0
/////////////////////////////////////////////////////////////////////////
1: import java.util.Properties;
1: import org.apache.derby.catalog.UUID;
1: import org.apache.derby.catalog.types.StatisticsImpl;
1: import org.apache.derby.iapi.error.StandardException;
1: import org.apache.derby.iapi.reference.SQLState;
1: import org.apache.derby.iapi.services.io.FormatableBitSet;
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: import org.apache.derby.iapi.sql.Activation;
1: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1: import org.apache.derby.iapi.sql.depend.DependencyManager;
1: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptorList;
1: import org.apache.derby.iapi.sql.dictionary.DataDescriptorGenerator;
1: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
1: import org.apache.derby.iapi.sql.dictionary.IndexRowGenerator;
1: import org.apache.derby.iapi.sql.dictionary.SchemaDescriptor;
1: import org.apache.derby.iapi.sql.dictionary.TableDescriptor;
1: import org.apache.derby.iapi.sql.execute.ConstantAction;
1: import org.apache.derby.iapi.sql.execute.ExecIndexRow;
1: import org.apache.derby.iapi.sql.execute.ExecRow;
1: import org.apache.derby.iapi.store.access.SortObserver;
1: import org.apache.derby.iapi.types.DataTypeDescriptor;
1: import org.apache.derby.iapi.types.RowLocation;
1: import org.apache.derby.iapi.types.TypeId;
commit:345de35
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derby.impl.sql.execute.CreateIndexConstantAction
1: 
0:    Copyright 1997, 2004 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
commit:9e5097f
/////////////////////////////////////////////////////////////////////////
commit:eac0369
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 1997, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
1: 
1:  */
1: 
1: package org.apache.derby.impl.sql.execute;
1: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: 
1: import org.apache.derby.iapi.services.loader.ClassFactory;
0: import org.apache.derby.iapi.services.loader.ClassInspector;
1: 
0: import org.apache.derby.iapi.services.stream.HeaderPrintWriter;
1: 
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
0: import org.apache.derby.iapi.sql.execute.ExecutionContext;
0: import org.apache.derby.iapi.sql.execute.ExecRow;
0: import org.apache.derby.iapi.sql.execute.ExecIndexRow;
1: 
1: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptor;
1: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptorList;
0: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptorList;
0: import org.apache.derby.iapi.sql.dictionary.DataDescriptorGenerator;
0: import org.apache.derby.iapi.sql.dictionary.DataDictionaryContext;
0: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
1: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptor;
1: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.SchemaDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.IndexRowGenerator;
0: import org.apache.derby.iapi.sql.dictionary.TableDescriptor;
1: import org.apache.derby.iapi.sql.dictionary.ConstraintDescriptor;
1: import org.apache.derby.iapi.sql.dictionary.StatisticsDescriptor;
0: import org.apache.derby.iapi.sql.depend.DependencyManager;
0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
0: import org.apache.derby.iapi.sql.Activation;
1: 
0: import org.apache.derby.iapi.types.DataValueFactory;
0: import org.apache.derby.iapi.types.DataTypeDescriptor;
0: import org.apache.derby.iapi.types.TypeId;
0: import org.apache.derby.iapi.types.RowLocation;
1: 
0: import org.apache.derby.iapi.reference.SQLState;
1: 
0: import org.apache.derby.iapi.error.StandardException;
1: 
1: import org.apache.derby.iapi.store.access.ColumnOrdering;
1: import org.apache.derby.iapi.store.access.ConglomerateController;
1: import org.apache.derby.iapi.store.access.GroupFetchScanController;
1: import org.apache.derby.iapi.store.access.RowLocationRetRowSource;
0: import org.apache.derby.iapi.store.access.ScanController;
0: import org.apache.derby.iapi.store.access.SortObserver;
1: import org.apache.derby.iapi.store.access.SortController;
1: import org.apache.derby.iapi.store.access.TransactionController;
1: import org.apache.derby.iapi.types.DataValueDescriptor;
1: 
1: 
0: import org.apache.derby.catalog.UUID;
0: import org.apache.derby.catalog.types.StatisticsImpl;
1: 
0: import java.util.Properties;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: 
1: /**
0:  *	This class  describes actions that are ALWAYS performed for a
0:  *	CREATE TABLE Statement at Execution time.
1:  *
0:  *	@author Jeff Lichtman	Cribbed from from CreateTableConstantAction
1:  */
1: 
1: class CreateIndexConstantAction extends IndexConstantAction
1: {
1: 	/**
0: 		IBM Copyright &copy notice.
1: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1997_2004;
1: 
1: 	private boolean			unique;
1: 	private String			indexType;
0: 	private long			conglomId;
1: 	private String[]		columnNames;
1: 	private boolean[]		isAscending;
1: 	private boolean			isConstraint;
1: 	private UUID			conglomerateUUID;
1: 	private Properties		properties;
1: 
1: 	private ExecRow indexTemplateRow;
1: 
1: 
1: 	// CONSTRUCTORS
1: 	/**
0: 	 *	Make the ConstantAction for a CREATE INDEX statement.
1: 	 *
0: 	 *  @param unique		True means it will be a unique index
0: 	 *  @param indexType	The type of index (BTREE, for example)
0: 	 *  @param sd			the schema that table (and index) lives in.
0: 	 *  @param indexName	Name of the index
0: 	 *  @param tableName	Name of table the index will be on
0: 	 *  @param tableId		UUID of table
0: 	 *  @param conglomId	Conglomerate ID of the index, if known in advance
0: 	 *  @param columnNames	Names of the columns in the index, in order
0: 	 *	@param isAscending	Array of booleans telling asc/desc on each column
0: 	 *  @param isConstraint	TRUE if index is backing up a constraint, else FALSE
0: 	 *  @param conglomerateUUID	ID of conglomerate
0: 	 *  @param properties	The optional properties list associated with the index.
1: 	 */
1: 	CreateIndexConstantAction(
0: 								boolean			unique,
0: 								String			indexType,
0: 								String			schemaName,
0: 								String			indexName,
0: 								String			tableName,
0: 								UUID			tableId,
0: 								long			conglomId,
0: 								String[]		columnNames,
0: 								boolean[]		isAscending,
0: 								boolean			isConstraint,
0: 								UUID			conglomerateUUID,
0: 								Properties		properties)
1: 	{
1: 		super(tableId, indexName, tableName, schemaName);
0: 		this.unique = unique;
0: 		this.indexType = indexType;
0: 		this.conglomId= conglomId;
0: 		this.columnNames = columnNames;
0: 		this.isAscending = isAscending;
0: 		this.isConstraint = isConstraint;
0: 		this.conglomerateUUID = conglomerateUUID;
0: 		this.properties = properties;
1: 	}
1: 
1: 	///////////////////////////////////////////////
1: 	//
1: 	// OBJECT SHADOWS
1: 	//
1: 	///////////////////////////////////////////////
1: 
1: 	public	String	toString()
1: 	{
1: 		// Do not put this under SanityManager.DEBUG - it is needed for
1: 		// error reporting.
1: 		return "CREATE INDEX " + indexName;
1: 	}
1: 
1: 	// INTERFACE METHODS
1: 
1: 
1: 	/**
0: 	 *	This is the guts of the Execution-time logic for CREATE INDEX.
1: 	 *
1: 	 *	@see ConstantAction#executeConstantAction
1: 	 *
1: 	 * @exception StandardException		Thrown on failure
1: 	 */
1: 	public void	executeConstantAction( Activation activation )
1: 						throws StandardException
1: 	{
0: 		boolean						forCreateTable;
1: 		TableDescriptor 			td;
1: 		UUID 						toid;
1: 		ColumnDescriptor			columnDescriptor;
1: 		int[]						baseColumnPositions;
1: 		IndexRowGenerator			indexRowGenerator = null;
1: 		ExecRow[]					baseRows;
1: 		ExecIndexRow[]				indexRows;
1: 		ExecRow[]					compactBaseRows;
1: 		GroupFetchScanController    scan;
1: 		RowLocationRetRowSource	    rowSource;
1: 		long						sortId;
1: 		int							maxBaseColumnPosition = -1;
1: 
1: 		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
1: 		DataDictionary dd = lcc.getDataDictionary();
1: 		DependencyManager dm = dd.getDependencyManager();
1: 		TransactionController tc = lcc.getTransactionExecute();
1: 
0: 		/* Remember whether or not we are doing a create table */
0: 		forCreateTable = activation.getForCreateTable();
1: 
1: 		/*
1: 		** Inform the data dictionary that we are about to write to it.
1: 		** There are several calls to data dictionary "get" methods here
1: 		** that might be done in "read" mode in the data dictionary, but
1: 		** it seemed safer to do this whole operation in "write" mode.
1: 		**
1: 		** We tell the data dictionary we're done writing at the end of
1: 		** the transaction.
1: 		*/
1: 		dd.startWriting(lcc);
1: 
1: 		/*
1: 		** If the schema descriptor is null, then
1: 		** we must have just read ourselves in.  
1: 		** So we will get the corresponding schema
1: 		** descriptor from the data dictionary.
1: 		*/
1: 		SchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;
1: 
1: 
1: 		/* Get the table descriptor. */
1: 		/* See if we can get the TableDescriptor 
1: 		 * from the Activation.  (Will be there
1: 		 * for backing indexes.)
1: 		 */
1: 		td = activation.getDDLTableDescriptor();
1: 
1: 		if (td == null)
1: 		{
1: 			/* tableId will be non-null if adding an index to
1: 			 * an existing table (as opposed to creating a
1: 			 * table with a constraint with a backing index).
1: 			 */
1: 			if (tableId != null)
1: 			{
1: 				td = dd.getTableDescriptor(tableId);
1: 			}
1: 			else
1: 			{
0: 				td = dd.getTableDescriptor(tableName, sd);
1: 			}
1: 		}
1: 
1: 		if (td == null)
1: 		{
1: 			throw StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, 
1: 						indexName, tableName);
1: 		}
1: 
1: 		if (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)
1: 		{
1: 			throw StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, 
1: 						indexName, tableName);
1: 		}
1: 
1: 		/* Get a shared table lock on the table. We need to lock table before
1: 		 * invalidate dependents, otherwise, we may interfere with the
1: 		 * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/
1: 		 * docs/language/SolutionsToConcurrencyIssues.txt (point f).
1: 		 */
1: 		lockTableForDDL(tc, td.getHeapConglomerateId(), false);
1: 
1: 		// invalidate any prepared statements that
1: 		// depended on this table (including this one)
1: 		if (! forCreateTable)
1: 		{
1: 			dm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);
1: 		}
1: 
1: 		// Translate the base column names to column positions
1: 		baseColumnPositions = new int[columnNames.length];
1: 		for (int i = 0; i < columnNames.length; i++)
1: 		{
1: 			// Look up the column in the data dictionary
1: 			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
1: 			if (columnDescriptor == null)
1: 			{
1: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, 
1: 															columnNames[i],
1: 															tableName);
1: 			}
1: 
1: 			TypeId typeId = columnDescriptor.getType().getTypeId();
1: 
1: 			// Don't allow a column to be created on a non-orderable type
1: 			ClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();
1: 			boolean isIndexable = typeId.orderable(cf);
1: 
1: 			if (isIndexable && typeId.userType()) {
1: 				String userClass = typeId.getCorrespondingJavaTypeName();
1: 
1: 				// Don't allow indexes to be created on classes that
1: 				// are loaded from the database. This is because recovery
1: 				// won't be able to see the class and it will need it to
1: 				// run the compare method.
1: 				try {
1: 					if (cf.isApplicationClass(cf.loadApplicationClass(userClass)))
1: 						isIndexable = false;
1: 				} catch (ClassNotFoundException cnfe) {
1: 					// shouldn't happen as we just check the class is orderable
1: 					isIndexable = false;
1: 				}
1: 			}
1: 
1: 			if (!isIndexable) {
1: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, 
1: 					typeId.getSQLTypeName());
1: 			}
1: 
1: 			// Remember the position in the base table of each column
1: 			baseColumnPositions[i] = columnDescriptor.getPosition();
1: 
1: 			if (maxBaseColumnPosition < baseColumnPositions[i])
1: 				maxBaseColumnPosition = baseColumnPositions[i];
1: 		}
1: 
1: 		// check if we have similar indices already for this table
1: 		ConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();
0: 		boolean duplicate = false;
1: 
1: 		for (int i = 0; i < congDescs.length; i++)
1: 		{
1: 			ConglomerateDescriptor cd = congDescs[i];
1: 			if ( ! cd.isIndex())
1: 				continue;
1: 			IndexRowGenerator irg = cd.getIndexDescriptor();
1: 			int[] bcps = irg.baseColumnPositions();
1: 			boolean[] ia = irg.isAscending();
1: 			int j = 0;
1: 
0: 			/* For an index to be considered a duplicate of already existing index, the
0: 			 * following conditions have to be satisfied:
1: 			 * 1. the set of columns (both key and include columns) and their 
1: 			 *  order in the index is the same as that of an existing index AND 
1: 			 * 2. the ordering attributes are the same AND 
0: 			 * 3. both the previously existing index and the one being created 
0: 			 *  are non-unique OR the previously existing index is unique
1: 			 */
1: 
0: 			if ((bcps.length == baseColumnPositions.length) &&
0: 			    (irg.isUnique() || !unique) &&
0: 				indexType.equals(irg.indexType()))
1: 			{
1: 				for (; j < bcps.length; j++)
1: 				{
1: 					if ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))
1: 						break;
1: 				}
1: 			}
1: 
0: 			if (j == baseColumnPositions.length)	// duplicate
1: 			{
1: 				/*
1: 				 * Don't allow users to create a duplicate index. Allow if being done internally
1: 				 * for a constraint
1: 				 */
1: 				if (!isConstraint)
1: 				{
1: 					activation.addWarning(
1: 							StandardException.newWarning(
1: 								SQLState.LANG_INDEX_DUPLICATE,
1: 								cd.getConglomerateName()));
1: 
1: 					return;
1: 				}
1: 
1: 				conglomId = cd.getConglomerateNumber();
0: 				indexRowGenerator = cd.getIndexDescriptor();
0: 				conglomerateUUID = cd.getUUID();
0: 				duplicate = true;
1: 				break;
1: 			}
1: 		}
1: 
1: 		/* If this index already has an essentially same one, we share the
1: 		 * conglomerate with the old one, and just simply add a descriptor
0: 		 * entry into SYSCONGLOMERATES.
1: 		 */
1: 		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
0: 		if (duplicate)
1: 		{
1: 			ConglomerateDescriptor cgd =
1: 				ddg.newConglomerateDescriptor(conglomId, indexName, true,
1: 										  indexRowGenerator, isConstraint,
1: 										  conglomerateUUID, td.getUUID(), sd.getUUID() );
1: 			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
1: 			// add newly added conglomerate to the list of conglomerate 
1: 			// descriptors in the td.
1: 			ConglomerateDescriptorList cdl = 
1: 				td.getConglomerateDescriptorList();
1: 			cdl.add(cgd);
1: 
1: 			// can't just return yet, need to get member "indexTemplateRow"
1: 			// because create constraint may use it
1: 		}
1: 
1: 		// Describe the properties of the index to the store using Properties
1: 		// RESOLVE: The following properties assume a BTREE index.
1: 		Properties	indexProperties;
1: 		
1: 		if (properties != null)
1: 		{
1: 			indexProperties = properties;
1: 		}
1: 		else
1: 		{
1: 			indexProperties = new Properties();
1: 		}
1: 
1: 		// Tell it the conglomerate id of the base table
1: 		indexProperties.put("baseConglomerateId",
1: 							Long.toString(td.getHeapConglomerateId()));
1: 
1: 		// All indexes are unique because they contain the RowLocation.
1: 		// The number of uniqueness columns must include the RowLocation
1: 		// if the user did not specify a unique index.
1: 		indexProperties.put("nUniqueColumns",
1: 					Integer.toString(unique ? baseColumnPositions.length :
1: 												baseColumnPositions.length + 1)
1: 							);
1: 
1: 		// By convention, the row location column is the last column
1: 		indexProperties.put("rowLocationColumn",
1: 							Integer.toString(baseColumnPositions.length));
1: 
1: 		// For now, all columns are key fields, including the RowLocation
1: 		indexProperties.put("nKeyFields",
1: 							Integer.toString(baseColumnPositions.length + 1));
1: 
1: 		// For now, assume that all index columns are ordered columns
0: 		if (! duplicate)
1: 		{
0: 			indexRowGenerator = new IndexRowGenerator(indexType, unique,
0: 													baseColumnPositions,
0: 													isAscending,
0: 													baseColumnPositions.length);
1: 		}
1: 
1: 		/* Now add the rows from the base table to the conglomerate.
1: 		 * We do this by scanning the base table and inserting the
1: 		 * rows into a sorter before inserting from the sorter
1: 		 * into the index.  This gives us better performance
1: 		 * and a more compact index.
1: 		 */
1: 
1: 		rowSource = null;
1: 		sortId = 0;
1: 		boolean needToDropSort = false;	// set to true once the sorter is created
1: 
1: 		/* bulkFetchSIze will be 16 (for now) unless
1: 		 * we are creating the table in which case it
1: 		 * will be 1.  Too hard to remove scan when
1: 		 * creating index on new table, so minimize
1: 		 * work where we can.
1: 		 */
1: 		int bulkFetchSize = (forCreateTable) ? 1 : 16;	
1: 		int numColumns = td.getNumberOfColumns();
1: 		int approximateRowSize = 0;
1: 
1: 		// Create the FormatableBitSet for mapping the partial to full base row
1: 		FormatableBitSet bitSet = new FormatableBitSet(numColumns+1);
1: 		for (int index = 0; index < baseColumnPositions.length; index++)
1: 		{
1: 			bitSet.set(baseColumnPositions[index]);
1: 		}
1: 		FormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);
1: 
1: 		// Start by opening a full scan on the base table.
1: 		scan = tc.openGroupFetchScan(
1:                             td.getHeapConglomerateId(),
1: 							false,	// hold
1: 							0,	// open base table read only
1:                             TransactionController.MODE_TABLE,
1:                             TransactionController.ISOLATION_SERIALIZABLE,
1: 							zeroBasedBitSet,    // all fields as objects
1: 							(DataValueDescriptor[]) null,	// startKeyValue
1: 							0,		// not used when giving null start posn.
1: 							null,	// qualifier
1: 							(DataValueDescriptor[]) null,	// stopKeyValue
1: 							0);		// not used when giving null stop posn.
1: 
1: 		// Create an array to put base row template
1: 		baseRows = new ExecRow[bulkFetchSize];
1: 		indexRows = new ExecIndexRow[bulkFetchSize];
1: 		compactBaseRows = new ExecRow[bulkFetchSize];
1: 
1: 		try
1: 		{
1: 			// Create the array of base row template
1: 			for (int i = 0; i < bulkFetchSize; i++)
1: 			{
1: 				// create a base row template
1: 				baseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);
1: 
1: 				// create an index row template
1: 				indexRows[i] = indexRowGenerator.getIndexRowTemplate();
1: 
1: 				// create a compact base row template
1: 				compactBaseRows[i] = activation.getExecutionFactory().getValueRow(
0: 													baseColumnPositions.length);
1: 			}
1: 
1: 			indexTemplateRow = indexRows[0];
1: 
1: 			// Fill the partial row with nulls of the correct type
1: 			ColumnDescriptorList cdl = td.getColumnDescriptorList();
1: 			int					 cdlSize = cdl.size();
1: 			for (int index = 0, numSet = 0; index < cdlSize; index++)
1: 			{
1: 				if (! zeroBasedBitSet.get(index))
1: 				{
1: 					continue;
1: 				}
1: 				numSet++;
0: 				ColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);
1: 				DataTypeDescriptor dts = cd.getType();
1: 
1: 
1: 				for (int i = 0; i < bulkFetchSize; i++)
1: 				{
1: 					// Put the column in both the compact and sparse base rows
1: 					baseRows[i].setColumn(index + 1,
1: 								  dts.getNull());
1: 					compactBaseRows[i].setColumn(numSet,
1: 								  baseRows[i].getColumn(index + 1));
1: 				}
1: 
1: 				// Calculate the approximate row size for the index row
1: 				approximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);
1: 			}
1: 
1: 			// Get an array of RowLocation template
1: 			RowLocation rl[] = new RowLocation[bulkFetchSize];
1: 			for (int i = 0; i < bulkFetchSize; i++)
1: 			{
1: 				rl[i] = scan.newRowLocationTemplate();
1: 
1: 				// Get an index row based on the base row
1: 				indexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);
1: 			}
1: 
0: 			/* now that we got indexTemplateRow, done for duplicate index
1: 			 */
0: 			if (duplicate)
1: 				return;
1: 
1: 			/* For non-unique indexes, we order by all columns + the RID.
1: 			 * For unique indexes, we just order by the columns.
1: 			 * We create a unique index observer for unique indexes
1: 			 * so that we can catch duplicate key.
1: 			 * We create a basic sort observer for non-unique indexes
1: 			 * so that we can reuse the wrappers during an external
1: 			 * sort.
1: 			 */
0: 			int numColumnOrderings;
0: 			SortObserver sortObserver = null;
0: 			if (unique)
1: 			{
0: 				numColumnOrderings = baseColumnPositions.length;
0: 				// if the index is a constraint, use constraintname in possible error messagge
1: 				String indexOrConstraintName = indexName;
1: 				if  (conglomerateUUID != null)
1: 				{
0: 					ConglomerateDescriptor cd = dd.getConglomerateDescriptor(conglomerateUUID);
0: 					if ((isConstraint) && (cd != null && cd.getUUID() != null && td != null))
1: 					{
0: 						ConstraintDescriptor conDesc = dd.getConstraintDescriptor(td,
0:                                                                       cd.getUUID());
1: 						indexOrConstraintName = conDesc.getConstraintName();
1: 					}
1: 				}
0: 				sortObserver = new UniqueIndexSortObserver(true, isConstraint, 
0: 														   indexOrConstraintName,
0: 														   indexTemplateRow,
0: 														   true,
0: 														   td.getName());
1: 			}
1: 			else
1: 			{
1: 				numColumnOrderings = baseColumnPositions.length + 1;
1: 				sortObserver = new BasicSortObserver(true, false, 
0: 													 indexTemplateRow,
1: 													 true);
1: 			}
1: 			ColumnOrdering[]	order = new ColumnOrdering[numColumnOrderings];
1: 			for (int i=0; i < numColumnOrderings; i++) 
1: 			{
0: 				order[i] = new IndexColumnOrder(i, unique || i < numColumnOrderings - 1 
0: 													? isAscending[i] : true);
1: 			}
1: 
1: 			// create the sorter
0: 			sortId = tc.createSort((Properties)null, 
1: 					indexTemplateRow.getRowArrayClone(),
1: 					order,
1: 					sortObserver,
1: 					false,			// not in order
1: 					scan.getEstimatedRowCount(),
1: 					approximateRowSize	// est row size, -1 means no idea	
1: 					);
1: 
1: 			needToDropSort = true;
1: 
1: 			// Populate sorter and get the output of the sorter into a row
1: 			// source.  The sorter has the indexed columns only and the columns
1: 			// are in the correct order. 
1: 			rowSource = loadSorter(baseRows, indexRows, tc,
1: 								   scan, sortId, rl);
1: 
0: 			conglomId = tc.createAndLoadConglomerate(
0: 					indexType,
1: 					indexTemplateRow.getRowArray(),	// index row template
1: 					order, //colums sort order
1: 					indexProperties,
1: 					TransactionController.IS_DEFAULT, // not temporary
1: 					rowSource,
1: 					(long[]) null);
1: 			
1: 		}
1: 		finally
1: 		{
1: 
1: 			/* close the table scan */
1: 			if (scan != null)
1: 				scan.close();
1: 
1: 			/* close the sorter row source before throwing exception */
1: 			if (rowSource != null)
1: 				rowSource.closeRowSource();
1: 
1: 			/*
1: 			** drop the sort so that intermediate external sort run can be
1: 			** removed from disk
1: 			*/
1: 			if (needToDropSort)
1: 			 	tc.dropSort(sortId);
1: 		}
1: 
1: 		ConglomerateController indexController =
1: 			tc.openConglomerate(
1:                 conglomId, false, 0, TransactionController.MODE_TABLE,
1:                 TransactionController.ISOLATION_SERIALIZABLE);
1: 
1: 		// Check to make sure that the conglomerate can be used as an index
1: 		if ( ! indexController.isKeyed())
1: 		{
1: 			indexController.close();
1: 			throw StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,
1: 														   indexType);
1: 		}
1: 		indexController.close();
1: 
1: 		//
0: 		// Create a conglomerate descriptor with the conglomId filled in and
0: 		// add it.
1: 		//
1: 
1: 		ConglomerateDescriptor cgd =
1: 			ddg.newConglomerateDescriptor(conglomId, indexName, true,
1: 										  indexRowGenerator, isConstraint,
1: 										  conglomerateUUID, td.getUUID(), sd.getUUID() );
1: 
1: 		dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
1: 
0: 		// add newly added conglomerate to the list of conglomerate descriptors
0: 		// in the td.
0: 		ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
1: 		cdl.add(cgd);
1: 
1: 		CardinalityCounter cCount = (CardinalityCounter)rowSource;
0: 		long numRows;
0: 		if ((numRows = cCount.getRowCount()) > 0)
1: 		{
1: 			long[] c = cCount.getCardinality();
1: 			for (int i = 0; i < c.length; i++)
1: 			{
1: 				StatisticsDescriptor statDesc = 
0: 					new StatisticsDescriptor(dd, dd.getUUIDFactory().createUUID(),
0: 												cgd.getUUID(), td.getUUID(), "I", new StatisticsImpl(numRows, c[i]),
0: 												i + 1);
1: 				dd.addDescriptor(statDesc, null, 
1: 								 DataDictionary.SYSSTATISTICS_CATALOG_NUM,
1: 								 true, tc);
1: 			}
1: 		}
1: 	}
1: 
1: 	// CLASS METHODS
1: 	
1: 	///////////////////////////////////////////////////////////////////////
1: 	//
1: 	//	GETTERs called by CreateConstraint
1: 	//
1: 	///////////////////////////////////////////////////////////////////////
1: 	ExecRow getIndexTemplateRow()
1: 	{
1: 		return indexTemplateRow;
1: 	}
1: 
1: 	/**
0: 	 * Do necessary clean up (close down controllers, etc.) before throwing
0: 	 * a statement exception.
1: 	 *
0: 	 * @param scan				ScanController for the heap
0: 	 * @param indexController	ConglomerateController for the index
1: 	 *
0: 	 * @return Nothing.
1: 	 */
0: 	private void statementExceptionCleanup(
0: 					ScanController scan, 
0: 					ConglomerateController indexController)
1:         throws StandardException
1: 	{
0: 		if (indexController != null)
1: 		{
1: 			indexController.close();
1: 		}
1: 		if (scan != null)
1: 		{
1: 			scan.close();
1: 		}
1: 	}
1: 
1: 	/**
1: 	 * Scan the base conglomerate and insert the keys into a sorter,
1: 	 * returning a rowSource on the sorter. 
1: 	 *
1: 	 * @return RowSource on the sorted index keys.
1: 	 *
1: 	 * @exception StandardException					thrown on error
1: 	 */
1: 	private RowLocationRetRowSource loadSorter(ExecRow[] baseRows,
1: 								               ExecIndexRow[] indexRows, 
1: 								               TransactionController tc,
1: 								               GroupFetchScanController scan,
1: 								               long sortId,
1: 								               RowLocation rl[])
1: 		throws StandardException
1: 	{
1: 		SortController		sorter;
1: 		long				rowCount = 0;
1: 
1: 		sorter = tc.openSort(sortId);
1: 
1: 		try
1: 		{
1: 			// Step through all the rows in the base table
1: 			// prepare an array or rows for bulk fetch
1: 			int bulkFetchSize = baseRows.length;
1: 
1: 			if (SanityManager.DEBUG)
1: 			{
1: 				SanityManager.ASSERT(bulkFetchSize == indexRows.length, 
1: 					"number of base rows and index rows does not match");
1: 				SanityManager.ASSERT(bulkFetchSize == rl.length,
1: 					"number of base rows and row locations does not match");
1: 			}
1: 
1: 			DataValueDescriptor[][] baseRowArray = new DataValueDescriptor[bulkFetchSize][];
1: 
1: 			for (int i = 0; i < bulkFetchSize; i++)
1: 				baseRowArray[i] = baseRows[i].getRowArray();
1: 
1: 			// rl[i] and baseRowArray[i] and indexRows[i] are all tied up
1: 			// beneath the surface.  Fetching the base row and row location
1: 			// from the table scan will automagically set up the indexRow
1: 			// fetchNextGroup will return how many rows are actually fetched.
0: 			int bulkFetched = 0;
1: 
1: 			while ((bulkFetched = scan.fetchNextGroup(baseRowArray, rl)) > 0)
1: 			{
1: 				for (int i = 0; i < bulkFetched; i++)
1: 				{
1: 					sorter.insert(indexRows[i].getRowArray());
1: 					rowCount++;
1: 				}
1: 			}
1: 
1: 			/*
1: 			** We've just done a full scan on the heap, so set the number
1: 			** of rows so the optimizer will have an accurate count.
1: 			*/
1: 			scan.setEstimatedRowCount(rowCount);
1: 		}
1: 		finally
1: 		{
0: 			sorter.close();
1: 		}
1: 
1: 		return new CardinalityCounter(tc.openSortRowSource(sortId));
1: 	}
1: }
1: 
author:David Van Couvering
-------------------------------------------------------------------------------
commit:f6123ee
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
commit:6b50965
/////////////////////////////////////////////////////////////////////////
0: 	 *  @param schemaName	the schema that table (and index) lives in.
/////////////////////////////////////////////////////////////////////////
author:Satheesh E. Bandaram
-------------------------------------------------------------------------------
commit:e1d51e3
/////////////////////////////////////////////////////////////////////////
0: 				//Duplicate indexes share the physical conglomerate underneath
1: 				//DERBY-655 and DERBY-1343  
0: 				//Duplicate indexes will have unqiue logical conglomerate UUIDs.  
1: 				conglomerateUUID = dd.getUUIDFactory().createUUID();
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
author:Ken Coar
-------------------------------------------------------------------------------
commit:95e7b46
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 1997, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
0: 
0:  */
0: 
0: package org.apache.derby.impl.sql.execute;
0: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
0: 
0: import org.apache.derby.iapi.services.loader.ClassFactory;
0: import org.apache.derby.iapi.services.loader.ClassInspector;
0: 
0: import org.apache.derby.iapi.services.stream.HeaderPrintWriter;
0: 
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
0: import org.apache.derby.iapi.sql.execute.ExecutionContext;
0: import org.apache.derby.iapi.sql.execute.ExecRow;
0: import org.apache.derby.iapi.sql.execute.ExecIndexRow;
0: 
0: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptorList;
0: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptorList;
0: import org.apache.derby.iapi.sql.dictionary.DataDescriptorGenerator;
0: import org.apache.derby.iapi.sql.dictionary.DataDictionaryContext;
0: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
0: import org.apache.derby.iapi.sql.dictionary.ConglomerateDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.ColumnDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.SchemaDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.IndexRowGenerator;
0: import org.apache.derby.iapi.sql.dictionary.TableDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.ConstraintDescriptor;
0: import org.apache.derby.iapi.sql.dictionary.StatisticsDescriptor;
0: import org.apache.derby.iapi.sql.depend.DependencyManager;
0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
0: import org.apache.derby.iapi.sql.Activation;
0: 
0: import org.apache.derby.iapi.types.DataValueFactory;
0: import org.apache.derby.iapi.types.DataTypeDescriptor;
0: import org.apache.derby.iapi.types.TypeId;
0: import org.apache.derby.iapi.types.RowLocation;
0: 
0: import org.apache.derby.iapi.reference.SQLState;
0: 
0: import org.apache.derby.iapi.error.StandardException;
0: 
0: import org.apache.derby.iapi.store.access.ColumnOrdering;
0: import org.apache.derby.iapi.store.access.ConglomerateController;
0: import org.apache.derby.iapi.store.access.GroupFetchScanController;
0: import org.apache.derby.iapi.store.access.RowLocationRetRowSource;
0: import org.apache.derby.iapi.store.access.ScanController;
0: import org.apache.derby.iapi.store.access.SortObserver;
0: import org.apache.derby.iapi.store.access.SortController;
0: import org.apache.derby.iapi.store.access.TransactionController;
0: import org.apache.derby.iapi.types.DataValueDescriptor;
0: 
0: 
0: import org.apache.derby.catalog.UUID;
0: import org.apache.derby.catalog.types.StatisticsImpl;
0: 
0: import java.util.Properties;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
0: 
0: /**
0:  *	This class  describes actions that are ALWAYS performed for a
0:  *	CREATE TABLE Statement at Execution time.
0:  *
0:  *	@author Jeff Lichtman	Cribbed from from CreateTableConstantAction
0:  */
0: 
0: class CreateIndexConstantAction extends IndexConstantAction
0: {
0: 	/**
0: 		IBM Copyright &copy notice.
0: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1997_2004;
0: 
0: 	private boolean			unique;
0: 	private String			indexType;
0: 	private long			conglomId;
0: 	private String[]		columnNames;
0: 	private boolean[]		isAscending;
0: 	private boolean			isConstraint;
0: 	private UUID			conglomerateUUID;
0: 	private Properties		properties;
0: 
0: 	private ExecRow indexTemplateRow;
0: 
0: 
0: 	// CONSTRUCTORS
0: 	/**
0: 	 *	Make the ConstantAction for a CREATE INDEX statement.
0: 	 *
0: 	 *  @param unique		True means it will be a unique index
0: 	 *  @param indexType	The type of index (BTREE, for example)
0: 	 *  @param sd			the schema that table (and index) lives in.
0: 	 *  @param indexName	Name of the index
0: 	 *  @param tableName	Name of table the index will be on
0: 	 *  @param tableId		UUID of table
0: 	 *  @param conglomId	Conglomerate ID of the index, if known in advance
0: 	 *  @param columnNames	Names of the columns in the index, in order
0: 	 *	@param isAscending	Array of booleans telling asc/desc on each column
0: 	 *  @param isConstraint	TRUE if index is backing up a constraint, else FALSE
0: 	 *  @param conglomerateUUID	ID of conglomerate
0: 	 *  @param properties	The optional properties list associated with the index.
0: 	 */
0: 	CreateIndexConstantAction(
0: 								boolean			unique,
0: 								String			indexType,
0: 								String			schemaName,
0: 								String			indexName,
0: 								String			tableName,
0: 								UUID			tableId,
0: 								long			conglomId,
0: 								String[]		columnNames,
0: 								boolean[]		isAscending,
0: 								boolean			isConstraint,
0: 								UUID			conglomerateUUID,
0: 								Properties		properties)
0: 	{
0: 		super(tableId, indexName, tableName, schemaName);
0: 		this.unique = unique;
0: 		this.indexType = indexType;
0: 		this.conglomId= conglomId;
0: 		this.columnNames = columnNames;
0: 		this.isAscending = isAscending;
0: 		this.isConstraint = isConstraint;
0: 		this.conglomerateUUID = conglomerateUUID;
0: 		this.properties = properties;
0: 	}
0: 
0: 	///////////////////////////////////////////////
0: 	//
0: 	// OBJECT SHADOWS
0: 	//
0: 	///////////////////////////////////////////////
0: 
0: 	public	String	toString()
0: 	{
0: 		// Do not put this under SanityManager.DEBUG - it is needed for
0: 		// error reporting.
0: 		return "CREATE INDEX " + indexName;
0: 	}
0: 
0: 	// INTERFACE METHODS
0: 
0: 
0: 	/**
0: 	 *	This is the guts of the Execution-time logic for CREATE INDEX.
0: 	 *
0: 	 *	@see ConstantAction#executeConstantAction
0: 	 *
0: 	 * @exception StandardException		Thrown on failure
0: 	 */
0: 	public void	executeConstantAction( Activation activation )
0: 						throws StandardException
0: 	{
0: 		boolean						forCreateTable;
0: 		TableDescriptor 			td;
0: 		UUID 						toid;
0: 		ColumnDescriptor			columnDescriptor;
0: 		int[]						baseColumnPositions;
0: 		IndexRowGenerator			indexRowGenerator = null;
0: 		ExecRow[]					baseRows;
0: 		ExecIndexRow[]				indexRows;
0: 		ExecRow[]					compactBaseRows;
0: 		GroupFetchScanController    scan;
0: 		RowLocationRetRowSource	    rowSource;
0: 		long						sortId;
0: 		int							maxBaseColumnPosition = -1;
0: 
0: 		LanguageConnectionContext lcc = activation.getLanguageConnectionContext();
0: 		DataDictionary dd = lcc.getDataDictionary();
0: 		DependencyManager dm = dd.getDependencyManager();
0: 		TransactionController tc = lcc.getTransactionExecute();
0: 
0: 		/* Remember whether or not we are doing a create table */
0: 		forCreateTable = activation.getForCreateTable();
0: 
0: 		/*
0: 		** Inform the data dictionary that we are about to write to it.
0: 		** There are several calls to data dictionary "get" methods here
0: 		** that might be done in "read" mode in the data dictionary, but
0: 		** it seemed safer to do this whole operation in "write" mode.
0: 		**
0: 		** We tell the data dictionary we're done writing at the end of
0: 		** the transaction.
0: 		*/
0: 		dd.startWriting(lcc);
0: 
0: 		/*
0: 		** If the schema descriptor is null, then
0: 		** we must have just read ourselves in.  
0: 		** So we will get the corresponding schema
0: 		** descriptor from the data dictionary.
0: 		*/
0: 		SchemaDescriptor sd = dd.getSchemaDescriptor(schemaName, tc, true) ;
0: 
0: 
0: 		/* Get the table descriptor. */
0: 		/* See if we can get the TableDescriptor 
0: 		 * from the Activation.  (Will be there
0: 		 * for backing indexes.)
0: 		 */
0: 		td = activation.getDDLTableDescriptor();
0: 
0: 		if (td == null)
0: 		{
0: 			/* tableId will be non-null if adding an index to
0: 			 * an existing table (as opposed to creating a
0: 			 * table with a constraint with a backing index).
0: 			 */
0: 			if (tableId != null)
0: 			{
0: 				td = dd.getTableDescriptor(tableId);
0: 			}
0: 			else
0: 			{
0: 				td = dd.getTableDescriptor(tableName, sd);
0: 			}
0: 		}
0: 
0: 		if (td == null)
0: 		{
0: 			throw StandardException.newException(SQLState.LANG_CREATE_INDEX_NO_TABLE, 
0: 						indexName, tableName);
0: 		}
0: 
0: 		if (td.getTableType() == TableDescriptor.SYSTEM_TABLE_TYPE)
0: 		{
0: 			throw StandardException.newException(SQLState.LANG_CREATE_SYSTEM_INDEX_ATTEMPTED, 
0: 						indexName, tableName);
0: 		}
0: 
0: 		/* Get a shared table lock on the table. We need to lock table before
0: 		 * invalidate dependents, otherwise, we may interfere with the
0: 		 * compilation/re-compilation of DML/DDL.  See beetle 4325 and $WS/
0: 		 * docs/language/SolutionsToConcurrencyIssues.txt (point f).
0: 		 */
0: 		lockTableForDDL(tc, td.getHeapConglomerateId(), false);
0: 
0: 		// invalidate any prepared statements that
0: 		// depended on this table (including this one)
0: 		if (! forCreateTable)
0: 		{
0: 			dm.invalidateFor(td, DependencyManager.CREATE_INDEX, lcc);
0: 		}
0: 
0: 		// Translate the base column names to column positions
0: 		baseColumnPositions = new int[columnNames.length];
0: 		for (int i = 0; i < columnNames.length; i++)
0: 		{
0: 			// Look up the column in the data dictionary
0: 			columnDescriptor = td.getColumnDescriptor(columnNames[i]);
0: 			if (columnDescriptor == null)
0: 			{
0: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_FOUND_IN_TABLE, 
0: 															columnNames[i],
0: 															tableName);
0: 			}
0: 
0: 			TypeId typeId = columnDescriptor.getType().getTypeId();
0: 
0: 			// Don't allow a column to be created on a non-orderable type
0: 			ClassFactory cf = lcc.getLanguageConnectionFactory().getClassFactory();
0: 			boolean isIndexable = typeId.orderable(cf);
0: 
0: 			if (isIndexable && typeId.userType()) {
0: 				String userClass = typeId.getCorrespondingJavaTypeName();
0: 
0: 				// Don't allow indexes to be created on classes that
0: 				// are loaded from the database. This is because recovery
0: 				// won't be able to see the class and it will need it to
0: 				// run the compare method.
0: 				try {
0: 					if (cf.isApplicationClass(cf.loadApplicationClass(userClass)))
0: 						isIndexable = false;
0: 				} catch (ClassNotFoundException cnfe) {
0: 					// shouldn't happen as we just check the class is orderable
0: 					isIndexable = false;
0: 				}
0: 			}
0: 
0: 			if (!isIndexable) {
0: 				throw StandardException.newException(SQLState.LANG_COLUMN_NOT_ORDERABLE_DURING_EXECUTION, 
0: 					typeId.getSQLTypeName());
0: 			}
0: 
0: 			// Remember the position in the base table of each column
0: 			baseColumnPositions[i] = columnDescriptor.getPosition();
0: 
0: 			if (maxBaseColumnPosition < baseColumnPositions[i])
0: 				maxBaseColumnPosition = baseColumnPositions[i];
0: 		}
0: 
0: 		// check if we have similar indices already for this table
0: 		ConglomerateDescriptor[] congDescs = td.getConglomerateDescriptors();
0: 		boolean duplicate = false;
0: 
0: 		for (int i = 0; i < congDescs.length; i++)
0: 		{
0: 			ConglomerateDescriptor cd = congDescs[i];
0: 			if ( ! cd.isIndex())
0: 				continue;
0: 			IndexRowGenerator irg = cd.getIndexDescriptor();
0: 			int[] bcps = irg.baseColumnPositions();
0: 			boolean[] ia = irg.isAscending();
0: 			int j = 0;
0: 
0: 			/* For an index to be considered a duplicate of already existing index, the
0: 			 * following conditions have to be satisfied:
0: 			 * 1. the set of columns (both key and include columns) and their 
0: 			 *  order in the index is the same as that of an existing index AND 
0: 			 * 2. the ordering attributes are the same AND 
0: 			 * 3. both the previously existing index and the one being created 
0: 			 *  are non-unique OR the previously existing index is unique
0: 			 */
0: 
0: 			if ((bcps.length == baseColumnPositions.length) &&
0: 			    (irg.isUnique() || !unique) &&
0: 				indexType.equals(irg.indexType()))
0: 			{
0: 				for (; j < bcps.length; j++)
0: 				{
0: 					if ((bcps[j] != baseColumnPositions[j]) || (ia[j] != isAscending[j]))
0: 						break;
0: 				}
0: 			}
0: 
0: 			if (j == baseColumnPositions.length)	// duplicate
0: 			{
0: 				/*
0: 				 * Don't allow users to create a duplicate index. Allow if being done internally
0: 				 * for a constraint
0: 				 */
0: 				if (!isConstraint)
0: 				{
0: 					activation.addWarning(
0: 							StandardException.newWarning(
0: 								SQLState.LANG_INDEX_DUPLICATE,
0: 								cd.getConglomerateName()));
0: 
0: 					return;
0: 				}
0: 
0: 				conglomId = cd.getConglomerateNumber();
0: 				indexRowGenerator = cd.getIndexDescriptor();
0: 				conglomerateUUID = cd.getUUID();
0: 				duplicate = true;
0: 				break;
0: 			}
0: 		}
0: 
0: 		/* If this index already has an essentially same one, we share the
0: 		 * conglomerate with the old one, and just simply add a descriptor
0: 		 * entry into SYSCONGLOMERATES.
0: 		 */
0: 		DataDescriptorGenerator ddg = dd.getDataDescriptorGenerator();
0: 		if (duplicate)
0: 		{
0: 			ConglomerateDescriptor cgd =
0: 				ddg.newConglomerateDescriptor(conglomId, indexName, true,
0: 										  indexRowGenerator, isConstraint,
0: 										  conglomerateUUID, td.getUUID(), sd.getUUID() );
0: 			dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
0: 			// add newly added conglomerate to the list of conglomerate 
0: 			// descriptors in the td.
0: 			ConglomerateDescriptorList cdl = 
0: 				td.getConglomerateDescriptorList();
0: 			cdl.add(cgd);
0: 
0: 			// can't just return yet, need to get member "indexTemplateRow"
0: 			// because create constraint may use it
0: 		}
0: 
0: 		// Describe the properties of the index to the store using Properties
0: 		// RESOLVE: The following properties assume a BTREE index.
0: 		Properties	indexProperties;
0: 		
0: 		if (properties != null)
0: 		{
0: 			indexProperties = properties;
0: 		}
0: 		else
0: 		{
0: 			indexProperties = new Properties();
0: 		}
0: 
0: 		// Tell it the conglomerate id of the base table
0: 		indexProperties.put("baseConglomerateId",
0: 							Long.toString(td.getHeapConglomerateId()));
0: 
0: 		// All indexes are unique because they contain the RowLocation.
0: 		// The number of uniqueness columns must include the RowLocation
0: 		// if the user did not specify a unique index.
0: 		indexProperties.put("nUniqueColumns",
0: 					Integer.toString(unique ? baseColumnPositions.length :
0: 												baseColumnPositions.length + 1)
0: 							);
0: 
0: 		// By convention, the row location column is the last column
0: 		indexProperties.put("rowLocationColumn",
0: 							Integer.toString(baseColumnPositions.length));
0: 
0: 		// For now, all columns are key fields, including the RowLocation
0: 		indexProperties.put("nKeyFields",
0: 							Integer.toString(baseColumnPositions.length + 1));
0: 
0: 		// For now, assume that all index columns are ordered columns
0: 		if (! duplicate)
0: 		{
0: 			indexRowGenerator = new IndexRowGenerator(indexType, unique,
0: 													baseColumnPositions,
0: 													isAscending,
0: 													baseColumnPositions.length);
0: 		}
0: 
0: 		/* Now add the rows from the base table to the conglomerate.
0: 		 * We do this by scanning the base table and inserting the
0: 		 * rows into a sorter before inserting from the sorter
0: 		 * into the index.  This gives us better performance
0: 		 * and a more compact index.
0: 		 */
0: 
0: 		rowSource = null;
0: 		sortId = 0;
0: 		boolean needToDropSort = false;	// set to true once the sorter is created
0: 
0: 		/* bulkFetchSIze will be 16 (for now) unless
0: 		 * we are creating the table in which case it
0: 		 * will be 1.  Too hard to remove scan when
0: 		 * creating index on new table, so minimize
0: 		 * work where we can.
0: 		 */
0: 		int bulkFetchSize = (forCreateTable) ? 1 : 16;	
0: 		int numColumns = td.getNumberOfColumns();
0: 		int approximateRowSize = 0;
0: 
0: 		// Create the FormatableBitSet for mapping the partial to full base row
0: 		FormatableBitSet bitSet = new FormatableBitSet(numColumns+1);
0: 		for (int index = 0; index < baseColumnPositions.length; index++)
0: 		{
0: 			bitSet.set(baseColumnPositions[index]);
0: 		}
0: 		FormatableBitSet zeroBasedBitSet = RowUtil.shift(bitSet, 1);
0: 
0: 		// Start by opening a full scan on the base table.
0: 		scan = tc.openGroupFetchScan(
0:                             td.getHeapConglomerateId(),
0: 							false,	// hold
0: 							0,	// open base table read only
0:                             TransactionController.MODE_TABLE,
0:                             TransactionController.ISOLATION_SERIALIZABLE,
0: 							zeroBasedBitSet,    // all fields as objects
0: 							(DataValueDescriptor[]) null,	// startKeyValue
0: 							0,		// not used when giving null start posn.
0: 							null,	// qualifier
0: 							(DataValueDescriptor[]) null,	// stopKeyValue
0: 							0);		// not used when giving null stop posn.
0: 
0: 		// Create an array to put base row template
0: 		baseRows = new ExecRow[bulkFetchSize];
0: 		indexRows = new ExecIndexRow[bulkFetchSize];
0: 		compactBaseRows = new ExecRow[bulkFetchSize];
0: 
0: 		try
0: 		{
0: 			// Create the array of base row template
0: 			for (int i = 0; i < bulkFetchSize; i++)
0: 			{
0: 				// create a base row template
0: 				baseRows[i] = activation.getExecutionFactory().getValueRow(maxBaseColumnPosition);
0: 
0: 				// create an index row template
0: 				indexRows[i] = indexRowGenerator.getIndexRowTemplate();
0: 
0: 				// create a compact base row template
0: 				compactBaseRows[i] = activation.getExecutionFactory().getValueRow(
0: 													baseColumnPositions.length);
0: 			}
0: 
0: 			indexTemplateRow = indexRows[0];
0: 
0: 			// Fill the partial row with nulls of the correct type
0: 			ColumnDescriptorList cdl = td.getColumnDescriptorList();
0: 			int					 cdlSize = cdl.size();
0: 			for (int index = 0, numSet = 0; index < cdlSize; index++)
0: 			{
0: 				if (! zeroBasedBitSet.get(index))
0: 				{
0: 					continue;
0: 				}
0: 				numSet++;
0: 				ColumnDescriptor cd = (ColumnDescriptor) cdl.elementAt(index);
0: 				DataTypeDescriptor dts = cd.getType();
0: 
0: 
0: 				for (int i = 0; i < bulkFetchSize; i++)
0: 				{
0: 					// Put the column in both the compact and sparse base rows
0: 					baseRows[i].setColumn(index + 1,
0: 								  dts.getNull());
0: 					compactBaseRows[i].setColumn(numSet,
0: 								  baseRows[i].getColumn(index + 1));
0: 				}
0: 
0: 				// Calculate the approximate row size for the index row
0: 				approximateRowSize += dts.getTypeId().getApproximateLengthInBytes(dts);
0: 			}
0: 
0: 			// Get an array of RowLocation template
0: 			RowLocation rl[] = new RowLocation[bulkFetchSize];
0: 			for (int i = 0; i < bulkFetchSize; i++)
0: 			{
0: 				rl[i] = scan.newRowLocationTemplate();
0: 
0: 				// Get an index row based on the base row
0: 				indexRowGenerator.getIndexRow(compactBaseRows[i], rl[i], indexRows[i], bitSet);
0: 			}
0: 
0: 			/* now that we got indexTemplateRow, done for duplicate index
0: 			 */
0: 			if (duplicate)
0: 				return;
0: 
0: 			/* For non-unique indexes, we order by all columns + the RID.
0: 			 * For unique indexes, we just order by the columns.
0: 			 * We create a unique index observer for unique indexes
0: 			 * so that we can catch duplicate key.
0: 			 * We create a basic sort observer for non-unique indexes
0: 			 * so that we can reuse the wrappers during an external
0: 			 * sort.
0: 			 */
0: 			int numColumnOrderings;
0: 			SortObserver sortObserver = null;
0: 			if (unique)
0: 			{
0: 				numColumnOrderings = baseColumnPositions.length;
0: 				// if the index is a constraint, use constraintname in possible error messagge
0: 				String indexOrConstraintName = indexName;
0: 				if  (conglomerateUUID != null)
0: 				{
0: 					ConglomerateDescriptor cd = dd.getConglomerateDescriptor(conglomerateUUID);
0: 					if ((isConstraint) && (cd != null && cd.getUUID() != null && td != null))
0: 					{
0: 						ConstraintDescriptor conDesc = dd.getConstraintDescriptor(td,
0:                                                                       cd.getUUID());
0: 						indexOrConstraintName = conDesc.getConstraintName();
0: 					}
0: 				}
0: 				sortObserver = new UniqueIndexSortObserver(true, isConstraint, 
0: 														   indexOrConstraintName,
0: 														   indexTemplateRow,
0: 														   true,
0: 														   td.getName());
0: 			}
0: 			else
0: 			{
0: 				numColumnOrderings = baseColumnPositions.length + 1;
0: 				sortObserver = new BasicSortObserver(true, false, 
0: 													 indexTemplateRow,
0: 													 true);
0: 			}
0: 			ColumnOrdering[]	order = new ColumnOrdering[numColumnOrderings];
0: 			for (int i=0; i < numColumnOrderings; i++) 
0: 			{
0: 				order[i] = new IndexColumnOrder(i, unique || i < numColumnOrderings - 1 
0: 													? isAscending[i] : true);
0: 			}
0: 
0: 			// create the sorter
0: 			sortId = tc.createSort((Properties)null, 
0: 					indexTemplateRow.getRowArrayClone(),
0: 					order,
0: 					sortObserver,
0: 					false,			// not in order
0: 					scan.getEstimatedRowCount(),
0: 					approximateRowSize	// est row size, -1 means no idea	
0: 					);
0: 
0: 			needToDropSort = true;
0: 
0: 			// Populate sorter and get the output of the sorter into a row
0: 			// source.  The sorter has the indexed columns only and the columns
0: 			// are in the correct order. 
0: 			rowSource = loadSorter(baseRows, indexRows, tc,
0: 								   scan, sortId, rl);
0: 
0: 			conglomId = tc.createAndLoadConglomerate(
0: 					indexType,
0: 					indexTemplateRow.getRowArray(),	// index row template
0: 					order, //colums sort order
0: 					indexProperties,
0: 					TransactionController.IS_DEFAULT, // not temporary
0: 					rowSource,
0: 					(long[]) null);
0: 			
0: 		}
0: 		finally
0: 		{
0: 
0: 			/* close the table scan */
0: 			if (scan != null)
0: 				scan.close();
0: 
0: 			/* close the sorter row source before throwing exception */
0: 			if (rowSource != null)
0: 				rowSource.closeRowSource();
0: 
0: 			/*
0: 			** drop the sort so that intermediate external sort run can be
0: 			** removed from disk
0: 			*/
0: 			if (needToDropSort)
0: 			 	tc.dropSort(sortId);
0: 		}
0: 
0: 		ConglomerateController indexController =
0: 			tc.openConglomerate(
0:                 conglomId, false, 0, TransactionController.MODE_TABLE,
0:                 TransactionController.ISOLATION_SERIALIZABLE);
0: 
0: 		// Check to make sure that the conglomerate can be used as an index
0: 		if ( ! indexController.isKeyed())
0: 		{
0: 			indexController.close();
0: 			throw StandardException.newException(SQLState.LANG_NON_KEYED_INDEX, indexName,
0: 														   indexType);
0: 		}
0: 		indexController.close();
0: 
0: 		//
0: 		// Create a conglomerate descriptor with the conglomId filled in and
0: 		// add it.
0: 		//
0: 
0: 		ConglomerateDescriptor cgd =
0: 			ddg.newConglomerateDescriptor(conglomId, indexName, true,
0: 										  indexRowGenerator, isConstraint,
0: 										  conglomerateUUID, td.getUUID(), sd.getUUID() );
0: 
0: 		dd.addDescriptor(cgd, sd, DataDictionary.SYSCONGLOMERATES_CATALOG_NUM, false, tc);
0: 
0: 		// add newly added conglomerate to the list of conglomerate descriptors
0: 		// in the td.
0: 		ConglomerateDescriptorList cdl = td.getConglomerateDescriptorList();
0: 		cdl.add(cgd);
0: 
0: 		CardinalityCounter cCount = (CardinalityCounter)rowSource;
0: 		long numRows;
0: 		if ((numRows = cCount.getRowCount()) > 0)
0: 		{
0: 			long[] c = cCount.getCardinality();
0: 			for (int i = 0; i < c.length; i++)
0: 			{
0: 				StatisticsDescriptor statDesc = 
0: 					new StatisticsDescriptor(dd, dd.getUUIDFactory().createUUID(),
0: 												cgd.getUUID(), td.getUUID(), "I", new StatisticsImpl(numRows, c[i]),
0: 												i + 1);
0: 				dd.addDescriptor(statDesc, null, 
0: 								 DataDictionary.SYSSTATISTICS_CATALOG_NUM,
0: 								 true, tc);
0: 			}
0: 		}
0: 	}
0: 
0: 	// CLASS METHODS
0: 	
0: 	///////////////////////////////////////////////////////////////////////
0: 	//
0: 	//	GETTERs called by CreateConstraint
0: 	//
0: 	///////////////////////////////////////////////////////////////////////
0: 	ExecRow getIndexTemplateRow()
0: 	{
0: 		return indexTemplateRow;
0: 	}
0: 
0: 	/**
0: 	 * Do necessary clean up (close down controllers, etc.) before throwing
0: 	 * a statement exception.
0: 	 *
0: 	 * @param scan				ScanController for the heap
0: 	 * @param indexController	ConglomerateController for the index
0: 	 *
0: 	 * @return Nothing.
0: 	 */
0: 	private void statementExceptionCleanup(
0: 					ScanController scan, 
0: 					ConglomerateController indexController)
0:         throws StandardException
0: 	{
0: 		if (indexController != null)
0: 		{
0: 			indexController.close();
0: 		}
0: 		if (scan != null)
0: 		{
0: 			scan.close();
0: 		}
0: 	}
0: 
0: 	/**
0: 	 * Scan the base conglomerate and insert the keys into a sorter,
0: 	 * returning a rowSource on the sorter. 
0: 	 *
0: 	 * @return RowSource on the sorted index keys.
0: 	 *
0: 	 * @exception StandardException					thrown on error
0: 	 */
0: 	private RowLocationRetRowSource loadSorter(ExecRow[] baseRows,
0: 								               ExecIndexRow[] indexRows, 
0: 								               TransactionController tc,
0: 								               GroupFetchScanController scan,
0: 								               long sortId,
0: 								               RowLocation rl[])
0: 		throws StandardException
0: 	{
0: 		SortController		sorter;
0: 		long				rowCount = 0;
0: 
0: 		sorter = tc.openSort(sortId);
0: 
0: 		try
0: 		{
0: 			// Step through all the rows in the base table
0: 			// prepare an array or rows for bulk fetch
0: 			int bulkFetchSize = baseRows.length;
0: 
0: 			if (SanityManager.DEBUG)
0: 			{
0: 				SanityManager.ASSERT(bulkFetchSize == indexRows.length, 
0: 					"number of base rows and index rows does not match");
0: 				SanityManager.ASSERT(bulkFetchSize == rl.length,
0: 					"number of base rows and row locations does not match");
0: 			}
0: 
0: 			DataValueDescriptor[][] baseRowArray = new DataValueDescriptor[bulkFetchSize][];
0: 
0: 			for (int i = 0; i < bulkFetchSize; i++)
0: 				baseRowArray[i] = baseRows[i].getRowArray();
0: 
0: 			// rl[i] and baseRowArray[i] and indexRows[i] are all tied up
0: 			// beneath the surface.  Fetching the base row and row location
0: 			// from the table scan will automagically set up the indexRow
0: 			// fetchNextGroup will return how many rows are actually fetched.
0: 			int bulkFetched = 0;
0: 
0: 			while ((bulkFetched = scan.fetchNextGroup(baseRowArray, rl)) > 0)
0: 			{
0: 				for (int i = 0; i < bulkFetched; i++)
0: 				{
0: 					sorter.insert(indexRows[i].getRowArray());
0: 					rowCount++;
0: 				}
0: 			}
0: 
0: 			/*
0: 			** We've just done a full scan on the heap, so set the number
0: 			** of rows so the optimizer will have an accurate count.
0: 			*/
0: 			scan.setEstimatedRowCount(rowCount);
0: 		}
0: 		finally
0: 		{
0: 			sorter.close();
0: 		}
0: 
0: 		return new CardinalityCounter(tc.openSortRowSource(sortId));
0: 	}
0: }
0: 
============================================================================
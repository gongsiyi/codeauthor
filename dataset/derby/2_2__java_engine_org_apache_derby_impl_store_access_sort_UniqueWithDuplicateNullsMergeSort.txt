1:28e234d: /*
2:28e234d:  
1:28e234d:    Derby - Class org.apache.derby.impl.store.access.sort.UniqueWithDuplicateNullsMergeSort
1:28e234d:  
1:28e234d:    Licensed to the Apache Software Foundation (ASF) under one or more
1:28e234d:    contributor license agreements.  See the NOTICE file distributed with
1:28e234d:    this work for additional information regarding copyright ownership.
1:28e234d:    The ASF licenses this file to you under the Apache License, Version 2.0
1:28e234d:    (the "License"); you may not use this file except in compliance with
1:28e234d:    the License.  You may obtain a copy of the License at
1:28e234d:  
1:28e234d:       http://www.apache.org/licenses/LICENSE-2.0
1:28e234d:  
1:28e234d:    Unless required by applicable law or agreed to in writing, software
1:28e234d:    distributed under the License is distributed on an "AS IS" BASIS,
1:28e234d:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:28e234d:    See the License for the specific language governing permissions and
1:28e234d:    limitations under the License.
1:28e234d:  
1:28e234d:  */
1:28e234d: 
1:28e234d: package org.apache.derby.impl.store.access.sort;
1:28e234d: 
1:28e234d: import org.apache.derby.iapi.error.StandardException;
1:28e234d: import org.apache.derby.iapi.types.DataValueDescriptor;
1:28e234d: 
1:28e234d: /**
1:d07f526:  * This class extends and customizes MergeSort to support unique indexes with
1:d07f526:  * duplicate nulls.
1:28e234d:  * It overrides compare method to consider keypart - 1 parts of the keys while
1:28e234d:  * comparing (only for non null keys).
1:28e234d:  */
1:28e234d: final class UniqueWithDuplicateNullsMergeSort extends MergeSort {
1:28e234d:     
1:28e234d:     /**
1:d07f526:      * Compares two keys. 
1:d07f526:      *
1:d07f526:      * If all the parts of the keys are not null then the leading 
1:0c5bc3a:      * (keys.length - 1) parts are compared, else if a part of the key
1:d07f526:      * is null then all parts of the key are compared (keys.length).
1:d07f526:      *
1:d07f526:      * This behavior is useful for implementing unique constraints where
1:d07f526:      * multiple null values are allowed, but uniqueness must still be 
1:d07f526:      * guaranteed for keys with no null values.   In this case the leading
1:d07f526:      * parts of the key are the user key columns, while the last column
1:d07f526:      * is a system provided column which is guaranteed unique per base row.
1:d07f526:      *
1:28e234d:      * @param r1 keys 
1:28e234d:      * @param r2 keys
1:d07f526:      *
1:28e234d:      * @return 0 for duplicates non zero for distinct keys 
1:28e234d:      */
1:0c5bc3a:     @Override
1:28e234d:     protected int compare(DataValueDescriptor[] r1, DataValueDescriptor[] r2)
1:28e234d:     throws StandardException {
1:28e234d:         // Get the number of columns we have to compare.
1:28e234d:         int colsToCompare = columnOrdering.length;
1:28e234d:         int r;
1:28e234d: 
1:d07f526:         // Compare the columns specified in the column ordering array.
1:28e234d:         boolean nonull = true;
1:28e234d:         for (int i = 0; i < colsToCompare; i++) {
1:d07f526:             //if there are any nulls in the row nonull will be false
1:d07f526:             //
1:d07f526:             //if there was no nulls in the row and we are about to 
1:d07f526:             //compare the last field (all fields except for the location
1:d07f526:             //are same), treat them as duplicate.   This is used by caller
1:d07f526:             //to implement unique key while ignoring case of keys with
1:d07f526:             //null values.
1:d07f526:             //
1:d07f526:             //if at least one field was null, go ahead and compare the 
1:d07f526:             //location too.  This is used to provide proper sorting of
1:d07f526:             //duplicate keys with nulls, they must be ordered properly 
1:d07f526:             //according to the last field also.
1:0c5bc3a:             if (i == colsToCompare - 1 && nonull) {
1:0c5bc3a:                 if (sortObserver.deferred()) {
1:0c5bc3a:                     sortObserver.rememberDuplicate(r1);
1:0c5bc3a:                 } else {
1:0c5bc3a:                     return 0;
1:0c5bc3a:                 }
1:0c5bc3a:             }
1:d07f526: 
1:28e234d:             // Get columns to compare.
1:28e234d:             int colid = columnOrderingMap[i];
1:28e234d:             boolean nullsLow = columnOrderingNullsLowMap[i];
1:28e234d:             
1:28e234d:             // If the columns don't compare equal, we're done.
1:28e234d:             // Return the sense of the comparison.
1:28e234d:             if ((r = r1[colid].compare(r2[colid], nullsLow))
1:28e234d:             != 0) {
1:28e234d:                 if (this.columnOrderingAscendingMap[i])
1:28e234d:                     return r;
1:28e234d:                 else
1:28e234d:                     return -r;
1:28e234d:             } else {
1:d07f526:                 //set nonull to false if the fields are equal and null
1:28e234d:                 if (r1[colid].isNull())
1:28e234d:                     nonull = false;
1:28e234d:             }
1:28e234d:         }
1:28e234d:         
1:28e234d:         // We made it through all the columns, and they must have
1:28e234d:         // all compared equal.  So return that the rows compare equal.
2:28e234d:         return 0;
1:28e234d:     }
1:28e234d: }
============================================================================
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:0c5bc3a
/////////////////////////////////////////////////////////////////////////
1:      * (keys.length - 1) parts are compared, else if a part of the key
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:             if (i == colsToCompare - 1 && nonull) {
1:                 if (sortObserver.deferred()) {
1:                     sortObserver.rememberDuplicate(r1);
1:                 } else {
1:                     return 0;
1:                 }
1:             }
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:d07f526
/////////////////////////////////////////////////////////////////////////
1:  * This class extends and customizes MergeSort to support unique indexes with
1:  * duplicate nulls.
1:      * Compares two keys. 
1:      *
1:      * If all the parts of the keys are not null then the leading 
0:      * (keys.length - 1) parts are compared, else if no part of the key
1:      * is null then all parts of the key are compared (keys.length).
1:      *
1:      * This behavior is useful for implementing unique constraints where
1:      * multiple null values are allowed, but uniqueness must still be 
1:      * guaranteed for keys with no null values.   In this case the leading
1:      * parts of the key are the user key columns, while the last column
1:      * is a system provided column which is guaranteed unique per base row.
1:      *
1:      *
/////////////////////////////////////////////////////////////////////////
1:         // Compare the columns specified in the column ordering array.
1:             //if there are any nulls in the row nonull will be false
1:             //
1:             //if there was no nulls in the row and we are about to 
1:             //compare the last field (all fields except for the location
1:             //are same), treat them as duplicate.   This is used by caller
1:             //to implement unique key while ignoring case of keys with
1:             //null values.
1:             //
1:             //if at least one field was null, go ahead and compare the 
1:             //location too.  This is used to provide proper sorting of
1:             //duplicate keys with nulls, they must be ordered properly 
1:             //according to the last field also.
1: 
/////////////////////////////////////////////////////////////////////////
1:                 //set nonull to false if the fields are equal and null
/////////////////////////////////////////////////////////////////////////
commit:28e234d
/////////////////////////////////////////////////////////////////////////
1: /*
1:  
1:    Derby - Class org.apache.derby.impl.store.access.sort.UniqueWithDuplicateNullsMergeSort
1:  
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
1:  
1:       http://www.apache.org/licenses/LICENSE-2.0
1:  
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
1:  
1:  */
1: 
1: package org.apache.derby.impl.store.access.sort;
1: 
1: import org.apache.derby.iapi.error.StandardException;
1: import org.apache.derby.iapi.types.DataValueDescriptor;
1: 
1: /**
0:  * This class extends and customizes MergeSort to support almost unique index.
1:  * It overrides compare method to consider keypart - 1 parts of the keys while
1:  * comparing (only for non null keys).
1:  */
1: final class UniqueWithDuplicateNullsMergeSort extends MergeSort {
1:     
1:     /**
0:      * Compares two sets of keys. If all the parts of the keys are not null
0:      * keys.length - 1 part is compared other wise all the parts are compared.
0:      * This methods assumes that last part is location.
1:      * @param r1 keys 
1:      * @param r2 keys
1:      * @return 0 for duplicates non zero for distinct keys 
1:      */
1:     protected int compare(DataValueDescriptor[] r1, DataValueDescriptor[] r2)
1:     throws StandardException {
1:         // Get the number of columns we have to compare.
1:         int colsToCompare = columnOrdering.length;
1:         int r;
1: 
0:         // Compare the columns specified in the column
0:         // ordering array.
1:         boolean nonull = true;
1:         for (int i = 0; i < colsToCompare; i++) {
0:             if (i == colsToCompare - 1 && nonull)
1:                 return 0;
1:             // Get columns to compare.
1:             int colid = columnOrderingMap[i];
1:             boolean nullsLow = columnOrderingNullsLowMap[i];
1:             
1:             // If the columns don't compare equal, we're done.
1:             // Return the sense of the comparison.
1:             if ((r = r1[colid].compare(r2[colid], nullsLow))
1:             != 0) {
1:                 if (this.columnOrderingAscendingMap[i])
1:                     return r;
1:                 else
1:                     return -r;
1:             } else {
1:                 if (r1[colid].isNull())
1:                     nonull = false;
1:             }
1:         }
1:         
1:         // We made it through all the columns, and they must have
1:         // all compared equal.  So return that the rows compare equal.
1:         return 0;
1:     }
1:     
1: }
============================================================================
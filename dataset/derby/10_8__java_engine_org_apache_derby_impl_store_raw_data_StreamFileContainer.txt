1:eac0369: /*
4:eac0369: 
1:345de35:    Derby - Class org.apache.derby.impl.store.raw.data.StreamFileContainer
1:345de35: 
1:270a34d:    Licensed to the Apache Software Foundation (ASF) under one or more
1:270a34d:    contributor license agreements.  See the NOTICE file distributed with
1:270a34d:    this work for additional information regarding copyright ownership.
1:270a34d:    The ASF licenses this file to you under the Apache License, Version 2.0
1:270a34d:    (the "License"); you may not use this file except in compliance with
1:270a34d:    the License.  You may obtain a copy of the License at
1:345de35: 
1:345de35:       http://www.apache.org/licenses/LICENSE-2.0
1:345de35: 
1:345de35:    Unless required by applicable law or agreed to in writing, software
1:345de35:    distributed under the License is distributed on an "AS IS" BASIS,
1:345de35:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:345de35:    See the License for the specific language governing permissions and
1:345de35:    limitations under the License.
1:345de35: 
2:eac0369:  */
1:eac0369: 
1:eac0369: package org.apache.derby.impl.store.raw.data;
1:eac0369: 
1:eac0369: import org.apache.derby.iapi.reference.SQLState;
1:eac0369: 
1:eac0369: import org.apache.derby.iapi.services.context.ContextService;
1:eac0369: 
1:7e51e9d: import org.apache.derby.shared.common.sanity.SanityManager;
1:eac0369: import org.apache.derby.iapi.services.io.Storable;
1:eac0369: import org.apache.derby.iapi.services.io.StreamStorable;
1:eac0369: import org.apache.derby.iapi.services.io.FormatIdInputStream;
1:eac0369: import org.apache.derby.iapi.services.io.FormatIdOutputStream;
1:eac0369: import org.apache.derby.iapi.services.io.StoredFormatIds;
1:eac0369: import org.apache.derby.iapi.services.io.TypedFormat;
1:eac0369: import org.apache.derby.iapi.services.monitor.Monitor;
1:eac0369: 
1:eac0369: import org.apache.derby.iapi.error.StandardException;
1:eac0369: import org.apache.derby.iapi.store.access.AccessFactory;
1:eac0369: import org.apache.derby.iapi.store.access.RowSource;
1:eac0369: import org.apache.derby.iapi.store.access.TransactionController;
1:eac0369: import org.apache.derby.iapi.store.raw.ContainerKey;
1:eac0369: import org.apache.derby.iapi.store.raw.RawStoreFactory;
1:eac0369: import org.apache.derby.iapi.store.raw.StreamContainerHandle;
1:eac0369: 
1:eac0369: import org.apache.derby.io.StorageFile;
1:eac0369: 
1:eac0369: import org.apache.derby.iapi.services.io.FormatableBitSet;
1:eac0369: import org.apache.derby.iapi.services.io.CompressedNumber;
1:eac0369: import org.apache.derby.iapi.services.io.DynamicByteArrayOutputStream;
1:eac0369: import org.apache.derby.iapi.services.io.LimitInputStream;
1:eac0369: import org.apache.derby.iapi.services.property.PropertyUtil;
1:eac0369: 
1:eac0369: import java.util.Properties;
1:eac0369: import java.io.InputStream;
1:eac0369: import java.io.BufferedInputStream;
1:eac0369: import java.io.OutputStream;
1:eac0369: import java.io.IOException;
1:eac0369: import java.io.EOFException;
1:eac0369: import java.io.InvalidClassException;
1:eac0369: import java.io.Externalizable;
1:a0dbbd7: import java.security.PrivilegedAction;
1:20445e3: import java.security.AccessController;
1:20445e3: import java.security.PrivilegedExceptionAction;
1:20445e3: import java.security.PrivilegedActionException;
1:20445e3: import java.io.FileNotFoundException;
1:eac0369: 
2:eac0369: /**
1:eac0369: 
1:eac0369:   The format of this stream file is:
1:eac0369:   (RH) (FH) (field data) (FH) (field data) ........ (FH) (field data)
1:eac0369: 
1:eac0369:   Record header is stored once at the beginning of the file
1:eac0369:   for all the rows stored in this file.
1:eac0369:   Record Header indicates how many fields are in each row.
1:eac0369:   Then we just stored all the column from each row.
1:eac0369:   Field header stored on this file is fixed size with fieldDataLength
1:eac0369:   size set to LARGE_SLOT_SIZE (4) bytes.
1:eac0369: 
1:eac0369:   NOTE: No locks are used in this container.  All transaction are not logged.
1:eac0369: 
1:eac0369: **/
1:eac0369: 
1:eac0369: 
1:93590df: class StreamFileContainer implements TypedFormat, PrivilegedExceptionAction<Object>
4:eac0369: {
1:eac0369: 
1:eac0369:     /**************************************************************************
1:eac0369:      * Constant Fields of the class
1:eac0369:      **************************************************************************
1:eac0369:      */
1:eac0369: 
1:eac0369: 	/*
1:eac0369: 	 * typed format
1:eac0369: 	 * format Id must fit in 4 bytes
1:eac0369: 	 */
1:eac0369: 	protected static int formatIdInteger = 
1:eac0369:         StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE; 
1:eac0369: 
1:eac0369: 
1:eac0369:     // 4 bytes for field data length
1:eac0369: 	protected static final int LARGE_SLOT_SIZE = 4;	
1:eac0369: 
1:eac0369: 	protected static final int MIN_BUFFER_SIZE = 
1:eac0369:         RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM;
1:eac0369: 	protected static final int FIELD_STATUS = 
1:eac0369:         StoredFieldHeader.setFixed(StoredFieldHeader.setInitial(), true);
1:eac0369: 	protected static final int FIELD_HEADER_SIZE = 
1:eac0369:         StoredFieldHeader.size(FIELD_STATUS, 0, LARGE_SLOT_SIZE);
1:eac0369: 
1:eac0369: 
1:eac0369:     /**************************************************************************
1:eac0369:      * Fields of the class
1:eac0369:      **************************************************************************
1:eac0369:      */
1:eac0369: 	protected   ContainerKey          identity;
1:eac0369: 	private   BaseDataFileFactory   dataFactory;  // the factory that made me
1:eac0369: 
1:eac0369: 	private int                             bufferSize;
1:eac0369: 
1:eac0369: 	private StorageFile file;
1:eac0369: 
1:eac0369: 	private OutputStream                fileOut;
1:eac0369: 	private DynamicByteArrayOutputStream    out;
1:eac0369: 	private FormatIdOutputStream            logicalDataOut;
1:eac0369: 
1:eac0369: 	private InputStream                 fileIn;
1:eac0369: 	private BufferedInputStream             bufferedIn;
1:eac0369: 	private DecryptInputStream              decryptIn;
1:eac0369: 	private LimitInputStream                limitIn;
1:eac0369: 	private FormatIdInputStream             logicalDataIn;
1:eac0369: 
1:eac0369: 	private StoredRecordHeader              recordHeader;
1:eac0369: 
1:eac0369: 	private byte[]                          ciphertext;
1:eac0369: 	private byte[]                          zeroBytes;	// in case encryption
1:eac0369:                                                         // stream needs pad.
1:20445e3: 
1:eac0369: 
1:20445e3:     /* privileged actions */
1:20445e3:     private static final int STORAGE_FILE_EXISTS_ACTION = 1;
1:20445e3:     private static final int STORAGE_FILE_DELETE_ACTION = 2;
1:20445e3:     private static final int STORAGE_FILE_MKDIRS_ACTION = 3;
1:20445e3:     private static final int STORAGE_FILE_GET_OUTPUT_STREAM_ACTION = 4;
1:20445e3:     private static final int STORAGE_FILE_GET_INPUT_STREAM_ACTION = 5;
1:20445e3:     private int actionCode;
1:20445e3:     private StorageFile actionStorageFile;
1:20445e3: 
1:20445e3: 
1:eac0369:     /**************************************************************************
1:eac0369:      * Constructors for This class:
1:eac0369:      **************************************************************************
1:eac0369:      */
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Constructor.
2:eac0369:      *
2:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	StreamFileContainer(
1:eac0369:     ContainerKey        identity, 
1:eac0369:     BaseDataFileFactory dataFactory)
1:eac0369:     {
1:eac0369: 		this.identity = identity;
1:eac0369: 		this.dataFactory = dataFactory;
4:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Constructor
1:eac0369:      * <p>
1:eac0369:      * when rowSource is passed to the constructor, it will be loaded into the 
1:eac0369:      * container after the container has been created.
1:eac0369:      * <p>
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	StreamFileContainer(
1:eac0369:     ContainerKey        identity, 
1:eac0369:     BaseDataFileFactory dataFactory,
1:eac0369:     Properties          prop)
2:eac0369: 		throws StandardException 
1:eac0369:     {
1:eac0369: 		this.identity       = identity;
1:eac0369: 		this.dataFactory    = dataFactory;
1:eac0369: 
1:eac0369: 		try 
1:eac0369:         {
1:eac0369: 			file = getFileName(identity, true, false);
1:eac0369: 
1:20445e3:             if (privExists(file)) 
1:eac0369:             {
1:eac0369: 				// note I'm left in the no-identity state as fillInIdentity()
1:eac0369:                 // hasn't been called.
1:eac0369: 				throw StandardException.newException(
1:eac0369:                         SQLState.FILE_EXISTS, file);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// get the properties to set buffer size
1:eac0369: 			// derby.storage.streamFileBufferSize
1:eac0369: 			getContainerProperties(prop);
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (SecurityException se) 
1:eac0369:         {
1:eac0369: 			throw StandardException.newException(
1:eac0369:                     SQLState.FILE_CREATE, se, file);
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**************************************************************************
1:eac0369:      * Private/Protected methods of This class:
1:eac0369:      **************************************************************************
1:eac0369:      */
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Open a stream file container.
1:eac0369:      * <p>
1:eac0369:      * Open a container. Open the file that maps to this container, if the
1:eac0369:      * file does not exist then we assume the container was never created
1:eac0369:      * and return.
1:eac0369:      * If the file exists but we have trouble opening it then we throw some 
1:eac0369:      * exception.
1:eac0369:      * <p>
1:eac0369:      *
1:eac0369: 	 * @return The opened StreamFileContainer.
1:eac0369:      *
1:eac0369:      * @param forUpdate     Currently only accepts false, updating and existing
1:eac0369:      *                      stream file container is not currently supported.
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	protected StreamFileContainer open(boolean forUpdate) 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 
1:eac0369: 		file = getFileName(this.identity, false, true);
1:20445e3:         if (!privExists(file))
1:eac0369: 			return null;
1:eac0369: 
1:eac0369: 		try 
1:a0dbbd7:         {
1:eac0369: 			if (!forUpdate) 
1:a0dbbd7:             {
1:20445e3: 				fileIn = privGetInputStream(file);
1:eac0369: 
1:eac0369: 				if (dataFactory.databaseEncrypted()) 
1:eac0369:                 {
1:eac0369: 					// if the database is encrypted, when reading the data back
1:eac0369:                     // from the file stream, we need to used the decrypt stream
1:eac0369:                     // to buffer up the bytes for reading.  DecryptInputStream 
1:eac0369:                     // also decrypts the data.
1:eac0369: 
1:eac0369: 					MemByteHolder byteHolder = 
1:eac0369:                         new MemByteHolder(
1:eac0369:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1:eac0369: 
1:eac0369: 					decryptIn = 
1:eac0369:                         new DecryptInputStream(fileIn, byteHolder, dataFactory);
1:eac0369: 
1:eac0369: 					limitIn = new LimitInputStream(decryptIn);
1:a0dbbd7: 				} 
1:a0dbbd7:                 else 
1:a0dbbd7:                 {
1:eac0369: 					bufferedIn = 
1:eac0369:                         new BufferedInputStream(
1:eac0369:                             fileIn, 
1:eac0369:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1:eac0369: 
1:eac0369: 					limitIn = new LimitInputStream(bufferedIn);
1:a0dbbd7: 				}
1:eac0369: 
1:eac0369: 				// the logicalDataIn input stream is on top of a limit Input
1:eac0369: 				// stream, use a limit stream to make sure we don't read off
1:eac0369: 				// more then what each column says it contains
1:eac0369: 
1:eac0369: 				logicalDataIn = new FormatIdInputStream(limitIn);
1:eac0369: 
1:eac0369: 				// get the record header
1:eac0369: 				recordHeader = new StoredRecordHeader();
1:eac0369: 				recordHeader.read(logicalDataIn);
1:eac0369: 
1:eac0369: 			} 
2:eac0369:             else 
1:eac0369:             {
1:eac0369: 				if (SanityManager.DEBUG)
1:eac0369: 					SanityManager.THROWASSERT(
1:eac0369:                         "updating existing stream container not supported yet");
1:eac0369: 
1:eac0369: 				return null;
1:eac0369: 			}
1:eac0369: 		} 
1:eac0369:         catch (IOException ioe) 
1:eac0369:         {
1:eac0369: 			throw StandardException.newException(
1:eac0369:                     SQLState.FILE_CREATE, ioe, file);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return this;
1:eac0369: 	}
1:eac0369: 
1:a0dbbd7:     /**
1:eac0369:      * Close the stream file.
1:eac0369:      * <p>
1:eac0369:      * Close this stream file, and all streams associated with it.
1:eac0369:      * <p>
1:eac0369:      **/
1:eac0369: 	protected void close()
1:eac0369:     {
1:eac0369: 		try 
1:eac0369:         {
1:eac0369: 
1:eac0369: 			if (fileIn != null) 
1:eac0369:             {
1:eac0369: 				fileIn.close();
1:eac0369: 				fileIn = null;
1:eac0369: 				if (dataFactory.databaseEncrypted()) 
1:eac0369:                 {
1:eac0369: 					decryptIn.close();
1:eac0369: 					decryptIn = null;
1:eac0369: 				} 
1:eac0369:                 else 
1:eac0369:                 {
1:eac0369: 					bufferedIn.close();
1:eac0369: 					bufferedIn = null;
1:eac0369: 				}
1:eac0369: 				logicalDataIn.close();
1:eac0369: 				logicalDataIn = null;
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			if (fileOut != null) 
1:eac0369:             {
1:eac0369: 				fileOut.close();
1:eac0369: 				logicalDataOut.close();
1:eac0369: 				fileOut = null;
1:eac0369: 				logicalDataOut = null;
1:eac0369: 				out = null;
1:eac0369: 			}
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (IOException ioe) 
1:eac0369:         {
1:eac0369:             // ignore close errors from fileOut.close() and fileIn.close() - 
1:eac0369:             // there isn't much we can do about them anyway - and some of the
1:eac0369:             // interfaces don't want to deal with exceptions from close().
1:eac0369: 
1:eac0369:             /*
1:eac0369: 			throw StandardException.newException(
1:eac0369:                     SQLState.FILE_CREATE, ioe, file);
1:eac0369:             */
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**************************************************************************
1:eac0369:      * Public Methods of This class:
1:eac0369:      **************************************************************************
1:eac0369:      */
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Return my format identifier.
1:eac0369:      **/
1:eac0369: 	public int getTypeFormatId() 
1:eac0369:     {
1:eac0369: 		return StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE;
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Request the system properties associated with a stream container. 
1:eac0369:      * <p>
1:eac0369:      * Request the value of properties associated with a stream container. 
1:eac0369:      * The following properties can be requested:
1:eac0369:      *     derby.storage.streamFileBufferSize
1:eac0369: 	 *
1:eac0369:      * <p>
1:eac0369:      * To get the value of a particular property add it to the property list,
1:eac0369:      * and on return the value of the property will be set to it's current 
1:eac0369:      * value.  For example:
1:eac0369:      *
1:eac0369:      * get_prop(ConglomerateController cc)
1:eac0369:      * {
1:eac0369:      *     Properties prop = new Properties();
1:eac0369:      *     prop.put("derby.storage.streamFileBufferSize", "");
1:eac0369:      *     cc.getContainerProperties(prop);
1:eac0369:      *
1:eac0369:      *     System.out.println(
1:eac0369:      *         "stream table's buffer size = " + 
1:eac0369:      *         prop.getProperty("derby.storage.streamFileBufferSize");
1:eac0369:      * }
1:eac0369:      *
1:eac0369:      * @param prop   Property list to fill in.
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369:     public void getContainerProperties(Properties prop) 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 
1:eac0369: 		AccessFactory af = (AccessFactory)
1:56c1dc2: 			getServiceModule(dataFactory, AccessFactory.MODULE);
1:eac0369: 
1:eac0369: 		TransactionController tc = 
1:eac0369:             (af == null) ? 
1:eac0369:                 null : 
1:eac0369:                 af.getTransaction(
1:a0dbbd7:                     getContextService().getCurrentContextManager());
1:eac0369: 
1:eac0369: 		bufferSize = 
1:eac0369: 			PropertyUtil.getServiceInt(tc, prop,
1:eac0369: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_PARAMETER,  
1:eac0369: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM, 
1:eac0369: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MAXIMUM,
1:eac0369: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Request the container key associated with the stream container. 
1:eac0369: 	 **/
1:eac0369: 	public ContainerKey getIdentity() 
1:eac0369:     {
1:eac0369: 		return this.identity;
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Can I use this container?
1:eac0369:      * <p>
1:eac0369:      * This method always return true right now.
1:eac0369:      * In the future when there are different uses for this container,
1:eac0369:      * we may need to add qualifications for this.
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	protected boolean use(StreamContainerHandle handle) 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 		return true;
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * load data into this container.
1:eac0369:      * <p>
1:eac0369:      * populate the stream container with data in the rowSource
1:eac0369:      * <p>
1:eac0369:      *
1:eac0369:      * @param rowSource The row source to get rows to load into this container.
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	public void load(RowSource rowSource) 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 		// use this output stream to buffer rows before inserting into file.
1:eac0369: 		out                 = new DynamicByteArrayOutputStream(bufferSize);
1:eac0369: 		logicalDataOut      = new FormatIdOutputStream(out);
1:eac0369: 		boolean encrypted   = dataFactory.databaseEncrypted();
1:eac0369: 
1:eac0369: 		// reserve the first dataFactory.getEncryptionBlockSize() - 1 bytes, if the database is 
1:eac0369:         // encrypted These reserved bytes will be used to pad the byte array if
1:eac0369:         // it is not dataFactory.getEncryptionBlockSize() aligned.
1:eac0369: 		if (encrypted) 
1:eac0369:         {
1:eac0369: 			if (zeroBytes == null)
1:eac0369: 				zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
1:eac0369: 
1:eac0369: 			out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		try 
1:eac0369:         {
1:20445e3: 			fileOut = privGetOutputStream(file);
1:eac0369: 
1:eac0369: 			FormatableBitSet validColumns = rowSource.getValidColumns();
1:eac0369: 
1:eac0369: 			Object[] row = rowSource.getNextRowFromRowSource();
1:eac0369: 
1:eac0369: 			int numberFields = 0;
1:eac0369: 			if (validColumns != null) 
1:eac0369:             {
1:eac0369: 				for (int i = validColumns.getLength() - 1; i >= 0; i--) 
1:eac0369:                 {
1:eac0369: 					if (validColumns.isSet(i)) 
1:eac0369:                     {
1:eac0369: 						numberFields = i + 1;
1:eac0369: 						break;
1:eac0369: 					}
1:eac0369: 				}
1:eac0369: 			} 
1:eac0369:             else 
1:eac0369:             {
1:eac0369: 				numberFields = row.length;
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// make the record header to have 0 record id
1:eac0369: 			recordHeader = new StoredRecordHeader(0, numberFields);
1:eac0369: 
1:eac0369: 			// write the record header once for all the rows, directly to the 
1:eac0369:             // beginning of the file.
1:eac0369: 			int rhLen = recordHeader.write(out);
1:eac0369: 
1:eac0369: 			int validColumnsSize = 
1:eac0369:                 validColumns == null ? 0 : validColumns.getLength();
1:eac0369: 
1:eac0369: 			while (row != null) 
1:eac0369:             {
1:eac0369: 
1:eac0369: 				int arrayPosition = -1;
1:eac0369: 
1:eac0369: 				for (int i = 0; i < numberFields; i++) 
1:eac0369:                 {
1:eac0369: 
1:eac0369: 					// write each column out
1:eac0369: 					if (validColumns == null) 
1:eac0369:                     {
1:eac0369: 						arrayPosition++;
1:eac0369: 						Object column = row[arrayPosition];
1:eac0369: 						writeColumn(column);
1:eac0369: 					} 
1:eac0369:                     else 
1:eac0369:                     {
1:eac0369: 
1:eac0369: 						if (validColumnsSize > i && validColumns.isSet(i)) 
1:eac0369:                         {
1:eac0369: 							arrayPosition++;
1:eac0369: 							Object column = row[arrayPosition];
1:eac0369: 							writeColumn(column);
1:eac0369: 						} 
1:eac0369:                         else 
1:eac0369:                         {
1:eac0369: 							// it is a non-existent column
1:eac0369: 							writeColumn(null);
1:eac0369: 						}
1:eac0369: 					}
1:eac0369: 
1:eac0369: 					// put the buffer onto the page, only if it exceeded the 
1:eac0369:                     // original buffer size or it has less than 100 bytes left 
1:eac0369:                     // in the buffer
1:eac0369: 					if ((out.getUsed() >= bufferSize) || 
1:eac0369:                         ((bufferSize - out.getUsed()) < MIN_BUFFER_SIZE)) 
1:eac0369:                     {
1:eac0369: 						writeToFile();
1:eac0369: 					}
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// get the next row and its valid columns from the rowSource
1:eac0369: 				row = rowSource.getNextRowFromRowSource();
1:eac0369: 			}
1:eac0369: 
1:eac0369: 
1:eac0369: 			// Write the buffer to the file if there is something in the output
1:eac0369: 			// buffer.  Remember we pad the output buffer with
1:eac0369: 			// dataFactory.getEncryptionBlockSize() - 1 if this is an encypted database
1:eac0369: 			if (encrypted)
1:eac0369: 			{
1:eac0369: 				if (out.getUsed() > (dataFactory.getEncryptionBlockSize() - 1))
1:eac0369: 					writeToFile();
1:eac0369: 			}
1:eac0369: 			else if (out.getUsed() > 0) 
1:eac0369:             {
1:eac0369: 				writeToFile();
1:eac0369: 			}
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (IOException ioe) 
1:eac0369:         {
1:eac0369: 			// handle IO error...
1:eac0369: 			throw StandardException.newException(
1:eac0369:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
1:eac0369: 
1:eac0369: 		}
1:eac0369:         finally 
1:eac0369:         {
1:eac0369: 			close();
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	/*
1:eac0369: 
1:eac0369: 	 */
1:eac0369:     /**
1:eac0369:      * Write the buffer to the file.
1:eac0369:      * <p>
1:eac0369:      * If the database is encrypted, the dataFactory.getEncryptionBlockSize() - 1 reserved bytes will
1:eac0369:      * be used to pad the byte array to be dataFactory.getEncryptionBlockSize()
1:eac0369:      * aligned.  Before the bytes are encrypted and written to the file stream,
1:eac0369:      * the actual length of the byte array is written out as a compressed 
1:eac0369:      * integer.  This number will be used when decrypting the data.
1:eac0369:      *
1:eac0369:      * If the database is not encrypted, then, we don't reserve the bytes 
1:eac0369:      * upfront, and we simple just write the bytes out to the file stream.
1:eac0369:      *
1:eac0369: 	 * @exception  StandardException  Standard exception policy.
1:eac0369:      **/
1:eac0369: 	private void writeToFile() 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 
1:eac0369: 		try
1:eac0369:         {
1:eac0369: 			if (dataFactory.databaseEncrypted()) 
1:eac0369:             {
1:eac0369: 				// if db is encrypted, 
1:eac0369:                 // use the first ENCRYPTION_ALIGN bytes for padding.
1:eac0369:                 //
1:eac0369: 				int realLen = out.getUsed() - (dataFactory.getEncryptionBlockSize() - 1);
1:eac0369: 				int tail = realLen % dataFactory.getEncryptionBlockSize();
1:eac0369: 				int padding = 
1:eac0369:                     (tail == 0) ? 0 : 
1:eac0369:                     (dataFactory.getEncryptionBlockSize() - tail);
1:eac0369: 
1:eac0369: 				int startByte = (tail == 0) ? (dataFactory.getEncryptionBlockSize() - 1) : (tail - 1);
1:eac0369: 				int encryptedLen = realLen + padding;
1:eac0369: 
1:eac0369: 				// there is nothing to write, just the encryption padding
1:eac0369: 				if (realLen <= 0)
1:eac0369: 					return;
1:eac0369: 
1:eac0369: 				if (ciphertext == null)
1:eac0369:                 {
1:eac0369: 					ciphertext = new byte[encryptedLen];
1:eac0369:                 }
1:eac0369: 				else 
1:eac0369:                 {
1:eac0369: 					if (ciphertext.length < encryptedLen)
1:eac0369: 						ciphertext = new byte[encryptedLen];
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				dataFactory.encrypt(
1:ae71c74:                     out.getByteArray(), startByte, encryptedLen, ciphertext, 0, false);
1:eac0369: 
1:eac0369: 				// write out the actual length, then the encrypted bytes.
1:eac0369: 				CompressedNumber.writeInt(fileOut, realLen);
1:eac0369: 				dataFactory.writeInProgress();
1:eac0369: 				try
1:eac0369: 				{
1:eac0369: 					fileOut.write(ciphertext, 0, encryptedLen);
1:eac0369: 				}
1:eac0369: 				finally
1:eac0369: 				{
1:eac0369: 					dataFactory.writeFinished();
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// reset the dynamic buffer
1:eac0369: 				out.reset();
1:eac0369: 
1:eac0369: 				// reserve bytes if database is encrypted.
1:eac0369: 				if (dataFactory.databaseEncrypted())
1:eac0369:                 {
1:eac0369: 					if (zeroBytes == null)
1:eac0369: 						zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
1:eac0369: 
1:eac0369: 					out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
1:eac0369: 				}
1:eac0369: 
1:eac0369: 			} 
1:eac0369:             else 
1:eac0369:             {
1:eac0369: 				// nothing to write
1:eac0369: 				if (out.getUsed() == 0)
1:eac0369: 					return;
1:eac0369: 
1:eac0369: 				dataFactory.writeInProgress();
1:eac0369: 				try
1:eac0369: 				{
1:eac0369: 					fileOut.write(out.getByteArray(), 0, out.getUsed());
1:eac0369: 				}
1:eac0369: 				finally
1:eac0369: 				{
1:eac0369: 					dataFactory.writeFinished();
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// reset the dynamic buffer
1:eac0369: 				out.reset();
1:eac0369: 			}
1:eac0369: 		} 
1:eac0369:         catch (IOException ioe) 
1:eac0369:         {
1:eac0369: 			throw StandardException.newException(
1:eac0369:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
1:eac0369: 		}
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	private void writeColumn(Object column) 
1:eac0369:         throws StandardException, IOException 
1:eac0369:     {
1:eac0369: 
1:eac0369: 		int fieldStatus = FIELD_STATUS;
1:eac0369: 		if (column == null) 
1:eac0369:         {
1:eac0369: 			// just write a non-existent header.
1:eac0369: 			fieldStatus = StoredFieldHeader.setNonexistent(fieldStatus);
1:eac0369: 			StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
1:eac0369: 			return;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// if the column is a null column, write the field header now.
1:eac0369: 		if (column instanceof Storable) 
1:eac0369:         {
1:eac0369: 			Storable sColumn = (Storable) column;
1:eac0369: 			if (sColumn.isNull()) 
1:eac0369:             {
1:eac0369: 				fieldStatus = StoredFieldHeader.setNull(fieldStatus, true);
1:eac0369: 				StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
1:eac0369: 				return;
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		int beginPosition = out.getPosition();
1:eac0369: 		int fieldDataLength = 0;
1:eac0369: 
1:eac0369: 		// write out the header, mostly to reserve the space
1:eac0369: 		StoredFieldHeader.write(
1:eac0369:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
1:eac0369: 
1:eac0369: 		if (column instanceof StreamStorable) 
1:eac0369:         {
1:eac0369: 			if (((StreamStorable) column).returnStream() != null) 
1:eac0369:             {
1:eac0369: 				column = (InputStream) ((StreamStorable) column).returnStream();
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		if (column instanceof InputStream) 
1:eac0369:         {
1:eac0369: 			InputStream inColumn = (InputStream) column;
1:1d0c179:             // Set a reasonable buffer size.
1:1d0c179:             // To avoid extremely inefficient reads, and an infinite loop when
1:1d0c179:             // InputStream.available() returns zero, a lower limit is set on
1:1d0c179:             // the buffer size. To avoid using too much memory (especially in
1:1d0c179:             // multi-user environments) an upper limit is set as well.
1:1d0c179:             // The limits can be tuned, but note that using a too high default
1:1d0c179:             // or lower limit can put unnecessary pressure on the memory sub-
1:1d0c179:             // system and the GC process.
1:1d0c179:             int bufferLen = Math.min(Math.max(inColumn.available(), 64), 8192);
1:eac0369: 			byte[] bufData = new byte[bufferLen];
1:eac0369: 
1:eac0369: 			do 
1:eac0369:             {
1:1d0c179:                 int lenRead = inColumn.read(bufData);
1:eac0369: 				if (lenRead != -1) 
1:eac0369:                 {
1:eac0369: 					fieldDataLength += lenRead;
1:1d0c179:                     out.write(bufData, 0, lenRead);
1:eac0369: 				} 
1:eac0369:                 else
1:eac0369:                 {
1:eac0369: 					break; 
1:eac0369:                 }
1:eac0369: 			} while (true);
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         else if (column instanceof Storable) 
1:eac0369:         {
1:eac0369: 
1:eac0369: 			Storable sColumn = (Storable) column;
1:eac0369: 			// write field data to the stream, we already handled the null case
1:eac0369:             
1:eac0369: 			sColumn.writeExternal(logicalDataOut);
1:eac0369: 			fieldDataLength = 
1:eac0369:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         else 
1:eac0369:         {
1:eac0369: 			// Serializable/Externalizable/Formattable
1:eac0369: 			// all look the same at this point.
1:eac0369: 			logicalDataOut.writeObject(column);
1:eac0369: 			fieldDataLength = 
1:eac0369:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		// Now we go back to update the fieldDataLength in the field header
1:eac0369: 		int endPosition = out.getPosition();
1:eac0369: 		out.setPosition(beginPosition);
1:eac0369: 
1:eac0369: 		StoredFieldHeader.write(
1:eac0369:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
1:eac0369: 
1:eac0369: 		// set position to the end of the field
1:eac0369: 		if (!StoredFieldHeader.isNull(fieldStatus))
1:eac0369: 			out.setPosition(endPosition);
1:eac0369: 	}
1:eac0369: 
1:eac0369: 	public boolean fetchNext(Object[] row) 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 
1:eac0369: 		boolean inUserCode = false;
1:eac0369: 		int columnId = 0;
1:eac0369: 		
1:eac0369: 		try	
1:eac0369:         {
1:eac0369: 
1:eac0369: 			// Get the number of columns in the row.
1:eac0369: 			int numberFields = recordHeader.getNumberFields();
1:eac0369: 
1:eac0369: 			int arrayPosition = 0;
1:eac0369: 			for (columnId = 0; columnId < numberFields; columnId++) 
1:eac0369:             {
1:eac0369: 
1:eac0369: 				if (arrayPosition >= row.length)
1:eac0369: 					break;
1:eac0369: 	
1:eac0369: 				limitIn.clearLimit();
1:eac0369: 
1:eac0369: 				// read the field header
1:eac0369: 				int fieldStatus = StoredFieldHeader.readStatus(logicalDataIn);
1:eac0369: 				int fieldDataLength = StoredFieldHeader.readFieldDataLength(
1:eac0369: 					logicalDataIn, fieldStatus, LARGE_SLOT_SIZE);
1:eac0369: 
1:eac0369: 				limitIn.setLimit(fieldDataLength);
1:eac0369: 
1:eac0369: 				if (SanityManager.DEBUG) 
1:eac0369:                 {
1:eac0369: 
1:eac0369:                     if (StoredFieldHeader.isExtensible(fieldStatus))
1:eac0369:                     {
1:eac0369:                         SanityManager.THROWASSERT(
1:eac0369:                             "extensible fields not supported yet.  columnId = "
1:eac0369:                             + columnId);
1:eac0369:                     }
1:eac0369: 
1:eac0369: 					SanityManager.ASSERT(!StoredFieldHeader.isOverflow(fieldStatus),
1:eac0369: 						"overflow field is not supported yet");
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				Object column = row[arrayPosition];
1:eac0369: 				
1:eac0369: 				// Deal with Storable columns
1:eac0369: 				if (StoredFieldHeader.isNullable(fieldStatus)) 
1:eac0369:                 {
1:eac0369: 									
1:eac0369: 					if (column == null)
1:eac0369:                     {
1:eac0369: 						throw StandardException.newException(
1:eac0369:                                 SQLState.DATA_NULL_STORABLE_COLUMN, 
1:eac0369:                                 Integer.toString(columnId));
1:eac0369:                     }
1:eac0369: 
1:eac0369: 					// SRW-DJD RESOLVE: - fix error message
1:eac0369: 					if (!(column instanceof Storable)) 
1:eac0369:                     {
1:eac0369: 						throw StandardException.newException(
1:eac0369:                             SQLState.DATA_NULL_STORABLE_COLUMN, 
1:eac0369:                             column.getClass().getName());
1:eac0369: 					}
1:eac0369: 
1:eac0369: 					Storable sColumn = (Storable) column;
1:eac0369: 
1:eac0369: 					// is the column null ?
1:eac0369: 					if (StoredFieldHeader.isNull(fieldStatus)) 
1:eac0369:                     {
1:eac0369: 
1:eac0369: 						sColumn.restoreToNull();
1:eac0369: 						arrayPosition++;
1:eac0369: 						continue;
1:eac0369: 					}
1:eac0369: 
1:eac0369: 					inUserCode = true;
1:eac0369: 					sColumn.readExternal(logicalDataIn);
1:eac0369: 					inUserCode = false;
1:eac0369: 					arrayPosition++;
1:eac0369: 					continue;
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// Only Storables can be null ... SRW-DJD RESOLVE: - fix error message
1:eac0369: 				if (StoredFieldHeader.isNull(fieldStatus))
1:eac0369:                 {
1:eac0369: 					throw StandardException.newException(
1:eac0369:                         SQLState.DATA_NULL_STORABLE_COLUMN, 
1:eac0369:                         Integer.toString(columnId));
1:eac0369:                 }
1:eac0369: 
1:eac0369: 				// This is a non-extensible field, which means the caller must 
1:eac0369:                 // know the correct type and thus the element in row is the 
1:eac0369:                 // correct type or null. If the element implements 
1:eac0369:                 // Externalizable then we can just fill it in, otherwise it 
1:eac0369:                 // must be Serializable and we have to throw it away.
1:eac0369: 
1:eac0369: 				Object neColumn = row[arrayPosition];
1:eac0369: 
1:eac0369: 				if (neColumn instanceof Externalizable) 
1:eac0369:                 {
1:eac0369: 
1:eac0369: 					Externalizable exColumn = (Externalizable) neColumn;
1:eac0369: 
1:eac0369: 					inUserCode = true;
1:eac0369: 					exColumn.readExternal(logicalDataIn);
1:eac0369: 					inUserCode = false;
1:eac0369: 
1:eac0369: 					arrayPosition++;
1:eac0369: 					continue;
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				// neColumn will be ignored
1:eac0369: 				neColumn = null;
1:eac0369: 				inUserCode = true;
1:eac0369: 				row[arrayPosition] = logicalDataIn.readObject();
1:eac0369: 				inUserCode = false;
1:eac0369: 
1:eac0369: 				arrayPosition++;
1:eac0369: 				continue;
1:eac0369: 			}
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (IOException ioe) 
1:eac0369:         {
1:eac0369: 
1:eac0369: 			// an exception during the restore of a user column, this doesn't
1:c6892a1: 			// make the database corrupt, just that this field is inaccessable
1:eac0369: 			if (inUserCode) 
1:eac0369:             { 
1:eac0369: 
1:eac0369: 				if (ioe instanceof EOFException) 
1:eac0369:                 {
1:eac0369: 					throw StandardException.newException(
1:eac0369:                         SQLState.DATA_STORABLE_READ_MISMATCH, 
1:eac0369:                         ioe, logicalDataIn.getErrorInfo());
1:eac0369: 				}
1:eac0369: 
1:eac0369: 				throw StandardException.newException(
1:eac0369:                     SQLState.DATA_STORABLE_READ_EXCEPTION, 
1:eac0369:                     ioe, logicalDataIn.getErrorInfo());
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			if (ioe instanceof InvalidClassException)
1:eac0369:             {
1:eac0369: 				throw StandardException.newException(
1:eac0369:                         SQLState.DATA_STORABLE_READ_EXCEPTION, 
1:eac0369:                         ioe, logicalDataIn.getErrorInfo());
1:eac0369:    			}
1:eac0369: 
1:eac0369: 			// If we are at the end of the file, trying to fetch the first 
1:eac0369:             // column, then we know there is no more rows to fetch
1:eac0369: 			if ((ioe instanceof EOFException) && (columnId == 0)) 
1:eac0369:             {
1:eac0369: 				close();
1:20445e3: 				return false;
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			throw dataFactory.markCorrupt(
1:eac0369:                 StandardException.newException(
1:eac0369:                     SQLState.DATA_CORRUPT_STREAM_CONTAINER, ioe, identity));
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (ClassNotFoundException cnfe) 
1:20445e3:         {
1:eac0369: 
1:eac0369: 			if (SanityManager.DEBUG) 
1:eac0369:             {
1:eac0369: 				SanityManager.ASSERT(inUserCode);
1:eac0369: 			}
1:eac0369: 
1:eac0369: 			// an exception during the restore of a user column, this doesn't
1:c6892a1: 			// make the database corrupt, just that this field is inaccessable
1:eac0369: 			throw StandardException.newException(
1:eac0369:                 SQLState.DATA_STORABLE_READ_MISSING_CLASS, cnfe, 
1:eac0369:                 logicalDataIn.getErrorInfo());
1:eac0369: 
1:eac0369: 		} 
1:eac0369:         catch (LinkageError le) 
1:eac0369:         {
1:eac0369: 			if (inUserCode)
1:eac0369:             {
1:eac0369: 				throw StandardException.newException(
1:eac0369:                     SQLState.DATA_STORABLE_READ_EXCEPTION, le,
1:eac0369:                     logicalDataIn.getErrorInfo());
1:eac0369:             }
1:eac0369: 			throw le;
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return true;
1:eac0369: 
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Close the stream file and remove the file.
1:eac0369:      *
1:eac0369:      * @exception StandardException Segment directory cannot be created
1:eac0369:      **/
1:eac0369: 	public boolean removeContainer() 
1:eac0369:         throws StandardException 
1:eac0369:     {
1:eac0369: 		close();
1:eac0369: 
1:20445e3:         if (privExists(file))
1:eac0369:         {
1:20445e3:             return privDelete(file);
1:eac0369:         }
1:eac0369:         else
1:eac0369:         {
1:eac0369:             return true;
1:eac0369:         }
1:eac0369: 
1:eac0369: 
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:eac0369:      * Return a file name for the identity.
1:eac0369:      * <p>
1:eac0369:      * Return a valid file name for the identity, or null if the data
1:eac0369:      * directory for this segment cannot be created
1:eac0369:      *
1:eac0369: 	 * @exception StandardException Segment directory cannot be created
1:eac0369:      **/
1:eac0369: 	protected StorageFile getFileName(
1:eac0369:     ContainerKey    identity, 
1:eac0369:     boolean         forCreate, 
1:eac0369:     boolean         errorOK)
1:eac0369: 		 throws StandardException 
1:eac0369:     {
1:eac0369: 		if (identity.getSegmentId() == StreamContainerHandle.TEMPORARY_SEGMENT)
1:eac0369:         {
1:eac0369: 			return( dataFactory.storageFactory.newStorageFile( dataFactory.storageFactory.getTempDir(), 
1:eac0369:                     "T" + identity.getContainerId() + ".tmp"));
1:eac0369:         }
1:eac0369: 		else 
1:eac0369:         {
1:eac0369: 			if (SanityManager.DEBUG)
1:eac0369: 				SanityManager.THROWASSERT(
1:eac0369:                     "cannot create stream container in non-temp segments yet.");
1:eac0369: 
1:eac0369: 			StorageFile container = dataFactory.getContainerPath( identity, false);
1:eac0369: 
1:20445e3: 			if (!privExists(container)) 
1:eac0369:             {
1:eac0369: 
1:eac0369: 				if (!forCreate)
1:eac0369: 					return null;
1:eac0369: 
1:eac0369: 				StorageFile directory = container.getParentDir();
1:eac0369: 
1:20445e3: 				if (!privExists(directory)) 
1:eac0369:                 {
1:eac0369: 					// make sure only 1 thread can create a segment at one time
1:eac0369: 					synchronized(dataFactory) 
1:eac0369:                     {
1:20445e3: 						if (!privExists(directory)) 
1:eac0369:                         {
1:4f7eee8:                             boolean created = false;
1:4f7eee8:                             IOException ex = null;
1:4f7eee8:                             try {
1:4f7eee8:                                 created = privMkdirs(directory);
1:4f7eee8:                             } catch (IOException ioe) {
1:4f7eee8:                                 ex = ioe;
1:4f7eee8:                             }
1:4f7eee8: 
1:4f7eee8:                             if (!created)
1:eac0369:                             {
1:eac0369: 								if (errorOK)
1:eac0369: 									return null;
1:eac0369: 								else
1:eac0369: 									throw StandardException.newException(
1:eac0369:                                             SQLState.FILE_CANNOT_CREATE_SEGMENT,
1:4f7eee8:                                             ex, directory);
1:eac0369: 							}
1:eac0369: 						}
1:eac0369: 					}
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 			return container;
1:eac0369: 		}
1:eac0369: 	}
1:20445e3: 
1:20445e3: 
1:20445e3: 
1:20445e3:     
1:20445e3:     private synchronized boolean privExists(StorageFile file)
1:20445e3:     {
1:20445e3:         actionCode = STORAGE_FILE_EXISTS_ACTION;
1:20445e3:         actionStorageFile = file;
1:20445e3: 
1:20445e3:         try
1:20445e3:         {
1:20445e3:             Object ret = AccessController.doPrivileged( this);
1:20445e3:             return ((Boolean) ret).booleanValue();
1:20445e3:         }catch( PrivilegedActionException pae) 
1:20445e3:         { 
1:20445e3:             // method executed under this priveleged block 
2:20445e3:             // does not throw an exception
1:20445e3:             return false;
1:20445e3:         } 
1:20445e3:         finally
1:20445e3:         {
1:20445e3:             actionStorageFile = null;
1:20445e3:         }
1:20445e3:     }
1:20445e3: 
1:20445e3:     private synchronized boolean privMkdirs(StorageFile file)
1:4f7eee8:             throws IOException
1:20445e3:     {
1:20445e3:         actionCode = STORAGE_FILE_MKDIRS_ACTION;
1:20445e3:         actionStorageFile = file;
1:20445e3: 
1:20445e3:         try
1:20445e3:         {
1:20445e3:             Object ret = AccessController.doPrivileged( this);
1:20445e3:             return ((Boolean) ret).booleanValue();
1:20445e3:         }catch( PrivilegedActionException pae) 
1:20445e3:         {
1:20445e3:             // method executed under this priveleged block 
1:4f7eee8:             // could throw IOException
1:4f7eee8:             throw (IOException) pae.getCause();
1:20445e3:         } 
1:20445e3:         finally
1:20445e3:         {
1:20445e3:             actionStorageFile = null;
1:20445e3:         }
1:20445e3:     }
1:20445e3: 
1:20445e3:     
1:20445e3:     private synchronized boolean privDelete(StorageFile file)
1:20445e3:     {
1:20445e3:         actionCode = STORAGE_FILE_DELETE_ACTION;
1:20445e3:         actionStorageFile = file;
1:20445e3: 
1:20445e3:         try
1:20445e3:         {
1:20445e3:             Object ret = AccessController.doPrivileged( this);
1:20445e3:             return ((Boolean) ret).booleanValue();
1:20445e3:         }catch( PrivilegedActionException pae) 
1:20445e3:         { 
1:20445e3:             // method executed under this priveleged block 
1:20445e3:             // does not throw an exception
1:20445e3:             return false;
1:20445e3:         } 
1:20445e3:         finally
1:20445e3:         {
1:20445e3:             actionStorageFile = null;
1:20445e3:         }
1:20445e3:     }
1:20445e3: 
1:20445e3:     private synchronized OutputStream privGetOutputStream(StorageFile file)
1:20445e3:         throws FileNotFoundException
1:20445e3:     {
1:20445e3:         actionCode = STORAGE_FILE_GET_OUTPUT_STREAM_ACTION;
1:20445e3:         actionStorageFile = file;
1:20445e3: 
1:20445e3:         try
1:20445e3:         {
1:20445e3:             return (OutputStream) AccessController.doPrivileged( this);
1:20445e3:         }catch( PrivilegedActionException pae) 
1:20445e3:         { 
1:20445e3:             throw (FileNotFoundException)pae.getException();
1:20445e3:         } 
1:20445e3:         finally
1:20445e3:         {
1:20445e3:             actionStorageFile = null;
1:20445e3:         }
1:20445e3:     }
1:20445e3: 
1:20445e3: 
1:20445e3:     private synchronized InputStream privGetInputStream(StorageFile file)
1:20445e3:         throws FileNotFoundException
1:20445e3:     {
1:20445e3:         actionCode = STORAGE_FILE_GET_INPUT_STREAM_ACTION;
1:20445e3:         actionStorageFile = file;
1:20445e3: 
1:20445e3:         try
1:20445e3:         {
1:20445e3:             return (InputStream) AccessController.doPrivileged( this);
1:20445e3:         }catch( PrivilegedActionException pae) 
1:20445e3:         { 
1:20445e3:             throw (FileNotFoundException)pae.getException();
1:20445e3:         } 
1:20445e3:         finally
1:eac0369:         {
1:20445e3:             actionStorageFile = null;
1:20445e3:         }
1:20445e3:     }
1:20445e3: 
1:20445e3: 
1:20445e3:     // PrivilegedAction method
1:4f7eee8:     public Object run() throws IOException
1:20445e3:     {
1:20445e3:         switch(actionCode)
1:20445e3:         {
1:20445e3:         case STORAGE_FILE_EXISTS_ACTION:
1:bb5be6f:             return actionStorageFile.exists();
1:20445e3:         case STORAGE_FILE_DELETE_ACTION:
1:bb5be6f:             return actionStorageFile.delete();
1:20445e3:         case STORAGE_FILE_MKDIRS_ACTION:
1:dc43cf8:             boolean created = actionStorageFile.mkdirs();
1:dc43cf8:             actionStorageFile.limitAccessToOwner();
1:bb5be6f:             return created;
1:20445e3:         case STORAGE_FILE_GET_OUTPUT_STREAM_ACTION:
1:20445e3:             return actionStorageFile.getOutputStream();
1:20445e3:         case STORAGE_FILE_GET_INPUT_STREAM_ACTION:
1:20445e3:             return actionStorageFile.getInputStream();
1:20445e3:         }
1:20445e3: 
1:20445e3:         return null;
1:20445e3:     }
1:20445e3: 
1:eac0369:     /**
1:a0dbbd7:      * Privileged lookup of the ContextService. Must be private so that user code
1:a0dbbd7:      * can't call this entry point.
1:a0dbbd7:      */
1:a0dbbd7:     private  static  ContextService    getContextService()
1:a0dbbd7:     {
1:56c1dc2:         return AccessController.doPrivileged
1:56c1dc2:             (
1:56c1dc2:              new PrivilegedAction<ContextService>()
1:56c1dc2:              {
1:56c1dc2:                  public ContextService run()
1:a0dbbd7:                  {
1:56c1dc2:                      return ContextService.getFactory();
1:56c1dc2:                  }
1:a0dbbd7:              }
1:56c1dc2:              );
1:56c1dc2:     }
1:56c1dc2: 
1:56c1dc2:     /**
1:56c1dc2:      * Privileged module lookup. Must be private so that user code
1:56c1dc2:      * can't call this entry point.
1:56c1dc2:      */
1:56c1dc2:     private static  Object getServiceModule( final Object serviceModule, final String factoryInterface )
1:56c1dc2:     {
1:56c1dc2:         return AccessController.doPrivileged
1:56c1dc2:             (
1:56c1dc2:              new PrivilegedAction<Object>()
1:56c1dc2:              {
1:56c1dc2:                  public Object run()
1:56c1dc2:                  {
1:56c1dc2:                      return Monitor.getServiceModule( serviceModule, factoryInterface );
1:56c1dc2:                  }
1:56c1dc2:              }
1:56c1dc2:              );
1:a0dbbd7:     }
1:a0dbbd7: 
1:a0dbbd7: }
============================================================================
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:bb5be6f
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             return actionStorageFile.exists();
1:             return actionStorageFile.delete();
1:             return created;
commit:4f7eee8
/////////////////////////////////////////////////////////////////////////
1:                             boolean created = false;
1:                             IOException ex = null;
1:                             try {
1:                                 created = privMkdirs(directory);
1:                             } catch (IOException ioe) {
1:                                 ex = ioe;
1:                             }
1: 
1:                             if (!created)
1:                                             ex, directory);
/////////////////////////////////////////////////////////////////////////
1:             throws IOException
/////////////////////////////////////////////////////////////////////////
1:             // could throw IOException
1:             throw (IOException) pae.getCause();
/////////////////////////////////////////////////////////////////////////
1:     public Object run() throws IOException
commit:f668d94
/////////////////////////////////////////////////////////////////////////
commit:c6892a1
/////////////////////////////////////////////////////////////////////////
1: 			// make the database corrupt, just that this field is inaccessable
/////////////////////////////////////////////////////////////////////////
1: 			// make the database corrupt, just that this field is inaccessable
commit:2349a90
/////////////////////////////////////////////////////////////////////////
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:56c1dc2
/////////////////////////////////////////////////////////////////////////
1: 			getServiceModule(dataFactory, AccessFactory.MODULE);
/////////////////////////////////////////////////////////////////////////
1:         return AccessController.doPrivileged
1:             (
1:              new PrivilegedAction<ContextService>()
1:              {
1:                  public ContextService run()
1:                      return ContextService.getFactory();
1:              }
1:              );
1:     }
1: 
1:     /**
1:      * Privileged module lookup. Must be private so that user code
1:      * can't call this entry point.
1:      */
1:     private static  Object getServiceModule( final Object serviceModule, final String factoryInterface )
1:     {
1:         return AccessController.doPrivileged
1:             (
1:              new PrivilegedAction<Object>()
1:              {
1:                  public Object run()
1:                  {
1:                      return Monitor.getServiceModule( serviceModule, factoryInterface );
1:                  }
1:              }
1:              );
commit:a0dbbd7
/////////////////////////////////////////////////////////////////////////
1: import java.security.PrivilegedAction;
/////////////////////////////////////////////////////////////////////////
1:                     getContextService().getCurrentContextManager());
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Privileged lookup of the ContextService. Must be private so that user code
1:      * can't call this entry point.
1:      */
1:     private  static  ContextService    getContextService()
1:     {
0:         if ( System.getSecurityManager() == null )
1:         {
0:             return ContextService.getFactory();
1:         }
1:         else
1:         {
0:             return AccessController.doPrivileged
0:                 (
0:                  new PrivilegedAction<ContextService>()
1:                  {
0:                      public ContextService run()
1:                      {
0:                          return ContextService.getFactory();
1:                      }
1:                  }
0:                  );
1:         }
1:     }
1: 
commit:93590df
/////////////////////////////////////////////////////////////////////////
1: class StreamFileContainer implements TypedFormat, PrivilegedExceptionAction<Object>
commit:7e7a589
/////////////////////////////////////////////////////////////////////////
0: public class StreamFileContainer implements TypedFormat, PrivilegedExceptionAction<Object>
commit:270a34d
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.sanity.SanityManager;
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:dc43cf8
/////////////////////////////////////////////////////////////////////////
1:             boolean created = actionStorageFile.mkdirs();
1:             actionStorageFile.limitAccessToOwner();
0:             return ReuseFactory.getBoolean(created);
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:1d0c179
/////////////////////////////////////////////////////////////////////////
1:             // Set a reasonable buffer size.
1:             // To avoid extremely inefficient reads, and an infinite loop when
1:             // InputStream.available() returns zero, a lower limit is set on
1:             // the buffer size. To avoid using too much memory (especially in
1:             // multi-user environments) an upper limit is set as well.
1:             // The limits can be tuned, but note that using a too high default
1:             // or lower limit can put unnecessary pressure on the memory sub-
1:             // system and the GC process.
1:             int bufferLen = Math.min(Math.max(inColumn.available(), 64), 8192);
1:                 int lenRead = inColumn.read(bufData);
1:                     out.write(bufData, 0, lenRead);
author:Satheesh E. Bandaram
-------------------------------------------------------------------------------
commit:ae71c74
/////////////////////////////////////////////////////////////////////////
1:                     out.getByteArray(), startByte, encryptedLen, ciphertext, 0, false);
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:20445e3
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.util.ReuseFactory;
/////////////////////////////////////////////////////////////////////////
1: import java.security.AccessController;
1: import java.security.PrivilegedExceptionAction;
1: import java.security.PrivilegedActionException;
1: import java.io.FileNotFoundException;
/////////////////////////////////////////////////////////////////////////
0: public class StreamFileContainer implements TypedFormat, PrivilegedExceptionAction
/////////////////////////////////////////////////////////////////////////
1: 
1:     /* privileged actions */
1:     private static final int STORAGE_FILE_EXISTS_ACTION = 1;
1:     private static final int STORAGE_FILE_DELETE_ACTION = 2;
1:     private static final int STORAGE_FILE_MKDIRS_ACTION = 3;
1:     private static final int STORAGE_FILE_GET_OUTPUT_STREAM_ACTION = 4;
1:     private static final int STORAGE_FILE_GET_INPUT_STREAM_ACTION = 5;
1:     private int actionCode;
1:     private StorageFile actionStorageFile;
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1:             if (privExists(file)) 
/////////////////////////////////////////////////////////////////////////
1:         if (!privExists(file))
1: 				fileIn = privGetInputStream(file);
/////////////////////////////////////////////////////////////////////////
1: 			fileOut = privGetOutputStream(file);
/////////////////////////////////////////////////////////////////////////
1:         if (privExists(file))
1:             return privDelete(file);
/////////////////////////////////////////////////////////////////////////
1: 			if (!privExists(container)) 
/////////////////////////////////////////////////////////////////////////
1: 				if (!privExists(directory)) 
1: 						if (!privExists(directory)) 
0: 							if (!privMkdirs(directory)) 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1:     
1:     private synchronized boolean privExists(StorageFile file)
1:     {
1:         actionCode = STORAGE_FILE_EXISTS_ACTION;
1:         actionStorageFile = file;
1: 
1:         try
1:         {
1:             Object ret = AccessController.doPrivileged( this);
1:             return ((Boolean) ret).booleanValue();
1:         }catch( PrivilegedActionException pae) 
1:         { 
1:             // method executed under this priveleged block 
1:             // does not throw an exception
1:             return false;
1:         } 
1:         finally
1:         {
1:             actionStorageFile = null;
1:         }
1:     }
1: 
1:     private synchronized boolean privMkdirs(StorageFile file)
1:     {
1:         actionCode = STORAGE_FILE_MKDIRS_ACTION;
1:         actionStorageFile = file;
1: 
1:         try
1:         {
1:             Object ret = AccessController.doPrivileged( this);
1:             return ((Boolean) ret).booleanValue();
1:         }catch( PrivilegedActionException pae) 
1:         {
1:             // method executed under this priveleged block 
1:             // does not throw an exception
1:             return false;
1:         } 
1:         finally
1:         {
1:             actionStorageFile = null;
1:         }
1:     }
1: 
1:     
1:     private synchronized boolean privDelete(StorageFile file)
1:     {
1:         actionCode = STORAGE_FILE_DELETE_ACTION;
1:         actionStorageFile = file;
1: 
1:         try
1:         {
1:             Object ret = AccessController.doPrivileged( this);
1:             return ((Boolean) ret).booleanValue();
1:         }catch( PrivilegedActionException pae) 
1:         { 
1:             // method executed under this priveleged block 
1:             // does not throw an exception
1:             return false;
1:         } 
1:         finally
1:         {
1:             actionStorageFile = null;
1:         }
1:     }
1: 
1:     private synchronized OutputStream privGetOutputStream(StorageFile file)
1:         throws FileNotFoundException
1:     {
1:         actionCode = STORAGE_FILE_GET_OUTPUT_STREAM_ACTION;
1:         actionStorageFile = file;
1: 
1:         try
1:         {
1:             return (OutputStream) AccessController.doPrivileged( this);
1:         }catch( PrivilegedActionException pae) 
1:         { 
1:             throw (FileNotFoundException)pae.getException();
1:         } 
1:         finally
1:         {
1:             actionStorageFile = null;
1:         }
1:     }
1: 
1: 
1:     private synchronized InputStream privGetInputStream(StorageFile file)
1:         throws FileNotFoundException
1:     {
1:         actionCode = STORAGE_FILE_GET_INPUT_STREAM_ACTION;
1:         actionStorageFile = file;
1: 
1:         try
1:         {
1:             return (InputStream) AccessController.doPrivileged( this);
1:         }catch( PrivilegedActionException pae) 
1:         { 
1:             throw (FileNotFoundException)pae.getException();
1:         } 
1:         finally
1:         {
1:             actionStorageFile = null;
1:         }
1:     }
1: 
1: 
1:     // PrivilegedAction method
0:     public Object run() throws FileNotFoundException
1:     {
1:         switch(actionCode)
1:         {
1:         case STORAGE_FILE_EXISTS_ACTION:
0:             return ReuseFactory.getBoolean(actionStorageFile.exists());
1:         case STORAGE_FILE_DELETE_ACTION:
0:             return ReuseFactory.getBoolean(actionStorageFile.delete());
1:         case STORAGE_FILE_MKDIRS_ACTION:
0:             return ReuseFactory.getBoolean(actionStorageFile.mkdirs());
1:         case STORAGE_FILE_GET_OUTPUT_STREAM_ACTION:
1:             return actionStorageFile.getOutputStream();
1:         case STORAGE_FILE_GET_INPUT_STREAM_ACTION:
1:             return actionStorageFile.getInputStream();
1:         }
1: 
1:         return null;
1:     }
1: 
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:345de35
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derby.impl.store.raw.data.StreamFileContainer
1: 
0:    Copyright 1999, 2004 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
commit:c6ad534
/////////////////////////////////////////////////////////////////////////
commit:eac0369
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.store.raw.data
0:    (C) Copyright IBM Corp. 1999, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
1: 
1:  */
1: 
1: package org.apache.derby.impl.store.raw.data;
1: 
1: import org.apache.derby.iapi.reference.SQLState;
1: 
1: import org.apache.derby.iapi.services.context.ContextService;
1: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: import org.apache.derby.iapi.services.io.Storable;
1: import org.apache.derby.iapi.services.io.StreamStorable;
1: import org.apache.derby.iapi.services.io.FormatIdInputStream;
1: import org.apache.derby.iapi.services.io.FormatIdOutputStream;
0: import org.apache.derby.iapi.services.io.FormatIdUtil;
1: import org.apache.derby.iapi.services.io.StoredFormatIds;
1: import org.apache.derby.iapi.services.io.TypedFormat;
1: import org.apache.derby.iapi.services.monitor.Monitor;
1: 
1: import org.apache.derby.iapi.error.StandardException;
1: import org.apache.derby.iapi.store.access.AccessFactory;
1: import org.apache.derby.iapi.store.access.RowSource;
0: import org.apache.derby.iapi.store.access.RowUtil;
1: import org.apache.derby.iapi.store.access.TransactionController;
1: import org.apache.derby.iapi.store.raw.ContainerKey;
1: import org.apache.derby.iapi.store.raw.RawStoreFactory;
1: import org.apache.derby.iapi.store.raw.StreamContainerHandle;
1: 
0: import org.apache.derby.io.StorageFactory;
0: import org.apache.derby.io.WritableStorageFactory;
1: import org.apache.derby.io.StorageFile;
1: 
0: import org.apache.derby.impl.store.raw.data.DecryptInputStream;
0: import org.apache.derby.impl.store.raw.data.StoredFieldHeader;
0: import org.apache.derby.impl.store.raw.data.StoredRecordHeader;
1: 
0: import org.apache.derby.iapi.services.io.ArrayInputStream;
1: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: import org.apache.derby.iapi.services.io.CompressedNumber;
1: import org.apache.derby.iapi.services.io.DynamicByteArrayOutputStream;
1: import org.apache.derby.iapi.services.io.LimitInputStream;
1: import org.apache.derby.iapi.services.property.PropertyUtil;
1: 
1: import java.util.Properties;
1: import java.io.InputStream;
1: import java.io.BufferedInputStream;
1: import java.io.OutputStream;
1: import java.io.IOException;
1: import java.io.EOFException;
1: import java.io.InvalidClassException;
1: import java.io.Externalizable;
1: 
1: /**
1: 
1:   The format of this stream file is:
1:   (RH) (FH) (field data) (FH) (field data) ........ (FH) (field data)
1: 
1:   Record header is stored once at the beginning of the file
1:   for all the rows stored in this file.
1:   Record Header indicates how many fields are in each row.
1:   Then we just stored all the column from each row.
1:   Field header stored on this file is fixed size with fieldDataLength
1:   size set to LARGE_SLOT_SIZE (4) bytes.
1: 
1:   NOTE: No locks are used in this container.  All transaction are not logged.
1: 
1: **/
1: 
1: 
0: public class StreamFileContainer implements TypedFormat
1: {
1: 	/**
0: 		IBM Copyright &copy notice.
1: 	*/
1:  
0:     private static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1999_2004;
1: 
1:     /**************************************************************************
1:      * Constant Fields of the class
1:      **************************************************************************
1:      */
1: 
1: 	/*
1: 	 * typed format
1: 	 * format Id must fit in 4 bytes
1: 	 */
1: 	protected static int formatIdInteger = 
1:         StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE; 
1: 
1: 
1:     // 4 bytes for field data length
1: 	protected static final int LARGE_SLOT_SIZE = 4;	
1: 
1: 	protected static final int MIN_BUFFER_SIZE = 
1:         RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM;
1: 	protected static final int FIELD_STATUS = 
1:         StoredFieldHeader.setFixed(StoredFieldHeader.setInitial(), true);
1: 	protected static final int FIELD_HEADER_SIZE = 
1:         StoredFieldHeader.size(FIELD_STATUS, 0, LARGE_SLOT_SIZE);
1: 
1: 
1:     /**************************************************************************
1:      * Fields of the class
1:      **************************************************************************
1:      */
1: 	protected   ContainerKey          identity;
1: 	private   BaseDataFileFactory   dataFactory;  // the factory that made me
1: 
1: 	private int                             bufferSize;
1: 
1: 	private StorageFile file;
1: 
1: 	private OutputStream                fileOut;
1: 	private DynamicByteArrayOutputStream    out;
1: 	private FormatIdOutputStream            logicalDataOut;
1: 
1: 	private InputStream                 fileIn;
1: 	private BufferedInputStream             bufferedIn;
1: 	private DecryptInputStream              decryptIn;
1: 	private LimitInputStream                limitIn;
1: 	private FormatIdInputStream             logicalDataIn;
1: 
1: 	private StoredRecordHeader              recordHeader;
1: 
1: 	private byte[]                          ciphertext;
1: 	private byte[]                          zeroBytes;	// in case encryption
1:                                                         // stream needs pad.
1: 
1:     /**************************************************************************
1:      * Constructors for This class:
1:      **************************************************************************
1:      */
1: 
1:     /**
1:      * Constructor.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	StreamFileContainer(
1:     ContainerKey        identity, 
1:     BaseDataFileFactory dataFactory)
1: 		throws StandardException 
1:     {
1: 		this.identity = identity;
1: 		this.dataFactory = dataFactory;
1: 	}
1: 
1:     /**
1:      * Constructor
1:      * <p>
1:      * when rowSource is passed to the constructor, it will be loaded into the 
1:      * container after the container has been created.
1:      * <p>
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	StreamFileContainer(
1:     ContainerKey        identity, 
1:     BaseDataFileFactory dataFactory,
1:     Properties          prop)
1: 		throws StandardException 
1:     {
1: 		this.identity       = identity;
1: 		this.dataFactory    = dataFactory;
1: 
1: 		try 
1:         {
1: 			file = getFileName(identity, true, false);
1: 
0:             if (file.exists()) 
1:             {
1: 				// note I'm left in the no-identity state as fillInIdentity()
1:                 // hasn't been called.
1: 				throw StandardException.newException(
1:                         SQLState.FILE_EXISTS, file);
1: 			}
1: 
1: 			// get the properties to set buffer size
1: 			// derby.storage.streamFileBufferSize
1: 			getContainerProperties(prop);
1: 
1: 		} 
1:         catch (SecurityException se) 
1:         {
1: 			throw StandardException.newException(
1:                     SQLState.FILE_CREATE, se, file);
1: 		}
1: 	}
1: 
1:     /**************************************************************************
1:      * Private/Protected methods of This class:
1:      **************************************************************************
1:      */
1: 
1:     /**
1:      * Open a stream file container.
1:      * <p>
1:      * Open a container. Open the file that maps to this container, if the
1:      * file does not exist then we assume the container was never created
1:      * and return.
1:      * If the file exists but we have trouble opening it then we throw some 
1:      * exception.
1:      * <p>
1:      *
1: 	 * @return The opened StreamFileContainer.
1:      *
1:      * @param forUpdate     Currently only accepts false, updating and existing
1:      *                      stream file container is not currently supported.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	protected StreamFileContainer open(boolean forUpdate) 
1:         throws StandardException 
1:     {
1: 
1: 		file = getFileName(this.identity, false, true);
0:         if (!file.exists())
1: 			return null;
1: 
1: 		try 
1:         {
1: 			if (!forUpdate) 
1:             {
0: 				fileIn = file.getInputStream();
1: 
1: 				if (dataFactory.databaseEncrypted()) 
1:                 {
1: 					// if the database is encrypted, when reading the data back
1:                     // from the file stream, we need to used the decrypt stream
1:                     // to buffer up the bytes for reading.  DecryptInputStream 
1:                     // also decrypts the data.
1: 
1: 					MemByteHolder byteHolder = 
1:                         new MemByteHolder(
1:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1: 
1: 					decryptIn = 
1:                         new DecryptInputStream(fileIn, byteHolder, dataFactory);
1: 
1: 					limitIn = new LimitInputStream(decryptIn);
1: 				} 
1:                 else 
1:                 {
1: 					bufferedIn = 
1:                         new BufferedInputStream(
1:                             fileIn, 
1:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1: 
1: 					limitIn = new LimitInputStream(bufferedIn);
1: 				}
1: 
1: 				// the logicalDataIn input stream is on top of a limit Input
1: 				// stream, use a limit stream to make sure we don't read off
1: 				// more then what each column says it contains
1: 
1: 				logicalDataIn = new FormatIdInputStream(limitIn);
1: 
1: 				// get the record header
1: 				recordHeader = new StoredRecordHeader();
1: 				recordHeader.read(logicalDataIn);
1: 
1: 			} 
1:             else 
1:             {
1: 				if (SanityManager.DEBUG)
1: 					SanityManager.THROWASSERT(
1:                         "updating existing stream container not supported yet");
1: 
1: 				return null;
1: 			}
1: 		} 
1:         catch (IOException ioe) 
1:         {
1: 			throw StandardException.newException(
1:                     SQLState.FILE_CREATE, ioe, file);
1: 		}
1: 
1: 		return this;
1: 	}
1: 
1:     /**
1:      * Close the stream file.
1:      * <p>
1:      * Close this stream file, and all streams associated with it.
1:      * <p>
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	protected void close()
1:     {
1: 		try 
1:         {
1: 
1: 			if (fileIn != null) 
1:             {
1: 				fileIn.close();
1: 				fileIn = null;
1: 				if (dataFactory.databaseEncrypted()) 
1:                 {
1: 					decryptIn.close();
1: 					decryptIn = null;
1: 				} 
1:                 else 
1:                 {
1: 					bufferedIn.close();
1: 					bufferedIn = null;
1: 				}
1: 				logicalDataIn.close();
1: 				logicalDataIn = null;
1: 			}
1: 
1: 			if (fileOut != null) 
1:             {
1: 				fileOut.close();
1: 				logicalDataOut.close();
1: 				fileOut = null;
1: 				logicalDataOut = null;
1: 				out = null;
1: 			}
1: 
1: 		} 
1:         catch (IOException ioe) 
1:         {
1:             // ignore close errors from fileOut.close() and fileIn.close() - 
1:             // there isn't much we can do about them anyway - and some of the
1:             // interfaces don't want to deal with exceptions from close().
1: 
1:             /*
1: 			throw StandardException.newException(
1:                     SQLState.FILE_CREATE, ioe, file);
1:             */
1: 		}
1: 	}
1: 
1:     /**************************************************************************
1:      * Public Methods of This class:
1:      **************************************************************************
1:      */
1: 
1:     /**
1:      * Return my format identifier.
1:      **/
1: 	public int getTypeFormatId() 
1:     {
1: 		return StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE;
1: 	}
1: 
1:     /**
1:      * Request the system properties associated with a stream container. 
1:      * <p>
1:      * Request the value of properties associated with a stream container. 
1:      * The following properties can be requested:
1:      *     derby.storage.streamFileBufferSize
1: 	 *
1:      * <p>
1:      * To get the value of a particular property add it to the property list,
1:      * and on return the value of the property will be set to it's current 
1:      * value.  For example:
1:      *
1:      * get_prop(ConglomerateController cc)
1:      * {
1:      *     Properties prop = new Properties();
1:      *     prop.put("derby.storage.streamFileBufferSize", "");
1:      *     cc.getContainerProperties(prop);
1:      *
1:      *     System.out.println(
1:      *         "stream table's buffer size = " + 
1:      *         prop.getProperty("derby.storage.streamFileBufferSize");
1:      * }
1:      *
1:      * @param prop   Property list to fill in.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1:     public void getContainerProperties(Properties prop) 
1:         throws StandardException 
1:     {
1: 
1: 		AccessFactory af = (AccessFactory)
0: 			Monitor.getServiceModule(dataFactory, AccessFactory.MODULE);
1: 
1: 		TransactionController tc = 
1:             (af == null) ? 
1:                 null : 
1:                 af.getTransaction(
0:                     ContextService.getFactory().getCurrentContextManager());
1: 
1: 		bufferSize = 
1: 			PropertyUtil.getServiceInt(tc, prop,
1: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_PARAMETER,  
1: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM, 
1: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MAXIMUM,
1: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
1: 	}
1: 
1:     /**
1:      * Request the container key associated with the stream container. 
1: 	 **/
1: 	public ContainerKey getIdentity() 
1:     {
1: 		return this.identity;
1: 	}
1: 
1:     /**
1:      * Can I use this container?
1:      * <p>
1:      * This method always return true right now.
1:      * In the future when there are different uses for this container,
1:      * we may need to add qualifications for this.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	protected boolean use(StreamContainerHandle handle) 
1:         throws StandardException 
1:     {
1: 		return true;
1: 	}
1: 
1:     /**
1:      * load data into this container.
1:      * <p>
1:      * populate the stream container with data in the rowSource
1:      * <p>
1:      *
1:      * @param rowSource The row source to get rows to load into this container.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	public void load(RowSource rowSource) 
1:         throws StandardException 
1:     {
1: 		// use this output stream to buffer rows before inserting into file.
1: 		out                 = new DynamicByteArrayOutputStream(bufferSize);
1: 		logicalDataOut      = new FormatIdOutputStream(out);
1: 		boolean encrypted   = dataFactory.databaseEncrypted();
1: 
1: 		// reserve the first dataFactory.getEncryptionBlockSize() - 1 bytes, if the database is 
1:         // encrypted These reserved bytes will be used to pad the byte array if
1:         // it is not dataFactory.getEncryptionBlockSize() aligned.
1: 		if (encrypted) 
1:         {
1: 			if (zeroBytes == null)
1: 				zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
1: 
1: 			out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
1: 		}
1: 
1: 		try 
1:         {
0: 			fileOut = file.getOutputStream();
1: 
1: 			FormatableBitSet validColumns = rowSource.getValidColumns();
1: 
1: 			Object[] row = rowSource.getNextRowFromRowSource();
1: 
1: 			int numberFields = 0;
1: 			if (validColumns != null) 
1:             {
1: 				for (int i = validColumns.getLength() - 1; i >= 0; i--) 
1:                 {
1: 					if (validColumns.isSet(i)) 
1:                     {
1: 						numberFields = i + 1;
1: 						break;
1: 					}
1: 				}
1: 			} 
1:             else 
1:             {
1: 				numberFields = row.length;
1: 			}
1: 
1: 			// make the record header to have 0 record id
1: 			recordHeader = new StoredRecordHeader(0, numberFields);
1: 
1: 			// write the record header once for all the rows, directly to the 
1:             // beginning of the file.
1: 			int rhLen = recordHeader.write(out);
1: 
1: 			int validColumnsSize = 
1:                 validColumns == null ? 0 : validColumns.getLength();
1: 
1: 			while (row != null) 
1:             {
1: 
1: 				int arrayPosition = -1;
1: 
1: 				for (int i = 0; i < numberFields; i++) 
1:                 {
1: 
1: 					// write each column out
1: 					if (validColumns == null) 
1:                     {
1: 						arrayPosition++;
1: 						Object column = row[arrayPosition];
1: 						writeColumn(column);
1: 					} 
1:                     else 
1:                     {
1: 
1: 						if (validColumnsSize > i && validColumns.isSet(i)) 
1:                         {
1: 							arrayPosition++;
1: 							Object column = row[arrayPosition];
1: 							writeColumn(column);
1: 						} 
1:                         else 
1:                         {
1: 							// it is a non-existent column
1: 							writeColumn(null);
1: 						}
1: 					}
1: 
1: 					// put the buffer onto the page, only if it exceeded the 
1:                     // original buffer size or it has less than 100 bytes left 
1:                     // in the buffer
1: 					if ((out.getUsed() >= bufferSize) || 
1:                         ((bufferSize - out.getUsed()) < MIN_BUFFER_SIZE)) 
1:                     {
1: 						writeToFile();
1: 					}
1: 				}
1: 
1: 				// get the next row and its valid columns from the rowSource
1: 				row = rowSource.getNextRowFromRowSource();
1: 			}
1: 
1: 
1: 			// Write the buffer to the file if there is something in the output
1: 			// buffer.  Remember we pad the output buffer with
1: 			// dataFactory.getEncryptionBlockSize() - 1 if this is an encypted database
1: 			if (encrypted)
1: 			{
1: 				if (out.getUsed() > (dataFactory.getEncryptionBlockSize() - 1))
1: 					writeToFile();
1: 			}
1: 			else if (out.getUsed() > 0) 
1:             {
1: 				writeToFile();
1: 			}
1: 
1: 		} 
1:         catch (IOException ioe) 
1:         {
1: 			// handle IO error...
1: 			throw StandardException.newException(
1:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
1: 
1: 		}
1:         finally 
1:         {
1: 			close();
1: 		}
1: 	}
1: 
1: 	/*
1: 
1: 	 */
1:     /**
1:      * Write the buffer to the file.
1:      * <p>
1:      * If the database is encrypted, the dataFactory.getEncryptionBlockSize() - 1 reserved bytes will
1:      * be used to pad the byte array to be dataFactory.getEncryptionBlockSize()
1:      * aligned.  Before the bytes are encrypted and written to the file stream,
1:      * the actual length of the byte array is written out as a compressed 
1:      * integer.  This number will be used when decrypting the data.
1:      *
1:      * If the database is not encrypted, then, we don't reserve the bytes 
1:      * upfront, and we simple just write the bytes out to the file stream.
1:      *
1: 	 * @exception  StandardException  Standard exception policy.
1:      **/
1: 	private void writeToFile() 
1:         throws StandardException 
1:     {
1: 
1: 		try
1:         {
1: 			if (dataFactory.databaseEncrypted()) 
1:             {
1: 				// if db is encrypted, 
1:                 // use the first ENCRYPTION_ALIGN bytes for padding.
1:                 //
1: 				int realLen = out.getUsed() - (dataFactory.getEncryptionBlockSize() - 1);
1: 				int tail = realLen % dataFactory.getEncryptionBlockSize();
1: 				int padding = 
1:                     (tail == 0) ? 0 : 
1:                     (dataFactory.getEncryptionBlockSize() - tail);
1: 
1: 				int startByte = (tail == 0) ? (dataFactory.getEncryptionBlockSize() - 1) : (tail - 1);
1: 				int encryptedLen = realLen + padding;
1: 
1: 				// there is nothing to write, just the encryption padding
1: 				if (realLen <= 0)
1: 					return;
1: 
1: 				if (ciphertext == null)
1:                 {
1: 					ciphertext = new byte[encryptedLen];
1:                 }
1: 				else 
1:                 {
1: 					if (ciphertext.length < encryptedLen)
1: 						ciphertext = new byte[encryptedLen];
1: 				}
1: 
1: 				dataFactory.encrypt(
0:                     out.getByteArray(), startByte, encryptedLen, ciphertext, 0);
1: 
1: 				// write out the actual length, then the encrypted bytes.
1: 				CompressedNumber.writeInt(fileOut, realLen);
1: 				dataFactory.writeInProgress();
1: 				try
1: 				{
1: 					fileOut.write(ciphertext, 0, encryptedLen);
1: 				}
1: 				finally
1: 				{
1: 					dataFactory.writeFinished();
1: 				}
1: 
1: 				// reset the dynamic buffer
1: 				out.reset();
1: 
1: 				// reserve bytes if database is encrypted.
1: 				if (dataFactory.databaseEncrypted())
1:                 {
1: 					if (zeroBytes == null)
1: 						zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
1: 
1: 					out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
1: 				}
1: 
1: 			} 
1:             else 
1:             {
1: 				// nothing to write
1: 				if (out.getUsed() == 0)
1: 					return;
1: 
1: 				dataFactory.writeInProgress();
1: 				try
1: 				{
1: 					fileOut.write(out.getByteArray(), 0, out.getUsed());
1: 				}
1: 				finally
1: 				{
1: 					dataFactory.writeFinished();
1: 				}
1: 
1: 				// reset the dynamic buffer
1: 				out.reset();
1: 			}
1: 		} 
1:         catch (IOException ioe) 
1:         {
1: 			throw StandardException.newException(
1:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
1: 		}
1: 	}
1: 
1: 	private void writeColumn(Object column) 
1:         throws StandardException, IOException 
1:     {
1: 
1: 		int fieldStatus = FIELD_STATUS;
1: 		if (column == null) 
1:         {
1: 			// just write a non-existent header.
1: 			fieldStatus = StoredFieldHeader.setNonexistent(fieldStatus);
1: 			StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
1: 			return;
1: 		}
1: 
1: 		// if the column is a null column, write the field header now.
1: 		if (column instanceof Storable) 
1:         {
1: 			Storable sColumn = (Storable) column;
1: 			if (sColumn.isNull()) 
1:             {
1: 				fieldStatus = StoredFieldHeader.setNull(fieldStatus, true);
1: 				StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
1: 				return;
1: 			}
1: 		}
1: 
1: 		int beginPosition = out.getPosition();
1: 		int fieldDataLength = 0;
1: 
1: 		// write out the header, mostly to reserve the space
1: 		StoredFieldHeader.write(
1:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
1: 
1: 		if (column instanceof StreamStorable) 
1:         {
1: 			if (((StreamStorable) column).returnStream() != null) 
1:             {
1: 				column = (InputStream) ((StreamStorable) column).returnStream();
1: 			}
1: 		}
1: 
1: 		if (column instanceof InputStream) 
1:         {
1: 			InputStream inColumn = (InputStream) column;
0: 			int bufferLen = inColumn.available();
1: 			byte[] bufData = new byte[bufferLen];
1: 
1: 			do 
1:             {
0: 				int lenRead = inColumn.read(bufData, bufferLen, 0);
1: 				if (lenRead != -1) 
1:                 {
1: 					fieldDataLength += lenRead;
0: 					out.write(bufData, lenRead, 0);
1: 				} 
1:                 else
1:                 {
1: 					break; 
1:                 }
1: 			} while (true);
1: 
1: 		} 
1:         else if (column instanceof Storable) 
1:         {
1: 
1: 			Storable sColumn = (Storable) column;
1: 			// write field data to the stream, we already handled the null case
1:             
1: 			sColumn.writeExternal(logicalDataOut);
1: 			fieldDataLength = 
1:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
1: 
1: 		} 
1:         else 
1:         {
1: 			// Serializable/Externalizable/Formattable
1: 			// all look the same at this point.
1: 			logicalDataOut.writeObject(column);
1: 			fieldDataLength = 
1:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
1: 		}
1: 
1: 		// Now we go back to update the fieldDataLength in the field header
1: 		int endPosition = out.getPosition();
1: 		out.setPosition(beginPosition);
1: 
1: 		StoredFieldHeader.write(
1:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
1: 
1: 		// set position to the end of the field
1: 		if (!StoredFieldHeader.isNull(fieldStatus))
1: 			out.setPosition(endPosition);
1: 	}
1: 
1: 	public boolean fetchNext(Object[] row) 
1:         throws StandardException 
1:     {
1: 
1: 		boolean inUserCode = false;
1: 		int columnId = 0;
1: 		
1: 		try	
1:         {
1: 
1: 			// Get the number of columns in the row.
1: 			int numberFields = recordHeader.getNumberFields();
1: 
1: 			int arrayPosition = 0;
1: 			for (columnId = 0; columnId < numberFields; columnId++) 
1:             {
1: 
1: 				if (arrayPosition >= row.length)
1: 					break;
1: 	
1: 				limitIn.clearLimit();
1: 
1: 				// read the field header
1: 				int fieldStatus = StoredFieldHeader.readStatus(logicalDataIn);
1: 				int fieldDataLength = StoredFieldHeader.readFieldDataLength(
1: 					logicalDataIn, fieldStatus, LARGE_SLOT_SIZE);
1: 
1: 				limitIn.setLimit(fieldDataLength);
1: 
1: 				if (SanityManager.DEBUG) 
1:                 {
1: 
1:                     if (StoredFieldHeader.isExtensible(fieldStatus))
1:                     {
1:                         SanityManager.THROWASSERT(
1:                             "extensible fields not supported yet.  columnId = "
1:                             + columnId);
1:                     }
1: 
1: 					SanityManager.ASSERT(!StoredFieldHeader.isOverflow(fieldStatus),
1: 						"overflow field is not supported yet");
1: 				}
1: 
1: 				Object column = row[arrayPosition];
1: 				
1: 				// Deal with Storable columns
1: 				if (StoredFieldHeader.isNullable(fieldStatus)) 
1:                 {
1: 									
1: 					if (column == null)
1:                     {
1: 						throw StandardException.newException(
1:                                 SQLState.DATA_NULL_STORABLE_COLUMN, 
1:                                 Integer.toString(columnId));
1:                     }
1: 
1: 					// SRW-DJD RESOLVE: - fix error message
1: 					if (!(column instanceof Storable)) 
1:                     {
1: 						throw StandardException.newException(
1:                             SQLState.DATA_NULL_STORABLE_COLUMN, 
1:                             column.getClass().getName());
1: 					}
1: 
1: 					Storable sColumn = (Storable) column;
1: 
1: 					// is the column null ?
1: 					if (StoredFieldHeader.isNull(fieldStatus)) 
1:                     {
1: 
1: 						sColumn.restoreToNull();
1: 						arrayPosition++;
1: 						continue;
1: 					}
1: 
1: 					inUserCode = true;
1: 					sColumn.readExternal(logicalDataIn);
1: 					inUserCode = false;
1: 					arrayPosition++;
1: 					continue;
1: 				}
1: 
1: 				// Only Storables can be null ... SRW-DJD RESOLVE: - fix error message
1: 				if (StoredFieldHeader.isNull(fieldStatus))
1:                 {
1: 					throw StandardException.newException(
1:                         SQLState.DATA_NULL_STORABLE_COLUMN, 
1:                         Integer.toString(columnId));
1:                 }
1: 
1: 				// This is a non-extensible field, which means the caller must 
1:                 // know the correct type and thus the element in row is the 
1:                 // correct type or null. If the element implements 
1:                 // Externalizable then we can just fill it in, otherwise it 
1:                 // must be Serializable and we have to throw it away.
1: 
1: 				Object neColumn = row[arrayPosition];
1: 
1: 				if (neColumn instanceof Externalizable) 
1:                 {
1: 
1: 					Externalizable exColumn = (Externalizable) neColumn;
1: 
1: 					inUserCode = true;
1: 					exColumn.readExternal(logicalDataIn);
1: 					inUserCode = false;
1: 
1: 					arrayPosition++;
1: 					continue;
1: 				}
1: 
1: 				// neColumn will be ignored
1: 				neColumn = null;
1: 				inUserCode = true;
1: 				row[arrayPosition] = logicalDataIn.readObject();
1: 				inUserCode = false;
1: 
1: 				arrayPosition++;
1: 				continue;
1: 			}
1: 
1: 		} 
1:         catch (IOException ioe) 
1:         {
1: 
1: 			// an exception during the restore of a user column, this doesn't
0: 			// make the databse corrupt, just that this field is inaccessable
1: 			if (inUserCode) 
1:             { 
1: 
1: 				if (ioe instanceof EOFException) 
1:                 {
1: 					throw StandardException.newException(
1:                         SQLState.DATA_STORABLE_READ_MISMATCH, 
1:                         ioe, logicalDataIn.getErrorInfo());
1: 				}
1: 
1: 				throw StandardException.newException(
1:                     SQLState.DATA_STORABLE_READ_EXCEPTION, 
1:                     ioe, logicalDataIn.getErrorInfo());
1: 			}
1: 
1: 			if (ioe instanceof InvalidClassException)
1:             {
1: 				throw StandardException.newException(
1:                         SQLState.DATA_STORABLE_READ_EXCEPTION, 
1:                         ioe, logicalDataIn.getErrorInfo());
1:    			}
1: 
1: 			// If we are at the end of the file, trying to fetch the first 
1:             // column, then we know there is no more rows to fetch
1: 			if ((ioe instanceof EOFException) && (columnId == 0)) 
1:             {
1: 				close();
0: 				return false;
1: 			}
1: 
1: 			throw dataFactory.markCorrupt(
1:                 StandardException.newException(
1:                     SQLState.DATA_CORRUPT_STREAM_CONTAINER, ioe, identity));
1: 
1: 		} 
1:         catch (ClassNotFoundException cnfe) 
1:         {
1: 
1: 			if (SanityManager.DEBUG) 
1:             {
1: 				SanityManager.ASSERT(inUserCode);
1: 			}
1: 
1: 			// an exception during the restore of a user column, this doesn't
0: 			// make the databse corrupt, just that this field is inaccessable
1: 			throw StandardException.newException(
1:                 SQLState.DATA_STORABLE_READ_MISSING_CLASS, cnfe, 
1:                 logicalDataIn.getErrorInfo());
1: 
1: 		} 
1:         catch (LinkageError le) 
1:         {
1: 			if (inUserCode)
1:             {
1: 				throw StandardException.newException(
1:                     SQLState.DATA_STORABLE_READ_EXCEPTION, le,
1:                     logicalDataIn.getErrorInfo());
1:             }
1: 			throw le;
1: 		}
1: 
1: 		return true;
1: 
1: 	}
1: 
1:     /**
1:      * Close the stream file and remove the file.
1:      *
1:      * @exception StandardException Segment directory cannot be created
1:      **/
1: 	public boolean removeContainer() 
1:         throws StandardException 
1:     {
1: 		close();
1: 
0:         if (file.exists())
1:         {
0:             return file.delete();
1:         }
1:         else
1:         {
1:             return true;
1:         }
1: 
1: 
1: 	}
1: 
1:     /**
1:      * Return a file name for the identity.
1:      * <p>
1:      * Return a valid file name for the identity, or null if the data
1:      * directory for this segment cannot be created
1:      *
1: 	 * @exception StandardException Segment directory cannot be created
1:      **/
1: 	protected StorageFile getFileName(
1:     ContainerKey    identity, 
1:     boolean         forCreate, 
1:     boolean         errorOK)
1: 		 throws StandardException 
1:     {
1: 		if (identity.getSegmentId() == StreamContainerHandle.TEMPORARY_SEGMENT)
1:         {
1: 			return( dataFactory.storageFactory.newStorageFile( dataFactory.storageFactory.getTempDir(), 
1:                     "T" + identity.getContainerId() + ".tmp"));
1:         }
1: 		else 
1:         {
1: 			if (SanityManager.DEBUG)
1: 				SanityManager.THROWASSERT(
1:                     "cannot create stream container in non-temp segments yet.");
1: 
1: 			StorageFile container = dataFactory.getContainerPath( identity, false);
1: 
0: 			if (!container.exists()) 
1:             {
1: 
1: 				if (!forCreate)
1: 					return null;
1: 
1: 				StorageFile directory = container.getParentDir();
1: 
0: 				if (!directory.exists()) 
1:                 {
1: 					// make sure only 1 thread can create a segment at one time
1: 					synchronized(dataFactory) 
1:                     {
0: 						if (!directory.exists()) 
1:                         {
0: 							if (!directory.mkdirs()) 
1:                             {
1: 								if (errorOK)
1: 									return null;
1: 								else
1: 									throw StandardException.newException(
1:                                             SQLState.FILE_CANNOT_CREATE_SEGMENT,
0:                                             directory);
1: 							}
1: 						}
1: 					}
1: 				}
1: 			}
1: 			return container;
1: 		}
1: 	}
1: }
author:Ken Coar
-------------------------------------------------------------------------------
commit:95e7b46
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.store.raw.data
0:    (C) Copyright IBM Corp. 1999, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
0: 
0:  */
0: 
0: package org.apache.derby.impl.store.raw.data;
0: 
0: import org.apache.derby.iapi.reference.SQLState;
0: 
0: import org.apache.derby.iapi.services.context.ContextService;
0: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
0: import org.apache.derby.iapi.services.io.Storable;
0: import org.apache.derby.iapi.services.io.StreamStorable;
0: import org.apache.derby.iapi.services.io.FormatIdInputStream;
0: import org.apache.derby.iapi.services.io.FormatIdOutputStream;
0: import org.apache.derby.iapi.services.io.FormatIdUtil;
0: import org.apache.derby.iapi.services.io.StoredFormatIds;
0: import org.apache.derby.iapi.services.io.TypedFormat;
0: import org.apache.derby.iapi.services.monitor.Monitor;
0: 
0: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.store.access.AccessFactory;
0: import org.apache.derby.iapi.store.access.RowSource;
0: import org.apache.derby.iapi.store.access.RowUtil;
0: import org.apache.derby.iapi.store.access.TransactionController;
0: import org.apache.derby.iapi.store.raw.ContainerKey;
0: import org.apache.derby.iapi.store.raw.RawStoreFactory;
0: import org.apache.derby.iapi.store.raw.StreamContainerHandle;
0: 
0: import org.apache.derby.io.StorageFactory;
0: import org.apache.derby.io.WritableStorageFactory;
0: import org.apache.derby.io.StorageFile;
0: 
0: import org.apache.derby.impl.store.raw.data.DecryptInputStream;
0: import org.apache.derby.impl.store.raw.data.StoredFieldHeader;
0: import org.apache.derby.impl.store.raw.data.StoredRecordHeader;
0: 
0: import org.apache.derby.iapi.services.io.ArrayInputStream;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
0: import org.apache.derby.iapi.services.io.CompressedNumber;
0: import org.apache.derby.iapi.services.io.DynamicByteArrayOutputStream;
0: import org.apache.derby.iapi.services.io.LimitInputStream;
0: import org.apache.derby.iapi.services.property.PropertyUtil;
0: 
0: import java.util.Properties;
0: import java.io.InputStream;
0: import java.io.BufferedInputStream;
0: import java.io.OutputStream;
0: import java.io.IOException;
0: import java.io.EOFException;
0: import java.io.InvalidClassException;
0: import java.io.Externalizable;
0: 
0: /**
0: 
0:   The format of this stream file is:
0:   (RH) (FH) (field data) (FH) (field data) ........ (FH) (field data)
0: 
0:   Record header is stored once at the beginning of the file
0:   for all the rows stored in this file.
0:   Record Header indicates how many fields are in each row.
0:   Then we just stored all the column from each row.
0:   Field header stored on this file is fixed size with fieldDataLength
0:   size set to LARGE_SLOT_SIZE (4) bytes.
0: 
0:   NOTE: No locks are used in this container.  All transaction are not logged.
0: 
0: **/
0: 
0: 
0: public class StreamFileContainer implements TypedFormat
0: {
0: 	/**
0: 		IBM Copyright &copy notice.
0: 	*/
0:  
0:     private static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1999_2004;
0: 
0:     /**************************************************************************
0:      * Constant Fields of the class
0:      **************************************************************************
0:      */
0: 
0: 	/*
0: 	 * typed format
0: 	 * format Id must fit in 4 bytes
0: 	 */
0: 	protected static int formatIdInteger = 
0:         StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE; 
0: 
0: 
0:     // 4 bytes for field data length
0: 	protected static final int LARGE_SLOT_SIZE = 4;	
0: 
0: 	protected static final int MIN_BUFFER_SIZE = 
0:         RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM;
0: 	protected static final int FIELD_STATUS = 
0:         StoredFieldHeader.setFixed(StoredFieldHeader.setInitial(), true);
0: 	protected static final int FIELD_HEADER_SIZE = 
0:         StoredFieldHeader.size(FIELD_STATUS, 0, LARGE_SLOT_SIZE);
0: 
0: 
0:     /**************************************************************************
0:      * Fields of the class
0:      **************************************************************************
0:      */
0: 	protected   ContainerKey          identity;
0: 	private   BaseDataFileFactory   dataFactory;  // the factory that made me
0: 
0: 	private int                             bufferSize;
0: 
0: 	private StorageFile file;
0: 
0: 	private OutputStream                fileOut;
0: 	private DynamicByteArrayOutputStream    out;
0: 	private FormatIdOutputStream            logicalDataOut;
0: 
0: 	private InputStream                 fileIn;
0: 	private BufferedInputStream             bufferedIn;
0: 	private DecryptInputStream              decryptIn;
0: 	private LimitInputStream                limitIn;
0: 	private FormatIdInputStream             logicalDataIn;
0: 
0: 	private StoredRecordHeader              recordHeader;
0: 
0: 	private byte[]                          ciphertext;
0: 	private byte[]                          zeroBytes;	// in case encryption
0:                                                         // stream needs pad.
0: 
0:     /**************************************************************************
0:      * Constructors for This class:
0:      **************************************************************************
0:      */
0: 
0:     /**
0:      * Constructor.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	StreamFileContainer(
0:     ContainerKey        identity, 
0:     BaseDataFileFactory dataFactory)
0: 		throws StandardException 
0:     {
0: 		this.identity = identity;
0: 		this.dataFactory = dataFactory;
0: 	}
0: 
0:     /**
0:      * Constructor
0:      * <p>
0:      * when rowSource is passed to the constructor, it will be loaded into the 
0:      * container after the container has been created.
0:      * <p>
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	StreamFileContainer(
0:     ContainerKey        identity, 
0:     BaseDataFileFactory dataFactory,
0:     Properties          prop)
0: 		throws StandardException 
0:     {
0: 		this.identity       = identity;
0: 		this.dataFactory    = dataFactory;
0: 
0: 		try 
0:         {
0: 			file = getFileName(identity, true, false);
0: 
0:             if (file.exists()) 
0:             {
0: 				// note I'm left in the no-identity state as fillInIdentity()
0:                 // hasn't been called.
0: 				throw StandardException.newException(
0:                         SQLState.FILE_EXISTS, file);
0: 			}
0: 
0: 			// get the properties to set buffer size
0: 			// derby.storage.streamFileBufferSize
0: 			getContainerProperties(prop);
0: 
0: 		} 
0:         catch (SecurityException se) 
0:         {
0: 			throw StandardException.newException(
0:                     SQLState.FILE_CREATE, se, file);
0: 		}
0: 	}
0: 
0:     /**************************************************************************
0:      * Private/Protected methods of This class:
0:      **************************************************************************
0:      */
0: 
0:     /**
0:      * Open a stream file container.
0:      * <p>
0:      * Open a container. Open the file that maps to this container, if the
0:      * file does not exist then we assume the container was never created
0:      * and return.
0:      * If the file exists but we have trouble opening it then we throw some 
0:      * exception.
0:      * <p>
0:      *
0: 	 * @return The opened StreamFileContainer.
0:      *
0:      * @param forUpdate     Currently only accepts false, updating and existing
0:      *                      stream file container is not currently supported.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	protected StreamFileContainer open(boolean forUpdate) 
0:         throws StandardException 
0:     {
0: 
0: 		file = getFileName(this.identity, false, true);
0:         if (!file.exists())
0: 			return null;
0: 
0: 		try 
0:         {
0: 			if (!forUpdate) 
0:             {
0: 				fileIn = file.getInputStream();
0: 
0: 				if (dataFactory.databaseEncrypted()) 
0:                 {
0: 					// if the database is encrypted, when reading the data back
0:                     // from the file stream, we need to used the decrypt stream
0:                     // to buffer up the bytes for reading.  DecryptInputStream 
0:                     // also decrypts the data.
0: 
0: 					MemByteHolder byteHolder = 
0:                         new MemByteHolder(
0:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
0: 
0: 					decryptIn = 
0:                         new DecryptInputStream(fileIn, byteHolder, dataFactory);
0: 
0: 					limitIn = new LimitInputStream(decryptIn);
0: 				} 
0:                 else 
0:                 {
0: 					bufferedIn = 
0:                         new BufferedInputStream(
0:                             fileIn, 
0:                             RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
0: 
0: 					limitIn = new LimitInputStream(bufferedIn);
0: 				}
0: 
0: 				// the logicalDataIn input stream is on top of a limit Input
0: 				// stream, use a limit stream to make sure we don't read off
0: 				// more then what each column says it contains
0: 
0: 				logicalDataIn = new FormatIdInputStream(limitIn);
0: 
0: 				// get the record header
0: 				recordHeader = new StoredRecordHeader();
0: 				recordHeader.read(logicalDataIn);
0: 
0: 			} 
0:             else 
0:             {
0: 				if (SanityManager.DEBUG)
0: 					SanityManager.THROWASSERT(
0:                         "updating existing stream container not supported yet");
0: 
0: 				return null;
0: 			}
0: 		} 
0:         catch (IOException ioe) 
0:         {
0: 			throw StandardException.newException(
0:                     SQLState.FILE_CREATE, ioe, file);
0: 		}
0: 
0: 		return this;
0: 	}
0: 
0:     /**
0:      * Close the stream file.
0:      * <p>
0:      * Close this stream file, and all streams associated with it.
0:      * <p>
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	protected void close()
0:     {
0: 		try 
0:         {
0: 
0: 			if (fileIn != null) 
0:             {
0: 				fileIn.close();
0: 				fileIn = null;
0: 				if (dataFactory.databaseEncrypted()) 
0:                 {
0: 					decryptIn.close();
0: 					decryptIn = null;
0: 				} 
0:                 else 
0:                 {
0: 					bufferedIn.close();
0: 					bufferedIn = null;
0: 				}
0: 				logicalDataIn.close();
0: 				logicalDataIn = null;
0: 			}
0: 
0: 			if (fileOut != null) 
0:             {
0: 				fileOut.close();
0: 				logicalDataOut.close();
0: 				fileOut = null;
0: 				logicalDataOut = null;
0: 				out = null;
0: 			}
0: 
0: 		} 
0:         catch (IOException ioe) 
0:         {
0:             // ignore close errors from fileOut.close() and fileIn.close() - 
0:             // there isn't much we can do about them anyway - and some of the
0:             // interfaces don't want to deal with exceptions from close().
0: 
0:             /*
0: 			throw StandardException.newException(
0:                     SQLState.FILE_CREATE, ioe, file);
0:             */
0: 		}
0: 	}
0: 
0:     /**************************************************************************
0:      * Public Methods of This class:
0:      **************************************************************************
0:      */
0: 
0:     /**
0:      * Return my format identifier.
0:      **/
0: 	public int getTypeFormatId() 
0:     {
0: 		return StoredFormatIds.RAW_STORE_SINGLE_CONTAINER_STREAM_FILE;
0: 	}
0: 
0:     /**
0:      * Request the system properties associated with a stream container. 
0:      * <p>
0:      * Request the value of properties associated with a stream container. 
0:      * The following properties can be requested:
0:      *     derby.storage.streamFileBufferSize
0: 	 *
0:      * <p>
0:      * To get the value of a particular property add it to the property list,
0:      * and on return the value of the property will be set to it's current 
0:      * value.  For example:
0:      *
0:      * get_prop(ConglomerateController cc)
0:      * {
0:      *     Properties prop = new Properties();
0:      *     prop.put("derby.storage.streamFileBufferSize", "");
0:      *     cc.getContainerProperties(prop);
0:      *
0:      *     System.out.println(
0:      *         "stream table's buffer size = " + 
0:      *         prop.getProperty("derby.storage.streamFileBufferSize");
0:      * }
0:      *
0:      * @param prop   Property list to fill in.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0:     public void getContainerProperties(Properties prop) 
0:         throws StandardException 
0:     {
0: 
0: 		AccessFactory af = (AccessFactory)
0: 			Monitor.getServiceModule(dataFactory, AccessFactory.MODULE);
0: 
0: 		TransactionController tc = 
0:             (af == null) ? 
0:                 null : 
0:                 af.getTransaction(
0:                     ContextService.getFactory().getCurrentContextManager());
0: 
0: 		bufferSize = 
0: 			PropertyUtil.getServiceInt(tc, prop,
0: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_PARAMETER,  
0: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MINIMUM, 
0: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_MAXIMUM,
0: 				RawStoreFactory.STREAM_FILE_BUFFER_SIZE_DEFAULT);
0: 	}
0: 
0:     /**
0:      * Request the container key associated with the stream container. 
0: 	 **/
0: 	public ContainerKey getIdentity() 
0:     {
0: 		return this.identity;
0: 	}
0: 
0:     /**
0:      * Can I use this container?
0:      * <p>
0:      * This method always return true right now.
0:      * In the future when there are different uses for this container,
0:      * we may need to add qualifications for this.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	protected boolean use(StreamContainerHandle handle) 
0:         throws StandardException 
0:     {
0: 		return true;
0: 	}
0: 
0:     /**
0:      * load data into this container.
0:      * <p>
0:      * populate the stream container with data in the rowSource
0:      * <p>
0:      *
0:      * @param rowSource The row source to get rows to load into this container.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	public void load(RowSource rowSource) 
0:         throws StandardException 
0:     {
0: 		// use this output stream to buffer rows before inserting into file.
0: 		out                 = new DynamicByteArrayOutputStream(bufferSize);
0: 		logicalDataOut      = new FormatIdOutputStream(out);
0: 		boolean encrypted   = dataFactory.databaseEncrypted();
0: 
0: 		// reserve the first dataFactory.getEncryptionBlockSize() - 1 bytes, if the database is 
0:         // encrypted These reserved bytes will be used to pad the byte array if
0:         // it is not dataFactory.getEncryptionBlockSize() aligned.
0: 		if (encrypted) 
0:         {
0: 			if (zeroBytes == null)
0: 				zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
0: 
0: 			out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
0: 		}
0: 
0: 		try 
0:         {
0: 			fileOut = file.getOutputStream();
0: 
0: 			FormatableBitSet validColumns = rowSource.getValidColumns();
0: 
0: 			Object[] row = rowSource.getNextRowFromRowSource();
0: 
0: 			int numberFields = 0;
0: 			if (validColumns != null) 
0:             {
0: 				for (int i = validColumns.getLength() - 1; i >= 0; i--) 
0:                 {
0: 					if (validColumns.isSet(i)) 
0:                     {
0: 						numberFields = i + 1;
0: 						break;
0: 					}
0: 				}
0: 			} 
0:             else 
0:             {
0: 				numberFields = row.length;
0: 			}
0: 
0: 			// make the record header to have 0 record id
0: 			recordHeader = new StoredRecordHeader(0, numberFields);
0: 
0: 			// write the record header once for all the rows, directly to the 
0:             // beginning of the file.
0: 			int rhLen = recordHeader.write(out);
0: 
0: 			int validColumnsSize = 
0:                 validColumns == null ? 0 : validColumns.getLength();
0: 
0: 			while (row != null) 
0:             {
0: 
0: 				int arrayPosition = -1;
0: 
0: 				for (int i = 0; i < numberFields; i++) 
0:                 {
0: 
0: 					// write each column out
0: 					if (validColumns == null) 
0:                     {
0: 						arrayPosition++;
0: 						Object column = row[arrayPosition];
0: 						writeColumn(column);
0: 					} 
0:                     else 
0:                     {
0: 
0: 						if (validColumnsSize > i && validColumns.isSet(i)) 
0:                         {
0: 							arrayPosition++;
0: 							Object column = row[arrayPosition];
0: 							writeColumn(column);
0: 						} 
0:                         else 
0:                         {
0: 							// it is a non-existent column
0: 							writeColumn(null);
0: 						}
0: 					}
0: 
0: 					// put the buffer onto the page, only if it exceeded the 
0:                     // original buffer size or it has less than 100 bytes left 
0:                     // in the buffer
0: 					if ((out.getUsed() >= bufferSize) || 
0:                         ((bufferSize - out.getUsed()) < MIN_BUFFER_SIZE)) 
0:                     {
0: 						writeToFile();
0: 					}
0: 				}
0: 
0: 				// get the next row and its valid columns from the rowSource
0: 				row = rowSource.getNextRowFromRowSource();
0: 			}
0: 
0: 
0: 			// Write the buffer to the file if there is something in the output
0: 			// buffer.  Remember we pad the output buffer with
0: 			// dataFactory.getEncryptionBlockSize() - 1 if this is an encypted database
0: 			if (encrypted)
0: 			{
0: 				if (out.getUsed() > (dataFactory.getEncryptionBlockSize() - 1))
0: 					writeToFile();
0: 			}
0: 			else if (out.getUsed() > 0) 
0:             {
0: 				writeToFile();
0: 			}
0: 
0: 		} 
0:         catch (IOException ioe) 
0:         {
0: 			// handle IO error...
0: 			throw StandardException.newException(
0:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
0: 
0: 		}
0:         finally 
0:         {
0: 			close();
0: 		}
0: 	}
0: 
0: 	/*
0: 
0: 	 */
0:     /**
0:      * Write the buffer to the file.
0:      * <p>
0:      * If the database is encrypted, the dataFactory.getEncryptionBlockSize() - 1 reserved bytes will
0:      * be used to pad the byte array to be dataFactory.getEncryptionBlockSize()
0:      * aligned.  Before the bytes are encrypted and written to the file stream,
0:      * the actual length of the byte array is written out as a compressed 
0:      * integer.  This number will be used when decrypting the data.
0:      *
0:      * If the database is not encrypted, then, we don't reserve the bytes 
0:      * upfront, and we simple just write the bytes out to the file stream.
0:      *
0: 	 * @exception  StandardException  Standard exception policy.
0:      **/
0: 	private void writeToFile() 
0:         throws StandardException 
0:     {
0: 
0: 		try
0:         {
0: 			if (dataFactory.databaseEncrypted()) 
0:             {
0: 				// if db is encrypted, 
0:                 // use the first ENCRYPTION_ALIGN bytes for padding.
0:                 //
0: 				int realLen = out.getUsed() - (dataFactory.getEncryptionBlockSize() - 1);
0: 				int tail = realLen % dataFactory.getEncryptionBlockSize();
0: 				int padding = 
0:                     (tail == 0) ? 0 : 
0:                     (dataFactory.getEncryptionBlockSize() - tail);
0: 
0: 				int startByte = (tail == 0) ? (dataFactory.getEncryptionBlockSize() - 1) : (tail - 1);
0: 				int encryptedLen = realLen + padding;
0: 
0: 				// there is nothing to write, just the encryption padding
0: 				if (realLen <= 0)
0: 					return;
0: 
0: 				if (ciphertext == null)
0:                 {
0: 					ciphertext = new byte[encryptedLen];
0:                 }
0: 				else 
0:                 {
0: 					if (ciphertext.length < encryptedLen)
0: 						ciphertext = new byte[encryptedLen];
0: 				}
0: 
0: 				dataFactory.encrypt(
0:                     out.getByteArray(), startByte, encryptedLen, ciphertext, 0);
0: 
0: 				// write out the actual length, then the encrypted bytes.
0: 				CompressedNumber.writeInt(fileOut, realLen);
0: 				dataFactory.writeInProgress();
0: 				try
0: 				{
0: 					fileOut.write(ciphertext, 0, encryptedLen);
0: 				}
0: 				finally
0: 				{
0: 					dataFactory.writeFinished();
0: 				}
0: 
0: 				// reset the dynamic buffer
0: 				out.reset();
0: 
0: 				// reserve bytes if database is encrypted.
0: 				if (dataFactory.databaseEncrypted())
0:                 {
0: 					if (zeroBytes == null)
0: 						zeroBytes = new byte[dataFactory.getEncryptionBlockSize() - 1];
0: 
0: 					out.write(zeroBytes, 0, dataFactory.getEncryptionBlockSize() - 1);
0: 				}
0: 
0: 			} 
0:             else 
0:             {
0: 				// nothing to write
0: 				if (out.getUsed() == 0)
0: 					return;
0: 
0: 				dataFactory.writeInProgress();
0: 				try
0: 				{
0: 					fileOut.write(out.getByteArray(), 0, out.getUsed());
0: 				}
0: 				finally
0: 				{
0: 					dataFactory.writeFinished();
0: 				}
0: 
0: 				// reset the dynamic buffer
0: 				out.reset();
0: 			}
0: 		} 
0:         catch (IOException ioe) 
0:         {
0: 			throw StandardException.newException(
0:                     SQLState.DATA_UNEXPECTED_EXCEPTION, ioe);
0: 		}
0: 	}
0: 
0: 	private void writeColumn(Object column) 
0:         throws StandardException, IOException 
0:     {
0: 
0: 		int fieldStatus = FIELD_STATUS;
0: 		if (column == null) 
0:         {
0: 			// just write a non-existent header.
0: 			fieldStatus = StoredFieldHeader.setNonexistent(fieldStatus);
0: 			StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
0: 			return;
0: 		}
0: 
0: 		// if the column is a null column, write the field header now.
0: 		if (column instanceof Storable) 
0:         {
0: 			Storable sColumn = (Storable) column;
0: 			if (sColumn.isNull()) 
0:             {
0: 				fieldStatus = StoredFieldHeader.setNull(fieldStatus, true);
0: 				StoredFieldHeader.write(out, fieldStatus, 0, LARGE_SLOT_SIZE);
0: 				return;
0: 			}
0: 		}
0: 
0: 		int beginPosition = out.getPosition();
0: 		int fieldDataLength = 0;
0: 
0: 		// write out the header, mostly to reserve the space
0: 		StoredFieldHeader.write(
0:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
0: 
0: 		if (column instanceof StreamStorable) 
0:         {
0: 			if (((StreamStorable) column).returnStream() != null) 
0:             {
0: 				column = (InputStream) ((StreamStorable) column).returnStream();
0: 			}
0: 		}
0: 
0: 		if (column instanceof InputStream) 
0:         {
0: 			InputStream inColumn = (InputStream) column;
0: 			int bufferLen = inColumn.available();
0: 			byte[] bufData = new byte[bufferLen];
0: 
0: 			do 
0:             {
0: 				int lenRead = inColumn.read(bufData, bufferLen, 0);
0: 				if (lenRead != -1) 
0:                 {
0: 					fieldDataLength += lenRead;
0: 					out.write(bufData, lenRead, 0);
0: 				} 
0:                 else
0:                 {
0: 					break; 
0:                 }
0: 			} while (true);
0: 
0: 		} 
0:         else if (column instanceof Storable) 
0:         {
0: 
0: 			Storable sColumn = (Storable) column;
0: 			// write field data to the stream, we already handled the null case
0:             
0: 			sColumn.writeExternal(logicalDataOut);
0: 			fieldDataLength = 
0:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
0: 
0: 		} 
0:         else 
0:         {
0: 			// Serializable/Externalizable/Formattable
0: 			// all look the same at this point.
0: 			logicalDataOut.writeObject(column);
0: 			fieldDataLength = 
0:                 out.getPosition() - beginPosition - FIELD_HEADER_SIZE;
0: 		}
0: 
0: 		// Now we go back to update the fieldDataLength in the field header
0: 		int endPosition = out.getPosition();
0: 		out.setPosition(beginPosition);
0: 
0: 		StoredFieldHeader.write(
0:             out, fieldStatus, fieldDataLength, LARGE_SLOT_SIZE);
0: 
0: 		// set position to the end of the field
0: 		if (!StoredFieldHeader.isNull(fieldStatus))
0: 			out.setPosition(endPosition);
0: 	}
0: 
0: 	public boolean fetchNext(Object[] row) 
0:         throws StandardException 
0:     {
0: 
0: 		boolean inUserCode = false;
0: 		int columnId = 0;
0: 		
0: 		try	
0:         {
0: 
0: 			// Get the number of columns in the row.
0: 			int numberFields = recordHeader.getNumberFields();
0: 
0: 			int arrayPosition = 0;
0: 			for (columnId = 0; columnId < numberFields; columnId++) 
0:             {
0: 
0: 				if (arrayPosition >= row.length)
0: 					break;
0: 	
0: 				limitIn.clearLimit();
0: 
0: 				// read the field header
0: 				int fieldStatus = StoredFieldHeader.readStatus(logicalDataIn);
0: 				int fieldDataLength = StoredFieldHeader.readFieldDataLength(
0: 					logicalDataIn, fieldStatus, LARGE_SLOT_SIZE);
0: 
0: 				limitIn.setLimit(fieldDataLength);
0: 
0: 				if (SanityManager.DEBUG) 
0:                 {
0: 
0:                     if (StoredFieldHeader.isExtensible(fieldStatus))
0:                     {
0:                         SanityManager.THROWASSERT(
0:                             "extensible fields not supported yet.  columnId = "
0:                             + columnId);
0:                     }
0: 
0: 					SanityManager.ASSERT(!StoredFieldHeader.isOverflow(fieldStatus),
0: 						"overflow field is not supported yet");
0: 				}
0: 
0: 				Object column = row[arrayPosition];
0: 				
0: 				// Deal with Storable columns
0: 				if (StoredFieldHeader.isNullable(fieldStatus)) 
0:                 {
0: 									
0: 					if (column == null)
0:                     {
0: 						throw StandardException.newException(
0:                                 SQLState.DATA_NULL_STORABLE_COLUMN, 
0:                                 Integer.toString(columnId));
0:                     }
0: 
0: 					// SRW-DJD RESOLVE: - fix error message
0: 					if (!(column instanceof Storable)) 
0:                     {
0: 						throw StandardException.newException(
0:                             SQLState.DATA_NULL_STORABLE_COLUMN, 
0:                             column.getClass().getName());
0: 					}
0: 
0: 					Storable sColumn = (Storable) column;
0: 
0: 					// is the column null ?
0: 					if (StoredFieldHeader.isNull(fieldStatus)) 
0:                     {
0: 
0: 						sColumn.restoreToNull();
0: 						arrayPosition++;
0: 						continue;
0: 					}
0: 
0: 					inUserCode = true;
0: 					sColumn.readExternal(logicalDataIn);
0: 					inUserCode = false;
0: 					arrayPosition++;
0: 					continue;
0: 				}
0: 
0: 				// Only Storables can be null ... SRW-DJD RESOLVE: - fix error message
0: 				if (StoredFieldHeader.isNull(fieldStatus))
0:                 {
0: 					throw StandardException.newException(
0:                         SQLState.DATA_NULL_STORABLE_COLUMN, 
0:                         Integer.toString(columnId));
0:                 }
0: 
0: 				// This is a non-extensible field, which means the caller must 
0:                 // know the correct type and thus the element in row is the 
0:                 // correct type or null. If the element implements 
0:                 // Externalizable then we can just fill it in, otherwise it 
0:                 // must be Serializable and we have to throw it away.
0: 
0: 				Object neColumn = row[arrayPosition];
0: 
0: 				if (neColumn instanceof Externalizable) 
0:                 {
0: 
0: 					Externalizable exColumn = (Externalizable) neColumn;
0: 
0: 					inUserCode = true;
0: 					exColumn.readExternal(logicalDataIn);
0: 					inUserCode = false;
0: 
0: 					arrayPosition++;
0: 					continue;
0: 				}
0: 
0: 				// neColumn will be ignored
0: 				neColumn = null;
0: 				inUserCode = true;
0: 				row[arrayPosition] = logicalDataIn.readObject();
0: 				inUserCode = false;
0: 
0: 				arrayPosition++;
0: 				continue;
0: 			}
0: 
0: 		} 
0:         catch (IOException ioe) 
0:         {
0: 
0: 			// an exception during the restore of a user column, this doesn't
0: 			// make the databse corrupt, just that this field is inaccessable
0: 			if (inUserCode) 
0:             { 
0: 
0: 				if (ioe instanceof EOFException) 
0:                 {
0: 					throw StandardException.newException(
0:                         SQLState.DATA_STORABLE_READ_MISMATCH, 
0:                         ioe, logicalDataIn.getErrorInfo());
0: 				}
0: 
0: 				throw StandardException.newException(
0:                     SQLState.DATA_STORABLE_READ_EXCEPTION, 
0:                     ioe, logicalDataIn.getErrorInfo());
0: 			}
0: 
0: 			if (ioe instanceof InvalidClassException)
0:             {
0: 				throw StandardException.newException(
0:                         SQLState.DATA_STORABLE_READ_EXCEPTION, 
0:                         ioe, logicalDataIn.getErrorInfo());
0:    			}
0: 
0: 			// If we are at the end of the file, trying to fetch the first 
0:             // column, then we know there is no more rows to fetch
0: 			if ((ioe instanceof EOFException) && (columnId == 0)) 
0:             {
0: 				close();
0: 				return false;
0: 			}
0: 
0: 			throw dataFactory.markCorrupt(
0:                 StandardException.newException(
0:                     SQLState.DATA_CORRUPT_STREAM_CONTAINER, ioe, identity));
0: 
0: 		} 
0:         catch (ClassNotFoundException cnfe) 
0:         {
0: 
0: 			if (SanityManager.DEBUG) 
0:             {
0: 				SanityManager.ASSERT(inUserCode);
0: 			}
0: 
0: 			// an exception during the restore of a user column, this doesn't
0: 			// make the databse corrupt, just that this field is inaccessable
0: 			throw StandardException.newException(
0:                 SQLState.DATA_STORABLE_READ_MISSING_CLASS, cnfe, 
0:                 logicalDataIn.getErrorInfo());
0: 
0: 		} 
0:         catch (LinkageError le) 
0:         {
0: 			if (inUserCode)
0:             {
0: 				throw StandardException.newException(
0:                     SQLState.DATA_STORABLE_READ_EXCEPTION, le,
0:                     logicalDataIn.getErrorInfo());
0:             }
0: 			throw le;
0: 		}
0: 
0: 		return true;
0: 
0: 	}
0: 
0:     /**
0:      * Close the stream file and remove the file.
0:      *
0:      * @exception StandardException Segment directory cannot be created
0:      **/
0: 	public boolean removeContainer() 
0:         throws StandardException 
0:     {
0: 		close();
0: 
0:         if (file.exists())
0:         {
0:             return file.delete();
0:         }
0:         else
0:         {
0:             return true;
0:         }
0: 
0: 
0: 	}
0: 
0:     /**
0:      * Return a file name for the identity.
0:      * <p>
0:      * Return a valid file name for the identity, or null if the data
0:      * directory for this segment cannot be created
0:      *
0: 	 * @exception StandardException Segment directory cannot be created
0:      **/
0: 	protected StorageFile getFileName(
0:     ContainerKey    identity, 
0:     boolean         forCreate, 
0:     boolean         errorOK)
0: 		 throws StandardException 
0:     {
0: 		if (identity.getSegmentId() == StreamContainerHandle.TEMPORARY_SEGMENT)
0:         {
0: 			return( dataFactory.storageFactory.newStorageFile( dataFactory.storageFactory.getTempDir(), 
0:                     "T" + identity.getContainerId() + ".tmp"));
0:         }
0: 		else 
0:         {
0: 			if (SanityManager.DEBUG)
0: 				SanityManager.THROWASSERT(
0:                     "cannot create stream container in non-temp segments yet.");
0: 
0: 			StorageFile container = dataFactory.getContainerPath( identity, false);
0: 
0: 			if (!container.exists()) 
0:             {
0: 
0: 				if (!forCreate)
0: 					return null;
0: 
0: 				StorageFile directory = container.getParentDir();
0: 
0: 				if (!directory.exists()) 
0:                 {
0: 					// make sure only 1 thread can create a segment at one time
0: 					synchronized(dataFactory) 
0:                     {
0: 						if (!directory.exists()) 
0:                         {
0: 							if (!directory.mkdirs()) 
0:                             {
0: 								if (errorOK)
0: 									return null;
0: 								else
0: 									throw StandardException.newException(
0:                                             SQLState.FILE_CANNOT_CREATE_SEGMENT,
0:                                             directory);
0: 							}
0: 						}
0: 					}
0: 				}
0: 			}
0: 			return container;
0: 		}
0: 	}
0: }
============================================================================
1:d847ced: /*
52:d847ced: 
1:fbf176c:    Class org.apache.derby.optional.lucene.LuceneSupport
1:d847ced: 
1:d847ced:    Licensed to the Apache Software Foundation (ASF) under one or more
1:d847ced:    contributor license agreements.  See the NOTICE file distributed with
1:d847ced:    this work for additional information regarding copyright ownership.
1:d847ced:    The ASF licenses this file to You under the Apache License, Version 2.0
1:d847ced:    (the "License"); you may not use this file except in compliance with
1:d847ced:    the License.  You may obtain a copy of the License at
1:d847ced: 
1:d847ced:       http://www.apache.org/licenses/LICENSE-2.0
1:d847ced: 
1:d847ced:    Unless required by applicable law or agreed to in writing, software
1:d847ced:    distributed under the License is distributed on an "AS IS" BASIS,
1:d847ced:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:d847ced:    See the License for the specific language governing permissions and
1:d847ced:    limitations under the License.
1:d847ced: 
10:d847ced: */
1:d847ced: 
1:fbf176c: package org.apache.derby.optional.lucene;
1:d847ced: 
1:5cf7a46: import java.io.InputStream;
1:5cf7a46: import java.io.OutputStream;
1:d847ced: import java.io.IOException;
1:2277df2: import java.lang.reflect.InvocationTargetException;
1:2277df2: import java.lang.reflect.Method;
1:d847ced: import java.security.AccessController;
1:7234498: import java.security.PrivilegedAction;
1:d847ced: import java.security.PrivilegedActionException;
1:d847ced: import java.security.PrivilegedExceptionAction;
1:d847ced: import java.sql.Connection;
1:d847ced: import java.sql.DatabaseMetaData;
1:d847ced: import java.sql.Date;
1:d847ced: import java.sql.DriverManager;
1:d847ced: import java.sql.PreparedStatement;
1:d847ced: import java.sql.ResultSet;
1:d847ced: import java.sql.ResultSetMetaData;
1:d847ced: import java.sql.SQLException;
1:d847ced: import java.sql.Time;
1:d847ced: import java.sql.Timestamp;
1:d847ced: import java.sql.Types;
1:d847ced: import java.util.Arrays;
1:d847ced: import java.util.ArrayList;
1:7e538ec: import java.util.HashSet;
1:2277df2: import java.util.Properties;
1:d847ced: 
1:502ed2e: import org.apache.derby.database.Database;
1:2a8df97: import org.apache.derby.iapi.sql.conn.ConnectionUtil;
1:96e2ea4: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
1:d847ced: import org.apache.derby.iapi.sql.dictionary.OptionalTool;
1:d847ced: import org.apache.derby.iapi.error.StandardException;
1:5cf7a46: import org.apache.derby.iapi.reference.Property;
1:a409436: import org.apache.derby.iapi.services.loader.ClassFactory;
1:a409436: import org.apache.derby.iapi.services.loader.ClassInspector;
1:5cf7a46: import org.apache.derby.iapi.services.monitor.Monitor;
1:5cf7a46: import org.apache.derby.iapi.store.raw.data.DataFactory;
1:d847ced: import org.apache.derby.iapi.util.IdUtil;
1:d847ced: import org.apache.derby.impl.jdbc.EmbedConnection;
1:5cf7a46: import org.apache.derby.io.StorageFactory;
1:5cf7a46: import org.apache.derby.io.StorageFile;
1:d847ced: import org.apache.derby.shared.common.reference.SQLState;
1:a4e6298: import org.apache.derby.optional.api.LuceneIndexDescriptor;
1:fbf176c: import org.apache.derby.optional.api.LuceneUtils;
1:6b8ad38: import org.apache.derby.optional.utils.ToolUtilities;
1:d847ced: import org.apache.derby.vti.VTITemplate;
1:d847ced: 
1:d847ced: import org.apache.lucene.analysis.Analyzer;
1:d847ced: import org.apache.lucene.document.Document;
1:d847ced: import org.apache.lucene.document.Field.Store;
1:d847ced: import org.apache.lucene.document.StoredField;
1:d847ced: import org.apache.lucene.document.StringField;
1:d847ced: import org.apache.lucene.document.TextField;
1:d847ced: import org.apache.lucene.index.IndexableField;
1:d847ced: import org.apache.lucene.index.IndexWriter;
1:d847ced: import org.apache.lucene.index.IndexWriterConfig;
1:d847ced: import org.apache.lucene.queryparser.classic.ParseException;
1:d847ced: import org.apache.lucene.util.BytesRef;
1:d847ced: import org.apache.lucene.util.Version;
1:d847ced: 
10:d847ced: /**
1:d847ced:  * Support for creating, updating, and querying Lucene
1:d847ced:  * indexes in Derby, and associated utility functions.
3:d847ced:  * 
1:d847ced:  */
1:d847ced: public class LuceneSupport implements OptionalTool
46:d847ced: {
1:d847ced:     private static  final   String  LUCENE_SCHEMA = "LuceneSupport";
1:d847ced:     private static  final   String  LIST_INDEXES = LUCENE_SCHEMA + "." + "listIndexes";
1:d847ced:     private static  final   String  CREATE_INDEX = LUCENE_SCHEMA + "." + "createIndex";
1:d847ced:     private static  final   String  DROP_INDEX = LUCENE_SCHEMA + "." + "dropIndex";
1:d847ced:     private static  final   String  UPDATE_INDEX = LUCENE_SCHEMA + "." + "updateIndex";
1:d847ced:     private static  final   String  SEPARATOR = "__";
1:8fbaf26: 
1:cbdf827:     // names of columns in all query table functions
1:cbdf827:     private static  final   String  SCORE = "SCORE";
1:cbdf827:     private static  final   String  DOCUMENT_ID = "DOCUMENTID";
1:cbdf827: 
1:d847ced:     // for decomposing a function name into the table and column parts
1:d847ced:     static  final   int TABLE_PART = 0;
1:d847ced:     static  final   int COLUMN_PART = TABLE_PART + 1;
1:d847ced:     static  final   int PART_COUNT = COLUMN_PART + 1;
1:2277df2: 
1:2277df2:     // file which holds properties specific to a Lucene index
1:2277df2:     private static  final   String  PROPERTIES_FILE_NAME = "derby-lucene.properties";
1:2277df2: 
1:2277df2:     // properties which go in that file
1:2277df2: 
1:2277df2:     /** property identifying the static method which materializes an Analyzer for the index */
1:a4e6298:     public  static  final   String  INDEX_DESCRIPTOR_MAKER = "derby.lucene.index.descriptor.maker";
1:2277df2: 
1:2277df2:     /** class name of the Analyzer used for the index */
1:2277df2:     public  static  final   String  ANALYZER = "derby.lucene.analyzer";
1:2277df2: 
1:2277df2:     /** version of Lucene used to create or recreate an index */
1:2277df2:     public  static  final   String  LUCENE_VERSION = "derby.lucene.version";
1:2277df2: 	
1:2277df2:     /** system time when the index was created/updated */
1:2277df2:     public  static  final   String  UPDATE_TIMESTAMP = "derby.lucene.last.updated";
1:d847ced: 	
3:d847ced:     /////////////////////////////////////////////////////////////////////
3:d847ced:     //
1:d847ced:     //  OptionalTool BEHAVIOR
1:2277df2:     //
1:2277df2:     /////////////////////////////////////////////////////////////////////
1:2277df2: 
1:2a8df97: 	/**
1:d847ced: 	 * 0-arg constructor as an OptionalTool
1:d847ced: 	 */
1:d847ced: 	public LuceneSupport() {
45:d847ced: 	}
1:5cf7a46: 	
1:a409436: 	/**
1:d847ced: 	 * Load the procedures and functions for Lucene support:
1:d847ced: 	 * In the LuceneSupport schema, these are:
1:d847ced: 	 * listIndexes, createIndex, dropIndex,
1:d847ced: 	 * updateIndex.
1:d847ced: 	 */
1:d847ced: 	public void loadTool(String... configurationParameters) throws SQLException
1:d847ced:     {
1:2a8df97:         forbidReadOnlyConnections();
1:96e2ea4: 
1:96e2ea4:         // not allowed during soft-upgrade
1:96e2ea4:         try {
1:96e2ea4:             ConnectionUtil.getCurrentLCC().getDataDictionary().checkVersion
1:96e2ea4:                 ( DataDictionary.DD_VERSION_DERBY_10_11, "luceneSupport" );
1:96e2ea4:         }
1:6b8ad38:         catch (StandardException se)    { throw ToolUtilities.sqlException( se ); }
1:2a8df97:         
1:d847ced:         Connection  conn = getDefaultConnection();
1:6b8ad38:         ToolUtilities.mustBeDBO( conn );
1:2a8df97: 
1:502ed2e:         //
1:502ed2e:         // Lucene indexes are not allowed in encrypted databases. They leak
1:502ed2e:         // encrypted data in plaintext.
1:502ed2e:         //
1:502ed2e:         if ( getDataFactory( conn ).databaseEncrypted() )
1:502ed2e:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ENCRYPTED_DB );
1:502ed2e:         }
1:502ed2e: 
1:d847ced:         if ( luceneSchemaExists( conn ) )
1:d847ced:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ALREADY_LOADED );
1:d847ced:         }
1:2a8df97: 
1:6b8ad38:         boolean sqlAuthorizationEnabled = ToolUtilities.sqlAuthorizationEnabled( conn );
1:2277df2:         
1:d847ced: 		StringBuilder listFunction = new StringBuilder();
1:d847ced: 		listFunction.append("create function " + LIST_INDEXES );
1:d847ced: 		listFunction.append(" () ");
1:d847ced: 		listFunction.append("returns table");
1:d847ced: 		listFunction.append("(");
1:d847ced: 		listFunction.append("schemaname varchar( 128 ),");
1:d847ced: 		listFunction.append("tablename varchar( 128 ),");
1:d847ced: 		listFunction.append("columnname varchar( 128 ),");
1:2277df2: 		listFunction.append("lastupdated timestamp,");
1:2277df2: 		listFunction.append("luceneversion varchar( 20 ),");
1:2277df2: 		listFunction.append("analyzer varchar( 32672 ),");
1:a4e6298: 		listFunction.append("indexdescriptormaker varchar( 32672 )");
1:d847ced: 		listFunction.append(")");
1:d847ced: 		listFunction.append("language java ");
1:d847ced: 		listFunction.append("parameter style DERBY_JDBC_RESULT_SET ");
1:d847ced: 		listFunction.append("contains sql ");
1:d847ced: 		listFunction.append("external name '" + getClass().getName() + ".listIndexes'");
1:d847ced: 		
1:d847ced: 		executeDDL( conn, listFunction.toString() );
1:d847ced: 		
1:d847ced: 		StringBuilder createProcedure = new StringBuilder();
1:d847ced: 		createProcedure.append("create procedure " + CREATE_INDEX );
1:d847ced: 		createProcedure.append(" (schemaname varchar( 128 ),");
1:d847ced: 		createProcedure.append("tablename varchar( 128 ),");
1:2277df2: 		createProcedure.append("textcolumn varchar( 128 ),");
1:a4e6298: 		createProcedure.append("indexdescriptormaker varchar( 32672 ),");
1:fcf3e6d: 		createProcedure.append("keyColumns varchar( 32672 )...)");
1:fcf3e6d: 		createProcedure.append("parameter style derby modifies sql data language java external name ");
1:d847ced: 		createProcedure.append("'" + getClass().getName() + ".createIndex'");
1:d847ced: 		
1:d847ced: 		executeDDL( conn, createProcedure.toString() );
1:d847ced: 
1:d847ced: 		StringBuilder dropProcedure = new StringBuilder();
1:d847ced: 		dropProcedure.append("create procedure " + DROP_INDEX );
1:d847ced: 		dropProcedure.append(" (schemaname varchar( 128 ),");
1:d847ced: 		dropProcedure.append("tablename varchar( 128 ),");
1:d847ced: 		dropProcedure.append("textcolumn varchar( 128 ))");
1:d847ced: 		dropProcedure.append("parameter style java modifies sql data language java external name ");
1:d847ced: 		dropProcedure.append("'" + getClass().getName() + ".dropIndex'");
1:d847ced: 		
1:d847ced: 		executeDDL( conn, dropProcedure.toString() );
1:d847ced: 
1:d847ced: 		StringBuilder updateProcedure = new StringBuilder();
1:d847ced: 		updateProcedure.append("create procedure " + UPDATE_INDEX );
1:d847ced: 		updateProcedure.append(" (schemaname varchar( 128 ),");
1:d847ced: 		updateProcedure.append("tablename varchar( 128 ),");
1:2277df2: 		updateProcedure.append("textcolumn varchar( 128 ),");
1:a4e6298: 		updateProcedure.append("indexdescriptormaker varchar( 32672 ))");
1:d847ced: 		updateProcedure.append("parameter style java reads sql data language java external name ");
1:d847ced: 		updateProcedure.append("'" + getClass().getName() + ".updateIndex'");
1:d847ced: 		
1:d847ced: 		executeDDL( conn, updateProcedure.toString() );
1:d847ced: 
1:d847ced:         if ( sqlAuthorizationEnabled ) { grantPermissions(); }
1:502ed2e: 
1:502ed2e:         createLuceneDir( conn );
1:d847ced: 	}
1:d847ced: 
1:502ed2e:     /**
1:d847ced:      * Grant permissions to use the newly loaded LuceneSupport routines.
1:d847ced:      */
1:d847ced:     private void    grantPermissions()  throws SQLException
1:d847ced:     {
1:d847ced:         Connection  conn = getDefaultConnection();
1:d847ced: 
1:d847ced:         executeDDL( conn, "grant execute on function " + LIST_INDEXES + " to public" );
1:d847ced:         executeDDL( conn, "grant execute on procedure " + CREATE_INDEX + " to public" );
1:d847ced:         executeDDL( conn, "grant execute on procedure " + DROP_INDEX + " to public" );
1:d847ced:         executeDDL( conn, "grant execute on procedure " + UPDATE_INDEX + " to public" );
1:d847ced:     }
1:d847ced: 
1:fcf3e6d: 	/**
1:d847ced: 	 * Removes the functions and procedures loaded by loadTool and created by createIndex.
1:d847ced:      * Drop the LuceneSupport schema. Drop the lucene subdirectory.
1:d847ced: 	 */
1:d847ced: 	public void unloadTool(String... configurationParameters)
5:d847ced:         throws SQLException
1:d847ced:     {
1:2a8df97:         forbidReadOnlyConnections();
1:2a8df97:         
1:d847ced:         Connection  conn = getDefaultConnection();
1:6b8ad38:         ToolUtilities.mustBeDBO( conn );
1:d847ced: 
1:d847ced:         if ( !luceneSchemaExists( conn ) )
1:d847ced:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ALREADY_UNLOADED );
1:d847ced:         }
1:d847ced: 
1:5cf7a46:         //
1:d847ced:         // Drop all of the functions and procedures bound to methods in this package.
1:d847ced:         //
1:d847ced:         String      className = getClass().getName();
1:d847ced:         int             endPackageIdx = className.lastIndexOf( "." );
1:d847ced:         String      packageName = className.substring( 0, endPackageIdx );
1:5b79ae0:         PreparedStatement   ps = conn.prepareStatement
12:d847ced:             (
1:d847ced:              "select s.schemaName, a.alias, a.aliastype\n" +
1:d847ced:              "from sys.sysschemas s, sys.sysaliases a\n" +
1:d847ced:              "where s.schemaID = a.schemaID\n" +
1:5b79ae0:              "and substr( cast( a.javaclassname as varchar( 32672 ) ), 1, ? ) = ?\n"
1:5b79ae0:              );
1:5b79ae0:         ps.setInt( 1, packageName.length() );
1:5b79ae0:         ps.setString( 2, packageName );
1:5b79ae0:         ResultSet   routines = ps.executeQuery();
1:d847ced: 
5:d847ced:         try {
1:d847ced:             while ( routines.next() )
1:d847ced:             {
1:d847ced:                 String  schema = routines.getString( 1 );
1:d847ced:                 String  routineName = routines.getString( 2 );
1:d847ced:                 String  routineType = ("P".equals( routines.getString( 3 ) )) ? "procedure" : "function";
1:d847ced: 
1:d847ced:                 conn.prepareStatement( "drop " + routineType + " " + makeTableName( schema, routineName ) ).execute();
1:d847ced:             }
1:d847ced:         }
1:d847ced:         finally { routines.close(); }
1:d847ced: 
1:d847ced:         //
1:d847ced:         // Drop the LuceneSupport schema.
1:d847ced:         //
1:d847ced:         conn.prepareStatement( "drop schema " + LUCENE_SCHEMA + " restrict" ).execute();
1:d847ced: 
1:d847ced:         //
1:d847ced:         // Now delete the Lucene subdirectory;
1:d847ced:         //
1:7234498:         StorageFactory storageFactory = getStorageFactory(conn);
1:7234498:         StorageFile luceneDir =
1:7234498:                 storageFactory.newStorageFile(Database.LUCENE_DIR);
1:7234498:         if (exists(luceneDir)) {
1:7234498:             deleteFile(luceneDir);
1:d847ced:         }
1:d847ced: 	}
1:d847ced: 	
1:5cf7a46:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  LUCENE QUERY
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:0b71ff5: 	/**
1:d847ced: 	 * Query a Lucene index created by createIndex
1:0b71ff5: 	 * 
1:d847ced: 	 * @param queryText a Lucene query, see the Lucene classic queryparser syntax 
1:cbdf827: 	 * @param scoreCeiling Return results only below this score
1:d847ced: 	 * @return A result set in the form of LuceneQueryVTI table
1:d847ced: 	 * @throws ParseException
3:d847ced: 	 * @throws IOException
1:fbf176c: 	 * @see org.apache.derby.optional.lucene.LuceneQueryVTI
1:0b71ff5: 	 */
1:d847ced: 	public static LuceneQueryVTI luceneQuery
1:0b71ff5:         (
1:d847ced:          String queryText,
1:9cc25e2:          int    windowSize,
1:4cedf31:          Float scoreCeiling
1:0b71ff5:          )
1:d847ced:         throws ParseException, IOException, SQLException
1:0b71ff5:     {
1:a4e6298: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, windowSize, scoreCeiling );
1:d847ced: 		return lqvti;
1:d847ced: 	}
1:d847ced: 	
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  LIST INDEXES
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:2277df2: 	/**
1:d847ced: 	 * Return a list of Lucene indexes for this database. Filter by schema and table, if given.
1:d847ced: 	 */
1:d847ced: 	public static LuceneListIndexesVTI listIndexes()
1:d847ced:         throws IOException, PrivilegedActionException, SQLException
1:d847ced:     {
1:d847ced: 		LuceneListIndexesVTI llivti = new LuceneListIndexesVTI();
1:d847ced: 		return llivti;
1:d847ced: 	}
1:d847ced: 	
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  UPDATE INDEX
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:2277df2: 	/**
1:d847ced: 	 * Update a document in a Lucene index. Drops and recreates the Lucene index
1:d847ced:      * but does not touch the query function specific to the index.
1:d847ced: 	 * 
1:d847ced: 	 * @param schema Schema where the indexed column resides
1:d847ced: 	 * @param table table where the indexed column resides
1:d847ced: 	 * @param textcol the indexed column
1:a4e6298: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 * @throws IOException
1:d847ced: 	 */
1:a4e6298: 	public static void updateIndex( String schema, String table, String textcol, String indexDescriptorMaker )
4:d847ced:         throws SQLException, IOException, PrivilegedActionException
1:d847ced:     {
1:2a8df97:         forbidReadOnlyConnections();
1:d847ced: 
1:d847ced:         Connection              conn = getDefaultConnection();
1:d847ced: 
1:4f7c143:         vetIdentifiers( schema, table, textcol );
1:4f7c143: 
1:d847ced:         // only the dbo or the schema owner can perform this function
1:6b8ad38:         ToolUtilities.mustBeOwner( conn, schema );
1:4f7c143: 
1:d847ced:         if ( !tableFunctionExists( conn, schema, table, textcol ) )
1:d847ced:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_INDEX_DOES_NOT_EXIST );
1:d847ced:         }
1:d847ced: 
1:a4e6298:         createOrRecreateIndex( conn, schema, table, textcol, indexDescriptorMaker, false );
1:d847ced: 	}
1:d847ced: 	
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  CREATE INDEX
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced: 	/**
1:d847ced: 	 * Create a Lucene index on the specified column.
1:d847ced: 	 *  
1:d847ced: 	 * @param schema The schema of the column to index
1:fcf3e6d: 	 * @param table The table or view containing the indexable column
1:d847ced: 	 * @param textcol The column to create the Lucene index on
1:a4e6298: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
1:fcf3e6d: 	 * @param keyColumns names of key columns if we're indexing a column in a view
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 * @throws IOException
1:d847ced: 	 */
1:fcf3e6d: 	public static void createIndex
1:fcf3e6d:         (
1:fcf3e6d:          String schema,
1:fcf3e6d:          String table,
1:fcf3e6d:          String textcol,
1:a4e6298:          String indexDescriptorMaker,
1:fcf3e6d:          String... keyColumns
1:fcf3e6d:          )
1:d847ced:         throws SQLException, IOException, PrivilegedActionException
1:d847ced:     {
1:2a8df97:         forbidReadOnlyConnections();
1:d847ced:         
1:d847ced:         Connection              conn = getDefaultConnection();
1:d847ced:         DatabaseMetaData    dbmd = conn.getMetaData();
1:4f7c143: 
1:4f7c143:         vetIdentifiers( schema, table, textcol );
1:d847ced: 
1:d847ced:         // First make sure that the text column exists and is a String type
1:d847ced:         vetTextColumn( dbmd, schema, table, textcol );
1:d847ced: 
1:a4e6298:         createOrRecreateIndex( conn, schema, table, textcol, indexDescriptorMaker, true, keyColumns );
1:d847ced: 	}
1:d847ced: 
1:d847ced: 	/**
1:d847ced: 	 * Create or re-create a Lucene index on the specified column.
1:d847ced: 	 *  
1:d847ced: 	 * @param schema The schema of the column to index
2:d847ced: 	 * @param table The table of the column to index
1:d847ced: 	 * @param textcol The column to create the Lucene index on
1:a4e6298: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
1:d847ced: 	 * @param create True if the index is to be created, false if it is to be recreated
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 * @throws IOException
1:d847ced: 	 */
1:d847ced: 	private static void createOrRecreateIndex
1:d847ced:         (
1:d847ced:          Connection conn,
1:d847ced:          String schema,
1:d847ced:          String table,
1:d847ced:          String textcol,
1:a4e6298:          String indexDescriptorMaker,
1:fcf3e6d:          boolean create,
1:fcf3e6d:          String... keyColumns
3:d847ced:          )
1:d847ced:         throws SQLException, IOException, PrivilegedActionException
1:d847ced:     {
1:fcf3e6d:         VTITemplate.ColumnDescriptor[] primaryKeys = new VTITemplate.ColumnDescriptor[ 0 ];
1:fcf3e6d: 
1:fcf3e6d:         // can't override keys when the index is updated
1:fcf3e6d:         if ( !create )
1:fcf3e6d:         { primaryKeys = getKeys( conn, schema, table, textcol ); }
1:fcf3e6d:         // use the supplied keys if possible
1:fcf3e6d:         else if ( (keyColumns != null) && (keyColumns.length > 0) )
1:fcf3e6d:         { primaryKeys = getKeys( conn, schema, table, keyColumns ); }
1:fcf3e6d:         else
1:fcf3e6d:         { primaryKeys = getPrimaryKeys( conn, schema, table  ); }
1:fcf3e6d: 
1:fcf3e6d:         // can't create an index without specifying keys for joining it back to Derby data
1:d847ced:         if ( primaryKeys.length == 0 )
1:d847ced:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_NO_PRIMARY_KEY );
1:d847ced:         }
1:d847ced: 
1:cbdf827:         // don't let the user create a table function with duplicate column names
1:6b8ad38:         vetColumnName( ToolUtilities.derbyIdentifier( textcol ) );
1:cbdf827:         for ( VTITemplate.ColumnDescriptor key : primaryKeys )
1:cbdf827:         {
1:cbdf827:             vetColumnName(  key.columnName );
1:cbdf827:         }
1:cbdf827:         
1:cbdf827:         int             keyCount = 0;
1:5cf7a46:         StorageFile propertiesFile = getIndexPropertiesFile( conn, schema, table, textcol );
1:2277df2: 
1:d847ced:         //
1:d847ced:         // Drop the old index directory if we're recreating the index.
1:d847ced:         // We do this after verifying that the key exists.
1:d847ced:         //
1:2277df2:         if ( !create )
1:2277df2:         {
1:2277df2:             dropIndexDirectories( schema, table, textcol );
1:2277df2:         }
1:2277df2: 
1:2277df2:         Version luceneVersion = LuceneUtils.currentVersion();
1:2277df2: 
1:5cf7a46:         // create the new directory
1:5cf7a46:         DerbyLuceneDir  derbyLuceneDir = getDerbyLuceneDir( conn, schema, table, textcol );
1:5cf7a46: 
1:a4e6298:         // get the Analyzer and the field names. use the default if the user didn't specify an override
1:a4e6298:         if ( indexDescriptorMaker == null ) { indexDescriptorMaker = LuceneUtils.class.getName() + ".defaultIndexDescriptor"; }
1:a4e6298:         LuceneIndexDescriptor   indexDescriptor = getIndexDescriptor( indexDescriptorMaker );
1:a4e6298:         String[]  fieldNames = indexDescriptor.getFieldNames();
1:a4e6298:         Analyzer    analyzer = indexDescriptor.getAnalyzer();
1:2277df2: 
1:7e538ec:         // make sure the field names don't overlap with the key names
1:7e538ec:         sortAndVetFieldNames( fieldNames, primaryKeys );
1:7e538ec: 
1:2277df2:         Properties  indexProperties = new Properties();
1:2277df2:         indexProperties.setProperty( LUCENE_VERSION, luceneVersion.toString() );
1:2277df2:         indexProperties.setProperty( UPDATE_TIMESTAMP, Long.toString( System.currentTimeMillis() ) );
1:a4e6298:         indexProperties.setProperty( INDEX_DESCRIPTOR_MAKER, indexDescriptorMaker );
1:2277df2:         indexProperties.setProperty( ANALYZER, analyzer.getClass().getName() );
1:d847ced:             
1:d847ced:         StringBuilder   tableFunction = new StringBuilder();
1:d847ced:         tableFunction.append( "create function " + makeTableFunctionName( schema, table, textcol ) + "\n" );
1:a4e6298:         tableFunction.append( "( query varchar( 32672 ), windowSize int, scoreCeiling real )\n" );
1:d847ced:         tableFunction.append( "returns table\n(" );
1:d847ced: 
1:4e1453d:         writeIndexProperties( propertiesFile, indexProperties );
1:4e1453d:         
1:d847ced:         PreparedStatement   ps = null;
1:d847ced:         ResultSet rs = null;
1:d847ced:         IndexWriter iw = null;
1:d847ced:         try {
1:5cf7a46:             iw = getIndexWriter( luceneVersion, analyzer, derbyLuceneDir );
1:d847ced: 
1:d847ced:             // select all keys and the textcol from this column, add to lucene index
1:d847ced:             StringBuilder query = new StringBuilder("select ");
1:d847ced:         
1:d847ced:             for ( VTITemplate.ColumnDescriptor keyDesc : primaryKeys )
1:d847ced:             {
1:3240e21:                 String  keyName = delimitID( keyDesc.columnName );
1:d847ced:                 if ( keyCount > 0 ) { query.append( ", " ); }
1:d847ced:                 query.append( keyName );
1:d847ced: 
1:d847ced:                 String  keyType = mapType( keyDesc );
1:d847ced: 
1:d847ced:                 if ( keyCount > 0 ) { tableFunction.append( "," ); }
1:d847ced:                 tableFunction.append( "\n\t" + keyName + " " + keyType );
1:d847ced:                 keyCount++;
1:d847ced:             }
1:cbdf827:             tableFunction.append(",\n\t" + DOCUMENT_ID + " int");
1:cbdf827:             tableFunction.append(",\n\t" + SCORE + " real");
1:d847ced:             tableFunction.append( "\n)\nlanguage java parameter style derby_jdbc_result_set contains sql\n" );
1:fbf176c:             tableFunction.append( "external name '" + LuceneSupport.class.getName() + ".luceneQuery'" );
1:d847ced: 
1:d847ced:             // now create the table function for this text column
1:d847ced:             if ( create )
1:d847ced:             {
1:d847ced:                 conn.prepareStatement( tableFunction.toString() ).execute();
1:d847ced:             }
1:d847ced:         
1:d847ced:             query.append(", ");
1:6b8ad38:             query.append( delimitID( ToolUtilities.derbyIdentifier( textcol ) ) );
1:d847ced:             query.append(" from " + makeTableName( schema, table ) );
1:d847ced: 
1:d847ced:             ps = conn.prepareStatement( query.toString() );
1:d847ced:             rs = ps.executeQuery();
1:d847ced: 
1:d847ced:             while ( rs.next() )
1:d847ced:             {
1:d847ced:                 Document doc = new Document();
1:d847ced: 
1:d847ced:                 for ( int i = 0; i < keyCount; i++ )
1:d847ced:                 {
1:d847ced:                     VTITemplate.ColumnDescriptor   keyDescriptor = primaryKeys[ i ];
1:d847ced:                     addValue( doc, keyDescriptor, rs, i + 1 );
1:d847ced:                 }
1:d847ced: 
1:d847ced:                 String  textcolValue = rs.getString( keyCount + 1 );
1:d847ced:                 if ( textcolValue != null )
1:d847ced:                 {
1:a4e6298:                     for ( String fieldName : fieldNames )
1:a4e6298:                     {
1:a4e6298:                         doc.add( new TextField( fieldName, textcolValue, Store.NO ) );
1:a4e6298:                     }
1:d847ced:                 }
1:d847ced:                 addDocument( iw, doc );
1:d847ced:             }
1:d847ced:         }
1:d847ced:         finally
1:d847ced:         {
1:d847ced:             try {
1:d847ced:                  if ( iw != null ) { close( iw ); }
1:d847ced:             }
1:d847ced:             finally {
1:d847ced:                 try {
1:d847ced:                     if ( rs != null ) { rs.close(); }
1:d847ced:                 }
1:d847ced:                 finally {
1:d847ced:                     if ( ps != null ) { ps.close(); }
1:d847ced:                 }
1:d847ced:             }
1:d847ced:         }
1:d847ced: 	}
1:d847ced: 
1:4f7c143:     /** Verify that the schema, table, and column names aren't null */
1:4f7c143: 	private static void vetIdentifiers
1:4f7c143:         (
1:4f7c143:          String schema,
1:4f7c143:          String table,
1:4f7c143:          String textcol
1:4f7c143:          )
1:4f7c143:         throws SQLException
1:4f7c143:     {
1:4f7c143:         checkNotNull( "SCHEMANAME", schema );
1:4f7c143:         checkNotNull( "TABLENAME", table );
1:4f7c143:         checkNotNull( "TEXTCOLUMN", textcol );
1:4f7c143:     }
1:7e538ec: 
1:7e538ec:     /**
1:7e538ec:      * Raise an exception if a field has the same name as a key or if two
1:7e538ec:      * fields have the same name.
1:7e538ec:      */
1:7e538ec:     private static  void    sortAndVetFieldNames( String[] fieldNames, VTITemplate.ColumnDescriptor[] keys )
1:7e538ec:         throws SQLException
1:7e538ec:     {
1:7e538ec:         for ( String fieldName : fieldNames )
1:7e538ec:         {
1:7e538ec:             if ( fieldName == null )
1:7e538ec:             {
1:6b8ad38:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
1:7e538ec:             }
1:7e538ec:         }
1:7e538ec:         Arrays.sort( fieldNames );
1:7e538ec:         
1:7e538ec:         HashSet<String>   keyNames = new HashSet<String>();
1:7e538ec:         for ( VTITemplate.ColumnDescriptor cd : keys ) { keyNames.add( cd.columnName ); }
1:7e538ec: 
1:7e538ec:         String  previousFieldName = null;
1:7e538ec:         for ( String fieldName : fieldNames )
1:7e538ec:         {
1:7e538ec:             if ( fieldName.equals( previousFieldName ) )
1:7e538ec:             {
1:6b8ad38:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
1:7e538ec:             }
1:7e538ec:             previousFieldName = fieldName;
1:7e538ec: 
1:7e538ec:             if ( keyNames.contains( fieldName ) )
1:7e538ec:             {
1:6b8ad38:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_FIELD_KEY_CONFLICT, fieldName );
1:7e538ec:             }
1:7e538ec:         }
1:7e538ec:     }
1:4f7c143:     
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  DROP INDEX
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced: 	/**
1:d847ced: 	 * Drop a Lucene index. This removes the Lucene index directory from the filesystem.
1:d847ced: 	 * 
1:d847ced: 	 * @param schema The schema of the column that is indexed
1:d847ced: 	 * @param table The table of the column that is indexed
1:d847ced: 	 * @param textcol The column that is indexed
1:d847ced: 	 * 
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 */
1:d847ced: 	public static void dropIndex( String schema, String table, String textcol )
1:fcf3e6d:         throws SQLException
1:d847ced:     {
1:2a8df97:         forbidReadOnlyConnections();
1:2a8df97:         
1:4f7c143:         vetIdentifiers( schema, table, textcol );
1:d847ced: 
1:d847ced:         getDefaultConnection().prepareStatement
1:d847ced:             (
1:d847ced:              "drop function " + makeTableFunctionName( schema, table, textcol )
1:d847ced:              ).execute();
1:d847ced: 
1:d847ced:         dropIndexDirectories( schema, table, textcol );
1:d847ced: 	}
1:d847ced: 
1:d847ced:     /**
1:5cf7a46:      * <p>
1:d847ced:      * Drop the Lucene directories which support an index.
1:5cf7a46:      * </p>
1:5cf7a46:      */
1:d847ced: 	private static void dropIndexDirectories( String schema, String table, String textcol )
1:d847ced:         throws SQLException
1:5cf7a46:     {
1:5cf7a46:         DerbyLuceneDir  derbyLuceneDir = getDerbyLuceneDir( getDefaultConnection(), schema, table, textcol );
1:5cf7a46: 
1:5cf7a46:         StorageFile indexDir = derbyLuceneDir.getDirectory();
1:5cf7a46: 		StorageFile tableDir = indexDir.getParentDir();
1:5cf7a46:         StorageFile schemaDir = tableDir.getParentDir();
1:5cf7a46: 		
1:d847ced:         deleteFile( indexDir );
1:d847ced:         if ( isEmpty( tableDir ) )
1:2277df2:         {
1:d847ced:             deleteFile( tableDir );
1:d847ced:             if ( isEmpty( schemaDir ) ) { deleteFile( schemaDir ); }
1:d847ced:         }
1:d847ced:     }
1:2277df2: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  TYPE HANDLING
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced:     /** Get the SQL type name for a key column */
1:d847ced:     private static  String  mapType( VTITemplate.ColumnDescriptor keyDesc )
1:d847ced:         throws SQLException
1:2277df2:     {
1:d847ced:         return mapType
1:2277df2:             (
1:d847ced:              keyDesc.jdbcType,
1:d847ced:              keyDesc.precision,
1:d847ced:              keyDesc.scale,
1:d847ced:              keyDesc.typeName
6:d847ced:              );
1:d847ced:     }
1:d847ced: 
1:d847ced:     /**
1:2277df2:      * <p>
1:d847ced:      * Get the type of an external database's column as a Derby type name.
1:2277df2:      * </p>
1:d847ced:      *
1:2277df2:      */
1:d847ced:     private static String    mapType( int jdbcType, int precision, int scale, String typeName )
1:d847ced:         throws SQLException
1:2277df2:     {
1:d847ced:         switch( jdbcType )
1:2277df2:         {
1:d847ced:         case    Types.BIGINT:           return "bigint";
1:d847ced:         case    Types.BINARY:           return "char " + precisionToLength( precision ) + "  for bit data";
1:d847ced:         case    Types.BIT:              return "boolean";
1:d847ced:         case    Types.BLOB:             return "blob";
1:d847ced:         case    Types.BOOLEAN:          return "boolean";
1:d847ced:         case    Types.CHAR:             return "char" + precisionToLength( precision );
1:d847ced:         case    Types.CLOB:             return "clob";
1:d847ced:         case    Types.DATE:             return "date";
1:d847ced:         case    Types.DECIMAL:          return "decimal" + precisionAndScale( precision, scale );
1:d847ced:         case    Types.DOUBLE:           return "double";
1:d847ced:         case    Types.FLOAT:            return "float";
1:d847ced:         case    Types.INTEGER:          return "integer";
1:d847ced:         case    Types.LONGVARBINARY:    return "long varchar for bit data";
1:d847ced:         case    Types.LONGVARCHAR:      return "long varchar";
1:d847ced:         case    Types.NUMERIC:          return "numeric" + precisionAndScale( precision, scale );
1:d847ced:         case    Types.REAL:             return "real";
1:d847ced:         case    Types.SMALLINT:         return "smallint";
1:d847ced:         case    Types.TIME:             return "time";
1:d847ced:         case    Types.TIMESTAMP:        return "timestamp";
1:d847ced:         case    Types.TINYINT:          return "smallint";
1:d847ced:         case    Types.VARBINARY:        return "varchar " + precisionToLength( precision ) + "  for bit data";
1:d847ced:         case    Types.VARCHAR:          return "varchar" + precisionToLength( precision );
1:d847ced:  
1:6b8ad38:         default:  throw ToolUtilities.newSQLException( SQLState.LUCENE_UNSUPPORTED_TYPE, typeName );
1:d847ced:         }
1:d847ced:     }
1:d847ced: 
1:d847ced:     /**
5:d847ced:      * <p>
1:d847ced:      * Turns precision into a length designator.
5:d847ced:      * </p>
1:d847ced:      *
1:d847ced:      */
1:d847ced:     private  static String  precisionToLength( int precision )
1:d847ced:     {
1:d847ced:         return "( " + precision + " )";
1:d847ced:     }
1:d847ced: 
1:d847ced:     /**
1:d847ced:      * <p>
1:d847ced:      * Build a precision and scale designator.
1:d847ced:      * </p>
1:d847ced:      *
1:d847ced:      */
1:d847ced:     private static  String  precisionAndScale( int precision, int scale )
1:d847ced:     {
1:d847ced:         return "( " + precision + ", " + scale + " )";
1:d847ced:     }
1:d847ced: 
1:d847ced:     /**
1:d847ced:      * Add the field to the document so that it can be read by LuceneQueryVTI.
1:d847ced:      * May raise an exception if the type is not supported.
1:d847ced:      */
1:d847ced:     private static  void    addValue
1:d847ced:         (
1:d847ced:          Document   doc,
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         IndexableField     field = null;
1:d847ced:         
1:d847ced:         switch( keyDescriptor.jdbcType )
1:d847ced:         {
1:d847ced:         case    Types.SMALLINT:
1:d847ced:         case    Types.TINYINT:
1:d847ced:         case    Types.INTEGER:
1:d847ced:             field = getIntField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.REAL:
1:d847ced:             field = getFloatField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.FLOAT:
1:d847ced:         case    Types.DOUBLE:
1:d847ced:             field = getDoubleField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.BIGINT:
1:d847ced:             field = getLongField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.DATE:
1:d847ced:             field = getDateField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.TIME:
1:d847ced:             field = getTimeField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.TIMESTAMP:
1:d847ced:             field = getTimestampField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.CHAR:
1:d847ced:         case    Types.CLOB:
1:d847ced:         case    Types.DECIMAL:
1:d847ced:         case    Types.LONGVARCHAR:
1:d847ced:         case    Types.NUMERIC:
1:d847ced:         case    Types.VARCHAR:
1:d847ced:             field = getStringField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.BLOB:
1:d847ced:         case    Types.BINARY:
1:d847ced:         case    Types.LONGVARBINARY:
1:d847ced:         case    Types.VARBINARY:
1:d847ced:             field = getBinaryField( keyDescriptor, rs, columnIdx );
1:d847ced:             break;
1:d847ced: 
1:d847ced:         case    Types.BIT:
1:d847ced:         case    Types.BOOLEAN:
1:d847ced:             boolean booleanValue = rs.getBoolean( columnIdx );
1:d847ced:             if ( !rs.wasNull() )
1:d847ced:             {
1:d847ced:                 field = new StringField( keyDescriptor.columnName, booleanValue ? "true" : "false", Store.YES );
1:d847ced:             }
1:d847ced:             break;
1:d847ced:             
1:d847ced:         default:
1:6b8ad38:             throw ToolUtilities.newSQLException
1:6b8ad38:                 ( SQLState.LUCENE_UNSUPPORTED_TYPE, keyDescriptor.typeName );
1:d847ced:         }
1:d847ced: 
1:abb2084:         // Lucene fields do not allow null values
1:abb2084:         if ( rs.wasNull() ) { field = null; }
1:abb2084: 
1:d847ced:         if ( field != null ) { doc.add( field ); }
1:d847ced:     }
1:d847ced: 	
1:d847ced:     /**
1:d847ced:      * Get a string value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField getStringField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         String  stringValue = rs.getString( columnIdx );
1:d847ced:         if ( stringValue != null )
1:d847ced:         {
1:d847ced:             return new StringField( keyDescriptor.columnName, stringValue, Store.YES );
1:d847ced:         }
2:d847ced:         else { return null; }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a float value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getFloatField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         float   value = rs.getFloat( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:2277df2:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a double value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getDoubleField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         double   value = rs.getDouble( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:2277df2:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get an long value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getLongField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         long    value = rs.getLong( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
5:d847ced:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a Date value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getDateField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         Date    value = rs.getDate( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:d847ced:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a Time value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getTimeField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         Time    value = rs.getTime( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:d847ced:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a Timestamp value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getTimestampField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         Timestamp    value = rs.getTimestamp( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:d847ced:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get an integer value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getIntField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         int     value = rs.getInt( columnIdx );
1:d847ced:         if ( rs.wasNull() ) { return null; }
1:d847ced:         else
1:d847ced:         {
1:d847ced:             return new StoredField( keyDescriptor.columnName, value );
1:d847ced:         }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Get a binary value to add to the document read by LuceneQueryVTI.
1:d847ced:      */
1:d847ced:     private static  IndexableField    getBinaryField
1:d847ced:         (
1:d847ced:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:d847ced:          ResultSet  rs,
1:d847ced:          int    columnIdx   // 1-based
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         byte[]  value = rs.getBytes( columnIdx );
1:d847ced:         if ( value != null )
1:d847ced:         {
1:d847ced:             BytesRef    ref = new BytesRef( value );
1:d847ced:             return new StoredField( keyDescriptor.columnName, ref );
1:d847ced:         }
1:d847ced:         else { return null; }
1:d847ced:     }
1:d847ced:     
1:d847ced:     /**
1:d847ced:      * Raise an exception if the text column doesn't exist or isn't a String datatype.
1:d847ced:      */
1:d847ced: 	private static void vetTextColumn( DatabaseMetaData dbmd, String schema, String table, String textcol )
1:d847ced:         throws SQLException
1:d847ced:     {
1:6b8ad38:         schema = ToolUtilities.derbyIdentifier( schema );
1:6b8ad38:         table = ToolUtilities.derbyIdentifier( table );
1:6b8ad38:         textcol = ToolUtilities.derbyIdentifier( textcol );
1:d847ced:         
1:d847ced:         ResultSet   rs = dbmd.getColumns( null, schema, table, textcol );
1:d847ced: 
1:d847ced:         try {
1:d847ced:             if ( rs.next() )
1:d847ced:             {
1:d847ced:                 switch( rs.getInt( "DATA_TYPE" ) )
1:d847ced:                 {
1:d847ced:                 case    Types.CHAR:
1:d847ced:                 case    Types.CLOB:
1:d847ced:                 case    Types.LONGVARCHAR:
1:d847ced:                 case    Types.VARCHAR:
1:d847ced:                     return;
1:d847ced:                 }
1:d847ced:             }
1:d847ced: 
1:6b8ad38:             throw ToolUtilities.sqlException
1:6b8ad38:                 ( StandardException.newException( SQLState.LUCENE_NOT_A_STRING_TYPE ) );
1:d847ced:         }
1:d847ced:         finally
1:d847ced:         {
1:d847ced:             rs.close();
1:d847ced:         }
1:d847ced:     }
1:d847ced: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  NAMESPACE
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced:     /**
1:cbdf827:      * A Lucene query table function already has system-supplied columns
1:cbdf827:      * named documentID and score. These can't be the names of the key
1:cbdf827:      * or text columns supplied by the user.
1:cbdf827:      */
1:cbdf827:     private static  void    vetColumnName( String columnName )
1:cbdf827:         throws SQLException
1:cbdf827:     {
1:19ca71c:         String  derbyColumnName = columnName;
1:cbdf827: 
1:cbdf827:         if (
1:cbdf827:             DOCUMENT_ID.equals( derbyColumnName ) ||
1:cbdf827:             SCORE.equals( derbyColumnName )
1:cbdf827:             )
1:cbdf827:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_BAD_COLUMN_NAME, derbyColumnName );
1:cbdf827:         }
1:cbdf827:     }
1:cbdf827: 
1:cbdf827:     /**
1:d847ced:      * Return the qualified name of the table.
1:d847ced:      */
1:d847ced: 	static String   makeTableName( String schema, String table )
1:d847ced:         throws SQLException
1:d847ced:     {
1:6b8ad38:         schema = ToolUtilities.derbyIdentifier( schema );
1:6b8ad38:         table = ToolUtilities.derbyIdentifier( table );
1:d847ced: 
1:d847ced:         return IdUtil.mkQualifiedName( schema, table );
1:d847ced:     }
1:d847ced: 
1:d847ced:     /** Return the qualified name of the table function */
1:d847ced: 	private static String   makeTableFunctionName( String schema, String table, String textcol )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced: 		// Provide some basic protection against someone trying to put path modifiers (../../etc.)
1:d847ced: 		// into the arguments.
1:d847ced:         forbidCharacter( schema, table, textcol, "." );
1:d847ced:         forbidCharacter( schema, table, textcol, "/" );
1:d847ced:         forbidCharacter( schema, table, textcol, "\\" );
1:d847ced: 		
1:6b8ad38:         schema = ToolUtilities.derbyIdentifier( schema );
1:d847ced:         String  function = makeUnqualifiedTableFunctionName( table, textcol );
1:d847ced: 
1:d847ced:         return IdUtil.mkQualifiedName( schema, function );
1:d847ced:     }
1:d847ced: 
1:d847ced:     /** Make the unqualified name of a querying table function */
1:d847ced:     private static  String  makeUnqualifiedTableFunctionName( String table, String textcol )
1:d847ced:         throws SQLException
1:d847ced:     {
1:6b8ad38:         return ToolUtilities.derbyIdentifier( table ) + SEPARATOR +
1:6b8ad38:             ToolUtilities.derbyIdentifier( textcol );
1:d847ced:     }
1:d847ced: 
1:d847ced:     /** Return true if the table function exists */
1:d847ced:     private static  boolean tableFunctionExists( Connection conn, String schema, String table, String textcol )
1:d847ced:         throws SQLException
1:d847ced:     {
1:6b8ad38:         schema = ToolUtilities.derbyIdentifier( schema );
1:d847ced:         String  function = makeUnqualifiedTableFunctionName( table, textcol );
1:d847ced: 
1:d847ced:         ResultSet   rs = conn.getMetaData().getFunctions( null, schema, function );
1:d847ced: 
1:d847ced:         try {
1:d847ced:             return rs.next();
1:d847ced:         }
3:d847ced:         finally { rs.close(); }
1:d847ced:     }
1:d847ced: 
1:d847ced:     /** Decompose a function name of the form $table__$column into $table and $column */
1:d847ced:     static  String[]    decodeFunctionName( String functionName )
1:d847ced:     {
1:d847ced:         int     separatorIdx = functionName.indexOf( SEPARATOR );
1:d847ced:         String[]    retval = new String[ PART_COUNT ];
1:d847ced: 
1:d847ced:         retval[ TABLE_PART ] = functionName.substring( 0, separatorIdx );
1:d847ced:         retval[ COLUMN_PART ] = functionName.substring( separatorIdx + SEPARATOR.length() );
1:d847ced: 
1:d847ced:         return retval;
1:d847ced:     }
1:d847ced: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:2277df2:     //  MANAGE THE INDEX PROPERTIES FILE
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced:     /**
1:d847ced:      * <p>
1:2277df2:      * Get the handle on the file holding the index properties.
1:d847ced:      * </p>
1:d847ced:      */
1:5cf7a46: 	static StorageFile getIndexPropertiesFile( Connection conn, String schema, String table, String textcol )
1:2277df2:         throws SQLException, IOException, PrivilegedActionException
1:2277df2:     {
1:5cf7a46:         return getIndexPropertiesFile( getDerbyLuceneDir( conn, schema, table, textcol ) );
1:5cf7a46:     }
1:5cf7a46:     
1:5cf7a46:     /**
1:5cf7a46:      * <p>
1:5cf7a46:      * Get the handle on the file holding the index properties.
1:5cf7a46:      * </p>
1:5cf7a46:      */
1:5cf7a46: 	static StorageFile getIndexPropertiesFile( DerbyLuceneDir dir )
1:5cf7a46:         throws SQLException, IOException, PrivilegedActionException
1:5cf7a46:     {
1:5cf7a46:         StorageFile         propertiesFile = dir.getFile( PROPERTIES_FILE_NAME );
1:d847ced: 
1:2277df2:         return propertiesFile;
1:2277df2:     }
1:2277df2:     
1:9344889:     /** Read the index properties file */
1:5cf7a46:     static  Properties readIndexPropertiesNoPrivs( StorageFile file )
1:9344889:         throws IOException
1:9344889:     {
1:9344889:         if ( file == null ) { return null; }
1:9344889:         
1:9344889:         Properties  properties = new Properties();
1:5cf7a46:         InputStream is = file.getInputStream();
1:9344889: 
1:5cf7a46:         properties.load( is );
1:5cf7a46:         is.close();
1:9344889:                         
1:9344889:         return properties;
1:9344889:     }
1:9344889: 
1:2277df2:     /** Write the index properties file */
1:7234498:     private static  void    writeIndexProperties( final StorageFile file, Properties properties )
1:7234498:         throws IOException
1:2277df2:     {
1:7234498:         if (file == null || properties == null) {
1:7234498:             return;
1:2277df2:         }
1:2277df2: 
1:7234498:         OutputStream os;
1:d847ced:         try {
1:7234498:             os = AccessController.doPrivileged(
1:7234498:                     new PrivilegedExceptionAction<OutputStream>() {
1:7234498:                 public OutputStream run() throws IOException {
1:7234498:                     return file.getOutputStream();
1:2277df2:                 }
1:d847ced:             });
1:d847ced:         } catch (PrivilegedActionException pae) {
1:d847ced:             throw (IOException) pae.getCause();
1:2277df2:         }
1:2277df2: 
1:5cf7a46:         properties.store( os, null );
1:5cf7a46:         os.flush();
1:5cf7a46:         os.close();
1:2277df2:     }
1:2277df2: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  SQL/JDBC SUPPORT
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced:     /**
1:2a8df97:      * Raise an error if the connection is readonly.
1:2a8df97:      */
1:2a8df97:     private static  void    forbidReadOnlyConnections()
1:2a8df97:         throws SQLException
1:2a8df97:     {
1:2a8df97:         if ( ConnectionUtil.getCurrentLCC().getAuthorizer().isReadOnlyConnection() )
1:2a8df97:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.AUTH_WRITE_WITH_READ_ONLY_CONNECTION );
1:2a8df97:         }
1:2a8df97:     }
1:2a8df97: 
1:d847ced: 	/**
1:d847ced: 	 * Get a connection to the database
1:d847ced: 	 * 
1:d847ced: 	 * @return a connection
1:d847ced: 	 * 
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 */
1:d847ced: 	static Connection getDefaultConnection() throws SQLException
1:d847ced:     {
1:d847ced: 		return DriverManager.getConnection( "jdbc:default:connection" );
1:d847ced: 	}
1:d847ced: 
1:d847ced:     /** Return true if the LuceneSupport schema exists already */
1:d847ced:     private static  boolean luceneSchemaExists( Connection conn )
1:d847ced:         throws SQLException
1:d847ced:     {
1:d847ced:         PreparedStatement ps = conn.prepareStatement
1:d847ced:             ( "select count(*) from sys.sysschemas where schemaName = ?" );
1:d847ced:         ps.setString( 1, LUCENE_SCHEMA.toUpperCase() );
2:d847ced:         ResultSet   rs = ps.executeQuery();
1:d847ced: 
1:d847ced:         try {
3:d847ced:             rs.next();
1:d847ced:             return ( rs.getInt( 1 ) > 0 );
1:d847ced:         } finally
1:d847ced:         {
1:d847ced:             rs.close();
1:d847ced:             ps.close();
1:d847ced:         }
1:d847ced:     }
1:d847ced: 
1:d847ced: 	/**
1:d847ced: 	 * Execute a DDL statement
1:d847ced: 	 * 
1:d847ced: 	 * @param c a Connection
1:d847ced: 	 * @param text the text of the statement to execute
1:d847ced: 	 * @throws SQLException
1:d847ced: 	 */
1:d847ced: 	private void executeDDL(Connection c, String text) throws SQLException {
1:d847ced:     	PreparedStatement ddl = c.prepareStatement(text);
1:d847ced:     	ddl.execute();
1:d847ced:     	ddl.close();
1:d847ced:     }
1:d847ced: 	
1:3240e21:     /** Double quote an identifier in order to preserver casing */
1:3240e21:     static String delimitID( String id )
1:3240e21:     {
1:3240e21:         return IdUtil.normalToDelimited( id );
1:3240e21:     }
1:3240e21: 
1:4f7c143:     /** Raise an error if an argument is being given a null value */
1:4f7c143:     static  void    checkNotNull( String argumentName, String argumentValue )
1:4f7c143:         throws SQLException
1:4f7c143:     {
1:4f7c143:         if ( argumentValue == null )
1:4f7c143:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.ARGUMENT_MAY_NOT_BE_NULL, argumentName );
1:4f7c143:         }
1:4f7c143:     }
1:4f7c143: 
1:d847ced:     /**
1:d847ced:      * Return the primary key columns for a table, sorted by key position.
1:d847ced:      */
1:d847ced:     private static  VTITemplate.ColumnDescriptor[] getPrimaryKeys
1:d847ced:         (
1:d847ced:          Connection conn,
1:d847ced:          String schema,
1:d847ced:          String table
1:d847ced:          )
1:d847ced:         throws SQLException
1:d847ced:     {
1:6b8ad38:         ResultSet   keysRS = conn.getMetaData().getPrimaryKeys
1:6b8ad38:             ( null, ToolUtilities.derbyIdentifier( schema ), ToolUtilities.derbyIdentifier( table ) );
1:d847ced:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1:d847ced:         try {
1:d847ced:             while ( keysRS.next() )
1:d847ced:             {
1:d847ced:                 String  columnName = keysRS.getString( "COLUMN_NAME" );
1:d847ced:                 int     keyPosition = keysRS.getInt( "KEY_SEQ" );
1:d847ced: 
1:d847ced:                 ResultSet   colInfoRS = conn.prepareStatement
1:d847ced:                     ( "select " + columnName + " from " + makeTableName( schema, table ) + " where 1=2" ).executeQuery();
1:d847ced:                 ResultSetMetaData   rsmd = colInfoRS.getMetaData();
1:d847ced:                 VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:d847ced:                     (
1:d847ced:                      columnName,
1:d847ced:                      rsmd.getColumnType( 1 ),
1:d847ced:                      rsmd.getPrecision( 1 ),
1:d847ced:                      rsmd.getScale( 1 ),
1:d847ced:                      rsmd.getColumnTypeName( 1 ),
1:d847ced:                      keyPosition
1:d847ced:                      );
1:d847ced:                 keyArray.add( keyDescriptor );
1:d847ced:                 colInfoRS.close();
1:d847ced:             }
1:d847ced:         }
1:d847ced:         finally
1:d847ced:         {
1:d847ced:             keysRS.close();
1:d847ced:         }
1:fcf3e6d: 
1:d847ced:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:d847ced:         keyArray.toArray( result );
1:d847ced:         Arrays.sort( result );
1:d847ced: 
1:d847ced:         return result;
1:5cf7a46:     }
1:5cf7a46: 
1:5cf7a46:     /**
1:fcf3e6d:      * Return the key columns for an existing LuceneQueryVTI table function.
1:fcf3e6d:      */
1:fcf3e6d:     private static  VTITemplate.ColumnDescriptor[] getKeys
1:fcf3e6d:         (
1:fcf3e6d:          Connection conn,
1:fcf3e6d:          String schema,
1:fcf3e6d:          String table,
1:fcf3e6d:          String textcol
1:fcf3e6d:          )
1:5cf7a46:         throws SQLException
1:fcf3e6d:     {
1:6b8ad38:         schema = ToolUtilities.derbyIdentifier( schema );
1:fcf3e6d:         String  functionName = makeUnqualifiedTableFunctionName( table, textcol );
1:fcf3e6d:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1:fcf3e6d: 
1:fcf3e6d:         ResultSet   rs = conn.getMetaData().getFunctionColumns( null, schema, functionName, "%" );
1:fcf3e6d:         try {
1:fcf3e6d:             while ( rs.next() )
1:fcf3e6d:             {
1:fcf3e6d:                 if ( rs.getInt( "COLUMN_TYPE" ) == DatabaseMetaData.functionColumnResult )
1:fcf3e6d:                 {
1:fcf3e6d:                     VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:fcf3e6d:                         (
1:fcf3e6d:                          rs.getString( "COLUMN_NAME" ),
1:fcf3e6d:                          rs.getInt( "DATA_TYPE" ),
1:fcf3e6d:                          rs.getInt( "PRECISION" ),
1:fcf3e6d:                          rs.getInt( "SCALE" ),
1:fcf3e6d:                          rs.getString( "TYPE_NAME" ),
1:fcf3e6d:                          rs.getInt( "ORDINAL_POSITION" )
1:fcf3e6d:                          );
1:fcf3e6d:                     keyArray.add( keyDescriptor );
1:fcf3e6d:                 }
1:fcf3e6d:             }
1:fcf3e6d:         }
1:fcf3e6d:         finally
1:fcf3e6d:         {
1:fcf3e6d:             rs.close();
1:fcf3e6d:         }
1:fcf3e6d:         
1:fcf3e6d:         VTITemplate.ColumnDescriptor[] temp = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:fcf3e6d:         keyArray.toArray( temp );
1:fcf3e6d:         Arrays.sort( temp );
1:fcf3e6d: 
1:cbdf827:         // remove the last two columns, which are not keys. they are the DOCUMENTID and SCORE columns.
1:fcf3e6d:         int     count = temp.length - 2;
1:fcf3e6d:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ count ];
1:fcf3e6d:         for ( int i = 0; i < count; i++ ) { result[ i ] = temp[ i ]; }
1:fcf3e6d: 
1:fcf3e6d:         return result;
1:fcf3e6d:     }
1:fcf3e6d:     
1:fcf3e6d:     /**
1:fcf3e6d:      * Return column information for a proposed set of keys.
1:fcf3e6d:      */
1:fcf3e6d:     private static  VTITemplate.ColumnDescriptor[] getKeys
1:fcf3e6d:         (
1:fcf3e6d:          Connection conn,
1:fcf3e6d:          String schema,
1:fcf3e6d:          String table,
1:fcf3e6d:          String... keyColumns
1:fcf3e6d:          )
1:fcf3e6d:         throws SQLException
1:fcf3e6d:     {
1:fcf3e6d:         String      qualifiedName = makeTableName( schema, table );
1:fcf3e6d:         StringBuilder   buffer = new StringBuilder();
1:fcf3e6d: 
1:fcf3e6d:         buffer.append( "select " );
1:fcf3e6d:         int counter = 0;
1:fcf3e6d:         for ( String key : keyColumns )
1:fcf3e6d:         {
1:4f7c143:             checkNotNull( "KEYCOLUMNS", key );
1:3240e21: 
1:fcf3e6d:             if ( counter > 0 ) { buffer.append( ", " ); }
1:fcf3e6d:             counter++;
1:6b8ad38:             buffer.append( delimitID( ToolUtilities.derbyIdentifier( key ) ) );
1:fcf3e6d:         }
1:fcf3e6d:         buffer.append( "\nfrom " + qualifiedName );
1:fcf3e6d:         buffer.append( "\nwhere 1=2" );
1:4f7c143: 
1:fcf3e6d:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1:fcf3e6d: 
1:fcf3e6d:         ResultSet   rs = conn.prepareStatement( buffer.toString() ).executeQuery();
1:fcf3e6d:         ResultSetMetaData   rsmd = rs.getMetaData();
1:fcf3e6d:         try {
1:fcf3e6d:             for ( int keyPosition = 1; keyPosition <= rsmd.getColumnCount(); keyPosition++ )
1:fcf3e6d:             {
1:fcf3e6d:                 VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:fcf3e6d:                     (
1:fcf3e6d:                      rsmd.getColumnName( keyPosition ),
1:fcf3e6d:                      rsmd.getColumnType( keyPosition ),
1:fcf3e6d:                      rsmd.getPrecision( keyPosition ),
1:fcf3e6d:                      rsmd.getScale( keyPosition ),
1:fcf3e6d:                      rsmd.getColumnTypeName( keyPosition ),
1:fcf3e6d:                      keyPosition
1:fcf3e6d:                      );
1:fcf3e6d:                 keyArray.add( keyDescriptor );
1:fcf3e6d:             }
1:fcf3e6d:         }
1:fcf3e6d:         finally
1:fcf3e6d:         {
1:fcf3e6d:             rs.close();
1:fcf3e6d:         }
1:fcf3e6d:         
1:fcf3e6d:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:fcf3e6d:         keyArray.toArray( result );
1:fcf3e6d: 
1:fcf3e6d:         return result;
1:fcf3e6d:     }
1:fcf3e6d:     
1:fcf3e6d: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  FILE MANAGEMENT
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced:     /** Return true if the directory is empty */
1:5cf7a46:     private static  boolean isEmpty( final StorageFile dir )
1:d847ced:     {
1:5cf7a46:         String[]  contents = AccessController.doPrivileged
1:5cf7a46:             (
1:7234498:              new PrivilegedAction<String[]>()
1:5cf7a46:              {
1:7234498:                  public String[] run()
1:5cf7a46:                 {
1:5cf7a46:                     return dir.list();
1:5cf7a46:                 }
1:5cf7a46:              }
1:5cf7a46:              );
1:d847ced: 
1:d847ced:         if ( contents == null ) { return true; }
1:d847ced:         else if ( contents.length == 0 ) { return true; }
1:d847ced:         else { return false; }
1:d847ced:     }
1:d847ced: 
1:5cf7a46:     /** Return true if the file exists */
1:5cf7a46:     private static  boolean exists( final StorageFile file )
1:2277df2:     {
1:0b71ff5:         return AccessController.doPrivileged
1:0b71ff5:             (
1:7234498:              new PrivilegedAction<Boolean>()
1:0b71ff5:              {
1:7234498:                  public Boolean run()
1:8fbaf26:                 {
1:5cf7a46:                     return file.exists();
1:0b71ff5:                 }
1:8fbaf26:              }
1:2277df2:              ).booleanValue();
1:2277df2:     }
1:2277df2: 
1:d847ced:     /** Really delete a file */
1:5cf7a46:     private static  boolean deleteFile( final StorageFile file )
1:d847ced:         throws SQLException
1:2277df2:     {
1:7234498:         boolean result = AccessController.doPrivileged(
1:7234498:                 new PrivilegedAction<Boolean>() {
1:7234498:             public Boolean run() {
1:7234498:                 return file.isDirectory() ? file.deleteAll() : file.delete();
1:2277df2:             }
1:7234498:         });
1:8fbaf26: 
1:7234498:         if (!result) {
1:6b8ad38:             throw ToolUtilities.newSQLException
1:6b8ad38:                 ( SQLState.UNABLE_TO_DELETE_FILE, file.getPath() );
1:2277df2:         }
1:8fbaf26: 
1:8fbaf26:         return result;
1:d847ced:     }
1:2277df2: 
1:d847ced:     /** Forbid invalid character */
1:d847ced:     private static  void    forbidCharacter( String schema, String table, String textcol, String invalidCharacter )
1:d847ced:         throws SQLException
1:2277df2:     {
1:d847ced: 		if (schema.indexOf( invalidCharacter ) > 0 || table.indexOf( invalidCharacter ) > 0 || textcol.indexOf( invalidCharacter ) > 0)
1:d847ced:         {
1:6b8ad38:             throw ToolUtilities.newSQLException( SQLState.LUCENE_INVALID_CHARACTER, invalidCharacter );
1:d847ced: 		}		
1:d847ced:     }
1:d847ced: 
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced:     //
1:d847ced:     //  LUCENE SUPPORT
1:d847ced:     //
1:d847ced:     /////////////////////////////////////////////////////////////////////
1:d847ced: 
1:d847ced: 	/**
1:d847ced: 	 * Returns a Lucene IndexWriter, that writes inside the lucene directory inside the database
1:d847ced: 	 * directory.
1:d847ced: 	 * 
1:2277df2: 	 * @param luceneVersion the version of Lucene being used
1:2277df2: 	 * @param analyzer      the Analyzer being used
1:d847ced: 	 * @param schema The schema of the indexed column
1:d847ced: 	 * @param table The table of the indexed column
1:d847ced: 	 * @param textcol The name of the column to be indexed
1:d847ced: 	 * @return a Lucene IndexWriter
1:d847ced: 	 */
1:d847ced: 	private static IndexWriter getIndexWriter
1:2277df2:         (
1:2277df2:          final Version  luceneVersion,
1:2277df2:          final  Analyzer    analyzer,
1:5cf7a46:          final DerbyLuceneDir   derbyLuceneDir
1:d847ced:          )
1:7234498:         throws IOException
1:d847ced:     {
1:d847ced:         try {
1:2277df2:             return AccessController.doPrivileged
1:d847ced:             (
1:d847ced:              new PrivilegedExceptionAction<IndexWriter>()
1:d847ced:              {
1:7234498:                  public IndexWriter run() throws IOException
1:d847ced:                  {
1:d847ced:                      // allow this to be overridden in the configuration during load later.
1:2277df2:                      IndexWriterConfig iwc = new IndexWriterConfig( luceneVersion, analyzer );
1:5cf7a46:                      IndexWriter iw = new IndexWriter( derbyLuceneDir, iwc );
1:d847ced: 		
1:d847ced:                      return iw;
1:d847ced:                  }
1:d847ced:              }
1:0b71ff5:              );
1:7234498:         } catch (PrivilegedActionException pae) {
1:7234498:             throw (IOException) pae.getCause();
1:d847ced:         }
1:d847ced: 	}
1:d847ced: 	
1:d847ced: 	/**
1:502ed2e: 	 * Add a document to a Lucene index wrier.
1:502ed2e: 	 */
1:d847ced:     private static void addDocument
1:d847ced:         (
1:d847ced:          final IndexWriter  indexWriter,
1:d847ced:          final Document     document
1:d847ced:          )
1:7234498:         throws IOException
1:d847ced:     {
1:d847ced:         try {
1:2277df2:             AccessController.doPrivileged
1:2277df2:             (
1:7234498:              new PrivilegedExceptionAction<Void>()
1:2277df2:              {
1:7234498:                  public Void run() throws IOException
1:2277df2:                  {
1:d847ced:                      indexWriter.addDocument( document );
1:2277df2: 		
1:2277df2:                      return null;
1:2277df2:                  }
1:2277df2:              }
1:2277df2:              );
1:7234498:         } catch (PrivilegedActionException pae) {
1:7234498:             throw (IOException) pae.getCause();
1:2277df2:         }
1:2277df2:     }
1:2277df2: 
1:d847ced: 	/**
1:d847ced: 	 * Close an IndexWriter.
1:d847ced: 	 */
1:d847ced:     private static void close( final IndexWriter  indexWriter )
1:7234498:         throws IOException
1:2277df2:     {
1:d847ced:         try {
2:d847ced:             AccessController.doPrivileged
1:d847ced:             (
1:7234498:              new PrivilegedExceptionAction<Void>()
1:d847ced:              {
1:7234498:                  public Void run() throws IOException
1:d847ced:                  {
1:d847ced:                      indexWriter.close();
1:2277df2: 		
2:d847ced:                      return null;
1:d847ced:                  }
1:d847ced:              }
1:2277df2:              );
1:7234498:         } catch (PrivilegedActionException pae) {
1:7234498:             throw (IOException) pae.getCause();
1:d847ced:         }
1:d847ced:     }
1:d847ced: 
1:d847ced: 	/**
1:a4e6298: 	 * Invoke a static method (possibly supplied by the user) to instantiate an index descriptor.
1:9344889:      * The method has no arguments.
1:2277df2: 	 */
1:a4e6298: 	private static LuceneIndexDescriptor getIndexDescriptor( final String indexDescriptorMaker )
1:a409436:         throws PrivilegedActionException, SQLException
1:2277df2:     {
1:2277df2:         return AccessController.doPrivileged
1:2277df2:             (
1:a4e6298:              new PrivilegedExceptionAction<LuceneIndexDescriptor>()
1:2277df2:              {
1:a4e6298:                  public LuceneIndexDescriptor run()
1:a409436:                      throws ClassNotFoundException, IllegalAccessException,
1:a409436:                      InvocationTargetException, NoSuchMethodException,
1:a409436:                      SQLException
1:2277df2:                  {
1:a4e6298:                      return getIndexDescriptorNoPrivs( indexDescriptorMaker );
1:2277df2:                  }
1:2277df2:              }
1:2277df2:              );
1:2277df2: 	}
1:2277df2: 	
1:d847ced: 	/**
1:a4e6298: 	 * Invoke a static method (possibly supplied by the user) to instantiate an index descriptor.
1:2277df2:      * The method has no arguments.
1:d847ced: 	 */
1:a4e6298: 	static LuceneIndexDescriptor getIndexDescriptorNoPrivs( String indexDescriptorMaker )
1:0b71ff5:         throws ClassNotFoundException, IllegalAccessException, InvocationTargetException,
1:a409436:                NoSuchMethodException, SQLException
1:0b71ff5:     {
1:a4e6298:         int    lastDotIdx = indexDescriptorMaker.lastIndexOf( "." );
1:a4e6298:         String  className = indexDescriptorMaker.substring( 0, lastDotIdx );
1:a409436:         ClassInspector  ci = getClassFactory().getClassInspector();
1:a409436:         Class<? extends Object>  klass = ci.getClass( className );
1:a4e6298:         String methodName = indexDescriptorMaker.substring( lastDotIdx + 1, indexDescriptorMaker.length() );
1:9344889:         Method method = klass.getDeclaredMethod( methodName );
1:0b71ff5:                      
1:a4e6298:         return (LuceneIndexDescriptor) method.invoke( null );
1:0b71ff5: 	}
1:0b71ff5: 
1:d847ced: 	/**
1:d847ced: 	 * Add a document to a Lucene index wrier.
1:d847ced: 	 */
1:502ed2e:     private static void createLuceneDir( final Connection conn )
1:502ed2e:         throws SQLException
1:502ed2e:     {
1:502ed2e:         try {
1:502ed2e:             AccessController.doPrivileged
1:502ed2e:                 (
1:502ed2e:                  new PrivilegedExceptionAction<Object>()
1:502ed2e:                  {
1:502ed2e:                      public Object run() throws SQLException
1:502ed2e:                      {
1:502ed2e:                          StorageFactory storageFactory = getStorageFactory( conn );
1:502ed2e:                          StorageFile    luceneDir = storageFactory.newStorageFile( Database.LUCENE_DIR );
1:502ed2e: 
1:502ed2e:                          luceneDir.mkdir();
1:502ed2e: 		
1:502ed2e:                          return null;
1:502ed2e:                      }
1:502ed2e:                  }
1:502ed2e:                  );
1:502ed2e:         }
1:7234498:         catch (PrivilegedActionException pae) {
1:7234498:             throw (SQLException) pae.getCause();
1:502ed2e:         }
1:0b71ff5:     }
1:502ed2e: 
1:2277df2:     /////////////////////////////////////////////////////////////////////
1:2277df2:     //
1:5cf7a46:     //  DERBY STORE
1:5cf7a46:     //
1:5cf7a46:     /////////////////////////////////////////////////////////////////////
1:5cf7a46: 
1:5cf7a46:     /**
1:5cf7a46:      * <p>
1:5cf7a46:      * Get the handle on the Lucene directory inside the database.
1:5cf7a46:      * </p>
1:5cf7a46:      */
1:5cf7a46: 	static DerbyLuceneDir getDerbyLuceneDir( Connection conn, String schema, String table, String textcol )
1:5cf7a46:         throws SQLException
1:5cf7a46:     {
1:5cf7a46:         StorageFactory  storageFactory = getStorageFactory( conn );
1:502ed2e:         DerbyLuceneDir  result = DerbyLuceneDir.getDirectory( storageFactory, schema, table, textcol );
1:5cf7a46: 
1:5cf7a46:         return result;
1:5cf7a46:     }
1:5cf7a46:     
1:5cf7a46:     /** Get the StorageFactory of the connected database */
1:5cf7a46:     static  StorageFactory  getStorageFactory( Connection conn )
1:5cf7a46:         throws SQLException
1:5cf7a46:     {
1:502ed2e:         return getDataFactory( conn ).getStorageFactory();
1:502ed2e:     }
1:502ed2e: 
1:502ed2e:     /** Get the DataFactory of the connected database */
1:502ed2e:     static  DataFactory  getDataFactory( Connection conn )
1:502ed2e:         throws SQLException
1:502ed2e:     {
1:5cf7a46:         try {
1:56c1dc2:             Object monitor = findService
1:5cf7a46:                 ( Property.DATABASE_MODULE, ((EmbedConnection) conn).getDBName() ) ;
1:56c1dc2:             return (DataFactory) findServiceModule( monitor, DataFactory.MODULE );
1:5cf7a46:         }
1:6b8ad38:         catch (StandardException se) { throw ToolUtilities.wrap( se ); }
1:5cf7a46:     }
1:5cf7a46: 
1:d847ced: 	/**
1:a409436: 		Get the ClassFactory to use with this database.
1:a409436: 	*/
1:a409436: 	static  ClassFactory getClassFactory()
1:a409436:         throws SQLException
1:a409436:     {
1:a409436: 		return ConnectionUtil.getCurrentLCC().getLanguageConnectionFactory().getClassFactory();
1:a409436: 	}
1:5cf7a46: 	
1:56c1dc2:     /**
1:56c1dc2:      * Privileged startup. Must be private so that user code
1:56c1dc2:      * can't call this entry point.
1:56c1dc2:      */
1:56c1dc2:     private  static  Object findServiceModule( final Object serviceModule, final String factoryInterface)
1:56c1dc2:         throws StandardException
1:56c1dc2:     {
1:56c1dc2:         try {
1:56c1dc2:             return AccessController.doPrivileged
1:56c1dc2:                 (
1:56c1dc2:                  new PrivilegedExceptionAction<Object>()
1:56c1dc2:                  {
1:56c1dc2:                      public Object run()
1:56c1dc2:                          throws StandardException
1:56c1dc2:                      {
1:56c1dc2:                          return Monitor.findServiceModule( serviceModule, factoryInterface );
1:56c1dc2:                      }
1:56c1dc2:                  }
1:56c1dc2:                  );
1:56c1dc2:         } catch (PrivilegedActionException pae)
1:56c1dc2:         {
1:56c1dc2:             throw StandardException.plainWrapException( pae );
1:56c1dc2:         }
1:56c1dc2:     }
1:56c1dc2: 
1:56c1dc2:     /**
1:56c1dc2:      * Privileged service lookup. Must be private so that user code
1:56c1dc2:      * can't call this entry point.
1:56c1dc2:      */
1:56c1dc2:     private static  Object findService( final String factoryInterface, final String serviceName )
1:56c1dc2:     {
1:56c1dc2:         return AccessController.doPrivileged
1:56c1dc2:             (
1:56c1dc2:              new PrivilegedAction<Object>()
1:56c1dc2:              {
1:56c1dc2:                  public Object run()
1:56c1dc2:                  {
1:56c1dc2:                      return Monitor.findService( factoryInterface, serviceName );
1:56c1dc2:                  }
1:56c1dc2:              }
1:56c1dc2:              );
1:56c1dc2:     }
1:56c1dc2:     
1:d847ced: }
============================================================================
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:6b8ad38
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.optional.utils.ToolUtilities;
/////////////////////////////////////////////////////////////////////////
1:         catch (StandardException se)    { throw ToolUtilities.sqlException( se ); }
1:         ToolUtilities.mustBeDBO( conn );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ENCRYPTED_DB );
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ALREADY_LOADED );
1:         boolean sqlAuthorizationEnabled = ToolUtilities.sqlAuthorizationEnabled( conn );
/////////////////////////////////////////////////////////////////////////
1:         ToolUtilities.mustBeDBO( conn );
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_ALREADY_UNLOADED );
/////////////////////////////////////////////////////////////////////////
1:         ToolUtilities.mustBeOwner( conn, schema );
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_INDEX_DOES_NOT_EXIST );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_NO_PRIMARY_KEY );
1:         vetColumnName( ToolUtilities.derbyIdentifier( textcol ) );
/////////////////////////////////////////////////////////////////////////
1:             query.append( delimitID( ToolUtilities.derbyIdentifier( textcol ) ) );
/////////////////////////////////////////////////////////////////////////
1:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
/////////////////////////////////////////////////////////////////////////
1:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
1:                 throw ToolUtilities.newSQLException( SQLState.LUCENE_FIELD_KEY_CONFLICT, fieldName );
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         default:  throw ToolUtilities.newSQLException( SQLState.LUCENE_UNSUPPORTED_TYPE, typeName );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException
1:                 ( SQLState.LUCENE_UNSUPPORTED_TYPE, keyDescriptor.typeName );
/////////////////////////////////////////////////////////////////////////
1:         schema = ToolUtilities.derbyIdentifier( schema );
1:         table = ToolUtilities.derbyIdentifier( table );
1:         textcol = ToolUtilities.derbyIdentifier( textcol );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.sqlException
1:                 ( StandardException.newException( SQLState.LUCENE_NOT_A_STRING_TYPE ) );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_BAD_COLUMN_NAME, derbyColumnName );
/////////////////////////////////////////////////////////////////////////
1:         schema = ToolUtilities.derbyIdentifier( schema );
1:         table = ToolUtilities.derbyIdentifier( table );
/////////////////////////////////////////////////////////////////////////
1:         schema = ToolUtilities.derbyIdentifier( schema );
/////////////////////////////////////////////////////////////////////////
1:         return ToolUtilities.derbyIdentifier( table ) + SEPARATOR +
1:             ToolUtilities.derbyIdentifier( textcol );
1:         schema = ToolUtilities.derbyIdentifier( schema );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.AUTH_WRITE_WITH_READ_ONLY_CONNECTION );
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.ARGUMENT_MAY_NOT_BE_NULL, argumentName );
/////////////////////////////////////////////////////////////////////////
1:         ResultSet   keysRS = conn.getMetaData().getPrimaryKeys
1:             ( null, ToolUtilities.derbyIdentifier( schema ), ToolUtilities.derbyIdentifier( table ) );
/////////////////////////////////////////////////////////////////////////
1:         schema = ToolUtilities.derbyIdentifier( schema );
/////////////////////////////////////////////////////////////////////////
1:             buffer.append( delimitID( ToolUtilities.derbyIdentifier( key ) ) );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException
1:                 ( SQLState.UNABLE_TO_DELETE_FILE, file.getPath() );
/////////////////////////////////////////////////////////////////////////
1:             throw ToolUtilities.newSQLException( SQLState.LUCENE_INVALID_CHARACTER, invalidCharacter );
/////////////////////////////////////////////////////////////////////////
1:         catch (StandardException se) { throw ToolUtilities.wrap( se ); }
commit:56c1dc2
/////////////////////////////////////////////////////////////////////////
1:             Object monitor = findService
1:             return (DataFactory) findServiceModule( monitor, DataFactory.MODULE );
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Privileged startup. Must be private so that user code
1:      * can't call this entry point.
1:      */
1:     private  static  Object findServiceModule( final Object serviceModule, final String factoryInterface)
1:         throws StandardException
1:     {
1:         try {
1:             return AccessController.doPrivileged
1:                 (
1:                  new PrivilegedExceptionAction<Object>()
1:                  {
1:                      public Object run()
1:                          throws StandardException
1:                      {
1:                          return Monitor.findServiceModule( serviceModule, factoryInterface );
1:                      }
1:                  }
1:                  );
1:         } catch (PrivilegedActionException pae)
1:         {
1:             throw StandardException.plainWrapException( pae );
1:         }
1:     }
1: 
1:     /**
1:      * Privileged service lookup. Must be private so that user code
1:      * can't call this entry point.
1:      */
1:     private static  Object findService( final String factoryInterface, final String serviceName )
1:     {
1:         return AccessController.doPrivileged
1:             (
1:              new PrivilegedAction<Object>()
1:              {
1:                  public Object run()
1:                  {
1:                      return Monitor.findService( factoryInterface, serviceName );
1:                  }
1:              }
1:              );
1:     }
1:     
commit:19ca71c
/////////////////////////////////////////////////////////////////////////
0:         vetColumnName( derbyIdentifier( textcol ) );
/////////////////////////////////////////////////////////////////////////
1:         String  derbyColumnName = columnName;
commit:3240e21
/////////////////////////////////////////////////////////////////////////
1:                 String  keyName = delimitID( keyDesc.columnName );
/////////////////////////////////////////////////////////////////////////
0:             query.append( delimitID( derbyIdentifier( textcol ) ) );
/////////////////////////////////////////////////////////////////////////
1:     /** Double quote an identifier in order to preserver casing */
1:     static String delimitID( String id )
1:     {
1:         return IdUtil.normalToDelimited( id );
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1: 
0:             buffer.append( delimitID( derbyIdentifier( key ) ) );
commit:7e538ec
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashSet;
/////////////////////////////////////////////////////////////////////////
1:         // make sure the field names don't overlap with the key names
1:         sortAndVetFieldNames( fieldNames, primaryKeys );
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * Raise an exception if a field has the same name as a key or if two
1:      * fields have the same name.
1:      */
1:     private static  void    sortAndVetFieldNames( String[] fieldNames, VTITemplate.ColumnDescriptor[] keys )
1:         throws SQLException
1:     {
1:         for ( String fieldName : fieldNames )
1:         {
1:             if ( fieldName == null )
1:             {
0:                 throw newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
1:             }
1:         }
1:         Arrays.sort( fieldNames );
1:         
1:         HashSet<String>   keyNames = new HashSet<String>();
1:         for ( VTITemplate.ColumnDescriptor cd : keys ) { keyNames.add( cd.columnName ); }
1: 
1:         String  previousFieldName = null;
1:         for ( String fieldName : fieldNames )
1:         {
1:             if ( fieldName.equals( previousFieldName ) )
1:             {
0:                 throw newSQLException( SQLState.LUCENE_DUPLICATE_FIELD_NAME, fieldName );
1:             }
1:             previousFieldName = fieldName;
1: 
1:             if ( keyNames.contains( fieldName ) )
1:             {
0:                 throw newSQLException( SQLState.LUCENE_FIELD_KEY_CONFLICT, fieldName );
1:             }
1:         }
1:     }
commit:a4e6298
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.optional.api.LuceneIndexDescriptor;
/////////////////////////////////////////////////////////////////////////
1:     public  static  final   String  INDEX_DESCRIPTOR_MAKER = "derby.lucene.index.descriptor.maker";
/////////////////////////////////////////////////////////////////////////
1: 		listFunction.append("indexdescriptormaker varchar( 32672 )");
/////////////////////////////////////////////////////////////////////////
1: 		createProcedure.append("indexdescriptormaker varchar( 32672 ),");
/////////////////////////////////////////////////////////////////////////
1: 		updateProcedure.append("indexdescriptormaker varchar( 32672 ))");
/////////////////////////////////////////////////////////////////////////
1: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, windowSize, scoreCeiling );
/////////////////////////////////////////////////////////////////////////
1: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
1: 	public static void updateIndex( String schema, String table, String textcol, String indexDescriptorMaker )
/////////////////////////////////////////////////////////////////////////
1:         createOrRecreateIndex( conn, schema, table, textcol, indexDescriptorMaker, false );
/////////////////////////////////////////////////////////////////////////
1: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
/////////////////////////////////////////////////////////////////////////
1:          String indexDescriptorMaker,
/////////////////////////////////////////////////////////////////////////
1:         createOrRecreateIndex( conn, schema, table, textcol, indexDescriptorMaker, true, keyColumns );
/////////////////////////////////////////////////////////////////////////
1: 	 * @param indexDescriptorMaker name of static method which instantiates the index configuration. may be null.
/////////////////////////////////////////////////////////////////////////
1:          String indexDescriptorMaker,
/////////////////////////////////////////////////////////////////////////
1:         // get the Analyzer and the field names. use the default if the user didn't specify an override
1:         if ( indexDescriptorMaker == null ) { indexDescriptorMaker = LuceneUtils.class.getName() + ".defaultIndexDescriptor"; }
1:         LuceneIndexDescriptor   indexDescriptor = getIndexDescriptor( indexDescriptorMaker );
1:         String[]  fieldNames = indexDescriptor.getFieldNames();
1:         Analyzer    analyzer = indexDescriptor.getAnalyzer();
1:         indexProperties.setProperty( INDEX_DESCRIPTOR_MAKER, indexDescriptorMaker );
1:         tableFunction.append( "( query varchar( 32672 ), windowSize int, scoreCeiling real )\n" );
/////////////////////////////////////////////////////////////////////////
1:                     for ( String fieldName : fieldNames )
1:                     {
1:                         doc.add( new TextField( fieldName, textcolValue, Store.NO ) );
1:                     }
/////////////////////////////////////////////////////////////////////////
1: 	 * Invoke a static method (possibly supplied by the user) to instantiate an index descriptor.
1: 	private static LuceneIndexDescriptor getIndexDescriptor( final String indexDescriptorMaker )
1:              new PrivilegedExceptionAction<LuceneIndexDescriptor>()
1:                  public LuceneIndexDescriptor run()
1:                      return getIndexDescriptorNoPrivs( indexDescriptorMaker );
1: 	 * Invoke a static method (possibly supplied by the user) to instantiate an index descriptor.
1: 	static LuceneIndexDescriptor getIndexDescriptorNoPrivs( String indexDescriptorMaker )
1:         int    lastDotIdx = indexDescriptorMaker.lastIndexOf( "." );
1:         String  className = indexDescriptorMaker.substring( 0, lastDotIdx );
1:         String methodName = indexDescriptorMaker.substring( lastDotIdx + 1, indexDescriptorMaker.length() );
1:         return (LuceneIndexDescriptor) method.invoke( null );
commit:4f7c143
/////////////////////////////////////////////////////////////////////////
1:         vetIdentifiers( schema, table, textcol );
1: 
/////////////////////////////////////////////////////////////////////////
1:         vetIdentifiers( schema, table, textcol );
1: 
/////////////////////////////////////////////////////////////////////////
1:     /** Verify that the schema, table, and column names aren't null */
1: 	private static void vetIdentifiers
1:         (
1:          String schema,
1:          String table,
1:          String textcol
1:          )
1:         throws SQLException
1:     {
1:         checkNotNull( "SCHEMANAME", schema );
1:         checkNotNull( "TABLENAME", table );
1:         checkNotNull( "TEXTCOLUMN", textcol );
1:     }
1:     
/////////////////////////////////////////////////////////////////////////
1:         vetIdentifiers( schema, table, textcol );
1: 
/////////////////////////////////////////////////////////////////////////
1:     /** Raise an error if an argument is being given a null value */
1:     static  void    checkNotNull( String argumentName, String argumentValue )
1:         throws SQLException
1:     {
1:         if ( argumentValue == null )
1:         {
0:             throw newSQLException( SQLState.ARGUMENT_MAY_NOT_BE_NULL, argumentName );
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:             checkNotNull( "KEYCOLUMNS", key );
1:             
commit:abb2084
/////////////////////////////////////////////////////////////////////////
1:         // Lucene fields do not allow null values
1:         if ( rs.wasNull() ) { field = null; }
1: 
commit:4e1453d
/////////////////////////////////////////////////////////////////////////
1:         writeIndexProperties( propertiesFile, indexProperties );
1:         
/////////////////////////////////////////////////////////////////////////
commit:a409436
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.services.loader.ClassFactory;
1: import org.apache.derby.iapi.services.loader.ClassInspector;
/////////////////////////////////////////////////////////////////////////
1:         throws PrivilegedActionException, SQLException
1:                      throws ClassNotFoundException, IllegalAccessException,
1:                      InvocationTargetException, NoSuchMethodException,
1:                      SQLException
/////////////////////////////////////////////////////////////////////////
1:                NoSuchMethodException, SQLException
0:         String  className = analyzerMaker.substring( 0, lastDotIdx );
1:         ClassInspector  ci = getClassFactory().getClassInspector();
1:         Class<? extends Object>  klass = ci.getClass( className );
/////////////////////////////////////////////////////////////////////////
1: 	/**
1: 		Get the ClassFactory to use with this database.
1: 	*/
1: 	static  ClassFactory getClassFactory()
1:         throws SQLException
1:     {
1: 		return ConnectionUtil.getCurrentLCC().getLanguageConnectionFactory().getClassFactory();
1: 	}
commit:4cedf31
/////////////////////////////////////////////////////////////////////////
1:          Float scoreCeiling
commit:502ed2e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.database.Database;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         //
1:         // Lucene indexes are not allowed in encrypted databases. They leak
1:         // encrypted data in plaintext.
1:         //
1:         if ( getDataFactory( conn ).databaseEncrypted() )
1:         {
0:             throw newSQLException( SQLState.LUCENE_ENCRYPTED_DB );
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:         createLuceneDir( conn );
/////////////////////////////////////////////////////////////////////////
0:             StorageFile     luceneDir = storageFactory.newStorageFile( Database.LUCENE_DIR );
/////////////////////////////////////////////////////////////////////////
0:     static  String  derbyIdentifier( String rawString )
/////////////////////////////////////////////////////////////////////////
1: 	/**
1: 	 * Add a document to a Lucene index wrier.
1: 	 */
1:     private static void createLuceneDir( final Connection conn )
1:         throws SQLException
1:     {
1:         try {
1:             AccessController.doPrivileged
1:                 (
1:                  new PrivilegedExceptionAction<Object>()
1:                  {
1:                      public Object run() throws SQLException
1:                      {
1:                          StorageFactory storageFactory = getStorageFactory( conn );
1:                          StorageFile    luceneDir = storageFactory.newStorageFile( Database.LUCENE_DIR );
1: 
1:                          luceneDir.mkdir();
1: 		
1:                          return null;
1:                      }
1:                  }
1:                  );
1:         }
0:         catch (PrivilegedActionException pae) { throw wrap( pae ); }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:         DerbyLuceneDir  result = DerbyLuceneDir.getDirectory( storageFactory, schema, table, textcol );
1:         return getDataFactory( conn ).getStorageFactory();
1:     }
1: 
1:     /** Get the DataFactory of the connected database */
1:     static  DataFactory  getDataFactory( Connection conn )
1:         throws SQLException
1:     {
0:             return (DataFactory) Monitor.findServiceModule( monitor, DataFactory.MODULE );
commit:5cf7a46
/////////////////////////////////////////////////////////////////////////
1: import java.io.InputStream;
1: import java.io.OutputStream;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.reference.Property;
1: import org.apache.derby.iapi.services.monitor.Monitor;
1: import org.apache.derby.iapi.store.raw.data.DataFactory;
1: import org.apache.derby.io.StorageFactory;
1: import org.apache.derby.io.StorageFile;
/////////////////////////////////////////////////////////////////////////
0:     static  final   String  LUCENE_DIR = "lucene";
/////////////////////////////////////////////////////////////////////////
1:             StorageFactory  storageFactory = getStorageFactory( conn );
0:             StorageFile     luceneDir = storageFactory.newStorageFile( LUCENE_DIR );
0:             if ( exists( luceneDir ) ) { deleteFile( luceneDir ); }
/////////////////////////////////////////////////////////////////////////
1:         StorageFile propertiesFile = getIndexPropertiesFile( conn, schema, table, textcol );
/////////////////////////////////////////////////////////////////////////
1:         // create the new directory
1:         DerbyLuceneDir  derbyLuceneDir = getDerbyLuceneDir( conn, schema, table, textcol );
1: 
/////////////////////////////////////////////////////////////////////////
1:             iw = getIndexWriter( luceneVersion, analyzer, derbyLuceneDir );
/////////////////////////////////////////////////////////////////////////
1:         DerbyLuceneDir  derbyLuceneDir = getDerbyLuceneDir( getDefaultConnection(), schema, table, textcol );
1:         StorageFile indexDir = derbyLuceneDir.getDirectory();
1: 		StorageFile tableDir = indexDir.getParentDir();
1:         StorageFile schemaDir = tableDir.getParentDir();
1: 		
/////////////////////////////////////////////////////////////////////////
1: 	static StorageFile getIndexPropertiesFile( Connection conn, String schema, String table, String textcol )
1:         return getIndexPropertiesFile( getDerbyLuceneDir( conn, schema, table, textcol ) );
1:     }
1:     
1:     /**
1:      * <p>
1:      * Get the handle on the file holding the index properties.
1:      * </p>
1:      */
1: 	static StorageFile getIndexPropertiesFile( DerbyLuceneDir dir )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
1:         StorageFile         propertiesFile = dir.getFile( PROPERTIES_FILE_NAME );
1:     static  Properties readIndexPropertiesNoPrivs( StorageFile file )
1:         InputStream is = file.getInputStream();
1:         properties.load( is );
1:         is.close();
0:     private static  void    writeIndexProperties( final StorageFile file, final Properties properties )
/////////////////////////////////////////////////////////////////////////
0:                         OutputStream    os = file.getOutputStream();
1:                         properties.store( os, null );
1:                         os.flush();
1:                         os.close();
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     private static  boolean isEmpty( final StorageFile dir )
1:         String[]  contents = AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<String[]>()
1:              {
0:                  public String[] run() throws IOException, SQLException
1:                 {
1:                     return dir.list();
1:                 }
1:              }
1:              );
1:     /** Return true if the file exists */
1:     private static  boolean exists( final StorageFile file )
0:                  public Boolean run() throws IOException, SQLException
1:                     return file.exists();
1:     private static  boolean deleteFile( final StorageFile file )
/////////////////////////////////////////////////////////////////////////
0:                     boolean result = file.isDirectory() ? file.deleteAll() : file.delete();
0:                         throw newSQLException( SQLState.UNABLE_TO_DELETE_FILE, file.getPath() );
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:          final DerbyLuceneDir   derbyLuceneDir
/////////////////////////////////////////////////////////////////////////
1:                      IndexWriter iw = new IndexWriter( derbyLuceneDir, iwc );
/////////////////////////////////////////////////////////////////////////
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  DERBY STORE
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * <p>
1:      * Get the handle on the Lucene directory inside the database.
1:      * </p>
1:      */
1: 	static DerbyLuceneDir getDerbyLuceneDir( Connection conn, String schema, String table, String textcol )
1:         throws SQLException
1:     {
0:         StorageFactory  storageFactory = getStorageFactory( conn );
0:         String  relativePath = getRelativeIndexPath( schema, table, textcol );
0:         DerbyLuceneDir  result = DerbyLuceneDir.getDirectory( storageFactory, relativePath );
1: 
1:         return result;
1:     }
1:     
1:     /**
1:      * <p>
0:      * Get the relative path of the index in the database.
1:      * </p>
1:      */
0:     private static String getRelativeIndexPath( String schema, String table, String textcol )
1:         throws SQLException
1:     {
0:         return
0:             LUCENE_DIR + File.separator +
0:             derbyIdentifier( schema ) + File.separator +
0:             derbyIdentifier( table ) + File.separator +
0:             derbyIdentifier( textcol ) + File.separator;
1:     }
1: 
1:     
1:     /** Get the StorageFactory of the connected database */
1:     static  StorageFactory  getStorageFactory( Connection conn )
1:         throws SQLException
1:     {
1:         try {
0:             Object monitor = Monitor.findService
1:                 ( Property.DATABASE_MODULE, ((EmbedConnection) conn).getDBName() ) ;
0:             DataFactory dataFactory = (DataFactory) Monitor.findServiceModule( monitor, DataFactory.MODULE );
1: 
0:             return dataFactory.getStorageFactory();
1:         }
0:         catch (StandardException se) { throw wrap( se ); }
1:     }
1: 
commit:9344889
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.error.PublicAPI;
/////////////////////////////////////////////////////////////////////////
0:         return PublicAPI.wrapStandardException( se );
/////////////////////////////////////////////////////////////////////////
0:     private static  Properties readIndexProperties( final File file )
/////////////////////////////////////////////////////////////////////////
0:                     return readIndexPropertiesNoPrivs( file );
1:     /** Read the index properties file */
0:     static  Properties readIndexPropertiesNoPrivs( File file )
1:         throws IOException
1:     {
1:         if ( file == null ) { return null; }
1:         
1:         Properties  properties = new Properties();
0:         FileInputStream fis = new FileInputStream( file );
1: 
0:         properties.load( fis );
0:         fis.close();
1:                         
1:         return properties;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
0:     private static  boolean deleteFile( File file )
/////////////////////////////////////////////////////////////////////////
0:     private static  boolean isDirectory( final File file )
/////////////////////////////////////////////////////////////////////////
0:     private static  File[]  listFiles( final File file, final FileFilter fileFilter )
/////////////////////////////////////////////////////////////////////////
0:     private static  boolean fileExists( final File file )
/////////////////////////////////////////////////////////////////////////
0: 	private static Analyzer getAnalyzer( final String analyzerMaker )
/////////////////////////////////////////////////////////////////////////
0:                      return getAnalyzerNoPrivs( analyzerMaker );
0: 	 * Invoke a static method (possibly supplied by the user) to instantiate an Analyzer.
1:      * The method has no arguments.
0: 	static Analyzer getAnalyzerNoPrivs( String analyzerMaker )
0:                NoSuchMethodException
0:         int    lastDotIdx = analyzerMaker.lastIndexOf( "." );
0:         Class<? extends Object>  klass = Class.forName( analyzerMaker.substring( 0, lastDotIdx ) );
0:         String methodName = analyzerMaker.substring( lastDotIdx + 1, analyzerMaker.length() );
1:         Method method = klass.getDeclaredMethod( methodName );
0:         return (Analyzer) method.invoke( null );
commit:0b71ff5
/////////////////////////////////////////////////////////////////////////
0: import org.apache.lucene.queryparser.classic.QueryParser;
/////////////////////////////////////////////////////////////////////////
0:          String queryParserMaker,
0: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, queryParserMaker, windowSize, scoreCeiling );
/////////////////////////////////////////////////////////////////////////
0:         tableFunction.append( "( query varchar( 32672 ), queryParserMaker varchar( 32672 ), windowSize int, scoreCeiling real )\n" );
/////////////////////////////////////////////////////////////////////////
1: 	/**
0: 	 * Invoke a static method (possibly supplied by the user) to instantiate a QueryParser.
1:      *
0:      * @param queryParserMaker  Full name of public, static method whicn instantiates a QueryParser given the following arguments.
0:      * @param version   Lucene version.
0:      * @param fieldName Name of field holding the indexed text.
0:      * @param analyzer  Analyzer used to index the text.
1: 	 */
0: 	static QueryParser getQueryParser
1:         (
0:          final String queryParserMaker,
0:          final Version version,
0:          final String fieldName,
0:          final Analyzer analyzer
1:          )
1:         throws ClassNotFoundException, IllegalAccessException, InvocationTargetException,
0:                NoSuchMethodException, PrivilegedActionException
1:     {
1:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<QueryParser>()
1:              {
0:                  public QueryParser run()
0:                      throws ClassNotFoundException, IllegalAccessException, InvocationTargetException, NoSuchMethodException
1:                  {
0:                      int    lastDotIdx = queryParserMaker.lastIndexOf( "." );
0:                      Class<? extends Object>  klass = Class.forName( queryParserMaker.substring( 0, lastDotIdx ) );
0:                      String methodName = queryParserMaker.substring( lastDotIdx + 1, queryParserMaker.length() );
0:                      Method method = klass.getDeclaredMethod( methodName, Version.class, String.class, Analyzer.class );
1:                      
0:                      return (QueryParser) method.invoke( null, version, fieldName, analyzer );
1:                  }
1:              }
1:              );
1: 	}
1: 	
commit:9cc25e2
/////////////////////////////////////////////////////////////////////////
1:          int    windowSize,
0: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, windowSize, scoreCeiling );
/////////////////////////////////////////////////////////////////////////
0:         tableFunction.append( "( query varchar( 32672 ), windowSize int, scoreCeiling real )\n" );
commit:cbdf827
/////////////////////////////////////////////////////////////////////////
1:     // names of columns in all query table functions
1:     private static  final   String  SCORE = "SCORE";
1:     private static  final   String  DOCUMENT_ID = "DOCUMENTID";
1: 
/////////////////////////////////////////////////////////////////////////
1: 	 * @param scoreCeiling Return results only below this score
/////////////////////////////////////////////////////////////////////////
0:          float scoreCeiling
0: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, scoreCeiling );
/////////////////////////////////////////////////////////////////////////
1:         // don't let the user create a table function with duplicate column names
0:         vetColumnName( textcol );
1:         for ( VTITemplate.ColumnDescriptor key : primaryKeys )
1:         {
1:             vetColumnName(  key.columnName );
1:         }
1:         
1:         int             keyCount = 0;
/////////////////////////////////////////////////////////////////////////
0:         tableFunction.append( "( query varchar( 32672 ), scoreCeiling real )\n" );
/////////////////////////////////////////////////////////////////////////
1:             tableFunction.append(",\n\t" + DOCUMENT_ID + " int");
1:             tableFunction.append(",\n\t" + SCORE + " real");
/////////////////////////////////////////////////////////////////////////
1:      * A Lucene query table function already has system-supplied columns
1:      * named documentID and score. These can't be the names of the key
1:      * or text columns supplied by the user.
1:      */
1:     private static  void    vetColumnName( String columnName )
1:         throws SQLException
1:     {
0:         String  derbyColumnName = derbyIdentifier( columnName );
1: 
1:         if (
1:             DOCUMENT_ID.equals( derbyColumnName ) ||
1:             SCORE.equals( derbyColumnName )
1:             )
1:         {
0:             throw newSQLException( SQLState.LUCENE_BAD_COLUMN_NAME, derbyColumnName );
1:         }
1:     }
1: 
1:     /**
/////////////////////////////////////////////////////////////////////////
1:         // remove the last two columns, which are not keys. they are the DOCUMENTID and SCORE columns.
commit:8fbaf26
/////////////////////////////////////////////////////////////////////////
0:                         FileInputStream fis = new FileInputStream( file );
0:                         properties.load( fis );
0:                         fis.close();
/////////////////////////////////////////////////////////////////////////
0:         throws IOException, SQLException, PrivilegedActionException
1: 
0:         if ( !fileExists( file ) ) { return false; }
/////////////////////////////////////////////////////////////////////////
0:         throws IOException, SQLException, PrivilegedActionException
0:                  public Boolean run() throws IOException, SQLException
0:                     boolean result = file.delete();
1: 
0:                     if ( !result )
1:                     {
0:                         throw newSQLException( SQLState.UNABLE_TO_DELETE_FILE, file.getAbsolutePath() );
1:                     }
1: 
1:                     return result;
commit:96e2ea4
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.sql.dictionary.DataDictionary;
/////////////////////////////////////////////////////////////////////////
1: 
1:         // not allowed during soft-upgrade
1:         try {
1:             ConnectionUtil.getCurrentLCC().getDataDictionary().checkVersion
1:                 ( DataDictionary.DD_VERSION_DERBY_10_11, "luceneSupport" );
1:         }
0:         catch (StandardException se)    { throw sqlException( se ); }
commit:2a8df97
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.sql.conn.ConnectionUtil;
/////////////////////////////////////////////////////////////////////////
1:         forbidReadOnlyConnections();
1:         
/////////////////////////////////////////////////////////////////////////
1:         forbidReadOnlyConnections();
1:         
/////////////////////////////////////////////////////////////////////////
1:         forbidReadOnlyConnections();
1: 
/////////////////////////////////////////////////////////////////////////
1:         forbidReadOnlyConnections();
1:         
/////////////////////////////////////////////////////////////////////////
1:         forbidReadOnlyConnections();
1:         
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Raise an error if the connection is readonly.
1:      */
1:     private static  void    forbidReadOnlyConnections()
1:         throws SQLException
1:     {
1:         if ( ConnectionUtil.getCurrentLCC().getAuthorizer().isReadOnlyConnection() )
1:         {
0:             throw newSQLException( SQLState.AUTH_WRITE_WITH_READ_ONLY_CONNECTION );
1:         }
1:     }
1: 
commit:fcf3e6d
/////////////////////////////////////////////////////////////////////////
0: 		createProcedure.append("analyzerMaker varchar( 32672 ),");
1: 		createProcedure.append("keyColumns varchar( 32672 )...)");
1: 		createProcedure.append("parameter style derby modifies sql data language java external name ");
/////////////////////////////////////////////////////////////////////////
1: 	 * @param table The table or view containing the indexable column
1: 	 * @param keyColumns names of key columns if we're indexing a column in a view
1: 	public static void createIndex
1:         (
1:          String schema,
1:          String table,
1:          String textcol,
0:          String analyzerMaker,
1:          String... keyColumns
1:          )
/////////////////////////////////////////////////////////////////////////
0:         createOrRecreateIndex( conn, schema, table, textcol, analyzerMaker, true, keyColumns );
/////////////////////////////////////////////////////////////////////////
1:          boolean create,
1:          String... keyColumns
1:         VTITemplate.ColumnDescriptor[] primaryKeys = new VTITemplate.ColumnDescriptor[ 0 ];
1: 
1:         // can't override keys when the index is updated
1:         if ( !create )
1:         { primaryKeys = getKeys( conn, schema, table, textcol ); }
1:         // use the supplied keys if possible
1:         else if ( (keyColumns != null) && (keyColumns.length > 0) )
1:         { primaryKeys = getKeys( conn, schema, table, keyColumns ); }
1:         else
1:         { primaryKeys = getPrimaryKeys( conn, schema, table  ); }
1: 
1:         // can't create an index without specifying keys for joining it back to Derby data
/////////////////////////////////////////////////////////////////////////
0:                 String  keyName = derbyIdentifier( keyDesc.columnName );
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Return the key columns for an existing LuceneQueryVTI table function.
1:      */
1:     private static  VTITemplate.ColumnDescriptor[] getKeys
1:         (
1:          Connection conn,
1:          String schema,
1:          String table,
1:          String textcol
1:          )
1:         throws SQLException
1:     {
0:         schema = derbyIdentifier( schema );
1:         String  functionName = makeUnqualifiedTableFunctionName( table, textcol );
1:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1: 
1:         ResultSet   rs = conn.getMetaData().getFunctionColumns( null, schema, functionName, "%" );
1:         try {
1:             while ( rs.next() )
1:             {
1:                 if ( rs.getInt( "COLUMN_TYPE" ) == DatabaseMetaData.functionColumnResult )
1:                 {
1:                     VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:                         (
1:                          rs.getString( "COLUMN_NAME" ),
1:                          rs.getInt( "DATA_TYPE" ),
1:                          rs.getInt( "PRECISION" ),
1:                          rs.getInt( "SCALE" ),
1:                          rs.getString( "TYPE_NAME" ),
1:                          rs.getInt( "ORDINAL_POSITION" )
1:                          );
1:                     keyArray.add( keyDescriptor );
1:                 }
1:             }
1:         }
1:         finally
1:         {
1:             rs.close();
1:         }
1:         
1:         VTITemplate.ColumnDescriptor[] temp = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:         keyArray.toArray( temp );
1:         Arrays.sort( temp );
1: 
0:         // remove the last two columns, which are not keys. they are the DOCUMENT_ID and RANK columns.
1:         int     count = temp.length - 2;
1:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ count ];
1:         for ( int i = 0; i < count; i++ ) { result[ i ] = temp[ i ]; }
1: 
1:         return result;
1:     }
1:     
1:     /**
1:      * Return column information for a proposed set of keys.
1:      */
1:     private static  VTITemplate.ColumnDescriptor[] getKeys
1:         (
1:          Connection conn,
1:          String schema,
1:          String table,
1:          String... keyColumns
1:          )
1:         throws SQLException
1:     {
1:         String      qualifiedName = makeTableName( schema, table );
1:         StringBuilder   buffer = new StringBuilder();
1: 
1:         buffer.append( "select " );
1:         int counter = 0;
1:         for ( String key : keyColumns )
1:         {
1:             if ( counter > 0 ) { buffer.append( ", " ); }
1:             counter++;
0:             buffer.append( derbyIdentifier( key ) );
1:         }
1:         buffer.append( "\nfrom " + qualifiedName );
1:         buffer.append( "\nwhere 1=2" );
1: 
1:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1: 
1:         ResultSet   rs = conn.prepareStatement( buffer.toString() ).executeQuery();
1:         ResultSetMetaData   rsmd = rs.getMetaData();
1:         try {
1:             for ( int keyPosition = 1; keyPosition <= rsmd.getColumnCount(); keyPosition++ )
1:             {
1:                 VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:                     (
1:                      rsmd.getColumnName( keyPosition ),
1:                      rsmd.getColumnType( keyPosition ),
1:                      rsmd.getPrecision( keyPosition ),
1:                      rsmd.getScale( keyPosition ),
1:                      rsmd.getColumnTypeName( keyPosition ),
1:                      keyPosition
1:                      );
1:                 keyArray.add( keyDescriptor );
1:             }
1:         }
1:         finally
1:         {
1:             rs.close();
1:         }
1:         
1:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:         keyArray.toArray( result );
1: 
1:         return result;
1:     }
1:     
1: 
commit:fbf176c
/////////////////////////////////////////////////////////////////////////
1:    Class org.apache.derby.optional.lucene.LuceneSupport
/////////////////////////////////////////////////////////////////////////
1: package org.apache.derby.optional.lucene;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.optional.api.LuceneUtils;
/////////////////////////////////////////////////////////////////////////
1: 	 * @see org.apache.derby.optional.lucene.LuceneQueryVTI
/////////////////////////////////////////////////////////////////////////
1:             tableFunction.append( "external name '" + LuceneSupport.class.getName() + ".luceneQuery'" );
commit:2277df2
/////////////////////////////////////////////////////////////////////////
0: import java.io.FileInputStream;
0: import java.io.FileOutputStream;
1: import java.lang.reflect.InvocationTargetException;
1: import java.lang.reflect.Method;
/////////////////////////////////////////////////////////////////////////
1: import java.util.Properties;
0: import org.apache.derby.optional.LuceneUtils;
/////////////////////////////////////////////////////////////////////////
1: 
1:     // file which holds properties specific to a Lucene index
1:     private static  final   String  PROPERTIES_FILE_NAME = "derby-lucene.properties";
1: 
1:     // properties which go in that file
1: 
1:     /** property identifying the static method which materializes an Analyzer for the index */
0:     public  static  final   String  ANALYZER_MAKER = "derby.lucene.analyzer.maker";
1: 
1:     /** class name of the Analyzer used for the index */
1:     public  static  final   String  ANALYZER = "derby.lucene.analyzer";
1: 
1:     /** version of Lucene used to create or recreate an index */
1:     public  static  final   String  LUCENE_VERSION = "derby.lucene.version";
1: 	
1:     /** system time when the index was created/updated */
1:     public  static  final   String  UPDATE_TIMESTAMP = "derby.lucene.last.updated";
/////////////////////////////////////////////////////////////////////////
1: 		listFunction.append("lastupdated timestamp,");
1: 		listFunction.append("luceneversion varchar( 20 ),");
1: 		listFunction.append("analyzer varchar( 32672 ),");
0: 		listFunction.append("analyzermaker varchar( 32672 )");
/////////////////////////////////////////////////////////////////////////
1: 		createProcedure.append("textcolumn varchar( 128 ),");
0: 		createProcedure.append("analyzerMaker varchar( 32672 ))");
/////////////////////////////////////////////////////////////////////////
1: 		updateProcedure.append("textcolumn varchar( 128 ),");
0: 		updateProcedure.append("analyzerMaker varchar( 32672 ))");
/////////////////////////////////////////////////////////////////////////
0: 	 * @param analyzerMaker name of static method which instantiates an Analyzer. may be null.
0: 	public static void updateIndex( String schema, String table, String textcol, String analyzerMaker )
0:         throws SQLException, IOException, PrivilegedActionException,
0:                ClassNotFoundException, IllegalAccessException, InvocationTargetException, NoSuchMethodException
/////////////////////////////////////////////////////////////////////////
0:         createOrRecreateIndex( conn, schema, table, textcol, analyzerMaker, false );
/////////////////////////////////////////////////////////////////////////
0: 	 * @param analyzerMaker name of static method which instantiates an Analyzer. may be null.
0: 	public static void createIndex( String schema, String table, String textcol, String analyzerMaker )
0:         throws SQLException, IOException, PrivilegedActionException,
0:                ClassNotFoundException, IllegalAccessException, InvocationTargetException, NoSuchMethodException
/////////////////////////////////////////////////////////////////////////
0:         createOrRecreateIndex( conn, schema, table, textcol, analyzerMaker, true );
/////////////////////////////////////////////////////////////////////////
0: 	 * @param analyzerMaker name of static method which instantiates an Analyzer. may be null.
/////////////////////////////////////////////////////////////////////////
0:          String analyzerMaker,
0:         throws SQLException, IOException, PrivilegedActionException,
0:                ClassNotFoundException, IllegalAccessException, InvocationTargetException, NoSuchMethodException
/////////////////////////////////////////////////////////////////////////
0:         File            propertiesFile = getIndexPropertiesFile( conn, schema, table, textcol );
1: 
1:         if ( !create )
1:         {
1:             dropIndexDirectories( schema, table, textcol );
1:         }
1: 
1:         Version luceneVersion = LuceneUtils.currentVersion();
1: 
0:         // get the Analyzer. use the default if the user didn't specify an override
0:         if ( analyzerMaker == null ) { analyzerMaker = LuceneUtils.class.getName() + ".defaultAnalyzer"; }
0:         Analyzer    analyzer = getAnalyzer( analyzerMaker );
1: 
1:         Properties  indexProperties = new Properties();
1:         indexProperties.setProperty( LUCENE_VERSION, luceneVersion.toString() );
1:         indexProperties.setProperty( UPDATE_TIMESTAMP, Long.toString( System.currentTimeMillis() ) );
0:         indexProperties.setProperty( ANALYZER_MAKER, analyzerMaker );
1:         indexProperties.setProperty( ANALYZER, analyzer.getClass().getName() );
/////////////////////////////////////////////////////////////////////////
0:             iw = getIndexWriter( luceneVersion, analyzer, schema, table, textcol );
/////////////////////////////////////////////////////////////////////////
1: 
0:                 writeIndexProperties( propertiesFile, indexProperties );
/////////////////////////////////////////////////////////////////////////
1:     //  MANAGE THE INDEX PROPERTIES FILE
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * <p>
1:      * Get the handle on the file holding the index properties.
1:      * </p>
1:      */
0: 	static File getIndexPropertiesFile( Connection conn, String schema, String table, String textcol )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
0: 		File indexDir = new File( getIndexLocation( conn, schema, table, textcol ) );
0:         File    propertiesFile = new File( indexDir, PROPERTIES_FILE_NAME );
1: 
1:         return propertiesFile;
1:     }
1:     
0:     /** Read the index properties file */
0:     static  Properties readIndexProperties( final File file )
0:         throws IOException, PrivilegedActionException
1:     {
1:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Properties>()
1:              {
0:                 public Properties run() throws IOException
1:                 {
0:                     if ( file == null ) { return null; }
1:                     else
1:                     {
0:                         Properties  properties = new Properties();
1: 
0:                         properties.load( new FileInputStream( file ) );
1:                         
0:                         return properties;
1:                     }
1:                 }
1:              }
1:              );
1:     }
1: 
1:     /** Write the index properties file */
0:     private static  void    writeIndexProperties( final File file, final Properties properties )
0:         throws IOException, PrivilegedActionException
1:     {
1:         AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Object>()
1:              {
0:                 public Object run() throws IOException
1:                 {
0:                     if ( (file == null) || (properties == null) ) { return null; }
1:                     else
1:                     {
0:                         FileOutputStream    fos = new FileOutputStream( file );
1: 
0:                         properties.store( fos, null );
0:                         fos.flush();
0:                         fos.close();
1: 
1:                         return null;
1:                     }
1:                 }
1:              }
1:              );
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
/////////////////////////////////////////////////////////////////////////
0:     /** Return true if the file exists */
0:     static  boolean fileExists( final File file )
0:         throws IOException, PrivilegedActionException
1:     {
1:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Boolean>()
1:              {
0:                 public Boolean run() throws IOException
1:                 {
0:                     if ( file == null ) { return false; }
0:                     else { return file.exists(); }
1:                 }
1:              }
1:              ).booleanValue();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1: 	 * @param luceneVersion the version of Lucene being used
1: 	 * @param analyzer      the Analyzer being used
/////////////////////////////////////////////////////////////////////////
1:          final Version  luceneVersion,
1:          final  Analyzer    analyzer,
/////////////////////////////////////////////////////////////////////////
1:                      IndexWriterConfig iwc = new IndexWriterConfig( luceneVersion, analyzer );
0:                      IndexWriter iw = new IndexWriter( dir, iwc );
/////////////////////////////////////////////////////////////////////////
1: 	/**
0: 	 * Invoke a static method (possibly supplied by the user) to instantiate an Analyzer.
1:      * The method has no arguments.
1: 	 */
0: 	static Analyzer getAnalyzer( final String analyzerMaker )
0:         throws ClassNotFoundException, IllegalAccessException, InvocationTargetException,
0:                NoSuchMethodException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Analyzer>()
1:              {
0:                  public Analyzer run()
0:                      throws ClassNotFoundException, IllegalAccessException, InvocationTargetException, NoSuchMethodException
1:                  {
0:                      int    lastDotIdx = analyzerMaker.lastIndexOf( "." );
0:                      Class<? extends Object>  klass = Class.forName( analyzerMaker.substring( 0, lastDotIdx ) );
0:                      String methodName = analyzerMaker.substring( lastDotIdx + 1, analyzerMaker.length() );
0:                      Method method = klass.getDeclaredMethod( methodName );
1:                      
0:                      return (Analyzer) method.invoke( null );
1:                  }
1:              }
1:              );
1: 	}
1: 	
commit:cb62199
/////////////////////////////////////////////////////////////////////////
commit:5b79ae0
/////////////////////////////////////////////////////////////////////////
1:         PreparedStatement   ps = conn.prepareStatement
1:              "and substr( cast( a.javaclassname as varchar( 32672 ) ), 1, ? ) = ?\n"
1:              );
1:         ps.setInt( 1, packageName.length() );
1:         ps.setString( 2, packageName );
1:         ResultSet   routines = ps.executeQuery();
/////////////////////////////////////////////////////////////////////////
0:             query.append( derbyIdentifier( textcol ) );
commit:d847ced
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Class org.apache.derby.impl.optional.lucene.LuceneSupport
1: 
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to You under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
1: 
1: */
1: 
0: package org.apache.derby.impl.optional.lucene;
1: 
0: import java.io.File;
0: import java.io.FileFilter;
1: import java.io.IOException;
0: import java.nio.charset.Charset;
1: import java.security.AccessController;
1: import java.security.PrivilegedActionException;
1: import java.security.PrivilegedExceptionAction;
1: import java.sql.Connection;
1: import java.sql.DatabaseMetaData;
1: import java.sql.Date;
1: import java.sql.DriverManager;
1: import java.sql.PreparedStatement;
1: import java.sql.ResultSet;
1: import java.sql.ResultSetMetaData;
1: import java.sql.SQLException;
1: import java.sql.Time;
1: import java.sql.Timestamp;
1: import java.sql.Types;
1: import java.util.Arrays;
1: import java.util.ArrayList;
1: 
1: import org.apache.derby.iapi.sql.dictionary.OptionalTool;
1: import org.apache.derby.iapi.error.StandardException;
1: import org.apache.derby.iapi.util.IdUtil;
1: import org.apache.derby.impl.jdbc.EmbedConnection;
1: import org.apache.derby.shared.common.reference.SQLState;
0: import org.apache.derby.vti.Restriction.ColumnQualifier;
1: import org.apache.derby.vti.VTITemplate;
1: 
1: import org.apache.lucene.analysis.Analyzer;
0: import org.apache.lucene.analysis.standard.StandardAnalyzer;
0: import org.apache.lucene.document.BinaryDocValuesField;
1: import org.apache.lucene.document.Document;
0: import org.apache.lucene.document.Field;
1: import org.apache.lucene.document.Field.Store;
1: import org.apache.lucene.document.StoredField;
1: import org.apache.lucene.document.StringField;
1: import org.apache.lucene.document.TextField;
0: import org.apache.lucene.index.DirectoryReader;
1: import org.apache.lucene.index.IndexableField;
0: import org.apache.lucene.index.IndexReader;
1: import org.apache.lucene.index.IndexWriter;
1: import org.apache.lucene.index.IndexWriterConfig;
0: import org.apache.lucene.index.Term;
1: import org.apache.lucene.queryparser.classic.ParseException;
0: import org.apache.lucene.store.Directory;
0: import org.apache.lucene.store.FSDirectory;
1: import org.apache.lucene.util.BytesRef;
1: import org.apache.lucene.util.Version;
1: 
1: /**
1:  * Support for creating, updating, and querying Lucene
1:  * indexes in Derby, and associated utility functions.
1:  * 
1:  */
1: public class LuceneSupport implements OptionalTool
1: {
1:     private static  final   String  LUCENE_SCHEMA = "LuceneSupport";
1:     private static  final   String  LIST_INDEXES = LUCENE_SCHEMA + "." + "listIndexes";
1:     private static  final   String  CREATE_INDEX = LUCENE_SCHEMA + "." + "createIndex";
1:     private static  final   String  DROP_INDEX = LUCENE_SCHEMA + "." + "dropIndex";
1:     private static  final   String  UPDATE_INDEX = LUCENE_SCHEMA + "." + "updateIndex";
1:     private static  final   String  SEPARATOR = "__";
1: 
0:     private static  final   String  LUCENE_DIR = "lucene";
1: 
1:     // for decomposing a function name into the table and column parts
1:     static  final   int TABLE_PART = 0;
1:     static  final   int COLUMN_PART = TABLE_PART + 1;
1:     static  final   int PART_COUNT = COLUMN_PART + 1;
1: 	
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  OptionalTool BEHAVIOR
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * 0-arg constructor as an OptionalTool
1: 	 */
1: 	public LuceneSupport() {
1: 	}
1: 	
1: 	/**
1: 	 * Load the procedures and functions for Lucene support:
1: 	 * In the LuceneSupport schema, these are:
1: 	 * listIndexes, createIndex, dropIndex,
1: 	 * updateIndex.
1: 	 */
1: 	public void loadTool(String... configurationParameters) throws SQLException
1:     {
1:         Connection  conn = getDefaultConnection();
0:         mustBeDBO( conn );
1: 
1:         if ( luceneSchemaExists( conn ) )
1:         {
0:             throw newSQLException( SQLState.LUCENE_ALREADY_LOADED );
1:         }
1: 
0:         boolean sqlAuthorizationEnabled = sqlAuthorizationEnabled( conn );
1:         
1: 		StringBuilder listFunction = new StringBuilder();
1: 		listFunction.append("create function " + LIST_INDEXES );
1: 		listFunction.append(" () ");
1: 		listFunction.append("returns table");
1: 		listFunction.append("(");
0: 		listFunction.append("id int,");
1: 		listFunction.append("schemaname varchar( 128 ),");
1: 		listFunction.append("tablename varchar( 128 ),");
1: 		listFunction.append("columnname varchar( 128 ),");
0: 		listFunction.append("lastupdated timestamp");
1: 		listFunction.append(")");
1: 		listFunction.append("language java ");
1: 		listFunction.append("parameter style DERBY_JDBC_RESULT_SET ");
1: 		listFunction.append("contains sql ");
1: 		listFunction.append("external name '" + getClass().getName() + ".listIndexes'");
1: 		
1: 		executeDDL( conn, listFunction.toString() );
1: 		
1: 		StringBuilder createProcedure = new StringBuilder();
1: 		createProcedure.append("create procedure " + CREATE_INDEX );
1: 		createProcedure.append(" (schemaname varchar( 128 ),");
1: 		createProcedure.append("tablename varchar( 128 ),");
0: 		createProcedure.append("textcolumn varchar( 128 ))");
0: 		createProcedure.append("parameter style java modifies sql data language java external name ");
1: 		createProcedure.append("'" + getClass().getName() + ".createIndex'");
1: 		
1: 		executeDDL( conn, createProcedure.toString() );
1: 
1: 		StringBuilder dropProcedure = new StringBuilder();
1: 		dropProcedure.append("create procedure " + DROP_INDEX );
1: 		dropProcedure.append(" (schemaname varchar( 128 ),");
1: 		dropProcedure.append("tablename varchar( 128 ),");
1: 		dropProcedure.append("textcolumn varchar( 128 ))");
1: 		dropProcedure.append("parameter style java modifies sql data language java external name ");
1: 		dropProcedure.append("'" + getClass().getName() + ".dropIndex'");
1: 		
1: 		executeDDL( conn, dropProcedure.toString() );
1: 
1: 		StringBuilder updateProcedure = new StringBuilder();
1: 		updateProcedure.append("create procedure " + UPDATE_INDEX );
1: 		updateProcedure.append(" (schemaname varchar( 128 ),");
1: 		updateProcedure.append("tablename varchar( 128 ),");
0: 		updateProcedure.append("textcolumn varchar( 128 ))");
1: 		updateProcedure.append("parameter style java reads sql data language java external name ");
1: 		updateProcedure.append("'" + getClass().getName() + ".updateIndex'");
1: 		
1: 		executeDDL( conn, updateProcedure.toString() );
1: 
1:         if ( sqlAuthorizationEnabled ) { grantPermissions(); }
1: 	}
1: 
1:     /**
1:      * Grant permissions to use the newly loaded LuceneSupport routines.
1:      */
1:     private void    grantPermissions()  throws SQLException
1:     {
1:         Connection  conn = getDefaultConnection();
1: 
1:         executeDDL( conn, "grant execute on function " + LIST_INDEXES + " to public" );
1:         executeDDL( conn, "grant execute on procedure " + CREATE_INDEX + " to public" );
1:         executeDDL( conn, "grant execute on procedure " + DROP_INDEX + " to public" );
1:         executeDDL( conn, "grant execute on procedure " + UPDATE_INDEX + " to public" );
1:     }
1: 
1: 	/**
1: 	 * Removes the functions and procedures loaded by loadTool and created by createIndex.
1:      * Drop the LuceneSupport schema. Drop the lucene subdirectory.
1: 	 */
1: 	public void unloadTool(String... configurationParameters)
1:         throws SQLException
1:     {
1:         Connection  conn = getDefaultConnection();
0:         mustBeDBO( conn );
1: 
1:         if ( !luceneSchemaExists( conn ) )
1:         {
0:             throw newSQLException( SQLState.LUCENE_ALREADY_UNLOADED );
1:         }
1: 
1:         //
1:         // Drop all of the functions and procedures bound to methods in this package.
1:         //
1:         String      className = getClass().getName();
1:         int             endPackageIdx = className.lastIndexOf( "." );
1:         String      packageName = className.substring( 0, endPackageIdx );
0:         ResultSet   routines = conn.prepareStatement
1:             (
1:              "select s.schemaName, a.alias, a.aliastype\n" +
1:              "from sys.sysschemas s, sys.sysaliases a\n" +
1:              "where s.schemaID = a.schemaID\n" +
0:              "and substr( cast( a.javaclassname as varchar( 32672 ) ), 1, " + packageName.length() + " ) = '" + packageName + "'\n"
0:              ).executeQuery();
1: 
1:         try {
1:             while ( routines.next() )
1:             {
1:                 String  schema = routines.getString( 1 );
1:                 String  routineName = routines.getString( 2 );
1:                 String  routineType = ("P".equals( routines.getString( 3 ) )) ? "procedure" : "function";
1: 
1:                 conn.prepareStatement( "drop " + routineType + " " + makeTableName( schema, routineName ) ).execute();
1:             }
1:         }
1:         finally { routines.close(); }
1: 
1:         //
1:         // Drop the LuceneSupport schema.
1:         //
1:         conn.prepareStatement( "drop schema " + LUCENE_SCHEMA + " restrict" ).execute();
1: 
1:         //
1:         // Now delete the Lucene subdirectory;
1:         //
1:         try {
0:             deleteFile( new File( getLuceneDirectory( conn ) ) );
1:         }
0:         catch (IOException ioe) { throw wrap( ioe ); }
0:         catch (PrivilegedActionException pae) { throw wrap( pae ); }
1: 	}
1: 	
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  LUCENE QUERY
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Query a Lucene index created by createIndex
1: 	 * 
1: 	 * @param queryText a Lucene query, see the Lucene classic queryparser syntax 
0: 	 * @param rankCutoff Return results only below this rank
1: 	 * @return A result set in the form of LuceneQueryVTI table
1: 	 * @throws ParseException
1: 	 * @throws IOException
0: 	 * @see org.apache.derby.impl.optional.lucene.LuceneQueryVTI
1: 	 */
1: 	public static LuceneQueryVTI luceneQuery
1:         (
1:          String queryText,
0:          double rankCutoff
1:          )
1:         throws ParseException, IOException, SQLException
1:     {
0: 		LuceneQueryVTI lqvti = new LuceneQueryVTI( queryText, rankCutoff );
1: 		return lqvti;
1: 	}
1: 	
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  LIST INDEXES
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Return a list of Lucene indexes for this database. Filter by schema and table, if given.
1: 	 */
1: 	public static LuceneListIndexesVTI listIndexes()
1:         throws IOException, PrivilegedActionException, SQLException
1:     {
1: 		LuceneListIndexesVTI llivti = new LuceneListIndexesVTI();
1: 		return llivti;
1: 	}
1: 	
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  UPDATE INDEX
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Update a document in a Lucene index. Drops and recreates the Lucene index
1:      * but does not touch the query function specific to the index.
1: 	 * 
1: 	 * @param schema Schema where the indexed column resides
1: 	 * @param table table where the indexed column resides
1: 	 * @param textcol the indexed column
1: 	 * @throws SQLException
1: 	 * @throws IOException
1: 	 */
0: 	public static void updateIndex( String schema, String table, String textcol )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
1:         Connection              conn = getDefaultConnection();
1: 
1:         // only the dbo or the schema owner can perform this function
0:         mustBeOwner( conn, schema );
1: 
1:         if ( !tableFunctionExists( conn, schema, table, textcol ) )
1:         {
0:             throw newSQLException( SQLState.LUCENE_INDEX_DOES_NOT_EXIST );
1:         }
1: 
0:         createOrRecreateIndex( conn, schema, table, textcol, false );
1: 	}
1: 	
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  CREATE INDEX
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Create a Lucene index on the specified column.
1: 	 *  
1: 	 * @param schema The schema of the column to index
1: 	 * @param table The table of the column to index
1: 	 * @param textcol The column to create the Lucene index on
1: 	 * @throws SQLException
1: 	 * @throws IOException
1: 	 */
0: 	public static void createIndex( String schema, String table, String textcol )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
1:         Connection              conn = getDefaultConnection();
1:         DatabaseMetaData    dbmd = conn.getMetaData();
1: 
1:         // First make sure that the text column exists and is a String type
1:         vetTextColumn( dbmd, schema, table, textcol );
1: 
0:         createOrRecreateIndex( conn, schema, table, textcol, true );
1: 	}
1: 
1: 	/**
1: 	 * Create or re-create a Lucene index on the specified column.
1: 	 *  
1: 	 * @param schema The schema of the column to index
1: 	 * @param table The table of the column to index
1: 	 * @param textcol The column to create the Lucene index on
1: 	 * @param create True if the index is to be created, false if it is to be recreated
1: 	 * @throws SQLException
1: 	 * @throws IOException
1: 	 */
1: 	private static void createOrRecreateIndex
1:         (
1:          Connection conn,
1:          String schema,
1:          String table,
1:          String textcol,
0:          boolean create
1:          )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
0:         VTITemplate.ColumnDescriptor[] primaryKeys = getPrimaryKeys( conn, schema, table );
1:         if ( primaryKeys.length == 0 )
1:         {
0:             throw newSQLException( SQLState.LUCENE_NO_PRIMARY_KEY );
1:         }
0:         int             keyCount = 0;
1: 
1:         //
1:         // Drop the old index directory if we're recreating the index.
1:         // We do this after verifying that the key exists.
1:         //
0:         if ( !create ) { dropIndexDirectories( schema, table, textcol ); }
1:             
1:         StringBuilder   tableFunction = new StringBuilder();
1:         tableFunction.append( "create function " + makeTableFunctionName( schema, table, textcol ) + "\n" );
0:         tableFunction.append( "( query varchar( 32672 ), rankCutoff double )\n" );
1:         tableFunction.append( "returns table\n(" );
1: 
1:         PreparedStatement   ps = null;
1:         ResultSet rs = null;
1:         IndexWriter iw = null;
1:         try {
0:             iw = getIndexWriter( schema, table, textcol );
1: 
1:             // select all keys and the textcol from this column, add to lucene index
1:             StringBuilder query = new StringBuilder("select ");
1:         
1:             for ( VTITemplate.ColumnDescriptor keyDesc : primaryKeys )
1:             {
0:                 String  keyName = keyDesc.columnName;
1:                 if ( keyCount > 0 ) { query.append( ", " ); }
1:                 query.append( keyName );
1: 
1:                 String  keyType = mapType( keyDesc );
1: 
1:                 if ( keyCount > 0 ) { tableFunction.append( "," ); }
1:                 tableFunction.append( "\n\t" + keyName + " " + keyType );
1:                 keyCount++;
1:             }
0:             tableFunction.append(",\n\tdocumentID int");
0:             tableFunction.append(",\n\trank real");
1:             tableFunction.append( "\n)\nlanguage java parameter style derby_jdbc_result_set contains sql\n" );
0:             tableFunction.append( "external name 'org.apache.derby.impl.optional.lucene.LuceneSupport.luceneQuery'" );
1: 
1:             // now create the table function for this text column
1:             if ( create )
1:             {
1:                 conn.prepareStatement( tableFunction.toString() ).execute();
1:             }
1:         
1:             query.append(", ");
0:             query.append( textcol );
1:             query.append(" from " + makeTableName( schema, table ) );
1: 
1:             ps = conn.prepareStatement( query.toString() );
1:             rs = ps.executeQuery();
1: 
1:             while ( rs.next() )
1:             {
1:                 Document doc = new Document();
1: 
1:                 for ( int i = 0; i < keyCount; i++ )
1:                 {
1:                     VTITemplate.ColumnDescriptor   keyDescriptor = primaryKeys[ i ];
1:                     addValue( doc, keyDescriptor, rs, i + 1 );
1:                 }
1: 
1:                 String  textcolValue = rs.getString( keyCount + 1 );
1:                 if ( textcolValue != null )
1:                 {
0:                     doc.add(new TextField( LuceneQueryVTI.TEXT_FIELD_NAME, textcolValue, Store.NO));
1:                 }
1:                 addDocument( iw, doc );
1:             }
1:         }
1:         finally
1:         {
1:             try {
1:                  if ( iw != null ) { close( iw ); }
1:             }
1:             finally {
1:                 try {
1:                     if ( rs != null ) { rs.close(); }
1:                 }
1:                 finally {
1:                     if ( ps != null ) { ps.close(); }
1:                 }
1:             }
1:         }
1: 	}
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  DROP INDEX
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Drop a Lucene index. This removes the Lucene index directory from the filesystem.
1: 	 * 
1: 	 * @param schema The schema of the column that is indexed
1: 	 * @param table The table of the column that is indexed
1: 	 * @param textcol The column that is indexed
1: 	 * 
1: 	 * @throws SQLException
1: 	 * @throws IOException
1: 	 */
1: 	public static void dropIndex( String schema, String table, String textcol )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
1:         getDefaultConnection().prepareStatement
1:             (
1:              "drop function " + makeTableFunctionName( schema, table, textcol )
1:              ).execute();
1: 
1:         dropIndexDirectories( schema, table, textcol );
1: 	}
1: 
1:     /**
1:      * <p>
1:      * Drop the Lucene directories which support an index.
1:      * </p>
1:      */
1: 	private static void dropIndexDirectories( String schema, String table, String textcol )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
0: 		File indexDir = new File(getIndexLocation( getDefaultConnection(), schema, table, textcol ) );
0: 		File tableDir = indexDir.getParentFile();
0:         File schemaDir = tableDir.getParentFile();
1: 		
0: 		if ( !isDirectory( indexDir ) )
1:         {
0: 			throw newSQLException
0:                 ( SQLState.LUCENE_BAD_INDEX, indexDir.getAbsolutePath() );
1: 		}
1: 
1:         deleteFile( indexDir );
1:         if ( isEmpty( tableDir ) )
1:         {
1:             deleteFile( tableDir );
1:             if ( isEmpty( schemaDir ) ) { deleteFile( schemaDir ); }
1:         }
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
0:     //  ERROR HANDLING
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
0:     /** Make a SQLException from a SQLState and optional args */
0:     public  static  SQLException    newSQLException( String sqlState, Object... args )
1:     {
0:         StandardException   se = StandardException.newException( sqlState, args );
0:         return sqlException( se );
1:     }
1:     
0:     /** Turn a StandardException into a SQLException */
0:     public  static  SQLException    sqlException( StandardException se )
1:     {
0:         return new SQLException( se.getMessage(), se.getSQLState() );
1:     }
1: 
0:     /** Wrap an external exception */
0:     public  static  SQLException    wrap( Throwable t )
1:     {
0:         return sqlException( StandardException.plainWrapException( t ) );
1:     }
1:     
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  TYPE HANDLING
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1:     /** Get the SQL type name for a key column */
1:     private static  String  mapType( VTITemplate.ColumnDescriptor keyDesc )
1:         throws SQLException
1:     {
1:         return mapType
1:             (
1:              keyDesc.jdbcType,
1:              keyDesc.precision,
1:              keyDesc.scale,
1:              keyDesc.typeName
1:              );
1:     }
1: 
1:     /**
1:      * <p>
1:      * Get the type of an external database's column as a Derby type name.
1:      * </p>
1:      *
1:      */
1:     private static String    mapType( int jdbcType, int precision, int scale, String typeName )
1:         throws SQLException
1:     {
1:         switch( jdbcType )
1:         {
1:         case    Types.BIGINT:           return "bigint";
1:         case    Types.BINARY:           return "char " + precisionToLength( precision ) + "  for bit data";
1:         case    Types.BIT:              return "boolean";
1:         case    Types.BLOB:             return "blob";
1:         case    Types.BOOLEAN:          return "boolean";
1:         case    Types.CHAR:             return "char" + precisionToLength( precision );
1:         case    Types.CLOB:             return "clob";
1:         case    Types.DATE:             return "date";
1:         case    Types.DECIMAL:          return "decimal" + precisionAndScale( precision, scale );
1:         case    Types.DOUBLE:           return "double";
1:         case    Types.FLOAT:            return "float";
1:         case    Types.INTEGER:          return "integer";
1:         case    Types.LONGVARBINARY:    return "long varchar for bit data";
1:         case    Types.LONGVARCHAR:      return "long varchar";
1:         case    Types.NUMERIC:          return "numeric" + precisionAndScale( precision, scale );
1:         case    Types.REAL:             return "real";
1:         case    Types.SMALLINT:         return "smallint";
1:         case    Types.TIME:             return "time";
1:         case    Types.TIMESTAMP:        return "timestamp";
1:         case    Types.TINYINT:          return "smallint";
1:         case    Types.VARBINARY:        return "varchar " + precisionToLength( precision ) + "  for bit data";
1:         case    Types.VARCHAR:          return "varchar" + precisionToLength( precision );
1:  
0:         default:                throw newSQLException( SQLState.LUCENE_UNSUPPORTED_TYPE, typeName );
1:         }
1:     }
1: 
1:     /**
1:      * <p>
1:      * Turns precision into a length designator.
1:      * </p>
1:      *
1:      */
1:     private  static String  precisionToLength( int precision )
1:     {
1:         return "( " + precision + " )";
1:     }
1: 
1:     /**
1:      * <p>
1:      * Build a precision and scale designator.
1:      * </p>
1:      *
1:      */
1:     private static  String  precisionAndScale( int precision, int scale )
1:     {
1:         return "( " + precision + ", " + scale + " )";
1:     }
1: 
1:     /**
1:      * Add the field to the document so that it can be read by LuceneQueryVTI.
1:      * May raise an exception if the type is not supported.
1:      */
1:     private static  void    addValue
1:         (
1:          Document   doc,
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         IndexableField     field = null;
1:         
1:         switch( keyDescriptor.jdbcType )
1:         {
1:         case    Types.SMALLINT:
1:         case    Types.TINYINT:
1:         case    Types.INTEGER:
1:             field = getIntField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.REAL:
1:             field = getFloatField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.FLOAT:
1:         case    Types.DOUBLE:
1:             field = getDoubleField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.BIGINT:
1:             field = getLongField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.DATE:
1:             field = getDateField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.TIME:
1:             field = getTimeField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.TIMESTAMP:
1:             field = getTimestampField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.CHAR:
1:         case    Types.CLOB:
1:         case    Types.DECIMAL:
1:         case    Types.LONGVARCHAR:
1:         case    Types.NUMERIC:
1:         case    Types.VARCHAR:
1:             field = getStringField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.BLOB:
1:         case    Types.BINARY:
1:         case    Types.LONGVARBINARY:
1:         case    Types.VARBINARY:
1:             field = getBinaryField( keyDescriptor, rs, columnIdx );
1:             break;
1: 
1:         case    Types.BIT:
1:         case    Types.BOOLEAN:
1:             boolean booleanValue = rs.getBoolean( columnIdx );
1:             if ( !rs.wasNull() )
1:             {
1:                 field = new StringField( keyDescriptor.columnName, booleanValue ? "true" : "false", Store.YES );
1:             }
1:             break;
1:             
1:         default:
0:             throw newSQLException( SQLState.LUCENE_UNSUPPORTED_TYPE, keyDescriptor.typeName );
1:         }
1: 
1:         if ( field != null ) { doc.add( field ); }
1:     }
1: 	
1:     /**
1:      * Get a string value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField getStringField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         String  stringValue = rs.getString( columnIdx );
1:         if ( stringValue != null )
1:         {
1:             return new StringField( keyDescriptor.columnName, stringValue, Store.YES );
1:         }
1:         else { return null; }
1:     }
1:     
1:     /**
1:      * Get a float value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getFloatField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         float   value = rs.getFloat( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value );
1:         }
1:     }
1:     
1:     /**
1:      * Get a double value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getDoubleField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         double   value = rs.getDouble( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value );
1:         }
1:     }
1:     
1:     /**
1:      * Get an long value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getLongField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         long    value = rs.getLong( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value );
1:         }
1:     }
1:     
1:     /**
1:      * Get a Date value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getDateField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         Date    value = rs.getDate( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:         }
1:     }
1:     
1:     /**
1:      * Get a Time value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getTimeField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         Time    value = rs.getTime( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:         }
1:     }
1:     
1:     /**
1:      * Get a Timestamp value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getTimestampField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         Timestamp    value = rs.getTimestamp( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value.getTime() );
1:         }
1:     }
1:     
1:     /**
1:      * Get an integer value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getIntField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         int     value = rs.getInt( columnIdx );
1:         if ( rs.wasNull() ) { return null; }
1:         else
1:         {
1:             return new StoredField( keyDescriptor.columnName, value );
1:         }
1:     }
1:     
1:     /**
1:      * Get a binary value to add to the document read by LuceneQueryVTI.
1:      */
1:     private static  IndexableField    getBinaryField
1:         (
1:          VTITemplate.ColumnDescriptor  keyDescriptor,
1:          ResultSet  rs,
1:          int    columnIdx   // 1-based
1:          )
1:         throws SQLException
1:     {
1:         byte[]  value = rs.getBytes( columnIdx );
1:         if ( value != null )
1:         {
1:             BytesRef    ref = new BytesRef( value );
1:             return new StoredField( keyDescriptor.columnName, ref );
1:         }
1:         else { return null; }
1:     }
1:     
1:     /**
1:      * Raise an exception if the text column doesn't exist or isn't a String datatype.
1:      */
1: 	private static void vetTextColumn( DatabaseMetaData dbmd, String schema, String table, String textcol )
1:         throws SQLException
1:     {
0:         schema = derbyIdentifier( schema );
0:         table = derbyIdentifier( table );
0:         textcol = derbyIdentifier( textcol );
1:         
1:         ResultSet   rs = dbmd.getColumns( null, schema, table, textcol );
1: 
1:         try {
1:             if ( rs.next() )
1:             {
1:                 switch( rs.getInt( "DATA_TYPE" ) )
1:                 {
1:                 case    Types.CHAR:
1:                 case    Types.CLOB:
1:                 case    Types.LONGVARCHAR:
1:                 case    Types.VARCHAR:
1:                     return;
1:                 }
1:             }
1: 
0:             throw sqlException( StandardException.newException( SQLState.LUCENE_NOT_A_STRING_TYPE ) );
1:         }
1:         finally
1:         {
1:             rs.close();
1:         }
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  NAMESPACE
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * Return the qualified name of the table.
1:      */
1: 	static String   makeTableName( String schema, String table )
1:         throws SQLException
1:     {
0:         schema = derbyIdentifier( schema );
0:         table = derbyIdentifier( table );
1: 
1:         return IdUtil.mkQualifiedName( schema, table );
1:     }
1: 
1:     /** Return the qualified name of the table function */
1: 	private static String   makeTableFunctionName( String schema, String table, String textcol )
1:         throws SQLException
1:     {
1: 		// Provide some basic protection against someone trying to put path modifiers (../../etc.)
1: 		// into the arguments.
1:         forbidCharacter( schema, table, textcol, "." );
1:         forbidCharacter( schema, table, textcol, "/" );
1:         forbidCharacter( schema, table, textcol, "\\" );
1: 		
0:         schema = derbyIdentifier( schema );
1:         String  function = makeUnqualifiedTableFunctionName( table, textcol );
1: 
1:         return IdUtil.mkQualifiedName( schema, function );
1:     }
1: 
1:     /** Make the unqualified name of a querying table function */
1:     private static  String  makeUnqualifiedTableFunctionName( String table, String textcol )
1:         throws SQLException
1:     {
0:         return derbyIdentifier( table ) + SEPARATOR + derbyIdentifier( textcol );
1:     }
1: 
1:     /** Return true if the table function exists */
1:     private static  boolean tableFunctionExists( Connection conn, String schema, String table, String textcol )
1:         throws SQLException
1:     {
0:         schema = derbyIdentifier( schema );
1:         String  function = makeUnqualifiedTableFunctionName( table, textcol );
1: 
1:         ResultSet   rs = conn.getMetaData().getFunctions( null, schema, function );
1: 
1:         try {
1:             return rs.next();
1:         }
1:         finally { rs.close(); }
1:     }
1: 
1:     /** Decompose a function name of the form $table__$column into $table and $column */
1:     static  String[]    decodeFunctionName( String functionName )
1:     {
1:         int     separatorIdx = functionName.indexOf( SEPARATOR );
1:         String[]    retval = new String[ PART_COUNT ];
1: 
1:         retval[ TABLE_PART ] = functionName.substring( 0, separatorIdx );
1:         retval[ COLUMN_PART ] = functionName.substring( separatorIdx + SEPARATOR.length() );
1: 
1:         return retval;
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  SQL/JDBC SUPPORT
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Get a connection to the database
1: 	 * 
1: 	 * @return a connection
1: 	 * 
1: 	 * @throws SQLException
1: 	 */
1: 	static Connection getDefaultConnection() throws SQLException
1:     {
1: 		return DriverManager.getConnection( "jdbc:default:connection" );
1: 	}
1: 
1:     /**
1:      * <p>
0:      * Raise an exception if SQL authorization is enabled and the current user
0:      * isn't the DBO or the owner of the indicated schema or if the indicated schema
0:      * doesn't exist.
1:      * </p>
1:      */
0:     private static  void    mustBeOwner( Connection conn, String schema )
1:         throws SQLException
1:     {
0:         if ( !sqlAuthorizationEnabled( conn ) ) { return; }
1: 
0:         String  dbo = getOwner( conn, "SYS" );
0:         String  schemaOwner = getOwner( conn, schema );
0:         String  currentUser = getCurrentUser( conn );
1: 
0:         if (
0:             (schemaOwner != null) &&
1:             (
0:              schemaOwner.equals( currentUser ) ||
0:              dbo.equals( currentUser )
1:              )
0:             )   { return; }
1:         else
1:         {
0:             throw newSQLException( SQLState.LUCENE_MUST_OWN_SCHEMA );
1:         }
1:     }
1: 
1:     /**
1:      * <p>
0:      * Raise an exception if SQL authorization is enabled and the current user
0:      * isn't the DBO.
1:      * </p>
1:      */
0:     private static  void    mustBeDBO( Connection conn )
1:         throws SQLException
1:     {
0:         if ( !sqlAuthorizationEnabled( conn ) ) { return; }
1: 
0:         String  dbo = getOwner( conn, "SYS" );
0:         String  currentUser = getCurrentUser( conn );
1: 
0:         if ( dbo.equals( currentUser ) )   { return; }
1:         else
1:         {
0:             throw newSQLException( SQLState.DBO_ONLY );
1:         }
1:     }
1: 
0:     /** Get the current user */
0:     private static  String  getCurrentUser( Connection conn )
1:         throws SQLException
1:     {
0:         ResultSet   rs = conn.prepareStatement( "values current_user" ).executeQuery();
1:         try {
1:             rs.next();
0:             return rs.getString( 1 );
0:         } finally { rs.close(); }
1:     }
1: 
1:     /**
1:      * <p>
0:      * Get the owner of the indicated schema. Returns null if the schema doesn't exist.
1:      * </p>
1:      */
0:     private static  String  getOwner( Connection conn, String schema )
1:         throws SQLException
1:     {
0:         PreparedStatement   ps = conn.prepareStatement
0:             ( "select authorizationID from sys.sysschemas where schemaName = ?" );
0:         ps.setString( 1, derbyIdentifier( schema ) );
1: 
1:         ResultSet   rs = ps.executeQuery();
1:         try {
0:             if ( rs.next() ) { return rs.getString( 1 ); }
1:             else { return null; }
0:         } finally { rs.close(); }
1:     }
1: 
1:     /** Return true if the LuceneSupport schema exists already */
1:     private static  boolean luceneSchemaExists( Connection conn )
1:         throws SQLException
1:     {
1:         PreparedStatement ps = conn.prepareStatement
1:             ( "select count(*) from sys.sysschemas where schemaName = ?" );
1:         ps.setString( 1, LUCENE_SCHEMA.toUpperCase() );
1:         ResultSet   rs = ps.executeQuery();
1: 
1:         try {
1:             rs.next();
1:             return ( rs.getInt( 1 ) > 0 );
1:         } finally
1:         {
1:             rs.close();
1:             ps.close();
1:         }
1:     }
1: 
1:     /**
0:      * Returns true if SQL authorization is enabled in the connected database.
1:      */
0:     public  static  boolean sqlAuthorizationEnabled( Connection conn )
1:         throws SQLException
1:     {
1:         try {
0:             ResultSet   rs;
1:         
0:             // first check to see if NATIVE authentication is on
0:             rs = conn.prepareStatement( "select count(*) from sys.sysusers" ).executeQuery();
1:             rs.next();
1:             try {
0:                 if ( rs.getInt( 1 ) > 0 ) { return true; }
1:             }
1:             finally { rs.close(); }
1:         }
0:         catch (SQLException se)
1:         {
0:             if ( SQLState.DBO_ONLY.equals( se.getSQLState() ) ) { return true; }
1:         }
1:         
0:         ResultSet   rs = conn.prepareStatement
1:             (
0:              "values syscs_util.syscs_get_database_property( 'derby.database.sqlAuthorization' )"
0:              ).executeQuery();
1: 
1:         try {
0:             if ( !( rs.next() ) ) { return false; }
1: 
0:             return ( "true".equals( rs.getString( 1 ) ) );
1:         }
1:         finally { rs.close(); }
1:     }
1:     
1: 	/**
1: 	 * Execute a DDL statement
1: 	 * 
1: 	 * @param c a Connection
1: 	 * @param text the text of the statement to execute
1: 	 * @throws SQLException
1: 	 */
1: 	private void executeDDL(Connection c, String text) throws SQLException {
1:     	PreparedStatement ddl = c.prepareStatement(text);
1:     	ddl.execute();
1:     	ddl.close();
1:     }
1: 	
0: 	private static String getDerbySystemHome() throws IOException {
1:         try {
0:             return AccessController
0:                     .doPrivileged(new PrivilegedExceptionAction<String>() {
0:                         public String run() throws IOException {
0:                         	String dir = System.getProperty("derby.system.home");
0:                         	if (dir == null) {
0:                                 return System.getProperty("user.dir");	
0:                         	} else {
0:                         		return dir;
1:                         	}
1:                         }
1:                     });
1:         } catch (PrivilegedActionException pae) {
1:             throw (IOException) pae.getCause();
0:         } catch (SecurityException se) {
0:             throw (IOException) se.getCause();
1:         }
1: 	}
1: 	
0:     /** Convert a raw string into a properly cased and escaped Derby identifier */
0:     private static  String  derbyIdentifier( String rawString )
1:         throws SQLException
1:     {
1:         try {
0:             return IdUtil.parseSQLIdentifier( rawString );
1:         }
0:         catch (StandardException se)  { throw sqlException( se ); }
1:     }
1: 
1:     /**
1:      * Return the primary key columns for a table, sorted by key position.
1:      */
1:     private static  VTITemplate.ColumnDescriptor[] getPrimaryKeys
1:         (
1:          Connection conn,
1:          String schema,
1:          String table
1:          )
1:         throws SQLException
1:     {
0:         ResultSet   keysRS = conn.getMetaData().getPrimaryKeys( null, derbyIdentifier( schema ), derbyIdentifier( table ) );
1:         ArrayList<VTITemplate.ColumnDescriptor>    keyArray = new ArrayList<VTITemplate.ColumnDescriptor>();
1:         try {
1:             while ( keysRS.next() )
1:             {
1:                 String  columnName = keysRS.getString( "COLUMN_NAME" );
1:                 int     keyPosition = keysRS.getInt( "KEY_SEQ" );
1: 
1:                 ResultSet   colInfoRS = conn.prepareStatement
1:                     ( "select " + columnName + " from " + makeTableName( schema, table ) + " where 1=2" ).executeQuery();
1:                 ResultSetMetaData   rsmd = colInfoRS.getMetaData();
1:                 VTITemplate.ColumnDescriptor   keyDescriptor = new VTITemplate.ColumnDescriptor
1:                     (
1:                      columnName,
1:                      rsmd.getColumnType( 1 ),
1:                      rsmd.getPrecision( 1 ),
1:                      rsmd.getScale( 1 ),
1:                      rsmd.getColumnTypeName( 1 ),
1:                      keyPosition
1:                      );
1:                 keyArray.add( keyDescriptor );
1:                 colInfoRS.close();
1:             }
1:         }
1:         finally
1:         {
1:             keysRS.close();
1:         }
1: 
1:         VTITemplate.ColumnDescriptor[] result = new VTITemplate.ColumnDescriptor[ keyArray.size() ];
1:         keyArray.toArray( result );
1:         Arrays.sort( result );
1: 
1:         return result;
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  FILE MANAGEMENT
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1:     /** Return true if the directory is empty */
0:     private static  boolean isEmpty( File dir )
0:         throws IOException, PrivilegedActionException
1:     {
0:         File[]  contents = listFiles( dir, null );
1: 
1:         if ( contents == null ) { return true; }
1:         else if ( contents.length == 0 ) { return true; }
1:         else { return false; }
1:     }
1: 
1:     /**
0:      * Delete a file. If it's a directory, recursively delete all directories
0:      * and files underneath it first.
1:      */
0:     static  boolean deleteFile( File file )
0:         throws IOException, PrivilegedActionException
1:     {
0:         boolean retval = true;
1:         
0:         if ( isDirectory( file ) )
1:         {
0:             for ( File child : listFiles( file, null ) ) { retval = retval && deleteFile( child ); }
1:         }
1: 
0:         return retval && clobberFile( file );
1:     }
1: 
0:     /** Return true if the file is a directory */
0:     static  boolean isDirectory( final File file )
0:         throws IOException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Boolean>()
1:              {
0:                 public Boolean run() throws IOException
1:                 {
0:                     if ( file == null ) { return false; }
0:                     else { return file.isDirectory(); }
1:                 }
1:              }
0:              ).booleanValue();
1:     }
1: 
1:     /** Really delete a file */
0:     private static  boolean clobberFile( final File file )
0:         throws IOException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Boolean>()
1:              {
0:                 public Boolean run() throws IOException
1:                 {
0:                     return file.delete();
1:                 }
1:              }
0:              ).booleanValue();
1:     }
1: 
0:     /** Get the timestamp when the file was last modified */
0:     public static  long getLastModified( final File file )
0:         throws PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Long>()
1:              {
0:                 public Long run()
1:                 {
0:                     return file.lastModified();
1:                 }
1:              }
0:              ).longValue();
1:     }
1: 
0:     /** List files */
0:     static  File[]  listFiles( final File file, final FileFilter fileFilter )
0:         throws IOException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<File[]>()
1:              {
0:                 public File[] run() throws IOException
1:                 {
0:                     if ( fileFilter == null )   { return file.listFiles(); }
0:                     else { return file.listFiles( fileFilter ); }
1:                 }
1:              }
1:              );
1:     }
1: 
1: 	/**
0: 	 * Get the system property derby.system.home using the security manager.
0: 	 * @return Returns the value of the system property derby.system.home, or user.dir if not set.
1: 	 * @throws IOException
1: 	 */
1: 	/**
0: 	 * Provides the location of the directories used to name the individual Lucene index directories
0: 	 * for each column using the scheme 'schema_table_column'. The path should be inside the current
0: 	 * database directory.
1: 	 */
0: 	static String getIndexLocation( Connection conn, String schema, String table, String textcol )
0:         throws IOException, SQLException
1:     {
0: 		StringBuilder derbyHome = new StringBuilder();
1: 
0:         derbyHome.append( getLuceneDirectory( conn ) );
1: 		
0:         if ( schema != null )
1:         {
0:             schema = derbyIdentifier( schema );
1:                 
0:             derbyHome.append(File.separator);
0:             derbyHome.append(schema);
1: 
0:             if ( table != null )
1:             {
0:                 table = derbyIdentifier( table );
1:                     
0:                 derbyHome.append(File.separator);
0:                 derbyHome.append(table);
1: 
0:                 if ( textcol != null )
1:                 {
0:                     textcol = derbyIdentifier( textcol );
1:                         
0:                     derbyHome.append(File.separator);
0:                     derbyHome.append(textcol);
1:                 }
1:             }
1:         }
1: 		
0:         return derbyHome.toString();
1: 	}
1: 
0:     /** Get the location of the Lucene subdirectory */
0:     private static  String getLuceneDirectory( Connection conn )
0:         throws IOException, SQLException
1:     {
0:         EmbedConnection embedConnection = (EmbedConnection) conn;
0:         String dbname = embedConnection.getDBName();
1: 
0:         return getDerbySystemHome() + File.separator + dbname + File.separator + LUCENE_DIR;
1:     }
1:     
1:     /** Forbid invalid character */
1:     private static  void    forbidCharacter( String schema, String table, String textcol, String invalidCharacter )
1:         throws SQLException
1:     {
1: 		if (schema.indexOf( invalidCharacter ) > 0 || table.indexOf( invalidCharacter ) > 0 || textcol.indexOf( invalidCharacter ) > 0)
1:         {
0:             throw newSQLException( SQLState.LUCENE_INVALID_CHARACTER, invalidCharacter );
1: 		}		
1:     }
1: 
1:     /////////////////////////////////////////////////////////////////////
1:     //
1:     //  LUCENE SUPPORT
1:     //
1:     /////////////////////////////////////////////////////////////////////
1: 
1: 	/**
1: 	 * Returns a Lucene IndexWriter, that writes inside the lucene directory inside the database
1: 	 * directory.
1: 	 * 
1: 	 * @param schema The schema of the indexed column
1: 	 * @param table The table of the indexed column
1: 	 * @param textcol The name of the column to be indexed
1: 	 * @return a Lucene IndexWriter
1: 	 */
1: 	private static IndexWriter getIndexWriter
1:         (
0:          final String schema,
0:          final String table,
0:          final String textcol
1:          )
1:         throws SQLException, IOException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
1:              new PrivilegedExceptionAction<IndexWriter>()
1:              {
0:                  public IndexWriter run() throws SQLException, IOException
1:                  {
0:                      Directory dir = FSDirectory.open(new File( getIndexLocation( getDefaultConnection(), schema, table, textcol ) ) );
1: 
1:                      // allow this to be overridden in the configuration during load later.
0:                      Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_45);
0:                      IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_45,
0:                                                                    analyzer);
0:                      IndexWriter iw = new IndexWriter(dir, iwc);
1: 		
1:                      return iw;
1:                  }
1:              }
1:              );
1: 	}
1: 	
1: 	/**
1: 	 * Add a document to a Lucene index wrier.
1: 	 */
1:     private static void addDocument
1:         (
1:          final IndexWriter  indexWriter,
1:          final Document     document
1:          )
0:         throws IOException, PrivilegedActionException
1:     {
1:         AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Object>()
1:              {
0:                  public Object run() throws IOException
1:                  {
1:                      indexWriter.addDocument( document );
1: 		
1:                      return null;
1:                  }
1:              }
1:              );
1:     }
1: 
1: 	/**
1: 	 * Close an IndexWriter.
1: 	 */
1:     private static void close( final IndexWriter  indexWriter )
0:         throws IOException, PrivilegedActionException
1:     {
1:         AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<Object>()
1:              {
0:                  public Object run() throws IOException
1:                  {
1:                      indexWriter.close();
1: 		
1:                      return null;
1:                  }
1:              }
1:              );
1:     }
1: 
1: 	/**
0: 	 * Returns a Lucene IndexReader, which reads from the indicated Lucene index.
1: 	 * 
0: 	 * @param indexHome The directory holding the Lucene index.
1: 	 */
0: 	static IndexReader getIndexReader( final File indexHome )
0:         throws IOException, PrivilegedActionException
1:     {
0:         return AccessController.doPrivileged
1:             (
0:              new PrivilegedExceptionAction<IndexReader>()
1:              {
0:                  public IndexReader run() throws SQLException, IOException
1:                  {
0:                      return DirectoryReader.open( FSDirectory.open( indexHome ) );
1:                  }
1:              }
1:              );
1: 	}
1: 	
1: }
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:7234498
/////////////////////////////////////////////////////////////////////////
1: import java.security.PrivilegedAction;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         StorageFactory storageFactory = getStorageFactory(conn);
1:         StorageFile luceneDir =
1:                 storageFactory.newStorageFile(Database.LUCENE_DIR);
1:         if (exists(luceneDir)) {
1:             deleteFile(luceneDir);
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException, IOException, PrivilegedActionException
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException, IOException, PrivilegedActionException
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException, IOException, PrivilegedActionException
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException
/////////////////////////////////////////////////////////////////////////
1:     private static  void    writeIndexProperties( final StorageFile file, Properties properties )
1:         throws IOException
1:         if (file == null || properties == null) {
1:             return;
0:         }
1:         OutputStream os;
0:         try {
1:             os = AccessController.doPrivileged(
1:                     new PrivilegedExceptionAction<OutputStream>() {
1:                 public OutputStream run() throws IOException {
1:                     return file.getOutputStream();
1:             });
1:         } catch (PrivilegedActionException pae) {
1:             throw (IOException) pae.getCause();
0:         }
0: 
0:         properties.store( os, null );
0:         os.flush();
0:         os.close();
/////////////////////////////////////////////////////////////////////////
1:              new PrivilegedAction<String[]>()
1:                  public String[] run()
/////////////////////////////////////////////////////////////////////////
1:              new PrivilegedAction<Boolean>()
1:                  public Boolean run()
/////////////////////////////////////////////////////////////////////////
0:         throws SQLException
1:         boolean result = AccessController.doPrivileged(
1:                 new PrivilegedAction<Boolean>() {
1:             public Boolean run() {
1:                 return file.isDirectory() ? file.deleteAll() : file.delete();
0:             }
0:         });
1:         if (!result) {
0:             throw newSQLException(SQLState.UNABLE_TO_DELETE_FILE,
0:                                   file.getPath());
0:         }
0:         return result;
/////////////////////////////////////////////////////////////////////////
1:         throws IOException
0:         try {
0:             return AccessController.doPrivileged
1:                  public IndexWriter run() throws IOException
/////////////////////////////////////////////////////////////////////////
1:         } catch (PrivilegedActionException pae) {
1:             throw (IOException) pae.getCause();
0:         }
/////////////////////////////////////////////////////////////////////////
1:         throws IOException
0:         try {
0:             AccessController.doPrivileged
1:              new PrivilegedExceptionAction<Void>()
1:                  public Void run() throws IOException
/////////////////////////////////////////////////////////////////////////
1:         } catch (PrivilegedActionException pae) {
1:             throw (IOException) pae.getCause();
0:         }
1:         throws IOException
0:         try {
0:             AccessController.doPrivileged
1:              new PrivilegedExceptionAction<Void>()
1:                  public Void run() throws IOException
/////////////////////////////////////////////////////////////////////////
0:         } catch (PrivilegedActionException pae) {
0:             throw (IOException) pae.getCause();
0:         }
/////////////////////////////////////////////////////////////////////////
0:         throws PrivilegedActionException
/////////////////////////////////////////////////////////////////////////
1:         catch (PrivilegedActionException pae) {
1:             throw (SQLException) pae.getCause();
0:         }
============================================================================
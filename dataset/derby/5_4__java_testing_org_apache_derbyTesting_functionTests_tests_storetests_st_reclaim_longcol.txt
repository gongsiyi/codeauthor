1:7ddacaa: /*
32:7ddacaa: 
1:43bb9d4:    Derby - Class org.apache.derbyTesting.functionTests.tests.storetests.st_reclaim_longcol
1:d43d4c3: 
1:dff95a1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:dff95a1:    contributor license agreements.  See the NOTICE file distributed with
1:dff95a1:    this work for additional information regarding copyright ownership.
1:dff95a1:    The ASF licenses this file to You under the Apache License, Version 2.0
1:dff95a1:    (the "License"); you may not use this file except in compliance with
1:dff95a1:    the License.  You may obtain a copy of the License at
1:7ddacaa: 
1:7ddacaa:       http://www.apache.org/licenses/LICENSE-2.0
1:7ddacaa: 
1:7ddacaa:    Unless required by applicable law or agreed to in writing, software
1:7ddacaa:    distributed under the License is distributed on an "AS IS" BASIS,
1:7ddacaa:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:7ddacaa:    See the License for the specific language governing permissions and
1:7ddacaa:    limitations under the License.
1:7ddacaa: 
1:7ddacaa:  */
1:7ddacaa: 
1:7ddacaa: package org.apache.derbyTesting.functionTests.tests.storetests;
1:7ddacaa: 
1:7ddacaa: 
1:7ddacaa: import java.sql.PreparedStatement;
1:7ddacaa: import java.sql.ResultSet;
1:43bb9d4: import java.sql.ResultSetMetaData;
1:7ddacaa: import java.sql.SQLException;
1:7ddacaa: import java.sql.Statement;
1:7ddacaa: 
1:7ddacaa: import java.util.Arrays;
1:7ddacaa: 
1:43bb9d4: import junit.framework.Test;
1:43bb9d4: import org.apache.derbyTesting.junit.BaseJDBCTestCase;
1:43bb9d4: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1:43bb9d4: import org.apache.derbyTesting.junit.JDBC;
1:43bb9d4: import org.apache.derbyTesting.junit.TestConfiguration;
1:7ddacaa: 
1:7ddacaa: 
3:7ddacaa: /**
1:7ddacaa: 
1:7ddacaa: The purpose of this test space reclamation of long rows and long columns.
1:7ddacaa: This addresses DERBY-670.
1:7ddacaa: 
1:7ddacaa: The main issue is that previous to fixes for DERBY-670, space reclamation
1:7ddacaa: was only automatically queued when the last row on a page was deleted.  In
1:7ddacaa: the case of long columns, the actual row on the main page can be quite small
1:7ddacaa: as the long data is streamed onto other pages.  So the table can grow 
1:7ddacaa: unexpectedly quite large before the default space reclamation kicks in.  The
1:7ddacaa: change queues space reclamation in the case of long columns (blob/clob),
1:43bb9d4: immediately post commit of the single delete.
1:7ddacaa: 
1:7ddacaa: The testing strategy is to loop doing insert, delete, commit of a blob for
1:7ddacaa: a number of iterations and check that the actual size of the table is 
1:7ddacaa: reasonable.  A sleep will be added to allow time for post commit to catch up
1:7ddacaa: as the test may be run in a number of environments with varying performance
1:7ddacaa: of background activities.
1:7ddacaa: 
3:7ddacaa: **/
1:7ddacaa: 
1:43bb9d4: public class st_reclaim_longcol extends BaseJDBCTestCase
1:d43d4c3: {
1:7ddacaa:     static boolean verbose = false;
1:d43d4c3: 
1:43bb9d4:     public st_reclaim_longcol(String name) {
1:43bb9d4:         super(name);
1:d43d4c3:     }
1:d43d4c3: 
1:43bb9d4:     public static Test suite() {
1:43bb9d4:         return new CleanDatabaseTestSetup(
1:43bb9d4:                 TestConfiguration.embeddedSuite(st_reclaim_longcol.class));
1:d43d4c3:     }
1:d43d4c3: 
1:cf5ac0c:     /**
1:7ddacaa:      * Test reclaim of a single deleted blob on a page with non-deleted rows.
2:7ddacaa:      * <p>
1:7ddacaa:      * loops through inserting alternating long and short column rows resulting
1:7ddacaa:      * in pages with 1 short and one long.  Deletes the long column row and
1:7ddacaa:      * tests that space from the long column row is reclaimed even though
1:7ddacaa:      * there are non-deleted rows on the page.
1:7ddacaa:      **/
1:43bb9d4:     private void test1(int blob_size, int num_rows) throws SQLException
1:d43d4c3:     {
1:7ddacaa:         byte[]  long_byteVal    = new byte[blob_size];
1:7ddacaa:         byte[]  short_byteVal   = new byte[10];
1:d43d4c3: 
1:43bb9d4:         println(
2:7ddacaa:             "test1:insert/delete of " + num_rows + 
2:7ddacaa:                 " rows with blob(" + blob_size + ")"); 
1:d43d4c3: 
1:7ddacaa:         Arrays.fill(long_byteVal,  (byte)'L');
1:7ddacaa:         Arrays.fill(short_byteVal, (byte)'S');
1:7ddacaa: 
1:43bb9d4:         Statement s = createStatement();
1:43bb9d4:         dropTable("LONGCOL");
1:43bb9d4:         s.execute(
1:7ddacaa:             "create table longcol (id int primary key not null, val blob(" + 
1:7ddacaa:             blob_size + "))");
1:7ddacaa: 
1:43bb9d4:         commit();
1:7ddacaa: 
1:7ddacaa:         PreparedStatement ins_stmt = 
1:43bb9d4:             prepareStatement("insert into longcol values (?, ?)");
1:7ddacaa:         PreparedStatement del_stmt = 
1:43bb9d4:             prepareStatement("delete from longcol where id = ?");
1:7ddacaa: 
1:7ddacaa:         // worst case is a mixture of rows with long columns and those without.
1:7ddacaa:         // Insert of row with a long column always first goes onto a new 
1:7ddacaa:         // page by itself, but subsequent non-long column rows can be inserted
1:7ddacaa:         // on that page.  Then when the long column row is deleted - before the
1:7ddacaa:         // change - it and all it's chain won't get reclaimed until all rows
1:7ddacaa:         // on the page get deleted.
1:7ddacaa: 
1:7ddacaa:         // now do insert/delete/commit for subsequent rows.  Before fix the
1:7ddacaa:         // space used in the table will grow until the deleted rows do not
1:7ddacaa:         // fit on the first page.  And even then before the fix the rows
1:7ddacaa:         // on the first page are never reclaimed as the 1st one is never
1:7ddacaa:         // deleted.
1:cf5ac0c:         
1:cf5ac0c:         // keep track of what we think should be worst case number
1:cf5ac0c:         // of allocated pages based on total number of rows in the page
1:cf5ac0c:         // after long column is deleted.  Table starts with 1 page, then 
1:cf5ac0c:         // on each iteration the worst case is that the new short row goes
1:cf5ac0c:         // onto a new page.  Start out with 5 for overhead.
1:cf5ac0c:         int worst_case_max_allocated = 5;
1:cf5ac0c: 
1:cf5ac0c:       
1:7ddacaa:         for (int iter = 1; iter < num_rows; iter++)
1:d43d4c3:         {
1:7ddacaa:             // insert the long blob
1:7ddacaa:             ins_stmt.setInt(  1, iter);
1:7ddacaa:             ins_stmt.setBytes(2, long_byteVal);
1:7ddacaa:             ins_stmt.executeUpdate();
1:7ddacaa: 
1:7ddacaa:             // insert the short blob
1:7ddacaa:             ins_stmt.setInt(  1, -(iter));
1:7ddacaa:             ins_stmt.setBytes(2, short_byteVal);
1:7ddacaa:             ins_stmt.executeUpdate();
1:7ddacaa: 
1:7ddacaa:             // delete the long blob
1:7ddacaa:             del_stmt.setInt(1, iter);
1:7ddacaa:             del_stmt.executeUpdate();
1:7ddacaa: 
1:cf5ac0c:             // in the worst case each new set of 2 rows will result in
1:cf5ac0c:             // the one undeleted row getting put on a new page.
1:cf5ac0c:             worst_case_max_allocated++;
1:cf5ac0c: 
2:7ddacaa:             // commit the xact, post commit should kick in to reclaim the
2:7ddacaa:             // blob space sometime after the commit.
1:43bb9d4:             commit();
1:7ddacaa: 
1:cf5ac0c:             // after each commit give the background thread a chance to 
1:cf5ac0c:             // reclaim the deleted rows.
1:43bb9d4:             wait_for_max_allocated("test1", worst_case_max_allocated);
1:d43d4c3:         }
1:7ddacaa: 
1:cf5ac0c:         // get total pages = allocated pages + free pages
1:43bb9d4:         ResultSet rs = getSpaceTable("LONGCOL");
1:43bb9d4:         assertTrue("Space table was empty", rs.next());
1:7ddacaa: 
1:43bb9d4:         int allocated = rs.getInt("NUMALLOCATEDPAGES");
1:43bb9d4:         int free = rs.getInt("NUMFREEPAGES");
1:43bb9d4:         int total_pages = allocated + free;
1:43bb9d4: 
1:43bb9d4:         println("Space information after " + num_rows +
1:43bb9d4:                 "insert/delete pairs of rows in longcol table containing " +
1:43bb9d4:                 blob_size + "blobs:");
1:43bb9d4:         printCurrentRow(rs);
1:43bb9d4: 
1:43bb9d4:         JDBC.assertEmpty(rs);  // There should only be one row.
1:7ddacaa: 
1:7ddacaa:         int total_expected_page_max = 12 + num_rows;
1:d43d4c3: 
1:43bb9d4:         if (total_pages > total_expected_page_max)
1:d43d4c3:         {
1:cf5ac0c:             // for the above test case we expect the following space:
1:cf5ac0c:             //     page 0
1:cf5ac0c:             //     page 1 
1:cf5ac0c:             //     free space from 1 blob - 9 pages per blob
1:cf5ac0c:             //     allocated page per long/short blob insert.  Each long
1:cf5ac0c:             //         inserts onto a new page to try and fit it entirely
1:cf5ac0c:             //         on a page.  Then the short blob goes to last inserted
1:cf5ac0c:             //         page.  This process repeats.  The previous pages are
1:cf5ac0c:             //         marked "half-filled" and can be used in future for
1:cf5ac0c:             //         short rows that don't fit on the last page inserted.
1:d43d4c3: 
1:43bb9d4:             fail(
1:cf5ac0c:                 "Test 1 failed, expected less than " + 
1:cf5ac0c:                 total_expected_page_max + " pages - count is:\n" +
1:43bb9d4:                 "free pages     : " + free +
1:43bb9d4:                 "\nallocated pages: " + allocated);
1:d43d4c3:         }
1:d43d4c3: 
1:43bb9d4:         commit();
1:d43d4c3:     }
1:7ddacaa: 
1:79366f5:     /**
1:79366f5:      * DERBY-1913
1:79366f5:      * <p>
1:79366f5:      * test2 is too sensitive to machine speed and background thread
1:79366f5:      * processing.  It would be better suited as a long running stress
1:79366f5:      * test if someone has the inclination.  Disabling this test for
1:79366f5:      * now.  test1 covers the original intent to test that blobs are
1:79366f5:      * immediately marked for post commit on individual delete, rather
1:79366f5:      * than waiting for all rows on a page to be deleted.
1:79366f5:      **/
1:43bb9d4:     private void test2(
1:7ddacaa:     int         blob_size, 
1:7ddacaa:     int         work_size, 
1:7ddacaa:     int         total_work)
3:7ddacaa:         throws SQLException
1:cf5ac0c:     {
1:7ddacaa:         byte[]  long_byteVal    = new byte[blob_size];
1:7ddacaa:         byte[]  short_byteVal   = new byte[10];
1:79366f5: 
1:43bb9d4:         println(
2:7ddacaa:             "test2:queue of " + work_size + 
2:7ddacaa:                 " rows with blob(" + blob_size + "), total_work = " + 
2:7ddacaa:                 total_work); 
1:cf5ac0c: 
1:7ddacaa:         Arrays.fill(long_byteVal,  (byte)'L');
1:7ddacaa:         Arrays.fill(short_byteVal, (byte)'S');
1:cf5ac0c: 
1:43bb9d4:         Statement s = createStatement();
1:43bb9d4:         dropTable("LONGCOL");
1:43bb9d4:         s.execute(
1:7ddacaa:             "create table longcol (id int primary key not null, val blob(" + 
1:7ddacaa:             blob_size + "))");
1:7ddacaa: 
1:7ddacaa:         PreparedStatement ins_stmt = 
1:43bb9d4:             prepareStatement("insert into longcol values (?, ?)");
1:7ddacaa:         PreparedStatement del_stmt = 
1:43bb9d4:             prepareStatement("delete from longcol where id = ?");
1:7ddacaa: 
1:7ddacaa:         // insert the "work_size" number of elements into the table
1:7ddacaa:         for (int iter = 0; iter < work_size; iter++)
1:cf5ac0c:         {
1:7ddacaa:             // insert the long blob
1:7ddacaa:             ins_stmt.setInt(  1, iter);
1:7ddacaa:             ins_stmt.setBytes(2, long_byteVal);
1:7ddacaa:             ins_stmt.executeUpdate();
1:7ddacaa: 
1:cf5ac0c:         }
1:43bb9d4:         commit();
1:7ddacaa: 
1:7ddacaa: 
1:7ddacaa:         // for each subsequent work item, queue it to the end and delete
1:cf5ac0c:         // the oldest existing work item.
1:7ddacaa:         for (int iter = work_size; iter < total_work; iter++)
1:cf5ac0c:         {
1:7ddacaa:             // insert the long blob
1:7ddacaa:             ins_stmt.setInt(  1, iter);
1:7ddacaa:             ins_stmt.setBytes(2, long_byteVal);
1:7ddacaa:             ins_stmt.executeUpdate();
1:7ddacaa: 
1:7ddacaa:             // delete the long blob
1:cf5ac0c:             del_stmt.setInt(1, iter - work_size);
1:7ddacaa:             del_stmt.executeUpdate();
1:7ddacaa: 
1:7ddacaa:             // commit the xact, post commit should kick in to reclaim the
1:7ddacaa:             // blob space sometime after the commit.
1:43bb9d4:             commit();
1:cf5ac0c:         }
1:7ddacaa: 
1:7ddacaa: 
1:7ddacaa: 
1:7ddacaa:         // Expect at least allocated pages * 10 for each item in work_size, 
1:7ddacaa:         // plus some overhead for 1st page and such.
1:7ddacaa:         // Free page count depends on how quick post commit can free before
1:7ddacaa:         // subsequent insert, and very likely is machine/jvm/os dependent. In
1:7ddacaa:         // my testing adding a sleep of 100 ms. to the above insert/delete
1:7ddacaa:         // loop changed free from 60 to 30.  Minimum is 10 for the one row 
1:7ddacaa:         // that is deleted in the same xact as the first inserted row in the 
1:7ddacaa:         // insert/delete loop.  The 30 below is expected allocate of 10
1:7ddacaa:         // per work size, and then a guess at how fast post commit can keep
1:7ddacaa:         // up with free pages.  Run the test with total_work reasonably 
1:7ddacaa:         // bigger than worksize, something like work_size=5 and total_work >100
1:d43d4c3: 
1:cf5ac0c:         // Wait for background thread to convert all deleted rows to 
1:cf5ac0c:         // free pages.  Total number of free pages is very variable, dependent
1:cf5ac0c:         // on availability of background cpu, so just wait to get under
1:cf5ac0c:         // an expected max of allocated pages.  Expect 10 allocated pages per
1:cf5ac0c:         // item in work size and add 5 pages for misc overhead.
1:43bb9d4:         wait_for_max_allocated("test2", (10 * work_size) + 5);
1:7ddacaa: 
1:43bb9d4:         ResultSet rs = getSpaceTable("LONGCOL");
1:43bb9d4:         assertTrue("Space table was empty", rs.next());
1:7ddacaa: 
1:43bb9d4:         int total_pages =
1:43bb9d4:                 rs.getInt("NUMALLOCATEDPAGES") + rs.getInt("NUMFREEPAGES");
1:7ddacaa: 
1:43bb9d4:         println("Space information:");
1:43bb9d4:         printCurrentRow(rs);
1:43bb9d4:         JDBC.assertEmpty(rs);
1:7ddacaa: 
1:43bb9d4:         commit();
1:7ddacaa: 
1:7ddacaa:         // Run another iteration of the work loop, by now memory should 
1:7ddacaa:         // have gotten to constant.
1:cf5ac0c:         for (int iter = total_work; iter < (total_work * 2); iter++)
1:cf5ac0c:         {
1:7ddacaa:             // insert the long blob
1:7ddacaa:             ins_stmt.setInt(  1, iter);
1:7ddacaa:             ins_stmt.setBytes(2, long_byteVal);
1:7ddacaa:             ins_stmt.executeUpdate();
1:cf5ac0c: 
1:7ddacaa:             // delete the long blob
1:cf5ac0c:             del_stmt.setInt(1, iter - work_size);
1:7ddacaa:             del_stmt.executeUpdate();
1:7ddacaa: 
1:7ddacaa:             // commit the xact, post commit should kick in to reclaim the
1:7ddacaa:             // blob space sometime after the commit.
1:43bb9d4:             commit();
1:cf5ac0c:         }
1:7ddacaa: 
1:cf5ac0c:         // Wait for background thread to convert all deleted rows to 
1:cf5ac0c:         // free pages.  Total number of free pages is very variable, dependent
1:cf5ac0c:         // on availability of background cpu, so just wait to get under
1:cf5ac0c:         // an expected max of allocated pages.  Expect 10 allocated pages per
1:cf5ac0c:         // item in work size and add 5 pages for misc overhead.
1:43bb9d4:         wait_for_max_allocated("test2_2", (10 * work_size) + 5);
1:7ddacaa: 
1:43bb9d4:         rs = getSpaceTable("LONGCOL");
1:43bb9d4:         assertTrue("Space table was empty", rs.next());
1:7ddacaa: 
1:43bb9d4:         int second_total_pages =
1:43bb9d4:                 rs.getInt("NUMALLOCATEDPAGES") + rs.getInt("NUMFREEPAGES");
1:43bb9d4: 
1:43bb9d4:         println("Space information:");
1:43bb9d4:         printCurrentRow(rs);
1:43bb9d4:         JDBC.assertEmpty(rs);
1:7ddacaa: 
1:43bb9d4:         commit();
1:7ddacaa: 
1:cf5ac0c:         // This could fail due to machine variability, leaving it for now
1:cf5ac0c:         // as I have not seen this failure reported.
1:7ddacaa:         if (total_pages != second_total_pages)
3:d43d4c3:         {
1:43bb9d4:             fail(
1:cf5ac0c:                 "Test 2 failed, expected constant memory after second run." +
1:7ddacaa:                 "initial total = " + total_pages +
1:7ddacaa:                 "second total = " + second_total_pages);
1:d43d4c3:         }
1:d43d4c3:     }
1:7ddacaa: 
1:43bb9d4:     /**
1:43bb9d4:      * Invoke SYSCS_DIAG.SPACE_TABLE on the specified table in the current
1:43bb9d4:      * schema.
1:43bb9d4:      */
1:43bb9d4:     private ResultSet getSpaceTable(String table) throws SQLException {
1:43bb9d4:         PreparedStatement ps = prepareStatement(
1:43bb9d4:                 "select * from table(syscs_diag.space_table(?)) t "
1:43bb9d4:                         + "where isindex = 0");
1:43bb9d4:         ps.setString(1, table);
1:43bb9d4:         return ps.executeQuery();
1:43bb9d4:     }
1:43bb9d4: 
1:43bb9d4:     /**
1:43bb9d4:      * Print the value of all columns in the current row of the specified
1:43bb9d4:      * result set, if debugging is enabled.
1:43bb9d4:      */
1:43bb9d4:     private void printCurrentRow(ResultSet rs) throws SQLException {
1:43bb9d4:         if (TestConfiguration.getCurrent().isVerbose()) {
1:43bb9d4:             ResultSetMetaData rsmd = rs.getMetaData();
1:43bb9d4:             for (int col = 1; col <= rsmd.getColumnCount(); col++) {
1:43bb9d4:                 println(rsmd.getColumnName(col) + ": " + rs.getObject(col));
1:43bb9d4:             }
1:43bb9d4:         }
1:43bb9d4:     }
1:7ddacaa: 
1:7ddacaa:     /**
1:cf5ac0c:      * wait for background thread to convert allocated pages to free pages
1:cf5ac0c:      * <p>
1:dbed020:      * Wait until the total number of allocated pages is &lt;= alloc_wait_count.
1:cf5ac0c:      * The expectation is that the test has performed some deletes and 
1:cf5ac0c:      * committed allowing the background task converted empty allocated pages
1:cf5ac0c:      * with only deleted rows into free pages.
1:cf5ac0c:      *
1:cf5ac0c:      * On an machine with some idle processors only a short wait should
1:cf5ac0c:      * be necessary.  But on machines with lots of load, possibly other
1:cf5ac0c:      * tests running just sleeping does not guarantee background thread
1:cf5ac0c:      * an immediate chance to run.  Without this extra wait some nightly's
1:cf5ac0c:      * were seeing failures, see DERBY-1913.
1:cf5ac0c:      **/
1:cf5ac0c:     private void wait_for_max_allocated(
1:cf5ac0c:     String      test_name,
1:cf5ac0c:     int         alloc_wait_count)
1:cf5ac0c:         throws SQLException 
1:cf5ac0c:     {
1:cf5ac0c:         // an initial 1/10 of second which should work for most environments.
1:43bb9d4:         sleep(100);
1:cf5ac0c: 
1:43bb9d4:         Integer save_total_alloc = null;
1:cf5ac0c: 
1:cf5ac0c:         // wait for maximum 100 seconds.
1:cf5ac0c: 
1:cf5ac0c:         // wait 10 seconds and give up if it has mad no progress.
1:cf5ac0c:         int max_wait_for_bg_thread = 10000;
1:cf5ac0c:         int ms_waited              = 100;
1:cf5ac0c: 
1:43bb9d4:         while (true)
1:cf5ac0c:         {
1:43bb9d4:             ResultSet rs = getSpaceTable("LONGCOL");
1:43bb9d4:             assertTrue("Space table was empty", rs.next());
1:43bb9d4:             int total_alloc = rs.getInt("NUMALLOCATEDPAGES");
1:43bb9d4:             int free = rs.getInt("NUMFREEPAGES");
1:43bb9d4:             JDBC.assertEmpty(rs);
1:43bb9d4: 
1:43bb9d4:             if (total_alloc <= alloc_wait_count) {
1:43bb9d4:                 // The number of allocated pages has shrunk enough. Break
1:43bb9d4:                 // out of the loop.
1:43bb9d4:                 break;
1:43bb9d4:             }
1:43bb9d4: 
1:43bb9d4:             // Save the first count so that we can see if we've made
1:43bb9d4:             // progress later.
1:43bb9d4:             if (save_total_alloc == null) {
1:43bb9d4:                 save_total_alloc = total_alloc;
1:43bb9d4:             }
1:43bb9d4: 
1:cf5ac0c:             if (ms_waited < max_wait_for_bg_thread)
1:cf5ac0c:             {
1:cf5ac0c:                 // The result is dependent on background activity which may
1:cf5ac0c:                 // differ from machine to machine.  Loop, sleeping in this
1:cf5ac0c:                 // thread to allow background thread to run.
1:cf5ac0c: 
1:43bb9d4:                 ms_waited += 1000;
1:43bb9d4:                 sleep(1000);
1:cf5ac0c: 
1:cf5ac0c:             }
1:cf5ac0c:             else if (total_alloc < save_total_alloc)
1:cf5ac0c:             {
1:cf5ac0c:                 // background thread did make progress, give it another
1:cf5ac0c:                 // 10 seconds.
1:cf5ac0c:                 save_total_alloc = total_alloc;
1:cf5ac0c:                 max_wait_for_bg_thread += 10000;
1:cf5ac0c:             }
1:cf5ac0c:             else
1:cf5ac0c:             {
1:cf5ac0c:                 // for the above test case we expect the following space:
1:cf5ac0c:                 //     page 0
1:cf5ac0c:                 //     page 1 
1:cf5ac0c:                 //     free space from 1 blob - 9 pages per blob
1:cf5ac0c:                 //     allocated page per long/short blob insert.  Each long
1:cf5ac0c:                 //         inserts onto a new page to try and fit it entirely
1:cf5ac0c:                 //         on a page.  Then the short blob goes to last inserted
1:cf5ac0c:                 //         page.  This process repeats.  The previous pages are
1:cf5ac0c:                 //         marked "half-filled" and can be used in future for
1:cf5ac0c:                 //         short rows that don't fit on the last page inserted.
1:cf5ac0c: 
1:43bb9d4:                 fail(
1:cf5ac0c:                     "Test " + test_name + 
1:cf5ac0c:                     " failed in wait_for_max_allocated(), expected less than " + 
1:cf5ac0c:                     alloc_wait_count + " allocated pages:\n" +
1:43bb9d4:                     "free pages     : "   + free +
1:43bb9d4:                     "\nallocated pages: " + total_alloc +
1:cf5ac0c:                     "\nWaited " + ms_waited + "ms. for background work.");
1:cf5ac0c:             }
1:cf5ac0c:         }
1:cf5ac0c:     }
1:cf5ac0c: 
1:43bb9d4:     public void testList() throws SQLException
1:d43d4c3:     {
1:43bb9d4:         setAutoCommit(false);
1:43bb9d4: 
1:43bb9d4:         test1(250000, 20);
1:cf5ac0c: 
1:79366f5:         // DERBY-1913 - disabling test2 as it is too sensitive to background
1:79366f5:         // processing.
1:43bb9d4:         // test2(250000, 5, 500);
1:cf5ac0c:     }
1:d43d4c3: }
============================================================================
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:dbed020
/////////////////////////////////////////////////////////////////////////
1:      * Wait until the total number of allocated pages is &lt;= alloc_wait_count.
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:43bb9d4
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derbyTesting.functionTests.tests.storetests.st_reclaim_longcol
/////////////////////////////////////////////////////////////////////////
1: import java.sql.ResultSetMetaData;
1: import junit.framework.Test;
1: import org.apache.derbyTesting.junit.BaseJDBCTestCase;
1: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1: import org.apache.derbyTesting.junit.JDBC;
1: import org.apache.derbyTesting.junit.TestConfiguration;
/////////////////////////////////////////////////////////////////////////
1: immediately post commit of the single delete.
/////////////////////////////////////////////////////////////////////////
1: public class st_reclaim_longcol extends BaseJDBCTestCase
1:     public st_reclaim_longcol(String name) {
1:         super(name);
1:     public static Test suite() {
1:         return new CleanDatabaseTestSetup(
1:                 TestConfiguration.embeddedSuite(st_reclaim_longcol.class));
/////////////////////////////////////////////////////////////////////////
1:     private void test1(int blob_size, int num_rows) throws SQLException
1:         println(
1:         Statement s = createStatement();
1:         dropTable("LONGCOL");
1:         s.execute(
1:         commit();
1:             prepareStatement("insert into longcol values (?, ?)");
1:             prepareStatement("delete from longcol where id = ?");
/////////////////////////////////////////////////////////////////////////
1:             commit();
1:             wait_for_max_allocated("test1", worst_case_max_allocated);
1:         ResultSet rs = getSpaceTable("LONGCOL");
1:         assertTrue("Space table was empty", rs.next());
1:         int allocated = rs.getInt("NUMALLOCATEDPAGES");
1:         int free = rs.getInt("NUMFREEPAGES");
1:         int total_pages = allocated + free;
1: 
1:         println("Space information after " + num_rows +
1:                 "insert/delete pairs of rows in longcol table containing " +
1:                 blob_size + "blobs:");
1:         printCurrentRow(rs);
1: 
1:         JDBC.assertEmpty(rs);  // There should only be one row.
1:         if (total_pages > total_expected_page_max)
/////////////////////////////////////////////////////////////////////////
1:             fail(
1:                 "free pages     : " + free +
1:                 "\nallocated pages: " + allocated);
1:         commit();
/////////////////////////////////////////////////////////////////////////
1:     private void test2(
/////////////////////////////////////////////////////////////////////////
1:         println(
/////////////////////////////////////////////////////////////////////////
1:         Statement s = createStatement();
1:         dropTable("LONGCOL");
1:         s.execute(
1:             prepareStatement("insert into longcol values (?, ?)");
1:             prepareStatement("delete from longcol where id = ?");
/////////////////////////////////////////////////////////////////////////
1:         commit();
/////////////////////////////////////////////////////////////////////////
1:             commit();
/////////////////////////////////////////////////////////////////////////
1:         wait_for_max_allocated("test2", (10 * work_size) + 5);
1:         ResultSet rs = getSpaceTable("LONGCOL");
1:         assertTrue("Space table was empty", rs.next());
1:         int total_pages =
1:                 rs.getInt("NUMALLOCATEDPAGES") + rs.getInt("NUMFREEPAGES");
1:         println("Space information:");
1:         printCurrentRow(rs);
1:         JDBC.assertEmpty(rs);
1:         commit();
/////////////////////////////////////////////////////////////////////////
1:             commit();
/////////////////////////////////////////////////////////////////////////
1:         wait_for_max_allocated("test2_2", (10 * work_size) + 5);
1:         rs = getSpaceTable("LONGCOL");
1:         assertTrue("Space table was empty", rs.next());
1:         int second_total_pages =
1:                 rs.getInt("NUMALLOCATEDPAGES") + rs.getInt("NUMFREEPAGES");
1:         println("Space information:");
1:         printCurrentRow(rs);
1:         JDBC.assertEmpty(rs);
1: 
1:         commit();
1:             fail(
1:     /**
1:      * Invoke SYSCS_DIAG.SPACE_TABLE on the specified table in the current
1:      * schema.
1:      */
1:     private ResultSet getSpaceTable(String table) throws SQLException {
1:         PreparedStatement ps = prepareStatement(
1:                 "select * from table(syscs_diag.space_table(?)) t "
1:                         + "where isindex = 0");
1:         ps.setString(1, table);
1:         return ps.executeQuery();
1:     }
1: 
1:     /**
1:      * Print the value of all columns in the current row of the specified
1:      * result set, if debugging is enabled.
1:      */
1:     private void printCurrentRow(ResultSet rs) throws SQLException {
1:         if (TestConfiguration.getCurrent().isVerbose()) {
1:             ResultSetMetaData rsmd = rs.getMetaData();
1:             for (int col = 1; col <= rsmd.getColumnCount(); col++) {
1:                 println(rsmd.getColumnName(col) + ": " + rs.getObject(col));
1:             }
1:         }
1:     }
/////////////////////////////////////////////////////////////////////////
1:         sleep(100);
1:         Integer save_total_alloc = null;
/////////////////////////////////////////////////////////////////////////
1:         while (true)
1:             ResultSet rs = getSpaceTable("LONGCOL");
1:             assertTrue("Space table was empty", rs.next());
1:             int total_alloc = rs.getInt("NUMALLOCATEDPAGES");
1:             int free = rs.getInt("NUMFREEPAGES");
1:             JDBC.assertEmpty(rs);
1: 
1:             if (total_alloc <= alloc_wait_count) {
1:                 // The number of allocated pages has shrunk enough. Break
1:                 // out of the loop.
1:                 break;
1:             }
1: 
1:             // Save the first count so that we can see if we've made
1:             // progress later.
1:             if (save_total_alloc == null) {
1:                 save_total_alloc = total_alloc;
1:             }
1: 
1:                 ms_waited += 1000;
1:                 sleep(1000);
/////////////////////////////////////////////////////////////////////////
1:                 fail(
1:                     "free pages     : "   + free +
1:                     "\nallocated pages: " + total_alloc +
1:     public void testList() throws SQLException
1:         setAutoCommit(false);
1: 
1:         test1(250000, 20);
1:         // test2(250000, 5, 500);
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.shared.common.sanity.SanityManager;
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:79366f5
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * DERBY-1913
1:      * <p>
1:      * test2 is too sensitive to machine speed and background thread
1:      * processing.  It would be better suited as a long running stress
1:      * test if someone has the inclination.  Disabling this test for
1:      * now.  test1 covers the original intent to test that blobs are
1:      * immediately marked for post commit on individual delete, rather
1:      * than waiting for all rows on a page to be deleted.
1:      **/
/////////////////////////////////////////////////////////////////////////
1: 
1:         // DERBY-1913 - disabling test2 as it is too sensitive to background
1:         // processing.
0:         // test2(conn, 250000, 5, 500);
commit:cf5ac0c
/////////////////////////////////////////////////////////////////////////
1:         
1:         // keep track of what we think should be worst case number
1:         // of allocated pages based on total number of rows in the page
1:         // after long column is deleted.  Table starts with 1 page, then 
1:         // on each iteration the worst case is that the new short row goes
1:         // onto a new page.  Start out with 5 for overhead.
1:         int worst_case_max_allocated = 5;
1: 
1:       
/////////////////////////////////////////////////////////////////////////
1:             // in the worst case each new set of 2 rows will result in
1:             // the one undeleted row getting put on a new page.
1:             worst_case_max_allocated++;
1: 
1:             // after each commit give the background thread a chance to 
1:             // reclaim the deleted rows.
0:             wait_for_max_allocated(conn, "test1", worst_case_max_allocated);
1:         // get total pages = allocated pages + free pages
/////////////////////////////////////////////////////////////////////////
1:             // for the above test case we expect the following space:
1:             //     page 0
1:             //     page 1 
1:             //     free space from 1 blob - 9 pages per blob
1:             //     allocated page per long/short blob insert.  Each long
1:             //         inserts onto a new page to try and fit it entirely
1:             //         on a page.  Then the short blob goes to last inserted
1:             //         page.  This process repeats.  The previous pages are
1:             //         marked "half-filled" and can be used in future for
1:             //         short rows that don't fit on the last page inserted.
0:             System.out.println(
1:                 "Test 1 failed, expected less than " + 
1:                 total_expected_page_max + " pages - count is:\n" +
0:                 "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                 "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             break;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         // the oldest existing work item.
/////////////////////////////////////////////////////////////////////////
1:             del_stmt.setInt(1, iter - work_size);
/////////////////////////////////////////////////////////////////////////
1:         // Wait for background thread to convert all deleted rows to 
1:         // free pages.  Total number of free pages is very variable, dependent
1:         // on availability of background cpu, so just wait to get under
1:         // an expected max of allocated pages.  Expect 10 allocated pages per
1:         // item in work size and add 5 pages for misc overhead.
0:         wait_for_max_allocated(conn, "test2", (10 * work_size) + 5);
0:         int[] sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
0:         int total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
/////////////////////////////////////////////////////////////////////////
1:         for (int iter = total_work; iter < (total_work * 2); iter++)
1:             del_stmt.setInt(1, iter - work_size);
1:         // Wait for background thread to convert all deleted rows to 
1:         // free pages.  Total number of free pages is very variable, dependent
1:         // on availability of background cpu, so just wait to get under
1:         // an expected max of allocated pages.  Expect 10 allocated pages per
1:         // item in work size and add 5 pages for misc overhead.
0:         wait_for_max_allocated(conn, "test2_2", (10 * work_size) + 5);
1: 
1:         // This could fail due to machine variability, leaving it for now
1:         // as I have not seen this failure reported.
1:                 "Test 2 failed, expected constant memory after second run." +
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * wait for background thread to convert allocated pages to free pages
1:      * <p>
0:      * Wait until the total number of allocated pages is <= alloc_wait_count.
1:      * The expectation is that the test has performed some deletes and 
1:      * committed allowing the background task converted empty allocated pages
1:      * with only deleted rows into free pages.
1:      *
1:      * On an machine with some idle processors only a short wait should
1:      * be necessary.  But on machines with lots of load, possibly other
1:      * tests running just sleeping does not guarantee background thread
1:      * an immediate chance to run.  Without this extra wait some nightly's
1:      * were seeing failures, see DERBY-1913.
1:      **/
1:     private void wait_for_max_allocated(
0:     Connection  conn,
1:     String      test_name,
1:     int         alloc_wait_count)
1:         throws SQLException 
1:     {
1:         // an initial 1/10 of second which should work for most environments.
0:         try
1:         {
0:             Thread.sleep(100);
1:         }
0:         catch (Exception ex)
1:         {
0:             // just ignore interupts of sleep.
1:         }
1: 
0:         // get number of allocated pages
0:         int[] sp_info     = getSpaceInfo(conn, "APP", "LONGCOL", true);
0:         int   total_alloc = sp_info[SPACE_INFO_NUM_ALLOC];
0:         int   save_total_alloc = total_alloc;
1: 
1:         // wait for maximum 100 seconds.
1: 
1:         // wait 10 seconds and give up if it has mad no progress.
1:         int max_wait_for_bg_thread = 10000;
1:         int ms_waited              = 100;
1: 
0:         while (total_alloc > alloc_wait_count)
1:         {
1:             if (ms_waited < max_wait_for_bg_thread)
1:             {
1:                 // The result is dependent on background activity which may
1:                 // differ from machine to machine.  Loop, sleeping in this
1:                 // thread to allow background thread to run.
1: 
0:                 try
1:                 {
0:                     ms_waited += 1000;
0:                     Thread.sleep(1000);
1:                 }
0:                 catch (Exception ex)
1:                 {
0:                     // just ignore interupts of sleep.
1:                 }
1: 
0:                 // get number of allocated pages
0:                 sp_info     = getSpaceInfo(conn, "APP", "LONGCOL", true);
0:                 total_alloc = sp_info[SPACE_INFO_NUM_ALLOC];
1: 
1:             }
1:             else if (total_alloc < save_total_alloc)
1:             {
1:                 // background thread did make progress, give it another
1:                 // 10 seconds.
1:                 save_total_alloc = total_alloc;
1:                 max_wait_for_bg_thread += 10000;
1:             }
1:             else
1:             {
1:                 // for the above test case we expect the following space:
1:                 //     page 0
1:                 //     page 1 
1:                 //     free space from 1 blob - 9 pages per blob
1:                 //     allocated page per long/short blob insert.  Each long
1:                 //         inserts onto a new page to try and fit it entirely
1:                 //         on a page.  Then the short blob goes to last inserted
1:                 //         page.  This process repeats.  The previous pages are
1:                 //         marked "half-filled" and can be used in future for
1:                 //         short rows that don't fit on the last page inserted.
1: 
0:                 System.out.println(
1:                     "Test " + test_name + 
1:                     " failed in wait_for_max_allocated(), expected less than " + 
1:                     alloc_wait_count + " allocated pages:\n" +
0:                     "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                     "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC] +
1:                     "\nWaited " + ms_waited + "ms. for background work.");
1: 
0:                 break;
1:             }
1:         }
1:     }
1: 
1: 
commit:d43d4c3
/////////////////////////////////////////////////////////////////////////
0:         int MAX_WAIT_FOR_BG_THREAD = 100000;
0:         int ms_waited              = 20;
1: 
0:         while (total_pages > total_expected_page_max)
0:             if (ms_waited < MAX_WAIT_FOR_BG_THREAD)
1:             {
0:                 // The result is dependent on background activity which may
0:                 // differ from machine to machine.  Loop, sleeping in this
0:                 // thread to allow background thread to run.
0:                 try
1:                 {
0:                     ms_waited += 1000;
0:                     Thread.sleep(1000);
1:                 }
0:                 catch (Exception ex)
1:                 {
0:                     // just ignore interupts of sleep.
1:                 }
0:                 sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
1: 
0:                 total_pages = 
0:                     sp_info[SPACE_INFO_NUM_ALLOC] + 
0:                     sp_info[SPACE_INFO_NUM_FREE];
1:             }
0:             else
1:             {
0:                 // for the above test case we expect the following space:
0:                 //     page 0
0:                 //     page 1 
0:                 //     free space from 1 blob - 9 pages per blob
0:                 //     allocated page per long/short blob insert.  Each long
0:                 //         inserts onto a new page to try and fit it entirely
0:                 //         on a page.  Then the short blob goes to last inserted
0:                 //         page.  This process repeats.  The previous pages are
0:                 //         marked "half-filled" and can be used in future for
0:                 //         short rows that don't fit on the last page inserted.
1: 
0:                 System.out.println(
0:                     "Test 1 failed, expected less than " + 
0:                     total_expected_page_max + " pages - count is:\n" +
0:                     "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                     "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC] +
0:                     "\nWaited " + ms_waited + "ms. for background work.");
1: 
0:                 break;
1:             }
/////////////////////////////////////////////////////////////////////////
0:         int MAX_WAIT_FOR_BG_THREAD = 100000;
0:         int ms_waited              = 20;
1: 
0:         while (total_pages > total_expected_page_max)
0:             if (ms_waited < MAX_WAIT_FOR_BG_THREAD)
1:             {
0:                 // The result is dependent on background activity which may
0:                 // differ from machine to machine.  Loop, sleeping in this
0:                 // thread to allow background thread to run.
1: 
0:                 try
1:                 {
0:                     ms_waited += 1000;
0:                     Thread.sleep(1000);
1:                 }
0:                 catch (Exception ex)
1:                 {
0:                     // just ignore interupts of sleep.
1:                 }
1: 
0:                 sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
1: 
0:                 total_pages = 
0:                     sp_info[SPACE_INFO_NUM_ALLOC] + 
0:                     sp_info[SPACE_INFO_NUM_FREE];
1:             }
0:             else
1:             {
1: 
0:                 System.out.println(
0:                     "Test 2 failed, expected less than " + 
0:                     total_expected_page_max + " pages - count is:\n" +
0:                     "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                     "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC] +
0:                     "\nWaited " + ms_waited + "ms. for background work.");
1: 
0:                 break;
1:             }
commit:7ddacaa
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Derby - Class org.apache.derbyTesting.functionTests.harness.procedure
1: 
0:    Copyright 2005 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
1: 
1:  */
1: 
1: package org.apache.derbyTesting.functionTests.tests.storetests;
1: 
1: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: 
0: import org.apache.derbyTesting.functionTests.tests.store.BaseTest;
1: 
0: import java.sql.CallableStatement;
0: import java.sql.Connection;
1: import java.sql.PreparedStatement;
1: import java.sql.ResultSet;
1: import java.sql.SQLException;
1: import java.sql.Statement;
1: 
1: import java.util.Arrays;
1: 
0: import org.apache.derby.tools.ij;
1: 
1: 
1: /**
1: 
1: The purpose of this test space reclamation of long rows and long columns.
1: This addresses DERBY-670.
1: 
1: The main issue is that previous to fixes for DERBY-670, space reclamation
1: was only automatically queued when the last row on a page was deleted.  In
1: the case of long columns, the actual row on the main page can be quite small
1: as the long data is streamed onto other pages.  So the table can grow 
1: unexpectedly quite large before the default space reclamation kicks in.  The
1: change queues space reclamation in the case of long columns (blob/clob),
0: imediately post commit of the single delete.
1: 
1: The testing strategy is to loop doing insert, delete, commit of a blob for
1: a number of iterations and check that the actual size of the table is 
1: reasonable.  A sleep will be added to allow time for post commit to catch up
1: as the test may be run in a number of environments with varying performance
1: of background activities.
1: 
1: **/
1: 
0: public class st_reclaim_longcol extends BaseTest
0: {
1:     static boolean verbose = false;
1: 
0:     public st_reclaim_longcol()
0:     {
0:     }
1: 
1: 
1:     /**
0:      * Create the base table.
1:      **/
0:     private static void setup()
0:         throws Exception
0:     {
0:     }
1: 
1:     /**
1:      * Test reclaim of a single deleted blob on a page with non-deleted rows.
1:      * <p>
1:      * loops through inserting alternating long and short column rows resulting
1:      * in pages with 1 short and one long.  Deletes the long column row and
1:      * tests that space from the long column row is reclaimed even though
1:      * there are non-deleted rows on the page.
1:      **/
0:     private static final int SHORT_BLOB_SIZE = 10;
0:     public void test1(Connection conn, int blob_size, int num_rows)
1:         throws SQLException
0:     {
1:         byte[]  long_byteVal    = new byte[blob_size];
1:         byte[]  short_byteVal   = new byte[10];
1: 
0:         beginTest(
0:             conn, 
1:             "test1:insert/delete of " + num_rows + 
1:                 " rows with blob(" + blob_size + ")"); 
1: 
1:         Arrays.fill(long_byteVal,  (byte)'L');
1:         Arrays.fill(short_byteVal, (byte)'S');
1: 
0:         createTable(
0:             conn, 
0:             "longcol", 
1:             "create table longcol (id int primary key not null, val blob(" + 
1:             blob_size + "))");
1: 
0:         conn.commit();
1: 
1:         PreparedStatement ins_stmt = 
0:             conn.prepareStatement("insert into longcol values (?, ?)");
1:         PreparedStatement del_stmt = 
0:             conn.prepareStatement("delete from longcol where id = ?");
1: 
1:         // worst case is a mixture of rows with long columns and those without.
1:         // Insert of row with a long column always first goes onto a new 
1:         // page by itself, but subsequent non-long column rows can be inserted
1:         // on that page.  Then when the long column row is deleted - before the
1:         // change - it and all it's chain won't get reclaimed until all rows
1:         // on the page get deleted.
1: 
1:         // now do insert/delete/commit for subsequent rows.  Before fix the
1:         // space used in the table will grow until the deleted rows do not
1:         // fit on the first page.  And even then before the fix the rows
1:         // on the first page are never reclaimed as the 1st one is never
1:         // deleted.
1:         for (int iter = 1; iter < num_rows; iter++)
0:         {
1:             // insert the long blob
1:             ins_stmt.setInt(  1, iter);
1:             ins_stmt.setBytes(2, long_byteVal);
1:             ins_stmt.executeUpdate();
1: 
1:             // insert the short blob
1:             ins_stmt.setInt(  1, -(iter));
1:             ins_stmt.setBytes(2, short_byteVal);
1:             ins_stmt.executeUpdate();
1: 
1:             // delete the long blob
1:             del_stmt.setInt(1, iter);
1:             del_stmt.executeUpdate();
1: 
1:             // commit the xact, post commit should kick in to reclaim the
1:             // blob space sometime after the commit.
0:             conn.commit();
1: 
0:             // sleep, just in case on this machine background
0:             // post commit is slow.
0:             try
0:             {
0:                 Thread.sleep(20);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
1: 
0:         int[] sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
1: 
0:         int total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
1: 
1:         int total_expected_page_max = 12 + num_rows;
1: 
0:         if (total_pages > total_expected_page_max)
0:         {
0:             // for the above test case we expect the following space:
0:             //     page 0
0:             //     page 1 
0:             //     free space from 1 blob - 9 pages per blob
0:             //     allocated page per long/short blob insert.  Each long
0:             //         inserts onto a new page to try and fit it entirely
0:             //         on a page.  Then the short blob goes to last inserted
0:             //         page.  This process repeats.  The previous pages are
0:             //         marked "half-filled" and can be used in future for
0:             //         short rows that don't fit on the last page inserted.
1:             
1: 
1: 
0:             System.out.println(
0:                 "Test failed, expected less than " + 
0:                 total_expected_page_max + " pages - count is:\n" +
0:                 "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                 "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:         }
1: 
0:         if (verbose)
0:         {
0:             System.out.println(
0:                 "Space information after " + num_rows + 
0:                 "insert/delete pairs of rows in longcol table containing " + 
0:                 blob_size + "blobs:");
1: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
1: 
0:         endTest(
0:             conn, 
1:             "test1:insert/delete of " + num_rows + 
1:                 " rows with blob(" + blob_size + ")"); 
0:     }
1: 
1:     /**
0:      * Test reclaim of sequence of deleted blobs.
1:      * <p>
0:      * Simulates a "queue" of work of input "work_size".  Inserts "work_size"
0:      * elements, and then subsequently in each transaction inserts a new 
0:      * work item and deletes the oldest work item.  Checks that the used
0:      * space reaches a steady state, rather than constantly growing.
0:      *
1:      **/
0:     public void test2(
0:     Connection  conn, 
1:     int         blob_size, 
1:     int         work_size, 
1:     int         total_work)
1:         throws SQLException
0:     {
1:         byte[]  long_byteVal    = new byte[blob_size];
1:         byte[]  short_byteVal   = new byte[10];
1: 
0:         beginTest(
0:             conn, 
1:             "test2:queue of " + work_size + 
1:                 " rows with blob(" + blob_size + "), total_work = " + 
1:                 total_work); 
1: 
1:         Arrays.fill(long_byteVal,  (byte)'L');
1:         Arrays.fill(short_byteVal, (byte)'S');
1: 
0:         createTable(
0:             conn, 
0:             "longcol", 
1:             "create table longcol (id int primary key not null, val blob(" + 
1:             blob_size + "))");
1: 
0:         conn.commit();
1: 
1:         PreparedStatement ins_stmt = 
0:             conn.prepareStatement("insert into longcol values (?, ?)");
1:         PreparedStatement del_stmt = 
0:             conn.prepareStatement("delete from longcol where id = ?");
1: 
1:         // insert the "work_size" number of elements into the table
1:         for (int iter = 0; iter < work_size; iter++)
0:         {
1:             // insert the long blob
1:             ins_stmt.setInt(  1, iter);
1:             ins_stmt.setBytes(2, long_byteVal);
1:             ins_stmt.executeUpdate();
1: 
1:             // commit the xact, post commit should kick in to reclaim the
1:             // blob space sometime after the commit.
0:         }
0:         conn.commit();
1: 
1: 
1:         // for each subsequent work item, queue it to the end and delete
0:         // the oldes existing work item.
1:         for (int iter = work_size; iter < total_work; iter++)
0:         {
1:             // insert the long blob
1:             ins_stmt.setInt(  1, iter);
1:             ins_stmt.setBytes(2, long_byteVal);
1:             ins_stmt.executeUpdate();
1: 
1: 
1:             // delete the long blob
0:             del_stmt.setInt(1, iter - work_size - 1);
1:             del_stmt.executeUpdate();
1: 
1:             // commit the xact, post commit should kick in to reclaim the
1:             // blob space sometime after the commit.
0:             conn.commit();
1: 
0:             try
0:             {
0:                 Thread.sleep(20);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
1: 
1: 
0:         int[] sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
1: 
0:         int total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
1: 
1:         // Expect at least allocated pages * 10 for each item in work_size, 
1:         // plus some overhead for 1st page and such.
1:         // Free page count depends on how quick post commit can free before
1:         // subsequent insert, and very likely is machine/jvm/os dependent. In
1:         // my testing adding a sleep of 100 ms. to the above insert/delete
1:         // loop changed free from 60 to 30.  Minimum is 10 for the one row 
1:         // that is deleted in the same xact as the first inserted row in the 
1:         // insert/delete loop.  The 30 below is expected allocate of 10
1:         // per work size, and then a guess at how fast post commit can keep
1:         // up with free pages.  Run the test with total_work reasonably 
1:         // bigger than worksize, something like work_size=5 and total_work >100
0:         int total_expected_page_max = 30 * work_size; 
1: 
0:         if (total_pages > total_expected_page_max)
0:         {
0:             System.out.println(
0:                 "Test failed, expected less than " + 
0:                 total_expected_page_max + " pages - count is:\n" +
0:                 "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                 "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:         }
1: 
0:         if (verbose)
0:         {
0:             System.out.println("Space information:");
1: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
1: 
1:         // Run another iteration of the work loop, by now memory should 
1:         // have gotten to constant.
0:         for (int iter = work_size + total_work; iter < (total_work * 2); iter++)
0:         {
1:             // insert the long blob
1:             ins_stmt.setInt(  1, iter);
1:             ins_stmt.setBytes(2, long_byteVal);
1:             ins_stmt.executeUpdate();
1: 
1: 
1:             // delete the long blob
0:             del_stmt.setInt(1, iter - work_size - 1);
1:             del_stmt.executeUpdate();
1: 
1:             // commit the xact, post commit should kick in to reclaim the
1:             // blob space sometime after the commit.
0:             conn.commit();
1: 
0:             try
0:             {
0:                 Thread.sleep(100);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
1: 
1: 
0:         int[] second_sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
1: 
0:         int second_total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
1: 
1:         if (total_pages != second_total_pages)
0:         {
0:             System.out.println(
0:                 "Test failed, expected constant memory after second run." +
1:                 "initial total = " + total_pages +
1:                 "second total = " + second_total_pages);
0:         }
1: 
0:         if (verbose)
0:         {
0:             System.out.println("Space information:");
1: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
1: 
0:         endTest(
0:             conn, 
1:             "test2:queue of " + work_size + 
1:                 " rows with blob(" + blob_size + "), total_work = " + 
1:                 total_work); 
0:     }
1: 
1: 
0:     public void testList(Connection conn)
1:         throws SQLException
0:     {
0:         test1(conn, 250000, 20);
0:         test2(conn, 250000, 5, 500);
0:     }
1: 
0:     public static void main(String[] argv) 
0:         throws Throwable
0:     {
0:         st_reclaim_longcol test = new st_reclaim_longcol();
1: 
0:         ij.getPropertyArg(argv); 
0:         Connection conn = ij.startJBMS();
1: 
0:         try
0:         {
0:             test.testList(conn);
0:         }
0:         catch (SQLException sqle)
0:         {
0: 			org.apache.derby.tools.JDBCDisplayUtil.ShowSQLException(
0:                 System.out, sqle);
0: 			sqle.printStackTrace(System.out);
0: 		}
0:     }
0: }
commit:0ce6b77
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Derby - Class org.apache.derbyTesting.functionTests.harness.procedure
0: 
0:    Copyright 2005 The Apache Software Foundation or its licensors, as applicable.
0: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
0: 
0:       http://www.apache.org/licenses/LICENSE-2.0
0: 
0:    Unless required by applicable law or agreed to in writing, software
0:    distributed under the License is distributed on an "AS IS" BASIS,
0:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:    See the License for the specific language governing permissions and
0:    limitations under the License.
0: 
0:  */
0: 
0: package org.apache.derbyTesting.functionTests.tests.storetests;
0: 
0: 
0: import org.apache.derby.iapi.services.sanity.SanityManager;
0: 
0: import org.apache.derbyTesting.functionTests.tests.store.BaseTest;
0: 
0: import java.sql.CallableStatement;
0: import java.sql.Connection;
0: import java.sql.PreparedStatement;
0: import java.sql.ResultSet;
0: import java.sql.SQLException;
0: import java.sql.Statement;
0: 
0: import java.util.Arrays;
0: 
0: import org.apache.derby.tools.ij;
0: 
0: 
0: /**
0: 
0: The purpose of this test space reclamation of long rows and long columns.
0: This addresses DERBY-670.
0: 
0: The main issue is that previous to fixes for DERBY-670, space reclamation
0: was only automatically queued when the last row on a page was deleted.  In
0: the case of long columns, the actual row on the main page can be quite small
0: as the long data is streamed onto other pages.  So the table can grow 
0: unexpectedly quite large before the default space reclamation kicks in.  The
0: change queues space reclamation in the case of long columns (blob/clob),
0: imediately post commit of the single delete.
0: 
0: The testing strategy is to loop doing insert, delete, commit of a blob for
0: a number of iterations and check that the actual size of the table is 
0: reasonable.  A sleep will be added to allow time for post commit to catch up
0: as the test may be run in a number of environments with varying performance
0: of background activities.
0: 
0: **/
0: 
0: public class st_reclaim_longcol extends BaseTest
0: {
0:     static boolean verbose = false;
0: 
0:     public st_reclaim_longcol()
0:     {
0:     }
0: 
0: 
0:     /**
0:      * Create the base table.
0:      **/
0:     private static void setup()
0:         throws Exception
0:     {
0:     }
0: 
0:     /**
0:      * Test reclaim of a single deleted blob on a page with non-deleted rows.
0:      * <p>
0:      * loops through inserting alternating long and short column rows resulting
0:      * in pages with 1 short and one long.  Deletes the long column row and
0:      * tests that space from the long column row is reclaimed even though
0:      * there are non-deleted rows on the page.
0:      **/
0:     private static final int SHORT_BLOB_SIZE = 10;
0:     public void test1(Connection conn, int blob_size, int num_rows)
0:         throws SQLException
0:     {
0:         byte[]  long_byteVal    = new byte[blob_size];
0:         byte[]  short_byteVal   = new byte[10];
0: 
0:         beginTest(
0:             conn, 
0:             "test1:insert/delete of " + num_rows + 
0:                 " rows with blob(" + blob_size + ")"); 
0: 
0:         Arrays.fill(long_byteVal,  (byte)'L');
0:         Arrays.fill(short_byteVal, (byte)'S');
0: 
0:         createTable(
0:             conn, 
0:             "longcol", 
0:             "create table longcol (id int primary key not null, val blob(" + 
0:             blob_size + "))");
0: 
0:         conn.commit();
0: 
0:         PreparedStatement ins_stmt = 
0:             conn.prepareStatement("insert into longcol values (?, ?)");
0:         PreparedStatement del_stmt = 
0:             conn.prepareStatement("delete from longcol where id = ?");
0: 
0:         // worst case is a mixture of rows with long columns and those without.
0:         // Insert of row with a long column always first goes onto a new 
0:         // page by itself, but subsequent non-long column rows can be inserted
0:         // on that page.  Then when the long column row is deleted - before the
0:         // change - it and all it's chain won't get reclaimed until all rows
0:         // on the page get deleted.
0: 
0:         // now do insert/delete/commit for subsequent rows.  Before fix the
0:         // space used in the table will grow until the deleted rows do not
0:         // fit on the first page.  And even then before the fix the rows
0:         // on the first page are never reclaimed as the 1st one is never
0:         // deleted.
0:         for (int iter = 1; iter < num_rows; iter++)
0:         {
0:             // insert the long blob
0:             ins_stmt.setInt(  1, iter);
0:             ins_stmt.setBytes(2, long_byteVal);
0:             ins_stmt.executeUpdate();
0: 
0:             // insert the short blob
0:             ins_stmt.setInt(  1, -(iter));
0:             ins_stmt.setBytes(2, short_byteVal);
0:             ins_stmt.executeUpdate();
0: 
0:             // delete the long blob
0:             del_stmt.setInt(1, iter);
0:             del_stmt.executeUpdate();
0: 
0:             // commit the xact, post commit should kick in to reclaim the
0:             // blob space sometime after the commit.
0:             conn.commit();
0: 
0:             // sleep, just in case on this machine background
0:             // post commit is slow.
0:             try
0:             {
0:                 Thread.sleep(20);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
0: 
0:         int[] sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
0: 
0:         int total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
0: 
0:         int total_expected_page_max = 12 + num_rows;
0: 
0:         if (total_pages > total_expected_page_max)
0:         {
0:             // for the above test case we expect the following space:
0:             //     page 0
0:             //     page 1 
0:             //     free space from 1 blob - 9 pages per blob
0:             //     allocated page per long/short blob insert.  Each long
0:             //         inserts onto a new page to try and fit it entirely
0:             //         on a page.  Then the short blob goes to last inserted
0:             //         page.  This process repeats.  The previous pages are
0:             //         marked "half-filled" and can be used in future for
0:             //         short rows that don't fit on the last page inserted.
0:             
0: 
0: 
0:             System.out.println(
0:                 "Test failed, expected less than " + 
0:                 total_expected_page_max + " pages - count is:\n" +
0:                 "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                 "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:         }
0: 
0:         if (verbose)
0:         {
0:             System.out.println(
0:                 "Space information after " + num_rows + 
0:                 "insert/delete pairs of rows in longcol table containing " + 
0:                 blob_size + "blobs:");
0: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
0: 
0:         endTest(
0:             conn, 
0:             "test1:insert/delete of " + num_rows + 
0:                 " rows with blob(" + blob_size + ")"); 
0:     }
0: 
0:     /**
0:      * Test reclaim of sequence of deleted blobs.
0:      * <p>
0:      * Simulates a "queue" of work of input "work_size".  Inserts "work_size"
0:      * elements, and then subsequently in each transaction inserts a new 
0:      * work item and deletes the oldest work item.  Checks that the used
0:      * space reaches a steady state, rather than constantly growing.
0:      *
0:      **/
0:     public void test2(
0:     Connection  conn, 
0:     int         blob_size, 
0:     int         work_size, 
0:     int         total_work)
0:         throws SQLException
0:     {
0:         byte[]  long_byteVal    = new byte[blob_size];
0:         byte[]  short_byteVal   = new byte[10];
0: 
0:         beginTest(
0:             conn, 
0:             "test2:queue of " + work_size + 
0:                 " rows with blob(" + blob_size + "), total_work = " + 
0:                 total_work); 
0: 
0:         Arrays.fill(long_byteVal,  (byte)'L');
0:         Arrays.fill(short_byteVal, (byte)'S');
0: 
0:         createTable(
0:             conn, 
0:             "longcol", 
0:             "create table longcol (id int primary key not null, val blob(" + 
0:             blob_size + "))");
0: 
0:         conn.commit();
0: 
0:         PreparedStatement ins_stmt = 
0:             conn.prepareStatement("insert into longcol values (?, ?)");
0:         PreparedStatement del_stmt = 
0:             conn.prepareStatement("delete from longcol where id = ?");
0: 
0:         // insert the "work_size" number of elements into the table
0:         for (int iter = 0; iter < work_size; iter++)
0:         {
0:             // insert the long blob
0:             ins_stmt.setInt(  1, iter);
0:             ins_stmt.setBytes(2, long_byteVal);
0:             ins_stmt.executeUpdate();
0: 
0:             // commit the xact, post commit should kick in to reclaim the
0:             // blob space sometime after the commit.
0:         }
0:         conn.commit();
0: 
0: 
0:         // for each subsequent work item, queue it to the end and delete
0:         // the oldes existing work item.
0:         for (int iter = work_size; iter < total_work; iter++)
0:         {
0:             // insert the long blob
0:             ins_stmt.setInt(  1, iter);
0:             ins_stmt.setBytes(2, long_byteVal);
0:             ins_stmt.executeUpdate();
0: 
0: 
0:             // delete the long blob
0:             del_stmt.setInt(1, iter - work_size - 1);
0:             del_stmt.executeUpdate();
0: 
0:             // commit the xact, post commit should kick in to reclaim the
0:             // blob space sometime after the commit.
0:             conn.commit();
0: 
0:             try
0:             {
0:                 Thread.sleep(20);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
0: 
0: 
0:         int[] sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
0: 
0:         int total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
0: 
0:         // Expect at least allocated pages * 10 for each item in work_size, 
0:         // plus some overhead for 1st page and such.
0:         // Free page count depends on how quick post commit can free before
0:         // subsequent insert, and very likely is machine/jvm/os dependent. In
0:         // my testing adding a sleep of 100 ms. to the above insert/delete
0:         // loop changed free from 60 to 30.  Minimum is 10 for the one row 
0:         // that is deleted in the same xact as the first inserted row in the 
0:         // insert/delete loop.  The 30 below is expected allocate of 10
0:         // per work size, and then a guess at how fast post commit can keep
0:         // up with free pages.  Run the test with total_work reasonably 
0:         // bigger than worksize, something like work_size=5 and total_work >100
0:         int total_expected_page_max = 30 * work_size; 
0: 
0:         if (total_pages > total_expected_page_max)
0:         {
0:             System.out.println(
0:                 "Test failed, expected less than " + 
0:                 total_expected_page_max + " pages - count is:\n" +
0:                 "free pages     : "   + sp_info[SPACE_INFO_NUM_FREE] +
0:                 "\nallocated pages: " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:         }
0: 
0:         if (verbose)
0:         {
0:             System.out.println("Space information:");
0: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
0: 
0:         // Run another iteration of the work loop, by now memory should 
0:         // have gotten to constant.
0:         for (int iter = work_size + total_work; iter < (total_work * 2); iter++)
0:         {
0:             // insert the long blob
0:             ins_stmt.setInt(  1, iter);
0:             ins_stmt.setBytes(2, long_byteVal);
0:             ins_stmt.executeUpdate();
0: 
0: 
0:             // delete the long blob
0:             del_stmt.setInt(1, iter - work_size - 1);
0:             del_stmt.executeUpdate();
0: 
0:             // commit the xact, post commit should kick in to reclaim the
0:             // blob space sometime after the commit.
0:             conn.commit();
0: 
0:             try
0:             {
0:                 Thread.sleep(100);
0:             }
0:             catch (Exception ex)
0:             {
0:                 // just ignore interupts of sleep.
0:             }
0:         }
0: 
0: 
0:         int[] second_sp_info = getSpaceInfo(conn, "APP", "LONGCOL", true);
0: 
0:         int second_total_pages = 
0:             sp_info[SPACE_INFO_NUM_ALLOC] + sp_info[SPACE_INFO_NUM_FREE];
0: 
0:         if (total_pages != second_total_pages)
0:         {
0:             System.out.println(
0:                 "Test failed, expected constant memory after second run." +
0:                 "initial total = " + total_pages +
0:                 "second total = " + second_total_pages);
0:         }
0: 
0:         if (verbose)
0:         {
0:             System.out.println("Space information:");
0: 
0:             System.out.println("isindex = "   + sp_info[SPACE_INFO_IS_INDEX]);
0:             System.out.println("num_alloc = " + sp_info[SPACE_INFO_NUM_ALLOC]);
0:             System.out.println("num_free = "  + sp_info[SPACE_INFO_NUM_FREE]);
0:             System.out.println("page_size = " + sp_info[SPACE_INFO_PAGE_SIZE]);
0:             System.out.println(
0:                 "estimspacesaving = " + sp_info[SPACE_INFO_ESTIMSPACESAVING]);
0:         }
0: 
0:         endTest(
0:             conn, 
0:             "test2:queue of " + work_size + 
0:                 " rows with blob(" + blob_size + "), total_work = " + 
0:                 total_work); 
0:     }
0: 
0: 
0:     public void testList(Connection conn)
0:         throws SQLException
0:     {
0:         test1(conn, 250000, 20);
0:         test2(conn, 250000, 5, 500);
0:     }
0: 
0:     public static void main(String[] argv) 
0:         throws Throwable
0:     {
0:         st_reclaim_longcol test = new st_reclaim_longcol();
0: 
0:         ij.getPropertyArg(argv); 
0:         Connection conn = ij.startJBMS();
0: 
0:         try
0:         {
0:             test.testList(conn);
0:         }
0:         catch (SQLException sqle)
0:         {
0: 			org.apache.derby.tools.JDBCDisplayUtil.ShowSQLException(
0:                 System.out, sqle);
0: 			sqle.printStackTrace(System.out);
0: 		}
0:     }
0: }
author:Samuel Andrew McIntyre
-------------------------------------------------------------------------------
commit:dff95a1
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to You under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
============================================================================
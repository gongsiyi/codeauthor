1:a700f83: /*
1:a700f83:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:a700f83:  * contributor license agreements.  See the NOTICE file distributed with
1:a700f83:  * this work for additional information regarding copyright ownership.
1:a700f83:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:a700f83:  * (the "License"); you may not use this file except in compliance with
1:a700f83:  * the License.  You may obtain a copy of the License at
1:a700f83:  *
1:a700f83:  *    http://www.apache.org/licenses/LICENSE-2.0
1:a700f83:  *
1:a700f83:  * Unless required by applicable law or agreed to in writing, software
1:a700f83:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a700f83:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a700f83:  * See the License for the specific language governing permissions and
1:a700f83:  * limitations under the License.
1:a700f83:  */
1:a700f83: package org.apache.carbondata.hive;
1:a700f83: 
1:a700f83: import java.io.DataInput;
1:a700f83: import java.io.DataOutput;
1:a700f83: import java.io.IOException;
1:a700f83: import java.io.Serializable;
1:a700f83: import java.util.ArrayList;
1:a700f83: import java.util.HashMap;
1:a700f83: import java.util.List;
1:a700f83: import java.util.Map;
1:a700f83: 
1:a700f83: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:a700f83: import org.apache.carbondata.core.datastore.block.BlockletInfos;
1:a700f83: import org.apache.carbondata.core.datastore.block.Distributable;
1:a700f83: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:a700f83: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1:a700f83: import org.apache.carbondata.core.mutate.UpdateVO;
1:a700f83: import org.apache.carbondata.core.util.CarbonProperties;
1:a700f83: import org.apache.carbondata.core.util.path.CarbonTablePath;
1:a700f83: import org.apache.carbondata.hadoop.internal.index.Block;
1:a700f83: 
1:a700f83: import org.apache.hadoop.fs.Path;
1:a700f83: import org.apache.hadoop.io.Writable;
1:a700f83: import org.apache.hadoop.mapred.FileSplit;
1:a700f83: 
1:a700f83: public class CarbonHiveInputSplit extends FileSplit
1:a700f83:     implements Distributable, Serializable, Writable, Block {
1:a700f83: 
1:a700f83:   private static final long serialVersionUID = 3520344046772190208L;
1:a700f83:   private String taskId;
1:a700f83: 
1:a700f83:   private String segmentId;
1:a700f83: 
1:a700f83:   private String bucketId;
1:a700f83:   /*
1:a700f83:    * Invalid segments that need to be removed in task side index
1:a700f83:    */
1:a700f83:   private List<String> invalidSegments;
1:a700f83: 
1:a700f83:   /*
1:a700f83:    * Number of BlockLets in a block
1:a700f83:    */
1:a700f83:   private int numberOfBlocklets;
1:a700f83: 
1:a700f83:   private ColumnarFormatVersion version;
1:a700f83: 
1:a700f83:   /**
1:a700f83:    * map of blocklocation and storage id
1:a700f83:    */
1:a700f83:   private Map<String, String> blockStorageIdMap =
1:a700f83:       new HashMap<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:a700f83: 
1:a700f83:   private List<UpdateVO> invalidTimestampsList;
1:a700f83: 
1:a700f83:   public CarbonHiveInputSplit() {
1:a700f83:     segmentId = null;
1:a700f83:     taskId = "0";
1:a700f83:     bucketId = "0";
1:a700f83:     numberOfBlocklets = 0;
1:a700f83:     invalidSegments = new ArrayList<>();
1:a700f83:     version = CarbonProperties.getInstance().getFormatVersion();
2:a700f83:   }
1:a700f83: 
1:a700f83:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:a700f83:       String[] locations, ColumnarFormatVersion version) {
1:a700f83:     super(path, start, length, locations);
1:a700f83:     this.segmentId = segmentId;
1:a700f83:     this.taskId = CarbonTablePath.DataFileUtil.getTaskNo(path.getName());
1:a700f83:     this.bucketId = CarbonTablePath.DataFileUtil.getBucketNo(path.getName());
1:a700f83:     this.invalidSegments = new ArrayList<>();
1:a700f83:     this.version = version;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:a700f83:       String[] locations, int numberOfBlocklets, ColumnarFormatVersion version) {
1:a700f83:     this(segmentId, path, start, length, locations, version);
1:a700f83:     this.numberOfBlocklets = numberOfBlocklets;
1:a700f83:   }
1:a700f83: 
1:a700f83:   /**
1:a700f83:    * Constructor to initialize the CarbonInputSplit with blockStorageIdMap
1:a700f83:    *
1:a700f83:    * @param segmentId
1:a700f83:    * @param path
1:a700f83:    * @param start
1:a700f83:    * @param length
1:a700f83:    * @param locations
1:a700f83:    * @param numberOfBlocklets
1:a700f83:    * @param version
1:a700f83:    * @param blockStorageIdMap
1:a700f83:    */
1:a700f83:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:a700f83:       String[] locations, int numberOfBlocklets, ColumnarFormatVersion version,
1:a700f83:       Map<String, String> blockStorageIdMap) {
1:a700f83:     this(segmentId, path, start, length, locations, numberOfBlocklets, version);
1:a700f83:     this.blockStorageIdMap = blockStorageIdMap;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public static CarbonHiveInputSplit from(String segmentId, FileSplit split,
1:cbe1419:       ColumnarFormatVersion version) throws IOException {
1:a700f83:     return new CarbonHiveInputSplit(segmentId, split.getPath(), split.getStart(), split.getLength(),
1:d408a8d:         split.getLocations(), version);
1:a700f83:   }
1:a700f83: 
1:a700f83:   public static List<TableBlockInfo> createBlocks(List<CarbonHiveInputSplit> splitList) {
1:a700f83:     List<TableBlockInfo> tableBlockInfoList = new ArrayList<>();
1:a700f83:     for (CarbonHiveInputSplit split : splitList) {
1:a700f83:       BlockletInfos blockletInfos =
1:a700f83:           new BlockletInfos(split.getNumberOfBlocklets(), 0, split.getNumberOfBlocklets());
1:a700f83:       try {
1:a700f83:         tableBlockInfoList.add(
1:a700f83:             new TableBlockInfo(split.getPath().toString(), split.getStart(), split.getSegmentId(),
1:d408a8d:                 split.getLocations(), split.getLength(), blockletInfos, split.getVersion(), null));
1:a700f83:       } catch (IOException e) {
1:a700f83:         throw new RuntimeException("fail to get location of split: " + split, e);
1:a700f83:       }
1:a700f83:     }
1:a700f83:     return tableBlockInfoList;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public static TableBlockInfo getTableBlockInfo(CarbonHiveInputSplit inputSplit) {
1:a700f83:     BlockletInfos blockletInfos =
1:a700f83:         new BlockletInfos(inputSplit.getNumberOfBlocklets(), 0, inputSplit.getNumberOfBlocklets());
1:a700f83:     try {
1:a700f83:       return new TableBlockInfo(inputSplit.getPath().toString(), inputSplit.getStart(),
1:d408a8d:           inputSplit.getSegmentId(), inputSplit.getLocations(), inputSplit.getLength(),
1:d408a8d:           blockletInfos, inputSplit.getVersion(), null);
1:a700f83:     } catch (IOException e) {
1:a700f83:       throw new RuntimeException("fail to get location of split: " + inputSplit, e);
1:a700f83:     }
1:a700f83:   }
1:a700f83: 
1:a700f83:   public String getSegmentId() {
1:a700f83:     return segmentId;
1:a700f83:   }
1:a700f83: 
1:cbe1419:   @Override public void readFields(DataInput in) throws IOException {
1:a700f83:     super.readFields(in);
1:a700f83:     this.segmentId = in.readUTF();
1:a700f83:     this.version = ColumnarFormatVersion.valueOf(in.readShort());
1:a700f83:     this.bucketId = in.readUTF();
1:a700f83:     int numInvalidSegment = in.readInt();
1:a700f83:     invalidSegments = new ArrayList<>(numInvalidSegment);
1:a700f83:     for (int i = 0; i < numInvalidSegment; i++) {
1:a700f83:       invalidSegments.add(in.readUTF());
1:a700f83:     }
1:cbe1419:     this.numberOfBlocklets = in.readInt();
1:a700f83:   }
1:a700f83: 
1:cbe1419:   @Override public void write(DataOutput out) throws IOException {
1:a700f83:     super.write(out);
1:a700f83:     out.writeUTF(segmentId);
1:a700f83:     out.writeShort(version.number());
1:a700f83:     out.writeUTF(bucketId);
1:a700f83:     out.writeInt(invalidSegments.size());
1:a700f83:     for (String invalidSegment : invalidSegments) {
1:a700f83:       out.writeUTF(invalidSegment);
1:a700f83:     }
1:cbe1419:     out.writeInt(numberOfBlocklets);
1:a700f83:   }
1:a700f83: 
1:a700f83:   public List<String> getInvalidSegments() {
1:a700f83:     return invalidSegments;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public void setInvalidSegments(List<String> invalidSegments) {
1:a700f83:     this.invalidSegments = invalidSegments;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public void setInvalidTimestampRange(List<UpdateVO> invalidTimestamps) {
1:a700f83:     invalidTimestampsList = invalidTimestamps;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public List<UpdateVO> getInvalidTimestampRange() {
1:a700f83:     return invalidTimestampsList;
1:a700f83:   }
1:a700f83: 
1:a700f83:   /**
1:a700f83:    * returns the number of blocklets
1:a700f83:    *
1:a700f83:    * @return
1:a700f83:    */
1:a700f83:   public int getNumberOfBlocklets() {
1:a700f83:     return numberOfBlocklets;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public ColumnarFormatVersion getVersion() {
1:a700f83:     return version;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public void setVersion(ColumnarFormatVersion version) {
1:a700f83:     this.version = version;
1:a700f83:   }
1:a700f83: 
1:a700f83:   public String getBucketId() {
1:a700f83:     return bucketId;
1:a700f83:   }
1:a700f83: 
1:cbe1419:   @Override public int compareTo(Distributable o) {
1:a700f83:     if (o == null) {
1:a700f83:       return -1;
1:a700f83:     }
1:a700f83:     CarbonHiveInputSplit other = (CarbonHiveInputSplit) o;
1:d408a8d:     int compareResult;
1:a700f83:     // get the segment id
1:a700f83:     // converr seg ID to double.
1:a700f83: 
1:a700f83:     double seg1 = Double.parseDouble(segmentId);
1:a700f83:     double seg2 = Double.parseDouble(other.getSegmentId());
1:2d24e18:     if (Double.compare(seg1, seg2) < 0) {
1:a700f83:       return -1;
1:a700f83:     }
1:2d24e18:     if (Double.compare(seg1, seg2) > 0) {
1:a700f83:       return 1;
1:a700f83:     }
1:a700f83: 
1:a700f83:     // Comparing the time task id of the file to other
1:a700f83:     // if both the task id of the file is same then we need to compare the
1:a700f83:     // offset of
1:a700f83:     // the file
1:a700f83:     String filePath1 = this.getPath().getName();
1:a700f83:     String filePath2 = other.getPath().getName();
1:a700f83:     if (CarbonTablePath.isCarbonDataFile(filePath1)) {
1:a700f83:       int firstTaskId = Integer.parseInt(CarbonTablePath.DataFileUtil.getTaskNo(filePath1));
1:a700f83:       int otherTaskId = Integer.parseInt(CarbonTablePath.DataFileUtil.getTaskNo(filePath2));
1:a700f83:       if (firstTaskId != otherTaskId) {
1:a700f83:         return firstTaskId - otherTaskId;
1:a700f83:       }
1:a700f83: 
1:a700f83:       int firstBucketNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getBucketNo(filePath1));
1:a700f83:       int otherBucketNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getBucketNo(filePath2));
1:a700f83:       if (firstBucketNo != otherBucketNo) {
1:a700f83:         return firstBucketNo - otherBucketNo;
1:a700f83:       }
1:a700f83: 
1:a700f83:       // compare the part no of both block info
1:a700f83:       int firstPartNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(filePath1));
1:a700f83:       int SecondPartNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(filePath2));
1:a700f83:       compareResult = firstPartNo - SecondPartNo;
1:a700f83:     } else {
1:a700f83:       compareResult = filePath1.compareTo(filePath2);
1:a700f83:     }
1:a700f83:     if (compareResult != 0) {
1:a700f83:       return compareResult;
1:a700f83:     }
1:a700f83:     return 0;
1:a700f83:   }
1:a700f83: 
1:2d24e18:   @Override public boolean equals(Object obj) {
1:2d24e18:     if (this == obj) {
1:2d24e18:       return true;
1:2d24e18:     }
1:2d24e18: 
1:2d24e18:     if (!(obj instanceof CarbonHiveInputSplit)) {
1:2d24e18:       return false;
1:2d24e18:     }
1:2d24e18: 
1:2d24e18:     CarbonHiveInputSplit other = (CarbonHiveInputSplit) obj;
1:2d24e18:     return 0 == this.compareTo(other);
1:2d24e18:   }
1:2d24e18: 
1:2d24e18:   @Override public int hashCode() {
1:2d24e18:     int result = taskId.hashCode();
1:2d24e18:     result = 31 * result + segmentId.hashCode();
1:2d24e18:     result = 31 * result + bucketId.hashCode();
1:2d24e18:     result = 31 * result + invalidSegments.hashCode();
1:2d24e18:     result = 31 * result + numberOfBlocklets;
1:2d24e18:     return result;
1:2d24e18:   }
1:2d24e18: 
1:cbe1419:   @Override public String getBlockPath() {
1:a700f83:     return getPath().getName();
1:a700f83:   }
1:a700f83: 
1:cbe1419:   @Override public List<Long> getMatchedBlocklets() {
1:a700f83:     return null;
1:a700f83:   }
1:a700f83: 
1:cbe1419:   @Override public boolean fullScan() {
1:a700f83:     return true;
1:a700f83:   }
1:a700f83: 
1:a700f83:   /**
1:a700f83:    * returns map of blocklocation and storage id
1:a700f83:    *
1:a700f83:    * @return
1:a700f83:    */
1:a700f83:   public Map<String, String> getBlockStorageIdMap() {
1:a700f83:     return blockStorageIdMap;
1:d408a8d:   }
1:a700f83: }
============================================================================
author:Raghunandan S
-------------------------------------------------------------------------------
commit:2d24e18
/////////////////////////////////////////////////////////////////////////
1:     if (Double.compare(seg1, seg2) < 0) {
1:     if (Double.compare(seg1, seg2) > 0) {
/////////////////////////////////////////////////////////////////////////
1:   @Override public boolean equals(Object obj) {
1:     if (this == obj) {
1:       return true;
1:     }
1: 
1:     if (!(obj instanceof CarbonHiveInputSplit)) {
1:       return false;
1:     }
1: 
1:     CarbonHiveInputSplit other = (CarbonHiveInputSplit) obj;
1:     return 0 == this.compareTo(other);
1:   }
1: 
1:   @Override public int hashCode() {
1:     int result = taskId.hashCode();
1:     result = 31 * result + segmentId.hashCode();
1:     result = 31 * result + bucketId.hashCode();
1:     result = 31 * result + invalidSegments.hashCode();
1:     result = 31 * result + numberOfBlocklets;
1:     return result;
1:   }
1: 
author:Bhavya
-------------------------------------------------------------------------------
commit:cbe1419
/////////////////////////////////////////////////////////////////////////
1:       ColumnarFormatVersion version) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:   @Override public void readFields(DataInput in) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     this.numberOfBlocklets = in.readInt();
1:   @Override public void write(DataOutput out) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     out.writeInt(numberOfBlocklets);
/////////////////////////////////////////////////////////////////////////
1:   @Override public int compareTo(Distributable o) {
/////////////////////////////////////////////////////////////////////////
1:   @Override public String getBlockPath() {
1:   @Override public List<Long> getMatchedBlocklets() {
1:   @Override public boolean fullScan() {
author:chenliang613
-------------------------------------------------------------------------------
commit:d408a8d
/////////////////////////////////////////////////////////////////////////
0:       ColumnarFormatVersion version)
0:       throws IOException {
1:         split.getLocations(), version);
/////////////////////////////////////////////////////////////////////////
1:                 split.getLocations(), split.getLength(), blockletInfos, split.getVersion(), null));
/////////////////////////////////////////////////////////////////////////
1:           inputSplit.getSegmentId(), inputSplit.getLocations(), inputSplit.getLength(),
1:           blockletInfos, inputSplit.getVersion(), null);
/////////////////////////////////////////////////////////////////////////
1:     int compareResult;
/////////////////////////////////////////////////////////////////////////
1: }
author:kumarvishal
-------------------------------------------------------------------------------
commit:8a5ed81
/////////////////////////////////////////////////////////////////////////
0:             split.getLocations(), split.getLength(), blockletInfos, split.getVersion(), null));
/////////////////////////////////////////////////////////////////////////
0:         blockletInfos, inputSplit.getVersion(), null);
author:cenyuhai
-------------------------------------------------------------------------------
commit:a700f83
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.hive;
1: 
1: import java.io.DataInput;
1: import java.io.DataOutput;
1: import java.io.IOException;
1: import java.io.Serializable;
1: import java.util.ArrayList;
1: import java.util.HashMap;
1: import java.util.List;
1: import java.util.Map;
1: 
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.datastore.block.BlockletInfos;
1: import org.apache.carbondata.core.datastore.block.Distributable;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1: import org.apache.carbondata.core.mutate.UpdateVO;
1: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.path.CarbonTablePath;
1: import org.apache.carbondata.hadoop.internal.index.Block;
1: 
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Writable;
1: import org.apache.hadoop.mapred.FileSplit;
1: 
1: public class CarbonHiveInputSplit extends FileSplit
1:     implements Distributable, Serializable, Writable, Block {
1: 
1:   private static final long serialVersionUID = 3520344046772190208L;
1:   private String taskId;
1: 
1:   private String segmentId;
1: 
1:   private String bucketId;
1:   /*
1:    * Invalid segments that need to be removed in task side index
1:    */
1:   private List<String> invalidSegments;
1: 
1:   /*
1:    * Number of BlockLets in a block
1:    */
1:   private int numberOfBlocklets;
1: 
1:   private ColumnarFormatVersion version;
1: 
1:   /**
1:    * map of blocklocation and storage id
1:    */
1:   private Map<String, String> blockStorageIdMap =
1:       new HashMap<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1: 
1:   private List<UpdateVO> invalidTimestampsList;
1: 
1:   public CarbonHiveInputSplit() {
1:     segmentId = null;
1:     taskId = "0";
1:     bucketId = "0";
1:     numberOfBlocklets = 0;
1:     invalidSegments = new ArrayList<>();
1:     version = CarbonProperties.getInstance().getFormatVersion();
1:   }
1: 
1:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:       String[] locations, ColumnarFormatVersion version) {
1:     super(path, start, length, locations);
1:     this.segmentId = segmentId;
1:     this.taskId = CarbonTablePath.DataFileUtil.getTaskNo(path.getName());
1:     this.bucketId = CarbonTablePath.DataFileUtil.getBucketNo(path.getName());
1:     this.invalidSegments = new ArrayList<>();
1:     this.version = version;
1:   }
1: 
1:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:       String[] locations, int numberOfBlocklets, ColumnarFormatVersion version) {
1:     this(segmentId, path, start, length, locations, version);
1:     this.numberOfBlocklets = numberOfBlocklets;
1:   }
1: 
1:   /**
1:    * Constructor to initialize the CarbonInputSplit with blockStorageIdMap
1:    *
1:    * @param segmentId
1:    * @param path
1:    * @param start
1:    * @param length
1:    * @param locations
1:    * @param numberOfBlocklets
1:    * @param version
1:    * @param blockStorageIdMap
1:    */
1:   public CarbonHiveInputSplit(String segmentId, Path path, long start, long length,
1:       String[] locations, int numberOfBlocklets, ColumnarFormatVersion version,
1:       Map<String, String> blockStorageIdMap) {
1:     this(segmentId, path, start, length, locations, numberOfBlocklets, version);
1:     this.blockStorageIdMap = blockStorageIdMap;
1:   }
1: 
1:   public static CarbonHiveInputSplit from(String segmentId, FileSplit split,
0:                                           ColumnarFormatVersion version)
0:     throws IOException {
1:     return new CarbonHiveInputSplit(segmentId, split.getPath(), split.getStart(), split.getLength(),
0:       split.getLocations(), version);
1:   }
1: 
1:   public static List<TableBlockInfo> createBlocks(List<CarbonHiveInputSplit> splitList) {
1:     List<TableBlockInfo> tableBlockInfoList = new ArrayList<>();
1:     for (CarbonHiveInputSplit split : splitList) {
1:       BlockletInfos blockletInfos =
1:           new BlockletInfos(split.getNumberOfBlocklets(), 0, split.getNumberOfBlocklets());
1:       try {
1:         tableBlockInfoList.add(
1:             new TableBlockInfo(split.getPath().toString(), split.getStart(), split.getSegmentId(),
0:             split.getLocations(), split.getLength(), blockletInfos, split.getVersion()));
1:       } catch (IOException e) {
1:         throw new RuntimeException("fail to get location of split: " + split, e);
1:       }
1:     }
1:     return tableBlockInfoList;
1:   }
1: 
1:   public static TableBlockInfo getTableBlockInfo(CarbonHiveInputSplit inputSplit) {
1:     BlockletInfos blockletInfos =
1:         new BlockletInfos(inputSplit.getNumberOfBlocklets(), 0, inputSplit.getNumberOfBlocklets());
1:     try {
1:       return new TableBlockInfo(inputSplit.getPath().toString(), inputSplit.getStart(),
0:         inputSplit.getSegmentId(), inputSplit.getLocations(), inputSplit.getLength(),
0:         blockletInfos, inputSplit.getVersion());
1:     } catch (IOException e) {
1:       throw new RuntimeException("fail to get location of split: " + inputSplit, e);
1:     }
1:   }
1: 
1:   public String getSegmentId() {
1:     return segmentId;
1:   }
1: 
0:   @Override
0:   public void readFields(DataInput in) throws IOException {
1:     super.readFields(in);
1:     this.segmentId = in.readUTF();
1:     this.version = ColumnarFormatVersion.valueOf(in.readShort());
1:     this.bucketId = in.readUTF();
1:     int numInvalidSegment = in.readInt();
1:     invalidSegments = new ArrayList<>(numInvalidSegment);
1:     for (int i = 0; i < numInvalidSegment; i++) {
1:       invalidSegments.add(in.readUTF());
1:     }
1:   }
1: 
0:   @Override
0:   public void write(DataOutput out) throws IOException {
1:     super.write(out);
1:     out.writeUTF(segmentId);
1:     out.writeShort(version.number());
1:     out.writeUTF(bucketId);
1:     out.writeInt(invalidSegments.size());
1:     for (String invalidSegment : invalidSegments) {
1:       out.writeUTF(invalidSegment);
1:     }
1:   }
1: 
1:   public List<String> getInvalidSegments() {
1:     return invalidSegments;
1:   }
1: 
1:   public void setInvalidSegments(List<String> invalidSegments) {
1:     this.invalidSegments = invalidSegments;
1:   }
1: 
1:   public void setInvalidTimestampRange(List<UpdateVO> invalidTimestamps) {
1:     invalidTimestampsList = invalidTimestamps;
1:   }
1: 
1:   public List<UpdateVO> getInvalidTimestampRange() {
1:     return invalidTimestampsList;
1:   }
1: 
1:   /**
1:    * returns the number of blocklets
1:    *
1:    * @return
1:    */
1:   public int getNumberOfBlocklets() {
1:     return numberOfBlocklets;
1:   }
1: 
1:   public ColumnarFormatVersion getVersion() {
1:     return version;
1:   }
1: 
1:   public void setVersion(ColumnarFormatVersion version) {
1:     this.version = version;
1:   }
1: 
1:   public String getBucketId() {
1:     return bucketId;
1:   }
1: 
0:   @Override
0:   public int compareTo(Distributable o) {
1:     if (o == null) {
1:       return -1;
1:     }
1:     CarbonHiveInputSplit other = (CarbonHiveInputSplit) o;
0:     int compareResult = 0;
1:     // get the segment id
1:     // converr seg ID to double.
1: 
1:     double seg1 = Double.parseDouble(segmentId);
1:     double seg2 = Double.parseDouble(other.getSegmentId());
0:     if (seg1 - seg2 < 0) {
1:       return -1;
1:     }
0:     if (seg1 - seg2 > 0) {
1:       return 1;
1:     }
1: 
1:     // Comparing the time task id of the file to other
1:     // if both the task id of the file is same then we need to compare the
1:     // offset of
1:     // the file
1:     String filePath1 = this.getPath().getName();
1:     String filePath2 = other.getPath().getName();
1:     if (CarbonTablePath.isCarbonDataFile(filePath1)) {
1:       int firstTaskId = Integer.parseInt(CarbonTablePath.DataFileUtil.getTaskNo(filePath1));
1:       int otherTaskId = Integer.parseInt(CarbonTablePath.DataFileUtil.getTaskNo(filePath2));
1:       if (firstTaskId != otherTaskId) {
1:         return firstTaskId - otherTaskId;
1:       }
1: 
1:       int firstBucketNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getBucketNo(filePath1));
1:       int otherBucketNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getBucketNo(filePath2));
1:       if (firstBucketNo != otherBucketNo) {
1:         return firstBucketNo - otherBucketNo;
1:       }
1: 
1:       // compare the part no of both block info
1:       int firstPartNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(filePath1));
1:       int SecondPartNo = Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(filePath2));
1:       compareResult = firstPartNo - SecondPartNo;
1:     } else {
1:       compareResult = filePath1.compareTo(filePath2);
1:     }
1:     if (compareResult != 0) {
1:       return compareResult;
1:     }
1:     return 0;
1:   }
1: 
0:   @Override
0:   public String getBlockPath() {
1:     return getPath().getName();
1:   }
1: 
0:   @Override
0:   public List<Long> getMatchedBlocklets() {
1:     return null;
1:   }
1: 
0:   @Override
0:   public boolean fullScan() {
1:     return true;
1:   }
1: 
1:   /**
1:    * returns map of blocklocation and storage id
1:    *
1:    * @return
1:    */
1:   public Map<String, String> getBlockStorageIdMap() {
1:     return blockStorageIdMap;
1:   }
1: }
============================================================================
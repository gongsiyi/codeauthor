1:e39b0a1: /*
1:e39b0a1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:e39b0a1:  * contributor license agreements.  See the NOTICE file distributed with
1:e39b0a1:  * this work for additional information regarding copyright ownership.
1:e39b0a1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:e39b0a1:  * (the "License"); you may not use this file except in compliance with
1:e39b0a1:  * the License.  You may obtain a copy of the License at
1:e39b0a1:  *
1:e39b0a1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:e39b0a1:  *
1:e39b0a1:  * Unless required by applicable law or agreed to in writing, software
1:e39b0a1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:e39b0a1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:e39b0a1:  * See the License for the specific language governing permissions and
1:e39b0a1:  * limitations under the License.
1:e39b0a1:  */
9:e39b0a1: 
1:e39b0a1: package org.apache.carbondata.sdk.file;
1:e39b0a1: 
1:e39b0a1: import java.io.File;
1:e39b0a1: import java.io.FileFilter;
1:e39b0a1: import java.io.IOException;
1:b1c85fa: import java.io.UnsupportedEncodingException;
1:cf666c1: import java.util.HashMap;
1:cf666c1: import java.util.Map;
1:e39b0a1: 
1:b1c85fa: import org.apache.carbondata.common.exceptions.sql.InvalidLoadOptionException;
1:e39b0a1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:cf666c1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:bea277f: import org.apache.carbondata.core.metadata.schema.table.DiskBasedDMSchemaStorageProvider;
1:bea277f: import org.apache.carbondata.core.util.CarbonProperties;
1:e39b0a1: import org.apache.carbondata.core.util.path.CarbonTablePath;
1:e39b0a1: 
1:e39b0a1: import org.apache.avro.generic.GenericData;
1:e39b0a1: import org.apache.commons.io.FileUtils;
1:e39b0a1: import org.apache.commons.lang.CharEncoding;
1:cf55028: import org.junit.After;
1:e39b0a1: import org.junit.Assert;
1:cf55028: import org.junit.Before;
1:e39b0a1: import org.junit.Test;
1:e39b0a1: 
1:e39b0a1: import org.apache.avro.Schema;
1:3202cf5: 
1:e39b0a1: public class AvroCarbonWriterTest {
1:e39b0a1:   private String path = "./AvroCarbonWriterSuiteWriteFiles";
1:e39b0a1: 
1:cf55028:   @Before
1:cf55028:   public void cleanFile() {
1:bea277f:     String path = null;
1:bea277f:     try {
1:bea277f:       path = new File(AvroCarbonWriterTest.class.getResource("/").getPath() + "../")
1:bea277f:           .getCanonicalPath().replaceAll("\\\\", "/");
1:bea277f:     } catch (IOException e) {
1:bea277f:       assert (false);
1:bea277f:     }
1:bea277f:     CarbonProperties.getInstance()
1:bea277f:         .addProperty(CarbonCommonConstants.CARBON_SYSTEM_FOLDER_LOCATION, path);
1:cf55028:     assert (TestUtil.cleanMdtFile());
1:cf55028:   }
1:cf55028: 
1:cf55028:   @After
1:cf55028:   public void verifyDMFile() {
1:cf55028:     assert (!TestUtil.verifyMdtFile());
1:cf55028:   }
1:cf55028: 
1:e39b0a1:   @Test
1:e39b0a1:   public void testWriteBasic() throws IOException {
1:e39b0a1:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa: 
1:e39b0a1:     // Avro schema
1:e39b0a1:     String avroSchema =
1:e39b0a1:         "{" +
1:e39b0a1:             "   \"type\" : \"record\"," +
1:e39b0a1:             "   \"name\" : \"Acme\"," +
1:e39b0a1:             "   \"fields\" : ["
1:e39b0a1:             + "{ \"name\" : \"name\", \"type\" : \"string\" },"
1:e39b0a1:             + "{ \"name\" : \"age\", \"type\" : \"int\" }]" +
1:e39b0a1:         "}";
1:b1c85fa: 
1:e39b0a1:     String json = "{\"name\":\"bob\", \"age\":10}";
1:3202cf5: 
1:e39b0a1:     // conversion to GenericData.Record
1:4d3ecfb:     GenericData.Record record = TestUtil.jsonToAvro(json, avroSchema);
1:e39b0a1:     try {
1:4d3ecfb:       CarbonWriter writer = CarbonWriter.builder().outputPath(path).isTransactionalTable(true)
1:8f1a029:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema), TestUtil.configuration);
1:e39b0a1: 
1:e39b0a1:       for (int i = 0; i < 100; i++) {
1:e39b0a1:         writer.write(record);
1:e39b0a1:       }
1:e39b0a1:       writer.close();
1:e39b0a1:     } catch (Exception e) {
1:e39b0a1:       e.printStackTrace();
1:e39b0a1:       Assert.fail(e.getMessage());
1:e39b0a1:     }
1:e39b0a1: 
1:e39b0a1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:e39b0a1:     Assert.assertTrue(segmentFolder.exists());
1:e39b0a1: 
1:e39b0a1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:e39b0a1:       @Override public boolean accept(File pathname) {
1:e39b0a1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:e39b0a1:       }
1:e39b0a1:     });
1:e39b0a1:     Assert.assertNotNull(dataFiles);
1:e39b0a1:     Assert.assertEquals(1, dataFiles.length);
1:e39b0a1: 
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:e39b0a1:   }
1:e39b0a1: 
1:cf666c1:   @Test
1:e39b0a1:   public void testWriteAllPrimitive() throws IOException {
1:4b98af2:     FileUtils.deleteDirectory(new File(path));
1:4b98af2: 
1:4b98af2:     // Avro schema
1:4b98af2:     // Supported Primitive Datatype.
1:4b98af2:     // 1. Boolean
1:4b98af2:     // 2. Int
1:4b98af2:     // 3. long
1:4b98af2:     // 4. float -> To carbon Internally it is double.
1:4b98af2:     // 5. double
1:4b98af2:     // 6. String
1:4b98af2: 
1:4b98af2:     // Not Supported
1:4b98af2:     // 1.NULL Datatype
1:4b98af2:     // 2.Bytes
1:4b98af2: 
1:4b98af2:     String avroSchema = "{\n" + "  \"name\" : \"myrecord\",\n"
1:4b98af2:         + "  \"namespace\": \"org.apache.parquet.avro\",\n" + "  \"type\" : \"record\",\n"
1:4b98af2:         + "  \"fields\" : [ "
1:4b98af2:         + " {\n" + "    \"name\" : \"myboolean\",\n" + "    \"type\" : \"boolean\"\n  },"
1:4b98af2:         + " {\n" + "    \"name\" : \"myint\",\n" + "    \"type\" : \"int\"\n" + "  }, "
1:4b98af2:         + " {\n    \"name\" : \"mylong\",\n" + "    \"type\" : \"long\"\n" + "  },"
1:4b98af2:         + " {\n   \"name\" : \"myfloat\",\n" + "    \"type\" : \"float\"\n" + "  }, "
1:4b98af2:         + " {\n \"name\" : \"mydouble\",\n" + "    \"type\" : \"double\"\n" + "  },"
1:4b98af2:         + " {\n \"name\" : \"mystring\",\n" + "    \"type\" : \"string\"\n" + "  }\n" + "] }";
1:4b98af2: 
1:4b98af2:     String json = "{"
1:4b98af2:         + "\"myboolean\":true, "
1:4b98af2:         + "\"myint\": 10, "
1:4b98af2:         + "\"mylong\": 7775656565,"
1:4b98af2:         + " \"myfloat\": 0.2, "
1:4b98af2:         + "\"mydouble\": 44.56, "
1:4b98af2:         + "\"mystring\":\"Ajantha\"}";
1:4b98af2: 
1:4b98af2: 
1:4b98af2:     // conversion to GenericData.Record
1:4d3ecfb:     GenericData.Record record = TestUtil.jsonToAvro(json, avroSchema);
1:4b98af2: 
1:4b98af2:     try {
1:4b98af2:       CarbonWriter writer = CarbonWriter.builder()
1:4b98af2:           .outputPath(path)
1:4b98af2:           .isTransactionalTable(true)
1:8f1a029:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema), TestUtil.configuration);
1:4b98af2: 
1:4b98af2:       for (int i = 0; i < 100; i++) {
1:4b98af2:         writer.write(record);
1:4b98af2:       }
1:4b98af2:       writer.close();
1:4b98af2:     } catch (Exception e) {
1:4b98af2:       e.printStackTrace();
1:4b98af2:       Assert.fail(e.getMessage());
1:4b98af2:     }
1:4b98af2: 
1:4b98af2:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:4b98af2:     Assert.assertTrue(segmentFolder.exists());
1:4b98af2: 
1:4b98af2:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:4b98af2:       @Override public boolean accept(File pathname) {
1:4b98af2:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:4b98af2:       }
1:4b98af2:     });
1:4b98af2: 
1:4b98af2:     Assert.assertNotNull(dataFiles);
1:4b98af2:     Assert.assertEquals(1, dataFiles.length);
1:4b98af2: 
1:4b98af2:     FileUtils.deleteDirectory(new File(path));
1:e39b0a1:   }
1:4b98af2: 
1:4b98af2: 
1:b1c85fa:   @Test
1:e39b0a1:   public void testWriteNestedRecord() throws IOException {
1:3202cf5:     FileUtils.deleteDirectory(new File(path));
1:4b98af2: 
1:3202cf5:     String newAvroSchema =
1:3202cf5:         "{" +
1:3202cf5:           " \"type\" : \"record\", " +
1:3202cf5:           "  \"name\" : \"userInfo\", "  +
1:3202cf5:           "  \"namespace\" : \"my.example\", " +
1:3202cf5:           "  \"fields\" : [{\"name\" : \"username\", " +
1:3202cf5:           "  \"type\" : \"string\", " +
1:3202cf5:           "  \"default\" : \"NONE\"}, " +
1:3202cf5: 
1:3202cf5:        " {\"name\" : \"age\", " +
1:3202cf5:        " \"type\" : \"int\", " +
1:3202cf5:        " \"default\" : -1}, " +
1:3202cf5: 
1:3202cf5:     "{\"name\" : \"address\", " +
1:3202cf5:      "   \"type\" : { " +
1:3202cf5:       "  \"type\" : \"record\", " +
1:3202cf5:        "   \"name\" : \"mailing_address\", " +
1:3202cf5:         "  \"fields\" : [ {" +
1:3202cf5:       "        \"name\" : \"street\", " +
1:3202cf5:        "       \"type\" : \"string\", " +
1:3202cf5:        "       \"default\" : \"NONE\"}, { " +
1:3202cf5: 
1:3202cf5:       " \"name\" : \"city\", " +
1:3202cf5:         "  \"type\" : \"string\", " +
1:3202cf5:         "  \"default\" : \"NONE\"}, " +
1:3202cf5:          "                 ]}, " +
1:3202cf5:      " \"default\" : {} " +
1:3202cf5:    " } " +
1:3202cf5: "}";
1:3202cf5: 
1:3202cf5:     String mySchema =
1:3202cf5:     "{" +
1:3202cf5:     "  \"name\": \"address\", " +
1:3202cf5:     "   \"type\": \"record\", " +
1:3202cf5:     "    \"fields\": [  " +
1:3202cf5:     "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:3202cf5:     "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:3202cf5:     "  { " +
1:3202cf5:     "    \"name\": \"address\", " +
1:3202cf5:     "      \"type\": { " +
1:3202cf5:     "    \"type\" : \"record\", " +
1:3202cf5:     "        \"name\" : \"my_address\", " +
1:3202cf5:     "        \"fields\" : [ " +
1:3202cf5:     "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:3202cf5:     "    {\"name\": \"city\", \"type\": \"string\"} " +
1:3202cf5:     "  ]} " +
1:3202cf5:     "  } " +
1:3202cf5:     "] " +
1:3202cf5:     "}";
1:b1c85fa: 
1:3202cf5:    String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1:b1c85fa: 
1:b1c85fa: 
1:3202cf5:     // conversion to GenericData.Record
1:3202cf5:     Schema nn = new Schema.Parser().parse(mySchema);
1:4d3ecfb:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
1:b1c85fa: 
1:3202cf5:     try {
1:3202cf5:       CarbonWriter writer = CarbonWriter.builder()
1:3202cf5:           .outputPath(path)
1:3202cf5:           .isTransactionalTable(true)
1:8f1a029:           .buildWriterForAvroInput(nn, TestUtil.configuration);
1:3202cf5: 
1:3202cf5:       for (int i = 0; i < 100; i++) {
1:3202cf5:         writer.write(record);
1:b1c85fa:       }
1:3202cf5:       writer.close();
1:3202cf5:     } catch (Exception e) {
1:3202cf5:       e.printStackTrace();
1:3202cf5:       Assert.fail(e.getMessage());
1:3202cf5:     }
1:3202cf5: 
1:3202cf5:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:3202cf5:     Assert.assertTrue(segmentFolder.exists());
1:3202cf5: 
1:3202cf5:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:3202cf5:       @Override public boolean accept(File pathname) {
1:3202cf5:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:3202cf5:       }
1:3202cf5:     });
1:3202cf5:     Assert.assertNotNull(dataFiles);
1:3202cf5:     Assert.assertEquals(1, dataFiles.length);
1:3202cf5: 
1:3202cf5:     FileUtils.deleteDirectory(new File(path));
1:3202cf5:   }
1:3202cf5: 
1:3202cf5: 
1:e39b0a1:   @Test
1:b1c85fa:   public void testWriteNestedRecordWithMeasure() throws IOException {
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa: 
1:b1c85fa:     String mySchema =
1:b1c85fa:         "{" +
1:b1c85fa:             "  \"name\": \"address\", " +
1:b1c85fa:             "   \"type\": \"record\", " +
1:b1c85fa:             "    \"fields\": [  " +
1:b1c85fa:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:b1c85fa:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:b1c85fa:             "  { " +
1:b1c85fa:             "    \"name\": \"address\", " +
1:b1c85fa:             "      \"type\": { " +
1:b1c85fa:             "    \"type\" : \"record\", " +
1:b1c85fa:             "        \"name\" : \"my_address\", " +
1:b1c85fa:             "        \"fields\" : [ " +
1:b1c85fa:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:b1c85fa:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:b1c85fa:             "  ]} " +
1:b1c85fa:             "  } " +
1:b1c85fa:             "] " +
1:b1c85fa:             "}";
1:b1c85fa: 
1:b1c85fa:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1:b1c85fa: 
1:b1c85fa: 
1:b1c85fa:     // conversion to GenericData.Record
1:b1c85fa:     Schema nn = new Schema.Parser().parse(mySchema);
1:4d3ecfb:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
1:b1c85fa: 
1:b1c85fa:     try {
1:b1c85fa:       CarbonWriter writer = CarbonWriter.builder()
1:b1c85fa:           .outputPath(path)
1:b1c85fa:           .isTransactionalTable(true)
1:8f1a029:           .buildWriterForAvroInput(nn, TestUtil.configuration);
1:b1c85fa: 
1:b1c85fa:       for (int i = 0; i < 100; i++) {
1:b1c85fa:         writer.write(record);
1:b1c85fa:       }
1:b1c85fa:       writer.close();
1:b1c85fa:     } catch (Exception e) {
1:b1c85fa:       e.printStackTrace();
1:b1c85fa:       Assert.fail(e.getMessage());
1:b1c85fa:     }
1:b1c85fa: 
1:b1c85fa:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:b1c85fa:     Assert.assertTrue(segmentFolder.exists());
1:b1c85fa: 
1:b1c85fa:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:b1c85fa:       @Override public boolean accept(File pathname) {
1:b1c85fa:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:b1c85fa:       }
1:b1c85fa:     });
1:b1c85fa:     Assert.assertNotNull(dataFiles);
1:b1c85fa:     Assert.assertEquals(1, dataFiles.length);
1:b1c85fa: 
1:e39b0a1:     FileUtils.deleteDirectory(new File(path));
1:e39b0a1:   }
1:3202cf5: 
1:3202cf5: 
1:b1c85fa:   private void WriteAvroComplexData(String mySchema, String json, String[] sortColumns)
1:b1c85fa:       throws UnsupportedEncodingException, IOException, InvalidLoadOptionException {
1:b1c85fa: 
1:b1c85fa:     // conversion to GenericData.Record
1:b1c85fa:     Schema nn = new Schema.Parser().parse(mySchema);
1:4d3ecfb:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
1:b1c85fa:     try {
1:b1c85fa:       CarbonWriter writer = CarbonWriter.builder()
1:b1c85fa:           .outputPath(path)
1:b1c85fa:           .isTransactionalTable(true).sortBy(sortColumns)
1:8f1a029:           .buildWriterForAvroInput(nn, TestUtil.configuration);
1:b1c85fa: 
1:b1c85fa:       for (int i = 0; i < 100; i++) {
1:b1c85fa:         writer.write(record);
1:b1c85fa:       }
1:b1c85fa:       writer.close();
1:b1c85fa:     } catch (Exception e) {
1:b1c85fa:       e.printStackTrace();
1:b1c85fa:       throw e;
1:b1c85fa:     }
1:b1c85fa:   }
1:b1c85fa: 
1:b1c85fa: 
1:b1c85fa:   @Test
1:b1c85fa:   public void testWriteComplexRecord() throws IOException, InvalidLoadOptionException {
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa: 
1:b1c85fa:     String mySchema =
1:b1c85fa:         "{" +
1:b1c85fa:             "  \"name\": \"address\", " +
1:b1c85fa:             "   \"type\": \"record\", " +
1:b1c85fa:             "    \"fields\": [  " +
1:b1c85fa:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:b1c85fa:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:b1c85fa:             "  { " +
1:b1c85fa:             "    \"name\": \"address\", " +
1:b1c85fa:             "      \"type\": { " +
1:b1c85fa:             "    \"type\" : \"record\", " +
1:b1c85fa:             "        \"name\" : \"my_address\", " +
1:b1c85fa:             "        \"fields\" : [ " +
1:b1c85fa:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:b1c85fa:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:b1c85fa:             "  ]} " +
1:b1c85fa:             "  }, " +
1:b1c85fa:             "  {\"name\" :\"doorNum\", " +
1:b1c85fa:             "   \"type\" : { " +
1:b1c85fa:             "   \"type\" :\"array\", " +
1:b1c85fa:             "   \"items\":{ " +
1:b1c85fa:             "   \"name\" :\"EachdoorNums\", " +
1:b1c85fa:             "   \"type\" : \"int\", " +
1:b1c85fa:             "   \"default\":-1} " +
1:b1c85fa:             "              } " +
1:b1c85fa:             "  }] " +
1:b1c85fa:             "}";
1:b1c85fa: 
1:b1c85fa:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}, "
1:b1c85fa:         + "   \"doorNum\" : [1,2,3,4]}";
1:b1c85fa: 
1:b1c85fa:     WriteAvroComplexData(mySchema, json, null);
1:b1c85fa: 
1:b1c85fa:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:b1c85fa:     Assert.assertTrue(segmentFolder.exists());
1:b1c85fa: 
1:b1c85fa:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:b1c85fa:       @Override public boolean accept(File pathname) {
1:b1c85fa:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:b1c85fa:       }
1:b1c85fa:     });
1:b1c85fa:     Assert.assertNotNull(dataFiles);
1:b1c85fa:     Assert.assertEquals(1, dataFiles.length);
1:b1c85fa: 
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa:   }
1:b1c85fa: 
1:b1c85fa: 
1:b1c85fa:   @Test
1:b1c85fa:   public void testWriteComplexRecordWithSortColumns() throws IOException {
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa: 
1:b1c85fa:     String mySchema =
1:b1c85fa:         "{" +
1:b1c85fa:             "  \"name\": \"address\", " +
1:b1c85fa:             "   \"type\": \"record\", " +
1:b1c85fa:             "    \"fields\": [  " +
1:b1c85fa:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:b1c85fa:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:b1c85fa:             "  { " +
1:b1c85fa:             "    \"name\": \"address\", " +
1:b1c85fa:             "      \"type\": { " +
1:b1c85fa:             "    \"type\" : \"record\", " +
1:b1c85fa:             "        \"name\" : \"my_address\", " +
1:b1c85fa:             "        \"fields\" : [ " +
1:b1c85fa:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:b1c85fa:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:b1c85fa:             "  ]} " +
1:b1c85fa:             "  }, " +
1:b1c85fa:             "  {\"name\" :\"doorNum\", " +
1:b1c85fa:             "   \"type\" : { " +
1:b1c85fa:             "   \"type\" :\"array\", " +
1:b1c85fa:             "   \"items\":{ " +
1:b1c85fa:             "   \"name\" :\"EachdoorNums\", " +
1:b1c85fa:             "   \"type\" : \"int\", " +
1:b1c85fa:             "   \"default\":-1} " +
1:b1c85fa:             "              } " +
1:b1c85fa:             "  }] " +
1:b1c85fa:             "}";
1:b1c85fa: 
1:b1c85fa:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}, "
1:b1c85fa:         + "   \"doorNum\" : [1,2,3,4]}";
1:3202cf5: 
1:b1c85fa:     try {
1:b1c85fa:       WriteAvroComplexData(mySchema, json, new String[] { "doorNum" });
1:b1c85fa:       Assert.fail();
1:b1c85fa:     } catch (Exception e) {
1:b1c85fa:       Assert.assertTrue(true);
1:b1c85fa:     }
1:b1c85fa:     FileUtils.deleteDirectory(new File(path));
1:b1c85fa:   }
1:b1c85fa: 
1:e39b0a1:   @Test
1:cf666c1:   public void testExceptionForDuplicateColumns() throws IOException, InvalidLoadOptionException {
1:cf666c1:     Field[] field = new Field[2];
1:cf666c1:     field[0] = new Field("name", DataTypes.STRING);
1:cf666c1:     field[1] = new Field("name", DataTypes.STRING);
1:cf666c1:     CarbonWriterBuilder writer = CarbonWriter.builder().isTransactionalTable(false)
1:cf666c1:         .uniqueIdentifier(System.currentTimeMillis()).outputPath(path);
1:b1c85fa: 
1:cf666c1:     try {
1:8f1a029:       writer.buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field), TestUtil.configuration);
1:cf666c1:       Assert.fail();
1:cf666c1:     } catch (Exception e) {
1:cf666c1:       assert(e.getMessage().contains("Duplicate column name found in table schema"));
1:cf666c1:     }
1:cf666c1:     FileUtils.deleteDirectory(new File(path));
1:cf666c1:   }
1:cf666c1: 
1:cf666c1:   @Test
1:cf666c1:   public void testExceptionForInvalidDate() throws IOException, InvalidLoadOptionException {
1:cf666c1:     Field[] field = new Field[2];
1:cf666c1:     field[0] = new Field("name", DataTypes.STRING);
1:cf666c1:     field[1] = new Field("date", DataTypes.DATE);
1:cf666c1:     CarbonWriterBuilder writer = CarbonWriter.builder().isTransactionalTable(false)
1:cf666c1:         .uniqueIdentifier(System.currentTimeMillis()).outputPath(path);
1:cf666c1: 
1:cf666c1:     try {
1:cf666c1:       Map<String, String> loadOptions = new HashMap<String, String>();
1:cf666c1:       loadOptions.put("bad_records_action", "fail");
1:cf666c1:       CarbonWriter carbonWriter =
1:8f1a029:           writer.isTransactionalTable(false).withLoadOptions(loadOptions).buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field), TestUtil.configuration);
1:cf666c1:       carbonWriter.write(new String[] { "k", "20-02-2233" });
1:cf666c1:       carbonWriter.close();
1:cf666c1:       Assert.fail();
1:cf666c1:     } catch (Exception e) {
1:cf666c1:       assert(e.getMessage().contains("Data load failed due to bad record"));
1:cf666c1:     }
1:cf666c1:     FileUtils.deleteDirectory(new File(path));
1:cf666c1:   }
1:b1c85fa: 
1:e39b0a1: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema), TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema), TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           .buildWriterForAvroInput(nn, TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           .buildWriterForAvroInput(nn, TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           .buildWriterForAvroInput(nn, TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:       writer.buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field), TestUtil.configuration);
/////////////////////////////////////////////////////////////////////////
1:           writer.isTransactionalTable(false).withLoadOptions(loadOptions).buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field), TestUtil.configuration);
commit:cf666c1
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashMap;
1: import java.util.Map;
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
1:   @Test
1:   public void testExceptionForDuplicateColumns() throws IOException, InvalidLoadOptionException {
1:     Field[] field = new Field[2];
1:     field[0] = new Field("name", DataTypes.STRING);
1:     field[1] = new Field("name", DataTypes.STRING);
1:     CarbonWriterBuilder writer = CarbonWriter.builder().isTransactionalTable(false)
1:         .uniqueIdentifier(System.currentTimeMillis()).outputPath(path);
1:     try {
0:       writer.buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field));
1:       Assert.fail();
1:     } catch (Exception e) {
1:       assert(e.getMessage().contains("Duplicate column name found in table schema"));
1:     }
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1:   @Test
1:   public void testExceptionForInvalidDate() throws IOException, InvalidLoadOptionException {
1:     Field[] field = new Field[2];
1:     field[0] = new Field("name", DataTypes.STRING);
1:     field[1] = new Field("date", DataTypes.DATE);
1:     CarbonWriterBuilder writer = CarbonWriter.builder().isTransactionalTable(false)
1:         .uniqueIdentifier(System.currentTimeMillis()).outputPath(path);
1: 
1:     try {
1:       Map<String, String> loadOptions = new HashMap<String, String>();
1:       loadOptions.put("bad_records_action", "fail");
1:       CarbonWriter carbonWriter =
0:           writer.isTransactionalTable(false).withLoadOptions(loadOptions).buildWriterForCSVInput(new org.apache.carbondata.sdk.file.Schema(field));
1:       carbonWriter.write(new String[] { "k", "20-02-2233" });
1:       carbonWriter.close();
1:       Assert.fail();
1:     } catch (Exception e) {
1:       assert(e.getMessage().contains("Data load failed due to bad record"));
1:     }
1:     FileUtils.deleteDirectory(new File(path));
1:   }
commit:26eb2d0
/////////////////////////////////////////////////////////////////////////
0:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema));
/////////////////////////////////////////////////////////////////////////
0:           .buildWriterForAvroInput(new Schema.Parser().parse(avroSchema));
/////////////////////////////////////////////////////////////////////////
0:           .buildWriterForAvroInput(nn);
/////////////////////////////////////////////////////////////////////////
0:           .buildWriterForAvroInput(nn);
/////////////////////////////////////////////////////////////////////////
0:           .buildWriterForAvroInput(nn);
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:bea277f
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.schema.table.DiskBasedDMSchemaStorageProvider;
1: import org.apache.carbondata.core.util.CarbonProperties;
/////////////////////////////////////////////////////////////////////////
1:     String path = null;
1:     try {
1:       path = new File(AvroCarbonWriterTest.class.getResource("/").getPath() + "../")
1:           .getCanonicalPath().replaceAll("\\\\", "/");
1:     } catch (IOException e) {
1:       assert (false);
1:     }
1:     CarbonProperties.getInstance()
1:         .addProperty(CarbonCommonConstants.CARBON_SYSTEM_FOLDER_LOCATION, path);
author:rahul
-------------------------------------------------------------------------------
commit:4d3ecfb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     GenericData.Record record = TestUtil.jsonToAvro(json, avroSchema);
1:       CarbonWriter writer = CarbonWriter.builder().outputPath(path).isTransactionalTable(true)
/////////////////////////////////////////////////////////////////////////
1:     GenericData.Record record = TestUtil.jsonToAvro(json, avroSchema);
/////////////////////////////////////////////////////////////////////////
1:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
/////////////////////////////////////////////////////////////////////////
1:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
/////////////////////////////////////////////////////////////////////////
1:     GenericData.Record record = TestUtil.jsonToAvro(json, mySchema);
author:xubo245
-------------------------------------------------------------------------------
commit:cf55028
/////////////////////////////////////////////////////////////////////////
1: import org.junit.After;
1: import org.junit.Before;
1:   @Before
1:   public void cleanFile() {
1:     assert (TestUtil.cleanMdtFile());
1:   }
1: 
1:   @After
1:   public void verifyDMFile() {
1:     assert (!TestUtil.verifyMdtFile());
1:   }
1: 
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:cf3e919
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:           .withSchema(AvroCarbonWriter.getCarbonSchemaFromAvroSchema(avroSchema))
/////////////////////////////////////////////////////////////////////////
0:           .withSchema(AvroCarbonWriter.getCarbonSchemaFromAvroSchema(avroSchema))
/////////////////////////////////////////////////////////////////////////
0:           .withSchema(AvroCarbonWriter.getCarbonSchemaFromAvroSchema(mySchema))
/////////////////////////////////////////////////////////////////////////
0:           .withSchema(AvroCarbonWriter.getCarbonSchemaFromAvroSchema(mySchema))
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:           .withSchema(AvroCarbonWriter.getCarbonSchemaFromAvroSchema(mySchema))
commit:4b98af2
/////////////////////////////////////////////////////////////////////////
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     // Avro schema
1:     // Supported Primitive Datatype.
1:     // 1. Boolean
1:     // 2. Int
1:     // 3. long
1:     // 4. float -> To carbon Internally it is double.
1:     // 5. double
1:     // 6. String
1: 
1:     // Not Supported
1:     // 1.NULL Datatype
1:     // 2.Bytes
1: 
1:     String avroSchema = "{\n" + "  \"name\" : \"myrecord\",\n"
1:         + "  \"namespace\": \"org.apache.parquet.avro\",\n" + "  \"type\" : \"record\",\n"
1:         + "  \"fields\" : [ "
1:         + " {\n" + "    \"name\" : \"myboolean\",\n" + "    \"type\" : \"boolean\"\n  },"
1:         + " {\n" + "    \"name\" : \"myint\",\n" + "    \"type\" : \"int\"\n" + "  }, "
1:         + " {\n    \"name\" : \"mylong\",\n" + "    \"type\" : \"long\"\n" + "  },"
1:         + " {\n   \"name\" : \"myfloat\",\n" + "    \"type\" : \"float\"\n" + "  }, "
1:         + " {\n \"name\" : \"mydouble\",\n" + "    \"type\" : \"double\"\n" + "  },"
1:         + " {\n \"name\" : \"mystring\",\n" + "    \"type\" : \"string\"\n" + "  }\n" + "] }";
1: 
1:     String json = "{"
1:         + "\"myboolean\":true, "
1:         + "\"myint\": 10, "
1:         + "\"mylong\": 7775656565,"
1:         + " \"myfloat\": 0.2, "
1:         + "\"mydouble\": 44.56, "
1:         + "\"mystring\":\"Ajantha\"}";
1: 
1: 
1:     // conversion to GenericData.Record
0:     JsonAvroConverter converter = new JsonAvroConverter();
0:     GenericData.Record record = converter.convertToGenericDataRecord(
0:         json.getBytes(CharEncoding.UTF_8), new Schema.Parser().parse(avroSchema));
1: 
0:     Field[] fields = new Field[6];
0:     // fields[0] = new Field("mynull", DataTypes.NULL);
0:     fields[0] = new Field("myboolean", DataTypes.BOOLEAN);
0:     fields[1] = new Field("myint", DataTypes.INT);
0:     fields[2] = new Field("mylong", DataTypes.LONG);
0:     fields[3] = new Field("myfloat", DataTypes.DOUBLE);
0:     fields[4] = new Field("mydouble", DataTypes.DOUBLE);
0:     fields[5] = new Field("mystring", DataTypes.STRING);
1: 
1: 
1:     try {
1:       CarbonWriter writer = CarbonWriter.builder()
0:           .withSchema(new org.apache.carbondata.sdk.file.Schema(fields))
1:           .outputPath(path)
1:           .isTransactionalTable(true)
0:           .buildWriterForAvroInput();
1: 
1:       for (int i = 0; i < 100; i++) {
1:         writer.write(record);
1:       }
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:     Assert.assertTrue(segmentFolder.exists());
1: 
1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:       @Override public boolean accept(File pathname) {
1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:       }
1:     });
1: 
1:     Assert.assertNotNull(dataFiles);
1:     Assert.assertEquals(1, dataFiles.length);
1: 
1:     FileUtils.deleteDirectory(new File(path));
1: 
author:sounakr
-------------------------------------------------------------------------------
commit:b1c85fa
/////////////////////////////////////////////////////////////////////////
1: import java.io.UnsupportedEncodingException;
1: import org.apache.carbondata.common.exceptions.sql.InvalidLoadOptionException;
0: import org.apache.carbondata.core.metadata.datatype.ArrayType;
/////////////////////////////////////////////////////////////////////////
0: import scala.Array;
/////////////////////////////////////////////////////////////////////////
1: 
1:   @Test
1:   public void testWriteNestedRecordWithMeasure() throws IOException {
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     String mySchema =
1:         "{" +
1:             "  \"name\": \"address\", " +
1:             "   \"type\": \"record\", " +
1:             "    \"fields\": [  " +
1:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:             "  { " +
1:             "    \"name\": \"address\", " +
1:             "      \"type\": { " +
1:             "    \"type\" : \"record\", " +
1:             "        \"name\" : \"my_address\", " +
1:             "        \"fields\" : [ " +
1:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:             "  ]} " +
1:             "  } " +
1:             "] " +
1:             "}";
1: 
1:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1: 
1: 
1:     // conversion to GenericData.Record
1:     Schema nn = new Schema.Parser().parse(mySchema);
0:     JsonAvroConverter converter = new JsonAvroConverter();
0:     GenericData.Record record = converter.convertToGenericDataRecord(
0:         json.getBytes(CharEncoding.UTF_8), nn);
1: 
0:     Field[] fields = new Field[3];
0:     fields[0] = new Field("name", DataTypes.STRING);
0:     fields[1] = new Field("name1", DataTypes.STRING);
0:     // fields[1] = new Field("age", DataTypes.INT);
0:     List fld = new ArrayList<StructField>();
0:     fld.add(new StructField("street", DataTypes.STRING));
0:     fld.add(new StructField("city", DataTypes.STRING));
0:     fields[2] = new Field("address", "struct", fld);
1: 
1:     try {
1:       CarbonWriter writer = CarbonWriter.builder()
0:           .withSchema(new org.apache.carbondata.sdk.file.Schema(fields))
1:           .outputPath(path)
1:           .isTransactionalTable(true)
0:           .buildWriterForAvroInput();
1: 
1:       for (int i = 0; i < 100; i++) {
1:         writer.write(record);
1:       }
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:     Assert.assertTrue(segmentFolder.exists());
1: 
1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:       @Override public boolean accept(File pathname) {
1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:       }
1:     });
1:     Assert.assertNotNull(dataFiles);
1:     Assert.assertEquals(1, dataFiles.length);
1: 
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1: 
1:   private void WriteAvroComplexData(String mySchema, String json, String[] sortColumns)
1:       throws UnsupportedEncodingException, IOException, InvalidLoadOptionException {
0:     Field[] fields = new Field[4];
0:     fields[0] = new Field("name", DataTypes.STRING);
0:     fields[1] = new Field("name1", DataTypes.STRING);
0:     // fields[1] = new Field("age", DataTypes.INT);
0:     List fld = new ArrayList<StructField>();
0:     fld.add(new StructField("street", DataTypes.STRING));
0:     fld.add(new StructField("city", DataTypes.STRING));
0:     fields[2] = new Field("address", "struct", fld);
0:     List fld1 = new ArrayList<StructField>();
0:     fld1.add(new StructField("eachDoorNum", DataTypes.INT));
0:     fields[3] = new Field("doorNum","array",fld1);
1: 
1:     // conversion to GenericData.Record
1:     Schema nn = new Schema.Parser().parse(mySchema);
0:     JsonAvroConverter converter = new JsonAvroConverter();
0:     GenericData.Record record = converter.convertToGenericDataRecord(
0:         json.getBytes(CharEncoding.UTF_8), nn);
1: 
1:     try {
1:       CarbonWriter writer = CarbonWriter.builder()
0:           .withSchema(new org.apache.carbondata.sdk.file.Schema(fields))
1:           .outputPath(path)
1:           .isTransactionalTable(true).sortBy(sortColumns)
0:           .buildWriterForAvroInput();
1: 
1:       for (int i = 0; i < 100; i++) {
1:         writer.write(record);
1:       }
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       throw e;
1:     }
1:   }
1: 
1: 
1:   @Test
1:   public void testWriteComplexRecord() throws IOException, InvalidLoadOptionException {
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     String mySchema =
1:         "{" +
1:             "  \"name\": \"address\", " +
1:             "   \"type\": \"record\", " +
1:             "    \"fields\": [  " +
1:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:             "  { " +
1:             "    \"name\": \"address\", " +
1:             "      \"type\": { " +
1:             "    \"type\" : \"record\", " +
1:             "        \"name\" : \"my_address\", " +
1:             "        \"fields\" : [ " +
1:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:             "  ]} " +
1:             "  }, " +
1:             "  {\"name\" :\"doorNum\", " +
1:             "   \"type\" : { " +
1:             "   \"type\" :\"array\", " +
1:             "   \"items\":{ " +
1:             "   \"name\" :\"EachdoorNums\", " +
1:             "   \"type\" : \"int\", " +
1:             "   \"default\":-1} " +
1:             "              } " +
1:             "  }] " +
1:             "}";
1: 
1:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}, "
1:         + "   \"doorNum\" : [1,2,3,4]}";
1: 
1:     WriteAvroComplexData(mySchema, json, null);
1: 
1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:     Assert.assertTrue(segmentFolder.exists());
1: 
1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:       @Override public boolean accept(File pathname) {
1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:       }
1:     });
1:     Assert.assertNotNull(dataFiles);
1:     Assert.assertEquals(1, dataFiles.length);
1: 
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1: 
1:   @Test
1:   public void testWriteComplexRecordWithSortColumns() throws IOException {
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     String mySchema =
1:         "{" +
1:             "  \"name\": \"address\", " +
1:             "   \"type\": \"record\", " +
1:             "    \"fields\": [  " +
1:             "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:             "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:             "  { " +
1:             "    \"name\": \"address\", " +
1:             "      \"type\": { " +
1:             "    \"type\" : \"record\", " +
1:             "        \"name\" : \"my_address\", " +
1:             "        \"fields\" : [ " +
1:             "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:             "    {\"name\": \"city\", \"type\": \"string\"} " +
1:             "  ]} " +
1:             "  }, " +
1:             "  {\"name\" :\"doorNum\", " +
1:             "   \"type\" : { " +
1:             "   \"type\" :\"array\", " +
1:             "   \"items\":{ " +
1:             "   \"name\" :\"EachdoorNums\", " +
1:             "   \"type\" : \"int\", " +
1:             "   \"default\":-1} " +
1:             "              } " +
1:             "  }] " +
1:             "}";
1: 
1:     String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}, "
1:         + "   \"doorNum\" : [1,2,3,4]}";
1: 
1:     try {
1:       WriteAvroComplexData(mySchema, json, new String[] { "doorNum" });
1:       Assert.fail();
1:     } catch (Exception e) {
1:       Assert.assertTrue(true);
1:     }
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1: 
1: 
commit:3202cf5
/////////////////////////////////////////////////////////////////////////
0: import java.util.ArrayList;
0: import java.util.List;
0: import org.apache.carbondata.core.metadata.datatype.StructField;
0: import org.apache.carbondata.core.metadata.datatype.StructType;
0: import org.apache.avro.generic.GenericRecord;
0: import org.apache.hadoop.conf.Configuration;
0: import static org.apache.hadoop.yarn.webapp.hamlet.HamletSpec.InputType.file;
1: 
/////////////////////////////////////////////////////////////////////////
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     String newAvroSchema =
1:         "{" +
1:           " \"type\" : \"record\", " +
1:           "  \"name\" : \"userInfo\", "  +
1:           "  \"namespace\" : \"my.example\", " +
1:           "  \"fields\" : [{\"name\" : \"username\", " +
1:           "  \"type\" : \"string\", " +
1:           "  \"default\" : \"NONE\"}, " +
1: 
1:        " {\"name\" : \"age\", " +
1:        " \"type\" : \"int\", " +
1:        " \"default\" : -1}, " +
1: 
1:     "{\"name\" : \"address\", " +
1:      "   \"type\" : { " +
1:       "  \"type\" : \"record\", " +
1:        "   \"name\" : \"mailing_address\", " +
1:         "  \"fields\" : [ {" +
1:       "        \"name\" : \"street\", " +
1:        "       \"type\" : \"string\", " +
1:        "       \"default\" : \"NONE\"}, { " +
1: 
1:       " \"name\" : \"city\", " +
1:         "  \"type\" : \"string\", " +
1:         "  \"default\" : \"NONE\"}, " +
1:          "                 ]}, " +
1:      " \"default\" : {} " +
1:    " } " +
1: "}";
1: 
1:     String mySchema =
1:     "{" +
1:     "  \"name\": \"address\", " +
1:     "   \"type\": \"record\", " +
1:     "    \"fields\": [  " +
1:     "  { \"name\": \"name\", \"type\": \"string\"}, " +
1:     "  { \"name\": \"age\", \"type\": \"int\"}, " +
1:     "  { " +
1:     "    \"name\": \"address\", " +
1:     "      \"type\": { " +
1:     "    \"type\" : \"record\", " +
1:     "        \"name\" : \"my_address\", " +
1:     "        \"fields\" : [ " +
1:     "    {\"name\": \"street\", \"type\": \"string\"}, " +
1:     "    {\"name\": \"city\", \"type\": \"string\"} " +
1:     "  ]} " +
1:     "  } " +
1:     "] " +
1:     "}";
1: 
1:    String json = "{\"name\":\"bob\", \"age\":10, \"address\" : {\"street\":\"abc\", \"city\":\"bang\"}}";
1: 
1: 
1:     // conversion to GenericData.Record
1:     Schema nn = new Schema.Parser().parse(mySchema);
0:     JsonAvroConverter converter = new JsonAvroConverter();
0:     GenericData.Record record = converter.convertToGenericDataRecord(
0:         json.getBytes(CharEncoding.UTF_8), nn);
1: 
0:     Field[] fields = new Field[3];
0:     fields[0] = new Field("name", DataTypes.STRING);
0:     fields[1] = new Field("name1", DataTypes.STRING);
0:     // fields[1] = new Field("age", DataTypes.INT);
0:     List fld = new ArrayList<StructField>();
0:     fld.add(new StructField("street", DataTypes.STRING));
0:     fld.add(new StructField("city", DataTypes.STRING));
0:     fields[2] = new Field("address", "struct", fld);
1: 
1:     try {
1:       CarbonWriter writer = CarbonWriter.builder()
0:           .withSchema(new org.apache.carbondata.sdk.file.Schema(fields))
1:           .outputPath(path)
1:           .isTransactionalTable(true)
0:           .buildWriterForAvroInput();
1: 
1:       for (int i = 0; i < 100; i++) {
1:         writer.write(record);
1:       }
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:     Assert.assertTrue(segmentFolder.exists());
1: 
1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:       @Override public boolean accept(File pathname) {
1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:       }
1:     });
1:     Assert.assertNotNull(dataFiles);
1:     Assert.assertEquals(1, dataFiles.length);
1: 
1:     FileUtils.deleteDirectory(new File(path));
commit:b7b8073
/////////////////////////////////////////////////////////////////////////
0:           .isTransactionalTable(true)
author:Jacky Li
-------------------------------------------------------------------------------
commit:e39b0a1
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.sdk.file;
1: 
1: import java.io.File;
1: import java.io.FileFilter;
1: import java.io.IOException;
1: 
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.util.path.CarbonTablePath;
1: 
1: import org.apache.avro.generic.GenericData;
1: import org.apache.commons.io.FileUtils;
1: import org.apache.commons.lang.CharEncoding;
1: import org.junit.Assert;
1: import org.junit.Test;
1: 
0: import tech.allegro.schema.json2avro.converter.JsonAvroConverter;
1: import org.apache.avro.Schema;
1: 
1: public class AvroCarbonWriterTest {
1:   private String path = "./AvroCarbonWriterSuiteWriteFiles";
1: 
1:   @Test
1:   public void testWriteBasic() throws IOException {
1:     FileUtils.deleteDirectory(new File(path));
1: 
1:     // Avro schema
1:     String avroSchema =
1:         "{" +
1:             "   \"type\" : \"record\"," +
1:             "   \"name\" : \"Acme\"," +
1:             "   \"fields\" : ["
1:             + "{ \"name\" : \"name\", \"type\" : \"string\" },"
1:             + "{ \"name\" : \"age\", \"type\" : \"int\" }]" +
1:         "}";
1: 
1:     String json = "{\"name\":\"bob\", \"age\":10}";
1: 
1:     // conversion to GenericData.Record
0:     JsonAvroConverter converter = new JsonAvroConverter();
0:     GenericData.Record record = converter.convertToGenericDataRecord(
0:         json.getBytes(CharEncoding.UTF_8), new Schema.Parser().parse(avroSchema));
1: 
0:     Field[] fields = new Field[2];
0:     fields[0] = new Field("name", DataTypes.STRING);
0:     fields[1] = new Field("age", DataTypes.STRING);
1: 
1:     try {
0:       CarbonWriter writer = CarbonWriter.builder()
0:           .withSchema(new org.apache.carbondata.sdk.file.Schema(fields))
0:           .outputPath(path)
0:           .buildWriterForAvroInput();
1: 
1:       for (int i = 0; i < 100; i++) {
1:         writer.write(record);
1:       }
1:       writer.close();
1:     } catch (Exception e) {
1:       e.printStackTrace();
1:       Assert.fail(e.getMessage());
1:     }
1: 
1:     File segmentFolder = new File(CarbonTablePath.getSegmentPath(path, "null"));
1:     Assert.assertTrue(segmentFolder.exists());
1: 
1:     File[] dataFiles = segmentFolder.listFiles(new FileFilter() {
1:       @Override public boolean accept(File pathname) {
1:         return pathname.getName().endsWith(CarbonCommonConstants.FACT_FILE_EXT);
1:       }
1:     });
1:     Assert.assertNotNull(dataFiles);
1:     Assert.assertEquals(1, dataFiles.length);
1: 
1:     FileUtils.deleteDirectory(new File(path));
1:   }
1: 
1:   @Test
1:   public void testWriteAllPrimitive() throws IOException {
0:     // TODO
1:   }
1: 
1:   @Test
1:   public void testWriteNestedRecord() throws IOException {
0:     // TODO
1:   }
1: 
1: }
============================================================================
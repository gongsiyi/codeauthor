1:707e258: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:707e258:  *
1:707e258:  *    http://www.apache.org/licenses/LICENSE-2.0
1:707e258:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
1:707e258:  */
4:707e258: 
1:707e258: package org.apache.carbondata.core.util;
1:707e258: 
1:956833e: import java.io.ByteArrayInputStream;
1:956833e: import java.io.DataInputStream;
1:956833e: import java.io.IOException;
1:956833e: import java.nio.ByteBuffer;
1:956833e: import java.util.ArrayList;
1:956833e: import java.util.Arrays;
1:956833e: import java.util.List;
1:707e258: 
1:daa6465: import org.apache.carbondata.core.datastore.FileReader;
1:956833e: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:ce09aaa: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:daa6465: import org.apache.carbondata.core.datastore.impl.FileReaderImpl;
1:956833e: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1:956833e: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1:956833e: import org.apache.carbondata.core.metadata.blocklet.SegmentInfo;
1:707e258: import org.apache.carbondata.core.reader.CarbonFooterReader;
1:707e258: import org.apache.carbondata.core.reader.CarbonIndexFileReader;
1:707e258: import org.apache.carbondata.core.reader.ThriftReader;
1:956833e: import org.apache.carbondata.format.BlockIndex;
1:956833e: import org.apache.carbondata.format.BlockletBTreeIndex;
1:956833e: import org.apache.carbondata.format.BlockletMinMaxIndex;
1:707e258: import org.apache.carbondata.format.ColumnSchema;
1:956833e: import org.apache.carbondata.format.DataType;
1:956833e: import org.apache.carbondata.format.Encoding;
1:956833e: import org.apache.carbondata.format.FileFooter;
1:956833e: import org.apache.carbondata.format.IndexHeader;
1:707e258: 
1:956833e: import mockit.Mock;
1:956833e: import mockit.MockUp;
1:8f1a029: import org.apache.hadoop.conf.Configuration;
1:707e258: import org.junit.Test;
1:707e258: 
1:956833e: import static junit.framework.TestCase.assertEquals;
1:707e258: 
1:707e258: public class DataFileFooterConverterTest {
1:707e258: 
1:707e258:   @Test public void testGetIndexInfo() throws Exception {
1:707e258:     DataFileFooterConverter dataFileFooterConverter = new DataFileFooterConverter();
1:707e258:     final ThriftReader thriftReader = new ThriftReader("file");
1:707e258:     List<Encoding> encoders = new ArrayList<>();
1:707e258:     encoders.add(Encoding.INVERTED_INDEX);
1:707e258:     encoders.add(Encoding.BIT_PACKED);
1:707e258:     encoders.add(Encoding.DELTA);
1:707e258:     encoders.add(Encoding.DICTIONARY);
1:707e258:     encoders.add(Encoding.DIRECT_DICTIONARY);
1:707e258:     encoders.add(Encoding.RLE);
1:707e258: 
1:707e258:     ColumnSchema columnSchema = new ColumnSchema(DataType.INT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema1 =
1:707e258:         new ColumnSchema(DataType.ARRAY, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema2 =
1:707e258:         new ColumnSchema(DataType.DECIMAL, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema3 =
1:707e258:         new ColumnSchema(DataType.DOUBLE, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema4 =
1:707e258:         new ColumnSchema(DataType.LONG, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema5 =
1:707e258:         new ColumnSchema(DataType.SHORT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema6 =
1:707e258:         new ColumnSchema(DataType.STRUCT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema7 =
1:707e258:         new ColumnSchema(DataType.STRING, "column", "3", true, encoders, true);
1:707e258: 
1:707e258:     final List<ColumnSchema> columnSchemas = new ArrayList<>();
1:707e258:     columnSchemas.add(columnSchema);
1:707e258:     columnSchemas.add(columnSchema1);
1:707e258:     columnSchemas.add(columnSchema2);
1:707e258:     columnSchemas.add(columnSchema3);
1:707e258:     columnSchemas.add(columnSchema4);
1:707e258:     columnSchemas.add(columnSchema5);
1:707e258:     columnSchemas.add(columnSchema6);
1:707e258:     columnSchemas.add(columnSchema7);
1:707e258: 
1:707e258:     final BlockIndex blockIndex = new BlockIndex();
1:707e258:     blockIndex.setBlock_index(new org.apache.carbondata.format.BlockletIndex());
1:707e258:     org.apache.carbondata.format.BlockletIndex blockletIndex1 =
1:707e258:         new org.apache.carbondata.format.BlockletIndex();
1:707e258:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:707e258:     blockletBTreeIndex.setStart_key("1".getBytes());
1:707e258:     blockletBTreeIndex.setEnd_key("3".getBytes());
1:707e258:     blockletIndex1.setB_tree_index(blockletBTreeIndex);
1:707e258:     BlockletMinMaxIndex blockletMinMaxIndex = new BlockletMinMaxIndex();
1:707e258:     blockletMinMaxIndex.setMax_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 2)));
1:707e258:     blockletMinMaxIndex.setMin_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 1)));
1:707e258:     blockletIndex1.setMin_max_index(blockletMinMaxIndex);
1:707e258:     blockIndex.setBlock_index(blockletIndex1);
1:707e258:     List<Integer> column_cardinalities = new ArrayList<>();
1:707e258:     column_cardinalities.add(new Integer("1"));
1:707e258:     final org.apache.carbondata.format.SegmentInfo segmentInfo1 =
1:707e258:         new org.apache.carbondata.format.SegmentInfo(3, column_cardinalities);
1:707e258:     new MockUp<CarbonIndexFileReader>() {
1:707e258:       boolean mockedHasNextStatus = true;
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock public boolean hasNext() throws IOException {
1:707e258:         boolean temp = mockedHasNextStatus;
1:707e258:         mockedHasNextStatus = false;
1:707e258:         return temp;
1:707e258:       }
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock public void openThriftReader(String filePath)
1:707e258:           throws IOException {
1:707e258:         thriftReader.open();
1:707e258:       }
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock public IndexHeader readIndexHeader() throws IOException {
1:707e258:         return new IndexHeader(1, columnSchemas, segmentInfo1);
1:707e258:       }
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock public BlockIndex readBlockIndexInfo() throws IOException {
1:707e258:         return blockIndex;
1:707e258:       }
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock public void closeThriftReader() {
1:707e258:         thriftReader.close();
1:707e258:       }
1:707e258:     };
1:707e258: 
1:707e258:     new MockUp<IndexHeader>() {
1:707e258:       @SuppressWarnings("unused") @Mock public List<ColumnSchema> getTable_columns() {
1:707e258:         return columnSchemas;
1:707e258:       }
1:707e258:     };
1:707e258:     ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream("1".getBytes());
1:707e258:     final DataInputStream dataInputStream = new DataInputStream(byteArrayInputStream);
1:707e258:     new MockUp<FileFactory>() {
1:707e258:       @SuppressWarnings("unused") @Mock
1:707e258:       public DataInputStream getDataInputStream(String path, FileFactory.FileType fileType,
1:8f1a029:           int bufferSize, Configuration configuration) {
1:707e258:         return dataInputStream;
1:707e258:       }
1:707e258:     };
1:707e258:     String[] arr = { "a", "b", "c" };
1:ae4a30c:     String fileName = "/part-0-0_batchno0-0-1495074251740.carbondata";
1:8a5ed81:     TableBlockInfo tableBlockInfo = new TableBlockInfo(fileName, 3, "id", arr, 3, ColumnarFormatVersion.V1, null);
1:707e258:     tableBlockInfo.getBlockletInfos().setNoOfBlockLets(3);
1:707e258:     List<TableBlockInfo> tableBlockInfoList = new ArrayList<>();
1:707e258:     tableBlockInfoList.add(tableBlockInfo);
1:ae4a30c:     String idxFileName = "0_batchno0-0-1495074251740.carbonindex";
1:707e258:     List<DataFileFooter> dataFileFooterList =
1:ae4a30c:         dataFileFooterConverter.getIndexInfo(idxFileName, tableBlockInfoList);
1:707e258:     byte[] exp = dataFileFooterList.get(0).getBlockletIndex().getBtreeIndex().getStartKey();
1:707e258:     byte[] res = "1".getBytes();
1:707e258:     for (int i = 0; i < exp.length; i++) {
1:707e258:       assertEquals(exp[i], res[i]);
1:707e258:     }
1:707e258: 
1:707e258:   }
1:707e258: 
1:707e258:   @Test public void testReadDataFileFooter() throws Exception {
1:707e258:     DataFileFooterConverter dataFileFooterConverter = new DataFileFooterConverter();
1:707e258:     DataFileFooter dataFileFooter = new DataFileFooter();
1:707e258:     List<Integer> column_cardinalities = new ArrayList<>();
1:707e258:     column_cardinalities.add(new Integer("1"));
1:707e258:     column_cardinalities.add(new Integer("2"));
1:707e258:     column_cardinalities.add(new Integer("3"));
1:707e258:     org.apache.carbondata.format.SegmentInfo segmentInfo1 =
1:707e258:         new org.apache.carbondata.format.SegmentInfo(3, column_cardinalities);
1:707e258:     List<Encoding> encoders = new ArrayList<>();
1:707e258:     encoders.add(Encoding.INVERTED_INDEX);
1:707e258:     encoders.add(Encoding.BIT_PACKED);
1:707e258:     encoders.add(Encoding.DELTA);
1:707e258:     encoders.add(Encoding.DICTIONARY);
1:707e258:     encoders.add(Encoding.DIRECT_DICTIONARY);
1:707e258:     encoders.add(Encoding.RLE);
1:707e258:     ColumnSchema columnSchema = new ColumnSchema(DataType.INT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema1 =
1:707e258:         new ColumnSchema(DataType.ARRAY, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema2 =
1:707e258:         new ColumnSchema(DataType.DECIMAL, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema3 =
1:707e258:         new ColumnSchema(DataType.DOUBLE, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema4 =
1:707e258:         new ColumnSchema(DataType.LONG, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema5 =
1:707e258:         new ColumnSchema(DataType.SHORT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema6 =
1:707e258:         new ColumnSchema(DataType.STRUCT, "column", "3", true, encoders, true);
1:707e258:     ColumnSchema columnSchema7 =
1:707e258:         new ColumnSchema(DataType.STRING, "column", "3", true, encoders, true);
1:707e258:     final List<ColumnSchema> columnSchemas = new ArrayList<>();
1:707e258:     columnSchemas.add(columnSchema);
1:707e258:     columnSchemas.add(columnSchema1);
1:707e258:     columnSchemas.add(columnSchema2);
1:707e258:     columnSchemas.add(columnSchema3);
1:707e258:     columnSchemas.add(columnSchema4);
1:707e258:     columnSchemas.add(columnSchema5);
1:707e258:     columnSchemas.add(columnSchema6);
1:707e258:     columnSchemas.add(columnSchema7);
1:707e258:     org.apache.carbondata.format.BlockletIndex blockletIndex1 =
1:707e258:         new org.apache.carbondata.format.BlockletIndex();
1:707e258:     List<org.apache.carbondata.format.BlockletIndex> blockletIndexArrayList = new ArrayList<>();
1:707e258:     blockletIndexArrayList.add(blockletIndex1);
1:707e258:     org.apache.carbondata.format.BlockletInfo blockletInfo =
1:707e258:         new org.apache.carbondata.format.BlockletInfo();
1:707e258:     List<org.apache.carbondata.format.BlockletInfo> blockletInfoArrayList = new ArrayList<>();
1:707e258:     blockletInfoArrayList.add(blockletInfo);
1:d54dc64:     final FileFooter fileFooter = 
1:d54dc64:         new FileFooter(1, 3, columnSchemas, segmentInfo1, blockletIndexArrayList);
1:d54dc64:     fileFooter.setBlocklet_info_list(blockletInfoArrayList);
1:707e258:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:707e258:     blockletBTreeIndex.setStart_key("1".getBytes());
1:707e258:     blockletBTreeIndex.setEnd_key("3".getBytes());
1:707e258:     blockletIndex1.setB_tree_index(blockletBTreeIndex);
1:707e258:     BlockletMinMaxIndex blockletMinMaxIndex = new BlockletMinMaxIndex();
1:707e258:     blockletMinMaxIndex.setMax_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 2)));
1:707e258:     blockletMinMaxIndex.setMin_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 1)));
1:707e258:     blockletIndex1.setMin_max_index(blockletMinMaxIndex);
1:707e258:     new MockUp<FileFactory>() {
1:707e258:       @SuppressWarnings("unused") @Mock public FileFactory.FileType getFileType(String path) {
1:707e258:         return FileFactory.FileType.LOCAL;
1:707e258:       }
1:707e258: 
1:707e258:       @SuppressWarnings("unused") @Mock
1:daa6465:       public FileReader getFileHolder(FileFactory.FileType fileType) {
1:daa6465:         return new FileReaderImpl();
1:707e258:       }
1:707e258: 
1:707e258:     };
1:707e258: 
1:daa6465:     new MockUp<FileReaderImpl>() {
1:707e258:       @SuppressWarnings("unused") @Mock public long readLong(String filePath, long offset) {
1:707e258:         return 1;
1:707e258:       }
1:707e258:     };
1:707e258: 
1:707e258:     new MockUp<CarbonFooterReader>() {
1:707e258:       @SuppressWarnings("unused") @Mock public FileFooter readFooter() throws IOException {
1:707e258:         return fileFooter;
1:707e258:       }
1:707e258:     };
1:707e258:     SegmentInfo segmentInfo = new SegmentInfo();
1:707e258:     int[] arr = { 1, 2, 3 };
1:707e258:     segmentInfo.setColumnCardinality(arr);
1:707e258:     dataFileFooter.setNumberOfRows(3);
1:707e258:     dataFileFooter.setSegmentInfo(segmentInfo);
1:8a5ed81:     TableBlockInfo info = new TableBlockInfo("/file.carbondata", 1, "0", new String[0], 1, ColumnarFormatVersion.V1, null);
1:d54dc64:     DataFileFooter result = dataFileFooterConverter.readDataFileFooter(info);
1:707e258:     assertEquals(result.getNumberOfRows(), 3);
1:707e258:   }
1:707e258: 
1:707e258: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
/////////////////////////////////////////////////////////////////////////
1:           int bufferSize, Configuration configuration) {
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.FileReader;
1: import org.apache.carbondata.core.datastore.impl.FileReaderImpl;
/////////////////////////////////////////////////////////////////////////
1:       public FileReader getFileHolder(FileFactory.FileType fileType) {
1:         return new FileReaderImpl();
1:     new MockUp<FileReaderImpl>() {
/////////////////////////////////////////////////////////////////////////
commit:956833e
/////////////////////////////////////////////////////////////////////////
1: import java.io.ByteArrayInputStream;
1: import java.io.DataInputStream;
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.util.ArrayList;
1: import java.util.Arrays;
1: import java.util.List;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1: import org.apache.carbondata.core.metadata.blocklet.SegmentInfo;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.format.BlockIndex;
1: import org.apache.carbondata.format.BlockletBTreeIndex;
1: import org.apache.carbondata.format.BlockletMinMaxIndex;
1: import org.apache.carbondata.format.DataType;
1: import org.apache.carbondata.format.Encoding;
1: import org.apache.carbondata.format.FileFooter;
1: import org.apache.carbondata.format.IndexHeader;
1: import mockit.Mock;
1: import mockit.MockUp;
1: import static junit.framework.TestCase.assertEquals;
author:xubo245
-------------------------------------------------------------------------------
commit:15f04c3
/////////////////////////////////////////////////////////////////////////
author:kumarvishal
-------------------------------------------------------------------------------
commit:8a5ed81
/////////////////////////////////////////////////////////////////////////
1:     TableBlockInfo tableBlockInfo = new TableBlockInfo(fileName, 3, "id", arr, 3, ColumnarFormatVersion.V1, null);
/////////////////////////////////////////////////////////////////////////
1:     TableBlockInfo info = new TableBlockInfo("/file.carbondata", 1, "0", new String[0], 1, ColumnarFormatVersion.V1, null);
commit:d54dc64
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo("file", 3, "id", arr, 3, (short) 1);
/////////////////////////////////////////////////////////////////////////
1:     final FileFooter fileFooter = 
1:         new FileFooter(1, 3, columnSchemas, segmentInfo1, blockletIndexArrayList);
1:     fileFooter.setBlocklet_info_list(blockletInfoArrayList);
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo info = new TableBlockInfo("file", 1, "0", new String[0], 1, (short)1);
1:     DataFileFooter result = dataFileFooterConverter.readDataFileFooter(info);
author:Sephiroth-Lin
-------------------------------------------------------------------------------
commit:ae4a30c
/////////////////////////////////////////////////////////////////////////
1:     String fileName = "/part-0-0_batchno0-0-1495074251740.carbondata";
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo(fileName, 3, "id", arr, 3, ColumnarFormatVersion.V1);
1:     String idxFileName = "0_batchno0-0-1495074251740.carbonindex";
1:         dataFileFooterConverter.getIndexInfo(idxFileName, tableBlockInfoList);
author:QiangCai
-------------------------------------------------------------------------------
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:jackylk
-------------------------------------------------------------------------------
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
0: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
0: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
0: import org.apache.carbondata.core.metadata.blocklet.SegmentInfo;
0: import org.apache.carbondata.core.datastore.FileHolder;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
0: import org.apache.carbondata.core.datastore.impl.FileHolderImpl;
commit:0ef3fb8
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.carbon.ColumnarFormatVersion;
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo("file", 3, "id", arr, 3, ColumnarFormatVersion.V1);
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo info = new TableBlockInfo("file", 1, "0", new String[0], 1, ColumnarFormatVersion.V1);
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:b6ab4ef
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo("/file.carbondata", 3, "id", arr, 3, ColumnarFormatVersion.V1);
/////////////////////////////////////////////////////////////////////////
0:     TableBlockInfo info = new TableBlockInfo("/file.carbondata", 1, "0", new String[0], 1, ColumnarFormatVersion.V1);
author:abhishek
-------------------------------------------------------------------------------
commit:707e258
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
1: package org.apache.carbondata.core.util;
1: 
0: import mockit.Mock;
0: import mockit.MockUp;
1: 
0: import org.apache.carbondata.core.carbon.datastore.block.BlockInfo;
0: import org.apache.carbondata.core.carbon.datastore.block.TableBlockInfo;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.BlockletInfo;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.DataFileFooter;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.SegmentInfo;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.index.BlockletIndex;
0: import org.apache.carbondata.core.carbon.metadata.schema.table.column.*;
0: import org.apache.carbondata.core.datastorage.store.FileHolder;
0: import org.apache.carbondata.core.datastorage.store.impl.FileFactory;
0: import org.apache.carbondata.core.datastorage.store.impl.FileHolderImpl;
1: import org.apache.carbondata.core.reader.CarbonFooterReader;
1: import org.apache.carbondata.core.reader.CarbonIndexFileReader;
1: import org.apache.carbondata.core.reader.ThriftReader;
0: import org.apache.carbondata.format.*;
1: import org.apache.carbondata.format.ColumnSchema;
1: 
0: import org.junit.AfterClass;
0: import org.junit.BeforeClass;
1: import org.junit.Test;
1: 
0: import java.lang.reflect.Method;
0: import java.nio.ByteBuffer;
0: import java.util.ArrayList;
0: import java.util.List;
1: 
0: import org.apache.carbondata.core.util.DataFileFooterConverter.*;
1: 
0: import java.io.*;
0: import java.util.*;
1: 
0: import static junit.framework.TestCase.*;
1: 
1: public class DataFileFooterConverterTest {
1: 
1:   @Test public void testGetIndexInfo() throws Exception {
1:     DataFileFooterConverter dataFileFooterConverter = new DataFileFooterConverter();
1:     final ThriftReader thriftReader = new ThriftReader("file");
1:     List<Encoding> encoders = new ArrayList<>();
1:     encoders.add(Encoding.INVERTED_INDEX);
1:     encoders.add(Encoding.BIT_PACKED);
1:     encoders.add(Encoding.DELTA);
1:     encoders.add(Encoding.DICTIONARY);
1:     encoders.add(Encoding.DIRECT_DICTIONARY);
1:     encoders.add(Encoding.RLE);
1: 
1:     ColumnSchema columnSchema = new ColumnSchema(DataType.INT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema1 =
1:         new ColumnSchema(DataType.ARRAY, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema2 =
1:         new ColumnSchema(DataType.DECIMAL, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema3 =
1:         new ColumnSchema(DataType.DOUBLE, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema4 =
1:         new ColumnSchema(DataType.LONG, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema5 =
1:         new ColumnSchema(DataType.SHORT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema6 =
1:         new ColumnSchema(DataType.STRUCT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema7 =
1:         new ColumnSchema(DataType.STRING, "column", "3", true, encoders, true);
1: 
1:     final List<ColumnSchema> columnSchemas = new ArrayList<>();
1:     columnSchemas.add(columnSchema);
1:     columnSchemas.add(columnSchema1);
1:     columnSchemas.add(columnSchema2);
1:     columnSchemas.add(columnSchema3);
1:     columnSchemas.add(columnSchema4);
1:     columnSchemas.add(columnSchema5);
1:     columnSchemas.add(columnSchema6);
1:     columnSchemas.add(columnSchema7);
1: 
1:     final BlockIndex blockIndex = new BlockIndex();
1:     blockIndex.setBlock_index(new org.apache.carbondata.format.BlockletIndex());
1:     org.apache.carbondata.format.BlockletIndex blockletIndex1 =
1:         new org.apache.carbondata.format.BlockletIndex();
1:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:     blockletBTreeIndex.setStart_key("1".getBytes());
1:     blockletBTreeIndex.setEnd_key("3".getBytes());
1:     blockletIndex1.setB_tree_index(blockletBTreeIndex);
1:     BlockletMinMaxIndex blockletMinMaxIndex = new BlockletMinMaxIndex();
1:     blockletMinMaxIndex.setMax_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 2)));
1:     blockletMinMaxIndex.setMin_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 1)));
1:     blockletIndex1.setMin_max_index(blockletMinMaxIndex);
1:     blockIndex.setBlock_index(blockletIndex1);
1:     List<Integer> column_cardinalities = new ArrayList<>();
1:     column_cardinalities.add(new Integer("1"));
1:     final org.apache.carbondata.format.SegmentInfo segmentInfo1 =
1:         new org.apache.carbondata.format.SegmentInfo(3, column_cardinalities);
1:     new MockUp<CarbonIndexFileReader>() {
1:       boolean mockedHasNextStatus = true;
1: 
1:       @SuppressWarnings("unused") @Mock public boolean hasNext() throws IOException {
1:         boolean temp = mockedHasNextStatus;
1:         mockedHasNextStatus = false;
1:         return temp;
1:       }
1: 
1:       @SuppressWarnings("unused") @Mock public void openThriftReader(String filePath)
1:           throws IOException {
1:         thriftReader.open();
1:       }
1: 
1:       @SuppressWarnings("unused") @Mock public IndexHeader readIndexHeader() throws IOException {
1:         return new IndexHeader(1, columnSchemas, segmentInfo1);
1:       }
1: 
1:       @SuppressWarnings("unused") @Mock public BlockIndex readBlockIndexInfo() throws IOException {
1:         return blockIndex;
1:       }
1: 
1:       @SuppressWarnings("unused") @Mock public void closeThriftReader() {
1:         thriftReader.close();
1:       }
1:     };
1: 
1:     new MockUp<IndexHeader>() {
1:       @SuppressWarnings("unused") @Mock public List<ColumnSchema> getTable_columns() {
1:         return columnSchemas;
1:       }
1:     };
1:     ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream("1".getBytes());
1:     final DataInputStream dataInputStream = new DataInputStream(byteArrayInputStream);
1:     new MockUp<FileFactory>() {
1:       @SuppressWarnings("unused") @Mock
1:       public DataInputStream getDataInputStream(String path, FileFactory.FileType fileType,
0:           int bufferSize) {
1:         return dataInputStream;
1:       }
1:     };
1:     String[] arr = { "a", "b", "c" };
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo("file", 3, "id", arr, 3);
1:     tableBlockInfo.getBlockletInfos().setNoOfBlockLets(3);
1:     List<TableBlockInfo> tableBlockInfoList = new ArrayList<>();
1:     tableBlockInfoList.add(tableBlockInfo);
1:     List<DataFileFooter> dataFileFooterList =
0:         dataFileFooterConverter.getIndexInfo("indexfile", tableBlockInfoList);
1:     byte[] exp = dataFileFooterList.get(0).getBlockletIndex().getBtreeIndex().getStartKey();
1:     byte[] res = "1".getBytes();
1:     for (int i = 0; i < exp.length; i++) {
1:       assertEquals(exp[i], res[i]);
1:     }
1: 
1:   }
1: 
1:   @Test public void testReadDataFileFooter() throws Exception {
1:     DataFileFooterConverter dataFileFooterConverter = new DataFileFooterConverter();
1:     DataFileFooter dataFileFooter = new DataFileFooter();
1:     List<Integer> column_cardinalities = new ArrayList<>();
1:     column_cardinalities.add(new Integer("1"));
1:     column_cardinalities.add(new Integer("2"));
1:     column_cardinalities.add(new Integer("3"));
1:     org.apache.carbondata.format.SegmentInfo segmentInfo1 =
1:         new org.apache.carbondata.format.SegmentInfo(3, column_cardinalities);
1:     List<Encoding> encoders = new ArrayList<>();
1:     encoders.add(Encoding.INVERTED_INDEX);
1:     encoders.add(Encoding.BIT_PACKED);
1:     encoders.add(Encoding.DELTA);
1:     encoders.add(Encoding.DICTIONARY);
1:     encoders.add(Encoding.DIRECT_DICTIONARY);
1:     encoders.add(Encoding.RLE);
1:     ColumnSchema columnSchema = new ColumnSchema(DataType.INT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema1 =
1:         new ColumnSchema(DataType.ARRAY, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema2 =
1:         new ColumnSchema(DataType.DECIMAL, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema3 =
1:         new ColumnSchema(DataType.DOUBLE, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema4 =
1:         new ColumnSchema(DataType.LONG, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema5 =
1:         new ColumnSchema(DataType.SHORT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema6 =
1:         new ColumnSchema(DataType.STRUCT, "column", "3", true, encoders, true);
1:     ColumnSchema columnSchema7 =
1:         new ColumnSchema(DataType.STRING, "column", "3", true, encoders, true);
1:     final List<ColumnSchema> columnSchemas = new ArrayList<>();
1:     columnSchemas.add(columnSchema);
1:     columnSchemas.add(columnSchema1);
1:     columnSchemas.add(columnSchema2);
1:     columnSchemas.add(columnSchema3);
1:     columnSchemas.add(columnSchema4);
1:     columnSchemas.add(columnSchema5);
1:     columnSchemas.add(columnSchema6);
1:     columnSchemas.add(columnSchema7);
1:     org.apache.carbondata.format.BlockletIndex blockletIndex1 =
1:         new org.apache.carbondata.format.BlockletIndex();
1:     List<org.apache.carbondata.format.BlockletIndex> blockletIndexArrayList = new ArrayList<>();
1:     blockletIndexArrayList.add(blockletIndex1);
1:     org.apache.carbondata.format.BlockletInfo blockletInfo =
1:         new org.apache.carbondata.format.BlockletInfo();
1:     List<org.apache.carbondata.format.BlockletInfo> blockletInfoArrayList = new ArrayList<>();
1:     blockletInfoArrayList.add(blockletInfo);
0:     final FileFooter fileFooter =
0:         new FileFooter(1, 3, columnSchemas, segmentInfo1, blockletIndexArrayList,
0:             blockletInfoArrayList);
1:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:     blockletBTreeIndex.setStart_key("1".getBytes());
1:     blockletBTreeIndex.setEnd_key("3".getBytes());
1:     blockletIndex1.setB_tree_index(blockletBTreeIndex);
1:     BlockletMinMaxIndex blockletMinMaxIndex = new BlockletMinMaxIndex();
1:     blockletMinMaxIndex.setMax_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 2)));
1:     blockletMinMaxIndex.setMin_values(Arrays.asList(ByteBuffer.allocate(1).put((byte) 1)));
1:     blockletIndex1.setMin_max_index(blockletMinMaxIndex);
1:     new MockUp<FileFactory>() {
1:       @SuppressWarnings("unused") @Mock public FileFactory.FileType getFileType(String path) {
1:         return FileFactory.FileType.LOCAL;
1:       }
1: 
1:       @SuppressWarnings("unused") @Mock
0:       public FileHolder getFileHolder(FileFactory.FileType fileType) {
0:         return new FileHolderImpl();
1:       }
1: 
1:     };
1: 
0:     new MockUp<FileHolderImpl>() {
1:       @SuppressWarnings("unused") @Mock public long readLong(String filePath, long offset) {
1:         return 1;
1:       }
1:     };
1: 
1:     new MockUp<CarbonFooterReader>() {
1:       @SuppressWarnings("unused") @Mock public FileFooter readFooter() throws IOException {
1:         return fileFooter;
1:       }
1:     };
1:     SegmentInfo segmentInfo = new SegmentInfo();
1:     int[] arr = { 1, 2, 3 };
1:     segmentInfo.setColumnCardinality(arr);
0:     segmentInfo.setNumberOfColumns(segmentInfo1.getNum_cols());
1:     dataFileFooter.setNumberOfRows(3);
1:     dataFileFooter.setSegmentInfo(segmentInfo);
0:     DataFileFooter result = dataFileFooterConverter.readDataFileFooter("file", 1, 1);
1:     assertEquals(result.getNumberOfRows(), 3);
1:   }
1: 
1: }
============================================================================
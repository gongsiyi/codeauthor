1:cbe1419: /*
1:cbe1419:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:cbe1419:  * contributor license agreements.  See the NOTICE file distributed with
1:cbe1419:  * this work for additional information regarding copyright ownership.
1:cbe1419:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:cbe1419:  * (the "License"); you may not use this file except in compliance with
1:cbe1419:  * the License.  You may obtain a copy of the License at
2:cbe1419:  *
1:cbe1419:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cbe1419:  *
1:cbe1419:  * Unless required by applicable law or agreed to in writing, software
1:cbe1419:  * distributed under the License is distributed on an "AS IS" BASIS,
1:cbe1419:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:cbe1419:  * See the License for the specific language governing permissions and
1:cbe1419:  * limitations under the License.
2:cbe1419:  */
1:cbe1419: package org.apache.carbondata.hive;
5:cbe1419: 
1:cbe1419: import java.io.IOException;
1:cbe1419: import java.sql.Date;
1:cbe1419: import java.sql.Timestamp;
1:cbe1419: import java.util.ArrayList;
1:c257468: import java.util.Calendar;
1:cbe1419: import java.util.List;
1:cbe1419: 
1:cbe1419: import org.apache.carbondata.core.cache.Cache;
1:cbe1419: import org.apache.carbondata.core.cache.CacheProvider;
1:cbe1419: import org.apache.carbondata.core.cache.CacheType;
1:cbe1419: import org.apache.carbondata.core.cache.dictionary.Dictionary;
1:cbe1419: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
1:29dc302: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:cbe1419: import org.apache.carbondata.core.metadata.datatype.DataType;
1:956833e: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:cbe1419: import org.apache.carbondata.core.metadata.encoder.Encoding;
1:29dc302: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:cbe1419: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:cbe1419: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
1:cbe1419: import org.apache.carbondata.core.util.CarbonUtil;
1:cbe1419: import org.apache.carbondata.hadoop.readsupport.CarbonReadSupport;
1:cbe1419: 
1:cbe1419: import org.apache.hadoop.hive.common.type.HiveDecimal;
1:cbe1419: import org.apache.hadoop.hive.serde2.io.DateWritable;
1:cbe1419: import org.apache.hadoop.hive.serde2.io.DoubleWritable;
1:cbe1419: import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
1:cbe1419: import org.apache.hadoop.hive.serde2.io.ShortWritable;
1:cbe1419: import org.apache.hadoop.hive.serde2.io.TimestampWritable;
1:cbe1419: import org.apache.hadoop.io.ArrayWritable;
1:cbe1419: import org.apache.hadoop.io.IntWritable;
1:cbe1419: import org.apache.hadoop.io.LongWritable;
1:cbe1419: import org.apache.hadoop.io.Text;
1:cbe1419: import org.apache.hadoop.io.Writable;
1:cbe1419: import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;
1:cbe1419: import org.apache.spark.sql.catalyst.util.GenericArrayData;
1:cbe1419: 
2:cbe1419: /**
1:01492fc:  * This is the class to decode dictionary encoded column data back to its original value.
1:cbe1419:  */
1:cbe1419: public class CarbonDictionaryDecodeReadSupport<T> implements CarbonReadSupport<T> {
1:cbe1419: 
1:cbe1419:   protected Dictionary[] dictionaries;
1:cbe1419: 
1:cbe1419:   protected DataType[] dataTypes;
1:cbe1419:   /**
1:cbe1419:    * carbon columns
1:cbe1419:    */
1:cbe1419:   protected CarbonColumn[] carbonColumns;
1:cbe1419: 
1:cbe1419:   protected Writable[] writableArr;
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * This initialization is done inside executor task
1:cbe1419:    * for column dictionary involved in decoding.
1:cbe1419:    *
1:cbe1419:    * @param carbonColumns           column list
1:29dc302:    * @param carbonTable table identifier
1:cbe1419:    */
1:cbe1419:   @Override public void initialize(CarbonColumn[] carbonColumns,
1:29dc302:       CarbonTable carbonTable) throws IOException {
1:cbe1419:     this.carbonColumns = carbonColumns;
1:cbe1419:     dictionaries = new Dictionary[carbonColumns.length];
1:cbe1419:     dataTypes = new DataType[carbonColumns.length];
1:cbe1419:     for (int i = 0; i < carbonColumns.length; i++) {
1:cbe1419:       if (carbonColumns[i].hasEncoding(Encoding.DICTIONARY) && !carbonColumns[i]
1:cbe1419:           .hasEncoding(Encoding.DIRECT_DICTIONARY) && !carbonColumns[i].isComplex()) {
1:cbe1419:         CacheProvider cacheProvider = CacheProvider.getInstance();
1:cbe1419:         Cache<DictionaryColumnUniqueIdentifier, Dictionary> forwardDictionaryCache = cacheProvider
1:1155d4d:             .createCache(CacheType.FORWARD_DICTIONARY);
1:cbe1419:         dataTypes[i] = carbonColumns[i].getDataType();
1:29dc302:         String dictionaryPath = carbonTable.getTableInfo().getFactTable().getTableProperties()
1:29dc302:             .get(CarbonCommonConstants.DICTIONARY_PATH);
1:cbe1419:         dictionaries[i] = forwardDictionaryCache.get(
1:29dc302:             new DictionaryColumnUniqueIdentifier(carbonTable.getAbsoluteTableIdentifier(),
1:29dc302:                 carbonColumns[i].getColumnIdentifier(), dataTypes[i], dictionaryPath));
1:cbe1419:       } else {
1:cbe1419:         dataTypes[i] = carbonColumns[i].getDataType();
4:cbe1419:       }
1:cbe1419:     }
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   @Override public T readRow(Object[] data) {
1:cbe1419:     assert (data.length == dictionaries.length);
1:cbe1419:     writableArr = new Writable[data.length];
1:cbe1419:     for (int i = 0; i < dictionaries.length; i++) {
1:cbe1419:       if (dictionaries[i] != null) {
1:cbe1419:         data[i] = dictionaries[i].getDictionaryValueForKey((int) data[i]);
1:cbe1419:       }
1:cbe1419:       try {
1:cbe1419:         writableArr[i] = createWritableObject(data[i], carbonColumns[i]);
1:cbe1419:       } catch (IOException e) {
1:cbe1419:         throw new RuntimeException(e.getMessage(), e);
1:cbe1419:       }
1:cbe1419:     }
1:cbe1419: 
1:cbe1419:     return (T) writableArr;
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * to book keep the dictionary cache or update access count for each
1:cbe1419:    * column involved during decode, to facilitate LRU cache policy if memory
1:cbe1419:    * threshold is reached
1:cbe1419:    */
1:cbe1419:   @Override public void close() {
1:cbe1419:     if (dictionaries == null) {
1:cbe1419:       return;
1:cbe1419:     }
1:cbe1419:     for (int i = 0; i < dictionaries.length; i++) {
1:cbe1419:       CarbonUtil.clearDictionaryCache(dictionaries[i]);
1:cbe1419:     }
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * To Create the Writable from the CarbonData data
1:cbe1419:    *
2:cbe1419:    * @param obj
2:cbe1419:    * @param carbonColumn
1:cbe1419:    * @return
2:cbe1419:    * @throws IOException
1:cbe1419:    */
1:cbe1419:   private Writable createWritableObject(Object obj, CarbonColumn carbonColumn) throws IOException {
2:cbe1419:     DataType dataType = carbonColumn.getDataType();
1:933e30c:     if (DataTypes.isStructType(dataType)) {
1:956833e:       return createStruct(obj, carbonColumn);
1:933e30c:     } else if (DataTypes.isArrayType(dataType)) {
1:956833e:       return createArray(obj, carbonColumn);
1:956833e:     } else {
1:956833e:       return createWritablePrimitive(obj, carbonColumn);
1:cbe1419:     }
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * Create Array Data for Array Datatype
1:cbe1419:    *
1:cbe1419:    * @param obj
1:cbe1419:    * @param carbonColumn
1:cbe1419:    * @return
1:cbe1419:    * @throws IOException
1:cbe1419:    */
1:cbe1419:   private ArrayWritable createArray(Object obj, CarbonColumn carbonColumn) throws IOException {
1:cbe1419:     if (obj instanceof GenericArrayData) {
1:cbe1419:       Object[] objArray = ((GenericArrayData) obj).array();
1:cbe1419:       List<CarbonDimension> childCarbonDimensions = null;
1:cbe1419:       CarbonDimension arrayDimension = null;
1:cbe1419:       if (carbonColumn.isDimension() && carbonColumn.getColumnSchema().getNumberOfChild() > 0) {
1:cbe1419:         childCarbonDimensions = ((CarbonDimension) carbonColumn).getListOfChildDimensions();
1:cbe1419:         arrayDimension = childCarbonDimensions.get(0);
1:cbe1419:       }
1:cbe1419:       List array = new ArrayList();
1:cbe1419:       if (objArray != null) {
2:cbe1419:         for (int i = 0; i < objArray.length; i++) {
1:cbe1419:           Object curObj = objArray[i];
1:cbe1419:           Writable newObj = createWritableObject(curObj, arrayDimension);
1:cbe1419:           array.add(newObj);
1:cbe1419:         }
1:cbe1419:       }
1:cbe1419:       if (array.size() > 0) {
1:cbe1419:         ArrayWritable subArray = new ArrayWritable(Writable.class,
1:cbe1419:             (Writable[]) array.toArray(new Writable[array.size()]));
1:cbe1419:         return new ArrayWritable(Writable.class, new Writable[] { subArray });
1:cbe1419:       }
1:cbe1419:     }
2:cbe1419:     return null;
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * Create the Struct data for the Struct Datatype
1:cbe1419:    *
1:cbe1419:    * @param obj
1:cbe1419:    * @param carbonColumn
1:cbe1419:    * @return
1:cbe1419:    * @throws IOException
1:cbe1419:    */
1:cbe1419:   private ArrayWritable createStruct(Object obj, CarbonColumn carbonColumn) throws IOException {
1:cbe1419:     if (obj instanceof GenericInternalRow) {
1:cbe1419:       Object[] objArray = ((GenericInternalRow) obj).values();
1:cbe1419:       List<CarbonDimension> childCarbonDimensions = null;
1:cbe1419:       if (carbonColumn.isDimension() && carbonColumn.getColumnSchema().getNumberOfChild() > 0) {
1:cbe1419:         childCarbonDimensions = ((CarbonDimension) carbonColumn).getListOfChildDimensions();
1:cbe1419:       }
1:cbe1419: 
1:7ef9164:       if (null != childCarbonDimensions) {
1:7ef9164:         Writable[] arr = new Writable[objArray.length];
1:7ef9164:         for (int i = 0; i < objArray.length; i++) {
1:7ef9164: 
1:7ef9164:           arr[i] = createWritableObject(objArray[i], childCarbonDimensions.get(i));
1:7ef9164:         }
1:7ef9164:         return new ArrayWritable(Writable.class, arr);
1:cbe1419:       }
1:cbe1419:     }
1:cbe1419:     throw new IOException("DataType not supported in Carbondata");
1:cbe1419:   }
1:cbe1419: 
1:cbe1419:   /**
1:cbe1419:    * This method will create the Writable Objects for primitives.
1:cbe1419:    *
1:cbe1419:    * @param obj
1:cbe1419:    * @param carbonColumn
1:cbe1419:    * @return
1:cbe1419:    * @throws IOException
1:cbe1419:    */
1:cbe1419:   private Writable createWritablePrimitive(Object obj, CarbonColumn carbonColumn)
2:cbe1419:       throws IOException {
1:cbe1419:     DataType dataType = carbonColumn.getDataType();
2:cbe1419:     if (obj == null) {
1:cbe1419:       return null;
1:cbe1419:     }
1:956833e:     if (dataType == DataTypes.NULL) {
1:956833e:       return null;
1:956833e:     } else if (dataType == DataTypes.DOUBLE) {
1:956833e:       return new DoubleWritable((double) obj);
1:956833e:     } else if (dataType == DataTypes.INT) {
1:956833e:       return new IntWritable((int) obj);
1:956833e:     } else if (dataType == DataTypes.LONG) {
1:956833e:       return new LongWritable((long) obj);
1:956833e:     } else if (dataType == DataTypes.SHORT) {
1:956833e:       return new ShortWritable((short) obj);
1:956833e:     } else if (dataType == DataTypes.DATE) {
1:956833e:       Calendar c = Calendar.getInstance();
1:956833e:       c.setTime(new Date(0));
1:956833e:       c.add(Calendar.DAY_OF_YEAR, (Integer) obj);
1:956833e:       Date date = new java.sql.Date(c.getTime().getTime());
1:956833e:       return new DateWritable(date);
1:956833e:     } else if (dataType == DataTypes.TIMESTAMP) {
1:956833e:       return new TimestampWritable(new Timestamp((long) obj / 1000));
1:956833e:     } else if (dataType == DataTypes.STRING) {
1:956833e:       return new Text(obj.toString());
1:f209e8e:     } else if (DataTypes.isDecimal(dataType)) {
1:956833e:       return new HiveDecimalWritable(HiveDecimal.create(new java.math.BigDecimal(obj.toString())));
1:956833e:     } else {
1:2d24e18:       throw new IOException("unsupported data type:" + dataType);
1:cbe1419:     }
1:cbe1419:   }
1:cbe1419: 
1:cbe1419: }
============================================================================
author:Raghunandan S
-------------------------------------------------------------------------------
commit:7ef9164
/////////////////////////////////////////////////////////////////////////
1:       if (null != childCarbonDimensions) {
1:         Writable[] arr = new Writable[objArray.length];
1:         for (int i = 0; i < objArray.length; i++) {
1: 
1:           arr[i] = createWritableObject(objArray[i], childCarbonDimensions.get(i));
1:         }
1:         return new ArrayWritable(Writable.class, arr);
commit:2d24e18
/////////////////////////////////////////////////////////////////////////
0:         return new DateWritable(new Date((long) obj));
/////////////////////////////////////////////////////////////////////////
0:       default:
1:         throw new IOException("unsupported data type:" + dataType);
/////////////////////////////////////////////////////////////////////////
0:         break;
0:       default:
0:         throw new IOException("unsupported data type:" + dataType);
author:manishgupta88
-------------------------------------------------------------------------------
commit:29dc302
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
/////////////////////////////////////////////////////////////////////////
1:    * @param carbonTable table identifier
1:       CarbonTable carbonTable) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:         String dictionaryPath = carbonTable.getTableInfo().getFactTable().getTableProperties()
1:             .get(CarbonCommonConstants.DICTIONARY_PATH);
1:             new DictionaryColumnUniqueIdentifier(carbonTable.getAbsoluteTableIdentifier(),
1:                 carbonColumns[i].getColumnIdentifier(), dataTypes[i], dictionaryPath));
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:1155d4d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             .createCache(CacheType.FORWARD_DICTIONARY);
0:             new DictionaryColumnUniqueIdentifier(absoluteTableIdentifier,
0:                 carbonColumns[i].getColumnIdentifier()));
author:Jacky Li
-------------------------------------------------------------------------------
commit:933e30c
/////////////////////////////////////////////////////////////////////////
1:     if (DataTypes.isStructType(dataType)) {
1:     } else if (DataTypes.isArrayType(dataType)) {
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
1:     } else if (DataTypes.isDecimal(dataType)) {
commit:956833e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:     if (dataType == DataTypes.STRUCT) {
1:       return createStruct(obj, carbonColumn);
0:     } else if (dataType == DataTypes.ARRAY) {
1:       return createArray(obj, carbonColumn);
1:     } else {
1:       return createWritablePrimitive(obj, carbonColumn);
/////////////////////////////////////////////////////////////////////////
1:     if (dataType == DataTypes.NULL) {
1:       return null;
1:     } else if (dataType == DataTypes.DOUBLE) {
1:       return new DoubleWritable((double) obj);
1:     } else if (dataType == DataTypes.INT) {
1:       return new IntWritable((int) obj);
1:     } else if (dataType == DataTypes.LONG) {
1:       return new LongWritable((long) obj);
1:     } else if (dataType == DataTypes.SHORT) {
1:       return new ShortWritable((short) obj);
1:     } else if (dataType == DataTypes.DATE) {
1:       Calendar c = Calendar.getInstance();
1:       c.setTime(new Date(0));
1:       c.add(Calendar.DAY_OF_YEAR, (Integer) obj);
1:       Date date = new java.sql.Date(c.getTime().getTime());
1:       return new DateWritable(date);
1:     } else if (dataType == DataTypes.TIMESTAMP) {
1:       return new TimestampWritable(new Timestamp((long) obj / 1000));
1:     } else if (dataType == DataTypes.STRING) {
1:       return new Text(obj.toString());
0:     } else if (dataType == DataTypes.DECIMAL) {
1:       return new HiveDecimalWritable(HiveDecimal.create(new java.math.BigDecimal(obj.toString())));
1:     } else {
0:       throw new IOException("unsupported data type:" + dataType);
author:anubhav100
-------------------------------------------------------------------------------
commit:c257468
/////////////////////////////////////////////////////////////////////////
1: import java.util.Calendar;
/////////////////////////////////////////////////////////////////////////
0:         return new ShortWritable((short) obj);
0:         Calendar c = Calendar.getInstance();
0:         c.setTime(new Date(0));
0:         c.add(Calendar.DAY_OF_YEAR, (Integer) obj);
0:         Date date = new java.sql.Date(c.getTime().getTime());
0:         return new DateWritable(date);
commit:01492fc
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:  * This is the class to decode dictionary encoded column data back to its original value.
/////////////////////////////////////////////////////////////////////////
0:         return new DateWritable(new Date((Integer) obj));
0:         return new TimestampWritable(new Timestamp((long) obj / 1000));
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:590bbb9
/////////////////////////////////////////////////////////////////////////
0:         return new DateWritable(new Date(((Integer) obj).longValue()));
author:dhatchayani
-------------------------------------------------------------------------------
commit:d3a09e2
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.path.CarbonStorePath;
/////////////////////////////////////////////////////////////////////////
0:                 carbonColumns[i].getColumnIdentifier(), dataTypes[i],
0:                 CarbonStorePath.getCarbonTablePath(absoluteTableIdentifier)));
author:Bhavya
-------------------------------------------------------------------------------
commit:cbe1419
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.hive;
1: 
1: import java.io.IOException;
1: import java.sql.Date;
1: import java.sql.Timestamp;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.core.cache.Cache;
1: import org.apache.carbondata.core.cache.CacheProvider;
1: import org.apache.carbondata.core.cache.CacheType;
1: import org.apache.carbondata.core.cache.dictionary.Dictionary;
1: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
0: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.encoder.Encoding;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: 
1: import org.apache.carbondata.hadoop.readsupport.CarbonReadSupport;
1: 
1: import org.apache.hadoop.hive.common.type.HiveDecimal;
1: import org.apache.hadoop.hive.serde2.io.DateWritable;
1: import org.apache.hadoop.hive.serde2.io.DoubleWritable;
1: import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;
1: import org.apache.hadoop.hive.serde2.io.ShortWritable;
1: import org.apache.hadoop.hive.serde2.io.TimestampWritable;
1: 
1: import org.apache.hadoop.io.ArrayWritable;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.LongWritable;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.io.Writable;
1: 
1: import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;
1: import org.apache.spark.sql.catalyst.util.GenericArrayData;
1: 
1: /**
0:  *  This is the class to decode dictionary encoded column data back to its original value.
1:  */
1: public class CarbonDictionaryDecodeReadSupport<T> implements CarbonReadSupport<T> {
1: 
1:   protected Dictionary[] dictionaries;
1: 
1:   protected DataType[] dataTypes;
1:   /**
1:    * carbon columns
1:    */
1:   protected CarbonColumn[] carbonColumns;
1: 
1:   protected Writable[] writableArr;
1: 
1:   /**
1:    * This initialization is done inside executor task
1:    * for column dictionary involved in decoding.
1:    *
1:    * @param carbonColumns           column list
0:    * @param absoluteTableIdentifier table identifier
1:    */
1:   @Override public void initialize(CarbonColumn[] carbonColumns,
0:       AbsoluteTableIdentifier absoluteTableIdentifier) throws IOException {
1:     this.carbonColumns = carbonColumns;
1:     dictionaries = new Dictionary[carbonColumns.length];
1:     dataTypes = new DataType[carbonColumns.length];
1:     for (int i = 0; i < carbonColumns.length; i++) {
1:       if (carbonColumns[i].hasEncoding(Encoding.DICTIONARY) && !carbonColumns[i]
1:           .hasEncoding(Encoding.DIRECT_DICTIONARY) && !carbonColumns[i].isComplex()) {
1:         CacheProvider cacheProvider = CacheProvider.getInstance();
1:         Cache<DictionaryColumnUniqueIdentifier, Dictionary> forwardDictionaryCache = cacheProvider
0:             .createCache(CacheType.FORWARD_DICTIONARY, absoluteTableIdentifier.getStorePath());
1:         dataTypes[i] = carbonColumns[i].getDataType();
1:         dictionaries[i] = forwardDictionaryCache.get(
0:             new DictionaryColumnUniqueIdentifier(absoluteTableIdentifier.getCarbonTableIdentifier(),
0:                 carbonColumns[i].getColumnIdentifier(), dataTypes[i]));
1:       } else {
1:         dataTypes[i] = carbonColumns[i].getDataType();
1:       }
1:     }
1:   }
1: 
1:   @Override public T readRow(Object[] data) {
1:     assert (data.length == dictionaries.length);
1:     writableArr = new Writable[data.length];
1:     for (int i = 0; i < dictionaries.length; i++) {
1:       if (dictionaries[i] != null) {
1:         data[i] = dictionaries[i].getDictionaryValueForKey((int) data[i]);
1:       }
1:       try {
1:         writableArr[i] = createWritableObject(data[i], carbonColumns[i]);
1:       } catch (IOException e) {
1:         throw new RuntimeException(e.getMessage(), e);
1:       }
1:     }
1: 
1:     return (T) writableArr;
1:   }
1: 
1:   /**
1:    * to book keep the dictionary cache or update access count for each
1:    * column involved during decode, to facilitate LRU cache policy if memory
1:    * threshold is reached
1:    */
1:   @Override public void close() {
1:     if (dictionaries == null) {
1:       return;
1:     }
1:     for (int i = 0; i < dictionaries.length; i++) {
1:       CarbonUtil.clearDictionaryCache(dictionaries[i]);
1:     }
1:   }
1: 
1:   /**
1:    * To Create the Writable from the CarbonData data
1:    *
1:    * @param obj
1:    * @param carbonColumn
1:    * @return
1:    * @throws IOException
1:    */
1:   private Writable createWritableObject(Object obj, CarbonColumn carbonColumn) throws IOException {
1:     DataType dataType = carbonColumn.getDataType();
0:     switch (dataType) {
0:       case STRUCT:
0:         return createStruct(obj, carbonColumn);
0:       case ARRAY:
0:         return createArray(obj, carbonColumn);
0:       default:
0:         return createWritablePrimitive(obj, carbonColumn);
1:     }
1:   }
1: 
1:   /**
1:    * Create Array Data for Array Datatype
1:    *
1:    * @param obj
1:    * @param carbonColumn
1:    * @return
1:    * @throws IOException
1:    */
1:   private ArrayWritable createArray(Object obj, CarbonColumn carbonColumn) throws IOException {
1:     if (obj instanceof GenericArrayData) {
1:       Object[] objArray = ((GenericArrayData) obj).array();
1:       List<CarbonDimension> childCarbonDimensions = null;
1:       CarbonDimension arrayDimension = null;
1:       if (carbonColumn.isDimension() && carbonColumn.getColumnSchema().getNumberOfChild() > 0) {
1:         childCarbonDimensions = ((CarbonDimension) carbonColumn).getListOfChildDimensions();
1:         arrayDimension = childCarbonDimensions.get(0);
1:       }
1:       List array = new ArrayList();
1:       if (objArray != null) {
1:         for (int i = 0; i < objArray.length; i++) {
1:           Object curObj = objArray[i];
1:           Writable newObj = createWritableObject(curObj, arrayDimension);
1:           array.add(newObj);
1:         }
1:       }
1:       if (array.size() > 0) {
1:         ArrayWritable subArray = new ArrayWritable(Writable.class,
1:             (Writable[]) array.toArray(new Writable[array.size()]));
1:         return new ArrayWritable(Writable.class, new Writable[] { subArray });
1:       }
1:     }
1:     return null;
1:   }
1: 
1:   /**
1:    * Create the Struct data for the Struct Datatype
1:    *
1:    * @param obj
1:    * @param carbonColumn
1:    * @return
1:    * @throws IOException
1:    */
1:   private ArrayWritable createStruct(Object obj, CarbonColumn carbonColumn) throws IOException {
1:     if (obj instanceof GenericInternalRow) {
1:       Object[] objArray = ((GenericInternalRow) obj).values();
1:       List<CarbonDimension> childCarbonDimensions = null;
1:       if (carbonColumn.isDimension() && carbonColumn.getColumnSchema().getNumberOfChild() > 0) {
1:         childCarbonDimensions = ((CarbonDimension) carbonColumn).getListOfChildDimensions();
1:       }
0:       Writable[] arr = new Writable[objArray.length];
1:       for (int i = 0; i < objArray.length; i++) {
1: 
0:         arr[i] = createWritableObject(objArray[i], childCarbonDimensions.get(i));
1:       }
0:       return new ArrayWritable(Writable.class, arr);
1:     }
1:     throw new IOException("DataType not supported in Carbondata");
1:   }
1: 
1:   /**
1:    * This method will create the Writable Objects for primitives.
1:    *
1:    * @param obj
1:    * @param carbonColumn
1:    * @return
1:    * @throws IOException
1:    */
1:   private Writable createWritablePrimitive(Object obj, CarbonColumn carbonColumn)
1:       throws IOException {
1:     DataType dataType = carbonColumn.getDataType();
1:     if (obj == null) {
1:       return null;
1:     }
0:     switch (dataType) {
0:       case NULL:
1:         return null;
0:       case DOUBLE:
0:         return new DoubleWritable((double) obj);
0:       case INT:
0:         return new IntWritable((int) obj);
0:       case LONG:
0:         return new LongWritable((long) obj);
0:       case SHORT:
0:         return new ShortWritable((Short) obj);
0:       case DATE:
0:         return new DateWritable(new Date((Integer) obj));
0:       case TIMESTAMP:
0:         return new TimestampWritable(new Timestamp((long) obj));
0:       case STRING:
0:         return new Text(obj.toString());
0:       case DECIMAL:
0:         return new HiveDecimalWritable(
0:             HiveDecimal.create(new java.math.BigDecimal(obj.toString())));
1:     }
0:     throw new IOException("Unknown primitive : " + dataType.getName());
1:   }
1: 
1:   /**
0:    * If we need to use the same Writable[] then we can use this method
1:    *
0:    * @param writable
1:    * @param obj
1:    * @param carbonColumn
1:    * @throws IOException
1:    */
0:   private void setPrimitive(Writable writable, Object obj, CarbonColumn carbonColumn)
1:       throws IOException {
1:     DataType dataType = carbonColumn.getDataType();
1:     if (obj == null) {
0:       writable.write(null);
1:     }
0:     switch (dataType) {
0:       case DOUBLE:
0:         ((DoubleWritable) writable).set((double) obj);
0:         break;
0:       case INT:
0:         ((IntWritable) writable).set((int) obj);
0:         break;
0:       case LONG:
0:         ((LongWritable) writable).set((long) obj);
0:         break;
0:       case SHORT:
0:         ((ShortWritable) writable).set((short) obj);
0:         break;
0:       case DATE:
0:         ((DateWritable) writable).set(new Date((Long) obj));
0:         break;
0:       case TIMESTAMP:
0:         ((TimestampWritable) writable).set(new Timestamp((long) obj));
0:         break;
0:       case STRING:
0:         ((Text) writable).set(obj.toString());
0:         break;
0:       case DECIMAL:
0:         ((HiveDecimalWritable) writable)
0:             .set(HiveDecimal.create(new java.math.BigDecimal(obj.toString())));
1:     }
1:   }
1: 
1: }
============================================================================
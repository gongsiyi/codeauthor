1:f1f9348: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:f1f9348:  *
1:f1f9348:  *    http://www.apache.org/licenses/LICENSE-2.0
1:f1f9348:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
5:f1f9348:  */
15:f1f9348: 
1:349c59c: package org.apache.carbondata.processing.loading.sort.unsafe.merger;
1:f1f9348: 
1:f1f9348: import java.io.File;
1:f1f9348: import java.io.FileFilter;
1:f1f9348: import java.util.AbstractQueue;
1:ded8b41: import java.util.ArrayList;
1:ded8b41: import java.util.Arrays;
1:b439b00: import java.util.Iterator;
1:f1f9348: import java.util.List;
1:7ef9164: import java.util.NoSuchElementException;
1:f1f9348: import java.util.PriorityQueue;
1:f1f9348: 
1:f1f9348: import org.apache.carbondata.common.CarbonIterator;
1:f1f9348: import org.apache.carbondata.common.logging.LogService;
1:f1f9348: import org.apache.carbondata.common.logging.LogServiceFactory;
1:dc83b2a: import org.apache.carbondata.core.datastore.exception.CarbonDataWriterException;
1:2b41f14: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.SortTempChunkHolder;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeFinalMergePageHolder;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeInmemoryHolder;
1:349c59c: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
1:349c59c: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
1:f1f9348: 
1:f1f9348: public class UnsafeSingleThreadFinalSortFilesMerger extends CarbonIterator<Object[]> {
5:f1f9348:   /**
1:f1f9348:    * LOGGER
1:f1f9348:    */
1:f1f9348:   private static final LogService LOGGER =
1:f1f9348:       LogServiceFactory.getLogService(UnsafeSingleThreadFinalSortFilesMerger.class.getName());
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * fileCounter
1:f1f9348:    */
1:f1f9348:   private int fileCounter;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * recordHolderHeap
1:f1f9348:    */
1:f1f9348:   private AbstractQueue<SortTempChunkHolder> recordHolderHeapLocal;
1:f1f9348: 
1:f1f9348:   private SortParameters parameters;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:f1f9348:   /**
1:f1f9348:    * tempFileLocation
1:f1f9348:    */
1:ded8b41:   private String[] tempFileLocation;
1:f1f9348: 
1:f1f9348:   private String tableName;
1:f1f9348: 
1:53accb3:   private boolean isStopProcess;
1:f1f9348: 
1:f82b10b:   public UnsafeSingleThreadFinalSortFilesMerger(SortParameters parameters,
1:ded8b41:       String[] tempFileLocation) {
1:f1f9348:     this.parameters = parameters;
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
1:f82b10b:     this.tempFileLocation = tempFileLocation;
1:f1f9348:     this.tableName = parameters.getTableName();
4:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to merger the merged files
1:f1f9348:    *
1:f1f9348:    */
1:f1f9348:   public void startFinalMerge(UnsafeCarbonRowPage[] rowPages,
1:f1f9348:       List<UnsafeInMemoryIntermediateDataMerger> merges) throws CarbonDataWriterException {
1:b439b00:     // remove the spilled pages
1:b439b00:     for (Iterator<UnsafeInMemoryIntermediateDataMerger> iter = merges.iterator();
1:b439b00:          iter.hasNext(); ) {
1:b439b00:       UnsafeInMemoryIntermediateDataMerger merger = iter.next();
1:b439b00:       if (merger.isSpillDisk()) {
1:b439b00:         // it has already been closed once the spill is finished, so no need to close it here
1:b439b00:         iter.remove();
1:b439b00:       }
1:b439b00:     }
1:f1f9348:     startSorting(rowPages, merges);
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * Below method will be used to start storing process This method will get
1:f1f9348:    * all the temp files present in sort temp folder then it will create the
1:f1f9348:    * record holder heap and then it will read first record from each file and
1:f1f9348:    * initialize the heap
1:f1f9348:    *
1:f1f9348:    */
1:f1f9348:   private void startSorting(UnsafeCarbonRowPage[] rowPages,
1:f1f9348:       List<UnsafeInMemoryIntermediateDataMerger> merges) throws CarbonDataWriterException {
2:f1f9348:     try {
1:ded8b41:       List<File> filesToMergeSort = getFilesToMergeSort();
1:ded8b41:       this.fileCounter = rowPages.length + filesToMergeSort.size() + merges.size();
1:9ffe177:       if (fileCounter == 0) {
1:9ffe177:         LOGGER.info("No files to merge sort");
1:9ffe177:         return;
1:f1f9348:       }
1:b439b00:       LOGGER.info(String.format("Starting final merge of %d pages, including row pages: %d"
1:b439b00:           + ", sort temp files: %d, intermediate merges: %d",
1:b439b00:           this.fileCounter, rowPages.length, filesToMergeSort.size(), merges.size()));
1:f1f9348: 
1:f1f9348:       // create record holder heap
1:f1f9348:       createRecordHolderQueue();
1:f1f9348: 
1:f1f9348:       // iterate over file list and create chunk holder and add to heap
1:f1f9348:       LOGGER.info("Started adding first record from each page");
1:f1f9348:       for (final UnsafeCarbonRowPage rowPage : rowPages) {
1:f1f9348: 
1:2b41f14:         SortTempChunkHolder sortTempFileChunkHolder = new UnsafeInmemoryHolder(rowPage);
1:f1f9348: 
1:f1f9348:         // initialize
1:f1f9348:         sortTempFileChunkHolder.readRow();
1:f1f9348: 
1:f1f9348:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:f1f9348:       }
1:f1f9348: 
1:f1f9348:       for (final UnsafeInMemoryIntermediateDataMerger merger : merges) {
1:f1f9348: 
1:f1f9348:         SortTempChunkHolder sortTempFileChunkHolder =
1:2b41f14:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionarySortColumn());
1:f1f9348: 
1:f1f9348:         // initialize
1:f1f9348:         sortTempFileChunkHolder.readRow();
1:f1f9348: 
1:f1f9348:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:f1f9348:       }
1:f1f9348: 
1:f1f9348:       for (final File file : filesToMergeSort) {
1:f1f9348: 
1:f1f9348:         SortTempChunkHolder sortTempFileChunkHolder =
1:f27efb3:             new UnsafeSortTempFileChunkHolder(file, parameters, true);
1:f1f9348: 
1:f1f9348:         // initialize
1:f1f9348:         sortTempFileChunkHolder.readRow();
1:f1f9348: 
1:f1f9348:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:f1f9348:       }
1:f1f9348: 
1:2b41f14:       LOGGER.info("Heap Size: " + this.recordHolderHeapLocal.size());
2:f1f9348:     } catch (Exception e) {
1:f1f9348:       LOGGER.error(e);
1:a734add:       throw new CarbonDataWriterException(e);
1:f1f9348:     }
1:f1f9348:   }
1:f1f9348: 
1:ded8b41:   private List<File> getFilesToMergeSort() {
1:d5396b1:     // this can be partitionId, bucketId or rangeId, let's call it rangeId
1:d5396b1:     final int rangeId = parameters.getRangeId();
1:d5396b1: 
1:ded8b41:     FileFilter fileFilter = new FileFilter() {
1:f1f9348:       public boolean accept(File pathname) {
1:d5396b1:         return pathname.getName().startsWith(tableName + '_' + rangeId);
1:f1f9348:       }
1:ded8b41:     };
1:f1f9348: 
1:ded8b41:     // get all the merged files
1:ded8b41:     List<File> files = new ArrayList<File>(tempFileLocation.length);
1:d5396b1:     for (String tempLoc : tempFileLocation) {
1:ded8b41:       File[] subFiles = new File(tempLoc).listFiles(fileFilter);
1:d5396b1:       if (null != subFiles && subFiles.length > 0) {
1:ded8b41:         files.addAll(Arrays.asList(subFiles));
1:ded8b41:       }
1:f1f9348:     }
1:ded8b41: 
1:ded8b41:     return files;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to create the heap which will be used to hold
1:f1f9348:    * the chunk of data
1:f1f9348:    */
1:f1f9348:   private void createRecordHolderQueue() {
1:f1f9348:     // creating record holder heap
1:f1f9348:     this.recordHolderHeapLocal = new PriorityQueue<SortTempChunkHolder>(fileCounter);
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:2b41f14:    * This method will be used to get the sorted row in 3-parted format.
1:2b41f14:    * The row will feed the following writer process step.
1:f1f9348:    *
1:f1f9348:    * @return sorted row
1:f1f9348:    */
1:f1f9348:   public Object[] next() {
1:7ef9164:     if (hasNext()) {
1:f27efb3:       return sortStepRowHandler.convertIntermediateSortTempRowTo3Parted(getSortedRecordFromFile());
1:7ef9164:     } else {
1:7ef9164:       throw new NoSuchElementException("No more elements to return");
1:7ef9164:     }
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to get the sorted record from file
1:f1f9348:    *
1:f1f9348:    * @return sorted record sorted record
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow getSortedRecordFromFile() throws CarbonDataWriterException {
1:2b41f14:     IntermediateSortTempRow row = null;
1:f1f9348: 
1:f1f9348:     // poll the top object from heap
1:f1f9348:     // heap maintains binary tree which is based on heap condition that will
1:f1f9348:     // be based on comparator we are passing the heap
1:f1f9348:     // when will call poll it will always delete root of the tree and then
1:f1f9348:     // it does trickel down operation complexity is log(n)
1:f1f9348:     SortTempChunkHolder poll = this.recordHolderHeapLocal.poll();
1:f1f9348: 
1:f1f9348:     // get the row from chunk
1:f1f9348:     row = poll.getRow();
1:f1f9348: 
1:f1f9348:     // check if there no entry present
1:f1f9348:     if (!poll.hasNext()) {
1:f1f9348:       // if chunk is empty then close the stream
1:f1f9348:       poll.close();
1:f1f9348: 
1:f1f9348:       // change the file counter
1:f1f9348:       --this.fileCounter;
1:f1f9348: 
1:f1f9348:       // reaturn row
1:f1f9348:       return row;
1:f1f9348:     }
1:f1f9348: 
1:f1f9348:     // read new row
1:f1f9348:     try {
1:f1f9348:       poll.readRow();
1:f1f9348:     } catch (Exception e) {
1:f1f9348:       throw new CarbonDataWriterException(e.getMessage(), e);
1:f1f9348:     }
1:f1f9348: 
1:f1f9348:     // add to heap
1:f1f9348:     this.recordHolderHeapLocal.add(poll);
1:f1f9348: 
1:f1f9348:     // return row
1:f1f9348:     return row;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to check whether any more element is present or
1:f1f9348:    * not
1:f1f9348:    *
1:f1f9348:    * @return more element is present
1:f1f9348:    */
1:f1f9348:   public boolean hasNext() {
1:f1f9348:     return this.fileCounter > 0;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   public void clear() {
1:f1f9348:     if (null != recordHolderHeapLocal) {
1:f1f9348:       for (SortTempChunkHolder pageHolder : recordHolderHeapLocal) {
1:f1f9348:         pageHolder.close();
1:f1f9348:       }
1:f1f9348:       recordHolderHeapLocal = null;
1:f1f9348:     }
1:f1f9348:   }
1:f1f9348: 
1:53accb3:   public boolean isStopProcess() {
1:53accb3:     return isStopProcess;
1:f1f9348:   }
1:f1f9348: 
1:53accb3:   public void setStopProcess(boolean stopProcess) {
1:53accb3:     isStopProcess = stopProcess;
1:f1f9348:   }
1:f1f9348: }
============================================================================
author:kumarvishal09
-------------------------------------------------------------------------------
commit:f27efb3
/////////////////////////////////////////////////////////////////////////
1:             new UnsafeSortTempFileChunkHolder(file, parameters, true);
/////////////////////////////////////////////////////////////////////////
1:       return sortStepRowHandler.convertIntermediateSortTempRowTo3Parted(getSortedRecordFromFile());
author:Raghunandan S
-------------------------------------------------------------------------------
commit:7ef9164
/////////////////////////////////////////////////////////////////////////
1: import java.util.NoSuchElementException;
/////////////////////////////////////////////////////////////////////////
1:     if (hasNext()) {
0:       IntermediateSortTempRow sortTempRow = getSortedRecordFromFile();
0:       return sortStepRowHandler.convertIntermediateSortTempRowTo3Parted(sortTempRow);
1:     } else {
1:       throw new NoSuchElementException("No more elements to return");
1:     }
author:xuchuanyin
-------------------------------------------------------------------------------
commit:b439b00
/////////////////////////////////////////////////////////////////////////
1: import java.util.Iterator;
/////////////////////////////////////////////////////////////////////////
1:     // remove the spilled pages
1:     for (Iterator<UnsafeInMemoryIntermediateDataMerger> iter = merges.iterator();
1:          iter.hasNext(); ) {
1:       UnsafeInMemoryIntermediateDataMerger merger = iter.next();
1:       if (merger.isSpillDisk()) {
1:         // it has already been closed once the spill is finished, so no need to close it here
1:         iter.remove();
1:       }
1:     }
/////////////////////////////////////////////////////////////////////////
1:       LOGGER.info(String.format("Starting final merge of %d pages, including row pages: %d"
1:           + ", sort temp files: %d, intermediate merges: %d",
1:           this.fileCounter, rowPages.length, filesToMergeSort.size(), merges.size()));
commit:d5396b1
/////////////////////////////////////////////////////////////////////////
1:     // this can be partitionId, bucketId or rangeId, let's call it rangeId
1:     final int rangeId = parameters.getRangeId();
1: 
1:         return pathname.getName().startsWith(tableName + '_' + rangeId);
1:     for (String tempLoc : tempFileLocation) {
1:       if (null != subFiles && subFiles.length > 0) {
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
1:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
/////////////////////////////////////////////////////////////////////////
1:         SortTempChunkHolder sortTempFileChunkHolder = new UnsafeInmemoryHolder(rowPage);
/////////////////////////////////////////////////////////////////////////
1:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionarySortColumn());
/////////////////////////////////////////////////////////////////////////
1:       LOGGER.info("Heap Size: " + this.recordHolderHeapLocal.size());
/////////////////////////////////////////////////////////////////////////
1:    * This method will be used to get the sorted row in 3-parted format.
1:    * The row will feed the following writer process step.
0:     IntermediateSortTempRow sortTempRow =  getSortedRecordFromFile();
0:     return sortStepRowHandler.convertIntermediateSortTempRowTo3Parted(sortTempRow);
/////////////////////////////////////////////////////////////////////////
1:   private IntermediateSortTempRow getSortedRecordFromFile() throws CarbonDataWriterException {
1:     IntermediateSortTempRow row = null;
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.sort.SortStepRowUtil;
/////////////////////////////////////////////////////////////////////////
0:   private SortStepRowUtil sortStepRowUtil;
/////////////////////////////////////////////////////////////////////////
0:     this.sortStepRowUtil = new SortStepRowUtil(parameters);
/////////////////////////////////////////////////////////////////////////
0:         SortTempChunkHolder sortTempFileChunkHolder = new UnsafeInmemoryHolder(rowPage,
0:             parameters.getDimColCount() + parameters.getComplexDimColCount() + parameters
0:                 .getMeasureColCount(), parameters.getNumberOfSortColumns());
/////////////////////////////////////////////////////////////////////////
0:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionarySortColumn(),
0:                 parameters.getDimColCount() + parameters.getComplexDimColCount() + parameters
0:                     .getMeasureColCount());
/////////////////////////////////////////////////////////////////////////
0:       LOGGER.info("Heap Size" + this.recordHolderHeapLocal.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted row
0:     return sortStepRowUtil.convertRow(getSortedRecordFromFile());
/////////////////////////////////////////////////////////////////////////
0:   private Object[] getSortedRecordFromFile() throws CarbonDataWriterException {
0:     Object[] row = null;
commit:21704cf
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:   private SortStepRowHandler sortStepRowHandler;
/////////////////////////////////////////////////////////////////////////
0:     this.sortStepRowHandler = new SortStepRowHandler(parameters);
/////////////////////////////////////////////////////////////////////////
0:         SortTempChunkHolder sortTempFileChunkHolder = new UnsafeInmemoryHolder(rowPage);
/////////////////////////////////////////////////////////////////////////
0:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionarySortColumn());
/////////////////////////////////////////////////////////////////////////
0:       LOGGER.info("Heap Size: " + this.recordHolderHeapLocal.size());
/////////////////////////////////////////////////////////////////////////
0:    * This method will be used to get the sorted row in 3-parted format.
0:    * The row will feed the following writer process step.
0:     IntermediateSortTempRow sortTempRow =  getSortedRecordFromFile();
0:     return sortStepRowHandler.convertIntermediateSortTempRowTo3Parted(sortTempRow);
/////////////////////////////////////////////////////////////////////////
0:   private IntermediateSortTempRow getSortedRecordFromFile() throws CarbonDataWriterException {
0:     IntermediateSortTempRow row = null;
commit:afe96a2
/////////////////////////////////////////////////////////////////////////
0:   private SortStepRowUtil sortStepRowUtil;
/////////////////////////////////////////////////////////////////////////
0:     this.sortStepRowUtil = new SortStepRowUtil(parameters);
/////////////////////////////////////////////////////////////////////////
0:     return sortStepRowUtil.convertRow(getSortedRecordFromFile());
commit:ded8b41
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
1: import java.util.Arrays;
/////////////////////////////////////////////////////////////////////////
1:   private String[] tempFileLocation;
1:       String[] tempFileLocation) {
/////////////////////////////////////////////////////////////////////////
1:       List<File> filesToMergeSort = getFilesToMergeSort();
1:       this.fileCounter = rowPages.length + filesToMergeSort.size() + merges.size();
/////////////////////////////////////////////////////////////////////////
1:   private List<File> getFilesToMergeSort() {
1:     FileFilter fileFilter = new FileFilter() {
1:     };
1:     // get all the merged files
1:     List<File> files = new ArrayList<File>(tempFileLocation.length);
0:     for (String tempLoc : tempFileLocation)
0:     {
1:       File[] subFiles = new File(tempLoc).listFiles(fileFilter);
0:       if (null != subFiles && subFiles.length > 0)
0:       {
1:         files.addAll(Arrays.asList(subFiles));
1:       }
1: 
1:     return files;
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
0:       LOGGER.info("Starting final merger");
/////////////////////////////////////////////////////////////////////////
1:       throw new CarbonDataWriterException(e);
author:Jacky Li
-------------------------------------------------------------------------------
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.loading.sort.unsafe.merger;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.sort.SortStepRowUtil;
1: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.SortTempChunkHolder;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeFinalMergePageHolder;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeInmemoryHolder;
1: import org.apache.carbondata.processing.loading.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
1: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
author:manishgupta88
-------------------------------------------------------------------------------
commit:c4f312f
/////////////////////////////////////////////////////////////////////////
0:     return SortStepRowUtil.convertRow(getSortedRecordFromFile(), parameters);
author:dhatchayani
-------------------------------------------------------------------------------
commit:0205fa6
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
author:Yadong Qi
-------------------------------------------------------------------------------
commit:6c41f89
/////////////////////////////////////////////////////////////////////////
0:     return SortStepRowUtil.convertRow(getSortedRecordFromFile(), parameters, false);
commit:82741c1
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.newflow.sort.SortStepRowUtil;
/////////////////////////////////////////////////////////////////////////
0:     return SortStepRowUtil.convertRow(getSortedRecordFromFile(), parameters);
/////////////////////////////////////////////////////////////////////////
author:jackylk
-------------------------------------------------------------------------------
commit:dc83b2a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.exception.CarbonDataWriterException;
commit:3fe6903
/////////////////////////////////////////////////////////////////////////
author:QiangCai
-------------------------------------------------------------------------------
commit:9f94529
/////////////////////////////////////////////////////////////////////////
0:                 .getMeasureColCount(), parameters.getNumberOfSortColumns());
/////////////////////////////////////////////////////////////////////////
0:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionarySortColumn(),
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:ravipesala
-------------------------------------------------------------------------------
commit:f82b10b
/////////////////////////////////////////////////////////////////////////
1:   public UnsafeSingleThreadFinalSortFilesMerger(SortParameters parameters,
0:       String tempFileLocation) {
/////////////////////////////////////////////////////////////////////////
1:     this.tempFileLocation = tempFileLocation;
commit:b13ead9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.util.NonDictionaryUtil;
/////////////////////////////////////////////////////////////////////////
0:             parameters.getDimColCount() + parameters.getComplexDimColCount() + parameters
0:                 .getMeasureColCount());
/////////////////////////////////////////////////////////////////////////
0:                 parameters.getDimColCount() + parameters.getComplexDimColCount() + parameters
0:                     .getMeasureColCount());
/////////////////////////////////////////////////////////////////////////
0:       NonDictionaryUtil.prepareOutObj(holder, dim, nonDicArray, measures);
commit:f1f9348
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.newflow.sort.unsafe.merger;
1: 
1: import java.io.File;
1: import java.io.FileFilter;
1: import java.util.AbstractQueue;
1: import java.util.List;
1: import java.util.PriorityQueue;
1: 
1: import org.apache.carbondata.common.CarbonIterator;
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.UnsafeCarbonRowPage;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.SortTempChunkHolder;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.UnsafeFinalMergePageHolder;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.UnsafeInmemoryHolder;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.holder.UnsafeSortTempFileChunkHolder;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.SortParameters;
0: import org.apache.carbondata.processing.store.writer.exception.CarbonDataWriterException;
0: import org.apache.carbondata.processing.util.RemoveDictionaryUtil;
1: 
1: public class UnsafeSingleThreadFinalSortFilesMerger extends CarbonIterator<Object[]> {
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(UnsafeSingleThreadFinalSortFilesMerger.class.getName());
1: 
1:   /**
0:    * lockObject
1:    */
0:   private static final Object LOCKOBJECT = new Object();
1: 
1:   /**
1:    * fileCounter
1:    */
1:   private int fileCounter;
1: 
1:   /**
1:    * recordHolderHeap
1:    */
1:   private AbstractQueue<SortTempChunkHolder> recordHolderHeapLocal;
1: 
1:   private SortParameters parameters;
1: 
1:   /**
0:    * number of measures
1:    */
0:   private int measureCount;
1: 
1:   /**
0:    * number of dimensionCount
1:    */
0:   private int dimensionCount;
1: 
1:   /**
0:    * number of complexDimensionCount
1:    */
0:   private int noDictionaryCount;
1: 
0:   private int complexDimensionCount;
1: 
0:   private boolean[] isNoDictionaryDimensionColumn;
1: 
1:   /**
1:    * tempFileLocation
1:    */
0:   private String tempFileLocation;
1: 
1:   private String tableName;
1: 
0:   public UnsafeSingleThreadFinalSortFilesMerger(SortParameters parameters) {
1:     this.parameters = parameters;
0:     // set measure and dimension count
0:     this.measureCount = parameters.getMeasureColCount();
0:     this.dimensionCount = parameters.getDimColCount();
0:     this.complexDimensionCount = parameters.getComplexDimColCount();
1: 
0:     this.noDictionaryCount = parameters.getNoDictionaryCount();
0:     this.isNoDictionaryDimensionColumn = parameters.getNoDictionaryDimnesionColumn();
0:     this.tempFileLocation = parameters.getTempFileLocation();
1:     this.tableName = parameters.getTableName();
1:   }
1: 
1:   /**
1:    * This method will be used to merger the merged files
1:    *
1:    */
1:   public void startFinalMerge(UnsafeCarbonRowPage[] rowPages,
1:       List<UnsafeInMemoryIntermediateDataMerger> merges) throws CarbonDataWriterException {
1:     startSorting(rowPages, merges);
1:   }
1: 
1:   /**
1:    * Below method will be used to start storing process This method will get
1:    * all the temp files present in sort temp folder then it will create the
1:    * record holder heap and then it will read first record from each file and
1:    * initialize the heap
1:    *
1:    */
1:   private void startSorting(UnsafeCarbonRowPage[] rowPages,
1:       List<UnsafeInMemoryIntermediateDataMerger> merges) throws CarbonDataWriterException {
1:     try {
0:       File[] filesToMergeSort = getFilesToMergeSort();
0:       this.fileCounter = rowPages.length + filesToMergeSort.length + merges.size();
1: 
0:       LOGGER.info("Number of row pages: " + this.fileCounter);
1: 
1:       // create record holder heap
1:       createRecordHolderQueue();
1: 
1:       // iterate over file list and create chunk holder and add to heap
1:       LOGGER.info("Started adding first record from each page");
1:       for (final UnsafeCarbonRowPage rowPage : rowPages) {
1: 
0:         SortTempChunkHolder sortTempFileChunkHolder = new UnsafeInmemoryHolder(rowPage,
0:             parameters.getDimColCount() + parameters.getMeasureColCount());
1: 
1:         // initialize
1:         sortTempFileChunkHolder.readRow();
1: 
1:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:       }
1: 
1:       for (final UnsafeInMemoryIntermediateDataMerger merger : merges) {
1: 
1:         SortTempChunkHolder sortTempFileChunkHolder =
0:             new UnsafeFinalMergePageHolder(merger, parameters.getNoDictionaryDimnesionColumn(),
0:                 parameters.getDimColCount() + parameters.getMeasureColCount());
1: 
1:         // initialize
1:         sortTempFileChunkHolder.readRow();
1: 
1:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:       }
1: 
1:       for (final File file : filesToMergeSort) {
1: 
1:         SortTempChunkHolder sortTempFileChunkHolder =
0:             new UnsafeSortTempFileChunkHolder(file, parameters);
1: 
1:         // initialize
1:         sortTempFileChunkHolder.readRow();
1: 
1:         recordHolderHeapLocal.add(sortTempFileChunkHolder);
1:       }
1: 
0:       LOGGER.info("Heap Size" + this.recordHolderHeapLocal.size());
1:     } catch (Exception e) {
1:       LOGGER.error(e);
0:       throw new CarbonDataWriterException(e.getMessage());
1:     }
1:   }
1: 
0:   private File[] getFilesToMergeSort() {
0:     // get all the merged files
0:     File file = new File(tempFileLocation);
1: 
0:     File[] fileList = file.listFiles(new FileFilter() {
1:       public boolean accept(File pathname) {
0:         return pathname.getName().startsWith(tableName);
1:       }
0:     });
1: 
0:     if (null == fileList || fileList.length < 0) {
0:       return new File[0];
1:     }
0:     return fileList;
1:   }
1: 
1:   /**
1:    * This method will be used to create the heap which will be used to hold
1:    * the chunk of data
1:    */
1:   private void createRecordHolderQueue() {
1:     // creating record holder heap
1:     this.recordHolderHeapLocal = new PriorityQueue<SortTempChunkHolder>(fileCounter);
1:   }
1: 
1:   /**
0:    * This method will be used to get the sorted row
1:    *
1:    * @return sorted row
1:    */
1:   public Object[] next() {
0:     return convertRow(getSortedRecordFromFile());
1:   }
1: 
1:   /**
1:    * This method will be used to get the sorted record from file
1:    *
1:    * @return sorted record sorted record
1:    */
0:   private Object[] getSortedRecordFromFile() throws CarbonDataWriterException {
0:     Object[] row = null;
1: 
1:     // poll the top object from heap
1:     // heap maintains binary tree which is based on heap condition that will
1:     // be based on comparator we are passing the heap
1:     // when will call poll it will always delete root of the tree and then
1:     // it does trickel down operation complexity is log(n)
1:     SortTempChunkHolder poll = this.recordHolderHeapLocal.poll();
1: 
1:     // get the row from chunk
1:     row = poll.getRow();
1: 
1:     // check if there no entry present
1:     if (!poll.hasNext()) {
1:       // if chunk is empty then close the stream
1:       poll.close();
1: 
1:       // change the file counter
1:       --this.fileCounter;
1: 
1:       // reaturn row
1:       return row;
1:     }
1: 
1:     // read new row
1:     try {
1:       poll.readRow();
1:     } catch (Exception e) {
1:       throw new CarbonDataWriterException(e.getMessage(), e);
1:     }
1: 
1:     // add to heap
1:     this.recordHolderHeapLocal.add(poll);
1: 
1:     // return row
1:     return row;
1:   }
1: 
1:   /**
1:    * This method will be used to check whether any more element is present or
1:    * not
1:    *
1:    * @return more element is present
1:    */
1:   public boolean hasNext() {
1:     return this.fileCounter > 0;
1:   }
1: 
0:   private Object[] convertRow(Object[] data) {
0:     // create new row of size 3 (1 for dims , 1 for high card , 1 for measures)
1: 
0:     Object[] holder = new Object[3];
0:     int index = 0;
0:     int nonDicIndex = 0;
0:     int allCount = 0;
0:     int[] dim = new int[this.dimensionCount];
0:     byte[][] nonDicArray = new byte[this.noDictionaryCount + this.complexDimensionCount][];
0:     Object[] measures = new Object[this.measureCount];
1:     try {
0:       // read dimension values
0:       for (int i = 0; i < isNoDictionaryDimensionColumn.length; i++) {
0:         if (isNoDictionaryDimensionColumn[i]) {
0:           nonDicArray[nonDicIndex++] = (byte[]) data[i];
0:         } else {
0:           dim[index++] = (int) data[allCount];
1:         }
0:         allCount++;
1:       }
1: 
0:       for (int i = 0; i < complexDimensionCount; i++) {
0:         nonDicArray[nonDicIndex++] = (byte[]) data[allCount];
0:         allCount++;
1:       }
1: 
0:       index = 0;
0:       // read measure values
0:       for (int i = 0; i < this.measureCount; i++) {
0:         measures[index++] = data[allCount];
0:         allCount++;
1:       }
1: 
0:       RemoveDictionaryUtil.prepareOutObj(holder, dim, nonDicArray, measures);
1: 
0:       // increment number if record read
1:     } catch (Exception e) {
0:       throw new RuntimeException("Problem while converting row ", e);
1:     }
1: 
0:     //return out row
0:     return holder;
1:   }
1: 
1:   public void clear() {
1:     if (null != recordHolderHeapLocal) {
1:       for (SortTempChunkHolder pageHolder : recordHolderHeapLocal) {
1:         pageHolder.close();
1:       }
1:       recordHolderHeapLocal = null;
1:     }
1:   }
1: }
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:9ffe177
/////////////////////////////////////////////////////////////////////////
1:       if (fileCounter == 0) {
1:         LOGGER.info("No files to merge sort");
1:         return;
0:       }
commit:53accb3
/////////////////////////////////////////////////////////////////////////
1:   private boolean isStopProcess;
0: 
/////////////////////////////////////////////////////////////////////////
0: 
1:   public boolean isStopProcess() {
1:     return isStopProcess;
0:   }
0: 
1:   public void setStopProcess(boolean stopProcess) {
1:     isStopProcess = stopProcess;
0:   }
============================================================================
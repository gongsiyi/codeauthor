1:09f7cdd: /*
1:09f7cdd:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:09f7cdd:  * contributor license agreements.  See the NOTICE file distributed with
1:09f7cdd:  * this work for additional information regarding copyright ownership.
1:09f7cdd:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:09f7cdd:  * (the "License"); you may not use this file except in compliance with
1:09f7cdd:  * the License.  You may obtain a copy of the License at
1:09f7cdd:  *
1:09f7cdd:  *    http://www.apache.org/licenses/LICENSE-2.0
1:09f7cdd:  *
1:09f7cdd:  * Unless required by applicable law or agreed to in writing, software
1:09f7cdd:  * distributed under the License is distributed on an "AS IS" BASIS,
1:09f7cdd:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:09f7cdd:  * See the License for the specific language governing permissions and
1:09f7cdd:  * limitations under the License.
1:09f7cdd:  */
1:09f7cdd: 
1:347b8e1: package org.apache.carbondata.converter;
1:09f7cdd: 
1:09f7cdd: import java.io.Serializable;
1:982d03f: import java.math.BigDecimal;
1:09f7cdd: 
1:c723947: import org.apache.carbondata.core.keygenerator.directdictionary.DirectDictionaryGenerator;
1:c723947: import org.apache.carbondata.core.keygenerator.directdictionary.DirectDictionaryKeyGeneratorFactory;
1:c723947: import org.apache.carbondata.core.metadata.datatype.DataType;
1:c723947: import org.apache.carbondata.core.metadata.encoder.Encoding;
1:c723947: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:c723947: import org.apache.carbondata.core.metadata.schema.table.column.CarbonMeasure;
1:09f7cdd: import org.apache.carbondata.core.util.DataTypeConverter;
1:09f7cdd: 
1:982d03f: import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;
1:fb6dffe: import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;
1:982d03f: import org.apache.spark.sql.catalyst.util.GenericArrayData;
1:c723947: import org.apache.spark.sql.types.DataTypes;
1:c723947: import org.apache.spark.sql.types.DecimalType;
1:c723947: import org.apache.spark.sql.types.StructField;
1:09f7cdd: import org.apache.spark.unsafe.types.UTF8String;
1:09f7cdd: 
1:09f7cdd: /**
1:09f7cdd:  * Convert java data type to spark data type
1:09f7cdd:  */
1:09f7cdd: public final class SparkDataTypeConverterImpl implements DataTypeConverter, Serializable {
1:09f7cdd: 
1:09f7cdd:   private static final long serialVersionUID = -4379212832935070583L;
1:09f7cdd: 
1:982d03f:   @Override
1:982d03f:   public Object convertFromStringToDecimal(Object data) {
1:347b8e1:     BigDecimal javaDecVal = new BigDecimal(data.toString());
1:09f7cdd:     return org.apache.spark.sql.types.Decimal.apply(javaDecVal);
1:982d03f:   }
1:2ea3b2d: 
1:982d03f:   @Override
1:982d03f:   public Object convertFromBigDecimalToDecimal(Object data) {
1:8d3c774:     if (null == data) {
1:8d3c774:       return null;
1:8d3c774:     }
1:982d03f:     return org.apache.spark.sql.types.Decimal.apply((BigDecimal)data);
1:c723947:   }
1:982d03f: 
1:982d03f:   @Override
1:982d03f:   public Object convertFromDecimalToBigDecimal(Object data) {
1:982d03f:     return ((org.apache.spark.sql.types.Decimal) data).toJavaBigDecimal();
1:982d03f:   }
1:982d03f: 
1:982d03f:   @Override
1:09f7cdd:   public byte[] convertFromStringToByte(Object data) {
1:8d3c774:     if (null == data) {
1:8d3c774:       return null;
1:8d3c774:     }
1:09f7cdd:     return UTF8String.fromString((String) data).getBytes();
1:8d3c774:   }
1:09f7cdd: 
1:982d03f:   @Override
1:982d03f:   public Object convertFromByteToUTF8String(byte[] data) {
1:8d3c774:     if (null == data) {
1:8d3c774:       return null;
1:982d03f:     }
1:982d03f:     return UTF8String.fromBytes(data);
5:09f7cdd:   }
1:09f7cdd: 
1:982d03f:   @Override
1:982d03f:   public byte[] convertFromByteToUTF8Bytes(byte[] data) {
1:982d03f:     return UTF8String.fromBytes(data).getBytes();
1:982d03f:   }
1:982d03f: 
1:982d03f:   @Override
1:09f7cdd:   public Object convertFromStringToUTF8String(Object data) {
1:8d3c774:     if (null == data) {
1:8d3c774:       return null;
1:8d3c774:     }
1:09f7cdd:     return UTF8String.fromString((String) data);
1:982d03f:   }
1:982d03f: 
1:982d03f:   @Override
1:982d03f:   public Object wrapWithGenericArrayData(Object data) {
1:982d03f:     return new GenericArrayData(data);
1:982d03f:   }
1:982d03f: 
1:982d03f:   @Override
1:982d03f:   public Object wrapWithGenericRow(Object[] fields) {
1:982d03f:     return new GenericInternalRow(fields);
1:c723947:   }
1:c723947: 
1:fb6dffe:   @Override
1:fb6dffe:   public Object wrapWithArrayBasedMapData(Object[] keyArray, Object[] valueArray) {
1:fb6dffe:     return new ArrayBasedMapData(new GenericArrayData(keyArray), new GenericArrayData(valueArray));
1:fb6dffe:   }
1:fb6dffe: 
1:fb6dffe:   @Override
1:fb6dffe:   public Object[] unwrapGenericRowToObject(Object data) {
1:fb6dffe:     GenericInternalRow row = (GenericInternalRow) data;
1:fb6dffe:     return row.values();
1:fb6dffe:   }
1:fb6dffe: 
1:c723947:   private static org.apache.spark.sql.types.DataType convertCarbonToSparkDataType(
1:c723947:       DataType carbonDataType) {
1:c723947:     if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.STRING) {
1:c723947:       return DataTypes.StringType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.SHORT) {
1:c723947:       return DataTypes.ShortType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.INT) {
1:c723947:       return DataTypes.IntegerType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.LONG) {
1:c723947:       return DataTypes.LongType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.DOUBLE) {
1:c723947:       return DataTypes.DoubleType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.BOOLEAN) {
1:c723947:       return DataTypes.BooleanType;
1:c723947:     } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isDecimal(carbonDataType)) {
1:c723947:       return DataTypes.createDecimalType();
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.TIMESTAMP) {
1:c723947:       return DataTypes.TimestampType;
1:c723947:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.DATE) {
1:c723947:       return DataTypes.DateType;
2:c723947:     } else {
1:c723947:       return null;
1:c723947:     }
1:c723947:   }
1:c723947: 
1:c723947:   /**
1:c723947:    * convert from CarbonColumn array to Spark's StructField array
1:c723947:    */
1:c723947:   @Override
1:c723947:   public Object[] convertCarbonSchemaToSparkSchema(CarbonColumn[] carbonColumns) {
1:c723947:     StructField[] fields = new StructField[carbonColumns.length];
1:2ea3b2d:     for (int i = 0; i < carbonColumns.length; i++) {
1:c723947:       CarbonColumn carbonColumn = carbonColumns[i];
1:c723947:       if (carbonColumn.isDimension()) {
1:c723947:         if (carbonColumn.hasEncoding(Encoding.DIRECT_DICTIONARY)) {
1:c723947:           DirectDictionaryGenerator generator = DirectDictionaryKeyGeneratorFactory
1:c723947:               .getDirectDictionaryGenerator(carbonColumn.getDataType());
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(generator.getReturnType()), true, null);
1:c723947:         } else if (!carbonColumn.hasEncoding(Encoding.DICTIONARY)) {
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(carbonColumn.getDataType()), true, null);
1:c723947:         } else if (carbonColumn.isComplex()) {
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(carbonColumn.getDataType()), true, null);
1:c723947:         } else {
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(
1:c723947:                   org.apache.carbondata.core.metadata.datatype.DataTypes.INT), true, null);
1:c723947:         }
1:c723947:       } else if (carbonColumn.isMeasure()) {
1:2ea3b2d:         DataType dataType = carbonColumn.getDataType();
1:c723947:         if (dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.BOOLEAN
1:c723947:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.SHORT
1:c723947:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.INT
1:c723947:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.LONG) {
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(dataType), true, null);
1:c723947:         } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isDecimal(dataType)) {
1:c723947:           CarbonMeasure measure = (CarbonMeasure) carbonColumn;
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               new DecimalType(measure.getPrecision(), measure.getScale()), true, null);
1:2ea3b2d:         } else {
1:c723947:           fields[i] = new StructField(carbonColumn.getColName(),
1:c723947:               convertCarbonToSparkDataType(
1:c723947:                   org.apache.carbondata.core.metadata.datatype.DataTypes.DOUBLE), true, null);
1:2ea3b2d:         }
1:2ea3b2d:       }
1:c723947:     }
1:c723947:     return fields;
1:2ea3b2d:   }
1:09f7cdd: 
1:c723947: }
============================================================================
author:manishgupta88
-------------------------------------------------------------------------------
commit:fb6dffe
/////////////////////////////////////////////////////////////////////////
1: import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   public Object wrapWithArrayBasedMapData(Object[] keyArray, Object[] valueArray) {
1:     return new ArrayBasedMapData(new GenericArrayData(keyArray), new GenericArrayData(valueArray));
1:   }
1: 
1:   @Override
1:   public Object[] unwrapGenericRowToObject(Object data) {
1:     GenericInternalRow row = (GenericInternalRow) data;
1:     return row.values();
1:   }
1: 
author:ravipesala
-------------------------------------------------------------------------------
commit:347b8e1
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.converter;
/////////////////////////////////////////////////////////////////////////
1:     BigDecimal javaDecVal = new BigDecimal(data.toString());
/////////////////////////////////////////////////////////////////////////
commit:8d3c774
/////////////////////////////////////////////////////////////////////////
1:     if (null == data) {
1:       return null;
1:     }
1:     if (null == data) {
1:       return null;
1:     }
1:     if (null == data) {
1:       return null;
1:     }
1:     if (null == data) {
1:       return null;
1:     }
author:Jacky Li
-------------------------------------------------------------------------------
commit:2ea3b2d
/////////////////////////////////////////////////////////////////////////
0: import java.util.ArrayList;
0: import java.util.List;
0: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
0: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
0: import org.apache.spark.sql.types.Metadata;
0: import org.apache.spark.sql.types.StructType;
0: import org.apache.spark.util.CarbonMetastoreTypes;
0: import org.apache.spark.util.SparkTypeConverter;
/////////////////////////////////////////////////////////////////////////
1: 
0:   public static StructType convertToSparkSchema(CarbonTable table, ColumnSchema[] carbonColumns) {
0:     List<StructField> fields = new ArrayList<>(carbonColumns.length);
1:     for (int i = 0; i < carbonColumns.length; i++) {
0:       ColumnSchema carbonColumn = carbonColumns[i];
1:       DataType dataType = carbonColumn.getDataType();
0:       if (org.apache.carbondata.core.metadata.datatype.DataTypes.isDecimal(dataType)) {
0:         fields.add(new StructField(carbonColumn.getColumnName(),
0:             new DecimalType(carbonColumn.getPrecision(), carbonColumn.getScale()),
0:             true, Metadata.empty()));
0:       } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isStructType(dataType)) {
0:         fields.add(
0:             new StructField(
0:                 carbonColumn.getColumnName(),
0:                 CarbonMetastoreTypes.toDataType(
0:                     String.format("struct<%s>",
0:                         SparkTypeConverter.getStructChildren(table, carbonColumn.getColumnName()))),
0:                 true,
0:                 Metadata.empty()));
0:       } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isArrayType(dataType)) {
0:         fields.add(
0:             new StructField(
0:                 carbonColumn.getColumnName(),
0:                 CarbonMetastoreTypes.toDataType(
0:                     String.format("array<%s>",
0:                         SparkTypeConverter.getArrayChildren(
0:                             table,
0:                             carbonColumn.getColumnName()))),
0:                 true,
0:                 Metadata.empty()));
1:       } else {
0:         fields.add(new StructField(carbonColumn.getColumnName(),
0:             convertCarbonToSparkDataType(carbonColumn.getDataType()), true, Metadata.empty()));
1:       }
1:     }
0:     return new StructType(fields.toArray(new StructField[0]));
1:   }
commit:c723947
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.keygenerator.directdictionary.DirectDictionaryGenerator;
1: import org.apache.carbondata.core.keygenerator.directdictionary.DirectDictionaryKeyGeneratorFactory;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.encoder.Encoding;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonMeasure;
1: import org.apache.spark.sql.types.DataTypes;
1: import org.apache.spark.sql.types.DecimalType;
1: import org.apache.spark.sql.types.StructField;
/////////////////////////////////////////////////////////////////////////
1: 
1:   private static org.apache.spark.sql.types.DataType convertCarbonToSparkDataType(
1:       DataType carbonDataType) {
1:     if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.STRING) {
1:       return DataTypes.StringType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.SHORT) {
1:       return DataTypes.ShortType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.INT) {
1:       return DataTypes.IntegerType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.LONG) {
1:       return DataTypes.LongType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.DOUBLE) {
1:       return DataTypes.DoubleType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.BOOLEAN) {
1:       return DataTypes.BooleanType;
1:     } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isDecimal(carbonDataType)) {
1:       return DataTypes.createDecimalType();
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.TIMESTAMP) {
1:       return DataTypes.TimestampType;
1:     } else if (carbonDataType == org.apache.carbondata.core.metadata.datatype.DataTypes.DATE) {
1:       return DataTypes.DateType;
1:     } else {
1:       return null;
1:     }
1:   }
1: 
1:   /**
1:    * convert from CarbonColumn array to Spark's StructField array
1:    */
1:   @Override
1:   public Object[] convertCarbonSchemaToSparkSchema(CarbonColumn[] carbonColumns) {
1:     StructField[] fields = new StructField[carbonColumns.length];
0:     for (int i = 0; i < carbonColumns.length; i++) {
1:       CarbonColumn carbonColumn = carbonColumns[i];
1:       if (carbonColumn.isDimension()) {
1:         if (carbonColumn.hasEncoding(Encoding.DIRECT_DICTIONARY)) {
1:           DirectDictionaryGenerator generator = DirectDictionaryKeyGeneratorFactory
1:               .getDirectDictionaryGenerator(carbonColumn.getDataType());
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(generator.getReturnType()), true, null);
1:         } else if (!carbonColumn.hasEncoding(Encoding.DICTIONARY)) {
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(carbonColumn.getDataType()), true, null);
1:         } else if (carbonColumn.isComplex()) {
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(carbonColumn.getDataType()), true, null);
1:         } else {
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(
1:                   org.apache.carbondata.core.metadata.datatype.DataTypes.INT), true, null);
1:         }
1:       } else if (carbonColumn.isMeasure()) {
0:         DataType dataType = carbonColumn.getDataType();
1:         if (dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.BOOLEAN
1:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.SHORT
1:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.INT
1:             || dataType == org.apache.carbondata.core.metadata.datatype.DataTypes.LONG) {
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(dataType), true, null);
1:         } else if (org.apache.carbondata.core.metadata.datatype.DataTypes.isDecimal(dataType)) {
1:           CarbonMeasure measure = (CarbonMeasure) carbonColumn;
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               new DecimalType(measure.getPrecision(), measure.getScale()), true, null);
1:         } else {
1:           fields[i] = new StructField(carbonColumn.getColName(),
1:               convertCarbonToSparkDataType(
1:                   org.apache.carbondata.core.metadata.datatype.DataTypes.DOUBLE), true, null);
1:         }
1:       }
1:     }
1:     return fields;
1:   }
commit:982d03f
/////////////////////////////////////////////////////////////////////////
1: import java.math.BigDecimal;
1: import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;
1: import org.apache.spark.sql.catalyst.util.GenericArrayData;
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   public Object convertFromStringToDecimal(Object data) {
1:   @Override
1:   public Object convertFromBigDecimalToDecimal(Object data) {
0:     if (null == data) {
0:       return null;
1:     }
1:     return org.apache.spark.sql.types.Decimal.apply((BigDecimal)data);
1:   }
1: 
1:   @Override
1:   public Object convertFromDecimalToBigDecimal(Object data) {
1:     return ((org.apache.spark.sql.types.Decimal) data).toJavaBigDecimal();
1:   }
1: 
1:   @Override
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:   public Object convertFromByteToUTF8String(byte[] data) {
1:     return UTF8String.fromBytes(data);
1:   @Override
1:   public byte[] convertFromByteToUTF8Bytes(byte[] data) {
1:     return UTF8String.fromBytes(data).getBytes();
1:   }
1: 
1:   @Override
1: 
1:   @Override
1:   public Object wrapWithGenericArrayData(Object data) {
1:     return new GenericArrayData(data);
1:   }
1: 
1:   @Override
1:   public Object wrapWithGenericRow(Object[] fields) {
1:     return new GenericInternalRow(fields);
1:   }
author:chenliang613
-------------------------------------------------------------------------------
commit:09f7cdd
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.carbondata.spark.util;
1: 
1: import java.io.Serializable;
1: 
1: import org.apache.carbondata.core.util.DataTypeConverter;
1: 
1: import org.apache.spark.unsafe.types.UTF8String;
1: 
1: /**
1:  * Convert java data type to spark data type
1:  */
1: public final class SparkDataTypeConverterImpl implements DataTypeConverter, Serializable {
1: 
1:   private static final long serialVersionUID = -4379212832935070583L;
1: 
0:   public Object convertToDecimal(Object data) {
0:     java.math.BigDecimal javaDecVal = new java.math.BigDecimal(data.toString());
1:     return org.apache.spark.sql.types.Decimal.apply(javaDecVal);
1:   }
1: 
1:   public byte[] convertFromStringToByte(Object data) {
1:     return UTF8String.fromString((String) data).getBytes();
1:   }
1: 
0:   public Object convertFromByteToUTF8String(Object data) {
0:     return UTF8String.fromBytes((byte[]) data);
1:   }
1: 
1:   public Object convertFromStringToUTF8String(Object data) {
1:     return UTF8String.fromString((String) data);
1:   }
1: }
============================================================================
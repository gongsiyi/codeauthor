1:cd6a4ff: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:cd6a4ff:  *
1:cd6a4ff:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cd6a4ff:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
3:cd6a4ff:  */
3:cd6a4ff: 
1:cd6a4ff: package org.apache.carbondata.core.writer;
1:cd6a4ff: 
1:cd6a4ff: import java.io.IOException;
1:cd6a4ff: import java.nio.ByteBuffer;
1:cd6a4ff: import java.nio.charset.Charset;
1:cd6a4ff: import java.util.ArrayList;
1:cd6a4ff: import java.util.List;
1:cd6a4ff: 
1:cd6a4ff: import org.apache.carbondata.common.logging.LogService;
1:cd6a4ff: import org.apache.carbondata.common.logging.LogServiceFactory;
1:d3a09e2: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
1:cd6a4ff: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:ce09aaa: import org.apache.carbondata.core.datastore.filesystem.CarbonFile;
1:ce09aaa: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryColumnMetaChunk;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReader;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReaderImpl;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonUtil;
1:285ce72: import org.apache.carbondata.core.util.path.HDFSLeaseUtils;
1:cd6a4ff: import org.apache.carbondata.format.ColumnDictionaryChunk;
1:cd6a4ff: import org.apache.carbondata.format.ColumnDictionaryChunkMeta;
1:cd6a4ff: 
1:cd6a4ff: import org.apache.thrift.TBase;
1:cd6a4ff: 
3:cd6a4ff: /**
1:cd6a4ff:  * This class is responsible for writing the dictionary file and its metadata
1:cd6a4ff:  */
1:cd6a4ff: public class CarbonDictionaryWriterImpl implements CarbonDictionaryWriter {
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * LOGGER
1:cd6a4ff:    */
1:cd6a4ff:   private static final LogService LOGGER =
1:cd6a4ff:       LogServiceFactory.getLogService(CarbonDictionaryWriterImpl.class.getName());
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * list which will hold values upto maximum of one dictionary chunk size
1:cd6a4ff:    */
1:cd6a4ff:   private List<ByteBuffer> oneDictionaryChunkList;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Meta object which will hold last segment entry details
1:cd6a4ff:    */
1:cd6a4ff:   private CarbonDictionaryColumnMetaChunk chunkMetaObjectForLastSegmentEntry;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * dictionary file and meta thrift writer
1:cd6a4ff:    */
1:cd6a4ff:   private ThriftWriter dictionaryThriftWriter;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * column identifier
1:cd6a4ff:    */
1:d3a09e2:   protected DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * dictionary file path
1:cd6a4ff:    */
1:cd6a4ff:   protected String dictionaryFilePath;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * dictionary metadata file path
1:cd6a4ff:    */
1:cd6a4ff:   protected String dictionaryMetaFilePath;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * start offset of dictionary chunk  for a segment
1:cd6a4ff:    */
1:cd6a4ff:   private long chunk_start_offset;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * end offset of a dictionary chunk for a segment
1:cd6a4ff:    */
1:cd6a4ff:   private long chunk_end_offset;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * total dictionary value record count for one segment
1:cd6a4ff:    */
1:cd6a4ff:   private int totalRecordCount;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * total thrift object chunk count written for one segment
1:cd6a4ff:    */
1:cd6a4ff:   private int chunk_count;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * chunk size for a dictionary file after which data will be written to disk
1:cd6a4ff:    */
1:cd6a4ff:   private int dictionary_one_chunk_size;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * flag to check whether write method is called for first time
1:cd6a4ff:    */
1:cd6a4ff:   private boolean isFirstTime;
1:cd6a4ff: 
1:cd6a4ff:   private static final Charset defaultCharset = Charset.forName(
1:cd6a4ff:       CarbonCommonConstants.DEFAULT_CHARSET);
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * Constructor
1:cd6a4ff:    *
1:1155d4d:    * @param dictionaryColumnUniqueIdentifier column unique identifier
1:cd6a4ff:    */
1:1155d4d:   public CarbonDictionaryWriterImpl(
1:d3a09e2:       DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier) {
1:d3a09e2:     this.dictionaryColumnUniqueIdentifier = dictionaryColumnUniqueIdentifier;
1:cd6a4ff:     this.isFirstTime = true;
2:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will write the data in thrift format to disk. This method will be guided by
1:cd6a4ff:    * parameter dictionary_one_chunk_size and data will be divided into chunks
1:cd6a4ff:    * based on this parameter
1:cd6a4ff:    *
1:cd6a4ff:    * @param value unique dictionary value
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   @Override public void write(String value) throws IOException {
1:cd6a4ff:     write(value.getBytes(defaultCharset));
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will write the data in thrift format to disk. This method will be guided by
1:cd6a4ff:    * parameter dictionary_one_chunk_size and data will be divided into chunks
1:cd6a4ff:    * based on this parameter
1:cd6a4ff:    *
1:cd6a4ff:    * @param value unique dictionary value
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:daa6465:   private void write(byte[] value) throws IOException {
1:cd6a4ff:     if (isFirstTime) {
1:cd6a4ff:       init();
1:cd6a4ff:       isFirstTime = false;
1:cd6a4ff:     }
1:943588d: 
1:943588d:     if (value.length > CarbonCommonConstants.MAX_CHARS_PER_COLUMN_DEFAULT) {
1:943588d:       throw new IOException("Dataload failed, String size cannot exceed "
1:943588d:           + CarbonCommonConstants.MAX_CHARS_PER_COLUMN_DEFAULT + " bytes");
1:943588d:     }
1:cd6a4ff:     // if one chunk size is equal to list size then write the data to file
1:cd6a4ff:     checkAndWriteDictionaryChunkToFile();
1:cd6a4ff:     oneDictionaryChunkList.add(ByteBuffer.wrap(value));
1:cd6a4ff:     totalRecordCount++;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will write the data in thrift format to disk. This method will not be guided by
1:cd6a4ff:    * parameter dictionary_one_chunk_size and complete data will be written as one chunk
1:cd6a4ff:    *
1:cd6a4ff:    * @param valueList list of byte array. Each byte array is unique dictionary value
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   @Override public void write(List<byte[]> valueList) throws IOException {
1:cd6a4ff:     if (isFirstTime) {
1:cd6a4ff:       init();
1:cd6a4ff:       isFirstTime = false;
1:cd6a4ff:     }
1:cd6a4ff:     for (byte[] value : valueList) {
1:cd6a4ff:       oneDictionaryChunkList.add(ByteBuffer.wrap(value));
1:cd6a4ff:       totalRecordCount++;
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * write dictionary metadata file and close thrift object
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   @Override public void close() throws IOException {
1:ebe987b:     if (null != dictionaryThriftWriter && dictionaryThriftWriter.isOpen()) {
1:e54456f:       try {
1:e54456f:         // if stream is open then only need to write dictionary file.
1:e54456f:         writeDictionaryFile();
1:e54456f:       } finally {
1:e54456f:         // close the thrift writer for dictionary file
1:e54456f:         closeThriftWriter();
1:e54456f:       }
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * check if the threshold has been reached for the number of
1:cd6a4ff:    * values that can kept in memory and then flush the data to file
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void checkAndWriteDictionaryChunkToFile() throws IOException {
1:cd6a4ff:     if (oneDictionaryChunkList.size() >= dictionary_one_chunk_size) {
2:cd6a4ff:       writeDictionaryFile();
1:cd6a4ff:       createChunkList();
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will serialize the object of dictionary file
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void writeDictionaryFile() throws IOException {
1:cd6a4ff:     ColumnDictionaryChunk columnDictionaryChunk = new ColumnDictionaryChunk();
1:cd6a4ff:     columnDictionaryChunk.setValues(oneDictionaryChunkList);
1:cd6a4ff:     writeThriftObject(columnDictionaryChunk);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will check and created the directory path where dictionary file has to be created
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void init() throws IOException {
1:cd6a4ff:     initDictionaryChunkSize();
1:cd6a4ff:     initPaths();
1:cd6a4ff:     boolean dictFileExists = CarbonUtil.isFileExists(this.dictionaryFilePath);
1:cd6a4ff:     if (dictFileExists && CarbonUtil.isFileExists(this.dictionaryMetaFilePath)) {
1:cd6a4ff:       this.chunk_start_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:       validateDictionaryFileOffsetWithLastSegmentEntryOffset();
1:cd6a4ff:     } else if (dictFileExists) {
1:cd6a4ff:       FileFactory.getCarbonFile(dictionaryFilePath, FileFactory.getFileType(dictionaryFilePath))
1:cd6a4ff:           .delete();
1:cd6a4ff:     }
1:cd6a4ff:     openThriftWriter(this.dictionaryFilePath);
1:cd6a4ff:     createChunkList();
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   protected void initPaths() {
1:29dc302:     this.dictionaryFilePath = dictionaryColumnUniqueIdentifier.getDictionaryFilePath();
1:29dc302:     this.dictionaryMetaFilePath = dictionaryColumnUniqueIdentifier.getDictionaryMetaFilePath();
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * initialize the value of dictionary chunk that can be kept in memory at a time
1:cd6a4ff:    */
1:cd6a4ff:   private void initDictionaryChunkSize() {
1:7e0584e:     dictionary_one_chunk_size = CarbonUtil.getDictionaryChunkSize();
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * initialise one dictionary size chunk list and increment chunk count
1:cd6a4ff:    */
1:cd6a4ff:   private void createChunkList() {
1:cd6a4ff:     this.oneDictionaryChunkList = new ArrayList<ByteBuffer>(dictionary_one_chunk_size);
1:cd6a4ff:     chunk_count++;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * if file already exists then read metadata file and
1:cd6a4ff:    * validate the last entry end offset with file size. If
1:cd6a4ff:    * they are not equal that means some invalid data is present which needs
1:cd6a4ff:    * to be truncated
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void validateDictionaryFileOffsetWithLastSegmentEntryOffset() throws IOException {
1:cd6a4ff:     // read last dictionary chunk meta entry from dictionary metadata file
1:cd6a4ff:     chunkMetaObjectForLastSegmentEntry = getChunkMetaObjectForLastSegmentEntry();
1:808999c:     int bytesToTruncate = 0;
1:808999c:     if (null != chunkMetaObjectForLastSegmentEntry) {
1:808999c:       bytesToTruncate =
1:d3a09e2:           (int) (chunk_start_offset - chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:808999c:     }
1:cd6a4ff:     if (bytesToTruncate > 0) {
1:d3a09e2:       LOGGER.info("some inconsistency in dictionary file for column "
1:d3a09e2:           + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier());
1:cd6a4ff:       // truncate the dictionary data till chunk meta end offset
1:cd6a4ff:       FileFactory.FileType fileType = FileFactory.getFileType(this.dictionaryFilePath);
1:cd6a4ff:       CarbonFile carbonFile = FileFactory.getCarbonFile(this.dictionaryFilePath, fileType);
1:cd6a4ff:       boolean truncateSuccess = carbonFile
1:cd6a4ff:           .truncate(this.dictionaryFilePath, chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:cd6a4ff:       if (!truncateSuccess) {
1:d3a09e2:         LOGGER.info("Diction file not truncated successfully for column "
1:d3a09e2:             + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier());
1:cd6a4ff:       }
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will write the dictionary metadata file for a given column
1:cd6a4ff:    *
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void writeDictionaryMetadataFile() throws IOException {
1:cd6a4ff:     // Format of dictionary metadata file
1:cd6a4ff:     // min, max, start offset, end offset and chunk count
1:cd6a4ff:     int min_surrogate_key = 0;
1:cd6a4ff:     int max_surrogate_key = 0;
1:cd6a4ff:     // case 1: first time dictionary writing
1:cd6a4ff:     // previousMax = 0, totalRecordCount = 5, min = 1, max= 5
1:cd6a4ff:     // case2: file already exists
1:cd6a4ff:     // previousMax = 5, totalRecordCount = 10, min = 6, max = 15
1:cd6a4ff:     // case 3: no unique values, total records 0
1:cd6a4ff:     // previousMax = 15, totalRecordCount = 0, min = 15, max = 15
1:cd6a4ff:     // both min and max equal to previous max
1:cd6a4ff:     if (null != chunkMetaObjectForLastSegmentEntry) {
1:cd6a4ff:       if (0 == totalRecordCount) {
1:cd6a4ff:         min_surrogate_key = chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key();
1:cd6a4ff:       } else {
1:cd6a4ff:         min_surrogate_key = chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key() + 1;
1:cd6a4ff:       }
1:cd6a4ff:       max_surrogate_key =
1:cd6a4ff:           chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key() + totalRecordCount;
1:cd6a4ff:     } else {
1:cd6a4ff:       if (totalRecordCount > 0) {
1:cd6a4ff:         min_surrogate_key = 1;
1:cd6a4ff:       }
1:cd6a4ff:       max_surrogate_key = totalRecordCount;
1:cd6a4ff:     }
1:cd6a4ff:     ColumnDictionaryChunkMeta dictionaryChunkMeta =
1:cd6a4ff:         new ColumnDictionaryChunkMeta(min_surrogate_key, max_surrogate_key, chunk_start_offset,
1:cd6a4ff:             chunk_end_offset, chunk_count);
1:e54456f:     try {
1:e54456f:       openThriftWriter(this.dictionaryMetaFilePath);
1:e54456f:       // write dictionary metadata file
1:e54456f:       writeThriftObject(dictionaryChunkMeta);
1:e54456f:       LOGGER.info("Dictionary metadata file written successfully for column "
1:d3a09e2:           + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier() + " at path "
1:d3a09e2:           + this.dictionaryMetaFilePath);
1:e54456f:     } finally {
1:e54456f:       closeThriftWriter();
1:e54456f:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * open thrift writer for writing dictionary chunk/meta object
1:cd6a4ff:    *
1:cd6a4ff:    * @param dictionaryFile can be dictionary file name or dictionary metadata file name
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void openThriftWriter(String dictionaryFile) throws IOException {
1:cd6a4ff:     // create thrift writer instance
1:cd6a4ff:     dictionaryThriftWriter = new ThriftWriter(dictionaryFile, true);
1:cd6a4ff:     // open the file stream
1:285ce72:     try {
1:285ce72:       dictionaryThriftWriter.open();
1:285ce72:     } catch (IOException e) {
1:285ce72:       // Cases to handle
1:285ce72:       // 1. Handle File lease recovery
1:285ce72:       if (HDFSLeaseUtils.checkExceptionMessageForLeaseRecovery(e.getMessage())) {
1:285ce72:         LOGGER.error(e, "Lease recovery exception encountered for file: " + dictionaryFile);
1:285ce72:         boolean leaseRecovered = HDFSLeaseUtils.recoverFileLease(dictionaryFile);
1:285ce72:         if (leaseRecovered) {
1:285ce72:           // try to open output stream again after recovering the lease on file
1:285ce72:           dictionaryThriftWriter.open();
1:285ce72:         } else {
1:285ce72:           throw e;
1:285ce72:         }
1:285ce72:       } else {
1:285ce72:         throw e;
1:285ce72:       }
1:285ce72:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will write the thrift object to a file
1:cd6a4ff:    *
1:cd6a4ff:    * @param dictionaryThriftObject can be dictionary thrift object or dictionary metadata
1:cd6a4ff:    *                               thrift object
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private void writeThriftObject(TBase dictionaryThriftObject) throws IOException {
1:cd6a4ff:     dictionaryThriftWriter.write(dictionaryThriftObject);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * close dictionary thrift writer
1:cd6a4ff:    */
1:70256e7:   private void closeThriftWriter() throws IOException {
3:cd6a4ff:     if (null != dictionaryThriftWriter) {
1:cd6a4ff:       dictionaryThriftWriter.close();
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will read the dictionary chunk metadata thrift object for last entry
1:cd6a4ff:    *
1:cd6a4ff:    * @return last entry of dictionary meta chunk
1:cd6a4ff:    * @throws IOException if an I/O error occurs
1:cd6a4ff:    */
1:cd6a4ff:   private CarbonDictionaryColumnMetaChunk getChunkMetaObjectForLastSegmentEntry()
1:cd6a4ff:       throws IOException {
1:cd6a4ff:     CarbonDictionaryColumnMetaChunk carbonDictionaryColumnMetaChunk = null;
1:cd6a4ff:     CarbonDictionaryMetadataReader columnMetadataReaderImpl = getDictionaryMetadataReader();
2:cd6a4ff:     try {
1:cd6a4ff:       // read the last segment entry for dictionary metadata
1:cd6a4ff:       carbonDictionaryColumnMetaChunk =
1:cd6a4ff:           columnMetadataReaderImpl.readLastEntryOfDictionaryMetaChunk();
1:cd6a4ff:     } finally {
1:cd6a4ff:       // Close metadata reader
1:cd6a4ff:       columnMetadataReaderImpl.close();
1:cd6a4ff:     }
1:cd6a4ff:     return carbonDictionaryColumnMetaChunk;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * @return
1:cd6a4ff:    */
1:cd6a4ff:   protected CarbonDictionaryMetadataReader getDictionaryMetadataReader() {
1:1155d4d:     return new CarbonDictionaryMetadataReaderImpl(dictionaryColumnUniqueIdentifier);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   @Override public void commit() throws IOException {
1:ebe987b:     if (null != dictionaryThriftWriter && dictionaryThriftWriter.isOpen()) {
1:cd6a4ff:       this.chunk_end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:       writeDictionaryMetadataFile();
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1:   private void write(byte[] value) throws IOException {
author:dhatchayani
-------------------------------------------------------------------------------
commit:943588d
/////////////////////////////////////////////////////////////////////////
1: 
1:     if (value.length > CarbonCommonConstants.MAX_CHARS_PER_COLUMN_DEFAULT) {
1:       throw new IOException("Dataload failed, String size cannot exceed "
1:           + CarbonCommonConstants.MAX_CHARS_PER_COLUMN_DEFAULT + " bytes");
1:     }
commit:d3a09e2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
/////////////////////////////////////////////////////////////////////////
1:   protected DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier;
/////////////////////////////////////////////////////////////////////////
0:    * @param dictionaryColumnUniqueIdentifier      column unique identifier
0:   public CarbonDictionaryWriterImpl(String storePath, CarbonTableIdentifier carbonTableIdentifier,
1:       DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier) {
1:     this.dictionaryColumnUniqueIdentifier = dictionaryColumnUniqueIdentifier;
/////////////////////////////////////////////////////////////////////////
0:     CarbonTablePath carbonTablePath = pathService
0:         .getCarbonTablePath(this.storePath, carbonTableIdentifier,
0:             dictionaryColumnUniqueIdentifier);
0:     this.dictionaryFilePath = carbonTablePath.getDictionaryFilePath(
0:         dictionaryColumnUniqueIdentifier.getColumnIdentifier().getColumnId());
0:     this.dictionaryMetaFilePath = carbonTablePath.getDictionaryMetaFilePath(
0:         dictionaryColumnUniqueIdentifier.getColumnIdentifier().getColumnId());
/////////////////////////////////////////////////////////////////////////
1:           (int) (chunk_start_offset - chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:       LOGGER.info("some inconsistency in dictionary file for column "
1:           + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier());
1:         LOGGER.info("Diction file not truncated successfully for column "
1:             + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier());
/////////////////////////////////////////////////////////////////////////
1:           + this.dictionaryColumnUniqueIdentifier.getColumnIdentifier() + " at path "
1:           + this.dictionaryMetaFilePath);
/////////////////////////////////////////////////////////////////////////
0:         dictionaryColumnUniqueIdentifier);
author:manishgupta88
-------------------------------------------------------------------------------
commit:29dc302
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     this.dictionaryFilePath = dictionaryColumnUniqueIdentifier.getDictionaryFilePath();
1:     this.dictionaryMetaFilePath = dictionaryColumnUniqueIdentifier.getDictionaryMetaFilePath();
commit:285ce72
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.path.HDFSLeaseUtils;
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       dictionaryThriftWriter.open();
1:     } catch (IOException e) {
1:       // Cases to handle
1:       // 1. Handle File lease recovery
1:       if (HDFSLeaseUtils.checkExceptionMessageForLeaseRecovery(e.getMessage())) {
1:         LOGGER.error(e, "Lease recovery exception encountered for file: " + dictionaryFile);
1:         boolean leaseRecovered = HDFSLeaseUtils.recoverFileLease(dictionaryFile);
1:         if (leaseRecovered) {
1:           // try to open output stream again after recovering the lease on file
1:           dictionaryThriftWriter.open();
1:         } else {
1:           throw e;
1:         }
1:       } else {
1:         throw e;
1:       }
1:     }
commit:70256e7
/////////////////////////////////////////////////////////////////////////
1:   private void closeThriftWriter() throws IOException {
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:1155d4d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:    * @param dictionaryColumnUniqueIdentifier column unique identifier
1:   public CarbonDictionaryWriterImpl(
/////////////////////////////////////////////////////////////////////////
0:         .getCarbonTablePath(dictionaryColumnUniqueIdentifier.getAbsoluteCarbonTableIdentifier(),
/////////////////////////////////////////////////////////////////////////
1:     return new CarbonDictionaryMetadataReaderImpl(dictionaryColumnUniqueIdentifier);
commit:e54456f
/////////////////////////////////////////////////////////////////////////
1:       try {
1:         // if stream is open then only need to write dictionary file.
1:         writeDictionaryFile();
1:       } finally {
1:         // close the thrift writer for dictionary file
1:         closeThriftWriter();
1:       }
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       openThriftWriter(this.dictionaryMetaFilePath);
1:       // write dictionary metadata file
1:       writeThriftObject(dictionaryChunkMeta);
1:       LOGGER.info("Dictionary metadata file written successfully for column "
0:           + this.columnIdentifier + " at path " + this.dictionaryMetaFilePath);
1:     } finally {
1:       closeThriftWriter();
1:     }
author:QiangCai
-------------------------------------------------------------------------------
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:jackylk
-------------------------------------------------------------------------------
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.filesystem.CarbonFile;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
0: import org.apache.carbondata.core.metadata.CarbonTableIdentifier;
0: import org.apache.carbondata.core.metadata.ColumnIdentifier;
0: import org.apache.carbondata.core.service.CarbonCommonFactory;
0: import org.apache.carbondata.core.util.path.CarbonTablePath;
author:vincentchenfei
-------------------------------------------------------------------------------
commit:808999c
/////////////////////////////////////////////////////////////////////////
1:     int bytesToTruncate = 0;
1:     if (null != chunkMetaObjectForLastSegmentEntry) {
1:       bytesToTruncate =
0:               (int) (chunk_start_offset - chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:     }
author:hexiaoqiao
-------------------------------------------------------------------------------
commit:a65ca7c
/////////////////////////////////////////////////////////////////////////
0:    * carbon dictionary data store path
0:   protected String storePath;
/////////////////////////////////////////////////////////////////////////
0:    * @param storePath             carbon dictionary data store path
0:   public CarbonDictionaryWriterImpl(String storePath,
0:     this.storePath = storePath;
/////////////////////////////////////////////////////////////////////////
0:             this.storePath, carbonTableIdentifier);
/////////////////////////////////////////////////////////////////////////
0:     return new CarbonDictionaryMetadataReaderImpl(storePath, carbonTableIdentifier,
commit:77c90b8
/////////////////////////////////////////////////////////////////////////
0:     CarbonTablePath carbonTablePath = pathService.getCarbonTablePath(
author:ravikiran
-------------------------------------------------------------------------------
commit:ebe987b
/////////////////////////////////////////////////////////////////////////
1:     if (null != dictionaryThriftWriter && dictionaryThriftWriter.isOpen()) {
0:       // if stream is open then only need to write dictionary file.
/////////////////////////////////////////////////////////////////////////
1:     if (null != dictionaryThriftWriter && dictionaryThriftWriter.isOpen()) {
author:manishgupt88
-------------------------------------------------------------------------------
commit:7e0584e
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     dictionary_one_chunk_size = CarbonUtil.getDictionaryChunkSize();
author:ravipesala
-------------------------------------------------------------------------------
commit:cd6a4ff
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
1: package org.apache.carbondata.core.writer;
1: 
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.nio.charset.Charset;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
0: import org.apache.carbondata.common.factory.CarbonCommonFactory;
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.carbon.CarbonTableIdentifier;
0: import org.apache.carbondata.core.carbon.ColumnIdentifier;
0: import org.apache.carbondata.core.carbon.path.CarbonTablePath;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.datastorage.store.filesystem.CarbonFile;
0: import org.apache.carbondata.core.datastorage.store.impl.FileFactory;
1: import org.apache.carbondata.core.reader.CarbonDictionaryColumnMetaChunk;
1: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReader;
1: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReaderImpl;
0: import org.apache.carbondata.core.service.PathService;
0: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: import org.apache.carbondata.format.ColumnDictionaryChunk;
1: import org.apache.carbondata.format.ColumnDictionaryChunkMeta;
1: 
1: import org.apache.thrift.TBase;
1: 
1: /**
1:  * This class is responsible for writing the dictionary file and its metadata
1:  */
1: public class CarbonDictionaryWriterImpl implements CarbonDictionaryWriter {
1: 
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(CarbonDictionaryWriterImpl.class.getName());
1: 
1:   /**
0:    * carbon type identifier
1:    */
0:   protected CarbonTableIdentifier carbonTableIdentifier;
1: 
1:   /**
1:    * list which will hold values upto maximum of one dictionary chunk size
1:    */
1:   private List<ByteBuffer> oneDictionaryChunkList;
1: 
1:   /**
1:    * Meta object which will hold last segment entry details
1:    */
1:   private CarbonDictionaryColumnMetaChunk chunkMetaObjectForLastSegmentEntry;
1: 
1:   /**
1:    * dictionary file and meta thrift writer
1:    */
1:   private ThriftWriter dictionaryThriftWriter;
1: 
1:   /**
1:    * column identifier
1:    */
0:   protected ColumnIdentifier columnIdentifier;
1: 
1:   /**
0:    * HDFS store path
1:    */
0:   protected String hdfsStorePath;
1: 
1:   /**
1:    * dictionary file path
1:    */
1:   protected String dictionaryFilePath;
1: 
1:   /**
1:    * dictionary metadata file path
1:    */
1:   protected String dictionaryMetaFilePath;
1: 
1:   /**
1:    * start offset of dictionary chunk  for a segment
1:    */
1:   private long chunk_start_offset;
1: 
1:   /**
1:    * end offset of a dictionary chunk for a segment
1:    */
1:   private long chunk_end_offset;
1: 
1:   /**
1:    * total dictionary value record count for one segment
1:    */
1:   private int totalRecordCount;
1: 
1:   /**
1:    * total thrift object chunk count written for one segment
1:    */
1:   private int chunk_count;
1: 
1:   /**
1:    * chunk size for a dictionary file after which data will be written to disk
1:    */
1:   private int dictionary_one_chunk_size;
1: 
1:   /**
1:    * flag to check whether write method is called for first time
1:    */
1:   private boolean isFirstTime;
1: 
1:   private static final Charset defaultCharset = Charset.forName(
1:       CarbonCommonConstants.DEFAULT_CHARSET);
1: 
1:   /**
1:    * Constructor
1:    *
0:    * @param hdfsStorePath         HDFS store path
0:    * @param carbonTableIdentifier table identifier which will give table name and database name
0:    * @param columnIdentifier      column unique identifier
1:    */
0:   public CarbonDictionaryWriterImpl(String hdfsStorePath,
0:       CarbonTableIdentifier carbonTableIdentifier, ColumnIdentifier columnIdentifier) {
0:     this.carbonTableIdentifier = carbonTableIdentifier;
0:     this.columnIdentifier = columnIdentifier;
0:     this.hdfsStorePath = hdfsStorePath;
1:     this.isFirstTime = true;
1:   }
1: 
1:   /**
1:    * This method will write the data in thrift format to disk. This method will be guided by
1:    * parameter dictionary_one_chunk_size and data will be divided into chunks
1:    * based on this parameter
1:    *
1:    * @param value unique dictionary value
1:    * @throws IOException if an I/O error occurs
1:    */
1:   @Override public void write(String value) throws IOException {
1:     write(value.getBytes(defaultCharset));
1:   }
1: 
1:   /**
1:    * This method will write the data in thrift format to disk. This method will be guided by
1:    * parameter dictionary_one_chunk_size and data will be divided into chunks
1:    * based on this parameter
1:    *
1:    * @param value unique dictionary value
1:    * @throws IOException if an I/O error occurs
1:    */
0:   @Override public void write(byte[] value) throws IOException {
1:     if (isFirstTime) {
1:       init();
1:       isFirstTime = false;
1:     }
1:     // if one chunk size is equal to list size then write the data to file
1:     checkAndWriteDictionaryChunkToFile();
1:     oneDictionaryChunkList.add(ByteBuffer.wrap(value));
1:     totalRecordCount++;
1:   }
1: 
1:   /**
1:    * This method will write the data in thrift format to disk. This method will not be guided by
1:    * parameter dictionary_one_chunk_size and complete data will be written as one chunk
1:    *
1:    * @param valueList list of byte array. Each byte array is unique dictionary value
1:    * @throws IOException if an I/O error occurs
1:    */
1:   @Override public void write(List<byte[]> valueList) throws IOException {
1:     if (isFirstTime) {
1:       init();
1:       isFirstTime = false;
1:     }
1:     for (byte[] value : valueList) {
1:       oneDictionaryChunkList.add(ByteBuffer.wrap(value));
1:       totalRecordCount++;
1:     }
1:   }
1: 
1:   /**
1:    * write dictionary metadata file and close thrift object
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   @Override public void close() throws IOException {
1:     if (null != dictionaryThriftWriter) {
1:       writeDictionaryFile();
0:       // close the thrift writer for dictionary file
0:       closeThriftWriter();
1:     }
1:   }
1: 
1:   /**
1:    * check if the threshold has been reached for the number of
1:    * values that can kept in memory and then flush the data to file
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void checkAndWriteDictionaryChunkToFile() throws IOException {
1:     if (oneDictionaryChunkList.size() >= dictionary_one_chunk_size) {
1:       writeDictionaryFile();
1:       createChunkList();
1:     }
1:   }
1: 
1:   /**
1:    * This method will serialize the object of dictionary file
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void writeDictionaryFile() throws IOException {
1:     ColumnDictionaryChunk columnDictionaryChunk = new ColumnDictionaryChunk();
1:     columnDictionaryChunk.setValues(oneDictionaryChunkList);
1:     writeThriftObject(columnDictionaryChunk);
1:   }
1: 
1:   /**
1:    * This method will check and created the directory path where dictionary file has to be created
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void init() throws IOException {
1:     initDictionaryChunkSize();
1:     initPaths();
1:     boolean dictFileExists = CarbonUtil.isFileExists(this.dictionaryFilePath);
1:     if (dictFileExists && CarbonUtil.isFileExists(this.dictionaryMetaFilePath)) {
1:       this.chunk_start_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:       validateDictionaryFileOffsetWithLastSegmentEntryOffset();
1:     } else if (dictFileExists) {
1:       FileFactory.getCarbonFile(dictionaryFilePath, FileFactory.getFileType(dictionaryFilePath))
1:           .delete();
1:     }
1:     openThriftWriter(this.dictionaryFilePath);
1:     createChunkList();
1:   }
1: 
1:   protected void initPaths() {
0:     PathService pathService = CarbonCommonFactory.getPathService();
0:     CarbonTablePath carbonTablePath = pathService.getCarbonTablePath(columnIdentifier,
0:             this.hdfsStorePath, carbonTableIdentifier);
0:     this.dictionaryFilePath = carbonTablePath.getDictionaryFilePath(columnIdentifier.getColumnId());
0:     this.dictionaryMetaFilePath =
0:         carbonTablePath.getDictionaryMetaFilePath(columnIdentifier.getColumnId());
1:   }
1: 
1:   /**
1:    * initialize the value of dictionary chunk that can be kept in memory at a time
1:    */
1:   private void initDictionaryChunkSize() {
1:     try {
0:       dictionary_one_chunk_size = Integer.parseInt(CarbonProperties.getInstance()
0:           .getProperty(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE,
0:               CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE_DEFAULT));
0:     } catch (NumberFormatException e) {
0:       dictionary_one_chunk_size =
0:           Integer.parseInt(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE_DEFAULT);
0:       LOGGER.error("Dictionary chunk size not configured properly. Taking default size "
0:               + dictionary_one_chunk_size);
1:     }
1:   }
1: 
1:   /**
1:    * initialise one dictionary size chunk list and increment chunk count
1:    */
1:   private void createChunkList() {
1:     this.oneDictionaryChunkList = new ArrayList<ByteBuffer>(dictionary_one_chunk_size);
1:     chunk_count++;
1:   }
1: 
1:   /**
1:    * if file already exists then read metadata file and
1:    * validate the last entry end offset with file size. If
1:    * they are not equal that means some invalid data is present which needs
1:    * to be truncated
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void validateDictionaryFileOffsetWithLastSegmentEntryOffset() throws IOException {
1:     // read last dictionary chunk meta entry from dictionary metadata file
1:     chunkMetaObjectForLastSegmentEntry = getChunkMetaObjectForLastSegmentEntry();
0:     int bytesToTruncate =
0:         (int) (chunk_start_offset - chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:     if (bytesToTruncate > 0) {
0:       LOGGER.info("some inconsistency in dictionary file for column " + this.columnIdentifier);
1:       // truncate the dictionary data till chunk meta end offset
1:       FileFactory.FileType fileType = FileFactory.getFileType(this.dictionaryFilePath);
1:       CarbonFile carbonFile = FileFactory.getCarbonFile(this.dictionaryFilePath, fileType);
1:       boolean truncateSuccess = carbonFile
1:           .truncate(this.dictionaryFilePath, chunkMetaObjectForLastSegmentEntry.getEnd_offset());
1:       if (!truncateSuccess) {
0:         LOGGER.info("Diction file not truncated successfully for column " + this.columnIdentifier);
1:       }
1:     }
1:   }
1: 
1:   /**
1:    * This method will write the dictionary metadata file for a given column
1:    *
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void writeDictionaryMetadataFile() throws IOException {
1:     // Format of dictionary metadata file
1:     // min, max, start offset, end offset and chunk count
1:     int min_surrogate_key = 0;
1:     int max_surrogate_key = 0;
1:     // case 1: first time dictionary writing
1:     // previousMax = 0, totalRecordCount = 5, min = 1, max= 5
1:     // case2: file already exists
1:     // previousMax = 5, totalRecordCount = 10, min = 6, max = 15
1:     // case 3: no unique values, total records 0
1:     // previousMax = 15, totalRecordCount = 0, min = 15, max = 15
1:     // both min and max equal to previous max
1:     if (null != chunkMetaObjectForLastSegmentEntry) {
1:       if (0 == totalRecordCount) {
1:         min_surrogate_key = chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key();
1:       } else {
1:         min_surrogate_key = chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key() + 1;
1:       }
1:       max_surrogate_key =
1:           chunkMetaObjectForLastSegmentEntry.getMax_surrogate_key() + totalRecordCount;
1:     } else {
1:       if (totalRecordCount > 0) {
1:         min_surrogate_key = 1;
1:       }
1:       max_surrogate_key = totalRecordCount;
1:     }
1:     ColumnDictionaryChunkMeta dictionaryChunkMeta =
1:         new ColumnDictionaryChunkMeta(min_surrogate_key, max_surrogate_key, chunk_start_offset,
1:             chunk_end_offset, chunk_count);
0:     openThriftWriter(this.dictionaryMetaFilePath);
0:     // write dictionary metadata file
0:     writeThriftObject(dictionaryChunkMeta);
0:     closeThriftWriter();
0:     LOGGER.info("Dictionary metadata file written successfully for column " + this.columnIdentifier
0:             + " at path " + this.dictionaryMetaFilePath);
1:   }
1: 
1:   /**
1:    * open thrift writer for writing dictionary chunk/meta object
1:    *
1:    * @param dictionaryFile can be dictionary file name or dictionary metadata file name
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void openThriftWriter(String dictionaryFile) throws IOException {
1:     // create thrift writer instance
1:     dictionaryThriftWriter = new ThriftWriter(dictionaryFile, true);
1:     // open the file stream
0:     dictionaryThriftWriter.open();
1:   }
1: 
1:   /**
1:    * This method will write the thrift object to a file
1:    *
1:    * @param dictionaryThriftObject can be dictionary thrift object or dictionary metadata
1:    *                               thrift object
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private void writeThriftObject(TBase dictionaryThriftObject) throws IOException {
1:     dictionaryThriftWriter.write(dictionaryThriftObject);
1:   }
1: 
1:   /**
1:    * close dictionary thrift writer
1:    */
0:   private void closeThriftWriter() {
1:     if (null != dictionaryThriftWriter) {
1:       dictionaryThriftWriter.close();
1:     }
1:   }
1: 
1:   /**
1:    * This method will read the dictionary chunk metadata thrift object for last entry
1:    *
1:    * @return last entry of dictionary meta chunk
1:    * @throws IOException if an I/O error occurs
1:    */
1:   private CarbonDictionaryColumnMetaChunk getChunkMetaObjectForLastSegmentEntry()
1:       throws IOException {
1:     CarbonDictionaryColumnMetaChunk carbonDictionaryColumnMetaChunk = null;
1:     CarbonDictionaryMetadataReader columnMetadataReaderImpl = getDictionaryMetadataReader();
1:     try {
1:       // read the last segment entry for dictionary metadata
1:       carbonDictionaryColumnMetaChunk =
1:           columnMetadataReaderImpl.readLastEntryOfDictionaryMetaChunk();
1:     } finally {
1:       // Close metadata reader
1:       columnMetadataReaderImpl.close();
1:     }
1:     return carbonDictionaryColumnMetaChunk;
1:   }
1: 
1:   /**
1:    * @return
1:    */
1:   protected CarbonDictionaryMetadataReader getDictionaryMetadataReader() {
0:     return new CarbonDictionaryMetadataReaderImpl(hdfsStorePath, carbonTableIdentifier,
0:         columnIdentifier);
1:   }
1: 
1:   @Override public void commit() throws IOException {
1:     if (null != dictionaryThriftWriter) {
1:       this.chunk_end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:       writeDictionaryMetadataFile();
1:     }
1:   }
1: }
============================================================================
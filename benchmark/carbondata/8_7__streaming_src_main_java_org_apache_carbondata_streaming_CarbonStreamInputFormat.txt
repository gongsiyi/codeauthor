1:d7393da: /*
1:d7393da:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:d7393da:  * contributor license agreements.  See the NOTICE file distributed with
1:d7393da:  * this work for additional information regarding copyright ownership.
1:d7393da:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:d7393da:  * (the "License"); you may not use this file except in compliance with
1:d7393da:  * the License.  You may obtain a copy of the License at
1:d7393da:  *
1:d7393da:  *    http://www.apache.org/licenses/LICENSE-2.0
1:d7393da:  *
1:d7393da:  * Unless required by applicable law or agreed to in writing, software
1:d7393da:  * distributed under the License is distributed on an "AS IS" BASIS,
1:d7393da:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:d7393da:  * See the License for the specific language governing permissions and
1:d7393da:  * limitations under the License.
1:d7393da:  */
3:d7393da: 
1:c723947: package org.apache.carbondata.streaming;
1:d7393da: 
1:d7393da: import java.io.IOException;
1:bcef656: import java.lang.reflect.Constructor;
1:d7393da: 
1:d7393da: import org.apache.carbondata.core.cache.Cache;
1:d7393da: import org.apache.carbondata.core.cache.dictionary.Dictionary;
1:d7393da: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
1:29dc302: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:d7393da: import org.apache.carbondata.core.metadata.datatype.DataType;
1:d7393da: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:d7393da: import org.apache.carbondata.core.metadata.encoder.Encoding;
1:d7393da: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:d7393da: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:d7393da: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
1:d7393da: import org.apache.carbondata.core.scan.complextypes.ArrayQueryType;
1:d7393da: import org.apache.carbondata.core.scan.complextypes.PrimitiveQueryType;
1:d7393da: import org.apache.carbondata.core.scan.complextypes.StructQueryType;
1:d7393da: import org.apache.carbondata.core.scan.filter.GenericQueryType;
1:bcef656: import org.apache.carbondata.core.scan.model.QueryModel;
1:d7393da: import org.apache.carbondata.core.util.CarbonUtil;
1:bcef656: import org.apache.carbondata.hadoop.InputMetricsStats;
1:bcef656: import org.apache.carbondata.streaming.CarbonStreamUtils;
1:d7393da: 
1:d7393da: import org.apache.hadoop.mapreduce.InputSplit;
1:d7393da: import org.apache.hadoop.mapreduce.RecordReader;
1:d7393da: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1:d7393da: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:d7393da: 
1:d7393da: /**
1:d7393da:  * Stream input format
1:d7393da:  */
1:d7393da: public class CarbonStreamInputFormat extends FileInputFormat<Void, Object> {
1:d7393da: 
1:d7393da:   public static final String READ_BUFFER_SIZE = "carbon.stream.read.buffer.size";
1:d7393da:   public static final String READ_BUFFER_SIZE_DEFAULT = "65536";
1:bcef656:   public static final String STREAM_RECORD_READER_INSTANCE =
1:bcef656:       "org.apache.carbondata.stream.CarbonStreamRecordReader";
1:bcef656:   // return raw row for handoff
1:bcef656:   private boolean useRawRow = false;
1:d7393da: 
1:bcef656:   public void setUseRawRow(boolean useRawRow) {
1:bcef656:     this.useRawRow = useRawRow;
1:bcef656:   }
1:bcef656: 
1:bcef656:   public void setInputMetricsStats(InputMetricsStats inputMetricsStats) {
1:bcef656:     this.inputMetricsStats = inputMetricsStats;
1:bcef656:   }
1:bcef656: 
1:74c3eb1:   public void setIsVectorReader(boolean vectorReader) {
1:bcef656:     isVectorReader = vectorReader;
1:bcef656:   }
1:bcef656: 
1:bcef656:   public void setModel(QueryModel model) {
1:bcef656:     this.model = model;
1:bcef656:   }
1:bcef656: 
1:bcef656:   // InputMetricsStats
1:bcef656:   private InputMetricsStats inputMetricsStats;
1:bcef656:   // vector reader
1:bcef656:   private boolean isVectorReader;
1:bcef656:   private QueryModel model;
1:bcef656: 
1:bcef656:   @Override
1:bcef656:   public RecordReader<Void, Object> createRecordReader(InputSplit split, TaskAttemptContext context)
1:bcef656:       throws IOException, InterruptedException {
1:bcef656:     try {
1:bcef656:       Constructor cons = CarbonStreamUtils
1:bcef656:           .getConstructorWithReflection(STREAM_RECORD_READER_INSTANCE, boolean.class,
1:bcef656:               InputMetricsStats.class, QueryModel.class, boolean.class);
1:bcef656:       return (RecordReader) CarbonStreamUtils
1:bcef656:           .getInstanceWithReflection(cons, isVectorReader, inputMetricsStats, model, useRawRow);
1:bcef656: 
1:bcef656:     } catch (Exception e) {
1:bcef656:       throw new IOException(e);
1:bcef656:     }
1:d7393da:   }
1:d7393da: 
1:d7393da:   public static GenericQueryType[] getComplexDimensions(CarbonTable carbontable,
1:d7393da:       CarbonColumn[] carbonColumns, Cache<DictionaryColumnUniqueIdentifier, Dictionary> cache)
1:d7393da:       throws IOException {
1:d7393da:     GenericQueryType[] queryTypes = new GenericQueryType[carbonColumns.length];
1:d7393da:     for (int i = 0; i < carbonColumns.length; i++) {
1:d7393da:       if (carbonColumns[i].isComplex()) {
1:933e30c:         if (DataTypes.isArrayType(carbonColumns[i].getDataType())) {
1:d7393da:           queryTypes[i] = new ArrayQueryType(carbonColumns[i].getColName(),
1:d7393da:               carbonColumns[i].getColName(), i);
1:933e30c:         } else if (DataTypes.isStructType(carbonColumns[i].getDataType())) {
1:d7393da:           queryTypes[i] = new StructQueryType(carbonColumns[i].getColName(),
1:d7393da:               carbonColumns[i].getColName(), i);
1:d7393da:         } else {
1:d7393da:           throw new UnsupportedOperationException(
1:d7393da:               carbonColumns[i].getDataType().getName() + " is not supported");
1:d7393da:         }
1:3202cf5: 
1:d7393da:         fillChildren(carbontable, queryTypes[i], (CarbonDimension) carbonColumns[i], i, cache);
1:d7393da:       }
1:d7393da:     }
1:d7393da: 
1:d7393da:     return queryTypes;
1:d7393da:   }
1:d7393da: 
1:d7393da:   private static void fillChildren(CarbonTable carbontable, GenericQueryType parentQueryType,
1:d7393da:       CarbonDimension dimension, int parentBlockIndex,
1:d7393da:       Cache<DictionaryColumnUniqueIdentifier, Dictionary> cache) throws IOException {
1:d7393da:     for (int i = 0; i < dimension.getNumberOfChild(); i++) {
1:d7393da:       CarbonDimension child = dimension.getListOfChildDimensions().get(i);
1:d7393da:       DataType dataType = child.getDataType();
1:d7393da:       GenericQueryType queryType = null;
1:933e30c:       if (DataTypes.isArrayType(dataType)) {
1:d7393da:         queryType =
1:d7393da:             new ArrayQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex);
1:d7393da: 
1:933e30c:       } else if (DataTypes.isStructType(dataType)) {
1:d7393da:         queryType =
1:d7393da:             new StructQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex);
1:d7393da:         parentQueryType.addChildren(queryType);
1:d7393da:       } else {
1:d7393da:         boolean isDirectDictionary =
1:d7393da:             CarbonUtil.hasEncoding(child.getEncoder(), Encoding.DIRECT_DICTIONARY);
1:3202cf5:         boolean isDictionary =
1:3202cf5:             CarbonUtil.hasEncoding(child.getEncoder(), Encoding.DICTIONARY);
1:7292869:         Dictionary dictionary = null;
1:7292869:         if (isDictionary) {
1:7292869:           String dictionaryPath = carbontable.getTableInfo().getFactTable().getTableProperties()
1:7292869:               .get(CarbonCommonConstants.DICTIONARY_PATH);
1:7292869:           DictionaryColumnUniqueIdentifier dictionarIdentifier =
1:7292869:               new DictionaryColumnUniqueIdentifier(carbontable.getAbsoluteTableIdentifier(),
1:7292869:                   child.getColumnIdentifier(), child.getDataType(), dictionaryPath);
1:7292869:           dictionary = cache.get(dictionarIdentifier);
1:7292869:         }
1:d7393da:         queryType =
1:d7393da:             new PrimitiveQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex,
1:7292869:                 child.getDataType(), 4, dictionary,
1:d7393da:                 isDirectDictionary);
1:d7393da:       }
1:d7393da:       parentQueryType.addChildren(queryType);
1:d7393da:       if (child.getNumberOfChild() > 0) {
1:d7393da:         fillChildren(carbontable, queryType, child, parentBlockIndex, cache);
1:d7393da:       }
1:d7393da:     }
1:d7393da:   }
1:d7393da: }
============================================================================
author:sandeep-katta
-------------------------------------------------------------------------------
commit:74c3eb1
/////////////////////////////////////////////////////////////////////////
1:   public void setIsVectorReader(boolean vectorReader) {
author:sujith71955
-------------------------------------------------------------------------------
commit:bcef656
/////////////////////////////////////////////////////////////////////////
1: import java.lang.reflect.Constructor;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.model.QueryModel;
1: import org.apache.carbondata.hadoop.InputMetricsStats;
1: import org.apache.carbondata.streaming.CarbonStreamUtils;
/////////////////////////////////////////////////////////////////////////
1:   public static final String STREAM_RECORD_READER_INSTANCE =
1:       "org.apache.carbondata.stream.CarbonStreamRecordReader";
1:   // return raw row for handoff
1:   private boolean useRawRow = false;
1:   public void setUseRawRow(boolean useRawRow) {
1:     this.useRawRow = useRawRow;
1:   }
1: 
1:   public void setInputMetricsStats(InputMetricsStats inputMetricsStats) {
1:     this.inputMetricsStats = inputMetricsStats;
1:   }
1: 
0:   public void setVectorReader(boolean vectorReader) {
1:     isVectorReader = vectorReader;
1:   }
1: 
1:   public void setModel(QueryModel model) {
1:     this.model = model;
1:   }
1: 
1:   // InputMetricsStats
1:   private InputMetricsStats inputMetricsStats;
1:   // vector reader
1:   private boolean isVectorReader;
1:   private QueryModel model;
1: 
1:   @Override
1:   public RecordReader<Void, Object> createRecordReader(InputSplit split, TaskAttemptContext context)
1:       throws IOException, InterruptedException {
1:     try {
1:       Constructor cons = CarbonStreamUtils
1:           .getConstructorWithReflection(STREAM_RECORD_READER_INSTANCE, boolean.class,
1:               InputMetricsStats.class, QueryModel.class, boolean.class);
1:       return (RecordReader) CarbonStreamUtils
1:           .getInstanceWithReflection(cons, isVectorReader, inputMetricsStats, model, useRawRow);
1: 
1:     } catch (Exception e) {
1:       throw new IOException(e);
1:     }
author:kumarvishal09
-------------------------------------------------------------------------------
commit:7292869
/////////////////////////////////////////////////////////////////////////
1:         Dictionary dictionary = null;
1:         if (isDictionary) {
1:           String dictionaryPath = carbontable.getTableInfo().getFactTable().getTableProperties()
1:               .get(CarbonCommonConstants.DICTIONARY_PATH);
1:           DictionaryColumnUniqueIdentifier dictionarIdentifier =
1:               new DictionaryColumnUniqueIdentifier(carbontable.getAbsoluteTableIdentifier(),
1:                   child.getColumnIdentifier(), child.getDataType(), dictionaryPath);
1:           dictionary = cache.get(dictionarIdentifier);
1:         }
1:                 child.getDataType(), 4, dictionary,
author:sounakr
-------------------------------------------------------------------------------
commit:3202cf5
/////////////////////////////////////////////////////////////////////////
1:         boolean isDictionary =
1:             CarbonUtil.hasEncoding(child.getEncoder(), Encoding.DICTIONARY);
1: 
author:Jacky Li
-------------------------------------------------------------------------------
commit:c723947
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.streaming;
commit:933e30c
/////////////////////////////////////////////////////////////////////////
1:         if (DataTypes.isArrayType(carbonColumns[i].getDataType())) {
1:         } else if (DataTypes.isStructType(carbonColumns[i].getDataType())) {
/////////////////////////////////////////////////////////////////////////
1:       if (DataTypes.isArrayType(dataType)) {
1:       } else if (DataTypes.isStructType(dataType)) {
author:manishgupta88
-------------------------------------------------------------------------------
commit:29dc302
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         String dictionaryPath = carbontable.getTableInfo().getFactTable().getTableProperties()
0:             .get(CarbonCommonConstants.DICTIONARY_PATH);
0:                 child.getColumnIdentifier(), child.getDataType(), dictionaryPath);
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:1155d4d
/////////////////////////////////////////////////////////////////////////
0:             new DictionaryColumnUniqueIdentifier(carbontable.getAbsoluteTableIdentifier(),
author:QiangCai
-------------------------------------------------------------------------------
commit:d7393da
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.carbondata.hadoop.streaming;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.carbondata.core.cache.Cache;
1: import org.apache.carbondata.core.cache.dictionary.Dictionary;
1: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.metadata.encoder.Encoding;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
1: import org.apache.carbondata.core.scan.complextypes.ArrayQueryType;
1: import org.apache.carbondata.core.scan.complextypes.PrimitiveQueryType;
1: import org.apache.carbondata.core.scan.complextypes.StructQueryType;
1: import org.apache.carbondata.core.scan.filter.GenericQueryType;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.core.util.path.CarbonStorePath;
1: 
1: import org.apache.hadoop.mapreduce.InputSplit;
1: import org.apache.hadoop.mapreduce.RecordReader;
1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: 
1: /**
1:  * Stream input format
1:  */
1: public class CarbonStreamInputFormat extends FileInputFormat<Void, Object> {
1: 
1:   public static final String READ_BUFFER_SIZE = "carbon.stream.read.buffer.size";
1:   public static final String READ_BUFFER_SIZE_DEFAULT = "65536";
1: 
0:   @Override public RecordReader<Void, Object> createRecordReader(InputSplit split,
0:       TaskAttemptContext context) throws IOException, InterruptedException {
0:     return new CarbonStreamRecordReader();
1:   }
1: 
1:   public static GenericQueryType[] getComplexDimensions(CarbonTable carbontable,
1:       CarbonColumn[] carbonColumns, Cache<DictionaryColumnUniqueIdentifier, Dictionary> cache)
1:       throws IOException {
1:     GenericQueryType[] queryTypes = new GenericQueryType[carbonColumns.length];
1:     for (int i = 0; i < carbonColumns.length; i++) {
1:       if (carbonColumns[i].isComplex()) {
0:         if (carbonColumns[i].getDataType() == DataTypes.ARRAY) {
1:           queryTypes[i] = new ArrayQueryType(carbonColumns[i].getColName(),
1:               carbonColumns[i].getColName(), i);
0:         } else if (carbonColumns[i].getDataType() == DataTypes.STRUCT) {
1:           queryTypes[i] = new StructQueryType(carbonColumns[i].getColName(),
1:               carbonColumns[i].getColName(), i);
1:         } else {
1:           throw new UnsupportedOperationException(
1:               carbonColumns[i].getDataType().getName() + " is not supported");
1:         }
1: 
1:         fillChildren(carbontable, queryTypes[i], (CarbonDimension) carbonColumns[i], i, cache);
1:       }
1:     }
1: 
1:     return queryTypes;
1:   }
1: 
1:   private static void fillChildren(CarbonTable carbontable, GenericQueryType parentQueryType,
1:       CarbonDimension dimension, int parentBlockIndex,
1:       Cache<DictionaryColumnUniqueIdentifier, Dictionary> cache) throws IOException {
1:     for (int i = 0; i < dimension.getNumberOfChild(); i++) {
1:       CarbonDimension child = dimension.getListOfChildDimensions().get(i);
1:       DataType dataType = child.getDataType();
1:       GenericQueryType queryType = null;
0:       if (dataType == DataTypes.ARRAY) {
1:         queryType =
1:             new ArrayQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex);
1: 
0:       } else if (dataType == DataTypes.STRUCT) {
1:         queryType =
1:             new StructQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex);
1:         parentQueryType.addChildren(queryType);
1:       } else {
1:         boolean isDirectDictionary =
1:             CarbonUtil.hasEncoding(child.getEncoder(), Encoding.DIRECT_DICTIONARY);
0:         DictionaryColumnUniqueIdentifier dictionarIdentifier =
0:             new DictionaryColumnUniqueIdentifier(carbontable.getCarbonTableIdentifier(),
0:                 child.getColumnIdentifier(), child.getDataType(),
0:                 CarbonStorePath.getCarbonTablePath(carbontable.getAbsoluteTableIdentifier()));
1: 
1:         queryType =
1:             new PrimitiveQueryType(child.getColName(), dimension.getColName(), ++parentBlockIndex,
0:                 child.getDataType(), 4, cache.get(dictionarIdentifier),
1:                 isDirectDictionary);
1:       }
1:       parentQueryType.addChildren(queryType);
1:       if (child.getNumberOfChild() > 0) {
1:         fillChildren(carbontable, queryType, child, parentBlockIndex, cache);
1:       }
1:     }
1:   }
1: }
============================================================================
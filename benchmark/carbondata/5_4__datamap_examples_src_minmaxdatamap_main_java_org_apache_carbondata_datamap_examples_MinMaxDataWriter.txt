1:ca7e2e3: /*
1:ca7e2e3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:ca7e2e3:  * contributor license agreements.  See the NOTICE file distributed with
1:ca7e2e3:  * this work for additional information regarding copyright ownership.
1:ca7e2e3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:ca7e2e3:  * (the "License"); you may not use this file except in compliance with
1:ca7e2e3:  * the License.  You may obtain a copy of the License at
1:ca7e2e3:  *
1:ca7e2e3:  *    http://www.apache.org/licenses/LICENSE-2.0
1:ca7e2e3:  *
1:ca7e2e3:  * Unless required by applicable law or agreed to in writing, software
1:ca7e2e3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:ca7e2e3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:ca7e2e3:  * See the License for the specific language governing permissions and
1:ca7e2e3:  * limitations under the License.
1:ca7e2e3:  */
11:ca7e2e3: 
1:ca7e2e3: package org.apache.carbondata.datamap.examples;
1:ca7e2e3: 
1:ca7e2e3: import java.io.BufferedWriter;
1:ca7e2e3: import java.io.DataOutputStream;
1:ecd6c0c: import java.io.File;
1:ca7e2e3: import java.io.IOException;
1:ca7e2e3: import java.io.OutputStreamWriter;
1:ca7e2e3: import java.util.ArrayList;
1:ca7e2e3: import java.util.HashMap;
1:ca7e2e3: import java.util.List;
1:ca7e2e3: import java.util.Map;
1:ca7e2e3: 
1:ca7e2e3: import org.apache.carbondata.common.logging.LogService;
1:ca7e2e3: import org.apache.carbondata.common.logging.LogServiceFactory;
1:8d8b589: import org.apache.carbondata.core.datamap.Segment;
1:fc2a7eb: import org.apache.carbondata.core.datamap.dev.DataMapWriter;
1:ca7e2e3: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:ca7e2e3: import org.apache.carbondata.core.datastore.page.ColumnPage;
1:ecd6c0c: import org.apache.carbondata.core.metadata.datatype.DataType;
1:ecd6c0c: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:ecd6c0c: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:9db662a: import org.apache.carbondata.core.metadata.schema.table.DataMapSchema;
1:ca7e2e3: import org.apache.carbondata.core.metadata.schema.table.TableInfo;
1:ecd6c0c: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:ca7e2e3: import org.apache.carbondata.core.util.ByteUtil;
1:ca7e2e3: import org.apache.carbondata.core.util.CarbonUtil;
1:ca7e2e3: 
1:ca7e2e3: import com.google.gson.Gson;
1:ecd6c0c: import org.apache.hadoop.fs.FileSystem;
1:ecd6c0c: import org.apache.hadoop.fs.Path;
1:ca7e2e3: 
1:fc2a7eb: public class MinMaxDataWriter extends DataMapWriter {
1:ca7e2e3: 
1:ca7e2e3:   private static final LogService LOGGER =
1:ca7e2e3:       LogServiceFactory.getLogService(TableInfo.class.getName());
1:ca7e2e3: 
1:ecd6c0c:   private Object[] pageLevelMin, pageLevelMax;
1:ca7e2e3: 
1:ca7e2e3:   private Map<Integer, BlockletMinMax> blockMinMaxMap;
1:ca7e2e3: 
1:ecd6c0c:   private int columnCnt;
1:ecd6c0c:   private DataType[] dataTypeArray;
1:8b33ab2:   private String indexShardName;
1:ca7e2e3: 
1:ecd6c0c:   /**
1:ecd6c0c:    * Since the sequence of indexed columns is defined the same as order in user-created, so
1:ecd6c0c:    * map colIdx in user-created to colIdx in MinMaxIndex.
1:ecd6c0c:    * Please note that the sequence of min-max values for each column in blocklet-min-max is not
1:ecd6c0c:    * the same as indexed columns, so we need to reorder the origin while writing the min-max values
1:ecd6c0c:    */
1:ecd6c0c:   private Map<Integer, Integer> origin2MinMaxOrdinal = new HashMap<>();
1:ecd6c0c: 
1:9db662a:   public MinMaxDataWriter(CarbonTable carbonTable, DataMapSchema dataMapSchema, Segment segment,
1:9db662a:       String shardName, List<CarbonColumn> indexColumns) {
1:9db662a:     super(carbonTable.getTablePath(), dataMapSchema.getDataMapName(), indexColumns, segment,
1:9db662a:         shardName);
1:9db662a:     this.columnCnt = indexColumns.size();
1:9db662a:     for (CarbonColumn col : indexColumns) {
1:9db662a:       this.origin2MinMaxOrdinal.put(col.getSchemaOrdinal(), col.getOrdinal());
1:d35fbaf:     }
1:9db662a:     if (this.dataTypeArray == null) {
1:9db662a:       this.dataTypeArray = new DataType[this.columnCnt];
1:9db662a:       for (int i = 0; i < this.columnCnt; i++) {
1:9db662a:         this.dataTypeArray[i] = indexColumns.get(i).getDataType();
1:9db662a:       }
1:ecd6c0c:     }
1:ecd6c0c:   }
1:ecd6c0c: 
1:9db662a:   @Override public void onBlockStart(String blockId) {
1:8b33ab2:     if (blockMinMaxMap == null) {
1:8b33ab2:       blockMinMaxMap = new HashMap<>();
1:8b33ab2:     }
1:ecd6c0c:   }
1:ca7e2e3: 
1:ca7e2e3:   @Override public void onBlockEnd(String blockId) {
1:ecd6c0c:   }
1:ca7e2e3: 
1:ca7e2e3:   @Override public void onBlockletStart(int blockletId) {
1:ecd6c0c:     pageLevelMin = new Object[columnCnt];
1:ecd6c0c:     pageLevelMax = new Object[columnCnt];
6:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3:   @Override public void onBlockletEnd(int blockletId) {
1:ecd6c0c:     updateCurrentBlockletMinMax(blockletId);
1:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3:   @Override
1:9db662a:   public void onPageAdded(int blockletId, int pageId, int pageSize, ColumnPage[] pages) {
1:ecd6c0c:     // as an example, we don't use page-level min-max generated by native carbondata here, we get
1:ecd6c0c:     // the min-max by comparing each row
1:9db662a:     for (int rowId = 0; rowId < pageSize; rowId++) {
1:ecd6c0c:       for (int colIdx = 0; colIdx < columnCnt; colIdx++) {
1:ecd6c0c:         Object originValue = pages[colIdx].getData(rowId);
1:9db662a:         DataType dataType = dataTypeArray[colIdx];
1:ecd6c0c:         // for string & bytes_array, data is prefixed with length, need to remove it
1:9db662a:         if (DataTypes.STRING == dataType || DataTypes.BYTE_ARRAY == dataType) {
1:ecd6c0c:           byte[] valueMin0 = (byte[]) pageLevelMin[colIdx];
1:ecd6c0c:           byte[] valueMax0 = (byte[]) pageLevelMax[colIdx];
1:ecd6c0c:           byte[] value1 = (byte[]) originValue;
1:ecd6c0c:           if (pageLevelMin[colIdx] == null || ByteUtil.UnsafeComparer.INSTANCE
1:ecd6c0c:               .compareTo(valueMin0, 0, valueMin0.length, value1, 2, value1.length - 2) > 0) {
1:ecd6c0c:             pageLevelMin[colIdx] = new byte[value1.length - 2];
1:ecd6c0c:             System.arraycopy(value1, 2, (byte[]) pageLevelMin[colIdx], 0, value1.length - 2);
1:ecd6c0c:           }
1:ecd6c0c:           if (pageLevelMax[colIdx] == null || ByteUtil.UnsafeComparer.INSTANCE
1:ecd6c0c:               .compareTo(valueMax0, 0, valueMax0.length, value1, 2, value1.length - 2) < 0) {
1:ecd6c0c:             pageLevelMax[colIdx] = new byte[value1.length - 2];
1:ecd6c0c:             System.arraycopy(value1, 2, (byte[]) pageLevelMax[colIdx], 0, value1.length - 2);
1:ecd6c0c:           }
1:9db662a:         } else if (DataTypes.INT == dataType) {
1:9db662a:           updateMinMax(colIdx, originValue, dataType);
1:ecd6c0c:         } else {
1:9db662a:           throw new UnsupportedOperationException("Not implement yet");
1:ca7e2e3:         }
1:ca7e2e3:       }
1:ca7e2e3:     }
1:ca7e2e3:   }
1:ca7e2e3: 
1:ecd6c0c:   private void updateMinMax(int colIdx, Object originValue, DataType dataType) {
1:ecd6c0c:     if (pageLevelMin[colIdx] == null) {
1:ecd6c0c:       pageLevelMin[colIdx] = originValue;
1:ecd6c0c:     }
1:ecd6c0c:     if (pageLevelMax[colIdx] == null) {
1:ecd6c0c:       pageLevelMax[colIdx] = originValue;
1:ecd6c0c:     }
1:ecd6c0c: 
1:ecd6c0c:     if (DataTypes.SHORT == dataType) {
1:ecd6c0c:       if (pageLevelMin[colIdx] == null || (short) pageLevelMin[colIdx] - (short) originValue > 0) {
1:ecd6c0c:         pageLevelMin[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:       if (pageLevelMax[colIdx] == null || (short) pageLevelMax[colIdx] - (short) originValue < 0) {
1:ecd6c0c:         pageLevelMax[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:     } else if (DataTypes.INT == dataType) {
1:ecd6c0c:       if (pageLevelMin[colIdx] == null || (int) pageLevelMin[colIdx] - (int) originValue > 0) {
1:ecd6c0c:         pageLevelMin[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:       if (pageLevelMax[colIdx] == null || (int) pageLevelMax[colIdx] - (int) originValue < 0) {
1:ecd6c0c:         pageLevelMax[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:     } else if (DataTypes.LONG == dataType) {
1:ecd6c0c:       if (pageLevelMin[colIdx] == null || (long) pageLevelMin[colIdx] - (long) originValue > 0) {
1:ecd6c0c:         pageLevelMin[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:       if (pageLevelMax[colIdx] == null || (long) pageLevelMax[colIdx] - (long) originValue < 0) {
1:ecd6c0c:         pageLevelMax[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:     } else if (DataTypes.DOUBLE == dataType) {
1:ecd6c0c:       if (pageLevelMin[colIdx] == null
1:ecd6c0c:           || (double) pageLevelMin[colIdx] - (double) originValue > 0) {
1:ecd6c0c:         pageLevelMin[colIdx] = originValue;
1:ecd6c0c:       }
1:ecd6c0c:       if (pageLevelMax[colIdx] == null
1:ecd6c0c:           || (double) pageLevelMax[colIdx] - (double) originValue < 0) {
1:ecd6c0c:         pageLevelMax[colIdx] = originValue;
1:ca7e2e3:       }
2:ca7e2e3:     } else {
1:ecd6c0c:       // todo:
1:ecd6c0c:       throw new RuntimeException("Not implemented yet");
1:ecd6c0c:     }
1:ca7e2e3:   }
1:ecd6c0c: 
1:ecd6c0c:   private void updateCurrentBlockletMinMax(int blockletId) {
1:ecd6c0c:     byte[][] max = new byte[this.columnCnt][];
1:ecd6c0c:     byte[][] min = new byte[this.columnCnt][];
2:ecd6c0c:     for (int i = 0; i < this.columnCnt; i++) {
1:ecd6c0c:       int targetColIdx = origin2MinMaxOrdinal.get(i);
1:ecd6c0c:       max[targetColIdx] = CarbonUtil.getValueAsBytes(this.dataTypeArray[i], pageLevelMax[i]);
1:ecd6c0c:       min[targetColIdx] = CarbonUtil.getValueAsBytes(this.dataTypeArray[i], pageLevelMin[i]);
1:ecd6c0c:     }
1:ecd6c0c: 
1:ca7e2e3:     BlockletMinMax blockletMinMax = new BlockletMinMax();
1:ecd6c0c:     blockletMinMax.setMax(max);
1:ecd6c0c:     blockletMinMax.setMin(min);
1:ca7e2e3:     blockMinMaxMap.put(blockletId, blockletMinMax);
1:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3: 
1:ca7e2e3:   public void updateMinMaxIndex(String blockId) {
1:ca7e2e3:     constructMinMaxIndex(blockId);
1:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3:   /**
1:ca7e2e3:    * Construct the Min Max Index.
1:ca7e2e3:    * @param blockId
1:ca7e2e3:    */
1:ca7e2e3:   public void constructMinMaxIndex(String blockId) {
1:ca7e2e3:     // construct Min and Max values of each Blocklets present inside a block.
1:ca7e2e3:     List<MinMaxIndexBlockDetails> tempMinMaxIndexBlockDetails = null;
1:ca7e2e3:     tempMinMaxIndexBlockDetails = loadBlockDetails();
1:ca7e2e3:     try {
1:d35fbaf:       writeMinMaxIndexFile(tempMinMaxIndexBlockDetails, blockId);
1:ca7e2e3:     } catch (IOException ex) {
1:ca7e2e3:       LOGGER.info(" Unable to write the file");
1:ca7e2e3:     }
1:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3:   /**
1:ca7e2e3:    * loadBlockDetails into the MinMaxIndexBlockDetails class.
1:ca7e2e3:    */
1:ca7e2e3:   private List<MinMaxIndexBlockDetails> loadBlockDetails() {
1:ca7e2e3:     List<MinMaxIndexBlockDetails> minMaxIndexBlockDetails = new ArrayList<MinMaxIndexBlockDetails>();
1:ca7e2e3: 
1:ca7e2e3:     for (int index = 0; index < blockMinMaxMap.size(); index++) {
1:ecd6c0c:       MinMaxIndexBlockDetails tmpminMaxIndexBlockDetails = new MinMaxIndexBlockDetails();
1:ca7e2e3:       tmpminMaxIndexBlockDetails.setMinValues(blockMinMaxMap.get(index).getMin());
1:ca7e2e3:       tmpminMaxIndexBlockDetails.setMaxValues(blockMinMaxMap.get(index).getMax());
1:ca7e2e3:       tmpminMaxIndexBlockDetails.setBlockletId(index);
1:ca7e2e3:       minMaxIndexBlockDetails.add(tmpminMaxIndexBlockDetails);
1:ca7e2e3:     }
1:ca7e2e3:     return minMaxIndexBlockDetails;
1:ca7e2e3:   }
1:ca7e2e3: 
1:ca7e2e3:   /**
1:ca7e2e3:    * Write the data to a file. This is JSON format file.
1:ca7e2e3:    * @param minMaxIndexBlockDetails
1:ca7e2e3:    * @param blockId
1:ca7e2e3:    * @throws IOException
1:ca7e2e3:    */
1:ca7e2e3:   public void writeMinMaxIndexFile(List<MinMaxIndexBlockDetails> minMaxIndexBlockDetails,
1:d35fbaf:       String blockId) throws IOException {
1:9db662a:     String filePath = dataMapPath + File.separator + blockId + ".minmaxindex";
1:ca7e2e3:     BufferedWriter brWriter = null;
1:ca7e2e3:     DataOutputStream dataOutStream = null;
1:ca7e2e3:     try {
1:ca7e2e3:       FileFactory.createNewFile(filePath, FileFactory.getFileType(filePath));
1:ca7e2e3:       dataOutStream = FileFactory.getDataOutputStream(filePath, FileFactory.getFileType(filePath));
1:ca7e2e3:       Gson gsonObjectToWrite = new Gson();
1:d35fbaf:       brWriter = new BufferedWriter(new OutputStreamWriter(dataOutStream, "UTF-8"));
1:ca7e2e3:       String minmaxIndexData = gsonObjectToWrite.toJson(minMaxIndexBlockDetails);
1:ca7e2e3:       brWriter.write(minmaxIndexData);
1:ca7e2e3:     } catch (IOException ioe) {
1:ca7e2e3:       LOGGER.info("Error in writing minMaxindex file");
1:ecd6c0c:       throw ioe;
1:ca7e2e3:     } finally {
1:ca7e2e3:       if (null != brWriter) {
1:ca7e2e3:         brWriter.flush();
1:ca7e2e3:       }
1:ca7e2e3:       if (null != dataOutStream) {
1:ca7e2e3:         dataOutStream.flush();
1:ca7e2e3:       }
1:ca7e2e3:       CarbonUtil.closeStreams(brWriter, dataOutStream);
1:d35fbaf:       commitFile(filePath);
1:ca7e2e3:     }
1:ca7e2e3:   }
1:ca7e2e3: 
1:d35fbaf:   @Override public void finish() throws IOException {
1:8b33ab2:     updateMinMaxIndex(indexShardName);
1:d35fbaf:   }
1:d35fbaf: 
1:ecd6c0c:   /**
1:ecd6c0c:    * create and return path that will store the datamap
1:ecd6c0c:    *
1:ecd6c0c:    * @param dataPath patch to store the carbondata factdata
1:ecd6c0c:    * @param dataMapName datamap name
1:ecd6c0c:    * @return path to store the datamap
1:ecd6c0c:    * @throws IOException
1:ecd6c0c:    */
1:ecd6c0c:   public static String genDataMapStorePath(String dataPath, String dataMapName)
1:ecd6c0c:       throws IOException {
1:ecd6c0c:     String dmDir = dataPath + File.separator + dataMapName;
1:ecd6c0c:     Path dmPath = FileFactory.getPath(dmDir);
1:ecd6c0c:     FileSystem fs = FileFactory.getFileSystem(dmPath);
1:ecd6c0c:     if (!fs.exists(dmPath)) {
1:ecd6c0c:       fs.mkdirs(dmPath);
1:ecd6c0c:     }
1:ecd6c0c:     return dmDir;
1:ecd6c0c:   }
1:ca7e2e3: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:9db662a
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.schema.table.DataMapSchema;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   public MinMaxDataWriter(CarbonTable carbonTable, DataMapSchema dataMapSchema, Segment segment,
1:       String shardName, List<CarbonColumn> indexColumns) {
1:     super(carbonTable.getTablePath(), dataMapSchema.getDataMapName(), indexColumns, segment,
1:         shardName);
1:     this.columnCnt = indexColumns.size();
1:     for (CarbonColumn col : indexColumns) {
1:       this.origin2MinMaxOrdinal.put(col.getSchemaOrdinal(), col.getOrdinal());
1:     if (this.dataTypeArray == null) {
1:       this.dataTypeArray = new DataType[this.columnCnt];
1:       for (int i = 0; i < this.columnCnt; i++) {
1:         this.dataTypeArray[i] = indexColumns.get(i).getDataType();
1:       }
1:   @Override public void onBlockStart(String blockId) {
/////////////////////////////////////////////////////////////////////////
1:   public void onPageAdded(int blockletId, int pageId, int pageSize, ColumnPage[] pages) {
1:     for (int rowId = 0; rowId < pageSize; rowId++) {
1:         DataType dataType = dataTypeArray[colIdx];
1:         if (DataTypes.STRING == dataType || DataTypes.BYTE_ARRAY == dataType) {
/////////////////////////////////////////////////////////////////////////
1:         } else if (DataTypes.INT == dataType) {
1:           updateMinMax(colIdx, originValue, dataType);
1:           throw new UnsupportedOperationException("Not implement yet");
/////////////////////////////////////////////////////////////////////////
1:     String filePath = dataMapPath + File.separator + blockId + ".minmaxindex";
commit:fc2a7eb
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.dev.DataMapWriter;
/////////////////////////////////////////////////////////////////////////
1: public class MinMaxDataWriter extends DataMapWriter {
author:ravipesala
-------------------------------------------------------------------------------
commit:8b33ab2
/////////////////////////////////////////////////////////////////////////
1:   private String indexShardName;
/////////////////////////////////////////////////////////////////////////
0:   @Override public void onBlockStart(String blockId, String indexShardName) {
1:     if (blockMinMaxMap == null) {
1:       blockMinMaxMap = new HashMap<>();
0:       this.indexShardName = indexShardName;
1:     }
/////////////////////////////////////////////////////////////////////////
1:     updateMinMaxIndex(indexShardName);
commit:d35fbaf
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.datamap.dev.AbstractDataMapWriter;
0: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
0: import org.apache.carbondata.core.util.path.CarbonTablePath;
0: public class MinMaxDataWriter extends AbstractDataMapWriter {
/////////////////////////////////////////////////////////////////////////
0:   private String dataWritePath;
0:   public MinMaxDataWriter(AbsoluteTableIdentifier identifier, String segmentId,
0:       String dataWritePath) {
0:     super(identifier, segmentId, dataWritePath);
0:     this.identifier = identifier;
0:     this.segmentId = segmentId;
0:     this.dataWritePath = dataWritePath;
1:   }
0:   @Override public void onBlockStart(String blockId) {
/////////////////////////////////////////////////////////////////////////
1:       writeMinMaxIndexFile(tempMinMaxIndexBlockDetails, blockId);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       String blockId) throws IOException {
0:     String filePath = dataWritePath +"/" + blockId + ".minmaxindex";
1:       brWriter = new BufferedWriter(new OutputStreamWriter(dataOutStream, "UTF-8"));
/////////////////////////////////////////////////////////////////////////
1:       commitFile(filePath);
1:   @Override public void finish() throws IOException {
1: 
1:   }
author:akashrn5
-------------------------------------------------------------------------------
commit:860e144
/////////////////////////////////////////////////////////////////////////
0:   @Override public void onBlockStart(String blockId, long taskId) {
author:xuchuanyin
-------------------------------------------------------------------------------
commit:ecd6c0c
/////////////////////////////////////////////////////////////////////////
1: import java.io.File;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.CarbonMetadata;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
0: import org.apache.carbondata.core.metadata.schema.table.column.CarbonDimension;
0: import org.apache.carbondata.core.metadata.schema.table.column.CarbonMeasure;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1:   private Object[] pageLevelMin, pageLevelMax;
0:   private String dataMapName;
1:   private int columnCnt;
1:   private DataType[] dataTypeArray;
1:   /**
1:    * Since the sequence of indexed columns is defined the same as order in user-created, so
1:    * map colIdx in user-created to colIdx in MinMaxIndex.
1:    * Please note that the sequence of min-max values for each column in blocklet-min-max is not
1:    * the same as indexed columns, so we need to reorder the origin while writing the min-max values
1:    */
1:   private Map<Integer, Integer> origin2MinMaxOrdinal = new HashMap<>();
1: 
0:   public MinMaxDataWriter(AbsoluteTableIdentifier identifier, String dataMapName, Segment segment,
0:     this.dataMapName = dataMapName;
0:     CarbonTable carbonTable = CarbonMetadata.getInstance().getCarbonTable(
0:         identifier.getDatabaseName(), identifier.getTableName());
0:     List<CarbonColumn> cols = carbonTable.getCreateOrderColumn(identifier.getTableName());
0:     this.columnCnt = cols.size();
0:     List<CarbonDimension> dimensions = carbonTable.getDimensionByTableName(identifier.getTableName());
0:     for (int i = 0; i < dimensions.size(); i++) {
0:       this.origin2MinMaxOrdinal.put(dimensions.get(i).getSchemaOrdinal(),
0:           dimensions.get(i).getOrdinal());
1:     }
0:     List<CarbonMeasure> measures = carbonTable.getMeasureByTableName(identifier.getTableName());
0:     for (int i = 0; i < measures.size(); i++) {
0:       this.origin2MinMaxOrdinal.put(measures.get(i).getSchemaOrdinal(),
0:           dimensions.size() + measures.get(i).getOrdinal());
1:     }
/////////////////////////////////////////////////////////////////////////
1:     pageLevelMin = new Object[columnCnt];
1:     pageLevelMax = new Object[columnCnt];
1:     updateCurrentBlockletMinMax(blockletId);
/////////////////////////////////////////////////////////////////////////
0:     if (this.dataTypeArray == null) {
0:       this.dataTypeArray = new DataType[this.columnCnt];
1:       for (int i = 0; i < this.columnCnt; i++) {
0:         this.dataTypeArray[i] = pages[i].getDataType();
1:       }
1:     }
1:     // as an example, we don't use page-level min-max generated by native carbondata here, we get
1:     // the min-max by comparing each row
0:     for (int rowId = 0; rowId < pages[0].getPageSize(); rowId++) {
1:       for (int colIdx = 0; colIdx < columnCnt; colIdx++) {
1:         Object originValue = pages[colIdx].getData(rowId);
1:         // for string & bytes_array, data is prefixed with length, need to remove it
0:         if (DataTypes.STRING == pages[colIdx].getDataType()
0:             || DataTypes.BYTE_ARRAY == pages[colIdx].getDataType()) {
1:           byte[] valueMin0 = (byte[]) pageLevelMin[colIdx];
1:           byte[] valueMax0 = (byte[]) pageLevelMax[colIdx];
1:           byte[] value1 = (byte[]) originValue;
1:           if (pageLevelMin[colIdx] == null || ByteUtil.UnsafeComparer.INSTANCE
1:               .compareTo(valueMin0, 0, valueMin0.length, value1, 2, value1.length - 2) > 0) {
1:             pageLevelMin[colIdx] = new byte[value1.length - 2];
1:             System.arraycopy(value1, 2, (byte[]) pageLevelMin[colIdx], 0, value1.length - 2);
1:           }
1:           if (pageLevelMax[colIdx] == null || ByteUtil.UnsafeComparer.INSTANCE
1:               .compareTo(valueMax0, 0, valueMax0.length, value1, 2, value1.length - 2) < 0) {
1:             pageLevelMax[colIdx] = new byte[value1.length - 2];
1:             System.arraycopy(value1, 2, (byte[]) pageLevelMax[colIdx], 0, value1.length - 2);
1:           }
0:         } else if (DataTypes.INT == pages[colIdx].getDataType()) {
0:           updateMinMax(colIdx, originValue, pages[colIdx].getDataType());
1:         } else {
0:           throw new RuntimeException("Not implement yet");
1:   private void updateMinMax(int colIdx, Object originValue, DataType dataType) {
1:     if (pageLevelMin[colIdx] == null) {
1:       pageLevelMin[colIdx] = originValue;
1:     }
1:     if (pageLevelMax[colIdx] == null) {
1:       pageLevelMax[colIdx] = originValue;
1:     }
1: 
1:     if (DataTypes.SHORT == dataType) {
1:       if (pageLevelMin[colIdx] == null || (short) pageLevelMin[colIdx] - (short) originValue > 0) {
1:         pageLevelMin[colIdx] = originValue;
1:       }
1:       if (pageLevelMax[colIdx] == null || (short) pageLevelMax[colIdx] - (short) originValue < 0) {
1:         pageLevelMax[colIdx] = originValue;
1:       }
1:     } else if (DataTypes.INT == dataType) {
1:       if (pageLevelMin[colIdx] == null || (int) pageLevelMin[colIdx] - (int) originValue > 0) {
1:         pageLevelMin[colIdx] = originValue;
1:       }
1:       if (pageLevelMax[colIdx] == null || (int) pageLevelMax[colIdx] - (int) originValue < 0) {
1:         pageLevelMax[colIdx] = originValue;
1:       }
1:     } else if (DataTypes.LONG == dataType) {
1:       if (pageLevelMin[colIdx] == null || (long) pageLevelMin[colIdx] - (long) originValue > 0) {
1:         pageLevelMin[colIdx] = originValue;
1:       }
1:       if (pageLevelMax[colIdx] == null || (long) pageLevelMax[colIdx] - (long) originValue < 0) {
1:         pageLevelMax[colIdx] = originValue;
1:       }
1:     } else if (DataTypes.DOUBLE == dataType) {
1:       if (pageLevelMin[colIdx] == null
1:           || (double) pageLevelMin[colIdx] - (double) originValue > 0) {
1:         pageLevelMin[colIdx] = originValue;
1:       }
1:       if (pageLevelMax[colIdx] == null
1:           || (double) pageLevelMax[colIdx] - (double) originValue < 0) {
1:         pageLevelMax[colIdx] = originValue;
1:       // todo:
1:       throw new RuntimeException("Not implemented yet");
1:   }
1: 
1:   private void updateCurrentBlockletMinMax(int blockletId) {
1:     byte[][] max = new byte[this.columnCnt][];
1:     byte[][] min = new byte[this.columnCnt][];
1:     for (int i = 0; i < this.columnCnt; i++) {
1:       int targetColIdx = origin2MinMaxOrdinal.get(i);
1:       max[targetColIdx] = CarbonUtil.getValueAsBytes(this.dataTypeArray[i], pageLevelMax[i]);
1:       min[targetColIdx] = CarbonUtil.getValueAsBytes(this.dataTypeArray[i], pageLevelMin[i]);
1:     }
1: 
1:     blockletMinMax.setMax(max);
1:     blockletMinMax.setMin(min);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       MinMaxIndexBlockDetails tmpminMaxIndexBlockDetails = new MinMaxIndexBlockDetails();
/////////////////////////////////////////////////////////////////////////
0:     String dataMapDir = genDataMapStorePath(this.writeDirectoryPath, this.dataMapName);
0:     String filePath = dataMapDir + File.separator + blockId + ".minmaxindex";
/////////////////////////////////////////////////////////////////////////
1:       throw ioe;
/////////////////////////////////////////////////////////////////////////
1: 
1:   /**
1:    * create and return path that will store the datamap
1:    *
1:    * @param dataPath patch to store the carbondata factdata
1:    * @param dataMapName datamap name
1:    * @return path to store the datamap
1:    * @throws IOException
1:    */
1:   public static String genDataMapStorePath(String dataPath, String dataMapName)
1:       throws IOException {
1:     String dmDir = dataPath + File.separator + dataMapName;
1:     Path dmPath = FileFactory.getPath(dmDir);
1:     FileSystem fs = FileFactory.getFileSystem(dmPath);
1:     if (!fs.exists(dmPath)) {
1:       fs.mkdirs(dmPath);
1:     }
1:     return dmDir;
1:   }
commit:859d71c
/////////////////////////////////////////////////////////////////////////
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.Segment;
/////////////////////////////////////////////////////////////////////////
0:   public MinMaxDataWriter(AbsoluteTableIdentifier identifier, Segment segment,
0:     super(identifier, segment, dataWritePath);
0:     this.segmentId = segment.getSegmentNo();
author:sounakr
-------------------------------------------------------------------------------
commit:ca7e2e3
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.datamap.examples;
1: 
1: import java.io.BufferedWriter;
1: import java.io.DataOutputStream;
0: import java.io.File;
1: import java.io.IOException;
1: import java.io.OutputStreamWriter;
1: import java.util.ArrayList;
1: import java.util.HashMap;
1: import java.util.List;
1: import java.util.Map;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.datamap.dev.DataMapWriter;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
1: import org.apache.carbondata.core.datastore.page.ColumnPage;
1: import org.apache.carbondata.core.metadata.schema.table.TableInfo;
1: import org.apache.carbondata.core.util.ByteUtil;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: 
1: import com.google.gson.Gson;
1: 
0: public class MinMaxDataWriter implements DataMapWriter {
1: 
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(TableInfo.class.getName());
1: 
0:   private byte[][] pageLevelMin, pageLevelMax;
1: 
0:   private byte[][] blockletLevelMin, blockletLevelMax;
1: 
1:   private Map<Integer, BlockletMinMax> blockMinMaxMap;
1: 
0:   private String blockPath;
1: 
1: 
0:   @Override public void onBlockStart(String blockId, String blockPath) {
0:     pageLevelMax = null;
0:     pageLevelMin = null;
0:     blockletLevelMax = null;
0:     blockletLevelMin = null;
0:     blockMinMaxMap = null;
0:     blockMinMaxMap = new HashMap<Integer, BlockletMinMax>();
0:     this.blockPath = blockPath;
1:   }
1: 
1:   @Override public void onBlockEnd(String blockId) {
0:     updateMinMaxIndex(blockId);
1:   }
1: 
1:   @Override public void onBlockletStart(int blockletId) {
1:   }
1: 
1:   @Override public void onBlockletEnd(int blockletId) {
0:     updateBlockletMinMax(blockletId);
1:   }
1: 
1:   @Override
0:   public void onPageAdded(int blockletId, int pageId, ColumnPage[] pages) {
0:     // Calculate Min and Max value within this page.
1: 
0:     // As part of example we are extracting Min Max values Manually. The same can be done from
0:     // retrieving the page statistics. For e.g.
1: 
0:     // if (pageLevelMin == null && pageLevelMax == null) {
0:     //    pageLevelMin[1] = CarbonUtil.getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //        pages[0].getStatistics().getMin());
0:     //    pageLevelMax[1] = CarbonUtil.getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //        pages[0].getStatistics().getMax());
0:     //  } else {
0:     //    if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(pageLevelMin[1], CarbonUtil
0:     //        .getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //            pages[0].getStatistics().getMin())) > 0) {
0:     //      pageLevelMin[1] = CarbonUtil.getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //          pages[0].getStatistics().getMin());
0:     //    }
0:     //    if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(pageLevelMax[1], CarbonUtil
0:     //        .getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //            pages[0].getStatistics().getMax())) < 0) {
0:     //      pageLevelMax[1] = CarbonUtil.getValueAsBytes(pages[0].getStatistics().getDataType(),
0:     //          pages[0].getStatistics().getMax());
0:     //    }
1: 
0:     byte[] value = new byte[pages[0].getBytes(0).length - 2];
0:     if (pageLevelMin == null && pageLevelMax == null) {
0:       pageLevelMin = new byte[2][];
0:       pageLevelMax = new byte[2][];
1: 
0:       System.arraycopy(pages[0].getBytes(0), 2, value, 0, value.length);
0:       pageLevelMin[1] = value;
0:       pageLevelMax[1] = value;
1: 
1:     } else {
0:       for (int rowIndex = 0; rowIndex < pages[0].getPageSize(); rowIndex++) {
0:         System.arraycopy(pages[0].getBytes(rowIndex), 2, value, 0, value.length);
0:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(pageLevelMin[1], value) > 0) {
0:           pageLevelMin[1] = value;
1:         }
0:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(pageLevelMax[1], value) < 0) {
0:           pageLevelMax[1] = value;
1:         }
1:       }
1:     }
1:   }
1: 
0:   private void updateBlockletMinMax(int blockletId) {
0:     if (blockletLevelMax == null || blockletLevelMin == null) {
0:       blockletLevelMax = new byte[2][];
0:       blockletLevelMin = new byte[2][];
0:       if (pageLevelMax != null || pageLevelMin != null) {
0:         blockletLevelMin = pageLevelMin;
0:         blockletLevelMax = pageLevelMax;
1:       }
1:     } else {
0:       if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(blockletLevelMin[1], pageLevelMin[1]) > 0) {
0:         blockletLevelMin = pageLevelMin;
1:       }
1: 
0:       if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(blockletLevelMax[1], pageLevelMax[1]) > 0) {
0:         blockletLevelMax = pageLevelMax;
1:       }
1:     }
1:     BlockletMinMax blockletMinMax = new BlockletMinMax();
0:     blockletMinMax.setMax(blockletLevelMax);
0:     blockletMinMax.setMin(blockletLevelMin);
1:     blockMinMaxMap.put(blockletId, blockletMinMax);
1:   }
1: 
1: 
1:   public void updateMinMaxIndex(String blockId) {
1:     constructMinMaxIndex(blockId);
1:   }
1: 
1: 
1: 
1:   /**
1:    * Construct the Min Max Index.
1:    * @param blockId
1:    */
1:   public void constructMinMaxIndex(String blockId) {
1:     // construct Min and Max values of each Blocklets present inside a block.
1:     List<MinMaxIndexBlockDetails> tempMinMaxIndexBlockDetails = null;
1:     tempMinMaxIndexBlockDetails = loadBlockDetails();
1:     try {
0:       writeMinMaxIndexFile(tempMinMaxIndexBlockDetails, blockPath, blockId);
1:     } catch (IOException ex) {
1:       LOGGER.info(" Unable to write the file");
1:     }
1:   }
1: 
1:   /**
1:    * loadBlockDetails into the MinMaxIndexBlockDetails class.
1:    */
1:   private List<MinMaxIndexBlockDetails> loadBlockDetails() {
1:     List<MinMaxIndexBlockDetails> minMaxIndexBlockDetails = new ArrayList<MinMaxIndexBlockDetails>();
0:     MinMaxIndexBlockDetails tmpminMaxIndexBlockDetails = new MinMaxIndexBlockDetails();
1: 
1:     for (int index = 0; index < blockMinMaxMap.size(); index++) {
1:       tmpminMaxIndexBlockDetails.setMinValues(blockMinMaxMap.get(index).getMin());
1:       tmpminMaxIndexBlockDetails.setMaxValues(blockMinMaxMap.get(index).getMax());
1:       tmpminMaxIndexBlockDetails.setBlockletId(index);
0:       tmpminMaxIndexBlockDetails.setFilePath(this.blockPath);
1:       minMaxIndexBlockDetails.add(tmpminMaxIndexBlockDetails);
1:     }
1:     return minMaxIndexBlockDetails;
1:   }
1: 
1:   /**
1:    * Write the data to a file. This is JSON format file.
1:    * @param minMaxIndexBlockDetails
0:    * @param blockPath
1:    * @param blockId
1:    * @throws IOException
1:    */
1:   public void writeMinMaxIndexFile(List<MinMaxIndexBlockDetails> minMaxIndexBlockDetails,
0:       String blockPath, String blockId) throws IOException {
0:     String filePath = blockPath.substring(0, blockPath.lastIndexOf(File.separator) + 1) + blockId
0:         + ".minmaxindex";
1:     BufferedWriter brWriter = null;
1:     DataOutputStream dataOutStream = null;
1:     try {
1:       FileFactory.createNewFile(filePath, FileFactory.getFileType(filePath));
1:       dataOutStream = FileFactory.getDataOutputStream(filePath, FileFactory.getFileType(filePath));
1:       Gson gsonObjectToWrite = new Gson();
0:       brWriter = new BufferedWriter(new OutputStreamWriter(dataOutStream,
0:           CarbonCommonConstants.CARBON_DEFAULT_STREAM_ENCODEFORMAT));
1:       String minmaxIndexData = gsonObjectToWrite.toJson(minMaxIndexBlockDetails);
1:       brWriter.write(minmaxIndexData);
1:     } catch (IOException ioe) {
1:       LOGGER.info("Error in writing minMaxindex file");
1:     } finally {
1:       if (null != brWriter) {
1:         brWriter.flush();
1:       }
1:       if (null != dataOutStream) {
1:         dataOutStream.flush();
1:       }
1:       CarbonUtil.closeStreams(brWriter, dataOutStream);
1:     }
1:   }
1: 
1: }
============================================================================
1:c2e4eb2: /*
1:c2e4eb2:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:c2e4eb2:  * contributor license agreements.  See the NOTICE file distributed with
1:c2e4eb2:  * this work for additional information regarding copyright ownership.
1:c2e4eb2:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:c2e4eb2:  * (the "License"); you may not use this file except in compliance with
1:c2e4eb2:  * the License.  You may obtain a copy of the License at
1:c2e4eb2:  *
1:c2e4eb2:  *    http://www.apache.org/licenses/LICENSE-2.0
1:c2e4eb2:  *
1:c2e4eb2:  * Unless required by applicable law or agreed to in writing, software
1:c2e4eb2:  * distributed under the License is distributed on an "AS IS" BASIS,
1:c2e4eb2:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:c2e4eb2:  * See the License for the specific language governing permissions and
1:c2e4eb2:  * limitations under the License.
1:c2e4eb2:  */
1:c2e4eb2: 
1:c2e4eb2: package org.apache.carbondata.core.scan.filter.executer;
1:c2e4eb2: 
1:c2e4eb2: import java.io.IOException;
1:c2e4eb2: import java.util.BitSet;
1:c2e4eb2: 
1:c2e4eb2: import org.apache.carbondata.core.scan.expression.exception.FilterUnsupportedException;
1:d7393da: import org.apache.carbondata.core.scan.filter.intf.RowIntf;
1:daa6465: import org.apache.carbondata.core.scan.processor.RawBlockletColumnChunks;
1:c2e4eb2: import org.apache.carbondata.core.util.BitSetGroup;
1:c2e4eb2: 
1:c2e4eb2: public class TrueFilterExecutor implements FilterExecuter {
1:c2e4eb2: 
1:c2e4eb2:   /**
1:c2e4eb2:    * API will apply filter based on resolver instance
1:c2e4eb2:    *
1:c2e4eb2:    * @return
1:c2e4eb2:    * @throws FilterUnsupportedException
1:c2e4eb2:    */
1:daa6465:   public BitSetGroup applyFilter(RawBlockletColumnChunks rawBlockletColumnChunks,
1:daa6465:       boolean useBitsetPipeLine) throws FilterUnsupportedException, IOException {
1:daa6465:     int numberOfPages = rawBlockletColumnChunks.getDataBlock().numberOfPages();
1:c2e4eb2:     BitSetGroup group = new BitSetGroup(numberOfPages);
1:c2e4eb2:     for (int i = 0; i < numberOfPages; i++) {
1:c2e4eb2:       BitSet set = new BitSet();
1:daa6465:       set.flip(0, rawBlockletColumnChunks.getDataBlock().getPageRowCount(i));
1:c2e4eb2:       group.setBitSet(set, i);
1:c2e4eb2:     }
1:c2e4eb2:     return group;
1:c2e4eb2:   }
1:c2e4eb2: 
1:daa6465:   @Override
1:daa6465:   public boolean applyFilter(RowIntf value, int dimOrdinalMax) {
1:d7393da:     return true;
1:d7393da:   }
1:d7393da: 
1:c2e4eb2:   /**
1:c2e4eb2:    * API will verify whether the block can be shortlisted based on block
1:c2e4eb2:    * max and min key.
1:c2e4eb2:    *
1:c2e4eb2:    * @param blockMaxValue, maximum value of the
1:c2e4eb2:    * @param blockMinValue
1:c2e4eb2:    * @return BitSet
1:c2e4eb2:    */
1:c2e4eb2:   public BitSet isScanRequired(byte[][] blockMaxValue, byte[][] blockMinValue) {
1:c2e4eb2:     BitSet bitSet = new BitSet(1);
1:c2e4eb2:     bitSet.flip(0, 1);
1:c2e4eb2:     return bitSet;
1:c2e4eb2:   }
1:c2e4eb2: 
1:c2e4eb2:   /**
1:c2e4eb2:    * It just reads necessary block for filter executor, it does not uncompress the data.
1:c2e4eb2:    *
1:daa6465:    * @param rawBlockletColumnChunks
1:c2e4eb2:    */
1:daa6465:   public void readColumnChunks(RawBlockletColumnChunks rawBlockletColumnChunks) {
1:c2e4eb2:     // do nothing
1:c2e4eb2:   }
1:c2e4eb2: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.processor.RawBlockletColumnChunks;
/////////////////////////////////////////////////////////////////////////
1:   public BitSetGroup applyFilter(RawBlockletColumnChunks rawBlockletColumnChunks,
1:       boolean useBitsetPipeLine) throws FilterUnsupportedException, IOException {
1:     int numberOfPages = rawBlockletColumnChunks.getDataBlock().numberOfPages();
1:       set.flip(0, rawBlockletColumnChunks.getDataBlock().getPageRowCount(i));
1:   @Override
1:   public boolean applyFilter(RowIntf value, int dimOrdinalMax) {
/////////////////////////////////////////////////////////////////////////
1:    * @param rawBlockletColumnChunks
1:   public void readColumnChunks(RawBlockletColumnChunks rawBlockletColumnChunks) {
author:dhatchayani
-------------------------------------------------------------------------------
commit:50e2f2c
/////////////////////////////////////////////////////////////////////////
0:       set.flip(0, blockChunkHolder.getDataBlock().getPageRowCount(i));
author:QiangCai
-------------------------------------------------------------------------------
commit:d7393da
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.filter.intf.RowIntf;
/////////////////////////////////////////////////////////////////////////
0:   @Override public boolean applyFilter(RowIntf value, int dimOrdinalMax) {
1:     return true;
1:   }
1: 
author:kumarvishal
-------------------------------------------------------------------------------
commit:75e0bd4
/////////////////////////////////////////////////////////////////////////
0:   public BitSetGroup applyFilter(BlocksChunkHolder blockChunkHolder, boolean useBitsetPipeLine)
author:sounakr
-------------------------------------------------------------------------------
commit:c2e4eb2
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.core.scan.filter.executer;
1: 
1: import java.io.IOException;
1: import java.util.BitSet;
1: 
1: import org.apache.carbondata.core.scan.expression.exception.FilterUnsupportedException;
0: import org.apache.carbondata.core.scan.processor.BlocksChunkHolder;
1: import org.apache.carbondata.core.util.BitSetGroup;
1: 
1: public class TrueFilterExecutor implements FilterExecuter {
1: 
1:   /**
1:    * API will apply filter based on resolver instance
1:    *
1:    * @return
1:    * @throws FilterUnsupportedException
1:    */
0:   public BitSetGroup applyFilter(BlocksChunkHolder blockChunkHolder)
0:       throws FilterUnsupportedException, IOException {
0:     int numberOfPages = blockChunkHolder.getDataBlock().numberOfPages();
1:     BitSetGroup group = new BitSetGroup(numberOfPages);
1:     for (int i = 0; i < numberOfPages; i++) {
1:       BitSet set = new BitSet();
0:       set.flip(0, blockChunkHolder.getDataBlock().nodeSize());
1:       group.setBitSet(set, i);
1:     }
1:     return group;
1:   }
1: 
1:   /**
1:    * API will verify whether the block can be shortlisted based on block
1:    * max and min key.
1:    *
1:    * @param blockMaxValue, maximum value of the
1:    * @param blockMinValue
1:    * @return BitSet
1:    */
1:   public BitSet isScanRequired(byte[][] blockMaxValue, byte[][] blockMinValue) {
1:     BitSet bitSet = new BitSet(1);
1:     bitSet.flip(0, 1);
1:     return bitSet;
1:   }
1: 
1:   /**
1:    * It just reads necessary block for filter executor, it does not uncompress the data.
1:    *
0:    * @param blockChunkHolder
1:    */
0:   public void readBlocks(BlocksChunkHolder blockChunkHolder) throws IOException {
1:     // do nothing
1:   }
1: }
============================================================================
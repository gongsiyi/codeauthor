1:9db662a: /*
1:9db662a:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:9db662a:  * contributor license agreements.  See the NOTICE file distributed with
1:9db662a:  * this work for additional information regarding copyright ownership.
1:9db662a:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:9db662a:  * (the "License"); you may not use this file except in compliance with
1:9db662a:  * the License.  You may obtain a copy of the License at
1:9db662a:  *
1:9db662a:  *    http://www.apache.org/licenses/LICENSE-2.0
1:9db662a:  *
1:9db662a:  * Unless required by applicable law or agreed to in writing, software
1:9db662a:  * distributed under the License is distributed on an "AS IS" BASIS,
1:9db662a:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:9db662a:  * See the License for the specific language governing permissions and
1:9db662a:  * limitations under the License.
1:9db662a:  */
2:9db662a: 
1:9db662a: package org.apache.carbondata.datamap.bloom;
1:9db662a: 
1:9db662a: import java.io.IOException;
1:9db662a: import java.util.List;
1:9db662a: 
1:9db662a: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:9db662a: import org.apache.carbondata.core.datamap.Segment;
1:747be9b: import org.apache.carbondata.core.datamap.dev.DataMapBuilder;
1:cd7c210: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1:81038f5: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:9db662a: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:81038f5: import org.apache.carbondata.core.util.CarbonUtil;
1:77a1110: 
1:9db662a: /**
1:9db662a:  * Implementation for BloomFilter DataMap to rebuild the datamap for main table with existing data
1:9db662a:  */
1:9db662a: @InterfaceAudience.Internal
1:5c483f3: public class BloomDataMapBuilder extends AbstractBloomDataMapWriter implements DataMapBuilder {
1:9db662a: 
1:747be9b:   BloomDataMapBuilder(String tablePath, String dataMapName, List<CarbonColumn> indexColumns,
1:cd7c210:       Segment segment, String shardName, SegmentProperties segmentProperties,
1:cd7c210:       int bloomFilterSize, double bloomFilterFpp, boolean bloomCompress) throws IOException {
1:cd7c210:     super(tablePath, dataMapName, indexColumns, segment, shardName, segmentProperties,
1:cd7c210:         bloomFilterSize, bloomFilterFpp, bloomCompress);
2:9db662a:   }
1:9db662a: 
1:9db662a:   @Override
1:9db662a:   public void initialize() throws IOException {
1:9db662a:     super.resetBloomFilters();
1:9db662a:   }
1:9db662a: 
1:9db662a:   @Override
1:9db662a:   public void addRow(int blockletId, int pageId, int rowId, Object[] values) {
1:9db662a:     if (currentBlockletId != blockletId) {
1:9db662a:       // new blocklet started, flush bloom filter to datamap fileh
1:9db662a:       super.writeBloomDataMapFile();
1:9db662a:       currentBlockletId = blockletId;
1:9db662a:     }
1:9db662a:     // for each indexed column, add the data to bloom filter
1:9db662a:     for (int i = 0; i < indexColumns.size(); i++) {
1:9db662a:       Object data = values[i];
1:5c483f3:       addValue2BloomIndex(i, data);
1:9db662a:     }
1:9db662a:   }
1:9db662a: 
1:9db662a:   @Override
1:5c483f3:   protected byte[] convertNonDictionaryValue(int indexColIdx, byte[] value) {
1:5c483f3:     return value;
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   @Override
1:9db662a:   public void finish() throws IOException {
1:dac5d3c:     if (!isWritingFinished()) {
1:dac5d3c:       if (indexBloomFilters.size() > 0) {
1:dac5d3c:         writeBloomDataMapFile();
1:dac5d3c:       }
1:dac5d3c:       releaseResouce();
1:dac5d3c:       setWritingFinished(true);
1:dac5d3c:     }
1:9db662a:   }
1:9db662a: 
1:9db662a:   @Override
1:81038f5:   protected byte[] convertDictionaryValue(int indexColIdx, Object value) {
1:81038f5:     // input value from IndexDataMapRebuildRDD is already decoded as surrogate key
1:81038f5:     return CarbonUtil.getValueAsBytes(DataTypes.INT, value);
1:81038f5:   }
1:81038f5: 
1:81038f5:   @Override
1:9db662a:   public void close() throws IOException {
1:9db662a:     releaseResouce();
1:9db662a:   }
1:9db662a: 
1:9db662a:   @Override
1:5c483f3:   public boolean isIndexForCarbonRawBytes() {
1:5c483f3:     return true;
1:9db662a:   }
1:9db662a: }
============================================================================
author:Manhua
-------------------------------------------------------------------------------
commit:81038f5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.util.CarbonUtil;
/////////////////////////////////////////////////////////////////////////
1:   protected byte[] convertDictionaryValue(int indexColIdx, Object value) {
1:     // input value from IndexDataMapRebuildRDD is already decoded as surrogate key
1:     return CarbonUtil.getValueAsBytes(DataTypes.INT, value);
1:   }
1: 
1:   @Override
author:xuchuanyin
-------------------------------------------------------------------------------
commit:98c7581
/////////////////////////////////////////////////////////////////////////
commit:5c483f3
/////////////////////////////////////////////////////////////////////////
1: public class BloomDataMapBuilder extends AbstractBloomDataMapWriter implements DataMapBuilder {
/////////////////////////////////////////////////////////////////////////
1:       addValue2BloomIndex(i, data);
1:   protected byte[] convertNonDictionaryValue(int indexColIdx, byte[] value) {
1:     return value;
1:   }
1: 
1:   @Override
/////////////////////////////////////////////////////////////////////////
1:   public boolean isIndexForCarbonRawBytes() {
1:     return true;
commit:cd7c210
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.block.SegmentProperties;
/////////////////////////////////////////////////////////////////////////
1:       Segment segment, String shardName, SegmentProperties segmentProperties,
1:       int bloomFilterSize, double bloomFilterFpp, boolean bloomCompress) throws IOException {
1:     super(tablePath, dataMapName, indexColumns, segment, shardName, segmentProperties,
1:         bloomFilterSize, bloomFilterFpp, bloomCompress);
0:     throw new RuntimeException(
0:         "Deferred rebuild for bloomfilter datamap is currently not supported");
commit:dac5d3c
/////////////////////////////////////////////////////////////////////////
1:     if (!isWritingFinished()) {
1:       if (indexBloomFilters.size() > 0) {
1:         writeBloomDataMapFile();
1:       }
1:       releaseResouce();
1:       setWritingFinished(true);
1:     }
commit:6b94971
/////////////////////////////////////////////////////////////////////////
0:       Segment segment, String shardName, int bloomFilterSize, double bloomFilterFpp)
0:       throws IOException {
0:     super(tablePath, dataMapName, indexColumns, segment, shardName,
0:         bloomFilterSize, bloomFilterFpp);
author:ravipesala
-------------------------------------------------------------------------------
commit:77a1110
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.util.bloom.Key;
1: 
/////////////////////////////////////////////////////////////////////////
0:       Segment segment, String shardName, int bloomFilterSize, double bloomFilterFpp,
0:       boolean bloomCompress) throws IOException {
0:     super(tablePath, dataMapName, indexColumns, segment, shardName, bloomFilterSize, bloomFilterFpp,
0:         bloomCompress);
/////////////////////////////////////////////////////////////////////////
0:       indexBloomFilters.get(i).add(new Key(indexValue));
author:Jacky Li
-------------------------------------------------------------------------------
commit:747be9b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datamap.dev.DataMapBuilder;
/////////////////////////////////////////////////////////////////////////
0: public class BloomDataMapBuilder extends BloomDataMapWriter implements DataMapBuilder {
1:   BloomDataMapBuilder(String tablePath, String dataMapName, List<CarbonColumn> indexColumns,
commit:9db662a
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.datamap.bloom;
1: 
1: import java.io.IOException;
1: import java.util.List;
1: 
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
0: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.datamap.Segment;
0: import org.apache.carbondata.core.datamap.dev.DataMapRefresher;
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
0: import org.apache.carbondata.core.util.CarbonUtil;
1: 
1: /**
1:  * Implementation for BloomFilter DataMap to rebuild the datamap for main table with existing data
1:  */
1: @InterfaceAudience.Internal
0: public class BloomDataMapRefresher extends BloomDataMapWriter implements DataMapRefresher {
1: 
0:   BloomDataMapRefresher(String tablePath, String dataMapName, List<CarbonColumn> indexColumns,
0:       Segment segment, String shardName, int bloomFilterSize) throws IOException {
0:     super(tablePath, dataMapName, indexColumns, segment, shardName, bloomFilterSize);
1:   }
1: 
1:   @Override
1:   public void initialize() throws IOException {
1:     super.resetBloomFilters();
1:   }
1: 
1:   @Override
1:   public void addRow(int blockletId, int pageId, int rowId, Object[] values) {
1:     if (currentBlockletId != blockletId) {
1:       // new blocklet started, flush bloom filter to datamap fileh
1:       super.writeBloomDataMapFile();
1:       currentBlockletId = blockletId;
1:     }
1:     // for each indexed column, add the data to bloom filter
0:     List<CarbonColumn> indexColumns = getIndexColumns();
1:     for (int i = 0; i < indexColumns.size(); i++) {
1:       Object data = values[i];
0:       DataType dataType = indexColumns.get(i).getDataType();
0:       byte[] indexValue;
0:       if (DataTypes.STRING == dataType) {
0:         indexValue = getStringData(data);
0:       } else if (DataTypes.BYTE_ARRAY == dataType) {
0:         byte[] originValue = (byte[]) data;
0:         // String and byte array is LV encoded, L is short type
0:         indexValue = new byte[originValue.length - 2];
0:         System.arraycopy(originValue, 2, indexValue, 0, originValue.length - 2);
0:       } else {
0:         indexValue = CarbonUtil.getValueAsBytes(dataType, data);
1:       }
0:       indexBloomFilters.get(i).put(indexValue);
1:     }
1:   }
1: 
1:   @Override
1:   public void finish() throws IOException {
0:     super.finish();
1:   }
1: 
1:   @Override
1:   public void close() throws IOException {
1:     releaseResouce();
1:   }
1: 
1:   @Override
0:   protected byte[] getStringData(Object data) {
0:     return ((String) data).getBytes(CarbonCommonConstants.DEFAULT_CHARSET_CLASS);
1:   }
1: }
============================================================================
1:81038f5: /*
1:81038f5:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:81038f5:  * contributor license agreements.  See the NOTICE file distributed with
1:81038f5:  * this work for additional information regarding copyright ownership.
1:81038f5:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:81038f5:  * (the "License"); you may not use this file except in compliance with
1:81038f5:  * the License.  You may obtain a copy of the License at
1:81038f5:  *
1:81038f5:  *    http://www.apache.org/licenses/LICENSE-2.0
1:81038f5:  *
1:81038f5:  * Unless required by applicable law or agreed to in writing, software
1:81038f5:  * distributed under the License is distributed on an "AS IS" BASIS,
1:81038f5:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:81038f5:  * See the License for the specific language governing permissions and
1:81038f5:  * limitations under the License.
1:81038f5:  */
1:81038f5: package org.apache.carbondata.core.scan.collector.impl;
1:81038f5: 
1:81038f5: import java.nio.charset.Charset;
1:81038f5: import java.util.ArrayList;
1:81038f5: import java.util.List;
1:81038f5: 
1:81038f5: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:81038f5: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:81038f5: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1:81038f5: import org.apache.carbondata.core.scan.model.ProjectionMeasure;
1:81038f5: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1:81038f5: import org.apache.carbondata.core.scan.wrappers.ByteArrayWrapper;
1:81038f5: import org.apache.carbondata.core.stats.QueryStatistic;
1:81038f5: import org.apache.carbondata.core.stats.QueryStatisticsConstants;
1:81038f5: 
1:81038f5: /**
1:81038f5:  * It is not a collector it is just a scanned result holder.
1:81038f5:  * This class returns all the dimensions in a ByteArrayWrapper and append
1:81038f5:  * blockletNo/PageId/RowId at end of the row.
1:81038f5:  */
1:81038f5: @InterfaceAudience.Internal
1:81038f5: public class RowIdRestructureBasedRawResultCollector extends RestructureBasedRawResultCollector {
1:81038f5: 
1:81038f5:   public RowIdRestructureBasedRawResultCollector(BlockExecutionInfo blockExecutionInfos) {
1:81038f5:     super(blockExecutionInfos);
1:81038f5:   }
1:81038f5: 
1:81038f5:   @Override
1:81038f5:   protected void scanAndFillData(BlockletScannedResult scannedResult, int batchSize,
1:81038f5:                                List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures) {
1:81038f5:     int numberOfPages = scannedResult.numberOfpages();
1:81038f5:     // loop will exit once the batchSize data has been read or the pages have been exhausted
1:81038f5:     while (scannedResult.getCurrentPageCounter() < numberOfPages) {
1:81038f5:       int currentPageRowCount = scannedResult.getCurrentPageRowCount();
1:81038f5:       if (currentPageRowCount == 0) {
1:81038f5:         scannedResult.incrementPageCounter();
1:81038f5:         continue;
1:81038f5:       }
1:81038f5:       int rowCounter = scannedResult.getRowCounter();
1:81038f5:       // getRowCounter holds total number rows processed. Calculate the
1:81038f5:       // Left over space through getRowCounter only.
1:81038f5:       int availableRows = currentPageRowCount - rowCounter;
1:81038f5:       // rows available in current page that can be processed from current page
1:81038f5:       int availableBatchRowCount = Math.min(batchSize, availableRows);
1:81038f5:       // this condition will be true if no data left in the current block/blocklet to be scanned
1:81038f5:       if (availableBatchRowCount < 1) {
1:81038f5:         break;
1:81038f5:       }
1:81038f5:       if (batchSize > availableRows) {
1:81038f5:         batchSize = batchSize - availableRows;
1:81038f5:       } else {
1:81038f5:         // this is done because in IUD cases actuals rows fetch can be less than batch size as
1:81038f5:         // some of the rows could have deleted. So in those cases batchSize need to be
1:81038f5:         // re initialized with left over value
1:81038f5:         batchSize = 0;
1:81038f5:       }
1:81038f5:       // for every iteration of available rows filling newly created list of Object[] and add it to
1:81038f5:       // the final list so there is no mismatch in the counter while filling dimension and
1:81038f5:       // measure data
1:81038f5:       List<Object[]> collectedData = new ArrayList<>(availableBatchRowCount);
1:81038f5:       // fill dimension data
1:81038f5:       fillDimensionData(scannedResult, collectedData, queryMeasures, availableBatchRowCount);
1:81038f5:       fillMeasureData(scannedResult, collectedData);
1:81038f5:       // increment the number of rows scanned in scanned result statistics
1:81038f5:       // incrementScannedResultRowCounter(scannedResult, availableBatchRowCount);
1:81038f5:       // assign the left over rows to batch size if the number of rows fetched are lesser
1:81038f5:       // than batchSize
1:81038f5:       if (collectedData.size() < availableBatchRowCount) {
1:81038f5:         batchSize += availableBatchRowCount - listBasedResult.size();
1:81038f5:       }
1:81038f5:       // add the collected data to the final list
1:81038f5:       listBasedResult.addAll(collectedData);
1:81038f5:     }
1:81038f5:   }
1:81038f5: 
1:81038f5:   private void fillDimensionData(BlockletScannedResult scannedResult,
1:81038f5:                List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures, int batchSize) {
1:81038f5:     long startTime = System.currentTimeMillis();
1:81038f5:     List<byte[]> dictionaryKeyArrayBatch = scannedResult.getDictionaryKeyArrayBatch(batchSize);
1:81038f5:     List<byte[][]> noDictionaryKeyArrayBatch =
1:81038f5:         scannedResult.getNoDictionaryKeyArrayBatch(batchSize);
1:81038f5:     List<byte[][]> complexTypeKeyArrayBatch = scannedResult.getComplexTypeKeyArrayBatch(batchSize);
1:81038f5:     // it will same for one blocklet so can be computed only once
1:81038f5:     byte[] implicitColumnByteArray = scannedResult.getBlockletId()
1:81038f5:         .getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET));
1:81038f5:     // Note: size check in for loop is for dictionaryKeyArrayBatch as this size can be lesser than
1:81038f5:     // batch size in case of IUD scenarios
1:81038f5:     for (int i = 0; i < dictionaryKeyArrayBatch.size(); i++) {
1:81038f5:       // 1 for ByteArrayWrapper object which will contain dictionary and no dictionary data
1:81038f5:       // 3 for blockletId, pageId, rowId
1:81038f5:       Object[] row = new Object[1 + queryMeasures.length + 3];
1:81038f5:       scannedResult.incrementCounter();
1:8952394:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
1:81038f5:       row[1 + queryMeasures.length + 1] = scannedResult.getCurrentPageCounter();
1:81038f5:       ByteArrayWrapper wrapper = new ByteArrayWrapper();
1:81038f5:       wrapper.setDictionaryKey(dictionaryKeyArrayBatch.get(i));
1:81038f5:       wrapper.setNoDictionaryKeys(noDictionaryKeyArrayBatch.get(i));
1:81038f5:       wrapper.setComplexTypesKeys(complexTypeKeyArrayBatch.get(i));
1:81038f5:       wrapper.setImplicitColumnByteArray(implicitColumnByteArray);
1:81038f5:       row[0] = wrapper;
1:81038f5:       row[1 + queryMeasures.length + 2] = scannedResult.getCurrentRowId();
1:81038f5:       listBasedResult.add(row);
1:81038f5:     }
1:81038f5:     QueryStatistic keyColumnFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:81038f5:         .get(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME);
1:81038f5:     keyColumnFillingTime.addCountStatistic(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME,
1:81038f5:         keyColumnFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:81038f5:   }
1:81038f5: 
1:81038f5:   private void fillMeasureData(BlockletScannedResult scannedResult,
1:81038f5:                                List<Object[]> listBasedResult) {
1:81038f5:     long startTime = System.currentTimeMillis();
1:81038f5:     // if list is not empty after filling the dimension data then only fill the measure data
1:81038f5:     if (!listBasedResult.isEmpty()) {
1:81038f5:       fillMeasureDataBatch(listBasedResult, 1, scannedResult);
1:81038f5:     }
1:81038f5:     QueryStatistic measureFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:81038f5:         .get(QueryStatisticsConstants.MEASURE_FILLING_TIME);
1:81038f5:     measureFillingTime.addCountStatistic(QueryStatisticsConstants.MEASURE_FILLING_TIME,
1:81038f5:         measureFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:81038f5:   }
1:81038f5: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:8952394
/////////////////////////////////////////////////////////////////////////
1:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
author:Manhua
-------------------------------------------------------------------------------
commit:ce53b48
/////////////////////////////////////////////////////////////////////////
0:       row[1 + queryMeasures.length] = Integer.parseInt(scannedResult.getBlockletNumber());
commit:81038f5
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.scan.collector.impl;
1: 
1: import java.nio.charset.Charset;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1: import org.apache.carbondata.core.scan.model.ProjectionMeasure;
1: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1: import org.apache.carbondata.core.scan.wrappers.ByteArrayWrapper;
1: import org.apache.carbondata.core.stats.QueryStatistic;
1: import org.apache.carbondata.core.stats.QueryStatisticsConstants;
1: 
1: /**
1:  * It is not a collector it is just a scanned result holder.
1:  * This class returns all the dimensions in a ByteArrayWrapper and append
1:  * blockletNo/PageId/RowId at end of the row.
1:  */
1: @InterfaceAudience.Internal
1: public class RowIdRestructureBasedRawResultCollector extends RestructureBasedRawResultCollector {
1: 
1:   public RowIdRestructureBasedRawResultCollector(BlockExecutionInfo blockExecutionInfos) {
1:     super(blockExecutionInfos);
1:   }
1: 
1:   @Override
1:   protected void scanAndFillData(BlockletScannedResult scannedResult, int batchSize,
1:                                List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures) {
1:     int numberOfPages = scannedResult.numberOfpages();
1:     // loop will exit once the batchSize data has been read or the pages have been exhausted
1:     while (scannedResult.getCurrentPageCounter() < numberOfPages) {
1:       int currentPageRowCount = scannedResult.getCurrentPageRowCount();
1:       if (currentPageRowCount == 0) {
1:         scannedResult.incrementPageCounter();
1:         continue;
1:       }
1:       int rowCounter = scannedResult.getRowCounter();
1:       // getRowCounter holds total number rows processed. Calculate the
1:       // Left over space through getRowCounter only.
1:       int availableRows = currentPageRowCount - rowCounter;
1:       // rows available in current page that can be processed from current page
1:       int availableBatchRowCount = Math.min(batchSize, availableRows);
1:       // this condition will be true if no data left in the current block/blocklet to be scanned
1:       if (availableBatchRowCount < 1) {
1:         break;
1:       }
1:       if (batchSize > availableRows) {
1:         batchSize = batchSize - availableRows;
1:       } else {
1:         // this is done because in IUD cases actuals rows fetch can be less than batch size as
1:         // some of the rows could have deleted. So in those cases batchSize need to be
1:         // re initialized with left over value
1:         batchSize = 0;
1:       }
1:       // for every iteration of available rows filling newly created list of Object[] and add it to
1:       // the final list so there is no mismatch in the counter while filling dimension and
1:       // measure data
1:       List<Object[]> collectedData = new ArrayList<>(availableBatchRowCount);
1:       // fill dimension data
1:       fillDimensionData(scannedResult, collectedData, queryMeasures, availableBatchRowCount);
1:       fillMeasureData(scannedResult, collectedData);
1:       // increment the number of rows scanned in scanned result statistics
1:       // incrementScannedResultRowCounter(scannedResult, availableBatchRowCount);
1:       // assign the left over rows to batch size if the number of rows fetched are lesser
1:       // than batchSize
1:       if (collectedData.size() < availableBatchRowCount) {
1:         batchSize += availableBatchRowCount - listBasedResult.size();
1:       }
1:       // add the collected data to the final list
1:       listBasedResult.addAll(collectedData);
1:     }
1:   }
1: 
1:   private void fillDimensionData(BlockletScannedResult scannedResult,
1:                List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures, int batchSize) {
1:     long startTime = System.currentTimeMillis();
1:     List<byte[]> dictionaryKeyArrayBatch = scannedResult.getDictionaryKeyArrayBatch(batchSize);
1:     List<byte[][]> noDictionaryKeyArrayBatch =
1:         scannedResult.getNoDictionaryKeyArrayBatch(batchSize);
1:     List<byte[][]> complexTypeKeyArrayBatch = scannedResult.getComplexTypeKeyArrayBatch(batchSize);
1:     // it will same for one blocklet so can be computed only once
1:     byte[] implicitColumnByteArray = scannedResult.getBlockletId()
1:         .getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET));
1:     // Note: size check in for loop is for dictionaryKeyArrayBatch as this size can be lesser than
1:     // batch size in case of IUD scenarios
1:     for (int i = 0; i < dictionaryKeyArrayBatch.size(); i++) {
1:       // 1 for ByteArrayWrapper object which will contain dictionary and no dictionary data
1:       // 3 for blockletId, pageId, rowId
1:       Object[] row = new Object[1 + queryMeasures.length + 3];
1:       scannedResult.incrementCounter();
0:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
1:       row[1 + queryMeasures.length + 1] = scannedResult.getCurrentPageCounter();
1:       ByteArrayWrapper wrapper = new ByteArrayWrapper();
1:       wrapper.setDictionaryKey(dictionaryKeyArrayBatch.get(i));
1:       wrapper.setNoDictionaryKeys(noDictionaryKeyArrayBatch.get(i));
1:       wrapper.setComplexTypesKeys(complexTypeKeyArrayBatch.get(i));
1:       wrapper.setImplicitColumnByteArray(implicitColumnByteArray);
1:       row[0] = wrapper;
1:       row[1 + queryMeasures.length + 2] = scannedResult.getCurrentRowId();
1:       listBasedResult.add(row);
1:     }
1:     QueryStatistic keyColumnFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:         .get(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME);
1:     keyColumnFillingTime.addCountStatistic(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME,
1:         keyColumnFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:   }
1: 
1:   private void fillMeasureData(BlockletScannedResult scannedResult,
1:                                List<Object[]> listBasedResult) {
1:     long startTime = System.currentTimeMillis();
1:     // if list is not empty after filling the dimension data then only fill the measure data
1:     if (!listBasedResult.isEmpty()) {
1:       fillMeasureDataBatch(listBasedResult, 1, scannedResult);
1:     }
1:     QueryStatistic measureFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:         .get(QueryStatisticsConstants.MEASURE_FILLING_TIME);
1:     measureFillingTime.addCountStatistic(QueryStatisticsConstants.MEASURE_FILLING_TIME,
1:         measureFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:   }
1: }
============================================================================
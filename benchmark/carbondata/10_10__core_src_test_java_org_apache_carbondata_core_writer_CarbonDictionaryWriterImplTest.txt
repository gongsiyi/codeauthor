1:cd6a4ff: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:cd6a4ff:  *
1:cd6a4ff:  *    http://www.apache.org/licenses/LICENSE-2.0
1:cd6a4ff:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
1:cd6a4ff:  */
1:cd6a4ff: 
1:cd6a4ff: package org.apache.carbondata.core.writer;
1:cd6a4ff: 
1:cd6a4ff: import java.io.File;
1:cd6a4ff: import java.io.FileInputStream;
1:cd6a4ff: import java.io.IOException;
1:cd6a4ff: import java.io.InputStream;
1:cd6a4ff: import java.net.URI;
1:cd6a4ff: import java.net.URISyntaxException;
1:4d882df: import java.net.URL;
1:cd6a4ff: import java.nio.charset.Charset;
1:cd6a4ff: import java.util.ArrayList;
1:cd6a4ff: import java.util.Arrays;
1:7e0584e: import java.util.Iterator;
1:cd6a4ff: import java.util.List;
1:cd6a4ff: import java.util.Properties;
1:cd6a4ff: import java.util.UUID;
1:cd6a4ff: 
1:d3a09e2: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
1:cd6a4ff: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:ce09aaa: import org.apache.carbondata.core.datastore.filesystem.CarbonFile;
1:ce09aaa: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:2fe7758: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1:2fe7758: import org.apache.carbondata.core.metadata.CarbonTableIdentifier;
1:2fe7758: import org.apache.carbondata.core.metadata.ColumnIdentifier;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryColumnMetaChunk;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReaderImpl;
1:cd6a4ff: import org.apache.carbondata.core.reader.CarbonDictionaryReaderImpl;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonProperties;
1:cd6a4ff: import org.apache.carbondata.core.util.CarbonUtil;
1:2fe7758: import org.apache.carbondata.core.util.path.CarbonTablePath;
1:2fe7758: import org.apache.carbondata.format.ColumnDictionaryChunkMeta;
1:cd6a4ff: 
1:cd6a4ff: import mockit.Mock;
1:cd6a4ff: import mockit.MockUp;
1:cd6a4ff: import org.junit.After;
1:cd6a4ff: import org.junit.Before;
1:cd6a4ff: import org.junit.Test;
1:cd6a4ff: 
1:cd6a4ff: import static org.junit.Assert.assertTrue;
1:cd6a4ff: 
1:cd6a4ff: /**
1:cd6a4ff:  * This class will test the functionality writing and
1:cd6a4ff:  * reading a dictionary and its corresponding metadata file
1:cd6a4ff:  */
1:cd6a4ff: public class CarbonDictionaryWriterImplTest {
1:cd6a4ff: 
1:cd6a4ff:   private static final String PROPERTY_FILE_NAME = "carbonTest.properties";
1:cd6a4ff: 
1:cd6a4ff:   private CarbonTableIdentifier carbonTableIdentifier;
1:cd6a4ff: 
1:1155d4d:   private AbsoluteTableIdentifier absoluteTableIdentifier;
1:1155d4d: 
1:cd6a4ff:   private String databaseName;
1:cd6a4ff: 
1:cd6a4ff:   private String tableName;
1:cd6a4ff: 
1:bf6c471:   private String tablePath;
1:cd6a4ff: 
1:cd6a4ff:   private ColumnIdentifier columnIdentifier;
1:cd6a4ff: 
1:d3a09e2:   private DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier;
1:d3a09e2: 
1:cd6a4ff:   private Properties props;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * dictionary file path
1:cd6a4ff:    */
1:cd6a4ff:   private String dictionaryFilePath;
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * dictionary metadata file path
1:cd6a4ff:    */
1:cd6a4ff:   private String dictionaryMetaFilePath;
1:cd6a4ff: 
1:cd6a4ff:   private List<String> dataSet1;
1:cd6a4ff: 
1:cd6a4ff:   private List<String> dataSet2;
1:cd6a4ff: 
1:cd6a4ff:   private List<String> dataSet3;
1:cd6a4ff: 
1:cd6a4ff:   @Before public void setUp() throws Exception {
1:cd6a4ff:     init();
1:cd6a4ff:     this.databaseName = props.getProperty("database", "testSchema");
1:cd6a4ff:     this.tableName = props.getProperty("tableName", "carbon");
1:bf6c471:     this.tablePath = props.getProperty("storePath", "carbonStore");
1:cd6a4ff:     this.columnIdentifier = new ColumnIdentifier("Name", null, null);
1:cd6a4ff:     carbonTableIdentifier = new CarbonTableIdentifier(databaseName, tableName, UUID.randomUUID().toString());
1:bf6c471:     absoluteTableIdentifier = AbsoluteTableIdentifier.from(tablePath, carbonTableIdentifier);
1:d3a09e2:     this.dictionaryColumnUniqueIdentifier =
1:1155d4d:         new DictionaryColumnUniqueIdentifier(absoluteTableIdentifier, columnIdentifier,
1:29dc302:             columnIdentifier.getDataType());
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     prepareDataSet();
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   @After public void tearDown() throws Exception {
1:cd6a4ff:     carbonTableIdentifier = null;
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * prepare the dataset required for running test cases
1:cd6a4ff:    */
1:cd6a4ff:   private void prepareDataSet() {
1:f911403:     dataSet1 = Arrays.asList("a", "b");
1:f911403:     dataSet2 = Arrays.asList("c", "d");
1:f911403:     dataSet3 = Arrays.asList("e", "f");
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * test writers write functionality for a column specific
1:cd6a4ff:    * to a table in a database
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testWriteForNormalColumn() throws IOException {
1:cd6a4ff:     // second parameter is chunk count which is for the number of
1:cd6a4ff:     // thrift objects written for a segment
1:cd6a4ff:     processColumnValuesForOneChunk(1);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * test writers write functionality for a column shared across tables
1:cd6a4ff:    * in a database
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testWriteForSharedColumn() throws IOException {
1:cd6a4ff:     // second parameter is chunk count which is for the number of
1:cd6a4ff:     // thrift objects written for a segment
1:cd6a4ff:     processColumnValuesForOneChunk(1);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * test writing multiple dictionary chunks for a single segment
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testWriteMultipleChunksForOneSegment() throws IOException {
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     CarbonProperties.getInstance()
1:cd6a4ff:         .addProperty(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE, "1");
1:cd6a4ff:     // prepare dictionary writer object
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     writeDictionaryFile(writer, dataSet1);
1:cd6a4ff:     // record file size from where data has to be read
1:cd6a4ff:     long end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:     // read metadata chunks from file
1:cd6a4ff:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:cd6a4ff:         readDictionaryMetadataFile();
1:cd6a4ff:     assertTrue(1 == carbonDictionaryColumnMetaChunks.size());
1:cd6a4ff:     // prepare retrieved chunk metadata
1:cd6a4ff:     long start_offset = 0L;
1:cd6a4ff:     CarbonDictionaryColumnMetaChunk expected =
1:cd6a4ff:         new CarbonDictionaryColumnMetaChunk(1, dataSet1.size(), start_offset, end_offset,
1:cd6a4ff:             dataSet1.size());
1:cd6a4ff:     // validate chunk metadata - actual and expected
1:cd6a4ff:     for (CarbonDictionaryColumnMetaChunk chunk : carbonDictionaryColumnMetaChunks) {
1:cd6a4ff:       validateDictionaryMetadata(chunk, expected);
1:cd6a4ff:     }
1:cd6a4ff:     //assert for chunk count
1:cd6a4ff:     List<byte[]> dictionaryValues = readDictionaryFile(0L, 0L);
1:cd6a4ff:     // prepare expected dictionary chunk list
1:cd6a4ff:     List<String> actual = convertByteArrayListToStringValueList(dictionaryValues);
1:cd6a4ff:     assertTrue(dataSet1.size() == actual.size());
1:cd6a4ff:     // validate the dictionary data
1:cd6a4ff:     compareDictionaryData(actual, dataSet1);
1:cd6a4ff:     CarbonProperties.getInstance().addProperty(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE,
1:cd6a4ff:         CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE_DEFAULT);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * prepare the dictionary writer object
1:cd6a4ff:    */
1:cd6a4ff:   private CarbonDictionaryWriterImpl prepareWriter() throws IOException {
1:cd6a4ff:     initDictionaryDirPaths();
1:1155d4d:     return new CarbonDictionaryWriterImpl(dictionaryColumnUniqueIdentifier);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will test the write method in case of any exception
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testWriteThrowException() throws IOException {
1:cd6a4ff:     final String failureMessage = "write operation failed";
1:cd6a4ff:     // mock write method of writer and throw exception
1:cd6a4ff:     new MockUp<CarbonDictionaryWriterImpl>() {
1:cd6a4ff:       @Mock public void write(String value) throws IOException {
1:cd6a4ff:         throw new IOException(failureMessage);
1:cd6a4ff:       }
1:cd6a4ff:     };
1:cd6a4ff:     // prepare the writer
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     try {
1:cd6a4ff:       for (String value : dataSet1) {
1:cd6a4ff:         // exception should be thrown when write method is called
1:cd6a4ff:         writer.write(value);
1:cd6a4ff:       }
1:cd6a4ff:     } catch (IOException e) {
1:cd6a4ff:       assertTrue(failureMessage.equals(e.getMessage()));
1:cd6a4ff:     } finally {
1:cd6a4ff:       writer.close();
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will test the truncate functionality
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testTruncateOperation() throws IOException {
1:cd6a4ff:     // delete store path
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     // prepare first dictionary chunk
1:cd6a4ff:     // prepare dictionary writer object
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     writeDictionaryFile(writer, dataSet1);
1:cd6a4ff:     long endOffsetAfterFirstDictionaryChunk = CarbonUtil.getFileSize(dictionaryFilePath);
1:cd6a4ff:     // maintain the offset till end offset of first chunk
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     writeDictionaryFile(writer, dataSet2);
1:cd6a4ff:     // prepare first column meta chunk object
1:cd6a4ff:     ColumnDictionaryChunkMeta firstDictionaryChunkMeta =
1:cd6a4ff:         new ColumnDictionaryChunkMeta(1, 2, 0, endOffsetAfterFirstDictionaryChunk, 1);
1:cd6a4ff:     // overwrite the dictionary meta chunk file to test the truncate operation
1:cd6a4ff:     overwriteDictionaryMetaFile(firstDictionaryChunkMeta, dictionaryMetaFilePath);
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     // in the next step truncate operation will be tested while writing dictionary file
1:cd6a4ff:     writeDictionaryFile(writer, dataSet3);
1:cd6a4ff:     // read dictionary file
1:cd6a4ff:     List<byte[]> dictionaryValues = readDictionaryFile(0L, 0L);
1:cd6a4ff:     List<String> actual = convertByteArrayListToStringValueList(dictionaryValues);
1:cd6a4ff:     List<String> expected = new ArrayList<>(4);
1:cd6a4ff:     expected.addAll(dataSet1);
1:cd6a4ff:     expected.addAll(dataSet3);
1:cd6a4ff:     // validate the data retrieved and it should match dataset1
1:cd6a4ff:     compareDictionaryData(actual, expected);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will overwrite a given file with data provided
1:cd6a4ff:    */
1:cd6a4ff:   private void overwriteDictionaryMetaFile(ColumnDictionaryChunkMeta firstDictionaryChunkMeta,
1:cd6a4ff:       String dictionaryFile) throws IOException {
1:cd6a4ff:     ThriftWriter thriftMetaChunkWriter = new ThriftWriter(dictionaryFile, false);
1:cd6a4ff:     try {
1:cd6a4ff:       thriftMetaChunkWriter.open();
1:cd6a4ff:       thriftMetaChunkWriter.write(firstDictionaryChunkMeta);
1:cd6a4ff:     } catch (IOException e) {
1:cd6a4ff: 
1:cd6a4ff:     } finally {
1:cd6a4ff:       thriftMetaChunkWriter.close();
1:cd6a4ff:     }
1:cd6a4ff: 
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will test the reading of dictionary file from a given offset
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testReadingOfDictionaryChunkFromAnOffset() throws Exception {
1:cd6a4ff:     // delete store path
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     // prepare the writer to write dataset1
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     // write dataset1 data
1:cd6a4ff:     writeDictionaryFile(writer, dataSet1);
1:cd6a4ff:     // prepare the writer to write dataset2
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     // write dataset2
1:cd6a4ff:     writeDictionaryFile(writer, dataSet2);
1:cd6a4ff:     // record the offset from where data has to be read
1:cd6a4ff:     long dictionaryFileOffsetToRead = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:     // prepare writer to write dataset3
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     // write dataset 3
1:cd6a4ff:     writeDictionaryFile(writer, dataSet3);
1:cd6a4ff:     // read dictionary chunk from dictionary file
1:cd6a4ff:     List<byte[]> dictionaryData = readDictionaryFile(dictionaryFileOffsetToRead, 0L);
1:cd6a4ff:     // prepare the retrieved data
1:cd6a4ff:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:cd6a4ff:     // compare dictionary data set
1:cd6a4ff:     compareDictionaryData(actual, dataSet3);
1:cd6a4ff:     // read chunk metadata file
1:cd6a4ff:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:cd6a4ff:         readDictionaryMetadataFile();
1:cd6a4ff:     // assert for metadata chunk size
1:cd6a4ff:     assertTrue(3 == carbonDictionaryColumnMetaChunks.size());
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will test the reading of dictionary file between start and end offset
1:cd6a4ff:    */
1:cd6a4ff:   @Test public void testReadingOfDictionaryChunkBetweenStartAndEndOffset() throws Exception {
1:cd6a4ff:     // delete store path
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     // prepare the writer to write dataset1
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     // write dataset1 data
1:cd6a4ff:     writeDictionaryFile(writer, dataSet1);
1:cd6a4ff:     // record dictionary file start offset
1:cd6a4ff:     long dictionaryStartOffset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:     // prepare the writer to write dataset2
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     // write dataset2
1:cd6a4ff:     writeDictionaryFile(writer, dataSet2);
1:cd6a4ff:     // record the end offset for dictionary file
1:cd6a4ff:     long dictionaryFileEndOffset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:     // prepare writer to write dataset3
1:cd6a4ff:     writer = prepareWriter();
1:cd6a4ff:     // write dataset 3
1:cd6a4ff:     writeDictionaryFile(writer, dataSet3);
1:cd6a4ff:     // read dictionary chunk from dictionary file
1:cd6a4ff:     List<byte[]> dictionaryData =
1:cd6a4ff:         readDictionaryFile(dictionaryStartOffset, dictionaryFileEndOffset);
1:cd6a4ff:     // prepare the retrieved data
1:cd6a4ff:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:cd6a4ff:     // compare dictionary data set
1:cd6a4ff:     compareDictionaryData(actual, dataSet2);
1:cd6a4ff:     // read chunk metadata file
1:cd6a4ff:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:cd6a4ff:         readDictionaryMetadataFile();
1:cd6a4ff:     // assert for metadata chunk size
1:cd6a4ff:     assertTrue(3 == carbonDictionaryColumnMetaChunks.size());
1:cd6a4ff:     CarbonDictionaryColumnMetaChunk expected =
1:cd6a4ff:         new CarbonDictionaryColumnMetaChunk(3, 4, dictionaryStartOffset, dictionaryFileEndOffset,
1:cd6a4ff:             1);
1:cd6a4ff:     validateDictionaryMetadata(carbonDictionaryColumnMetaChunks.get(1), expected);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will convert list of byte array to list of string
1:cd6a4ff:    */
1:cd6a4ff:   private List<String> convertByteArrayListToStringValueList(List<byte[]> dictionaryByteArrayList) {
1:cd6a4ff:     List<String> valueList = new ArrayList<>(dictionaryByteArrayList.size());
1:cd6a4ff:     for (byte[] value : dictionaryByteArrayList) {
1:cd6a4ff:       valueList.add(new String(value, Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET)));
1:cd6a4ff:     }
1:cd6a4ff:     return valueList;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will write the data into a file
1:cd6a4ff:    */
1:cd6a4ff:   private void writeDictionaryFile(CarbonDictionaryWriterImpl writer, List<String> list)
1:cd6a4ff:       throws IOException {
1:cd6a4ff:     try {
1:cd6a4ff:       for (String value : list) {
1:cd6a4ff:         writer.write(value);
1:cd6a4ff:       }
1:cd6a4ff:     } finally {
1:cd6a4ff:       writer.close();
1:cd6a4ff:       writer.commit();
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will test the functionality of writing and reading one dictionary chunk
1:cd6a4ff:    */
1:cd6a4ff:   private void processColumnValuesForOneChunk(int chunkCountForSegment) throws IOException {
1:cd6a4ff:     // delete store path
1:cd6a4ff:     deleteStorePath();
1:cd6a4ff:     // prepare writer
1:cd6a4ff:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:cd6a4ff:     // write the data into file
1:cd6a4ff:     // test write api for passing list of byte array
1:cd6a4ff:     writer.write(convertStringListToByteArray(dataSet1));
1:cd6a4ff:     // close the writer
1:cd6a4ff:     writer.close();
1:cd6a4ff:     //write metadata
1:cd6a4ff:     writer.commit();
1:cd6a4ff:     // record end offset of file
1:cd6a4ff:     long end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:cd6a4ff:     // read dictionary chunk from dictionary file
1:cd6a4ff:     List<byte[]> dictionaryData = readDictionaryFile(0L, 0L);
1:cd6a4ff:     // prepare the retrieved data
1:cd6a4ff:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:cd6a4ff:     // compare the expected and actual data
1:cd6a4ff:     compareDictionaryData(actual, dataSet1);
1:cd6a4ff:     // read dictionary metadata chunks
1:cd6a4ff:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:cd6a4ff:         readDictionaryMetadataFile();
1:cd6a4ff:     // assert
1:cd6a4ff:     assertTrue(1 == carbonDictionaryColumnMetaChunks.size());
1:cd6a4ff:     long start_offset = 0L;
1:cd6a4ff:     // validate actual chunk metadata with expected
1:cd6a4ff:     CarbonDictionaryColumnMetaChunk expected =
1:cd6a4ff:         new CarbonDictionaryColumnMetaChunk(1, 2, start_offset, end_offset, 1);
1:cd6a4ff:     for (CarbonDictionaryColumnMetaChunk chunk : carbonDictionaryColumnMetaChunks) {
1:cd6a4ff:       validateDictionaryMetadata(chunk, expected);
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will convert list of string to list of byte array
1:cd6a4ff:    */
1:cd6a4ff:   private List<byte[]> convertStringListToByteArray(List<String> valueList) {
1:cd6a4ff:     List<byte[]> byteArrayList = new ArrayList<>(valueList.size());
1:cd6a4ff:     for (String value : valueList) {
1:cd6a4ff:       byteArrayList.add(value.getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET)));
1:cd6a4ff:     }
1:cd6a4ff:     return byteArrayList;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will validate the dictionary chunk metadata
1:cd6a4ff:    */
1:cd6a4ff:   private void validateDictionaryMetadata(CarbonDictionaryColumnMetaChunk actual,
1:cd6a4ff:       CarbonDictionaryColumnMetaChunk expected) {
1:cd6a4ff:     assertTrue(expected.getMin_surrogate_key() == actual.getMin_surrogate_key());
1:cd6a4ff:     assertTrue(expected.getMax_surrogate_key() == actual.getMax_surrogate_key());
1:cd6a4ff:     assertTrue(expected.getStart_offset() == actual.getStart_offset());
1:cd6a4ff:     assertTrue(expected.getEnd_offset() == actual.getEnd_offset());
1:cd6a4ff:     assertTrue(expected.getChunk_count() == actual.getChunk_count());
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will validate the dictionary data
1:cd6a4ff:    */
1:cd6a4ff:   private void compareDictionaryData(List<String> actual, List<String> expected) {
1:cd6a4ff:     assertTrue(expected.size() == actual.size());
1:cd6a4ff:     for (int i = 0; i < actual.size(); i++) {
1:cd6a4ff:       assertTrue(actual.get(i).equals(expected.get(i)));
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will read dictionary metadata file and return the dictionary meta chunks
1:cd6a4ff:    *
1:cd6a4ff:    * @return list of dictionary metadata chunks
1:cd6a4ff:    * @throws IOException read and close method throws IO excpetion
1:cd6a4ff:    */
1:cd6a4ff:   private List<CarbonDictionaryColumnMetaChunk> readDictionaryMetadataFile() throws IOException {
1:cd6a4ff:     CarbonDictionaryMetadataReaderImpl columnMetadataReaderImpl =
1:1155d4d:         new CarbonDictionaryMetadataReaderImpl(this.dictionaryColumnUniqueIdentifier);
1:cd6a4ff:     List<CarbonDictionaryColumnMetaChunk> dictionaryMetaChunkList = null;
1:cd6a4ff:     // read metadata file
1:cd6a4ff:     try {
1:cd6a4ff:       dictionaryMetaChunkList = columnMetadataReaderImpl.read();
1:cd6a4ff:     } finally {
1:cd6a4ff:       // close the metadata reader
1:cd6a4ff:       columnMetadataReaderImpl.close();
1:cd6a4ff:     }
1:cd6a4ff:     return dictionaryMetaChunkList;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * This method will be used to read the dictionary file from a given offset
1:cd6a4ff:    */
1:cd6a4ff:   private List<byte[]> readDictionaryFile(long dictionaryStartOffset, long dictionaryEndOffset)
1:cd6a4ff:       throws IOException {
1:cd6a4ff:     CarbonDictionaryReaderImpl dictionaryReader =
1:1155d4d:         new CarbonDictionaryReaderImpl(this.dictionaryColumnUniqueIdentifier);
1:cd6a4ff:     List<byte[]> dictionaryValues = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:cd6a4ff:     try {
1:cd6a4ff:       if (0 == dictionaryEndOffset) {
1:cd6a4ff:         dictionaryValues = dictionaryReader.read(dictionaryStartOffset);
1:cd6a4ff:       } else {
1:7e0584e:         Iterator<byte[]> itr = dictionaryReader.read(dictionaryStartOffset, dictionaryEndOffset);
1:7e0584e:         while (itr.hasNext()) {
1:7e0584e:           dictionaryValues.add(itr.next());
1:7e0584e:         }
1:cd6a4ff:       }
1:cd6a4ff:     } finally {
1:cd6a4ff:       dictionaryReader.close();
1:cd6a4ff:     }
1:cd6a4ff:     return dictionaryValues;
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will delete the store path
1:cd6a4ff:    */
1:cd6a4ff:   private void deleteStorePath() {
1:bf6c471:     FileFactory.FileType fileType = FileFactory.getFileType(this.tablePath);
1:bf6c471:     CarbonFile carbonFile = FileFactory.getCarbonFile(this.tablePath, fileType);
1:cd6a4ff:     deleteRecursiveSilent(carbonFile);
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will delete the folders recursively
1:cd6a4ff:    */
1:cd6a4ff:   private static void deleteRecursiveSilent(CarbonFile f) {
1:cd6a4ff:     if (f.isDirectory()) {
1:cd6a4ff:       if (f.listFiles() != null) {
1:cd6a4ff:         for (CarbonFile c : f.listFiles()) {
1:cd6a4ff:           deleteRecursiveSilent(c);
1:cd6a4ff:         }
1:cd6a4ff:       }
1:cd6a4ff:     }
1:cd6a4ff:     if (f.exists() && !f.delete()) {
1:cd6a4ff:       return;
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will read the property file for required details
1:cd6a4ff:    * like dbName, tableName, etc
1:cd6a4ff:    */
1:cd6a4ff:   private void init() {
1:cd6a4ff:     InputStream in = null;
1:cd6a4ff:     props = new Properties();
1:cd6a4ff:     try {
1:4d882df:       URL url = getClass().getClassLoader().getResource(PROPERTY_FILE_NAME);
1:4d882df:       if (null != url) {
1:4d882df:         URI uri = url.toURI();
1:4d882df:         File file = new File(uri);
1:4d882df:         in = new FileInputStream(file);
1:4d882df:         props.load(in);
1:4d882df:       }
1:cd6a4ff:     } catch (IOException e) {
1:cd6a4ff:       e.printStackTrace();
1:cd6a4ff:     } catch (URISyntaxException e) {
1:cd6a4ff:       e.printStackTrace();
1:cd6a4ff:     } finally {
1:cd6a4ff:       CarbonUtil.closeStreams(in);
1:cd6a4ff:     }
1:cd6a4ff:   }
1:cd6a4ff: 
1:cd6a4ff:   /**
1:cd6a4ff:    * this method will form the dictionary directory paths
1:cd6a4ff:    */
1:cd6a4ff:   private void initDictionaryDirPaths() throws IOException {
1:bf6c471:     String dictionaryLocation = CarbonTablePath.getMetadataPath(tablePath);
1:cd6a4ff:     FileFactory.FileType fileType = FileFactory.getFileType(dictionaryLocation);
1:cd6a4ff:     if(!FileFactory.isFileExist(dictionaryLocation, fileType)) {
1:cd6a4ff:       FileFactory.mkdirs(dictionaryLocation, fileType);
1:cd6a4ff:     }
1:bf6c471:     this.dictionaryFilePath = CarbonTablePath.getDictionaryFilePath(tablePath, columnIdentifier.getColumnId());
1:bf6c471:     this.dictionaryMetaFilePath = CarbonTablePath.getDictionaryMetaFilePath(tablePath, columnIdentifier.getColumnId());
1:cd6a4ff:   }
1:cd6a4ff: }
============================================================================
author:sraghunandan
-------------------------------------------------------------------------------
commit:f911403
/////////////////////////////////////////////////////////////////////////
1:     dataSet1 = Arrays.asList("a", "b");
1:     dataSet2 = Arrays.asList("c", "d");
1:     dataSet3 = Arrays.asList("e", "f");
author:Jacky Li
-------------------------------------------------------------------------------
commit:bf6c471
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private String tablePath;
/////////////////////////////////////////////////////////////////////////
1:     this.tablePath = props.getProperty("storePath", "carbonStore");
1:     absoluteTableIdentifier = AbsoluteTableIdentifier.from(tablePath, carbonTableIdentifier);
/////////////////////////////////////////////////////////////////////////
1:     FileFactory.FileType fileType = FileFactory.getFileType(this.tablePath);
1:     CarbonFile carbonFile = FileFactory.getCarbonFile(this.tablePath, fileType);
/////////////////////////////////////////////////////////////////////////
1:     String dictionaryLocation = CarbonTablePath.getMetadataPath(tablePath);
1:     this.dictionaryFilePath = CarbonTablePath.getDictionaryFilePath(tablePath, columnIdentifier.getColumnId());
1:     this.dictionaryMetaFilePath = CarbonTablePath.getDictionaryMetaFilePath(tablePath, columnIdentifier.getColumnId());
commit:2fe7758
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
1: import org.apache.carbondata.core.metadata.CarbonTableIdentifier;
1: import org.apache.carbondata.core.metadata.ColumnIdentifier;
0: import org.apache.carbondata.core.util.path.CarbonStorePath;
1: import org.apache.carbondata.core.util.path.CarbonTablePath;
1: import org.apache.carbondata.format.ColumnDictionaryChunkMeta;
/////////////////////////////////////////////////////////////////////////
0:     absoluteTableIdentifier = AbsoluteTableIdentifier.from(carbonStorePath, carbonTableIdentifier);
author:manishgupta88
-------------------------------------------------------------------------------
commit:29dc302
/////////////////////////////////////////////////////////////////////////
1:             columnIdentifier.getDataType());
author:mohammadshahidkhan
-------------------------------------------------------------------------------
commit:1155d4d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
/////////////////////////////////////////////////////////////////////////
1:   private AbsoluteTableIdentifier absoluteTableIdentifier;
1: 
/////////////////////////////////////////////////////////////////////////
0:     absoluteTableIdentifier = new AbsoluteTableIdentifier(carbonStorePath, carbonTableIdentifier);
1:         new DictionaryColumnUniqueIdentifier(absoluteTableIdentifier, columnIdentifier,
/////////////////////////////////////////////////////////////////////////
1:     return new CarbonDictionaryWriterImpl(dictionaryColumnUniqueIdentifier);
/////////////////////////////////////////////////////////////////////////
1:         new CarbonDictionaryMetadataReaderImpl(this.dictionaryColumnUniqueIdentifier);
/////////////////////////////////////////////////////////////////////////
1:         new CarbonDictionaryReaderImpl(this.dictionaryColumnUniqueIdentifier);
author:dhatchayani
-------------------------------------------------------------------------------
commit:d3a09e2
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.cache.dictionary.DictionaryColumnUniqueIdentifier;
/////////////////////////////////////////////////////////////////////////
1:   private DictionaryColumnUniqueIdentifier dictionaryColumnUniqueIdentifier;
1: 
/////////////////////////////////////////////////////////////////////////
1:     this.dictionaryColumnUniqueIdentifier =
0:         new DictionaryColumnUniqueIdentifier(carbonTableIdentifier, columnIdentifier,
0:             columnIdentifier.getDataType(),
0:             CarbonStorePath.getCarbonTablePath(carbonStorePath, carbonTableIdentifier));
/////////////////////////////////////////////////////////////////////////
0:         dictionaryColumnUniqueIdentifier);
/////////////////////////////////////////////////////////////////////////
0:             this.dictionaryColumnUniqueIdentifier);
/////////////////////////////////////////////////////////////////////////
0:             this.dictionaryColumnUniqueIdentifier);
author:QiangCai
-------------------------------------------------------------------------------
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:jackylk
-------------------------------------------------------------------------------
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.CarbonTableIdentifier;
0: import org.apache.carbondata.core.metadata.ColumnIdentifier;
0: import org.apache.carbondata.core.util.path.CarbonStorePath;
0: import org.apache.carbondata.core.util.path.CarbonTablePath;
1: import org.apache.carbondata.core.datastore.filesystem.CarbonFile;
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
author:vincentchenfei
-------------------------------------------------------------------------------
commit:4d882df
/////////////////////////////////////////////////////////////////////////
1: import java.net.URL;
/////////////////////////////////////////////////////////////////////////
1:       URL url = getClass().getClassLoader().getResource(PROPERTY_FILE_NAME);
1:       if (null != url) {
1:         URI uri = url.toURI();
1:         File file = new File(uri);
1:         in = new FileInputStream(file);
1:         props.load(in);
1:       }
author:manishgupt88
-------------------------------------------------------------------------------
commit:7e0584e
/////////////////////////////////////////////////////////////////////////
1: import java.util.Iterator;
/////////////////////////////////////////////////////////////////////////
1:         Iterator<byte[]> itr = dictionaryReader.read(dictionaryStartOffset, dictionaryEndOffset);
1:         while (itr.hasNext()) {
1:           dictionaryValues.add(itr.next());
1:         }
author:ravipesala
-------------------------------------------------------------------------------
commit:cd6a4ff
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
1: package org.apache.carbondata.core.writer;
1: 
1: import java.io.File;
1: import java.io.FileInputStream;
1: import java.io.IOException;
1: import java.io.InputStream;
1: import java.net.URI;
1: import java.net.URISyntaxException;
1: import java.nio.charset.Charset;
1: import java.util.ArrayList;
1: import java.util.Arrays;
1: import java.util.List;
1: import java.util.Properties;
1: import java.util.UUID;
1: 
0: import org.apache.carbondata.core.carbon.CarbonTableIdentifier;
0: import org.apache.carbondata.core.carbon.ColumnIdentifier;
0: import org.apache.carbondata.core.carbon.path.CarbonStorePath;
0: import org.apache.carbondata.core.carbon.path.CarbonTablePath;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
0: import org.apache.carbondata.core.datastorage.store.filesystem.CarbonFile;
0: import org.apache.carbondata.core.datastorage.store.impl.FileFactory;
1: import org.apache.carbondata.core.reader.CarbonDictionaryColumnMetaChunk;
1: import org.apache.carbondata.core.reader.CarbonDictionaryMetadataReaderImpl;
1: import org.apache.carbondata.core.reader.CarbonDictionaryReaderImpl;
1: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.CarbonUtil;
1: 
1: import mockit.Mock;
1: import mockit.MockUp;
0: import org.apache.carbondata.format.ColumnDictionaryChunkMeta;
1: import org.junit.After;
1: import org.junit.Before;
1: import org.junit.Test;
1: 
1: import static org.junit.Assert.assertTrue;
1: 
1: /**
1:  * This class will test the functionality writing and
1:  * reading a dictionary and its corresponding metadata file
1:  */
1: public class CarbonDictionaryWriterImplTest {
1: 
1:   private static final String PROPERTY_FILE_NAME = "carbonTest.properties";
1: 
1:   private CarbonTableIdentifier carbonTableIdentifier;
1: 
1:   private String databaseName;
1: 
1:   private String tableName;
1: 
0:   private String carbonStorePath;
1: 
1:   private ColumnIdentifier columnIdentifier;
1: 
1:   private Properties props;
1: 
1:   /**
1:    * dictionary file path
1:    */
1:   private String dictionaryFilePath;
1: 
1:   /**
1:    * dictionary metadata file path
1:    */
1:   private String dictionaryMetaFilePath;
1: 
1:   private List<String> dataSet1;
1: 
1:   private List<String> dataSet2;
1: 
1:   private List<String> dataSet3;
1: 
1:   @Before public void setUp() throws Exception {
1:     init();
1:     this.databaseName = props.getProperty("database", "testSchema");
1:     this.tableName = props.getProperty("tableName", "carbon");
0:     this.carbonStorePath = props.getProperty("storePath", "carbonStore");
1:     this.columnIdentifier = new ColumnIdentifier("Name", null, null);
1:     carbonTableIdentifier = new CarbonTableIdentifier(databaseName, tableName, UUID.randomUUID().toString());
1:     deleteStorePath();
1:     prepareDataSet();
1:   }
1: 
1:   @After public void tearDown() throws Exception {
1:     carbonTableIdentifier = null;
1:     deleteStorePath();
1:   }
1: 
1:   /**
1:    * prepare the dataset required for running test cases
1:    */
1:   private void prepareDataSet() {
0:     dataSet1 = Arrays.asList(new String[] { "a", "b" });
0:     dataSet2 = Arrays.asList(new String[] { "c", "d" });
0:     dataSet3 = Arrays.asList(new String[] { "e", "f" });
1:   }
1: 
1:   /**
1:    * test writers write functionality for a column specific
1:    * to a table in a database
1:    */
1:   @Test public void testWriteForNormalColumn() throws IOException {
1:     // second parameter is chunk count which is for the number of
1:     // thrift objects written for a segment
1:     processColumnValuesForOneChunk(1);
1:   }
1: 
1:   /**
1:    * test writers write functionality for a column shared across tables
1:    * in a database
1:    */
1:   @Test public void testWriteForSharedColumn() throws IOException {
1:     // second parameter is chunk count which is for the number of
1:     // thrift objects written for a segment
1:     processColumnValuesForOneChunk(1);
1:   }
1: 
1:   /**
1:    * test writing multiple dictionary chunks for a single segment
1:    */
1:   @Test public void testWriteMultipleChunksForOneSegment() throws IOException {
1:     deleteStorePath();
1:     CarbonProperties.getInstance()
1:         .addProperty(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE, "1");
1:     // prepare dictionary writer object
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     writeDictionaryFile(writer, dataSet1);
1:     // record file size from where data has to be read
1:     long end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:     // read metadata chunks from file
1:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:         readDictionaryMetadataFile();
1:     assertTrue(1 == carbonDictionaryColumnMetaChunks.size());
1:     // prepare retrieved chunk metadata
1:     long start_offset = 0L;
1:     CarbonDictionaryColumnMetaChunk expected =
1:         new CarbonDictionaryColumnMetaChunk(1, dataSet1.size(), start_offset, end_offset,
1:             dataSet1.size());
1:     // validate chunk metadata - actual and expected
1:     for (CarbonDictionaryColumnMetaChunk chunk : carbonDictionaryColumnMetaChunks) {
1:       validateDictionaryMetadata(chunk, expected);
1:     }
1:     //assert for chunk count
1:     List<byte[]> dictionaryValues = readDictionaryFile(0L, 0L);
1:     // prepare expected dictionary chunk list
1:     List<String> actual = convertByteArrayListToStringValueList(dictionaryValues);
1:     assertTrue(dataSet1.size() == actual.size());
1:     // validate the dictionary data
1:     compareDictionaryData(actual, dataSet1);
1:     CarbonProperties.getInstance().addProperty(CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE,
1:         CarbonCommonConstants.DICTIONARY_ONE_CHUNK_SIZE_DEFAULT);
1:   }
1: 
1:   /**
1:    * prepare the dictionary writer object
1:    */
1:   private CarbonDictionaryWriterImpl prepareWriter() throws IOException {
1:     initDictionaryDirPaths();
0:     return new CarbonDictionaryWriterImpl(this.carbonStorePath, carbonTableIdentifier,
0:         columnIdentifier);
1:   }
1: 
1:   /**
1:    * this method will test the write method in case of any exception
1:    */
1:   @Test public void testWriteThrowException() throws IOException {
1:     final String failureMessage = "write operation failed";
1:     // mock write method of writer and throw exception
1:     new MockUp<CarbonDictionaryWriterImpl>() {
1:       @Mock public void write(String value) throws IOException {
1:         throw new IOException(failureMessage);
1:       }
1:     };
1:     // prepare the writer
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     try {
1:       for (String value : dataSet1) {
1:         // exception should be thrown when write method is called
1:         writer.write(value);
1:       }
1:     } catch (IOException e) {
1:       assertTrue(failureMessage.equals(e.getMessage()));
1:     } finally {
1:       writer.close();
1:     }
1:   }
1: 
1:   /**
1:    * This method will test the truncate functionality
1:    */
1:   @Test public void testTruncateOperation() throws IOException {
1:     // delete store path
1:     deleteStorePath();
1:     // prepare first dictionary chunk
1:     // prepare dictionary writer object
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     writeDictionaryFile(writer, dataSet1);
1:     long endOffsetAfterFirstDictionaryChunk = CarbonUtil.getFileSize(dictionaryFilePath);
1:     // maintain the offset till end offset of first chunk
1:     writer = prepareWriter();
1:     writeDictionaryFile(writer, dataSet2);
1:     // prepare first column meta chunk object
1:     ColumnDictionaryChunkMeta firstDictionaryChunkMeta =
1:         new ColumnDictionaryChunkMeta(1, 2, 0, endOffsetAfterFirstDictionaryChunk, 1);
1:     // overwrite the dictionary meta chunk file to test the truncate operation
1:     overwriteDictionaryMetaFile(firstDictionaryChunkMeta, dictionaryMetaFilePath);
1:     writer = prepareWriter();
1:     // in the next step truncate operation will be tested while writing dictionary file
1:     writeDictionaryFile(writer, dataSet3);
1:     // read dictionary file
1:     List<byte[]> dictionaryValues = readDictionaryFile(0L, 0L);
1:     List<String> actual = convertByteArrayListToStringValueList(dictionaryValues);
1:     List<String> expected = new ArrayList<>(4);
1:     expected.addAll(dataSet1);
1:     expected.addAll(dataSet3);
1:     // validate the data retrieved and it should match dataset1
1:     compareDictionaryData(actual, expected);
1:   }
1: 
1:   /**
1:    * This method will overwrite a given file with data provided
1:    */
1:   private void overwriteDictionaryMetaFile(ColumnDictionaryChunkMeta firstDictionaryChunkMeta,
1:       String dictionaryFile) throws IOException {
1:     ThriftWriter thriftMetaChunkWriter = new ThriftWriter(dictionaryFile, false);
1:     try {
1:       thriftMetaChunkWriter.open();
1:       thriftMetaChunkWriter.write(firstDictionaryChunkMeta);
1:     } catch (IOException e) {
1: 
1:     } finally {
1:       thriftMetaChunkWriter.close();
1:     }
1: 
1:   }
1: 
1:   /**
1:    * this method will test the reading of dictionary file from a given offset
1:    */
1:   @Test public void testReadingOfDictionaryChunkFromAnOffset() throws Exception {
1:     // delete store path
1:     deleteStorePath();
1:     // prepare the writer to write dataset1
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     // write dataset1 data
1:     writeDictionaryFile(writer, dataSet1);
1:     // prepare the writer to write dataset2
1:     writer = prepareWriter();
1:     // write dataset2
1:     writeDictionaryFile(writer, dataSet2);
1:     // record the offset from where data has to be read
1:     long dictionaryFileOffsetToRead = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:     // prepare writer to write dataset3
1:     writer = prepareWriter();
1:     // write dataset 3
1:     writeDictionaryFile(writer, dataSet3);
1:     // read dictionary chunk from dictionary file
1:     List<byte[]> dictionaryData = readDictionaryFile(dictionaryFileOffsetToRead, 0L);
1:     // prepare the retrieved data
1:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:     // compare dictionary data set
1:     compareDictionaryData(actual, dataSet3);
1:     // read chunk metadata file
1:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:         readDictionaryMetadataFile();
1:     // assert for metadata chunk size
1:     assertTrue(3 == carbonDictionaryColumnMetaChunks.size());
1:   }
1: 
1:   /**
1:    * this method will test the reading of dictionary file between start and end offset
1:    */
1:   @Test public void testReadingOfDictionaryChunkBetweenStartAndEndOffset() throws Exception {
1:     // delete store path
1:     deleteStorePath();
1:     // prepare the writer to write dataset1
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     // write dataset1 data
1:     writeDictionaryFile(writer, dataSet1);
1:     // record dictionary file start offset
1:     long dictionaryStartOffset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:     // prepare the writer to write dataset2
1:     writer = prepareWriter();
1:     // write dataset2
1:     writeDictionaryFile(writer, dataSet2);
1:     // record the end offset for dictionary file
1:     long dictionaryFileEndOffset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:     // prepare writer to write dataset3
1:     writer = prepareWriter();
1:     // write dataset 3
1:     writeDictionaryFile(writer, dataSet3);
1:     // read dictionary chunk from dictionary file
1:     List<byte[]> dictionaryData =
1:         readDictionaryFile(dictionaryStartOffset, dictionaryFileEndOffset);
1:     // prepare the retrieved data
1:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:     // compare dictionary data set
1:     compareDictionaryData(actual, dataSet2);
1:     // read chunk metadata file
1:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:         readDictionaryMetadataFile();
1:     // assert for metadata chunk size
1:     assertTrue(3 == carbonDictionaryColumnMetaChunks.size());
1:     CarbonDictionaryColumnMetaChunk expected =
1:         new CarbonDictionaryColumnMetaChunk(3, 4, dictionaryStartOffset, dictionaryFileEndOffset,
1:             1);
1:     validateDictionaryMetadata(carbonDictionaryColumnMetaChunks.get(1), expected);
1:   }
1: 
1:   /**
1:    * This method will convert list of byte array to list of string
1:    */
1:   private List<String> convertByteArrayListToStringValueList(List<byte[]> dictionaryByteArrayList) {
1:     List<String> valueList = new ArrayList<>(dictionaryByteArrayList.size());
1:     for (byte[] value : dictionaryByteArrayList) {
1:       valueList.add(new String(value, Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET)));
1:     }
1:     return valueList;
1:   }
1: 
1:   /**
1:    * this method will write the data into a file
1:    */
1:   private void writeDictionaryFile(CarbonDictionaryWriterImpl writer, List<String> list)
1:       throws IOException {
1:     try {
1:       for (String value : list) {
1:         writer.write(value);
1:       }
1:     } finally {
1:       writer.close();
1:       writer.commit();
1:     }
1:   }
1: 
1:   /**
1:    * this method will test the functionality of writing and reading one dictionary chunk
1:    */
1:   private void processColumnValuesForOneChunk(int chunkCountForSegment) throws IOException {
1:     // delete store path
1:     deleteStorePath();
1:     // prepare writer
1:     CarbonDictionaryWriterImpl writer = prepareWriter();
1:     // write the data into file
1:     // test write api for passing list of byte array
1:     writer.write(convertStringListToByteArray(dataSet1));
1:     // close the writer
1:     writer.close();
1:     //write metadata
1:     writer.commit();
1:     // record end offset of file
1:     long end_offset = CarbonUtil.getFileSize(this.dictionaryFilePath);
1:     // read dictionary chunk from dictionary file
1:     List<byte[]> dictionaryData = readDictionaryFile(0L, 0L);
1:     // prepare the retrieved data
1:     List<String> actual = convertByteArrayListToStringValueList(dictionaryData);
1:     // compare the expected and actual data
1:     compareDictionaryData(actual, dataSet1);
1:     // read dictionary metadata chunks
1:     List<CarbonDictionaryColumnMetaChunk> carbonDictionaryColumnMetaChunks =
1:         readDictionaryMetadataFile();
1:     // assert
1:     assertTrue(1 == carbonDictionaryColumnMetaChunks.size());
1:     long start_offset = 0L;
1:     // validate actual chunk metadata with expected
1:     CarbonDictionaryColumnMetaChunk expected =
1:         new CarbonDictionaryColumnMetaChunk(1, 2, start_offset, end_offset, 1);
1:     for (CarbonDictionaryColumnMetaChunk chunk : carbonDictionaryColumnMetaChunks) {
1:       validateDictionaryMetadata(chunk, expected);
1:     }
1:   }
1: 
1:   /**
1:    * this method will convert list of string to list of byte array
1:    */
1:   private List<byte[]> convertStringListToByteArray(List<String> valueList) {
1:     List<byte[]> byteArrayList = new ArrayList<>(valueList.size());
1:     for (String value : valueList) {
1:       byteArrayList.add(value.getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET)));
1:     }
1:     return byteArrayList;
1:   }
1: 
1:   /**
1:    * this method will validate the dictionary chunk metadata
1:    */
1:   private void validateDictionaryMetadata(CarbonDictionaryColumnMetaChunk actual,
1:       CarbonDictionaryColumnMetaChunk expected) {
1:     assertTrue(expected.getMin_surrogate_key() == actual.getMin_surrogate_key());
1:     assertTrue(expected.getMax_surrogate_key() == actual.getMax_surrogate_key());
1:     assertTrue(expected.getStart_offset() == actual.getStart_offset());
1:     assertTrue(expected.getEnd_offset() == actual.getEnd_offset());
1:     assertTrue(expected.getChunk_count() == actual.getChunk_count());
1:   }
1: 
1:   /**
1:    * this method will validate the dictionary data
1:    */
1:   private void compareDictionaryData(List<String> actual, List<String> expected) {
1:     assertTrue(expected.size() == actual.size());
1:     for (int i = 0; i < actual.size(); i++) {
1:       assertTrue(actual.get(i).equals(expected.get(i)));
1:     }
1:   }
1: 
1:   /**
1:    * This method will read dictionary metadata file and return the dictionary meta chunks
1:    *
1:    * @return list of dictionary metadata chunks
1:    * @throws IOException read and close method throws IO excpetion
1:    */
1:   private List<CarbonDictionaryColumnMetaChunk> readDictionaryMetadataFile() throws IOException {
1:     CarbonDictionaryMetadataReaderImpl columnMetadataReaderImpl =
0:         new CarbonDictionaryMetadataReaderImpl(this.carbonStorePath, this.carbonTableIdentifier,
0:             this.columnIdentifier);
1:     List<CarbonDictionaryColumnMetaChunk> dictionaryMetaChunkList = null;
1:     // read metadata file
1:     try {
1:       dictionaryMetaChunkList = columnMetadataReaderImpl.read();
1:     } finally {
1:       // close the metadata reader
1:       columnMetadataReaderImpl.close();
1:     }
1:     return dictionaryMetaChunkList;
1:   }
1: 
1:   /**
1:    * This method will be used to read the dictionary file from a given offset
1:    */
1:   private List<byte[]> readDictionaryFile(long dictionaryStartOffset, long dictionaryEndOffset)
1:       throws IOException {
1:     CarbonDictionaryReaderImpl dictionaryReader =
0:         new CarbonDictionaryReaderImpl(this.carbonStorePath, this.carbonTableIdentifier,
0:             this.columnIdentifier);
1:     List<byte[]> dictionaryValues = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:     try {
1:       if (0 == dictionaryEndOffset) {
1:         dictionaryValues = dictionaryReader.read(dictionaryStartOffset);
1:       } else {
0:         dictionaryValues = dictionaryReader.read(dictionaryStartOffset, dictionaryEndOffset);
1:       }
1:     } finally {
1:       dictionaryReader.close();
1:     }
1:     return dictionaryValues;
1:   }
1: 
1:   /**
1:    * this method will delete the store path
1:    */
1:   private void deleteStorePath() {
0:     FileFactory.FileType fileType = FileFactory.getFileType(this.carbonStorePath);
0:     CarbonFile carbonFile = FileFactory.getCarbonFile(this.carbonStorePath, fileType);
1:     deleteRecursiveSilent(carbonFile);
1:   }
1: 
1:   /**
1:    * this method will delete the folders recursively
1:    */
1:   private static void deleteRecursiveSilent(CarbonFile f) {
1:     if (f.isDirectory()) {
1:       if (f.listFiles() != null) {
1:         for (CarbonFile c : f.listFiles()) {
1:           deleteRecursiveSilent(c);
1:         }
1:       }
1:     }
1:     if (f.exists() && !f.delete()) {
1:       return;
1:     }
1:   }
1: 
1:   /**
1:    * this method will read the property file for required details
1:    * like dbName, tableName, etc
1:    */
1:   private void init() {
1:     InputStream in = null;
1:     props = new Properties();
1:     try {
0:       URI uri = getClass().getClassLoader().getResource(PROPERTY_FILE_NAME).toURI();
0:       File file = new File(uri);
0:       in = new FileInputStream(file);
0:       props.load(in);
1:     } catch (IOException e) {
1:       e.printStackTrace();
1:     } catch (URISyntaxException e) {
1:       e.printStackTrace();
1:     } finally {
1:       CarbonUtil.closeStreams(in);
1:     }
1:   }
1: 
1:   /**
1:    * this method will form the dictionary directory paths
1:    */
1:   private void initDictionaryDirPaths() throws IOException {
0:     CarbonTablePath carbonTablePath =
0:         CarbonStorePath.getCarbonTablePath(this.carbonStorePath, carbonTableIdentifier);
0:     String dictionaryLocation = carbonTablePath.getMetadataDirectoryPath();
1:     FileFactory.FileType fileType = FileFactory.getFileType(dictionaryLocation);
1:     if(!FileFactory.isFileExist(dictionaryLocation, fileType)) {
1:       FileFactory.mkdirs(dictionaryLocation, fileType);
1:     }
0:     this.dictionaryFilePath = carbonTablePath.getDictionaryFilePath(columnIdentifier.getColumnId());
0:     this.dictionaryMetaFilePath = carbonTablePath.getDictionaryMetaFilePath(columnIdentifier.getColumnId());
1:   }
1: }
============================================================================
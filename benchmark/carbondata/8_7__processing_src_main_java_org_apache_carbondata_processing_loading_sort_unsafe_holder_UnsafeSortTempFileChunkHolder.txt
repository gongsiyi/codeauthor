1:f1f9348: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
2:f1f9348:  *
1:f1f9348:  *    http://www.apache.org/licenses/LICENSE-2.0
1:f1f9348:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
8:f1f9348:  */
1:8d8b589: 
1:349c59c: package org.apache.carbondata.processing.loading.sort.unsafe.holder;
1:8d8b589: 
1:f1f9348: import java.io.DataInputStream;
1:f1f9348: import java.io.File;
1:f1f9348: import java.io.FileNotFoundException;
1:f1f9348: import java.io.IOException;
1:f1f9348: import java.util.Comparator;
1:f1f9348: import java.util.concurrent.Callable;
1:f1f9348: import java.util.concurrent.ExecutorService;
1:f1f9348: import java.util.concurrent.Executors;
1:f1f9348: import java.util.concurrent.Future;
31:f1f9348: 
1:f1f9348: import org.apache.carbondata.common.logging.LogService;
1:f1f9348: import org.apache.carbondata.common.logging.LogServiceFactory;
1:f1f9348: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:c100251: import org.apache.carbondata.core.datastore.impl.FileFactory;
1:f1f9348: import org.apache.carbondata.core.util.CarbonProperties;
1:f1f9348: import org.apache.carbondata.core.util.CarbonUtil;
1:2b41f14: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1:2b41f14: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1:349c59c: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
1:2b41f14: import org.apache.carbondata.processing.sort.sortdata.IntermediateSortTempRowComparator;
1:349c59c: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
1:2b41f14: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
1:f1f9348: 
1:f1f9348: public class UnsafeSortTempFileChunkHolder implements SortTempChunkHolder {
1:f1f9348: 
8:f1f9348:   /**
1:f1f9348:    * LOGGER
1:f1f9348:    */
1:f1f9348:   private static final LogService LOGGER =
1:f1f9348:       LogServiceFactory.getLogService(UnsafeSortTempFileChunkHolder.class.getName());
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * temp file
1:f1f9348:    */
1:f1f9348:   private File tempFile;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * read stream
1:f1f9348:    */
1:f1f9348:   private DataInputStream stream;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * entry count
1:f1f9348:    */
1:f1f9348:   private int entryCount;
1:f1f9348:   /**
1:f1f9348:    * return row
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow returnRow;
1:c100251:   private int readBufferSize;
1:c100251:   private String compressorName;
1:2b41f14:   private IntermediateSortTempRow[] currentBuffer;
1:f1f9348: 
1:2b41f14:   private IntermediateSortTempRow[] backupBuffer;
1:f1f9348: 
1:f1f9348:   private boolean isBackupFilled;
1:f1f9348: 
1:f1f9348:   private boolean prefetch;
1:f1f9348: 
1:f1f9348:   private int bufferSize;
1:f1f9348: 
1:f1f9348:   private int bufferRowCounter;
1:f1f9348: 
1:f1f9348:   private ExecutorService executorService;
1:f1f9348: 
1:f1f9348:   private Future<Void> submit;
1:f1f9348: 
1:f1f9348:   private int prefetchRecordsProceesed;
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * totalRecordFetch
1:f1f9348:    */
1:f1f9348:   private int totalRecordFetch;
1:f1f9348: 
1:f1f9348:   private int numberOfObjectRead;
1:8d8b589: 
1:2b41f14:   private TableFieldStat tableFieldStat;
1:2b41f14:   private SortStepRowHandler sortStepRowHandler;
1:2b41f14:   private Comparator<IntermediateSortTempRow> comparator;
1:f27efb3:   private boolean convertNoSortFields;
1:f1f9348:   /**
1:f1f9348:    * Constructor to initialize
1:f1f9348:    */
1:f27efb3:   public UnsafeSortTempFileChunkHolder(File tempFile, SortParameters parameters,
1:f27efb3:       boolean convertNoSortFields) {
1:f1f9348:     // set temp file
1:f1f9348:     this.tempFile = tempFile;
1:c100251:     this.readBufferSize = parameters.getBufferSize();
1:c100251:     this.compressorName = parameters.getSortTempCompressorName();
1:2b41f14:     this.tableFieldStat = new TableFieldStat(parameters);
1:2b41f14:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:c100251:     this.executorService = Executors.newFixedThreadPool(1);
1:2b41f14:     comparator = new IntermediateSortTempRowComparator(parameters.getNoDictionarySortColumn());
1:f27efb3:     this.convertNoSortFields = convertNoSortFields;
1:f1f9348:     initialize();
25:f1f9348:   }
1:8d8b589: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to initialize
1:21704cf:    *
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException problem while initializing
1:f1f9348:    */
1:f1f9348:   public void initialize() {
1:f1f9348:     prefetch = Boolean.parseBoolean(CarbonProperties.getInstance()
1:f1f9348:         .getProperty(CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH,
1:f1f9348:             CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH_DEFAULT));
1:c5aba5f:     bufferSize = Integer.parseInt(CarbonProperties.getInstance()
1:c5aba5f:         .getProperty(CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE,
1:c5aba5f:             CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE_DEFAULT));
1:f1f9348:     initialise();
1:f1f9348:   }
1:c100251: 
1:f1f9348:   private void initialise() {
1:8d8b589:     try {
1:c100251:       stream = FileFactory.getDataInputStream(tempFile.getPath(), FileFactory.FileType.LOCAL,
1:c100251:           readBufferSize, compressorName);
1:f1f9348:       this.entryCount = stream.readInt();
1:873c3de:       LOGGER.info("Processing unsafe mode file rows with size : " + entryCount);
1:f1f9348:       if (prefetch) {
3:f1f9348:         new DataFetcher(false).call();
1:f1f9348:         totalRecordFetch += currentBuffer.length;
1:f1f9348:         if (totalRecordFetch < this.entryCount) {
1:f1f9348:           submit = executorService.submit(new DataFetcher(true));
1:8d8b589:         }
1:8d8b589:       }
1:f1f9348:     } catch (FileNotFoundException e) {
2:f1f9348:       LOGGER.error(e);
1:f1f9348:       throw new RuntimeException(tempFile + " No Found", e);
1:8d8b589:     } catch (IOException e) {
1:f1f9348:       LOGGER.error(e);
1:f1f9348:       throw new RuntimeException(tempFile + " No Found", e);
3:f1f9348:     } catch (Exception e) {
1:f1f9348:       LOGGER.error(e);
1:f1f9348:       throw new RuntimeException(tempFile + " Problem while reading", e);
1:8d8b589:     }
1:8d8b589:   }
1:8d8b589: 
1:f1f9348:   /**
1:f1f9348:    * This method will be used to read new row from file
1:f1f9348:    *
1:f1f9348:    * @throws CarbonSortKeyAndGroupByException problem while reading
1:f1f9348:    */
1:2b41f14:   @Override
1:f1f9348:   public void readRow() throws CarbonSortKeyAndGroupByException {
1:f1f9348:     if (prefetch) {
1:f1f9348:       fillDataForPrefetch();
1:956833e:     } else {
1:2b41f14:       try {
1:f27efb3:         if (convertNoSortFields) {
1:f27efb3:           this.returnRow = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:f27efb3:         } else {
1:f27efb3:           this.returnRow = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:f27efb3:         }
1:2b41f14:         this.numberOfObjectRead++;
1:2b41f14:       } catch (IOException e) {
1:2b41f14:         throw new CarbonSortKeyAndGroupByException("Problems while reading row", e);
1:2b41f14:       }
1:8d8b589:     }
1:8d8b589:   }
1:8d8b589: 
1:f1f9348:   private void fillDataForPrefetch() {
2:f1f9348:     if (bufferRowCounter >= bufferSize) {
1:f1f9348:       if (isBackupFilled) {
2:f1f9348:         bufferRowCounter = 0;
1:f1f9348:         currentBuffer = backupBuffer;
1:f1f9348:         totalRecordFetch += currentBuffer.length;
1:f1f9348:         isBackupFilled = false;
1:f1f9348:         if (totalRecordFetch < this.entryCount) {
1:f1f9348:           submit = executorService.submit(new DataFetcher(true));
1:8d8b589:         }
1:8d8b589:       } else {
1:21704cf:         try {
1:f1f9348:           submit.get();
1:f1f9348:         } catch (Exception e) {
1:f1f9348:           LOGGER.error(e);
1:21704cf:         }
1:f1f9348:         bufferRowCounter = 0;
1:f1f9348:         currentBuffer = backupBuffer;
1:f1f9348:         isBackupFilled = false;
1:f1f9348:         totalRecordFetch += currentBuffer.length;
1:f1f9348:         if (totalRecordFetch < this.entryCount) {
1:f1f9348:           submit = executorService.submit(new DataFetcher(true));
1:f1f9348:         }
1:f1f9348:       }
1:f1f9348:     }
2:f1f9348:     prefetchRecordsProceesed++;
2:f1f9348:     returnRow = currentBuffer[bufferRowCounter++];
1:f1f9348:   }
1:8d8b589: 
1:f1f9348:   /**
1:2b41f14:    * get a batch of row, this interface is used in reading compressed sort temp files
1:2b41f14:    *
1:2b41f14:    * @param expected expected number in a batch
1:2b41f14:    * @return a batch of row
1:2b41f14:    * @throws IOException if error occurs while reading from stream
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected)
1:2b41f14:       throws IOException {
1:2b41f14:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
1:2b41f14:     for (int i = 0; i < expected; i++) {
1:f27efb3:       if (convertNoSortFields) {
1:f27efb3:         holders[i] = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:f27efb3:       } else {
1:f27efb3:         holders[i] = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:f27efb3:       }
1:f1f9348:     }
1:2b41f14:     this.numberOfObjectRead += expected;
1:2b41f14:     return holders;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * below method will be used to get the row
1:f1f9348:    *
1:f1f9348:    * @return row
1:f1f9348:    */
1:2b41f14:   public IntermediateSortTempRow getRow() {
1:f1f9348:     return this.returnRow;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * below method will be used to check whether any more records are present
1:f1f9348:    * in file or not
1:f1f9348:    *
1:f1f9348:    * @return more row present in file
1:f1f9348:    */
1:f1f9348:   public boolean hasNext() {
1:c100251:     if (prefetch) {
1:f1f9348:       return this.prefetchRecordsProceesed < this.entryCount;
1:f1f9348:     }
1:f1f9348:     return this.numberOfObjectRead < this.entryCount;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * Below method will be used to close streams
1:f1f9348:    */
1:f1f9348:   public void close() {
1:f1f9348:     CarbonUtil.closeStreams(stream);
1:a734add:     if (null != executorService && !executorService.isShutdown()) {
1:a734add:       executorService.shutdownNow();
1:a734add:     }
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will number of entries
1:f1f9348:    *
1:f1f9348:    * @return entryCount
1:f1f9348:    */
1:f1f9348:   public int numberOfRows() {
1:f1f9348:     return entryCount;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   @Override public int compareTo(SortTempChunkHolder other) {
1:f1f9348:     return comparator.compare(returnRow, other.getRow());
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   @Override public boolean equals(Object obj) {
1:06b0d08:     if (this == obj) {
1:06b0d08:       return true;
1:06b0d08:     }
1:06b0d08: 
1:f1f9348:     if (!(obj instanceof UnsafeSortTempFileChunkHolder)) {
1:f1f9348:       return false;
1:f1f9348:     }
1:f1f9348:     UnsafeSortTempFileChunkHolder o = (UnsafeSortTempFileChunkHolder) obj;
1:f1f9348: 
1:06b0d08:     return this == o;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   @Override public int hashCode() {
1:f1f9348:     int hash = 0;
1:2b41f14:     hash += tableFieldStat.hashCode();
1:f1f9348:     hash += tempFile.hashCode();
1:f1f9348:     return hash;
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   private final class DataFetcher implements Callable<Void> {
1:f1f9348:     private boolean isBackUpFilling;
1:f1f9348: 
1:f1f9348:     private int numberOfRecords;
1:f1f9348: 
1:f1f9348:     private DataFetcher(boolean backUp) {
1:f1f9348:       isBackUpFilling = backUp;
1:f1f9348:       calculateNumberOfRecordsToBeFetched();
1:f1f9348:     }
1:f1f9348: 
1:f1f9348:     private void calculateNumberOfRecordsToBeFetched() {
1:f1f9348:       int numberOfRecordsLeftToBeRead = entryCount - totalRecordFetch;
1:f1f9348:       numberOfRecords =
1:f1f9348:           bufferSize < numberOfRecordsLeftToBeRead ? bufferSize : numberOfRecordsLeftToBeRead;
1:f1f9348:     }
1:f1f9348: 
1:f1f9348:     @Override public Void call() throws Exception {
6:f1f9348:       try {
1:f1f9348:         if (isBackUpFilling) {
1:f1f9348:           backupBuffer = prefetchRecordsFromFile(numberOfRecords);
1:f1f9348:           isBackupFilled = true;
1:8d8b589:         } else {
1:f1f9348:           currentBuffer = prefetchRecordsFromFile(numberOfRecords);
1:f1f9348:         }
1:f1f9348:       } catch (Exception e) {
1:f1f9348:         LOGGER.error(e);
1:f1f9348:       }
1:f1f9348:       return null;
1:f1f9348:     }
1:f1f9348: 
1:f1f9348:   }
1:f1f9348: 
1:f1f9348:   /**
1:f1f9348:    * This method will read the records from sort temp file and keep it in a buffer
1:f1f9348:    *
1:2b41f14:    * @param numberOfRecords number of records to be read
1:2b41f14:    * @return batch of intermediate sort temp row
1:2b41f14:    * @throws IOException if error occurs reading records from file
1:f1f9348:    */
1:2b41f14:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
1:2b41f14:       throws IOException {
1:2b41f14:     return readBatchedRowFromStream(numberOfRecords);
1:8d8b589:   }
1:f1f9348: }
============================================================================
author:kumarvishal09
-------------------------------------------------------------------------------
commit:f27efb3
/////////////////////////////////////////////////////////////////////////
1:   private boolean convertNoSortFields;
1:   public UnsafeSortTempFileChunkHolder(File tempFile, SortParameters parameters,
1:       boolean convertNoSortFields) {
/////////////////////////////////////////////////////////////////////////
1:     this.convertNoSortFields = convertNoSortFields;
/////////////////////////////////////////////////////////////////////////
1:         if (convertNoSortFields) {
1:           this.returnRow = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:         } else {
1:           this.returnRow = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:         }
/////////////////////////////////////////////////////////////////////////
1:       if (convertNoSortFields) {
1:         holders[i] = sortStepRowHandler.readWithNoSortFieldConvert(stream);
1:       } else {
1:         holders[i] = sortStepRowHandler.readWithoutNoSortFieldConvert(stream);
1:       }
author:Jacky Li
-------------------------------------------------------------------------------
commit:873c3de
/////////////////////////////////////////////////////////////////////////
1:       LOGGER.info("Processing unsafe mode file rows with size : " + entryCount);
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
0:           } else if (DataTypes.isDecimal(dataType)) {
commit:956833e
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:           DataType dataType = measureDataType[mesCount];
0:           if (dataType == DataTypes.SHORT) {
0:             row[dimensionCount + mesCount] = stream.readShort();
0:           } else if (dataType == DataTypes.INT) {
0:             row[dimensionCount + mesCount] = stream.readInt();
0:           } else if (dataType == DataTypes.LONG) {
0:             row[dimensionCount + mesCount] = stream.readLong();
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             row[dimensionCount + mesCount] = stream.readDouble();
0:           } else if (dataType == DataTypes.DECIMAL) {
0:             short aShort = stream.readShort();
0:             byte[] bigDecimalInBytes = new byte[aShort];
0:             stream.readFully(bigDecimalInBytes);
0:             row[dimensionCount + mesCount] = DataTypeUtil.byteToBigDecimal(bigDecimalInBytes);
1:           } else {
0:             throw new IllegalArgumentException(
0:                 "unsupported data type:" + measureDataType[mesCount]);
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.loading.sort.unsafe.holder;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
1: import org.apache.carbondata.processing.sort.exception.CarbonSortKeyAndGroupByException;
0: import org.apache.carbondata.processing.sort.sortdata.NewRowComparator;
1: import org.apache.carbondata.processing.sort.sortdata.SortParameters;
author:xuchuanyin
-------------------------------------------------------------------------------
commit:2b41f14
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
1: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
1: import org.apache.carbondata.processing.sort.sortdata.IntermediateSortTempRowComparator;
1: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
/////////////////////////////////////////////////////////////////////////
1:   private IntermediateSortTempRow returnRow;
1:   private IntermediateSortTempRow[] currentBuffer;
1:   private IntermediateSortTempRow[] backupBuffer;
/////////////////////////////////////////////////////////////////////////
1:   private TableFieldStat tableFieldStat;
1:   private SortStepRowHandler sortStepRowHandler;
1:   private Comparator<IntermediateSortTempRow> comparator;
1:     this.tableFieldStat = new TableFieldStat(parameters);
1:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
1:     comparator = new IntermediateSortTempRowComparator(parameters.getNoDictionarySortColumn());
/////////////////////////////////////////////////////////////////////////
1:   @Override
1:       try {
0:         this.returnRow = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
1:         this.numberOfObjectRead++;
1:       } catch (IOException e) {
1:         throw new CarbonSortKeyAndGroupByException("Problems while reading row", e);
1:       }
/////////////////////////////////////////////////////////////////////////
1:    * get a batch of row, this interface is used in reading compressed sort temp files
1:    *
1:    * @param expected expected number in a batch
1:    * @return a batch of row
1:    * @throws IOException if error occurs while reading from stream
1:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected)
1:       throws IOException {
1:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
1:     for (int i = 0; i < expected; i++) {
0:       IntermediateSortTempRow holder
0:           = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:       holders[i] = holder;
1:     this.numberOfObjectRead += expected;
1:     return holders;
/////////////////////////////////////////////////////////////////////////
1:   public IntermediateSortTempRow getRow() {
/////////////////////////////////////////////////////////////////////////
1:     hash += tableFieldStat.hashCode();
/////////////////////////////////////////////////////////////////////////
1:    * @param numberOfRecords number of records to be read
1:    * @return batch of intermediate sort temp row
1:    * @throws IOException if error occurs reading records from file
1:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
1:       throws IOException {
1:     return readBatchedRowFromStream(numberOfRecords);
commit:8d8b589
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
0: import org.apache.carbondata.core.metadata.datatype.DataTypes;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.loading.sort.unsafe.UnsafeCarbonRowPage;
0: import org.apache.carbondata.processing.sort.sortdata.NewRowComparator;
/////////////////////////////////////////////////////////////////////////
1: 
0:   private Object[] returnRow;
0:   private int dimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
0:   private Object[][] currentBuffer;
0:   private Object[][] backupBuffer;
/////////////////////////////////////////////////////////////////////////
0:   private int nullSetWordsLength;
1: 
0:   private Comparator<Object[]> comparator;
1: 
0:     this.dimCnt = parameters.getDimColCount();
0:     this.complexCnt = parameters.getComplexDimColCount();
0:     this.measureCnt = parameters.getMeasureColCount();
0:     this.isNoDictionaryDimensionColumn = parameters.getNoDictionaryDimnesionColumn();
0:     this.measureDataTypes = parameters.getMeasureDataType();
1: 
0:     this.nullSetWordsLength = ((parameters.getMeasureColCount() - 1) >> 6) + 1;
0:     comparator = new NewRowComparator(parameters.getNoDictionarySortColumn());
/////////////////////////////////////////////////////////////////////////
0:       this.returnRow = getRowFromStream();
/////////////////////////////////////////////////////////////////////////
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
0:   private Object[] getRowFromStream() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = new Object[dimCnt + measureCnt];
1:     try {
0:       int dimCount = 0;
0:       for (; dimCount < isNoDictionaryDimensionColumn.length; dimCount++) {
0:         if (isNoDictionaryDimensionColumn[dimCount]) {
0:           short aShort = stream.readShort();
0:           byte[] col = new byte[aShort];
0:           stream.readFully(col);
0:           row[dimCount] = col;
1:         } else {
0:           int anInt = stream.readInt();
0:           row[dimCount] = anInt;
1:         }
1:       }
1: 
0:       // write complex dimensions here.
0:       for (; dimCount < dimCnt; dimCount++) {
0:         short aShort = stream.readShort();
0:         byte[] col = new byte[aShort];
0:         stream.readFully(col);
0:         row[dimCount] = col;
1:       }
1: 
0:       long[] words = new long[nullSetWordsLength];
0:       for (int i = 0; i < words.length; i++) {
0:         words[i] = stream.readLong();
1:       }
1: 
0:       for (int mesCount = 0; mesCount < measureCnt; mesCount++) {
0:         if (UnsafeCarbonRowPage.isSet(words, mesCount)) {
0:           DataType dataType = measureDataTypes[mesCount];
0:           if (dataType == DataTypes.SHORT) {
0:             row[dimCount + mesCount] = stream.readShort();
0:           } else if (dataType == DataTypes.INT) {
0:             row[dimCount + mesCount] = stream.readInt();
0:           } else if (dataType == DataTypes.LONG) {
0:             row[dimCount + mesCount] = stream.readLong();
0:           } else if (dataType == DataTypes.DOUBLE) {
0:             row[dimCount + mesCount] = stream.readDouble();
0:           } else if (DataTypes.isDecimal(dataType)) {
0:             short aShort = stream.readShort();
0:             byte[] bigDecimalInBytes = new byte[aShort];
0:             stream.readFully(bigDecimalInBytes);
0:             row[dimCount + mesCount] = DataTypeUtil.byteToBigDecimal(bigDecimalInBytes);
1:           } else {
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
1:           }
1:         }
1:       }
0:       return row;
1:     } catch (IOException e) {
0:       throw new CarbonSortKeyAndGroupByException(e);
/////////////////////////////////////////////////////////////////////////
0:   public Object[] getRow() {
/////////////////////////////////////////////////////////////////////////
0:     hash += 31 * measureCnt;
0:     hash += 31 * dimCnt;
0:     hash += 31 * complexCnt;
/////////////////////////////////////////////////////////////////////////
0:    * @param numberOfRecords
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
0:   private Object[][] prefetchRecordsFromFile(int numberOfRecords)
0:       throws CarbonSortKeyAndGroupByException {
0:     Object[][] records = new Object[numberOfRecords][];
0:     for (int i = 0; i < numberOfRecords; i++) {
0:       records[i] = getRowFromStream();
1:     }
0:     return records;
commit:21704cf
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.processing.loading.row.IntermediateSortTempRow;
0: import org.apache.carbondata.processing.loading.sort.SortStepRowHandler;
0: import org.apache.carbondata.processing.sort.sortdata.IntermediateSortTempRowComparator;
0: import org.apache.carbondata.processing.sort.sortdata.TableFieldStat;
/////////////////////////////////////////////////////////////////////////
0:   private IntermediateSortTempRow returnRow;
0:   private IntermediateSortTempRow[] currentBuffer;
0:   private IntermediateSortTempRow[] backupBuffer;
/////////////////////////////////////////////////////////////////////////
0:   private TableFieldStat tableFieldStat;
0:   private SortStepRowHandler sortStepRowHandler;
0:   private Comparator<IntermediateSortTempRow> comparator;
0:     this.tableFieldStat = new TableFieldStat(parameters);
0:     this.sortStepRowHandler = new SortStepRowHandler(tableFieldStat);
0:     comparator = new IntermediateSortTempRowComparator(parameters.getNoDictionarySortColumn());
/////////////////////////////////////////////////////////////////////////
0:   @Override
1:       try {
0:         this.returnRow = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:         this.numberOfObjectRead++;
0:       } catch (IOException e) {
0:         throw new CarbonSortKeyAndGroupByException("Problems while reading row", e);
1:       }
/////////////////////////////////////////////////////////////////////////
0:    * get a batch of row, this interface is used in reading compressed sort temp files
1:    *
0:    * @param expected expected number in a batch
0:    * @return a batch of row
0:    * @throws IOException if error occurs while reading from stream
0:   private IntermediateSortTempRow[] readBatchedRowFromStream(int expected)
0:       throws IOException {
0:     IntermediateSortTempRow[] holders = new IntermediateSortTempRow[expected];
0:     for (int i = 0; i < expected; i++) {
0:       IntermediateSortTempRow holder
0:           = sortStepRowHandler.readIntermediateSortTempRowFromInputStream(stream);
0:       holders[i] = holder;
0:     this.numberOfObjectRead += expected;
0:     return holders;
/////////////////////////////////////////////////////////////////////////
0:   public IntermediateSortTempRow getRow() {
/////////////////////////////////////////////////////////////////////////
0:     hash += tableFieldStat.hashCode();
/////////////////////////////////////////////////////////////////////////
0:    * @param numberOfRecords number of records to be read
0:    * @return batch of intermediate sort temp row
0:    * @throws IOException if error occurs reading records from file
0:   private IntermediateSortTempRow[] prefetchRecordsFromFile(int numberOfRecords)
0:       throws IOException {
0:     return readBatchedRowFromStream(numberOfRecords);
commit:c100251
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.impl.FileFactory;
/////////////////////////////////////////////////////////////////////////
0:   private int dimCnt;
0:   private int complexCnt;
0:   private int measureCnt;
0:   private boolean[] isNoDictionaryDimensionColumn;
0:   private DataType[] measureDataTypes;
1:   private int readBufferSize;
1:   private String compressorName;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     this.dimCnt = parameters.getDimColCount();
0:     this.complexCnt = parameters.getComplexDimColCount();
0:     this.measureCnt = parameters.getMeasureColCount();
0:     this.measureDataTypes = parameters.getMeasureDataType();
1:     this.readBufferSize = parameters.getBufferSize();
1:     this.compressorName = parameters.getSortTempCompressorName();
1: 
1:     this.executorService = Executors.newFixedThreadPool(1);
0:     this.nullSetWordsLength = ((parameters.getMeasureColCount() - 1) >> 6) + 1;
/////////////////////////////////////////////////////////////////////////
1:       stream = FileFactory.getDataInputStream(tempFile.getPath(), FileFactory.FileType.LOCAL,
1:           readBufferSize, compressorName);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     Object[] row = new Object[dimCnt + measureCnt];
/////////////////////////////////////////////////////////////////////////
0:       for (; dimCount < dimCnt; dimCount++) {
/////////////////////////////////////////////////////////////////////////
0:       for (int mesCount = 0; mesCount < measureCnt; mesCount++) {
0:           DataType dataType = measureDataTypes[mesCount];
0:             row[dimCount + mesCount] = stream.readShort();
0:             row[dimCount + mesCount] = stream.readInt();
0:             row[dimCount + mesCount] = stream.readLong();
0:             row[dimCount + mesCount] = stream.readDouble();
0:             row[dimCount + mesCount] = DataTypeUtil.byteToBigDecimal(bigDecimalInBytes);
0:             throw new IllegalArgumentException("unsupported data type:" + dataType);
/////////////////////////////////////////////////////////////////////////
1:     if (prefetch) {
/////////////////////////////////////////////////////////////////////////
0:     hash += 31 * measureCnt;
0:     hash += 31 * dimCnt;
0:     hash += 31 * complexCnt;
author:kumarvishal
-------------------------------------------------------------------------------
commit:a734add
/////////////////////////////////////////////////////////////////////////
1:     if (null != executorService && !executorService.isShutdown()) {
1:       executorService.shutdownNow();
1:     }
author:Raghunandan S
-------------------------------------------------------------------------------
commit:06b0d08
/////////////////////////////////////////////////////////////////////////
0:             default:
0:               throw new IllegalArgumentException("unsupported data type:" +
0:                   measureDataType[mesCount]);
0:     } catch (IOException e) {
/////////////////////////////////////////////////////////////////////////
1:     if (this == obj) {
1:       return true;
1:     }
1: 
1:     return this == o;
author:ravipesala
-------------------------------------------------------------------------------
commit:9e064ee
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeUtil;
/////////////////////////////////////////////////////////////////////////
0:               row[dimensionCount + mesCount] = DataTypeUtil.byteToBigDecimal(bigDecimalInBytes);
commit:8b3fa7f
/////////////////////////////////////////////////////////////////////////
0:               row[dimensionCount + mesCount] = stream.readShort();
0:               break;
0:               row[dimensionCount + mesCount] = stream.readInt();
0:               break;
commit:aca59ce
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             row[dimensionCount + mesCount] = bigDecimalInBytes;
commit:f1f9348
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.newflow.sort.unsafe.holder;
1: 
0: import java.io.BufferedInputStream;
1: import java.io.DataInputStream;
1: import java.io.File;
0: import java.io.FileInputStream;
1: import java.io.FileNotFoundException;
1: import java.io.IOException;
1: import java.util.Comparator;
1: import java.util.concurrent.Callable;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.Future;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.util.CarbonProperties;
1: import org.apache.carbondata.core.util.CarbonUtil;
0: import org.apache.carbondata.core.util.DataTypeUtil;
0: import org.apache.carbondata.processing.newflow.sort.unsafe.UnsafeCarbonRowPage;
0: import org.apache.carbondata.processing.sortandgroupby.exception.CarbonSortKeyAndGroupByException;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.NewRowComparator;
0: import org.apache.carbondata.processing.sortandgroupby.sortdata.SortParameters;
1: 
1: public class UnsafeSortTempFileChunkHolder implements SortTempChunkHolder {
1: 
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(UnsafeSortTempFileChunkHolder.class.getName());
1: 
1:   /**
1:    * temp file
1:    */
1:   private File tempFile;
1: 
1:   /**
1:    * read stream
1:    */
1:   private DataInputStream stream;
1: 
1:   /**
1:    * entry count
1:    */
1:   private int entryCount;
1: 
1:   /**
1:    * return row
1:    */
0:   private Object[] returnRow;
1: 
1:   /**
0:    * number of measures
1:    */
0:   private int measureCount;
1: 
1:   /**
0:    * number of dimensionCount
1:    */
0:   private int dimensionCount;
1: 
1:   /**
0:    * number of complexDimensionCount
1:    */
0:   private int complexDimensionCount;
1: 
1:   /**
0:    * fileBufferSize for file reader stream size
1:    */
0:   private int fileBufferSize;
1: 
0:   private Object[][] currentBuffer;
1: 
0:   private Object[][] backupBuffer;
1: 
1:   private boolean isBackupFilled;
1: 
1:   private boolean prefetch;
1: 
1:   private int bufferSize;
1: 
1:   private int bufferRowCounter;
1: 
1:   private ExecutorService executorService;
1: 
1:   private Future<Void> submit;
1: 
1:   private int prefetchRecordsProceesed;
1: 
1:   /**
0:    * sortTempFileNoOFRecordsInCompression
1:    */
0:   private int sortTempFileNoOFRecordsInCompression;
1: 
1:   /**
0:    * isSortTempFileCompressionEnabled
1:    */
0:   private boolean isSortTempFileCompressionEnabled;
1: 
1:   /**
1:    * totalRecordFetch
1:    */
1:   private int totalRecordFetch;
1: 
0:   private int noDictionaryCount;
1: 
0:   private char[] aggType;
1: 
1:   private int numberOfObjectRead;
1:   /**
0:    * to store whether dimension is of dictionary type or not
1:    */
0:   private boolean[] isNoDictionaryDimensionColumn;
1: 
0:   private int nullSetWordsLength;
1: 
0:   private Comparator<Object[]> comparator;
1: 
1:   /**
1:    * Constructor to initialize
1:    */
0:   public UnsafeSortTempFileChunkHolder(File tempFile, SortParameters parameters) {
1:     // set temp file
1:     this.tempFile = tempFile;
1: 
0:     // set measure and dimension count
0:     this.measureCount = parameters.getMeasureColCount();
0:     this.dimensionCount = parameters.getDimColCount();
0:     this.complexDimensionCount = parameters.getComplexDimColCount();
1: 
0:     this.noDictionaryCount = parameters.getNoDictionaryCount();
0:     // set mdkey length
0:     this.fileBufferSize = parameters.getFileBufferSize();
0:     this.executorService = Executors.newFixedThreadPool(1);
0:     this.aggType = parameters.getAggType();
0:     this.isNoDictionaryDimensionColumn = parameters.getNoDictionaryDimnesionColumn();
0:     this.nullSetWordsLength = ((measureCount - 1) >> 6) + 1;
0:     comparator = new NewRowComparator(isNoDictionaryDimensionColumn);
1:     initialize();
1:   }
1: 
1:   /**
1:    * This method will be used to initialize
1:    *
1:    * @throws CarbonSortKeyAndGroupByException problem while initializing
1:    */
1:   public void initialize() {
1:     prefetch = Boolean.parseBoolean(CarbonProperties.getInstance()
1:         .getProperty(CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH,
1:             CarbonCommonConstants.CARBON_MERGE_SORT_PREFETCH_DEFAULT));
0:     bufferSize = CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE;
0:     this.isSortTempFileCompressionEnabled = Boolean.parseBoolean(CarbonProperties.getInstance()
0:         .getProperty(CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED,
0:             CarbonCommonConstants.IS_SORT_TEMP_FILE_COMPRESSION_ENABLED_DEFAULTVALUE));
0:     if (this.isSortTempFileCompressionEnabled) {
0:       LOGGER.info("Compression was used while writing the sortTempFile");
1:     }
1: 
1:     try {
0:       this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(CarbonProperties.getInstance()
0:           .getProperty(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION,
0:               CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE));
0:       if (this.sortTempFileNoOFRecordsInCompression < 1) {
0:         LOGGER.error("Invalid value for: "
0:             + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:             + ": Only Positive Integer value(greater than zero) is allowed.Default value will"
0:             + " be used");
1: 
0:         this.sortTempFileNoOFRecordsInCompression = Integer.parseInt(
0:             CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:       }
0:     } catch (NumberFormatException e) {
0:       LOGGER.error(
0:           "Invalid value for: " + CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORDS_FOR_COMPRESSION
0:               + ", only Positive Integer value is allowed.Default value will be used");
0:       this.sortTempFileNoOFRecordsInCompression = Integer
0:           .parseInt(CarbonCommonConstants.SORT_TEMP_FILE_NO_OF_RECORD_FOR_COMPRESSION_DEFAULTVALUE);
1:     }
1: 
1:     initialise();
1:   }
1: 
1:   private void initialise() {
1:     try {
0:       if (isSortTempFileCompressionEnabled) {
0:         this.bufferSize = sortTempFileNoOFRecordsInCompression;
1:       }
0:       stream = new DataInputStream(
0:           new BufferedInputStream(new FileInputStream(tempFile), this.fileBufferSize));
1:       this.entryCount = stream.readInt();
0:       LOGGER.audit("Processing unsafe mode file rows with size : " + entryCount);
1:       if (prefetch) {
1:         new DataFetcher(false).call();
1:         totalRecordFetch += currentBuffer.length;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
0:       } else {
0:         if (isSortTempFileCompressionEnabled) {
1:           new DataFetcher(false).call();
1:         }
1:       }
1: 
1:     } catch (FileNotFoundException e) {
1:       LOGGER.error(e);
1:       throw new RuntimeException(tempFile + " No Found", e);
0:     } catch (IOException e) {
1:       LOGGER.error(e);
1:       throw new RuntimeException(tempFile + " No Found", e);
1:     } catch (Exception e) {
1:       LOGGER.error(e);
1:       throw new RuntimeException(tempFile + " Problem while reading", e);
1:     }
1:   }
1: 
1:   /**
1:    * This method will be used to read new row from file
1:    *
1:    * @throws CarbonSortKeyAndGroupByException problem while reading
1:    */
1:   public void readRow() throws CarbonSortKeyAndGroupByException {
1:     if (prefetch) {
1:       fillDataForPrefetch();
0:     } else if (isSortTempFileCompressionEnabled) {
1:       if (bufferRowCounter >= bufferSize) {
1:         try {
1:           new DataFetcher(false).call();
1:           bufferRowCounter = 0;
1:         } catch (Exception e) {
1:           LOGGER.error(e);
0:           throw new CarbonSortKeyAndGroupByException(tempFile + " Problem while reading", e);
1:         }
1: 
1:       }
1:       prefetchRecordsProceesed++;
1:       returnRow = currentBuffer[bufferRowCounter++];
0:     } else {
0:       Object[] outRow = getRowFromStream();
0:       this.returnRow = outRow;
1:     }
1:   }
1: 
1:   private void fillDataForPrefetch() {
1:     if (bufferRowCounter >= bufferSize) {
1:       if (isBackupFilled) {
1:         bufferRowCounter = 0;
1:         currentBuffer = backupBuffer;
1:         totalRecordFetch += currentBuffer.length;
1:         isBackupFilled = false;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
0:       } else {
1:         try {
1:           submit.get();
1:         } catch (Exception e) {
1:           LOGGER.error(e);
1:         }
1:         bufferRowCounter = 0;
1:         currentBuffer = backupBuffer;
1:         isBackupFilled = false;
1:         totalRecordFetch += currentBuffer.length;
1:         if (totalRecordFetch < this.entryCount) {
1:           submit = executorService.submit(new DataFetcher(true));
1:         }
1:       }
1:     }
1:     prefetchRecordsProceesed++;
1:     returnRow = currentBuffer[bufferRowCounter++];
1:   }
1: 
1:   /**
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[] getRowFromStream() throws CarbonSortKeyAndGroupByException {
0:     Object[] row = new Object[dimensionCount + measureCount];
1:     try {
0:       int dimCount = 0;
0:       for (; dimCount < isNoDictionaryDimensionColumn.length; dimCount++) {
0:         if (isNoDictionaryDimensionColumn[dimCount]) {
0:           short aShort = stream.readShort();
0:           byte[] col = new byte[aShort];
0:           stream.readFully(col);
0:           row[dimCount] = col;
0:         } else {
0:           int anInt = stream.readInt();
0:           row[dimCount] = anInt;
1:         }
1:       }
1: 
0:       // write complex dimensions here.
0:       for (; dimCount < dimensionCount; dimCount++) {
0:         short aShort = stream.readShort();
0:         byte[] col = new byte[aShort];
0:         stream.readFully(col);
0:         row[dimCount] = col;
1:       }
1: 
0:       long[] words = new long[nullSetWordsLength];
0:       for (int i = 0; i < words.length; i++) {
0:         words[i] = stream.readLong();
1:       }
1: 
0:       for (int mesCount = 0; mesCount < measureCount; mesCount++) {
0:         if (UnsafeCarbonRowPage.isSet(words, mesCount)) {
0:           if (aggType[mesCount] == CarbonCommonConstants.SUM_COUNT_VALUE_MEASURE) {
0:             row[dimensionCount + mesCount] = stream.readDouble();
0:           } else if (aggType[mesCount] == CarbonCommonConstants.BIG_INT_MEASURE) {
0:             row[dimensionCount + mesCount] = stream.readLong();
0:           } else if (aggType[mesCount] == CarbonCommonConstants.BIG_DECIMAL_MEASURE) {
0:             short aShort = stream.readShort();
0:             byte[] bigDecimalInBytes = new byte[aShort];
0:             stream.readFully(bigDecimalInBytes);
0:             row[dimensionCount + mesCount] = DataTypeUtil.byteToBigDecimal(bigDecimalInBytes);
1:           }
1:         }
1:       }
0:       return row;
1:     } catch (Exception e) {
0:       throw new CarbonSortKeyAndGroupByException(e);
1:     }
1:   }
1: 
1:   /**
1:    * below method will be used to get the row
1:    *
1:    * @return row
1:    */
0:   public Object[] getRow() {
1:     return this.returnRow;
1:   }
1: 
1:   /**
1:    * below method will be used to check whether any more records are present
1:    * in file or not
1:    *
1:    * @return more row present in file
1:    */
1:   public boolean hasNext() {
0:     if (prefetch || isSortTempFileCompressionEnabled) {
1:       return this.prefetchRecordsProceesed < this.entryCount;
1:     }
1:     return this.numberOfObjectRead < this.entryCount;
1:   }
1: 
1:   /**
1:    * Below method will be used to close streams
1:    */
1:   public void close() {
1:     CarbonUtil.closeStreams(stream);
0:     executorService.shutdown();
1:   }
1: 
1:   /**
1:    * This method will number of entries
1:    *
1:    * @return entryCount
1:    */
1:   public int numberOfRows() {
1:     return entryCount;
1:   }
1: 
1:   @Override public int compareTo(SortTempChunkHolder other) {
1:     return comparator.compare(returnRow, other.getRow());
1:   }
1: 
1:   @Override public boolean equals(Object obj) {
1:     if (!(obj instanceof UnsafeSortTempFileChunkHolder)) {
1:       return false;
1:     }
1:     UnsafeSortTempFileChunkHolder o = (UnsafeSortTempFileChunkHolder) obj;
1: 
0:     return o.compareTo(o) == 0;
1:   }
1: 
1:   @Override public int hashCode() {
1:     int hash = 0;
0:     hash += 31 * measureCount;
0:     hash += 31 * dimensionCount;
0:     hash += 31 * complexDimensionCount;
0:     hash += 31 * noDictionaryCount;
1:     hash += tempFile.hashCode();
1:     return hash;
1:   }
1: 
1:   private final class DataFetcher implements Callable<Void> {
1:     private boolean isBackUpFilling;
1: 
1:     private int numberOfRecords;
1: 
1:     private DataFetcher(boolean backUp) {
1:       isBackUpFilling = backUp;
1:       calculateNumberOfRecordsToBeFetched();
1:     }
1: 
1:     private void calculateNumberOfRecordsToBeFetched() {
1:       int numberOfRecordsLeftToBeRead = entryCount - totalRecordFetch;
1:       numberOfRecords =
1:           bufferSize < numberOfRecordsLeftToBeRead ? bufferSize : numberOfRecordsLeftToBeRead;
1:     }
1: 
1:     @Override public Void call() throws Exception {
1:       try {
1:         if (isBackUpFilling) {
1:           backupBuffer = prefetchRecordsFromFile(numberOfRecords);
1:           isBackupFilled = true;
0:         } else {
1:           currentBuffer = prefetchRecordsFromFile(numberOfRecords);
1:         }
1:       } catch (Exception e) {
1:         LOGGER.error(e);
1:       }
1:       return null;
1:     }
1: 
1:   }
1: 
1:   /**
1:    * This method will read the records from sort temp file and keep it in a buffer
1:    *
0:    * @param numberOfRecords
0:    * @return
0:    * @throws CarbonSortKeyAndGroupByException
1:    */
0:   private Object[][] prefetchRecordsFromFile(int numberOfRecords)
0:       throws CarbonSortKeyAndGroupByException {
0:     Object[][] records = new Object[numberOfRecords][];
0:     for (int i = 0; i < numberOfRecords; i++) {
0:       records[i] = getRowFromStream();
1:     }
0:     return records;
1:   }
1: }
author:jackylk
-------------------------------------------------------------------------------
commit:98df130
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.datatype.DataType;
/////////////////////////////////////////////////////////////////////////
0:   private DataType[] measureDataType;
/////////////////////////////////////////////////////////////////////////
0:     this.measureDataType = parameters.getMeasureDataType();
/////////////////////////////////////////////////////////////////////////
0:           switch (measureDataType[mesCount]) {
0:             case SHORT:
0:             case INT:
0:             case LONG:
0:               row[dimensionCount + mesCount] = stream.readLong();
0:               break;
0:             case DOUBLE:
0:               row[dimensionCount + mesCount] = stream.readDouble();
0:               break;
0:             case DECIMAL:
0:               short aShort = stream.readShort();
0:               byte[] bigDecimalInBytes = new byte[aShort];
0:               stream.readFully(bigDecimalInBytes);
0:               row[dimensionCount + mesCount] = bigDecimalInBytes;
0:               break;
commit:8cca0af
/////////////////////////////////////////////////////////////////////////
0:           if (aggType[mesCount] == CarbonCommonConstants.DOUBLE_MEASURE) {
author:QiangCai
-------------------------------------------------------------------------------
commit:81149f6
/////////////////////////////////////////////////////////////////////////
0:       this.returnRow = getRowFromStream();
commit:9f94529
/////////////////////////////////////////////////////////////////////////
0:     comparator = new NewRowComparator(parameters.getNoDictionarySortColumn());
commit:c5aba5f
/////////////////////////////////////////////////////////////////////////
1:     bufferSize = Integer.parseInt(CarbonProperties.getInstance()
1:         .getProperty(CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE,
1:             CarbonCommonConstants.CARBON_PREFETCH_BUFFERSIZE_DEFAULT));
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
============================================================================
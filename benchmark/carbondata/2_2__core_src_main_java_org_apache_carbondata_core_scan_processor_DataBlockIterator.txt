1:daa6465: /*
1:daa6465:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:daa6465:  * contributor license agreements.  See the NOTICE file distributed with
1:daa6465:  * this work for additional information regarding copyright ownership.
1:daa6465:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:daa6465:  * (the "License"); you may not use this file except in compliance with
1:daa6465:  * the License.  You may obtain a copy of the License at
1:daa6465:  *
1:daa6465:  *    http://www.apache.org/licenses/LICENSE-2.0
1:daa6465:  *
1:daa6465:  * Unless required by applicable law or agreed to in writing, software
1:daa6465:  * distributed under the License is distributed on an "AS IS" BASIS,
1:daa6465:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:daa6465:  * See the License for the specific language governing permissions and
1:daa6465:  * limitations under the License.
1:daa6465:  */
1:daa6465: package org.apache.carbondata.core.scan.processor;
1:daa6465: 
1:daa6465: import java.io.IOException;
1:daa6465: import java.util.ArrayList;
1:daa6465: import java.util.List;
1:daa6465: import java.util.concurrent.Callable;
1:daa6465: import java.util.concurrent.ExecutionException;
1:daa6465: import java.util.concurrent.ExecutorService;
1:daa6465: import java.util.concurrent.Future;
1:daa6465: import java.util.concurrent.atomic.AtomicBoolean;
1:daa6465: 
1:daa6465: import org.apache.carbondata.common.CarbonIterator;
1:daa6465: import org.apache.carbondata.core.datastore.DataRefNode;
1:daa6465: import org.apache.carbondata.core.datastore.FileReader;
1:daa6465: import org.apache.carbondata.core.scan.collector.ResultCollectorFactory;
1:daa6465: import org.apache.carbondata.core.scan.collector.ScannedResultCollector;
1:daa6465: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1:daa6465: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1:daa6465: import org.apache.carbondata.core.scan.result.vector.CarbonColumnarBatch;
1:daa6465: import org.apache.carbondata.core.scan.scanner.BlockletScanner;
1:daa6465: import org.apache.carbondata.core.scan.scanner.impl.BlockletFilterScanner;
1:daa6465: import org.apache.carbondata.core.scan.scanner.impl.BlockletFullScanner;
1:daa6465: import org.apache.carbondata.core.stats.QueryStatisticsModel;
1:daa6465: import org.apache.carbondata.core.util.TaskMetricsMap;
1:daa6465: 
1:daa6465: /**
1:daa6465:  * This abstract class provides a skeletal implementation of the
1:daa6465:  * Block iterator.
1:daa6465:  */
1:daa6465: public class DataBlockIterator extends CarbonIterator<List<Object[]>> {
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * iterator which will be used to iterate over blocklets
1:daa6465:    */
1:daa6465:   private BlockletIterator blockletIterator;
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * result collector which will be used to aggregate the scanned result
1:daa6465:    */
1:daa6465:   private ScannedResultCollector scannerResultAggregator;
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * processor which will be used to process the block processing can be
1:daa6465:    * filter processing or non filter processing
1:daa6465:    */
1:daa6465:   private BlockletScanner blockletScanner;
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * batch size of result
1:daa6465:    */
1:daa6465:   private int batchSize;
1:daa6465: 
1:daa6465:   private ExecutorService executorService;
1:daa6465: 
1:daa6465:   private Future<BlockletScannedResult> future;
1:daa6465: 
1:daa6465:   private Future<RawBlockletColumnChunks> futureIo;
1:daa6465: 
1:daa6465:   private BlockletScannedResult scannedResult;
1:daa6465: 
1:daa6465:   private BlockExecutionInfo blockExecutionInfo;
1:daa6465: 
1:daa6465:   private FileReader fileReader;
1:daa6465: 
1:daa6465:   private AtomicBoolean nextBlock;
1:daa6465: 
1:daa6465:   private AtomicBoolean nextRead;
1:daa6465: 
1:daa6465:   public DataBlockIterator(BlockExecutionInfo blockExecutionInfo, FileReader fileReader,
1:daa6465:       int batchSize, QueryStatisticsModel queryStatisticsModel, ExecutorService executorService) {
1:daa6465:     this.blockExecutionInfo = blockExecutionInfo;
1:26607fb:     this.blockExecutionInfo.setQueryStatisticsModel(queryStatisticsModel);
1:daa6465:     this.fileReader = fileReader;
1:daa6465:     blockletIterator = new BlockletIterator(blockExecutionInfo.getFirstDataBlock(),
1:daa6465:         blockExecutionInfo.getNumberOfBlockToScan());
1:daa6465:     if (blockExecutionInfo.getFilterExecuterTree() != null) {
1:daa6465:       blockletScanner = new BlockletFilterScanner(blockExecutionInfo, queryStatisticsModel);
1:daa6465:     } else {
1:daa6465:       blockletScanner = new BlockletFullScanner(blockExecutionInfo, queryStatisticsModel);
1:daa6465:     }
1:daa6465:     this.scannerResultAggregator =
1:daa6465:         ResultCollectorFactory.getScannedResultCollector(blockExecutionInfo);
1:daa6465:     this.batchSize = batchSize;
1:daa6465:     this.executorService = executorService;
1:daa6465:     this.nextBlock = new AtomicBoolean(false);
1:daa6465:     this.nextRead = new AtomicBoolean(false);
1:daa6465:   }
1:daa6465: 
1:daa6465:   @Override
1:daa6465:   public List<Object[]> next() {
1:daa6465:     List<Object[]> collectedResult = null;
1:daa6465:     if (updateScanner()) {
1:daa6465:       collectedResult = this.scannerResultAggregator.collectResultInRow(scannedResult, batchSize);
1:daa6465:       while (collectedResult.size() < batchSize && updateScanner()) {
1:daa6465:         List<Object[]> data = this.scannerResultAggregator
1:daa6465:             .collectResultInRow(scannedResult, batchSize - collectedResult.size());
1:daa6465:         collectedResult.addAll(data);
1:daa6465:       }
1:daa6465:     } else {
1:daa6465:       collectedResult = new ArrayList<>();
1:daa6465:     }
1:daa6465:     return collectedResult;
1:daa6465:   }
1:daa6465: 
1:daa6465:   @Override
1:daa6465:   public boolean hasNext() {
1:daa6465:     if (scannedResult != null && scannedResult.hasNext()) {
1:daa6465:       return true;
1:daa6465:     } else {
1:daa6465:       if (null != scannedResult) {
1:daa6465:         scannedResult.freeMemory();
1:daa6465:       }
1:daa6465:       return blockletIterator.hasNext() || nextBlock.get() || nextRead.get();
1:daa6465:     }
1:daa6465:   }
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * Return true if scan result if non-empty
1:daa6465:    */
1:daa6465:   private boolean updateScanner() {
1:daa6465:     try {
1:daa6465:       if (scannedResult != null && scannedResult.hasNext()) {
1:daa6465:         return true;
1:daa6465:       } else {
1:daa6465:         scannedResult = processNextBlocklet();
1:daa6465:         while (scannedResult != null) {
1:daa6465:           if (scannedResult.hasNext()) {
1:daa6465:             return true;
1:daa6465:           }
1:daa6465:           scannedResult = processNextBlocklet();
1:daa6465:         }
1:daa6465:         nextBlock.set(false);
1:daa6465:         nextRead.set(false);
1:daa6465:         return false;
1:daa6465:       }
1:daa6465:     } catch (Exception ex) {
1:daa6465:       throw new RuntimeException(ex);
1:daa6465:     }
1:daa6465:   }
1:daa6465: 
1:daa6465:   private BlockletScannedResult processNextBlocklet() throws Exception {
1:daa6465:     BlockletScannedResult result = null;
1:daa6465:     if (blockExecutionInfo.isPrefetchBlocklet()) {
1:daa6465:       if (blockletIterator.hasNext() || nextBlock.get() || nextRead.get()) {
1:daa6465:         if (future == null) {
1:daa6465:           future = scanNextBlockletAsync();
1:daa6465:         }
1:daa6465:         result = future.get();
1:daa6465:         nextBlock.set(false);
1:daa6465:         if (blockletIterator.hasNext() || nextRead.get()) {
1:daa6465:           nextBlock.set(true);
1:daa6465:           future = scanNextBlockletAsync();
1:daa6465:         }
1:daa6465:       }
1:daa6465:     } else {
1:daa6465:       if (blockletIterator.hasNext()) {
1:daa6465:         RawBlockletColumnChunks rawChunks = readNextBlockletColumnChunks();
1:daa6465:         if (rawChunks != null) {
1:daa6465:           result = blockletScanner.scanBlocklet(rawChunks);
1:daa6465:         }
1:daa6465:       }
1:daa6465:     }
1:daa6465:     return result;
1:daa6465:   }
1:daa6465: 
1:daa6465:   private RawBlockletColumnChunks readNextBlockletColumnChunks() throws IOException {
1:daa6465:     RawBlockletColumnChunks rawBlockletColumnChunks = getNextBlockletColumnChunks();
1:daa6465:     if (rawBlockletColumnChunks != null) {
1:daa6465:       blockletScanner.readBlocklet(rawBlockletColumnChunks);
1:daa6465:       return rawBlockletColumnChunks;
1:daa6465:     }
1:daa6465:     return null;
1:daa6465:   }
1:daa6465: 
1:daa6465:   private RawBlockletColumnChunks getNextBlockletColumnChunks() {
1:daa6465:     RawBlockletColumnChunks rawBlockletColumnChunks = null;
1:daa6465:     do {
1:daa6465:       DataRefNode dataBlock = blockletIterator.next();
1:daa6465:       if (dataBlock.getColumnsMaxValue() == null || blockletScanner.isScanRequired(dataBlock)) {
1:daa6465:         rawBlockletColumnChunks =  RawBlockletColumnChunks.newInstance(
1:daa6465:             blockExecutionInfo.getTotalNumberDimensionToRead(),
1:daa6465:             blockExecutionInfo.getTotalNumberOfMeasureToRead(), fileReader, dataBlock);
1:daa6465:       }
1:daa6465:     } while (rawBlockletColumnChunks == null && blockletIterator.hasNext());
1:daa6465:     return rawBlockletColumnChunks;
1:daa6465:   }
1:daa6465: 
1:daa6465:   private Future<BlockletScannedResult> scanNextBlockletAsync() {
1:daa6465:     return executorService.submit(new Callable<BlockletScannedResult>() {
1:daa6465:       @Override public BlockletScannedResult call() throws Exception {
1:daa6465:         if (futureIo == null) {
1:daa6465:           futureIo = readNextBlockletAsync();
1:daa6465:         }
1:daa6465:         RawBlockletColumnChunks rawBlockletColumnChunks = futureIo.get();
1:daa6465:         futureIo = null;
1:daa6465:         nextRead.set(false);
1:daa6465:         if (rawBlockletColumnChunks != null) {
1:daa6465:           if (blockletIterator.hasNext()) {
1:daa6465:             nextRead.set(true);
1:daa6465:             futureIo = readNextBlockletAsync();
1:daa6465:           }
1:daa6465:           return blockletScanner.scanBlocklet(rawBlockletColumnChunks);
1:daa6465:         }
1:daa6465:         return null;
1:daa6465:       }
1:daa6465:     });
1:daa6465:   }
1:daa6465: 
1:daa6465:   private Future<RawBlockletColumnChunks> readNextBlockletAsync() {
1:daa6465:     return executorService.submit(new Callable<RawBlockletColumnChunks>() {
1:daa6465:       @Override public RawBlockletColumnChunks call() throws Exception {
1:daa6465:         try {
1:daa6465:           TaskMetricsMap.getInstance().registerThreadCallback();
1:daa6465:           if (blockletIterator.hasNext()) {
1:daa6465:             return readNextBlockletColumnChunks();
1:daa6465:           } else {
1:daa6465:             return null;
1:daa6465:           }
1:daa6465:         } finally {
1:daa6465:           // update read bytes metrics for this thread
1:daa6465:           TaskMetricsMap.getInstance().updateReadBytes(Thread.currentThread().getId());
1:daa6465:         }
1:daa6465:       }
1:daa6465:     });
1:daa6465:   }
1:daa6465: 
1:daa6465:   public void processNextBatch(CarbonColumnarBatch columnarBatch) {
1:daa6465:     if (updateScanner()) {
1:daa6465:       this.scannerResultAggregator.collectResultInColumnarBatch(scannedResult, columnarBatch);
1:daa6465:     }
1:daa6465:   }
1:daa6465: 
1:daa6465: 
1:daa6465:   /**
1:daa6465:    * Close the resources
1:daa6465:    */
1:daa6465:   public void close() {
1:daa6465:     // free the current scanned result
1:daa6465:     if (null != scannedResult && !scannedResult.hasNext()) {
1:daa6465:       scannedResult.freeMemory();
1:daa6465:     }
1:daa6465:     // free any pre-fetched memory if present
1:daa6465:     if (null != future) {
1:daa6465:       try {
1:daa6465:         BlockletScannedResult blockletScannedResult = future.get();
1:daa6465:         if (blockletScannedResult != null) {
1:daa6465:           blockletScannedResult.freeMemory();
1:daa6465:         }
1:daa6465:       } catch (InterruptedException | ExecutionException e) {
1:daa6465:         throw new RuntimeException(e);
1:daa6465:       }
1:daa6465:     }
1:daa6465:   }
1:daa6465: }
============================================================================
author:manishgupta88
-------------------------------------------------------------------------------
commit:26607fb
/////////////////////////////////////////////////////////////////////////
1:     this.blockExecutionInfo.setQueryStatisticsModel(queryStatisticsModel);
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.scan.processor;
1: 
1: import java.io.IOException;
1: import java.util.ArrayList;
1: import java.util.List;
1: import java.util.concurrent.Callable;
1: import java.util.concurrent.ExecutionException;
1: import java.util.concurrent.ExecutorService;
1: import java.util.concurrent.Future;
1: import java.util.concurrent.atomic.AtomicBoolean;
1: 
1: import org.apache.carbondata.common.CarbonIterator;
1: import org.apache.carbondata.core.datastore.DataRefNode;
1: import org.apache.carbondata.core.datastore.FileReader;
1: import org.apache.carbondata.core.scan.collector.ResultCollectorFactory;
1: import org.apache.carbondata.core.scan.collector.ScannedResultCollector;
1: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1: import org.apache.carbondata.core.scan.result.vector.CarbonColumnarBatch;
1: import org.apache.carbondata.core.scan.scanner.BlockletScanner;
1: import org.apache.carbondata.core.scan.scanner.impl.BlockletFilterScanner;
1: import org.apache.carbondata.core.scan.scanner.impl.BlockletFullScanner;
1: import org.apache.carbondata.core.stats.QueryStatisticsModel;
1: import org.apache.carbondata.core.util.TaskMetricsMap;
1: 
1: /**
1:  * This abstract class provides a skeletal implementation of the
1:  * Block iterator.
1:  */
1: public class DataBlockIterator extends CarbonIterator<List<Object[]>> {
1: 
1:   /**
1:    * iterator which will be used to iterate over blocklets
1:    */
1:   private BlockletIterator blockletIterator;
1: 
1:   /**
1:    * result collector which will be used to aggregate the scanned result
1:    */
1:   private ScannedResultCollector scannerResultAggregator;
1: 
1:   /**
1:    * processor which will be used to process the block processing can be
1:    * filter processing or non filter processing
1:    */
1:   private BlockletScanner blockletScanner;
1: 
1:   /**
1:    * batch size of result
1:    */
1:   private int batchSize;
1: 
1:   private ExecutorService executorService;
1: 
1:   private Future<BlockletScannedResult> future;
1: 
1:   private Future<RawBlockletColumnChunks> futureIo;
1: 
1:   private BlockletScannedResult scannedResult;
1: 
1:   private BlockExecutionInfo blockExecutionInfo;
1: 
1:   private FileReader fileReader;
1: 
1:   private AtomicBoolean nextBlock;
1: 
1:   private AtomicBoolean nextRead;
1: 
1:   public DataBlockIterator(BlockExecutionInfo blockExecutionInfo, FileReader fileReader,
1:       int batchSize, QueryStatisticsModel queryStatisticsModel, ExecutorService executorService) {
1:     this.blockExecutionInfo = blockExecutionInfo;
1:     this.fileReader = fileReader;
1:     blockletIterator = new BlockletIterator(blockExecutionInfo.getFirstDataBlock(),
1:         blockExecutionInfo.getNumberOfBlockToScan());
1:     if (blockExecutionInfo.getFilterExecuterTree() != null) {
1:       blockletScanner = new BlockletFilterScanner(blockExecutionInfo, queryStatisticsModel);
1:     } else {
1:       blockletScanner = new BlockletFullScanner(blockExecutionInfo, queryStatisticsModel);
1:     }
1:     this.scannerResultAggregator =
1:         ResultCollectorFactory.getScannedResultCollector(blockExecutionInfo);
1:     this.batchSize = batchSize;
1:     this.executorService = executorService;
1:     this.nextBlock = new AtomicBoolean(false);
1:     this.nextRead = new AtomicBoolean(false);
1:   }
1: 
1:   @Override
1:   public List<Object[]> next() {
1:     List<Object[]> collectedResult = null;
1:     if (updateScanner()) {
1:       collectedResult = this.scannerResultAggregator.collectResultInRow(scannedResult, batchSize);
1:       while (collectedResult.size() < batchSize && updateScanner()) {
1:         List<Object[]> data = this.scannerResultAggregator
1:             .collectResultInRow(scannedResult, batchSize - collectedResult.size());
1:         collectedResult.addAll(data);
1:       }
1:     } else {
1:       collectedResult = new ArrayList<>();
1:     }
1:     return collectedResult;
1:   }
1: 
1:   @Override
1:   public boolean hasNext() {
1:     if (scannedResult != null && scannedResult.hasNext()) {
1:       return true;
1:     } else {
1:       if (null != scannedResult) {
1:         scannedResult.freeMemory();
1:       }
1:       return blockletIterator.hasNext() || nextBlock.get() || nextRead.get();
1:     }
1:   }
1: 
1:   /**
1:    * Return true if scan result if non-empty
1:    */
1:   private boolean updateScanner() {
1:     try {
1:       if (scannedResult != null && scannedResult.hasNext()) {
1:         return true;
1:       } else {
1:         scannedResult = processNextBlocklet();
1:         while (scannedResult != null) {
1:           if (scannedResult.hasNext()) {
1:             return true;
1:           }
1:           scannedResult = processNextBlocklet();
1:         }
1:         nextBlock.set(false);
1:         nextRead.set(false);
1:         return false;
1:       }
1:     } catch (Exception ex) {
1:       throw new RuntimeException(ex);
1:     }
1:   }
1: 
1:   private BlockletScannedResult processNextBlocklet() throws Exception {
1:     BlockletScannedResult result = null;
1:     if (blockExecutionInfo.isPrefetchBlocklet()) {
1:       if (blockletIterator.hasNext() || nextBlock.get() || nextRead.get()) {
1:         if (future == null) {
1:           future = scanNextBlockletAsync();
1:         }
1:         result = future.get();
1:         nextBlock.set(false);
1:         if (blockletIterator.hasNext() || nextRead.get()) {
1:           nextBlock.set(true);
1:           future = scanNextBlockletAsync();
1:         }
1:       }
1:     } else {
1:       if (blockletIterator.hasNext()) {
1:         RawBlockletColumnChunks rawChunks = readNextBlockletColumnChunks();
1:         if (rawChunks != null) {
1:           result = blockletScanner.scanBlocklet(rawChunks);
1:         }
1:       }
1:     }
1:     return result;
1:   }
1: 
1:   private RawBlockletColumnChunks readNextBlockletColumnChunks() throws IOException {
1:     RawBlockletColumnChunks rawBlockletColumnChunks = getNextBlockletColumnChunks();
1:     if (rawBlockletColumnChunks != null) {
1:       blockletScanner.readBlocklet(rawBlockletColumnChunks);
1:       return rawBlockletColumnChunks;
1:     }
1:     return null;
1:   }
1: 
1:   private RawBlockletColumnChunks getNextBlockletColumnChunks() {
1:     RawBlockletColumnChunks rawBlockletColumnChunks = null;
1:     do {
1:       DataRefNode dataBlock = blockletIterator.next();
1:       if (dataBlock.getColumnsMaxValue() == null || blockletScanner.isScanRequired(dataBlock)) {
1:         rawBlockletColumnChunks =  RawBlockletColumnChunks.newInstance(
1:             blockExecutionInfo.getTotalNumberDimensionToRead(),
1:             blockExecutionInfo.getTotalNumberOfMeasureToRead(), fileReader, dataBlock);
1:       }
1:     } while (rawBlockletColumnChunks == null && blockletIterator.hasNext());
1:     return rawBlockletColumnChunks;
1:   }
1: 
1:   private Future<BlockletScannedResult> scanNextBlockletAsync() {
1:     return executorService.submit(new Callable<BlockletScannedResult>() {
1:       @Override public BlockletScannedResult call() throws Exception {
1:         if (futureIo == null) {
1:           futureIo = readNextBlockletAsync();
1:         }
1:         RawBlockletColumnChunks rawBlockletColumnChunks = futureIo.get();
1:         futureIo = null;
1:         nextRead.set(false);
1:         if (rawBlockletColumnChunks != null) {
1:           if (blockletIterator.hasNext()) {
1:             nextRead.set(true);
1:             futureIo = readNextBlockletAsync();
1:           }
1:           return blockletScanner.scanBlocklet(rawBlockletColumnChunks);
1:         }
1:         return null;
1:       }
1:     });
1:   }
1: 
1:   private Future<RawBlockletColumnChunks> readNextBlockletAsync() {
1:     return executorService.submit(new Callable<RawBlockletColumnChunks>() {
1:       @Override public RawBlockletColumnChunks call() throws Exception {
1:         try {
1:           TaskMetricsMap.getInstance().registerThreadCallback();
1:           if (blockletIterator.hasNext()) {
1:             return readNextBlockletColumnChunks();
1:           } else {
1:             return null;
1:           }
1:         } finally {
1:           // update read bytes metrics for this thread
1:           TaskMetricsMap.getInstance().updateReadBytes(Thread.currentThread().getId());
1:         }
1:       }
1:     });
1:   }
1: 
1:   public void processNextBatch(CarbonColumnarBatch columnarBatch) {
1:     if (updateScanner()) {
1:       this.scannerResultAggregator.collectResultInColumnarBatch(scannedResult, columnarBatch);
1:     }
1:   }
1: 
1: 
1:   /**
1:    * Close the resources
1:    */
1:   public void close() {
1:     // free the current scanned result
1:     if (null != scannedResult && !scannedResult.hasNext()) {
1:       scannedResult.freeMemory();
1:     }
1:     // free any pre-fetched memory if present
1:     if (null != future) {
1:       try {
1:         BlockletScannedResult blockletScannedResult = future.get();
1:         if (blockletScannedResult != null) {
1:           blockletScannedResult.freeMemory();
1:         }
1:       } catch (InterruptedException | ExecutionException e) {
1:         throw new RuntimeException(e);
1:       }
1:     }
1:   }
1: }
============================================================================
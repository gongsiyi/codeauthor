1:b681244: /*
1:b681244:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b681244:  * contributor license agreements.  See the NOTICE file distributed with
1:b681244:  * this work for additional information regarding copyright ownership.
1:b681244:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b681244:  * (the "License"); you may not use this file except in compliance with
1:b681244:  * the License.  You may obtain a copy of the License at
1:b681244:  *
1:b681244:  *    http://www.apache.org/licenses/LICENSE-2.0
1:b681244:  *
1:b681244:  * Unless required by applicable law or agreed to in writing, software
1:b681244:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b681244:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b681244:  * See the License for the specific language governing permissions and
1:b681244:  * limitations under the License.
1:b681244:  */
1:b681244: package org.apache.carbondata.core.indexstore;
1:b681244: 
1:6094af6: import java.io.ByteArrayInputStream;
1:b681244: import java.io.DataInput;
1:6094af6: import java.io.DataInputStream;
1:b681244: import java.io.DataOutput;
1:b681244: import java.io.IOException;
1:b681244: import java.io.Serializable;
1:6094af6: import java.util.List;
1:b681244: 
1:531ecdf: import org.apache.carbondata.common.logging.LogService;
1:531ecdf: import org.apache.carbondata.common.logging.LogServiceFactory;
1:b681244: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
1:6094af6: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
1:f4a58c5: import org.apache.carbondata.core.util.BlockletDataMapUtil;
1:b681244: 
1:b681244: import org.apache.hadoop.io.Writable;
1:b681244: 
1:b681244: /**
1:b681244:  * Blocklet detail information to be sent to each executor
1:b681244:  */
1:b681244: public class BlockletDetailInfo implements Serializable, Writable {
1:b681244: 
1:531ecdf:   /**
1:531ecdf:    * LOGGER
1:531ecdf:    */
1:531ecdf:   private static final LogService LOGGER =
1:531ecdf:       LogServiceFactory.getLogService(BlockletDetailInfo.class.getName());
1:531ecdf: 
1:531ecdf:   private static final long serialVersionUID = 7957493757421513808L;
1:531ecdf: 
1:b681244:   private int rowCount;
1:b681244: 
1:b681244:   private short pagesCount;
1:b681244: 
1:b681244:   private short versionNumber;
1:b681244: 
1:0c8fa59:   private short blockletId;
1:b681244: 
1:b681244:   private int[] dimLens;
1:b681244: 
1:b681244:   private long schemaUpdatedTimeStamp;
1:b681244: 
1:b681244:   private BlockletInfo blockletInfo;
1:b681244: 
1:531ecdf:   private byte[] blockletInfoBinary;
1:531ecdf: 
1:6094af6:   private long blockFooterOffset;
1:6094af6: 
1:6094af6:   private List<ColumnSchema> columnSchemas;
1:6094af6: 
1:6094af6:   private byte[] columnSchemaBinary;
1:6094af6: 
1:44ffaf5:   private long blockSize;
1:6118711:   /**
1:6118711:    * flag to check for store from 1.1 or any prior version
1:6118711:    */
1:6118711:   private boolean isLegacyStore;
1:4df335f:   /**
1:4df335f:    * flag to check whether to serialize min max values. The flag will be set to true in case
1:4df335f:    * 1. When CACHE_LEVEL = BLOCKLET and filter column min/max in not cached in the driver using the
1:4df335f:    * property COLUMN_META_CACHE
1:4df335f:    * 2. for CACHE_LEVEL = BLOCK, it will always be true which is also the default value
1:4df335f:    */
1:4df335f:   private boolean useMinMaxForPruning = true;
1:44ffaf5: 
1:b681244:   public int getRowCount() {
1:b681244:     return rowCount;
2:b681244:   }
1:6094af6: 
1:b681244:   public void setRowCount(int rowCount) {
1:b681244:     this.rowCount = rowCount;
1:b681244:   }
1:6094af6: 
1:b681244:   public int getPagesCount() {
1:b681244:     return pagesCount;
1:b681244:   }
1:b681244: 
1:b681244:   public void setPagesCount(short pagesCount) {
1:b681244:     this.pagesCount = pagesCount;
1:b681244:   }
1:b681244: 
1:b681244:   public short getVersionNumber() {
1:b681244:     return versionNumber;
1:b681244:   }
1:b681244: 
1:b681244:   public void setVersionNumber(short versionNumber) {
1:b681244:     this.versionNumber = versionNumber;
1:b681244:   }
1:b681244: 
1:b681244:   public BlockletInfo getBlockletInfo() {
1:531ecdf:     if (null == blockletInfo) {
1:531ecdf:       try {
1:531ecdf:         setBlockletInfoFromBinary();
1:531ecdf:       } catch (IOException e) {
1:531ecdf:         throw new RuntimeException(e);
1:531ecdf:       }
1:531ecdf:     }
1:b681244:     return blockletInfo;
1:b681244:   }
1:b681244: 
1:b681244:   public void setBlockletInfo(BlockletInfo blockletInfo) {
1:b681244:     this.blockletInfo = blockletInfo;
1:b681244:   }
1:b681244: 
1:531ecdf:   private void setBlockletInfoFromBinary() throws IOException {
1:531ecdf:     if (null == this.blockletInfo && null != blockletInfoBinary && blockletInfoBinary.length > 0) {
1:531ecdf:       blockletInfo = new BlockletInfo();
1:531ecdf:       ByteArrayInputStream stream = new ByteArrayInputStream(blockletInfoBinary);
1:531ecdf:       DataInputStream inputStream = new DataInputStream(stream);
1:531ecdf:       try {
1:531ecdf:         blockletInfo.readFields(inputStream);
1:531ecdf:       } catch (IOException e) {
1:531ecdf:         LOGGER.error("Problem in reading blocklet info");
1:531ecdf:         throw new IOException("Problem in reading blocklet info." + e.getMessage());
1:531ecdf:       } finally {
1:531ecdf:         try {
1:531ecdf:           inputStream.close();
1:531ecdf:         } catch (IOException e) {
1:531ecdf:           LOGGER.error(e, "Problem in closing input stream of reading blocklet info.");
1:531ecdf:         }
1:531ecdf:       }
1:531ecdf:     }
1:531ecdf:   }
1:531ecdf: 
1:b681244:   public int[] getDimLens() {
1:b681244:     return dimLens;
1:b681244:   }
1:b681244: 
1:b681244:   public void setDimLens(int[] dimLens) {
1:b681244:     this.dimLens = dimLens;
1:b681244:   }
1:b681244: 
1:b681244:   public long getSchemaUpdatedTimeStamp() {
1:b681244:     return schemaUpdatedTimeStamp;
1:b681244:   }
1:b681244: 
1:b681244:   public void setSchemaUpdatedTimeStamp(long schemaUpdatedTimeStamp) {
1:b681244:     this.schemaUpdatedTimeStamp = schemaUpdatedTimeStamp;
1:b681244:   }
1:b681244: 
1:44ffaf5:   public long getBlockSize() {
1:44ffaf5:     return blockSize;
1:44ffaf5:   }
1:44ffaf5: 
1:44ffaf5:   public void setBlockSize(long blockSize) {
1:44ffaf5:     this.blockSize = blockSize;
1:44ffaf5:   }
1:44ffaf5: 
1:b681244:   @Override public void write(DataOutput out) throws IOException {
1:b681244:     out.writeInt(rowCount);
1:b681244:     out.writeShort(pagesCount);
1:b681244:     out.writeShort(versionNumber);
1:0c8fa59:     out.writeShort(blockletId);
1:b681244:     out.writeShort(dimLens.length);
1:b681244:     for (int i = 0; i < dimLens.length; i++) {
1:b681244:       out.writeInt(dimLens[i]);
1:b681244:     }
1:b681244:     out.writeLong(schemaUpdatedTimeStamp);
1:6094af6:     out.writeBoolean(blockletInfo != null);
1:6094af6:     if (blockletInfo != null) {
1:6094af6:       blockletInfo.write(out);
1:6094af6:     }
1:6094af6:     out.writeLong(blockFooterOffset);
1:f4a58c5:     // convert column schema list to binary format for serializing
1:f4a58c5:     convertColumnSchemaToBinary();
1:f4a58c5:     if (null != columnSchemaBinary) {
1:f4a58c5:       out.writeInt(columnSchemaBinary.length);
1:f4a58c5:       out.write(columnSchemaBinary);
1:f4a58c5:     } else {
1:f4a58c5:       // write -1 if columnSchemaBinary is null so that at the time of reading it can distinguish
1:f4a58c5:       // whether schema is written or not
1:f4a58c5:       out.writeInt(-1);
1:f4a58c5:     }
1:531ecdf:     out.writeInt(blockletInfoBinary.length);
1:531ecdf:     out.write(blockletInfoBinary);
1:44ffaf5:     out.writeLong(blockSize);
1:6118711:     out.writeBoolean(isLegacyStore);
1:4df335f:     out.writeBoolean(useMinMaxForPruning);
1:b681244:   }
1:b681244: 
1:b681244:   @Override public void readFields(DataInput in) throws IOException {
1:b681244:     rowCount = in.readInt();
1:b681244:     pagesCount = in.readShort();
1:b681244:     versionNumber = in.readShort();
1:0c8fa59:     blockletId = in.readShort();
1:b681244:     dimLens = new int[in.readShort()];
1:b681244:     for (int i = 0; i < dimLens.length; i++) {
1:b681244:       dimLens[i] = in.readInt();
1:6094af6:     }
1:b681244:     schemaUpdatedTimeStamp = in.readLong();
1:6094af6:     if (in.readBoolean()) {
1:6094af6:       blockletInfo = new BlockletInfo();
1:6094af6:       blockletInfo.readFields(in);
1:6094af6:     }
1:6094af6:     blockFooterOffset = in.readLong();
1:6094af6:     int bytesSize = in.readInt();
1:f4a58c5:     // if byteSize is -1 that means schema binary is not written
1:f4a58c5:     if (bytesSize != -1) {
1:f4a58c5:       byte[] schemaArray = new byte[bytesSize];
1:f4a58c5:       in.readFully(schemaArray);
1:f4a58c5:       readColumnSchema(schemaArray);
1:f4a58c5:     }
1:531ecdf:     int byteSize = in.readInt();
1:531ecdf:     blockletInfoBinary = new byte[byteSize];
1:531ecdf:     in.readFully(blockletInfoBinary);
1:531ecdf:     setBlockletInfoFromBinary();
1:44ffaf5:     blockSize = in.readLong();
1:6118711:     isLegacyStore = in.readBoolean();
1:4df335f:     useMinMaxForPruning = in.readBoolean();
1:6094af6:   }
1:6094af6: 
1:6094af6:   /**
1:6094af6:    * Read column schema from binary
1:6094af6:    * @param schemaArray
1:6094af6:    * @throws IOException
1:6094af6:    */
1:6094af6:   public void readColumnSchema(byte[] schemaArray) throws IOException {
1:dc29319:     if (null != schemaArray) {
1:f4a58c5:       columnSchemas = BlockletDataMapUtil.readColumnSchema(schemaArray);
1:f4a58c5:     }
1:f4a58c5:   }
1:f4a58c5: 
1:f4a58c5:   private void convertColumnSchemaToBinary() throws IOException {
1:f4a58c5:     if (null != columnSchemas) {
1:f4a58c5:       columnSchemaBinary = BlockletDataMapUtil.convertSchemaToBinary(columnSchemas);
1:f4a58c5:     }
1:6094af6:   }
1:6094af6: 
1:6094af6:   /**
1:6094af6:    * Create copy of BlockletDetailInfo
1:6094af6:    */
1:6094af6:   public BlockletDetailInfo copy() {
1:6094af6:     BlockletDetailInfo detailInfo = new BlockletDetailInfo();
1:6094af6:     detailInfo.rowCount = rowCount;
1:6094af6:     detailInfo.pagesCount = pagesCount;
1:6094af6:     detailInfo.versionNumber = versionNumber;
1:6094af6:     detailInfo.blockletId = blockletId;
1:6094af6:     detailInfo.dimLens = dimLens;
1:6094af6:     detailInfo.schemaUpdatedTimeStamp = schemaUpdatedTimeStamp;
1:6094af6:     detailInfo.blockletInfo = blockletInfo;
1:6118711:     detailInfo.blockletInfoBinary = blockletInfoBinary;
1:6094af6:     detailInfo.blockFooterOffset = blockFooterOffset;
1:6094af6:     detailInfo.columnSchemas = columnSchemas;
1:6118711:     detailInfo.columnSchemaBinary = columnSchemaBinary;
1:44ffaf5:     detailInfo.blockSize = blockSize;
1:6118711:     detailInfo.isLegacyStore = isLegacyStore;
1:4df335f:     detailInfo.useMinMaxForPruning = useMinMaxForPruning;
1:6094af6:     return detailInfo;
1:b681244:   }
1:b681244: 
1:0c8fa59:   public Short getBlockletId() {
1:0c8fa59:     return blockletId;
1:b681244:   }
1:0c8fa59: 
1:0c8fa59:   public void setBlockletId(Short blockletId) {
1:0c8fa59:     this.blockletId = blockletId;
1:6094af6:   }
1:6094af6: 
1:6094af6:   public long getBlockFooterOffset() {
1:6094af6:     return blockFooterOffset;
1:6094af6:   }
1:6094af6: 
1:6094af6:   public void setBlockFooterOffset(long blockFooterOffset) {
1:6094af6:     this.blockFooterOffset = blockFooterOffset;
1:6094af6:   }
1:6094af6: 
1:df5d7a9:   public List<ColumnSchema> getColumnSchemas() throws IOException {
1:df5d7a9:     if (columnSchemas == null && columnSchemaBinary != null) {
1:df5d7a9:       readColumnSchema(columnSchemaBinary);
1:df5d7a9:     }
1:6094af6:     return columnSchemas;
1:6094af6:   }
1:6094af6: 
1:6094af6:   public byte[] getColumnSchemaBinary() {
1:6094af6:     return columnSchemaBinary;
1:6094af6:   }
1:531ecdf: 
1:531ecdf:   public void setBlockletInfoBinary(byte[] blockletInfoBinary) {
1:531ecdf:     this.blockletInfoBinary = blockletInfoBinary;
1:531ecdf:   }
1:531ecdf: 
1:6118711:   public boolean isLegacyStore() {
1:6118711:     return isLegacyStore;
1:6118711:   }
1:6118711: 
1:6118711:   public void setLegacyStore(boolean legacyStore) {
1:6118711:     isLegacyStore = legacyStore;
1:6118711:   }
1:f4a58c5: 
1:f4a58c5:   public void setColumnSchemas(List<ColumnSchema> columnSchemas) {
1:f4a58c5:     this.columnSchemas = columnSchemas;
1:f4a58c5:   }
1:4df335f: 
1:4df335f:   public boolean isUseMinMaxForPruning() {
1:4df335f:     return useMinMaxForPruning;
1:4df335f:   }
1:4df335f: 
1:4df335f:   public void setUseMinMaxForPruning(boolean useMinMaxForPruning) {
1:4df335f:     this.useMinMaxForPruning = useMinMaxForPruning;
1:4df335f:   }
1:6094af6: }
============================================================================
author:manishgupta88
-------------------------------------------------------------------------------
commit:4df335f
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * flag to check whether to serialize min max values. The flag will be set to true in case
1:    * 1. When CACHE_LEVEL = BLOCKLET and filter column min/max in not cached in the driver using the
1:    * property COLUMN_META_CACHE
1:    * 2. for CACHE_LEVEL = BLOCK, it will always be true which is also the default value
1:    */
1:   private boolean useMinMaxForPruning = true;
/////////////////////////////////////////////////////////////////////////
1:     out.writeBoolean(useMinMaxForPruning);
/////////////////////////////////////////////////////////////////////////
1:     useMinMaxForPruning = in.readBoolean();
/////////////////////////////////////////////////////////////////////////
1:     detailInfo.useMinMaxForPruning = useMinMaxForPruning;
/////////////////////////////////////////////////////////////////////////
1: 
1:   public boolean isUseMinMaxForPruning() {
1:     return useMinMaxForPruning;
1:   }
1: 
1:   public void setUseMinMaxForPruning(boolean useMinMaxForPruning) {
1:     this.useMinMaxForPruning = useMinMaxForPruning;
1:   }
commit:dc29319
/////////////////////////////////////////////////////////////////////////
1:     if (null != schemaArray) {
commit:f4a58c5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.BlockletDataMapUtil;
/////////////////////////////////////////////////////////////////////////
1:     // convert column schema list to binary format for serializing
1:     convertColumnSchemaToBinary();
1:     if (null != columnSchemaBinary) {
1:       out.writeInt(columnSchemaBinary.length);
1:       out.write(columnSchemaBinary);
1:     } else {
1:       // write -1 if columnSchemaBinary is null so that at the time of reading it can distinguish
1:       // whether schema is written or not
1:       out.writeInt(-1);
1:     }
/////////////////////////////////////////////////////////////////////////
1:     // if byteSize is -1 that means schema binary is not written
1:     if (bytesSize != -1) {
1:       byte[] schemaArray = new byte[bytesSize];
1:       in.readFully(schemaArray);
1:       readColumnSchema(schemaArray);
1:     }
/////////////////////////////////////////////////////////////////////////
0:     if (null != columnSchemaBinary) {
1:       columnSchemas = BlockletDataMapUtil.readColumnSchema(schemaArray);
1:     }
1:   }
1: 
1:   private void convertColumnSchemaToBinary() throws IOException {
1:     if (null != columnSchemas) {
1:       columnSchemaBinary = BlockletDataMapUtil.convertSchemaToBinary(columnSchemas);
1:     }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
1:   public void setColumnSchemas(List<ColumnSchema> columnSchemas) {
1:     this.columnSchemas = columnSchemas;
1:   }
commit:6118711
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.indexstore.blockletindex.BlockDataMap;
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * flag to check for store from 1.1 or any prior version
1:    */
1:   private boolean isLegacyStore;
/////////////////////////////////////////////////////////////////////////
1:     out.writeBoolean(isLegacyStore);
/////////////////////////////////////////////////////////////////////////
1:     isLegacyStore = in.readBoolean();
/////////////////////////////////////////////////////////////////////////
0:     BlockDataMap blockDataMap = new BlockDataMap();
0:     columnSchemas = blockDataMap.readColumnSchema(schemaArray);
/////////////////////////////////////////////////////////////////////////
1:     detailInfo.blockletInfoBinary = blockletInfoBinary;
1:     detailInfo.columnSchemaBinary = columnSchemaBinary;
1:     detailInfo.isLegacyStore = isLegacyStore;
/////////////////////////////////////////////////////////////////////////
1:   public boolean isLegacyStore() {
1:     return isLegacyStore;
1:   }
1: 
1:   public void setLegacyStore(boolean legacyStore) {
1:     isLegacyStore = legacyStore;
1:   }
author:dhatchayani
-------------------------------------------------------------------------------
commit:531ecdf
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.indexstore.blockletindex.BlockletDataMap;
1:   /**
1:    * LOGGER
1:    */
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(BlockletDetailInfo.class.getName());
1: 
1:   private static final long serialVersionUID = 7957493757421513808L;
1: 
/////////////////////////////////////////////////////////////////////////
1:   private byte[] blockletInfoBinary;
1: 
/////////////////////////////////////////////////////////////////////////
1:     if (null == blockletInfo) {
1:       try {
1:         setBlockletInfoFromBinary();
1:       } catch (IOException e) {
1:         throw new RuntimeException(e);
1:       }
1:     }
/////////////////////////////////////////////////////////////////////////
1:   private void setBlockletInfoFromBinary() throws IOException {
1:     if (null == this.blockletInfo && null != blockletInfoBinary && blockletInfoBinary.length > 0) {
1:       blockletInfo = new BlockletInfo();
1:       ByteArrayInputStream stream = new ByteArrayInputStream(blockletInfoBinary);
1:       DataInputStream inputStream = new DataInputStream(stream);
1:       try {
1:         blockletInfo.readFields(inputStream);
1:       } catch (IOException e) {
1:         LOGGER.error("Problem in reading blocklet info");
1:         throw new IOException("Problem in reading blocklet info." + e.getMessage());
1:       } finally {
1:         try {
1:           inputStream.close();
1:         } catch (IOException e) {
1:           LOGGER.error(e, "Problem in closing input stream of reading blocklet info.");
1:         }
1:       }
1:     }
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     out.writeInt(blockletInfoBinary.length);
1:     out.write(blockletInfoBinary);
/////////////////////////////////////////////////////////////////////////
1:     int byteSize = in.readInt();
1:     blockletInfoBinary = new byte[byteSize];
1:     in.readFully(blockletInfoBinary);
1:     setBlockletInfoFromBinary();
/////////////////////////////////////////////////////////////////////////
0:     BlockletDataMap blockletDataMap = new BlockletDataMap();
0:     columnSchemas = blockletDataMap.readColumnSchema(schemaArray);
/////////////////////////////////////////////////////////////////////////
1: 
1:   public void setBlockletInfoBinary(byte[] blockletInfoBinary) {
1:     this.blockletInfoBinary = blockletInfoBinary;
1:   }
1: 
author:Jacky Li
-------------------------------------------------------------------------------
commit:df5d7a9
/////////////////////////////////////////////////////////////////////////
1:   public List<ColumnSchema> getColumnSchemas() throws IOException {
1:     if (columnSchemas == null && columnSchemaBinary != null) {
1:       readColumnSchema(columnSchemaBinary);
1:     }
commit:daa6465
/////////////////////////////////////////////////////////////////////////
author:ravipesala
-------------------------------------------------------------------------------
commit:44ffaf5
/////////////////////////////////////////////////////////////////////////
1:   private long blockSize;
1: 
/////////////////////////////////////////////////////////////////////////
1:   public long getBlockSize() {
1:     return blockSize;
1:   }
1: 
1:   public void setBlockSize(long blockSize) {
1:     this.blockSize = blockSize;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     out.writeLong(blockSize);
/////////////////////////////////////////////////////////////////////////
1:     blockSize = in.readLong();
/////////////////////////////////////////////////////////////////////////
1:     detailInfo.blockSize = blockSize;
commit:6094af6
/////////////////////////////////////////////////////////////////////////
1: import java.io.ByteArrayInputStream;
1: import java.io.DataInputStream;
0: import java.util.ArrayList;
1: import java.util.List;
1: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
0: import org.xerial.snappy.Snappy;
/////////////////////////////////////////////////////////////////////////
1:   private long blockFooterOffset;
1: 
1:   private List<ColumnSchema> columnSchemas;
1: 
1:   private byte[] columnSchemaBinary;
1: 
/////////////////////////////////////////////////////////////////////////
1:     out.writeBoolean(blockletInfo != null);
1:     if (blockletInfo != null) {
1:       blockletInfo.write(out);
1:     }
1:     out.writeLong(blockFooterOffset);
0:     out.writeInt(columnSchemaBinary.length);
0:     out.write(columnSchemaBinary);
/////////////////////////////////////////////////////////////////////////
1:     if (in.readBoolean()) {
1:       blockletInfo = new BlockletInfo();
1:       blockletInfo.readFields(in);
1:     }
1:     blockFooterOffset = in.readLong();
1:     int bytesSize = in.readInt();
0:     byte[] schemaArray = new byte[bytesSize];
0:     in.readFully(schemaArray);
0:     readColumnSchema(schemaArray);
1:   }
1: 
1:   /**
1:    * Read column schema from binary
1:    * @param schemaArray
1:    * @throws IOException
1:    */
1:   public void readColumnSchema(byte[] schemaArray) throws IOException {
0:     // uncompress it.
0:     schemaArray = Snappy.uncompress(schemaArray);
0:     ByteArrayInputStream schemaStream = new ByteArrayInputStream(schemaArray);
0:     DataInput schemaInput = new DataInputStream(schemaStream);
0:     columnSchemas = new ArrayList<>();
0:     int size = schemaInput.readShort();
0:     for (int i = 0; i < size; i++) {
0:       ColumnSchema columnSchema = new ColumnSchema();
0:       columnSchema.readFields(schemaInput);
0:       columnSchemas.add(columnSchema);
1:     }
1:   }
1: 
1:   /**
1:    * Create copy of BlockletDetailInfo
1:    */
1:   public BlockletDetailInfo copy() {
1:     BlockletDetailInfo detailInfo = new BlockletDetailInfo();
1:     detailInfo.rowCount = rowCount;
1:     detailInfo.pagesCount = pagesCount;
1:     detailInfo.versionNumber = versionNumber;
1:     detailInfo.blockletId = blockletId;
1:     detailInfo.dimLens = dimLens;
1:     detailInfo.schemaUpdatedTimeStamp = schemaUpdatedTimeStamp;
1:     detailInfo.blockletInfo = blockletInfo;
1:     detailInfo.blockFooterOffset = blockFooterOffset;
1:     detailInfo.columnSchemas = columnSchemas;
1:     return detailInfo;
/////////////////////////////////////////////////////////////////////////
1: 
1:   public long getBlockFooterOffset() {
1:     return blockFooterOffset;
1:   }
1: 
1:   public void setBlockFooterOffset(long blockFooterOffset) {
1:     this.blockFooterOffset = blockFooterOffset;
1:   }
1: 
0:   public List<ColumnSchema> getColumnSchemas() {
1:     return columnSchemas;
1:   }
1: 
0:   public void setColumnSchemas(List<ColumnSchema> columnSchemas) {
0:     this.columnSchemas = columnSchemas;
1:   }
1: 
0:   public void setColumnSchemaBinary(byte[] columnSchemaBinary) {
0:     this.columnSchemaBinary = columnSchemaBinary;
1:   }
1: 
1:   public byte[] getColumnSchemaBinary() {
1:     return columnSchemaBinary;
1:   }
commit:b681244
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.indexstore;
1: 
1: import java.io.DataInput;
1: import java.io.DataOutput;
1: import java.io.IOException;
1: import java.io.Serializable;
1: 
1: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
1: 
1: import org.apache.hadoop.io.Writable;
1: 
1: /**
1:  * Blocklet detail information to be sent to each executor
1:  */
1: public class BlockletDetailInfo implements Serializable, Writable {
1: 
1:   private int rowCount;
1: 
1:   private short pagesCount;
1: 
1:   private short versionNumber;
1: 
1:   private int[] dimLens;
1: 
1:   private long schemaUpdatedTimeStamp;
1: 
1:   private BlockletInfo blockletInfo;
1: 
1:   public int getRowCount() {
1:     return rowCount;
1:   }
1: 
1:   public void setRowCount(int rowCount) {
1:     this.rowCount = rowCount;
1:   }
1: 
1:   public int getPagesCount() {
1:     return pagesCount;
1:   }
1: 
1:   public void setPagesCount(short pagesCount) {
1:     this.pagesCount = pagesCount;
1:   }
1: 
1:   public short getVersionNumber() {
1:     return versionNumber;
1:   }
1: 
1:   public void setVersionNumber(short versionNumber) {
1:     this.versionNumber = versionNumber;
1:   }
1: 
1:   public BlockletInfo getBlockletInfo() {
1:     return blockletInfo;
1:   }
1: 
1:   public void setBlockletInfo(BlockletInfo blockletInfo) {
1:     this.blockletInfo = blockletInfo;
1:   }
1: 
1:   public int[] getDimLens() {
1:     return dimLens;
1:   }
1: 
1:   public void setDimLens(int[] dimLens) {
1:     this.dimLens = dimLens;
1:   }
1: 
1:   public long getSchemaUpdatedTimeStamp() {
1:     return schemaUpdatedTimeStamp;
1:   }
1: 
1:   public void setSchemaUpdatedTimeStamp(long schemaUpdatedTimeStamp) {
1:     this.schemaUpdatedTimeStamp = schemaUpdatedTimeStamp;
1:   }
1: 
1:   @Override public void write(DataOutput out) throws IOException {
1:     out.writeInt(rowCount);
1:     out.writeShort(pagesCount);
1:     out.writeShort(versionNumber);
1:     out.writeShort(dimLens.length);
1:     for (int i = 0; i < dimLens.length; i++) {
1:       out.writeInt(dimLens[i]);
1:     }
1:     out.writeLong(schemaUpdatedTimeStamp);
0:     blockletInfo.write(out);
1:   }
1: 
1:   @Override public void readFields(DataInput in) throws IOException {
1:     rowCount = in.readInt();
1:     pagesCount = in.readShort();
1:     versionNumber = in.readShort();
1:     dimLens = new int[in.readShort()];
1:     for (int i = 0; i < dimLens.length; i++) {
1:       dimLens[i] = in.readInt();
1:     }
1:     schemaUpdatedTimeStamp = in.readLong();
0:     blockletInfo = new BlockletInfo();
0:     blockletInfo.readFields(in);
1:   }
1: }
author:anubhav100
-------------------------------------------------------------------------------
commit:0c8fa59
/////////////////////////////////////////////////////////////////////////
1:   private short blockletId;
1: 
/////////////////////////////////////////////////////////////////////////
1:     out.writeShort(blockletId);
/////////////////////////////////////////////////////////////////////////
1:     blockletId = in.readShort();
/////////////////////////////////////////////////////////////////////////
0: 
1:   public Short getBlockletId() {
1:     return blockletId;
0:   }
0: 
1:   public void setBlockletId(Short blockletId) {
1:     this.blockletId = blockletId;
0:   }
============================================================================
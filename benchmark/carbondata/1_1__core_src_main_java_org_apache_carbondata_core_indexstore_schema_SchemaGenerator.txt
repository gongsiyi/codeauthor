1:6118711: /*
1:6118711:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:6118711:  * contributor license agreements.  See the NOTICE file distributed with
1:6118711:  * this work for additional information regarding copyright ownership.
1:6118711:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:6118711:  * (the "License"); you may not use this file except in compliance with
1:6118711:  * the License.  You may obtain a copy of the License at
1:6118711:  *
1:6118711:  *    http://www.apache.org/licenses/LICENSE-2.0
1:6118711:  *
1:6118711:  * Unless required by applicable law or agreed to in writing, software
1:6118711:  * distributed under the License is distributed on an "AS IS" BASIS,
1:6118711:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:6118711:  * See the License for the specific language governing permissions and
1:6118711:  * limitations under the License.
1:6118711:  */
1:6118711: 
1:6118711: package org.apache.carbondata.core.indexstore.schema;
1:6118711: 
1:6118711: import java.util.ArrayList;
1:6118711: import java.util.List;
1:6118711: 
1:6118711: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1:6118711: import org.apache.carbondata.core.memory.MemoryException;
1:6118711: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:dc29319: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1:dc29319: import org.apache.carbondata.core.util.BlockletDataMapUtil;
1:6118711: 
1:6118711: /**
1:6118711:  * class for creating schema for a given DataMap
1:6118711:  */
1:6118711: public class SchemaGenerator {
1:6118711: 
1:6118711:   /**
1:6118711:    * Method for creating blocklet Schema. Each blocklet row will share the same schema
1:6118711:    *
1:6118711:    * @param segmentProperties
1:6118711:    * @return
1:6118711:    */
1:dc29319:   public static CarbonRowSchema[] createBlockSchema(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonColumn> minMaxCacheColumns) {
1:6118711:     List<CarbonRowSchema> indexSchemas = new ArrayList<>();
1:6118711:     // get MinMax Schema
1:dc29319:     getMinMaxSchema(segmentProperties, indexSchemas, minMaxCacheColumns);
1:6118711:     // for number of rows.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.INT));
1:6118711:     // for table block path
1:6118711:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for version number.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:6118711:     // for schema updated time.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     // for block footer offset.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     // for locations
1:6118711:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for storing block length.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     CarbonRowSchema[] schema = indexSchemas.toArray(new CarbonRowSchema[indexSchemas.size()]);
1:6118711:     return schema;
1:6118711:   }
1:6118711: 
1:6118711:   /**
1:6118711:    * Method for creating blocklet Schema. Each blocklet row will share the same schema
1:6118711:    *
1:6118711:    * @param segmentProperties
1:6118711:    * @return
1:6118711:    */
1:dc29319:   public static CarbonRowSchema[] createBlockletSchema(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonColumn> minMaxCacheColumns) {
1:6118711:     List<CarbonRowSchema> indexSchemas = new ArrayList<>();
1:6118711:     // get MinMax Schema
1:dc29319:     getMinMaxSchema(segmentProperties, indexSchemas, minMaxCacheColumns);
1:6118711:     // for number of rows.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.INT));
1:6118711:     // for table block path
1:6118711:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for version number.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:6118711:     // for schema updated time.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     // for block footer offset.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     // for locations
1:6118711:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for storing block length.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:6118711:     //for blocklet info
1:6118711:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for number of pages.
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:6118711:     // for relative blocklet id i.e. blocklet id that belongs to a particular part file
1:6118711:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:6118711:     CarbonRowSchema[] schema = indexSchemas.toArray(new CarbonRowSchema[indexSchemas.size()]);
1:6118711:     return schema;
1:6118711:   }
1:6118711: 
1:6118711:   /**
1:6118711:    * Creates the schema to store summary information or the information which can be stored only
1:6118711:    * once per datamap. It stores datamap level max/min of each column and partition information of
1:6118711:    * datamap
1:6118711:    *
1:6118711:    * @param segmentProperties
1:6118711:    * @throws MemoryException
1:6118711:    */
1:6118711:   public static CarbonRowSchema[] createTaskSummarySchema(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonColumn> minMaxCacheColumns,
1:f4a58c5:       boolean storeBlockletCount, boolean filePathToBeStored) throws MemoryException {
1:6118711:     List<CarbonRowSchema> taskMinMaxSchemas = new ArrayList<>();
1:6118711:     // get MinMax Schema
1:dc29319:     getMinMaxSchema(segmentProperties, taskMinMaxSchemas, minMaxCacheColumns);
1:6118711:     // for storing file name
3:6118711:     taskMinMaxSchemas
1:f4a58c5:         .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     // for storing segmentid
1:6118711:     taskMinMaxSchemas
1:f4a58c5:         .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:f4a58c5:     // store path only in case of partition table or non transactional table
1:f4a58c5:     if (filePathToBeStored) {
1:f4a58c5:       // for storing file path
1:f4a58c5:       taskMinMaxSchemas
1:f4a58c5:           .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:f4a58c5:     }
1:6118711:     // flag to check whether it is required to store blocklet count of each carbondata file as
1:6118711:     // binary in summary schema. This will be true when it is not a legacy store (>1.1 version)
1:6118711:     // and CACHE_LEVEL=BLOCK
1:6118711:     if (storeBlockletCount) {
1:6118711:       taskMinMaxSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:6118711:     }
1:6118711:     CarbonRowSchema[] schema =
1:6118711:         taskMinMaxSchemas.toArray(new CarbonRowSchema[taskMinMaxSchemas.size()]);
1:6118711:     return schema;
1:6118711:   }
1:6118711: 
1:6118711:   /**
1:6118711:    * Method to create schema for storing min/max data
1:6118711:    *
1:6118711:    * @param segmentProperties
1:6118711:    * @param minMaxSchemas
1:6118711:    */
1:6118711:   private static void getMinMaxSchema(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonRowSchema> minMaxSchemas, List<CarbonColumn> minMaxCacheColumns) {
1:6118711:     // Index key
1:dc29319:     int[] minMaxLen = getMinMaxLength(segmentProperties, minMaxCacheColumns);
1:dc29319:     int[] columnOrdinals = getColumnOrdinalsToAccess(segmentProperties, minMaxCacheColumns);
1:6118711:     // do it 2 times, one for min and one for max.
1:6118711:     for (int k = 0; k < 2; k++) {
1:6118711:       CarbonRowSchema[] mapSchemas = new CarbonRowSchema[minMaxLen.length];
1:6118711:       for (int i = 0; i < minMaxLen.length; i++) {
1:6118711:         if (minMaxLen[i] <= 0) {
1:6118711:           boolean isVarchar = false;
1:dc29319:           if (columnOrdinals[i] < segmentProperties.getDimensions().size()
1:dc29319:               && segmentProperties.getDimensions().get(columnOrdinals[i]).getDataType()
1:dc29319:               == DataTypes.VARCHAR) {
1:6118711:             isVarchar = true;
1:6118711:           }
1:6118711:           mapSchemas[i] =
1:6118711:               new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY, isVarchar);
1:6118711:         } else {
1:6118711:           mapSchemas[i] =
1:6118711:               new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, minMaxLen[i]);
1:6118711:         }
1:6118711:       }
1:6118711:       CarbonRowSchema mapSchema =
1:6118711:           new CarbonRowSchema.StructCarbonRowSchema(DataTypes.createDefaultStructType(),
1:6118711:               mapSchemas);
1:6118711:       minMaxSchemas.add(mapSchema);
1:6118711:     }
1:6118711:   }
1:dc29319: 
1:dc29319:   /**
1:dc29319:    * Method to get the min max length of each column. It will return the length of only column
1:dc29319:    * which will be cached
1:dc29319:    *
1:dc29319:    * @param segmentProperties
1:dc29319:    * @param minMaxCacheColumns
1:dc29319:    * @return
1:dc29319:    */
1:dc29319:   private static int[] getMinMaxLength(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonColumn> minMaxCacheColumns) {
1:dc29319:     int[] minMaxLen = null;
1:dc29319:     if (null != minMaxCacheColumns) {
1:dc29319:       minMaxLen = new int[minMaxCacheColumns.size()];
1:dc29319:       int counter = 0;
1:dc29319:       for (CarbonColumn column : minMaxCacheColumns) {
1:dc29319:         minMaxLen[counter++] = segmentProperties.getColumnsValueSize()[BlockletDataMapUtil
1:dc29319:             .getColumnOrdinal(segmentProperties, column)];
1:dc29319:       }
1:dc29319:     } else {
1:dc29319:       minMaxLen = segmentProperties.getColumnsValueSize();
1:dc29319:     }
1:dc29319:     return minMaxLen;
1:dc29319:   }
1:dc29319: 
1:dc29319:   /**
1:dc29319:    * Method to fill the column ordinals to access based on the columns to be cached
1:dc29319:    *
1:dc29319:    * @param segmentProperties
1:dc29319:    * @param minMaxCacheColumns
1:dc29319:    * @return
1:dc29319:    */
1:dc29319:   private static int[] getColumnOrdinalsToAccess(SegmentProperties segmentProperties,
1:dc29319:       List<CarbonColumn> minMaxCacheColumns) {
1:dc29319:     int[] columnOrdinalsTOAccess = null;
1:dc29319:     if (null != minMaxCacheColumns) {
1:dc29319:       columnOrdinalsTOAccess = new int[minMaxCacheColumns.size()];
1:dc29319:       int counter = 0;
1:dc29319:       for (CarbonColumn column : minMaxCacheColumns) {
1:dc29319:         columnOrdinalsTOAccess[counter++] =
1:dc29319:             BlockletDataMapUtil.getColumnOrdinal(segmentProperties, column);
1:dc29319:       }
1:dc29319:     } else {
1:dc29319:       // when columns to cache is not specified then column access order will be same as the array
1:dc29319:       // index of min max length
1:dc29319:       columnOrdinalsTOAccess = new int[segmentProperties.getColumnsValueSize().length];
1:dc29319:       for (int i = 0; i < columnOrdinalsTOAccess.length; i++) {
1:dc29319:         columnOrdinalsTOAccess[i] = i;
1:dc29319:       }
1:dc29319:     }
1:dc29319:     return columnOrdinalsTOAccess;
1:dc29319:   }
1:6118711: }
============================================================================
author:manishgupta88
-------------------------------------------------------------------------------
commit:dc29319
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.schema.table.column.CarbonColumn;
1: import org.apache.carbondata.core.util.BlockletDataMapUtil;
/////////////////////////////////////////////////////////////////////////
1:   public static CarbonRowSchema[] createBlockSchema(SegmentProperties segmentProperties,
1:       List<CarbonColumn> minMaxCacheColumns) {
1:     getMinMaxSchema(segmentProperties, indexSchemas, minMaxCacheColumns);
/////////////////////////////////////////////////////////////////////////
1:   public static CarbonRowSchema[] createBlockletSchema(SegmentProperties segmentProperties,
1:       List<CarbonColumn> minMaxCacheColumns) {
1:     getMinMaxSchema(segmentProperties, indexSchemas, minMaxCacheColumns);
/////////////////////////////////////////////////////////////////////////
1:       List<CarbonColumn> minMaxCacheColumns,
1:     getMinMaxSchema(segmentProperties, taskMinMaxSchemas, minMaxCacheColumns);
/////////////////////////////////////////////////////////////////////////
1:       List<CarbonRowSchema> minMaxSchemas, List<CarbonColumn> minMaxCacheColumns) {
1:     int[] minMaxLen = getMinMaxLength(segmentProperties, minMaxCacheColumns);
1:     int[] columnOrdinals = getColumnOrdinalsToAccess(segmentProperties, minMaxCacheColumns);
1:           if (columnOrdinals[i] < segmentProperties.getDimensions().size()
1:               && segmentProperties.getDimensions().get(columnOrdinals[i]).getDataType()
1:               == DataTypes.VARCHAR) {
/////////////////////////////////////////////////////////////////////////
1: 
1:   /**
1:    * Method to get the min max length of each column. It will return the length of only column
1:    * which will be cached
1:    *
1:    * @param segmentProperties
1:    * @param minMaxCacheColumns
1:    * @return
1:    */
1:   private static int[] getMinMaxLength(SegmentProperties segmentProperties,
1:       List<CarbonColumn> minMaxCacheColumns) {
1:     int[] minMaxLen = null;
1:     if (null != minMaxCacheColumns) {
1:       minMaxLen = new int[minMaxCacheColumns.size()];
1:       int counter = 0;
1:       for (CarbonColumn column : minMaxCacheColumns) {
1:         minMaxLen[counter++] = segmentProperties.getColumnsValueSize()[BlockletDataMapUtil
1:             .getColumnOrdinal(segmentProperties, column)];
1:       }
1:     } else {
1:       minMaxLen = segmentProperties.getColumnsValueSize();
1:     }
1:     return minMaxLen;
1:   }
1: 
1:   /**
1:    * Method to fill the column ordinals to access based on the columns to be cached
1:    *
1:    * @param segmentProperties
1:    * @param minMaxCacheColumns
1:    * @return
1:    */
1:   private static int[] getColumnOrdinalsToAccess(SegmentProperties segmentProperties,
1:       List<CarbonColumn> minMaxCacheColumns) {
1:     int[] columnOrdinalsTOAccess = null;
1:     if (null != minMaxCacheColumns) {
1:       columnOrdinalsTOAccess = new int[minMaxCacheColumns.size()];
1:       int counter = 0;
1:       for (CarbonColumn column : minMaxCacheColumns) {
1:         columnOrdinalsTOAccess[counter++] =
1:             BlockletDataMapUtil.getColumnOrdinal(segmentProperties, column);
1:       }
1:     } else {
1:       // when columns to cache is not specified then column access order will be same as the array
1:       // index of min max length
1:       columnOrdinalsTOAccess = new int[segmentProperties.getColumnsValueSize().length];
1:       for (int i = 0; i < columnOrdinalsTOAccess.length; i++) {
1:         columnOrdinalsTOAccess[i] = i;
1:       }
1:     }
1:     return columnOrdinalsTOAccess;
1:   }
commit:f4a58c5
/////////////////////////////////////////////////////////////////////////
1:       boolean storeBlockletCount, boolean filePathToBeStored) throws MemoryException {
1:         .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:         .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // store path only in case of partition table or non transactional table
1:     if (filePathToBeStored) {
1:       // for storing file path
1:       taskMinMaxSchemas
1:           .add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     }
commit:6118711
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.core.indexstore.schema;
1: 
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.core.datastore.block.SegmentProperties;
1: import org.apache.carbondata.core.memory.MemoryException;
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1: 
1: /**
1:  * class for creating schema for a given DataMap
1:  */
1: public class SchemaGenerator {
1: 
1:   /**
1:    * Method for creating blocklet Schema. Each blocklet row will share the same schema
1:    *
1:    * @param segmentProperties
1:    * @return
1:    */
0:   public static CarbonRowSchema[] createBlockSchema(SegmentProperties segmentProperties) {
1:     List<CarbonRowSchema> indexSchemas = new ArrayList<>();
1:     // get MinMax Schema
0:     getMinMaxSchema(segmentProperties, indexSchemas);
1:     // for number of rows.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.INT));
1:     // for table block path
1:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // for version number.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:     // for schema updated time.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     // for block footer offset.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     // for locations
1:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // for storing block length.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     CarbonRowSchema[] schema = indexSchemas.toArray(new CarbonRowSchema[indexSchemas.size()]);
1:     return schema;
1:   }
1: 
1:   /**
1:    * Method for creating blocklet Schema. Each blocklet row will share the same schema
1:    *
1:    * @param segmentProperties
1:    * @return
1:    */
0:   public static CarbonRowSchema[] createBlockletSchema(SegmentProperties segmentProperties) {
1:     List<CarbonRowSchema> indexSchemas = new ArrayList<>();
1:     // get MinMax Schema
0:     getMinMaxSchema(segmentProperties, indexSchemas);
1:     // for number of rows.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.INT));
1:     // for table block path
1:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // for version number.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:     // for schema updated time.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     // for block footer offset.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     // for locations
1:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // for storing block length.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.LONG));
1:     //for blocklet info
1:     indexSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     // for number of pages.
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:     // for relative blocklet id i.e. blocklet id that belongs to a particular part file
1:     indexSchemas.add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.SHORT));
1:     CarbonRowSchema[] schema = indexSchemas.toArray(new CarbonRowSchema[indexSchemas.size()]);
1:     return schema;
1:   }
1: 
1:   /**
1:    * Creates the schema to store summary information or the information which can be stored only
1:    * once per datamap. It stores datamap level max/min of each column and partition information of
1:    * datamap
1:    *
1:    * @param segmentProperties
1:    * @throws MemoryException
1:    */
1:   public static CarbonRowSchema[] createTaskSummarySchema(SegmentProperties segmentProperties,
0:       byte[] schemaBinary, byte[] filePath, byte[] fileName, byte[] segmentId,
0:       boolean storeBlockletCount) throws MemoryException {
1:     List<CarbonRowSchema> taskMinMaxSchemas = new ArrayList<>();
1:     // get MinMax Schema
0:     getMinMaxSchema(segmentProperties, taskMinMaxSchemas);
0:     // for storing column schema
1:     taskMinMaxSchemas
0:         .add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, schemaBinary.length));
0:     // for storing file path
1:     taskMinMaxSchemas
0:         .add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, filePath.length));
1:     // for storing file name
1:     taskMinMaxSchemas
0:         .add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, fileName.length));
1:     // for storing segmentid
1:     taskMinMaxSchemas
0:         .add(new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, segmentId.length));
1:     // flag to check whether it is required to store blocklet count of each carbondata file as
1:     // binary in summary schema. This will be true when it is not a legacy store (>1.1 version)
1:     // and CACHE_LEVEL=BLOCK
1:     if (storeBlockletCount) {
1:       taskMinMaxSchemas.add(new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY));
1:     }
1:     CarbonRowSchema[] schema =
1:         taskMinMaxSchemas.toArray(new CarbonRowSchema[taskMinMaxSchemas.size()]);
1:     return schema;
1:   }
1: 
1:   /**
1:    * Method to create schema for storing min/max data
1:    *
1:    * @param segmentProperties
1:    * @param minMaxSchemas
1:    */
1:   private static void getMinMaxSchema(SegmentProperties segmentProperties,
0:       List<CarbonRowSchema> minMaxSchemas) {
1:     // Index key
0:     int[] minMaxLen = segmentProperties.getColumnsValueSize();
1:     // do it 2 times, one for min and one for max.
1:     for (int k = 0; k < 2; k++) {
1:       CarbonRowSchema[] mapSchemas = new CarbonRowSchema[minMaxLen.length];
1:       for (int i = 0; i < minMaxLen.length; i++) {
1:         if (minMaxLen[i] <= 0) {
1:           boolean isVarchar = false;
0:           if (i < segmentProperties.getDimensions().size()
0:               && segmentProperties.getDimensions().get(i).getDataType() == DataTypes.VARCHAR) {
1:             isVarchar = true;
1:           }
1:           mapSchemas[i] =
1:               new CarbonRowSchema.VariableCarbonRowSchema(DataTypes.BYTE_ARRAY, isVarchar);
1:         } else {
1:           mapSchemas[i] =
1:               new CarbonRowSchema.FixedCarbonRowSchema(DataTypes.BYTE_ARRAY, minMaxLen[i]);
1:         }
1:       }
1:       CarbonRowSchema mapSchema =
1:           new CarbonRowSchema.StructCarbonRowSchema(DataTypes.createDefaultStructType(),
1:               mapSchemas);
1:       minMaxSchemas.add(mapSchema);
1:     }
1:   }
1: }
============================================================================
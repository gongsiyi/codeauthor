1:5c483f3: /*
1:5c483f3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:5c483f3:  * contributor license agreements.  See the NOTICE file distributed with
1:5c483f3:  * this work for additional information regarding copyright ownership.
1:5c483f3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:5c483f3:  * (the "License"); you may not use this file except in compliance with
1:5c483f3:  * the License.  You may obtain a copy of the License at
1:5c483f3:  *
1:5c483f3:  *    http://www.apache.org/licenses/LICENSE-2.0
1:5c483f3:  *
1:5c483f3:  * Unless required by applicable law or agreed to in writing, software
1:5c483f3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:5c483f3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:5c483f3:  * See the License for the specific language governing permissions and
1:5c483f3:  * limitations under the License.
1:5c483f3:  */
1:5c483f3: package org.apache.carbondata.core.scan.collector.impl;
1:5c483f3: 
1:5c483f3: import java.nio.charset.Charset;
1:5c483f3: import java.util.ArrayList;
1:5c483f3: import java.util.List;
1:5c483f3: 
1:5c483f3: import org.apache.carbondata.common.annotations.InterfaceAudience;
1:5c483f3: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:5c483f3: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1:5c483f3: import org.apache.carbondata.core.scan.model.ProjectionMeasure;
1:5c483f3: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1:5c483f3: import org.apache.carbondata.core.scan.wrappers.ByteArrayWrapper;
1:5c483f3: import org.apache.carbondata.core.stats.QueryStatistic;
1:5c483f3: import org.apache.carbondata.core.stats.QueryStatisticsConstants;
1:5c483f3: 
1:5c483f3: /**
1:5c483f3:  * It is not a collector it is just a scanned result holder.
1:5c483f3:  * most of the lines are copyied from `RawBasedResultCollector`, the difference in function is that
1:5c483f3:  * this class return all the dimensions in a ByteArrayWrapper and append blockletNo/PageId/RowId at
1:5c483f3:  * end of the row.
1:5c483f3:  * This implementation refers to `RawBasedResultCollector` and `RowIdBaedResultCollector`
1:5c483f3:  */
1:5c483f3: @InterfaceAudience.Internal
1:5c483f3: public class RowIdRawBasedResultCollector extends AbstractScannedResultCollector {
1:5c483f3: 
1:5c483f3:   public RowIdRawBasedResultCollector(BlockExecutionInfo blockExecutionInfos) {
1:5c483f3:     super(blockExecutionInfos);
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   /**
1:5c483f3:    * This method will add a record both key and value to list object
1:5c483f3:    * it will keep track of how many record is processed, to handle limit scenario
1:5c483f3:    */
1:5c483f3:   @Override
1:5c483f3:   public List<Object[]> collectResultInRow(BlockletScannedResult scannedResult,
1:5c483f3:       int batchSize) {
1:5c483f3:     long startTime = System.currentTimeMillis();
1:5c483f3:     List<Object[]> listBasedResult = new ArrayList<>(batchSize);
1:5c483f3:     ProjectionMeasure[] queryMeasures = executionInfo.getProjectionMeasures();
1:5c483f3:     // scan the record and add to list
1:5c483f3:     scanAndFillData(scannedResult, batchSize, listBasedResult, queryMeasures);
1:5c483f3:     QueryStatistic resultPrepTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:5c483f3:         .get(QueryStatisticsConstants.RESULT_PREP_TIME);
1:5c483f3:     resultPrepTime.addCountStatistic(QueryStatisticsConstants.RESULT_PREP_TIME,
1:5c483f3:         resultPrepTime.getCount() + (System.currentTimeMillis() - startTime));
1:5c483f3:     return listBasedResult;
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   /**
1:5c483f3:    * This method will scan and fill dimension and measure data
1:5c483f3:    *
1:5c483f3:    * @param scannedResult
1:5c483f3:    * @param batchSize
1:5c483f3:    * @param listBasedResult
1:5c483f3:    * @param queryMeasures
1:5c483f3:    */
1:5c483f3:   protected void scanAndFillData(BlockletScannedResult scannedResult, int batchSize,
1:5c483f3:       List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures) {
1:5c483f3:     int numberOfPages = scannedResult.numberOfpages();
1:5c483f3:     // loop will exit once the batchSize data has been read or the pages have been exhausted
1:5c483f3:     while (scannedResult.getCurrentPageCounter() < numberOfPages) {
1:5c483f3:       int currentPageRowCount = scannedResult.getCurrentPageRowCount();
1:5c483f3:       if (currentPageRowCount == 0) {
1:5c483f3:         scannedResult.incrementPageCounter();
1:5c483f3:         continue;
1:5c483f3:       }
1:5c483f3:       int rowCounter = scannedResult.getRowCounter();
1:5c483f3:       // getRowCounter holds total number rows processed. Calculate the
1:5c483f3:       // Left over space through getRowCounter only.
1:5c483f3:       int availableRows = currentPageRowCount - rowCounter;
1:5c483f3:       // rows available in current page that can be processed from current page
1:5c483f3:       int availableBatchRowCount = Math.min(batchSize, availableRows);
1:5c483f3:       // this condition will be true if no data left in the current block/blocklet to be scanned
1:5c483f3:       if (availableBatchRowCount < 1) {
1:5c483f3:         break;
1:5c483f3:       }
1:5c483f3:       if (batchSize > availableRows) {
1:5c483f3:         batchSize = batchSize - availableRows;
1:5c483f3:       } else {
1:5c483f3:         // this is done because in IUD cases actuals rows fetch can be less than batch size as
1:5c483f3:         // some of the rows could have deleted. So in those cases batchSize need to be
1:5c483f3:         // re initialized with left over value
1:5c483f3:         batchSize = 0;
1:5c483f3:       }
1:5c483f3:       // for every iteration of available rows filling newly created list of Object[] and add it to
1:5c483f3:       // the final list so there is no mismatch in the counter while filling dimension and
1:5c483f3:       // measure data
1:5c483f3:       List<Object[]> collectedData = new ArrayList<>(availableBatchRowCount);
1:5c483f3:       // fill dimension data
1:5c483f3:       fillDimensionData(scannedResult, collectedData, queryMeasures, availableBatchRowCount);
1:5c483f3:       fillMeasureData(scannedResult, collectedData);
1:5c483f3:       // increment the number of rows scanned in scanned result statistics
1:5c483f3:       // incrementScannedResultRowCounter(scannedResult, availableBatchRowCount);
1:5c483f3:       // assign the left over rows to batch size if the number of rows fetched are lesser
1:5c483f3:       // than batchSize
1:5c483f3:       if (collectedData.size() < availableBatchRowCount) {
1:5c483f3:         batchSize += availableBatchRowCount - listBasedResult.size();
1:5c483f3:       }
1:5c483f3:       // add the collected data to the final list
1:5c483f3:       listBasedResult.addAll(collectedData);
1:5c483f3:     }
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   private void fillDimensionData(BlockletScannedResult scannedResult,
1:5c483f3:       List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures, int batchSize) {
1:5c483f3:     long startTime = System.currentTimeMillis();
1:5c483f3:     List<byte[]> dictionaryKeyArrayBatch = scannedResult.getDictionaryKeyArrayBatch(batchSize);
1:5c483f3:     List<byte[][]> noDictionaryKeyArrayBatch =
1:5c483f3:         scannedResult.getNoDictionaryKeyArrayBatch(batchSize);
1:5c483f3:     List<byte[][]> complexTypeKeyArrayBatch = scannedResult.getComplexTypeKeyArrayBatch(batchSize);
1:5c483f3:     // it will same for one blocklet so can be computed only once
1:5c483f3:     byte[] implicitColumnByteArray = scannedResult.getBlockletId()
1:5c483f3:         .getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET));
1:5c483f3:     // Note: size check in for loop is for dictionaryKeyArrayBatch as this size can be lesser than
1:5c483f3:     // batch size in case of IUD scenarios
1:5c483f3:     for (int i = 0; i < dictionaryKeyArrayBatch.size(); i++) {
1:5c483f3:       // 1 for ByteArrayWrapper object which will contain dictionary and no dictionary data
1:5c483f3:       // 3 for blockletId, pageId, rowId
1:5c483f3:       Object[] row = new Object[1 + queryMeasures.length + 3];
1:5c483f3:       scannedResult.incrementCounter();
1:8952394:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
1:5c483f3:       row[1 + queryMeasures.length + 1] = scannedResult.getCurrentPageCounter();
1:5c483f3:       ByteArrayWrapper wrapper = new ByteArrayWrapper();
1:5c483f3:       wrapper.setDictionaryKey(dictionaryKeyArrayBatch.get(i));
1:5c483f3:       wrapper.setNoDictionaryKeys(noDictionaryKeyArrayBatch.get(i));
1:5c483f3:       wrapper.setComplexTypesKeys(complexTypeKeyArrayBatch.get(i));
1:5c483f3:       wrapper.setImplicitColumnByteArray(implicitColumnByteArray);
1:5c483f3:       row[0] = wrapper;
1:5c483f3:       row[1 + queryMeasures.length + 2] = scannedResult.getCurrentRowId();
1:5c483f3:       listBasedResult.add(row);
1:5c483f3:     }
1:5c483f3:     QueryStatistic keyColumnFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:5c483f3:         .get(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME);
1:5c483f3:     keyColumnFillingTime.addCountStatistic(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME,
1:5c483f3:         keyColumnFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   private void fillMeasureData(BlockletScannedResult scannedResult,
1:5c483f3:       List<Object[]> listBasedResult) {
1:5c483f3:     long startTime = System.currentTimeMillis();
1:5c483f3:     // if list is not empty after filling the dimension data then only fill the measure data
1:5c483f3:     if (!listBasedResult.isEmpty()) {
1:5c483f3:       fillMeasureDataBatch(listBasedResult, 1, scannedResult);
1:5c483f3:     }
1:5c483f3:     QueryStatistic measureFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:5c483f3:         .get(QueryStatisticsConstants.MEASURE_FILLING_TIME);
1:5c483f3:     measureFillingTime.addCountStatistic(QueryStatisticsConstants.MEASURE_FILLING_TIME,
1:5c483f3:         measureFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:5c483f3:   }
1:5c483f3: 
1:5c483f3:   private void incrementScannedResultRowCounter(BlockletScannedResult scannedResult,
1:5c483f3:       int batchSize) {
1:5c483f3:     // increment row counter by batch size as those many number of rows have been processed at once
1:5c483f3:     scannedResult.incrementCounter(batchSize);
1:5c483f3:   }
1:5c483f3: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:8952394
/////////////////////////////////////////////////////////////////////////
1:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
author:Manhua
-------------------------------------------------------------------------------
commit:ce53b48
/////////////////////////////////////////////////////////////////////////
0:       row[1 + queryMeasures.length] = Integer.parseInt(scannedResult.getBlockletNumber());
author:xuchuanyin
-------------------------------------------------------------------------------
commit:5c483f3
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.scan.collector.impl;
1: 
1: import java.nio.charset.Charset;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import org.apache.carbondata.common.annotations.InterfaceAudience;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.scan.executor.infos.BlockExecutionInfo;
1: import org.apache.carbondata.core.scan.model.ProjectionMeasure;
1: import org.apache.carbondata.core.scan.result.BlockletScannedResult;
1: import org.apache.carbondata.core.scan.wrappers.ByteArrayWrapper;
1: import org.apache.carbondata.core.stats.QueryStatistic;
1: import org.apache.carbondata.core.stats.QueryStatisticsConstants;
1: 
1: /**
1:  * It is not a collector it is just a scanned result holder.
1:  * most of the lines are copyied from `RawBasedResultCollector`, the difference in function is that
1:  * this class return all the dimensions in a ByteArrayWrapper and append blockletNo/PageId/RowId at
1:  * end of the row.
1:  * This implementation refers to `RawBasedResultCollector` and `RowIdBaedResultCollector`
1:  */
1: @InterfaceAudience.Internal
1: public class RowIdRawBasedResultCollector extends AbstractScannedResultCollector {
1: 
1:   public RowIdRawBasedResultCollector(BlockExecutionInfo blockExecutionInfos) {
1:     super(blockExecutionInfos);
1:   }
1: 
1:   /**
1:    * This method will add a record both key and value to list object
1:    * it will keep track of how many record is processed, to handle limit scenario
1:    */
1:   @Override
1:   public List<Object[]> collectResultInRow(BlockletScannedResult scannedResult,
1:       int batchSize) {
1:     long startTime = System.currentTimeMillis();
1:     List<Object[]> listBasedResult = new ArrayList<>(batchSize);
1:     ProjectionMeasure[] queryMeasures = executionInfo.getProjectionMeasures();
1:     // scan the record and add to list
1:     scanAndFillData(scannedResult, batchSize, listBasedResult, queryMeasures);
1:     QueryStatistic resultPrepTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:         .get(QueryStatisticsConstants.RESULT_PREP_TIME);
1:     resultPrepTime.addCountStatistic(QueryStatisticsConstants.RESULT_PREP_TIME,
1:         resultPrepTime.getCount() + (System.currentTimeMillis() - startTime));
1:     return listBasedResult;
1:   }
1: 
1:   /**
1:    * This method will scan and fill dimension and measure data
1:    *
1:    * @param scannedResult
1:    * @param batchSize
1:    * @param listBasedResult
1:    * @param queryMeasures
1:    */
1:   protected void scanAndFillData(BlockletScannedResult scannedResult, int batchSize,
1:       List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures) {
1:     int numberOfPages = scannedResult.numberOfpages();
1:     // loop will exit once the batchSize data has been read or the pages have been exhausted
1:     while (scannedResult.getCurrentPageCounter() < numberOfPages) {
1:       int currentPageRowCount = scannedResult.getCurrentPageRowCount();
1:       if (currentPageRowCount == 0) {
1:         scannedResult.incrementPageCounter();
1:         continue;
1:       }
1:       int rowCounter = scannedResult.getRowCounter();
1:       // getRowCounter holds total number rows processed. Calculate the
1:       // Left over space through getRowCounter only.
1:       int availableRows = currentPageRowCount - rowCounter;
1:       // rows available in current page that can be processed from current page
1:       int availableBatchRowCount = Math.min(batchSize, availableRows);
1:       // this condition will be true if no data left in the current block/blocklet to be scanned
1:       if (availableBatchRowCount < 1) {
1:         break;
1:       }
1:       if (batchSize > availableRows) {
1:         batchSize = batchSize - availableRows;
1:       } else {
1:         // this is done because in IUD cases actuals rows fetch can be less than batch size as
1:         // some of the rows could have deleted. So in those cases batchSize need to be
1:         // re initialized with left over value
1:         batchSize = 0;
1:       }
1:       // for every iteration of available rows filling newly created list of Object[] and add it to
1:       // the final list so there is no mismatch in the counter while filling dimension and
1:       // measure data
1:       List<Object[]> collectedData = new ArrayList<>(availableBatchRowCount);
1:       // fill dimension data
1:       fillDimensionData(scannedResult, collectedData, queryMeasures, availableBatchRowCount);
1:       fillMeasureData(scannedResult, collectedData);
1:       // increment the number of rows scanned in scanned result statistics
1:       // incrementScannedResultRowCounter(scannedResult, availableBatchRowCount);
1:       // assign the left over rows to batch size if the number of rows fetched are lesser
1:       // than batchSize
1:       if (collectedData.size() < availableBatchRowCount) {
1:         batchSize += availableBatchRowCount - listBasedResult.size();
1:       }
1:       // add the collected data to the final list
1:       listBasedResult.addAll(collectedData);
1:     }
1:   }
1: 
1:   private void fillDimensionData(BlockletScannedResult scannedResult,
1:       List<Object[]> listBasedResult, ProjectionMeasure[] queryMeasures, int batchSize) {
1:     long startTime = System.currentTimeMillis();
1:     List<byte[]> dictionaryKeyArrayBatch = scannedResult.getDictionaryKeyArrayBatch(batchSize);
1:     List<byte[][]> noDictionaryKeyArrayBatch =
1:         scannedResult.getNoDictionaryKeyArrayBatch(batchSize);
1:     List<byte[][]> complexTypeKeyArrayBatch = scannedResult.getComplexTypeKeyArrayBatch(batchSize);
1:     // it will same for one blocklet so can be computed only once
1:     byte[] implicitColumnByteArray = scannedResult.getBlockletId()
1:         .getBytes(Charset.forName(CarbonCommonConstants.DEFAULT_CHARSET));
1:     // Note: size check in for loop is for dictionaryKeyArrayBatch as this size can be lesser than
1:     // batch size in case of IUD scenarios
1:     for (int i = 0; i < dictionaryKeyArrayBatch.size(); i++) {
1:       // 1 for ByteArrayWrapper object which will contain dictionary and no dictionary data
1:       // 3 for blockletId, pageId, rowId
1:       Object[] row = new Object[1 + queryMeasures.length + 3];
1:       scannedResult.incrementCounter();
0:       row[1 + queryMeasures.length] = scannedResult.getBlockletNumber();
1:       row[1 + queryMeasures.length + 1] = scannedResult.getCurrentPageCounter();
1:       ByteArrayWrapper wrapper = new ByteArrayWrapper();
1:       wrapper.setDictionaryKey(dictionaryKeyArrayBatch.get(i));
1:       wrapper.setNoDictionaryKeys(noDictionaryKeyArrayBatch.get(i));
1:       wrapper.setComplexTypesKeys(complexTypeKeyArrayBatch.get(i));
1:       wrapper.setImplicitColumnByteArray(implicitColumnByteArray);
1:       row[0] = wrapper;
1:       row[1 + queryMeasures.length + 2] = scannedResult.getCurrentRowId();
1:       listBasedResult.add(row);
1:     }
1:     QueryStatistic keyColumnFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:         .get(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME);
1:     keyColumnFillingTime.addCountStatistic(QueryStatisticsConstants.KEY_COLUMN_FILLING_TIME,
1:         keyColumnFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:   }
1: 
1:   private void fillMeasureData(BlockletScannedResult scannedResult,
1:       List<Object[]> listBasedResult) {
1:     long startTime = System.currentTimeMillis();
1:     // if list is not empty after filling the dimension data then only fill the measure data
1:     if (!listBasedResult.isEmpty()) {
1:       fillMeasureDataBatch(listBasedResult, 1, scannedResult);
1:     }
1:     QueryStatistic measureFillingTime = queryStatisticsModel.getStatisticsTypeAndObjMap()
1:         .get(QueryStatisticsConstants.MEASURE_FILLING_TIME);
1:     measureFillingTime.addCountStatistic(QueryStatisticsConstants.MEASURE_FILLING_TIME,
1:         measureFillingTime.getCount() + (System.currentTimeMillis() - startTime));
1:   }
1: 
1:   private void incrementScannedResultRowCounter(BlockletScannedResult scannedResult,
1:       int batchSize) {
1:     // increment row counter by batch size as those many number of rows have been processed at once
1:     scannedResult.incrementCounter(batchSize);
1:   }
1: }
============================================================================
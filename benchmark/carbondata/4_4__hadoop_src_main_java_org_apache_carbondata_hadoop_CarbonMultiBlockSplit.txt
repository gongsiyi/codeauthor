1:5f6a56c: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
1:5f6a56c:  *
1:5f6a56c:  *    http://www.apache.org/licenses/LICENSE-2.0
1:5f6a56c:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
1:5f6a56c:  */
1:5f6a56c: 
1:5f6a56c: package org.apache.carbondata.hadoop;
1:5f6a56c: 
1:5f6a56c: import java.io.DataInput;
1:5f6a56c: import java.io.DataOutput;
1:5f6a56c: import java.io.IOException;
1:3ff574d: import java.io.Serializable;
1:5f6a56c: import java.util.ArrayList;
1:44ffaf5: import java.util.HashMap;
1:5f6a56c: import java.util.List;
1:44ffaf5: import java.util.Map;
1:5f6a56c: 
1:3ff574d: import org.apache.carbondata.core.datastore.block.Distributable;
1:d7393da: import org.apache.carbondata.core.statusmanager.FileFormat;
1:5f6a56c: 
1:5f6a56c: import org.apache.hadoop.io.Writable;
1:5f6a56c: import org.apache.hadoop.mapreduce.InputSplit;
1:5f6a56c: 
1:5f6a56c: /**
1:5f6a56c:  * This class wraps multiple blocks belong to a same node to one split.
1:5f6a56c:  * So the scanning task will scan multiple blocks. This is an optimization for concurrent query.
1:5f6a56c:  */
1:3ff574d: public class CarbonMultiBlockSplit extends InputSplit implements Serializable, Writable {
1:5f6a56c: 
1:5f6a56c:   /*
1:5f6a56c:    * Splits (HDFS Blocks) for task to scan.
1:5f6a56c:    */
1:5f6a56c:   private List<CarbonInputSplit> splitList;
1:5f6a56c: 
1:5f6a56c:   /*
1:cbf8797:    * The locations of all wrapped splits
1:5f6a56c:    */
1:cbf8797:   private String[] locations;
1:d7393da: 
1:ee71610:   private FileFormat fileFormat = FileFormat.COLUMNAR_V3;
1:5f6a56c: 
1:694ee77:   private long length;
1:694ee77: 
1:5f6a56c:   public CarbonMultiBlockSplit() {
1:5f6a56c:     splitList = null;
1:cbf8797:     locations = null;
1:694ee77:     length = 0;
1:5f6a56c:   }
1:5f6a56c: 
1:3ff574d:   public CarbonMultiBlockSplit(List<Distributable> blocks, String hostname) {
1:3ff574d:     this.splitList = new ArrayList<>(blocks.size());
1:3ff574d:     for (Distributable block : blocks) {
1:3ff574d:       this.splitList.add((CarbonInputSplit)block);
1:3ff574d:     }
1:3ff574d:     this.locations = new String[]{hostname};
1:3ff574d:   }
1:3ff574d: 
1:44ffaf5:   public CarbonMultiBlockSplit(List<CarbonInputSplit> splitList,
1:44ffaf5:       String[] locations) {
1:5f6a56c:     this.splitList = splitList;
1:cbf8797:     this.locations = locations;
1:694ee77:     calculateLength();
1:5f6a56c:   }
1:5f6a56c: 
1:44ffaf5:   public CarbonMultiBlockSplit(List<CarbonInputSplit> splitList,
1:44ffaf5:       String[] locations, FileFormat fileFormat) {
1:d7393da:     this.splitList = splitList;
1:d7393da:     this.locations = locations;
1:d7393da:     this.fileFormat = fileFormat;
1:694ee77:     calculateLength();
1:d7393da:   }
1:d7393da: 
1:5f6a56c:   /**
1:5f6a56c:    * Return all splits for scan
1:5f6a56c:    * @return split list for scan
1:5f6a56c:    */
1:5f6a56c:   public List<CarbonInputSplit> getAllSplits() {
1:5f6a56c:     return splitList;
1:5f6a56c:   }
1:5f6a56c: 
1:5f6a56c:   @Override
1:44ffaf5:   public long getLength() {
1:694ee77:     return length;
1:694ee77:   }
1:694ee77: 
1:694ee77:   public void setLength(long length) {
1:694ee77:     this.length = length;
1:694ee77:   }
1:694ee77: 
1:d5bec4d:   public void calculateLength() {
1:5f6a56c:     long total = 0;
1:44ffaf5:     if (splitList.size() > 0 && splitList.get(0).getDetailInfo() != null) {
1:44ffaf5:       Map<String, Long> blockSizes = new HashMap<>();
1:694ee77:       for (CarbonInputSplit split : splitList) {
1:44ffaf5:         blockSizes.put(split.getBlockPath(), split.getDetailInfo().getBlockSize());
1:44ffaf5:       }
1:44ffaf5:       for (Map.Entry<String, Long> entry : blockSizes.entrySet()) {
1:44ffaf5:         total += entry.getValue();
1:44ffaf5:       }
1:44ffaf5:     } else {
2:44ffaf5:       for (CarbonInputSplit split : splitList) {
1:44ffaf5:         total += split.getLength();
1:44ffaf5:       }
1:5f6a56c:     }
1:694ee77:     length = total;
1:5f6a56c:   }
1:5f6a56c: 
1:5f6a56c:   @Override
1:44ffaf5:   public String[] getLocations() {
1:cbf8797:     return locations;
1:5f6a56c:   }
1:5f6a56c: 
1:5f6a56c:   @Override
1:5f6a56c:   public void write(DataOutput out) throws IOException {
1:5f6a56c:     // write number of splits and then write all splits
1:5f6a56c:     out.writeInt(splitList.size());
1:5f6a56c:     for (CarbonInputSplit split: splitList) {
1:5f6a56c:       split.write(out);
1:5f6a56c:     }
1:cbf8797:     out.writeInt(locations.length);
1:cbf8797:     for (int i = 0; i < locations.length; i++) {
1:cbf8797:       out.writeUTF(locations[i]);
1:cbf8797:     }
1:d7393da:     out.writeInt(fileFormat.ordinal());
1:5f6a56c:   }
1:5f6a56c: 
1:5f6a56c:   @Override
1:5f6a56c:   public void readFields(DataInput in) throws IOException {
1:5f6a56c:     // read all splits
1:5f6a56c:     int numSplit = in.readInt();
1:5f6a56c:     splitList = new ArrayList<>(numSplit);
1:5f6a56c:     for (int i = 0; i < numSplit; i++) {
1:5f6a56c:       CarbonInputSplit split = new CarbonInputSplit();
1:5f6a56c:       split.readFields(in);
1:5f6a56c:       splitList.add(split);
1:5f6a56c:     }
1:cbf8797:     int len = in.readInt();
1:cbf8797:     locations = new String[len];
1:cbf8797:     for (int i = 0; i < len; i++) {
1:cbf8797:       locations[i] = in.readUTF();
1:cbf8797:     }
1:d7393da:     fileFormat = FileFormat.getByOrdinal(in.readInt());
1:5f6a56c:   }
1:5f6a56c: 
1:d7393da:   public FileFormat getFileFormat() {
1:d7393da:     return fileFormat;
1:d7393da:   }
1:d7393da: 
1:d7393da:   public void setFileFormat(FileFormat fileFormat) {
1:d7393da:     this.fileFormat = fileFormat;
1:d7393da:   }
1:5f6a56c: }
============================================================================
author:Jacky Li
-------------------------------------------------------------------------------
commit:3ff574d
/////////////////////////////////////////////////////////////////////////
1: import java.io.Serializable;
1: import org.apache.carbondata.core.datastore.block.Distributable;
/////////////////////////////////////////////////////////////////////////
1: public class CarbonMultiBlockSplit extends InputSplit implements Serializable, Writable {
/////////////////////////////////////////////////////////////////////////
1:   public CarbonMultiBlockSplit(List<Distributable> blocks, String hostname) {
1:     this.splitList = new ArrayList<>(blocks.size());
1:     for (Distributable block : blocks) {
1:       this.splitList.add((CarbonInputSplit)block);
1:     }
1:     this.locations = new String[]{hostname};
1:   }
1: 
commit:ee71610
/////////////////////////////////////////////////////////////////////////
1:   private FileFormat fileFormat = FileFormat.COLUMNAR_V3;
author:QiangCai
-------------------------------------------------------------------------------
commit:d5bec4d
/////////////////////////////////////////////////////////////////////////
1:   public void calculateLength() {
commit:694ee77
/////////////////////////////////////////////////////////////////////////
1:   private long length;
1: 
1:     length = 0;
1:     calculateLength();
/////////////////////////////////////////////////////////////////////////
1:     calculateLength();
/////////////////////////////////////////////////////////////////////////
1:     return length;
1:   }
1: 
1:   public void setLength(long length) {
1:     this.length = length;
1:   }
1: 
0:   private void calculateLength() {
1:     for (CarbonInputSplit split : splitList) {
1:     length = total;
commit:d7393da
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.statusmanager.FileFormat;
/////////////////////////////////////////////////////////////////////////
0:   private FileFormat fileFormat = FileFormat.carbondata;
1: 
/////////////////////////////////////////////////////////////////////////
0:   public CarbonMultiBlockSplit(AbsoluteTableIdentifier identifier, List<CarbonInputSplit> splitList,
0:       String[] locations, FileFormat fileFormat) throws IOException {
1:     this.splitList = splitList;
1:     this.locations = locations;
1:     this.fileFormat = fileFormat;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     out.writeInt(fileFormat.ordinal());
/////////////////////////////////////////////////////////////////////////
1:     fileFormat = FileFormat.getByOrdinal(in.readInt());
1:   public FileFormat getFileFormat() {
1:     return fileFormat;
1:   }
1: 
1:   public void setFileFormat(FileFormat fileFormat) {
1:     this.fileFormat = fileFormat;
1:   }
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
author:ravipesala
-------------------------------------------------------------------------------
commit:44ffaf5
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashMap;
1: import java.util.Map;
/////////////////////////////////////////////////////////////////////////
1:   public CarbonMultiBlockSplit(List<CarbonInputSplit> splitList,
1:       String[] locations) {
1:   public CarbonMultiBlockSplit(List<CarbonInputSplit> splitList,
1:       String[] locations, FileFormat fileFormat) {
/////////////////////////////////////////////////////////////////////////
1:   public long getLength() {
/////////////////////////////////////////////////////////////////////////
1:     if (splitList.size() > 0 && splitList.get(0).getDetailInfo() != null) {
1:       Map<String, Long> blockSizes = new HashMap<>();
1:       for (CarbonInputSplit split : splitList) {
1:         blockSizes.put(split.getBlockPath(), split.getDetailInfo().getBlockSize());
1:       }
1:       for (Map.Entry<String, Long> entry : blockSizes.entrySet()) {
1:         total += entry.getValue();
1:       }
1:     } else {
1:       for (CarbonInputSplit split : splitList) {
1:         total += split.getLength();
1:       }
1:   public String[] getLocations() {
commit:cbf8797
/////////////////////////////////////////////////////////////////////////
1:    * The locations of all wrapped splits
1:   private String[] locations;
1:     locations = null;
0:       String[] locations) throws IOException {
1:     this.locations = locations;
/////////////////////////////////////////////////////////////////////////
1:     return locations;
/////////////////////////////////////////////////////////////////////////
1:     out.writeInt(locations.length);
1:     for (int i = 0; i < locations.length; i++) {
1:       out.writeUTF(locations[i]);
1:     }
/////////////////////////////////////////////////////////////////////////
1:     int len = in.readInt();
1:     locations = new String[len];
1:     for (int i = 0; i < len; i++) {
1:       locations[i] = in.readUTF();
1:     }
author:jackylk
-------------------------------------------------------------------------------
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.metadata.AbsoluteTableIdentifier;
commit:5f6a56c
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: 
1: package org.apache.carbondata.hadoop;
1: 
1: import java.io.DataInput;
1: import java.io.DataOutput;
1: import java.io.IOException;
1: import java.util.ArrayList;
1: import java.util.List;
1: 
0: import org.apache.carbondata.core.carbon.AbsoluteTableIdentifier;
1: 
1: import org.apache.hadoop.io.Writable;
1: import org.apache.hadoop.mapreduce.InputSplit;
1: 
1: /**
1:  * This class wraps multiple blocks belong to a same node to one split.
1:  * So the scanning task will scan multiple blocks. This is an optimization for concurrent query.
1:  */
0: public class CarbonMultiBlockSplit extends InputSplit implements Writable {
1: 
1:   /*
1:    * Splits (HDFS Blocks) for task to scan.
1:    */
1:   private List<CarbonInputSplit> splitList;
1: 
1:   /*
0:    * The location of all wrapped splits belong to the same node
1:    */
0:   private String location;
1: 
1:   public CarbonMultiBlockSplit() {
1:     splitList = null;
0:     location = null;
1:   }
1: 
0:   public CarbonMultiBlockSplit(AbsoluteTableIdentifier identifier, List<CarbonInputSplit> splitList,
0:       String location) throws IOException {
1:     this.splitList = splitList;
0:     this.location = location;
1:   }
1: 
1:   /**
1:    * Return all splits for scan
1:    * @return split list for scan
1:    */
1:   public List<CarbonInputSplit> getAllSplits() {
1:     return splitList;
1:   }
1: 
1:   @Override
0:   public long getLength() throws IOException, InterruptedException {
1:     long total = 0;
0:     for (InputSplit split: splitList) {
0:       total += split.getLength();
1:     }
0:     return total;
1:   }
1: 
1:   @Override
0:   public String[] getLocations() throws IOException, InterruptedException {
0:     return new String[]{location};
1:   }
1: 
1:   @Override
1:   public void write(DataOutput out) throws IOException {
1:     // write number of splits and then write all splits
1:     out.writeInt(splitList.size());
1:     for (CarbonInputSplit split: splitList) {
1:       split.write(out);
1:     }
0:     out.writeUTF(location);
1:   }
1: 
1:   @Override
1:   public void readFields(DataInput in) throws IOException {
1:     // read all splits
1:     int numSplit = in.readInt();
1:     splitList = new ArrayList<>(numSplit);
1:     for (int i = 0; i < numSplit; i++) {
1:       CarbonInputSplit split = new CarbonInputSplit();
1:       split.readFields(in);
1:       splitList.add(split);
1:     }
0:     location = in.readUTF();
1:   }
1: 
1: }
============================================================================
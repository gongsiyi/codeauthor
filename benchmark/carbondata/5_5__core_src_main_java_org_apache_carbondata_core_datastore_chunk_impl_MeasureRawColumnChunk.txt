1:72cb415: /*
1:72cb415:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:72cb415:  * contributor license agreements.  See the NOTICE file distributed with
1:72cb415:  * this work for additional information regarding copyright ownership.
1:72cb415:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:72cb415:  * (the "License"); you may not use this file except in compliance with
1:72cb415:  * the License.  You may obtain a copy of the License at
1:72cb415:  *
1:72cb415:  *    http://www.apache.org/licenses/LICENSE-2.0
1:72cb415:  *
1:72cb415:  * Unless required by applicable law or agreed to in writing, software
1:72cb415:  * distributed under the License is distributed on an "AS IS" BASIS,
1:72cb415:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:72cb415:  * See the License for the specific language governing permissions and
1:72cb415:  * limitations under the License.
1:72cb415:  */
1:72cb415: package org.apache.carbondata.core.datastore.chunk.impl;
2:72cb415: 
1:72cb415: import java.io.IOException;
1:72cb415: import java.nio.ByteBuffer;
1:72cb415: 
1:daa6465: import org.apache.carbondata.core.datastore.FileReader;
1:72cb415: import org.apache.carbondata.core.datastore.chunk.AbstractRawColumnChunk;
1:72cb415: import org.apache.carbondata.core.datastore.chunk.reader.MeasureColumnChunkReader;
1:e6a4f64: import org.apache.carbondata.core.datastore.page.ColumnPage;
1:7359601: import org.apache.carbondata.core.memory.MemoryException;
1:72cb415: 
1:72cb415: /**
1:72cb415:  * Contains raw measure data
1:72cb415:  * 1. The read uncompressed raw data of column chunk with all pages is stored in this instance.
1:daa6465:  * 2. The raw data can be converted to processed chunk using decodeColumnPage method
1:72cb415:  *  by specifying page number.
1:72cb415:  */
1:72cb415: public class MeasureRawColumnChunk extends AbstractRawColumnChunk {
1:72cb415: 
1:e6a4f64:   private ColumnPage[] columnPages;
1:72cb415: 
1:72cb415:   private MeasureColumnChunkReader chunkReader;
1:72cb415: 
1:daa6465:   private FileReader fileReader;
1:72cb415: 
1:d509f17:   public MeasureRawColumnChunk(int columnIndex, ByteBuffer rawData, long offSet, int length,
1:72cb415:       MeasureColumnChunkReader chunkReader) {
1:8c1ddbf:     super(columnIndex, rawData, offSet, length);
1:72cb415:     this.chunkReader = chunkReader;
1:72cb415:   }
1:72cb415: 
1:d509f17:   /**
1:e6a4f64:    * Convert all raw data with all pages to processed ColumnPage
1:72cb415:    */
1:daa6465:   public ColumnPage[] decodeAllColumnPages() {
1:e6a4f64:     if (columnPages == null) {
1:e6a4f64:       columnPages = new ColumnPage[pagesCount];
1:72cb415:     }
1:72cb415:     for (int i = 0; i < pagesCount; i++) {
1:72cb415:       try {
1:e6a4f64:         if (columnPages[i] == null) {
1:daa6465:           columnPages[i] = chunkReader.decodeColumnPage(this, i);
1:72cb415:         }
1:72cb415:       } catch (Exception e) {
1:72cb415:         throw new RuntimeException(e);
1:72cb415:       }
1:72cb415:     }
1:72cb415: 
1:e6a4f64:     return columnPages;
1:72cb415:   }
1:72cb415: 
1:72cb415:   /**
1:e6a4f64:    * Convert raw data with specified `columnIndex` processed to ColumnPage
1:72cb415:    */
1:daa6465:   public ColumnPage decodeColumnPage(int pageNumber) {
1:daa6465:     assert pageNumber < pagesCount;
1:e6a4f64:     if (columnPages == null) {
1:e6a4f64:       columnPages = new ColumnPage[pagesCount];
1:72cb415:     }
1:72cb415: 
1:72cb415:     try {
1:daa6465:       if (columnPages[pageNumber] == null) {
1:daa6465:         columnPages[pageNumber] = chunkReader.decodeColumnPage(this, pageNumber);
1:72cb415:       }
1:7359601:     } catch (IOException | MemoryException e) {
1:72cb415:       throw new RuntimeException(e);
1:72cb415:     }
1:72cb415: 
1:daa6465:     return columnPages[pageNumber];
1:72cb415:   }
1:72cb415: 
1:72cb415:   /**
1:d509f17:    * Convert raw data with specified page number processed to MeasureColumnDataChunk
1:d509f17:    *
1:d509f17:    * @param index
1:d509f17:    * @return
1:d509f17:    */
1:d509f17:   public ColumnPage convertToColumnPageWithOutCache(int index) {
1:d509f17:     assert index < pagesCount;
1:ceac8ab:     // in case of filter query filter columns blocklet pages will uncompressed
1:ceac8ab:     // so no need to decode again
1:ceac8ab:     if (null != columnPages && columnPages[index] != null) {
1:ceac8ab:       return columnPages[index];
1:ceac8ab:     }
1:d509f17:     try {
1:daa6465:       return chunkReader.decodeColumnPage(this, index);
1:d509f17:     } catch (IOException | MemoryException e) {
1:d509f17:       throw new RuntimeException(e);
1:d509f17:     }
1:d509f17:   }
1:d509f17: 
1:72cb415:   @Override public void freeMemory() {
1:4c9bed8:     super.freeMemory();
1:e6a4f64:     if (null != columnPages) {
1:e6a4f64:       for (int i = 0; i < columnPages.length; i++) {
1:e6a4f64:         if (columnPages[i] != null) {
1:e6a4f64:           columnPages[i].freeMemory();
1:4c9bed8:           columnPages[i] = null;
1:72cb415:         }
1:72cb415:       }
1:72cb415:     }
1:ceac8ab:     rawData = null;
1:72cb415:   }
1:d509f17: 
1:daa6465:   public void setFileReader(FileReader fileReader) {
1:72cb415:     this.fileReader = fileReader;
1:72cb415:   }
1:72cb415: 
1:daa6465:   public FileReader getFileReader() {
1:72cb415:     return fileReader;
1:72cb415:   }
1:72cb415: }
============================================================================
author:kumarvishal
-------------------------------------------------------------------------------
commit:ceac8ab
/////////////////////////////////////////////////////////////////////////
1:     // in case of filter query filter columns blocklet pages will uncompressed
1:     // so no need to decode again
1:     if (null != columnPages && columnPages[index] != null) {
1:       return columnPages[index];
1:     }
/////////////////////////////////////////////////////////////////////////
1:     rawData = null;
author:Jin Zhou
-------------------------------------------------------------------------------
commit:4c9bed8
/////////////////////////////////////////////////////////////////////////
1:     super.freeMemory();
1:           columnPages[i] = null;
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.FileReader;
/////////////////////////////////////////////////////////////////////////
1:  * 2. The raw data can be converted to processed chunk using decodeColumnPage method
/////////////////////////////////////////////////////////////////////////
1:   private FileReader fileReader;
/////////////////////////////////////////////////////////////////////////
1:   public ColumnPage[] decodeAllColumnPages() {
1:           columnPages[i] = chunkReader.decodeColumnPage(this, i);
/////////////////////////////////////////////////////////////////////////
1:   public ColumnPage decodeColumnPage(int pageNumber) {
1:     assert pageNumber < pagesCount;
1:       if (columnPages[pageNumber] == null) {
1:         columnPages[pageNumber] = chunkReader.decodeColumnPage(this, pageNumber);
1:     return columnPages[pageNumber];
/////////////////////////////////////////////////////////////////////////
1:       return chunkReader.decodeColumnPage(this, index);
/////////////////////////////////////////////////////////////////////////
1:   public void setFileReader(FileReader fileReader) {
1:   public FileReader getFileReader() {
commit:8c1ddbf
/////////////////////////////////////////////////////////////////////////
0:   public MeasureRawColumnChunk(int columnIndex, ByteBuffer rawData, int offSet, int length,
1:     super(columnIndex, rawData, offSet, length);
commit:e6a4f64
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.page.ColumnPage;
0:  * 2. The raw data can be converted to processed chunk using convertToColumnPage method
1:   private ColumnPage[] columnPages;
/////////////////////////////////////////////////////////////////////////
1:    * Convert all raw data with all pages to processed ColumnPage
0:   public ColumnPage[] convertToColumnPage() {
1:     if (columnPages == null) {
1:       columnPages = new ColumnPage[pagesCount];
1:         if (columnPages[i] == null) {
0:           columnPages[i] = chunkReader.convertToColumnPage(this, i);
1:     return columnPages;
1:    * Convert raw data with specified `columnIndex` processed to ColumnPage
0:   public ColumnPage convertToColumnPage(int columnIndex) {
0:     assert columnIndex < pagesCount;
1:     if (columnPages == null) {
1:       columnPages = new ColumnPage[pagesCount];
0:       if (columnPages[columnIndex] == null) {
0:         columnPages[columnIndex] = chunkReader.convertToColumnPage(this, columnIndex);
0:     return columnPages[columnIndex];
1:     if (null != columnPages) {
1:       for (int i = 0; i < columnPages.length; i++) {
1:         if (columnPages[i] != null) {
1:           columnPages[i].freeMemory();
author:ravipesala
-------------------------------------------------------------------------------
commit:d509f17
/////////////////////////////////////////////////////////////////////////
1:   public MeasureRawColumnChunk(int columnIndex, ByteBuffer rawData, long offSet, int length,
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * Convert raw data with specified page number processed to MeasureColumnDataChunk
1:    *
1:    * @param index
1:    * @return
1:    */
1:   public ColumnPage convertToColumnPageWithOutCache(int index) {
1:     assert index < pagesCount;
1: 
1:     try {
0:       return chunkReader.convertToColumnPage(this, index);
1:     } catch (IOException | MemoryException e) {
1:       throw new RuntimeException(e);
1:     }
1:   }
1: 
commit:72cb415
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.core.datastore.chunk.impl;
1: 
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: 
0: import org.apache.carbondata.core.datastore.FileHolder;
1: import org.apache.carbondata.core.datastore.chunk.AbstractRawColumnChunk;
0: import org.apache.carbondata.core.datastore.chunk.MeasureColumnDataChunk;
1: import org.apache.carbondata.core.datastore.chunk.reader.MeasureColumnChunkReader;
1: 
1: /**
1:  * Contains raw measure data
1:  * 1. The read uncompressed raw data of column chunk with all pages is stored in this instance.
0:  * 2. The raw data can be converted to processed chunk using convertToMeasureColDataChunk method
1:  *  by specifying page number.
1:  */
1: public class MeasureRawColumnChunk extends AbstractRawColumnChunk {
1: 
0:   private MeasureColumnDataChunk[] dataChunks;
1: 
1:   private MeasureColumnChunkReader chunkReader;
1: 
0:   private FileHolder fileReader;
1: 
0:   public MeasureRawColumnChunk(int blockId, ByteBuffer rawData, int offSet, int length,
1:       MeasureColumnChunkReader chunkReader) {
0:     super(blockId, rawData, offSet, length);
1:     this.chunkReader = chunkReader;
1:   }
1: 
1:   /**
0:    * Convert all raw data with all pages to processed MeasureColumnDataChunk's
0:    * @return
1:    */
0:   public MeasureColumnDataChunk[] convertToMeasureColDataChunks() {
0:     if (dataChunks == null) {
0:       dataChunks = new MeasureColumnDataChunk[pagesCount];
1:     }
1:     for (int i = 0; i < pagesCount; i++) {
1:       try {
0:         if (dataChunks[i] == null) {
0:           dataChunks[i] = chunkReader.convertToMeasureChunk(this, i);
1:         }
1:       } catch (Exception e) {
1:         throw new RuntimeException(e);
1:       }
1:     }
1: 
0:     return dataChunks;
1:   }
1: 
1:   /**
0:    * Convert raw data with specified page number processed to MeasureColumnDataChunk
0:    * @param index
0:    * @return
1:    */
0:   public MeasureColumnDataChunk convertToMeasureColDataChunk(int index) {
0:     assert index < pagesCount;
0:     if (dataChunks == null) {
0:       dataChunks = new MeasureColumnDataChunk[pagesCount];
1:     }
1: 
1:     try {
0:       if (dataChunks[index] == null) {
0:         dataChunks[index] = chunkReader.convertToMeasureChunk(this, index);
1:       }
0:     } catch (IOException e) {
1:       throw new RuntimeException(e);
1:     }
1: 
0:     return dataChunks[index];
1:   }
1: 
1:   @Override public void freeMemory() {
0:     if (null != dataChunks) {
0:       for (int i = 0; i < dataChunks.length; i++) {
0:         if (dataChunks[i] != null) {
0:           dataChunks[i].freeMemory();
1:         }
1:       }
1:     }
1:   }
1: 
0:   public void setFileReader(FileHolder fileReader) {
1:     this.fileReader = fileReader;
1:   }
1: 
0:   public FileHolder getFileReader() {
1:     return fileReader;
1:   }
1: }
author:jackylk
-------------------------------------------------------------------------------
commit:7359601
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.memory.MemoryException;
/////////////////////////////////////////////////////////////////////////
1:     } catch (IOException | MemoryException e) {
============================================================================
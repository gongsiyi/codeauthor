1:5804d75: /*
1:5804d75:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:5804d75:  * contributor license agreements.  See the NOTICE file distributed with
1:5804d75:  * this work for additional information regarding copyright ownership.
1:5804d75:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:5804d75:  * (the "License"); you may not use this file except in compliance with
1:5804d75:  * the License.  You may obtain a copy of the License at
1:5804d75:  *
1:5804d75:  *    http://www.apache.org/licenses/LICENSE-2.0
1:5804d75:  *
1:5804d75:  * Unless required by applicable law or agreed to in writing, software
1:5804d75:  * distributed under the License is distributed on an "AS IS" BASIS,
1:5804d75:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:5804d75:  * See the License for the specific language governing permissions and
1:5804d75:  * limitations under the License.
1:5804d75:  */
1:5804d75: package org.apache.carbondata.processing.loading.jsoninput;
1:5804d75: 
1:5804d75: import java.io.BufferedInputStream;
1:5804d75: import java.io.IOException;
1:5804d75: import java.security.InvalidParameterException;
1:5804d75: 
1:5804d75: import org.apache.hadoop.conf.Configuration;
1:5804d75: import org.apache.hadoop.fs.FSDataInputStream;
1:5804d75: import org.apache.hadoop.fs.FileSystem;
1:5804d75: import org.apache.hadoop.fs.Path;
1:5804d75: import org.apache.hadoop.io.LongWritable;
1:5804d75: import org.apache.hadoop.io.Text;
1:5804d75: import org.apache.hadoop.mapreduce.InputSplit;
1:5804d75: import org.apache.hadoop.mapreduce.Job;
1:5804d75: import org.apache.hadoop.mapreduce.RecordReader;
1:5804d75: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1:5804d75: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:5804d75: import org.apache.hadoop.mapreduce.lib.input.FileSplit;
1:5804d75: import org.apache.hadoop.mapreduce.lib.input.LineRecordReader;
1:5804d75: import org.apache.log4j.Logger;
1:5804d75: import org.codehaus.jackson.JsonFactory;
1:5804d75: import org.codehaus.jackson.JsonNode;
1:5804d75: import org.codehaus.jackson.map.ObjectMapper;
1:5804d75: 
1:5804d75: /**
1:5804d75:  * Code ported from Hydra-Spark {package com.pluralsight.hydra.hadoop.io} package
1:5804d75:  * The JsonInputFormat will read two types of JSON formatted data. The default
1:5804d75:  * expectation is each JSON record is newline delimited. This method is
1:5804d75:  * generally faster and is backed by the {@link LineRecordReader} you are likely
1:5804d75:  * familiar with. The other method is 'pretty print' of JSON records, where
1:5804d75:  * records span multiple lines and often have some type of root identifier. This
1:5804d75:  * method is likely slower, but respects record boundaries much like the
1:5804d75:  * LineRecordReader.<br>
1:5804d75:  * <br>
1:5804d75:  * Use of the 'pretty print' reader requires a record identifier.
1:5804d75:  */
1:5804d75: public class JsonInputFormat extends FileInputFormat<LongWritable, Text> {
1:5804d75: 
1:5804d75:   private static JsonFactory factory = new JsonFactory();
1:5804d75: 
1:5804d75:   private static ObjectMapper mapper = new ObjectMapper(factory);
1:5804d75: 
1:5804d75:   public static final String ONE_RECORD_PER_LINE = "json.input.format.one.record.per.line";
1:5804d75: 
1:5804d75:   public static final String RECORD_IDENTIFIER = "json.input.format.record.identifier";
1:5804d75: 
1:5804d75:   @Override public RecordReader<LongWritable, Text> createRecordReader(InputSplit split,
1:5804d75:       TaskAttemptContext context) throws IOException, InterruptedException {
1:5804d75:     RecordReader<LongWritable, Text> rdr;
1:5804d75: 
1:5804d75:     if (JsonInputFormat.getOneRecordPerLine(context.getConfiguration())) {
1:5804d75:       rdr = new SimpleJsonRecordReader();
1:5804d75:     } else {
1:5804d75:       return new JsonRecordReader();
1:5804d75:     }
1:5804d75:     rdr.initialize(split, context);
1:5804d75:     return rdr;
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * This class uses the {@link LineRecordReader} to read a line of JSON and
1:5804d75:    * return it as a Text object.
1:5804d75:    */
1:5804d75:   public static class SimpleJsonRecordReader extends RecordReader<LongWritable, Text> {
1:5804d75: 
1:5804d75:     private LineRecordReader reader = null;
1:5804d75: 
1:5804d75:     private LongWritable outKey = new LongWritable(0L);
1:5804d75: 
1:5804d75:     private Text outValue = new Text();
1:5804d75: 
1:5804d75:     @Override public void initialize(InputSplit split, TaskAttemptContext context)
1:5804d75:         throws IOException {
1:5804d75: 
1:5804d75:       reader = new LineRecordReader();
1:5804d75:       reader.initialize(split, context);
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public boolean nextKeyValue() throws IOException {
1:5804d75:       if (reader.nextKeyValue()) {
1:5804d75:         outValue.set(reader.getCurrentValue());
1:5804d75:         outKey.set(reader.getCurrentKey().get());
1:5804d75:         return true;
1:5804d75:       } else {
1:5804d75:         return false;
1:5804d75:       }
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public void close() throws IOException {
1:5804d75:       reader.close();
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public float getProgress() throws IOException {
1:5804d75:       return reader.getProgress();
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public LongWritable getCurrentKey() {
1:5804d75:       return outKey;
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public Text getCurrentValue() {
1:5804d75:       return outValue;
1:5804d75:     }
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * This class uses the {@link JsonStreamReader} to read JSON records from a
1:5804d75:    * file. It respects split boundaries to complete full JSON records, as
1:5804d75:    * specified by the root identifier. This class will discard any records
1:5804d75:    * that it was unable to decode using
1:5804d75:    * {@link JsonInputFormat#decodeLineToJsonNode(String)}
1:5804d75:    */
1:5804d75:   public static class JsonRecordReader extends RecordReader<LongWritable, Text> {
1:5804d75: 
1:5804d75:     private Logger LOG = Logger.getLogger(JsonRecordReader.class);
1:5804d75: 
1:5804d75:     private JsonStreamReader rdr = null;
1:5804d75: 
1:5804d75:     private long start = 0, end = 0;
1:5804d75: 
1:5804d75:     private float toRead = 0;
1:5804d75: 
1:5804d75:     private String identifier = null;
1:5804d75: 
1:5804d75:     private Logger log = Logger.getLogger(JsonRecordReader.class);
1:5804d75: 
1:5804d75:     private Text outJson = new Text();
1:5804d75: 
1:5804d75:     private LongWritable outKey = new LongWritable();
1:5804d75: 
1:5804d75:     @Override public void initialize(InputSplit split, TaskAttemptContext context)
1:5804d75:         throws IOException, InterruptedException {
1:5804d75: 
1:5804d75:       this.identifier = JsonInputFormat.getRecordIdentifier(context.getConfiguration());
1:5804d75: 
1:5804d75:       if (this.identifier == null || identifier.isEmpty()) {
1:5804d75:         throw new InvalidParameterException(JsonInputFormat.RECORD_IDENTIFIER + " is not set.");
1:5804d75:       } else {
1:5804d75:         LOG.info("Initializing JsonRecordReader with identifier " + identifier);
1:5804d75:       }
1:5804d75: 
1:5804d75:       FileSplit fSplit = (FileSplit) split;
1:5804d75: 
1:5804d75:       // get relevant data
1:5804d75:       Path file = fSplit.getPath();
1:5804d75: 
1:5804d75:       log.info("File is " + file);
1:5804d75: 
1:5804d75:       start = fSplit.getStart();
1:5804d75:       end = start + split.getLength();
1:5804d75:       toRead = end - start;
1:5804d75: 
1:5804d75:       FSDataInputStream strm = FileSystem.get(context.getConfiguration()).open(file);
1:5804d75: 
1:5804d75:       if (start != 0) {
1:5804d75:         strm.seek(start);
1:5804d75:       }
1:5804d75: 
1:5804d75:       rdr = new JsonStreamReader(identifier, new BufferedInputStream(strm));
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public boolean nextKeyValue() throws IOException {
1:5804d75:       boolean retVal = false;
1:5804d75:       boolean keepGoing;
1:5804d75:       do {
1:5804d75:         keepGoing = false;
1:5804d75:         String record = rdr.getJsonRecord();
1:5804d75:         if (record != null) {
1:5804d75:           if (JsonInputFormat.decodeLineToJsonNode(record) == null) {
1:5804d75:             keepGoing = true;
1:5804d75:           } else {
1:5804d75:             outJson.set(record);
1:5804d75:             outKey.set(rdr.getBytesRead());
1:5804d75:             retVal = true;
1:5804d75:           }
1:5804d75:         }
1:5804d75:       } while (keepGoing);
1:5804d75: 
1:5804d75:       return retVal;
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public void close() throws IOException {
1:5804d75:       rdr.close();
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public float getProgress() {
1:5804d75:       return (float) rdr.getBytesRead() / toRead;
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public LongWritable getCurrentKey() {
1:5804d75:       return outKey;
1:5804d75:     }
1:5804d75: 
1:5804d75:     @Override public Text getCurrentValue() {
1:5804d75:       return outJson;
1:5804d75:     }
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * Decodes a given string of text to a {@link JsonNode}.
1:5804d75:    *
1:5804d75:    * @param line The line of text
1:5804d75:    * @return The JsonNode or null if a JsonParseException,
1:5804d75:    * JsonMappingException, or IOException error occurs
1:5804d75:    */
1:5804d75:   public static synchronized JsonNode decodeLineToJsonNode(String line) {
1:5804d75: 
1:5804d75:     try {
1:5804d75:       return mapper.readTree(line);
1:5804d75:     } catch (IOException e) {
1:5804d75:       return null;
1:5804d75:     }
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * Sets the input format to use the {@link SimpleJsonRecordReader} if true,
1:5804d75:    * otherwise {@link JsonRecordReader}.<br>
1:5804d75:    * <br>
1:5804d75:    * Default is true.
1:5804d75:    *
1:5804d75:    * @param job                The job to configure
1:5804d75:    * @param isOneRecordPerLine True if JSON records are new line delimited, false otherwise.
1:5804d75:    */
1:5804d75:   public static void setOneRecordPerLine(Job job, boolean isOneRecordPerLine) {
1:5804d75:     job.getConfiguration().setBoolean(ONE_RECORD_PER_LINE, isOneRecordPerLine);
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * Gets if this is configured as one JSON record per line.
1:5804d75:    *
1:5804d75:    * @param conf the Job configuration
1:5804d75:    * @return True if one JSON record per line, false otherwise.
1:5804d75:    */
1:5804d75:   public static boolean getOneRecordPerLine(Configuration conf) {
1:5804d75:     return conf.getBoolean(ONE_RECORD_PER_LINE, false);
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * Specifies a record identifier to be used with the
1:5804d75:    * {@link JsonRecordReader}<br>
1:5804d75:    * <br>
1:5804d75:    * Must be set if {@link JsonInputFormat#setOneRecordPerLine} is false.
1:5804d75:    *
1:5804d75:    * @param job    The job to configure
1:5804d75:    * @param record The record identifier
1:5804d75:    */
1:5804d75:   public static void setRecordIdentifier(Job job, String record) {
1:5804d75:     job.getConfiguration().set(RECORD_IDENTIFIER, record);
1:5804d75:   }
1:5804d75: 
1:5804d75:   /**
1:5804d75:    * Gets the record identifier
1:5804d75:    *
1:5804d75:    * @param conf the Job configuration
1:5804d75:    * @return The record identifier or null if not set
1:5804d75:    */
1:5804d75:   public static String getRecordIdentifier(Configuration conf) {
1:5804d75:     return conf.get(RECORD_IDENTIFIER);
1:5804d75:   }
1:5804d75: }
1:5804d75: 
============================================================================
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:5804d75
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.carbondata.processing.loading.jsoninput;
1: 
1: import java.io.BufferedInputStream;
1: import java.io.IOException;
1: import java.security.InvalidParameterException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FSDataInputStream;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.LongWritable;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.InputSplit;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.RecordReader;
1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.FileSplit;
1: import org.apache.hadoop.mapreduce.lib.input.LineRecordReader;
1: import org.apache.log4j.Logger;
1: import org.codehaus.jackson.JsonFactory;
1: import org.codehaus.jackson.JsonNode;
1: import org.codehaus.jackson.map.ObjectMapper;
1: 
1: /**
1:  * Code ported from Hydra-Spark {package com.pluralsight.hydra.hadoop.io} package
1:  * The JsonInputFormat will read two types of JSON formatted data. The default
1:  * expectation is each JSON record is newline delimited. This method is
1:  * generally faster and is backed by the {@link LineRecordReader} you are likely
1:  * familiar with. The other method is 'pretty print' of JSON records, where
1:  * records span multiple lines and often have some type of root identifier. This
1:  * method is likely slower, but respects record boundaries much like the
1:  * LineRecordReader.<br>
1:  * <br>
1:  * Use of the 'pretty print' reader requires a record identifier.
1:  */
1: public class JsonInputFormat extends FileInputFormat<LongWritable, Text> {
1: 
1:   private static JsonFactory factory = new JsonFactory();
1: 
1:   private static ObjectMapper mapper = new ObjectMapper(factory);
1: 
1:   public static final String ONE_RECORD_PER_LINE = "json.input.format.one.record.per.line";
1: 
1:   public static final String RECORD_IDENTIFIER = "json.input.format.record.identifier";
1: 
1:   @Override public RecordReader<LongWritable, Text> createRecordReader(InputSplit split,
1:       TaskAttemptContext context) throws IOException, InterruptedException {
1:     RecordReader<LongWritable, Text> rdr;
1: 
1:     if (JsonInputFormat.getOneRecordPerLine(context.getConfiguration())) {
1:       rdr = new SimpleJsonRecordReader();
1:     } else {
1:       return new JsonRecordReader();
1:     }
1:     rdr.initialize(split, context);
1:     return rdr;
1:   }
1: 
1:   /**
1:    * This class uses the {@link LineRecordReader} to read a line of JSON and
1:    * return it as a Text object.
1:    */
1:   public static class SimpleJsonRecordReader extends RecordReader<LongWritable, Text> {
1: 
1:     private LineRecordReader reader = null;
1: 
1:     private LongWritable outKey = new LongWritable(0L);
1: 
1:     private Text outValue = new Text();
1: 
1:     @Override public void initialize(InputSplit split, TaskAttemptContext context)
1:         throws IOException {
1: 
1:       reader = new LineRecordReader();
1:       reader.initialize(split, context);
1:     }
1: 
1:     @Override public boolean nextKeyValue() throws IOException {
1:       if (reader.nextKeyValue()) {
1:         outValue.set(reader.getCurrentValue());
1:         outKey.set(reader.getCurrentKey().get());
1:         return true;
1:       } else {
1:         return false;
1:       }
1:     }
1: 
1:     @Override public void close() throws IOException {
1:       reader.close();
1:     }
1: 
1:     @Override public float getProgress() throws IOException {
1:       return reader.getProgress();
1:     }
1: 
1:     @Override public LongWritable getCurrentKey() {
1:       return outKey;
1:     }
1: 
1:     @Override public Text getCurrentValue() {
1:       return outValue;
1:     }
1:   }
1: 
1:   /**
1:    * This class uses the {@link JsonStreamReader} to read JSON records from a
1:    * file. It respects split boundaries to complete full JSON records, as
1:    * specified by the root identifier. This class will discard any records
1:    * that it was unable to decode using
1:    * {@link JsonInputFormat#decodeLineToJsonNode(String)}
1:    */
1:   public static class JsonRecordReader extends RecordReader<LongWritable, Text> {
1: 
1:     private Logger LOG = Logger.getLogger(JsonRecordReader.class);
1: 
1:     private JsonStreamReader rdr = null;
1: 
1:     private long start = 0, end = 0;
1: 
1:     private float toRead = 0;
1: 
1:     private String identifier = null;
1: 
1:     private Logger log = Logger.getLogger(JsonRecordReader.class);
1: 
1:     private Text outJson = new Text();
1: 
1:     private LongWritable outKey = new LongWritable();
1: 
1:     @Override public void initialize(InputSplit split, TaskAttemptContext context)
1:         throws IOException, InterruptedException {
1: 
1:       this.identifier = JsonInputFormat.getRecordIdentifier(context.getConfiguration());
1: 
1:       if (this.identifier == null || identifier.isEmpty()) {
1:         throw new InvalidParameterException(JsonInputFormat.RECORD_IDENTIFIER + " is not set.");
1:       } else {
1:         LOG.info("Initializing JsonRecordReader with identifier " + identifier);
1:       }
1: 
1:       FileSplit fSplit = (FileSplit) split;
1: 
1:       // get relevant data
1:       Path file = fSplit.getPath();
1: 
1:       log.info("File is " + file);
1: 
1:       start = fSplit.getStart();
1:       end = start + split.getLength();
1:       toRead = end - start;
1: 
1:       FSDataInputStream strm = FileSystem.get(context.getConfiguration()).open(file);
1: 
1:       if (start != 0) {
1:         strm.seek(start);
1:       }
1: 
1:       rdr = new JsonStreamReader(identifier, new BufferedInputStream(strm));
1:     }
1: 
1:     @Override public boolean nextKeyValue() throws IOException {
1:       boolean retVal = false;
1:       boolean keepGoing;
1:       do {
1:         keepGoing = false;
1:         String record = rdr.getJsonRecord();
1:         if (record != null) {
1:           if (JsonInputFormat.decodeLineToJsonNode(record) == null) {
1:             keepGoing = true;
1:           } else {
1:             outJson.set(record);
1:             outKey.set(rdr.getBytesRead());
1:             retVal = true;
1:           }
1:         }
1:       } while (keepGoing);
1: 
1:       return retVal;
1:     }
1: 
1:     @Override public void close() throws IOException {
1:       rdr.close();
1:     }
1: 
1:     @Override public float getProgress() {
1:       return (float) rdr.getBytesRead() / toRead;
1:     }
1: 
1:     @Override public LongWritable getCurrentKey() {
1:       return outKey;
1:     }
1: 
1:     @Override public Text getCurrentValue() {
1:       return outJson;
1:     }
1:   }
1: 
1:   /**
1:    * Decodes a given string of text to a {@link JsonNode}.
1:    *
1:    * @param line The line of text
1:    * @return The JsonNode or null if a JsonParseException,
1:    * JsonMappingException, or IOException error occurs
1:    */
1:   public static synchronized JsonNode decodeLineToJsonNode(String line) {
1: 
1:     try {
1:       return mapper.readTree(line);
1:     } catch (IOException e) {
1:       return null;
1:     }
1:   }
1: 
1:   /**
1:    * Sets the input format to use the {@link SimpleJsonRecordReader} if true,
1:    * otherwise {@link JsonRecordReader}.<br>
1:    * <br>
1:    * Default is true.
1:    *
1:    * @param job                The job to configure
1:    * @param isOneRecordPerLine True if JSON records are new line delimited, false otherwise.
1:    */
1:   public static void setOneRecordPerLine(Job job, boolean isOneRecordPerLine) {
1:     job.getConfiguration().setBoolean(ONE_RECORD_PER_LINE, isOneRecordPerLine);
1:   }
1: 
1:   /**
1:    * Gets if this is configured as one JSON record per line.
1:    *
1:    * @param conf the Job configuration
1:    * @return True if one JSON record per line, false otherwise.
1:    */
1:   public static boolean getOneRecordPerLine(Configuration conf) {
1:     return conf.getBoolean(ONE_RECORD_PER_LINE, false);
1:   }
1: 
1:   /**
1:    * Specifies a record identifier to be used with the
1:    * {@link JsonRecordReader}<br>
1:    * <br>
1:    * Must be set if {@link JsonInputFormat#setOneRecordPerLine} is false.
1:    *
1:    * @param job    The job to configure
1:    * @param record The record identifier
1:    */
1:   public static void setRecordIdentifier(Job job, String record) {
1:     job.getConfiguration().set(RECORD_IDENTIFIER, record);
1:   }
1: 
1:   /**
1:    * Gets the record identifier
1:    *
1:    * @param conf the Job configuration
1:    * @return The record identifier or null if not set
1:    */
1:   public static String getRecordIdentifier(Configuration conf) {
1:     return conf.get(RECORD_IDENTIFIER);
1:   }
1: }
1: 
============================================================================
1:9669c0b: /*
1:9669c0b:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:9669c0b:  * contributor license agreements.  See the NOTICE file distributed with
1:9669c0b:  * this work for additional information regarding copyright ownership.
1:9669c0b:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:9669c0b:  * (the "License"); you may not use this file except in compliance with
1:9669c0b:  * the License.  You may obtain a copy of the License at
1:531dcd2:  *
1:9669c0b:  *    http://www.apache.org/licenses/LICENSE-2.0
2:9669c0b:  *
1:9669c0b:  * Unless required by applicable law or agreed to in writing, software
1:9669c0b:  * distributed under the License is distributed on an "AS IS" BASIS,
1:9669c0b:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:9669c0b:  * See the License for the specific language governing permissions and
1:9669c0b:  * limitations under the License.
1:9669c0b:  */
20:9669c0b: 
1:9669c0b: package org.apache.carbondata.presto;
1:9669c0b: 
1:9669c0b: import java.io.IOException;
1:9669c0b: import java.util.List;
1:9669c0b: 
1:d4a1577: import static java.util.Objects.requireNonNull;
1:d4a1577: 
1:531dcd2: import org.apache.carbondata.common.logging.LogService;
1:531dcd2: import org.apache.carbondata.common.logging.LogServiceFactory;
1:a4c2ef5: import org.apache.carbondata.presto.readers.PrestoVectorBlockBuilder;
1:349c59c: import org.apache.carbondata.processing.loading.exception.CarbonDataLoadingException;
1:531dcd2: 
1:531dcd2: import com.facebook.presto.hadoop.$internal.com.google.common.base.Throwables;
1:2ad621d: import com.facebook.presto.spi.ColumnHandle;
1:9669c0b: import com.facebook.presto.spi.ConnectorPageSource;
1:9669c0b: import com.facebook.presto.spi.Page;
1:531dcd2: import com.facebook.presto.spi.PrestoException;
1:f2bb8d3: import com.facebook.presto.spi.block.Block;
1:f2bb8d3: import com.facebook.presto.spi.block.LazyBlock;
1:f2bb8d3: import com.facebook.presto.spi.block.LazyBlockLoader;
1:9669c0b: 
1:9669c0b: import static com.google.common.base.Preconditions.checkState;
1:531dcd2: 
1:9669c0b: /**
1:9669c0b:  * Carbondata Page Source class for custom Carbondata RecordSet Iteration.
1:9669c0b:  */
1:531dcd2: class CarbondataPageSource implements ConnectorPageSource {
1:531dcd2: 
1:531dcd2:   private static final LogService logger =
1:531dcd2:       LogServiceFactory.getLogService(CarbondataPageSource.class.getName());
1:a4c2ef5:   private List<ColumnHandle> columnHandles;
1:9669c0b:   private boolean closed;
1:daa6465:   private PrestoCarbonVectorizedRecordReader vectorReader;
1:531dcd2:   private long sizeOfData = 0;
1:531dcd2:   private int batchId;
1:531dcd2:   private long nanoStart;
1:531dcd2:   private long nanoEnd;
1:531dcd2: 
1:a4c2ef5:   CarbondataPageSource(PrestoCarbonVectorizedRecordReader vectorizedRecordReader,
1:a4c2ef5:       List<ColumnHandle> columnHandles) {
1:2ad621d:     this.columnHandles = columnHandles;
1:2ad621d:     vectorReader = vectorizedRecordReader;
16:9669c0b:   }
1:2ad621d: 
1:9669c0b:   @Override public long getCompletedBytes() {
2:531dcd2:     return sizeOfData;
1:2ad621d:   }
1:2ad621d: 
1:9669c0b:   @Override public long getReadTimeNanos() {
1:531dcd2:     return nanoStart > 0L ? (nanoEnd == 0 ? System.nanoTime() : nanoEnd) - nanoStart : 0L;
1:9669c0b:   }
1:2ad621d: 
1:9669c0b:   @Override public boolean isFinished() {
1:a4c2ef5:     return closed;
1:9669c0b:   }
1:531dcd2: 
1:9669c0b:   @Override public Page getNextPage() {
1:531dcd2:     if (nanoStart == 0) {
1:531dcd2:       nanoStart = System.nanoTime();
1:531dcd2:     }
1:e5e74fc:     CarbonVectorBatch columnarBatch = null;
1:531dcd2:     int batchSize = 0;
1:531dcd2:     try {
1:531dcd2:       batchId++;
1:a4c2ef5:       if (vectorReader.nextKeyValue()) {
1:590bbb9:         Object vectorBatch = vectorReader.getCurrentValue();
1:a4c2ef5:         if (vectorBatch instanceof CarbonVectorBatch) {
1:e5e74fc:           columnarBatch = (CarbonVectorBatch) vectorBatch;
1:531dcd2:           batchSize = columnarBatch.numRows();
1:a4c2ef5:           if (batchSize == 0) {
1:531dcd2:             close();
1:531dcd2:             return null;
1:9669c0b:           }
1:9669c0b:         }
1:531dcd2:       } else {
1:531dcd2:         close();
1:531dcd2:         return null;
1:531dcd2:       }
1:590bbb9:       if (columnarBatch == null) {
1:9669c0b:         return null;
1:531dcd2:       }
1:531dcd2: 
1:a4c2ef5:       Block[] blocks = new Block[columnHandles.size()];
1:531dcd2:       for (int column = 0; column < blocks.length; column++) {
1:a4c2ef5:         blocks[column] = new LazyBlock(batchSize, new CarbondataBlockLoader(column));
1:531dcd2:       }
1:531dcd2:       Page page = new Page(batchSize, blocks);
1:531dcd2:       return page;
1:a4c2ef5:     } catch (PrestoException e) {
3:531dcd2:       closeWithSuppression(e);
1:531dcd2:       throw e;
1:a4c2ef5:     } catch (RuntimeException | InterruptedException | IOException e) {
1:531dcd2:       closeWithSuppression(e);
3:531dcd2:       throw new CarbonDataLoadingException("Exception when creating the Carbon data Block", e);
1:9669c0b:     }
1:9669c0b:   }
1:531dcd2: 
1:9669c0b:   @Override public long getSystemMemoryUsage() {
1:531dcd2:     return sizeOfData;
1:9669c0b:   }
1:531dcd2: 
1:a4c2ef5:   @Override public void close() {
1:531dcd2:     // some hive input formats are broken and bad things can happen if you close them multiple times
1:531dcd2:     if (closed) {
1:531dcd2:       return;
1:531dcd2:     }
1:531dcd2:     closed = true;
1:531dcd2:     try {
1:531dcd2:       vectorReader.close();
1:531dcd2:       nanoEnd = System.nanoTime();
1:531dcd2:     } catch (Exception e) {
1:531dcd2:       throw Throwables.propagate(e);
1:531dcd2:     }
1:531dcd2: 
1:531dcd2:   }
1:531dcd2: 
1:a4c2ef5:   private void closeWithSuppression(Throwable throwable) {
1:531dcd2:     requireNonNull(throwable, "throwable is null");
1:531dcd2:     try {
1:531dcd2:       close();
1:a4c2ef5:     } catch (RuntimeException e) {
1:531dcd2:       // Self-suppression not permitted
1:531dcd2:       logger.error(e, e.getMessage());
1:531dcd2:       if (throwable != e) {
1:531dcd2:         throwable.addSuppressed(e);
1:531dcd2:       }
1:531dcd2:     }
1:9669c0b:   }
1:531dcd2: 
1:531dcd2:   /**
1:531dcd2:    * Lazy Block Implementation for the Carbondata
1:531dcd2:    */
1:a4c2ef5:   private final class CarbondataBlockLoader implements LazyBlockLoader<LazyBlock> {
1:531dcd2:     private final int expectedBatchId = batchId;
1:531dcd2:     private final int columnIndex;
1:f2bb8d3:     private boolean loaded;
1:531dcd2: 
1:a4c2ef5:     CarbondataBlockLoader(int columnIndex) {
1:531dcd2:       this.columnIndex = columnIndex;
1:9669c0b:     }
1:531dcd2: 
1:a4c2ef5:     @Override public final void load(LazyBlock lazyBlock) {
1:f2bb8d3:       if (loaded) {
1:f2bb8d3:         return;
1:531dcd2:       }
1:531dcd2:       checkState(batchId == expectedBatchId);
1:531dcd2:       try {
1:a4c2ef5:         PrestoVectorBlockBuilder blockBuilder =
1:a4c2ef5:             (PrestoVectorBlockBuilder) vectorReader.getColumnarBatch().column(columnIndex);
1:a4c2ef5:         blockBuilder.setBatchSize(lazyBlock.getPositionCount());
1:a4c2ef5:         Block block = blockBuilder.buildBlock();
1:01b48fc:         sizeOfData += block.getSizeInBytes();
1:531dcd2:         lazyBlock.setBlock(block);
1:a4c2ef5:       } catch (Exception e) {
1:531dcd2:         throw new CarbonDataLoadingException("Error in Reading Data from Carbondata ", e);
1:531dcd2:       }
1:f2bb8d3:       loaded = true;
1:531dcd2:     }
1:531dcd2:   }
1:531dcd2: 
1:531dcd2: }
============================================================================
author:ajantha-bhat
-------------------------------------------------------------------------------
commit:d4a1577
/////////////////////////////////////////////////////////////////////////
1: import static java.util.Objects.requireNonNull;
1: 
/////////////////////////////////////////////////////////////////////////
author:sv71294
-------------------------------------------------------------------------------
commit:a4c2ef5
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.presto.readers.PrestoVectorBlockBuilder;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private List<ColumnHandle> columnHandles;
1:   CarbondataPageSource(PrestoCarbonVectorizedRecordReader vectorizedRecordReader,
1:       List<ColumnHandle> columnHandles) {
/////////////////////////////////////////////////////////////////////////
1:     return closed;
/////////////////////////////////////////////////////////////////////////
1:       if (vectorReader.nextKeyValue()) {
1:         if (vectorBatch instanceof CarbonVectorBatch) {
1:           if (batchSize == 0) {
/////////////////////////////////////////////////////////////////////////
1:       Block[] blocks = new Block[columnHandles.size()];
1:         blocks[column] = new LazyBlock(batchSize, new CarbondataBlockLoader(column));
1:     } catch (PrestoException e) {
1:     } catch (RuntimeException | InterruptedException | IOException e) {
/////////////////////////////////////////////////////////////////////////
1:   @Override public void close() {
/////////////////////////////////////////////////////////////////////////
1:   private void closeWithSuppression(Throwable throwable) {
1:     } catch (RuntimeException e) {
/////////////////////////////////////////////////////////////////////////
1:   private final class CarbondataBlockLoader implements LazyBlockLoader<LazyBlock> {
1:     CarbondataBlockLoader(int columnIndex) {
1:     @Override public final void load(LazyBlock lazyBlock) {
1:         PrestoVectorBlockBuilder blockBuilder =
1:             (PrestoVectorBlockBuilder) vectorReader.getColumnarBatch().column(columnIndex);
1:         blockBuilder.setBatchSize(lazyBlock.getPositionCount());
1:         Block block = blockBuilder.buildBlock();
1:       } catch (Exception e) {
author:Bhavya
-------------------------------------------------------------------------------
commit:01b48fc
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     return closed ;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         sizeOfData += block.getSizeInBytes();
commit:2ad621d
/////////////////////////////////////////////////////////////////////////
0: import java.util.stream.Collectors;
/////////////////////////////////////////////////////////////////////////
1: import com.facebook.presto.spi.ColumnHandle;
/////////////////////////////////////////////////////////////////////////
0:   List<ColumnHandle> columnHandles;
0:   public CarbondataPageSource(CarbonDictionaryDecodeReadSupport readSupport,
0:       PrestoCarbonVectorizedRecordReader vectorizedRecordReader,
0:       List<ColumnHandle> columnHandles ) {
1:     this.columnHandles = columnHandles;
0:     this.types = getColumnTypes();
0:     this.readSupport = readSupport;
1:     vectorReader = vectorizedRecordReader;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:    private List<Type> getColumnTypes() {
0:     return columnHandles.stream().map(a -> ((CarbondataColumnHandle)a).getColumnType())
0:         .collect(Collectors.toList());
1:   }
1: 
1: 
commit:e5e74fc
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     CarbonVectorBatch columnarBatch = null;
0:         if(vectorBatch != null && vectorBatch instanceof CarbonVectorBatch)
1:           columnarBatch = (CarbonVectorBatch) vectorBatch;
commit:ccb6560
/////////////////////////////////////////////////////////////////////////
commit:531dcd2
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.common.CarbonIterator;
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
0: import org.apache.carbondata.core.scan.result.BatchResult;
0: import org.apache.carbondata.presto.readers.StreamReader;
0: import org.apache.carbondata.presto.readers.StreamReaders;
0: import org.apache.carbondata.processing.newflow.exception.CarbonDataLoadingException;
1: 
1: import com.facebook.presto.hadoop.$internal.com.google.common.base.Throwables;
1: import com.facebook.presto.spi.PrestoException;
0: import org.apache.spark.sql.execution.vectorized.ColumnarBatch;
1: class CarbondataPageSource implements ConnectorPageSource {
1:   private static final LogService logger =
1:       LogServiceFactory.getLogService(CarbondataPageSource.class.getName());
0:   private CarbonVectorizedRecordReader vectorReader;
0:   private CarbonDictionaryDecodeReadSupport<Object[]> readSupport;
1:   private long sizeOfData = 0;
0:   private final StreamReader[] readers ;
1:   private int batchId;
1: 
1:   private long nanoStart;
1:   private long nanoEnd;
1: 
0:   CarbondataPageSource(RecordSet recordSet) {
0:   private CarbondataPageSource(List<Type> types, RecordCursor cursor) {
0:     this.readSupport = ((CarbondataRecordCursor) cursor).getReadSupport();
0:     this.vectorReader = ((CarbondataRecordCursor) cursor).getVectorizedRecordReader();
0:     this.readers = createStreamReaders();
1:     return sizeOfData;
1:     return sizeOfData;
1:     return nanoStart > 0L ? (nanoEnd == 0 ? System.nanoTime() : nanoEnd) - nanoStart : 0L;
1: 
1:     if (nanoStart == 0) {
1:       nanoStart = System.nanoTime();
1:     }
0:     Object vectorBatch;
0:     ColumnarBatch columnarBatch = null;
1:     int batchSize = 0;
1:     try {
1:       batchId++;
0:       if(vectorReader.nextKeyValue()) {
0:         vectorBatch = vectorReader.getCurrentValue();
0:         if(vectorBatch instanceof ColumnarBatch)
0:         {
0:           columnarBatch = (ColumnarBatch) vectorBatch;
1:           batchSize = columnarBatch.numRows();
0:           if(batchSize == 0){
1:             close();
1:             return null;
1: 
1:       } else {
1:         close();
1:         return null;
1: 
0:       Block[] blocks = new Block[types.size()];
1:       for (int column = 0; column < blocks.length; column++) {
0:         Type type = types.get(column);
0:         readers[column].setBatchSize(columnarBatch.numRows());
0:         readers[column].setVectorReader(true);
0:         readers[column].setVector(columnarBatch.column(column));
0:         blocks[column] = new LazyBlock(batchSize, new CarbondataBlockLoader(column, type));
1:       }
1:       Page page = new Page(batchSize, blocks);
0:       sizeOfData += columnarBatch.capacity();
1:       return page;
1:     }
0:     catch (PrestoException e) {
1:       closeWithSuppression(e);
1:       throw e;
1:     }
0:     catch ( RuntimeException e) {
1:       closeWithSuppression(e);
1:       throw new CarbonDataLoadingException("Exception when creating the Carbon data Block", e);
0:     } catch (InterruptedException e) {
1:       closeWithSuppression(e);
1:       throw new CarbonDataLoadingException("Exception when creating the Carbon data Block", e);
0:     } catch (IOException e) {
1:       closeWithSuppression(e);
1:       throw new CarbonDataLoadingException("Exception when creating the Carbon data Block", e);
1:     return sizeOfData;
0:   @Override public void close()  {
1:     // some hive input formats are broken and bad things can happen if you close them multiple times
1:     if (closed) {
1:       return;
1:     closed = true;
1:     try {
1:       vectorReader.close();
0:       cursor.close();
1:       nanoEnd = System.nanoTime();
1:     } catch (Exception e) {
1:       throw Throwables.propagate(e);
1:     }
1: 
1:   }
1: 
0:   protected void closeWithSuppression(Throwable throwable)
0:   {
1:     requireNonNull(throwable, "throwable is null");
1:     try {
1:       close();
1:     }
0:     catch (RuntimeException e) {
1:       // Self-suppression not permitted
1:       logger.error(e, e.getMessage());
1:       if (throwable != e) {
1:         throwable.addSuppressed(e);
1:       }
1:     }
1:    * Lazy Block Implementation for the Carbondata
0:   private final class CarbondataBlockLoader
0:       implements LazyBlockLoader<LazyBlock>
0:   {
1:     private final int expectedBatchId = batchId;
1:     private final int columnIndex;
0:     private final Type type;
0:     public CarbondataBlockLoader(int columnIndex, Type type)
0:     {
1:       this.columnIndex = columnIndex;
0:       this.type = requireNonNull(type, "type is null");
0:     @Override
0:     public final void load(LazyBlock lazyBlock)
0:     {
1: 
1:       checkState(batchId == expectedBatchId);
1: 
1:       try {
0:         Block block = readers[columnIndex].readBlock(type);
1:         lazyBlock.setBlock(block);
1:       }
0:       catch (IOException e) {
1:         throw new CarbonDataLoadingException("Error in Reading Data from Carbondata ", e);
1:       }
1: 
1: 
1: 
1:   /**
0:    * Create the Stream Reader for every column based on their type
0:    * This method will be initialized only once based on the types.
1:    *
0:    * @return
1:    */
0:   private StreamReader[] createStreamReaders( ) {
0:     requireNonNull(types);
0:     StreamReader[] readers = new StreamReader[types.size()];
0:     for (int i = 0; i < types.size(); i++) {
0:       readers[i] =
0:           StreamReaders.createStreamReader(types.get(i), readSupport.getSliceArrayBlock(i));
1:     }
0:     return readers;
1:   }
1: 
1: }
commit:9669c0b
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.carbondata.presto;
1: 
1: import java.io.IOException;
0: import java.math.BigDecimal;
0: import java.util.ArrayList;
1: import java.util.List;
1: 
1: import com.facebook.presto.spi.ConnectorPageSource;
1: import com.facebook.presto.spi.Page;
0: import com.facebook.presto.spi.PageBuilder;
0: import com.facebook.presto.spi.RecordCursor;
0: import com.facebook.presto.spi.RecordSet;
0: import com.facebook.presto.spi.block.BlockBuilder;
0: import com.facebook.presto.spi.type.DecimalType;
0: import com.facebook.presto.spi.type.Type;
0: import io.airlift.slice.Slice;
1: 
0: import static com.facebook.presto.spi.type.Decimals.encodeUnscaledValue;
0: import static com.facebook.presto.spi.type.Decimals.isShortDecimal;
0: import static com.google.common.base.Preconditions.checkArgument;
1: import static com.google.common.base.Preconditions.checkState;
0: import static java.math.RoundingMode.HALF_UP;
0: import static java.util.Collections.unmodifiableList;
0: import static java.util.Objects.requireNonNull;
1: 
1: /**
1:  * Carbondata Page Source class for custom Carbondata RecordSet Iteration.
1:  */
0: public class CarbondataPageSource implements ConnectorPageSource {
1: 
0:   private static final int ROWS_PER_REQUEST = 4096;
0:   private final RecordCursor cursor;
0:   private final List<Type> types;
0:   private final PageBuilder pageBuilder;
1:   private boolean closed;
0:   private final char[] buffer = new char[100];
1: 
0:   public CarbondataPageSource(RecordSet recordSet)
0:   {
0:     this(requireNonNull(recordSet, "recordSet is null").getColumnTypes(), recordSet.cursor());
1:   }
1: 
0:   public CarbondataPageSource(List<Type> types, RecordCursor cursor)
0:   {
0:     this.cursor = requireNonNull(cursor, "cursor is null");
0:     this.types = unmodifiableList(new ArrayList<>(requireNonNull(types, "types is null")));
0:     this.pageBuilder = new PageBuilder(this.types);
1:   }
1: 
0:   public RecordCursor getCursor()
0:   {
0:     return cursor;
1:   }
1: 
0:   @Override public long getTotalBytes() {
0:     return cursor.getTotalBytes();
1:   }
1: 
1:   @Override public long getCompletedBytes() {
0:     return cursor.getCompletedBytes();
1:   }
1: 
1:   @Override public long getReadTimeNanos() {
0:     return cursor.getReadTimeNanos();
1:   }
1: 
1:   @Override public boolean isFinished() {
0:     return closed && pageBuilder.isEmpty();
1:   }
1: 
1:   @Override public Page getNextPage() {
0:     if (!closed) {
0:       int i;
0:       for (i = 0; i < ROWS_PER_REQUEST; i++) {
0:         if (pageBuilder.isFull()) {
0:           break;
1:         }
0:         if (!cursor.advanceNextPosition()) {
0:           closed = true;
0:           break;
1:         }
1: 
0:         pageBuilder.declarePosition();
0:         for (int column = 0; column < types.size(); column++) {
0:           BlockBuilder output = pageBuilder.getBlockBuilder(column);
0:           if (cursor.isNull(column)) {
0:             output.appendNull();
0:           } else {
0:             Type type = types.get(column);
0:             Class<?> javaType = type.getJavaType();
0:             if (javaType == boolean.class) {
0:               type.writeBoolean(output, cursor.getBoolean(column));
0:             } else if (javaType == long.class) {
0:               type.writeLong(output, cursor.getLong(column));
0:             } else if (javaType == double.class) {
0:               type.writeDouble(output, cursor.getDouble(column));
0:             } else if (javaType == Slice.class) {
0:               Slice slice = cursor.getSlice(column);
0:               if(type instanceof  DecimalType)
0:               {
0:                 if (isShortDecimal(type)) {
0:                   type.writeLong(output, parseLong((DecimalType) type, slice, 0, slice.length()));
0:                 } else {
0:                   type.writeSlice(output, parseSlice((DecimalType) type, slice, 0, slice.length()));
1:                 }
0:               } else {
0:                 type.writeSlice(output, slice, 0, slice.length());
1:               }
0:             } else {
0:               type.writeObject(output, cursor.getObject(column));
1:             }
1:           }
1:         }
1:       }
1:     }
1: 
0:     // only return a page if the buffer is full or we are finishing
0:     if (pageBuilder.isEmpty() || (!closed && !pageBuilder.isFull())) {
1:       return null;
1:     }
0:     Page page = pageBuilder.build();
0:     pageBuilder.reset();
0:     return page;
1:  }
1: 
1:   @Override public long getSystemMemoryUsage() {
0:     return cursor.getSystemMemoryUsage() + pageBuilder.getSizeInBytes();
1:   }
1: 
0:   @Override public void close() throws IOException {
0:     closed = true;
0:     cursor.close();
1: 
1:   }
1: 
0:   private long parseLong(DecimalType type, Slice slice, int offset, int length)
0:   {
0:     BigDecimal decimal = parseBigDecimal(type, slice, offset, length);
0:     return decimal.unscaledValue().longValue();
1:   }
1: 
1: 
0:   private Slice parseSlice(DecimalType type, Slice slice, int offset, int length)
0:   {
0:     BigDecimal decimal = parseBigDecimal(type, slice, offset, length);
0:     return encodeUnscaledValue(decimal.unscaledValue());
1:   }
1: 
0:   private BigDecimal parseBigDecimal(DecimalType type, Slice slice, int offset, int length)
0:   {
0:     checkArgument(length < buffer.length);
0:     for (int i = 0; i < length; i++) {
0:       buffer[i] = (char) slice.getByte(offset + i);
1:     }
0:     BigDecimal decimal = new BigDecimal(buffer, 0, length);
0:     checkState(decimal.scale() <= type.getScale(), "Read decimal value scale larger than column scale");
0:     decimal = decimal.setScale(type.getScale(), HALF_UP);
0:     checkState(decimal.precision() <= type.getPrecision(), "Read decimal precision larger than column precision");
0:     return decimal;
1:   }
1: }
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
1:   private PrestoCarbonVectorizedRecordReader vectorReader;
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.processing.loading.exception.CarbonDataLoadingException;
author:anubhav100
-------------------------------------------------------------------------------
commit:6add19a
/////////////////////////////////////////////////////////////////////////
0:     this(requireNonNull(recordSet, "recordSet is null").getColumnTypes(),
0:         recordSet.cursor());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     catch ( RuntimeException | InterruptedException | IOException e) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:       readers[i] = StreamReaders.createStreamReader(types.get(i), readSupport
0:           .getSliceArrayBlock(i),readSupport.getDictionaries()[i]);
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:590bbb9
/////////////////////////////////////////////////////////////////////////
1:         Object vectorBatch = vectorReader.getCurrentValue();
0:         if(vectorBatch != null && vectorBatch instanceof ColumnarBatch)
/////////////////////////////////////////////////////////////////////////
1:       if (columnarBatch == null) {
0:         return null;
0:       }
author:Raghunandan S
-------------------------------------------------------------------------------
commit:110f9b2
/////////////////////////////////////////////////////////////////////////
0:   private static final class CarbonBlockLoader implements LazyBlockLoader<LazyBlock> {
author:Bhavya Aggarwal
-------------------------------------------------------------------------------
commit:f2bb8d3
/////////////////////////////////////////////////////////////////////////
1: import com.facebook.presto.spi.block.Block;
1: import com.facebook.presto.spi.block.LazyBlock;
1: import com.facebook.presto.spi.block.LazyBlockLoader;
/////////////////////////////////////////////////////////////////////////
0:   private Block[] blocks;
0:   public CarbondataPageSource(RecordSet recordSet) {
0:   public CarbondataPageSource(List<Type> types, RecordCursor cursor) {
0:     this.blocks = new Block[types.size()];
0:   public RecordCursor getCursor() {
/////////////////////////////////////////////////////////////////////////
0:     BlockBuilder output;
0:     Page page;
0:     int size = types.size();
/////////////////////////////////////////////////////////////////////////
0: 
0:         for (int column = 0; column < size; column++) {
0:           output = pageBuilder.getBlockBuilder(column);
/////////////////////////////////////////////////////////////////////////
0:               if (type instanceof DecimalType) {
/////////////////////////////////////////////////////////////////////////
0:           blocks[column] = new LazyBlock(output.getPositionCount(),
0:               new CarbonBlockLoader(output.build(), types.get(column)));
/////////////////////////////////////////////////////////////////////////
0: 
0:     if (blocks != null && blocks.length > 0) {
0:       page = new Page(blocks[0].getPositionCount(), blocks);
0:     } else {
0:       page = pageBuilder.build();
0:     }
0: 
0:   }
/////////////////////////////////////////////////////////////////////////
0:   private long parseLong(DecimalType type, Slice slice, int offset, int length) {
0:   private Slice parseSlice(DecimalType type, Slice slice, int offset, int length) {
0:   private BigDecimal parseBigDecimal(DecimalType type, Slice slice, int offset, int length) {
0:     checkState(decimal.scale() <= type.getScale(),
0:         "Read decimal value scale larger than column scale");
0:     checkState(decimal.precision() <= type.getPrecision(),
0:         "Read decimal precision larger than column precision");
0: 
0:   /**
0:    * Using the LazyBlockLoader
0:    */
0:   private final class CarbonBlockLoader implements LazyBlockLoader<LazyBlock> {
1:     private boolean loaded;
0:     private Block dataBlock;
0:     private Type type;
0: 
0:     public CarbonBlockLoader(Block dataBlock, Type type) {
0:       this.dataBlock = dataBlock;
0:       this.type = type;
0:     }
0: 
0:     @Override public void load(LazyBlock block) {
1:       if (loaded) {
1:         return;
0:       }
0:       block.setBlock(dataBlock);
1:       loaded = true;
0:     }
0:   }
============================================================================
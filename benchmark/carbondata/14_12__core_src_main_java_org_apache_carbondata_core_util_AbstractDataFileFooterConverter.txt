1:d54dc64: /*
1:41347d8:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:41347d8:  * contributor license agreements.  See the NOTICE file distributed with
1:41347d8:  * this work for additional information regarding copyright ownership.
1:41347d8:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:41347d8:  * (the "License"); you may not use this file except in compliance with
1:41347d8:  * the License.  You may obtain a copy of the License at
5:d54dc64:  *
1:d54dc64:  *    http://www.apache.org/licenses/LICENSE-2.0
1:d54dc64:  *
1:41347d8:  * Unless required by applicable law or agreed to in writing, software
1:41347d8:  * distributed under the License is distributed on an "AS IS" BASIS,
1:41347d8:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:41347d8:  * See the License for the specific language governing permissions and
1:41347d8:  * limitations under the License.
5:d54dc64:  */
1:d54dc64: package org.apache.carbondata.core.util;
5:d54dc64: 
1:d54dc64: import java.io.IOException;
1:d54dc64: import java.nio.ByteBuffer;
1:d54dc64: import java.util.ArrayList;
1:d54dc64: import java.util.BitSet;
1:d54dc64: import java.util.List;
1:9f94529: import java.util.Map;
1:d54dc64: 
1:d54dc64: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:ce09aaa: import org.apache.carbondata.core.datastore.block.BlockInfo;
1:ce09aaa: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:ce09aaa: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1:d54dc64: import org.apache.carbondata.core.metadata.ValueEncoderMeta;
1:1e21cd1: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.SegmentInfo;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.datachunk.DataChunk;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.index.BlockletBTreeIndex;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
1:ce09aaa: import org.apache.carbondata.core.metadata.blocklet.index.BlockletMinMaxIndex;
1:ce09aaa: import org.apache.carbondata.core.metadata.datatype.DataType;
1:956833e: import org.apache.carbondata.core.metadata.datatype.DataTypes;
1:f209e8e: import org.apache.carbondata.core.metadata.datatype.DecimalType;
1:ce09aaa: import org.apache.carbondata.core.metadata.encoder.Encoding;
1:3169918: import org.apache.carbondata.core.metadata.schema.table.RelationIdentifier;
1:ce09aaa: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
1:3169918: import org.apache.carbondata.core.metadata.schema.table.column.ParentColumnTableRelation;
1:d54dc64: import org.apache.carbondata.core.reader.CarbonIndexFileReader;
1:3894e1d: import org.apache.carbondata.core.scan.executor.util.QueryUtil;
1:ae4a30c: import org.apache.carbondata.core.util.path.CarbonTablePath;
1:d54dc64: import org.apache.carbondata.format.BlockIndex;
1:d54dc64: 
1:8f1a029: import org.apache.hadoop.conf.Configuration;
1:8f1a029: 
5:d54dc64: /**
1:d54dc64:  * Footer reader class
1:d54dc64:  */
1:d54dc64: public abstract class AbstractDataFileFooterConverter {
1:d54dc64: 
1:8f1a029:   protected Configuration configuration;
1:8f1a029: 
1:8f1a029:   AbstractDataFileFooterConverter(Configuration configuration) {
1:8f1a029:     this.configuration = configuration;
1:8f1a029:   }
1:8f1a029: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to convert the thrift presence meta to wrapper
1:d54dc64:    * presence meta
1:d54dc64:    *
1:d54dc64:    * @param presentMetadataThrift
1:d54dc64:    * @return wrapper presence meta
1:d54dc64:    */
1:e6a4f64:   private static BitSet getPresenceMeta(
1:d54dc64:       org.apache.carbondata.format.PresenceMeta presentMetadataThrift) {
1:7ef9164:     final byte[] present_bit_stream = presentMetadataThrift.getPresent_bit_stream();
1:7ef9164:     if (null != present_bit_stream) {
1:7ef9164:       return BitSet.valueOf(present_bit_stream);
1:7ef9164:     } else {
1:7ef9164:       return new BitSet(1);
1:7ef9164:     }
5:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:b681244:    * Below method will be used to get the index info from index file
1:b681244:    *
1:b681244:    * @param filePath           file path of the index file
1:d54dc64:    * @param tableBlockInfoList table block index
1:b681244:    * @return list of index info
1:b681244:    * @throws IOException problem while reading the index file
1:b681244:    */
1:8f1a029:   public List<DataFileFooter> getIndexInfo(String filePath, List<TableBlockInfo>
1:8f1a029:       tableBlockInfoList)
1:eaadc88:       throws IOException {
1:b681244:     CarbonIndexFileReader indexReader = new CarbonIndexFileReader();
1:b681244:     List<DataFileFooter> dataFileFooters = new ArrayList<DataFileFooter>();
1:b681244:     try {
1:b681244:       // open the reader
1:b681244:       indexReader.openThriftReader(filePath);
1:b681244:       // get the index header
1:b681244:       org.apache.carbondata.format.IndexHeader readIndexHeader = indexReader.readIndexHeader();
1:b681244:       List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:b681244:       List<org.apache.carbondata.format.ColumnSchema> table_columns =
1:b681244:           readIndexHeader.getTable_columns();
1:b681244:       for (int i = 0; i < table_columns.size(); i++) {
1:8896a63:         columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
1:b681244:       }
1:b681244:       // get the segment info
1:b681244:       SegmentInfo segmentInfo = getSegmentInfo(readIndexHeader.getSegment_info());
1:b681244:       BlockletIndex blockletIndex = null;
1:d54dc64:       int counter = 0;
1:ae4a30c:       int index = 0;
1:b681244:       DataFileFooter dataFileFooter = null;
1:b681244:       // read the block info from file
1:b681244:       while (indexReader.hasNext()) {
1:b681244:         BlockIndex readBlockIndexInfo = indexReader.readBlockIndexInfo();
1:b681244:         blockletIndex = getBlockletIndex(readBlockIndexInfo.getBlock_index());
1:b681244:         dataFileFooter = new DataFileFooter();
1:ae4a30c:         TableBlockInfo tableBlockInfo = tableBlockInfoList.get(index);
1:ae4a30c:         if (Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(
1:ae4a30c:             tableBlockInfo.getFilePath())) == counter++) {
1:b681244:           tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
1:b681244:           tableBlockInfo.setVersion(
1:b681244:               ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion()));
1:b681244:           int blockletSize = getBlockletSize(readBlockIndexInfo);
1:b681244:           tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
1:d54dc64:           dataFileFooter.setBlockletIndex(blockletIndex);
1:d54dc64:           dataFileFooter.setColumnInTable(columnSchemaList);
1:d54dc64:           dataFileFooter.setNumberOfRows(readBlockIndexInfo.getNum_rows());
1:d54dc64:           dataFileFooter.setBlockInfo(new BlockInfo(tableBlockInfo));
1:d54dc64:           dataFileFooter.setSegmentInfo(segmentInfo);
1:d54dc64:           dataFileFooters.add(dataFileFooter);
1:ae4a30c:           if (++index == tableBlockInfoList.size()) {
1:ae4a30c:             break;
1:d54dc64:           }
1:d54dc64:         }
1:d54dc64:       }
1:d54dc64:     } finally {
1:d54dc64:       indexReader.closeThriftReader();
1:d54dc64:     }
1:d54dc64:     return dataFileFooters;
1:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to get the index info from index file
1:d54dc64:    *
1:d54dc64:    * @param filePath           file path of the index file
1:d54dc64:    * @return list of index info
1:d54dc64:    * @throws IOException problem while reading the index file
1:d54dc64:    */
1:0586146:   public List<DataFileFooter> getIndexInfo(String filePath, byte[] fileData) throws IOException {
1:3894e1d:     return getIndexInfo(filePath, fileData, true);
1:3894e1d:   }
1:3894e1d: 
1:3894e1d:   /**
1:3894e1d:    * Below method will be used to get the index info from index file
1:3894e1d:    */
1:3894e1d:   public List<DataFileFooter> getIndexInfo(String filePath, byte[] fileData,
1:3894e1d:       boolean isTransactionalTable) throws IOException {
1:8f1a029:     CarbonIndexFileReader indexReader = new CarbonIndexFileReader(configuration);
1:d54dc64:     List<DataFileFooter> dataFileFooters = new ArrayList<DataFileFooter>();
1:b681244:     String parentPath = filePath.substring(0, filePath.lastIndexOf("/"));
1:d54dc64:     try {
1:d54dc64:       // open the reader
1:0586146:       if (fileData != null) {
1:0586146:         indexReader.openThriftReader(fileData);
1:0586146:       } else {
1:0586146:         indexReader.openThriftReader(filePath);
1:0586146:       }
1:d54dc64:       // get the index header
1:d54dc64:       org.apache.carbondata.format.IndexHeader readIndexHeader = indexReader.readIndexHeader();
1:d54dc64:       List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:d54dc64:       List<org.apache.carbondata.format.ColumnSchema> table_columns =
1:d54dc64:           readIndexHeader.getTable_columns();
1:d54dc64:       for (int i = 0; i < table_columns.size(); i++) {
1:8896a63:         columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
1:b681244:       }
1:3894e1d:       if (!isTransactionalTable) {
1:3894e1d:         QueryUtil.updateColumnUniqueIdForNonTransactionTable(columnSchemaList);
1:3894e1d:       }
1:d54dc64:       // get the segment info
1:d54dc64:       SegmentInfo segmentInfo = getSegmentInfo(readIndexHeader.getSegment_info());
1:d54dc64:       BlockletIndex blockletIndex = null;
1:d54dc64:       DataFileFooter dataFileFooter = null;
1:d54dc64:       // read the block info from file
1:d54dc64:       while (indexReader.hasNext()) {
1:d54dc64:         BlockIndex readBlockIndexInfo = indexReader.readBlockIndexInfo();
1:d54dc64:         blockletIndex = getBlockletIndex(readBlockIndexInfo.getBlock_index());
1:d54dc64:         dataFileFooter = new DataFileFooter();
1:e820006:         TableBlockInfo tableBlockInfo =
1:e820006:             getTableBlockInfo(readBlockIndexInfo, readIndexHeader, parentPath);
1:b681244:         dataFileFooter.setBlockletIndex(blockletIndex);
1:b681244:         dataFileFooter.setColumnInTable(columnSchemaList);
1:b681244:         dataFileFooter.setNumberOfRows(readBlockIndexInfo.getNum_rows());
1:b681244:         dataFileFooter.setBlockInfo(new BlockInfo(tableBlockInfo));
1:b681244:         dataFileFooter.setSegmentInfo(segmentInfo);
1:e820006:         dataFileFooter.setVersionId(tableBlockInfo.getVersion());
1:7ed144c:         // In case of old schema time stamp will not be found in the index header
1:7ed144c:         if (readIndexHeader.isSetSchema_time_stamp()) {
1:7ed144c:           dataFileFooter.setSchemaUpdatedTimeStamp(readIndexHeader.getSchema_time_stamp());
1:b681244:         }
1:1e21cd1:         if (readBlockIndexInfo.isSetBlocklet_info()) {
1:1e21cd1:           List<BlockletInfo> blockletInfoList = new ArrayList<BlockletInfo>();
1:8f1a029:           BlockletInfo blockletInfo = new DataFileFooterConverterV3(configuration)
1:1e21cd1:               .getBlockletInfo(readBlockIndexInfo.getBlocklet_info(),
1:1e21cd1:                   CarbonUtil.getNumberOfDimensionColumns(columnSchemaList));
1:1e21cd1:           blockletInfo.setBlockletIndex(blockletIndex);
1:1e21cd1:           blockletInfoList.add(blockletInfo);
1:1e21cd1:           dataFileFooter.setBlockletList(blockletInfoList);
1:7ed144c:         }
1:b681244:         dataFileFooters.add(dataFileFooter);
1:d54dc64:       }
1:b681244:     } finally {
1:b681244:       indexReader.closeThriftReader();
1:d54dc64:     }
1:b681244:     return dataFileFooters;
1:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:e820006:    * This method will create a table block info object from index file info
1:e820006:    *
1:e820006:    * @param readBlockIndexInfo
1:e820006:    * @param readIndexHeader
1:e820006:    * @param parentPath
1:e820006:    * @return
1:e820006:    */
1:e820006:   public TableBlockInfo getTableBlockInfo(BlockIndex readBlockIndexInfo,
1:e820006:       org.apache.carbondata.format.IndexHeader readIndexHeader, String parentPath) {
1:b681244:     TableBlockInfo tableBlockInfo = new TableBlockInfo();
1:e820006:     tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
1:e820006:     ColumnarFormatVersion version =
1:e820006:         ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion());
1:e820006:     tableBlockInfo.setVersion(version);
1:e820006:     int blockletSize = getBlockletSize(readBlockIndexInfo);
1:e820006:     tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
1:e820006:     String fileName = readBlockIndexInfo.file_name;
1:e820006:     // Take only name of file.
1:e820006:     if (fileName.lastIndexOf("/") > 0) {
1:e820006:       fileName = fileName.substring(fileName.lastIndexOf("/"));
1:b681244:     }
1:1202e20:     fileName = (CarbonCommonConstants.FILE_SEPARATOR + fileName).replaceAll("//", "/");
1:1202e20:     tableBlockInfo.setFilePath(parentPath + fileName);
1:e820006:     return tableBlockInfo;
1:e820006:   }
1:b681244: 
1:b681244:   /**
1:d54dc64:    * the methods returns the number of blocklets in a block
1:d54dc64:    *
1:d54dc64:    * @param readBlockIndexInfo
1:d54dc64:    * @return
1:d54dc64:    */
1:d54dc64:   protected int getBlockletSize(BlockIndex readBlockIndexInfo) {
1:d54dc64:     long num_rows = readBlockIndexInfo.getNum_rows();
1:d54dc64:     int blockletSize = Integer.parseInt(CarbonProperties.getInstance()
1:d54dc64:         .getProperty(CarbonCommonConstants.BLOCKLET_SIZE,
1:d54dc64:             CarbonCommonConstants.BLOCKLET_SIZE_DEFAULT_VAL));
1:d54dc64:     int remainder = (int) (num_rows % blockletSize);
1:d54dc64:     int noOfBlockLet = (int) (num_rows / blockletSize);
1:d54dc64:     // there could be some blocklets which will not
1:d54dc64:     // contain the total records equal to the blockletSize
1:d54dc64:     if (remainder > 0) {
1:d54dc64:       noOfBlockLet = noOfBlockLet + 1;
1:e820006:     }
1:d54dc64:     return noOfBlockLet;
1:d54dc64:   }
1:e820006: 
1:e820006:   /**
1:d54dc64:    * Below method will be used to convert thrift file meta to wrapper file meta
1:d54dc64:    */
1:d54dc64:   public abstract DataFileFooter readDataFileFooter(TableBlockInfo tableBlockInfo)
1:d54dc64:       throws IOException;
1:d54dc64: 
1:b681244:   public abstract List<ColumnSchema> getSchema(TableBlockInfo tableBlockInfo) throws IOException;
1:b681244: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to get blocklet index for data file meta
1:d54dc64:    *
1:d54dc64:    * @param blockletIndexList
1:d54dc64:    * @return blocklet index
1:d54dc64:    */
1:d54dc64:   protected BlockletIndex getBlockletIndexForDataFileFooter(List<BlockletIndex> blockletIndexList) {
1:d54dc64:     BlockletIndex blockletIndex = new BlockletIndex();
1:d54dc64:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:d54dc64:     blockletBTreeIndex.setStartKey(blockletIndexList.get(0).getBtreeIndex().getStartKey());
1:d54dc64:     blockletBTreeIndex
1:d54dc64:         .setEndKey(blockletIndexList.get(blockletIndexList.size() - 1).getBtreeIndex().getEndKey());
1:d54dc64:     blockletIndex.setBtreeIndex(blockletBTreeIndex);
1:d54dc64:     byte[][] currentMinValue = blockletIndexList.get(0).getMinMaxIndex().getMinValues().clone();
1:d54dc64:     byte[][] currentMaxValue = blockletIndexList.get(0).getMinMaxIndex().getMaxValues().clone();
1:d54dc64:     byte[][] minValue = null;
1:d54dc64:     byte[][] maxValue = null;
1:d54dc64:     for (int i = 1; i < blockletIndexList.size(); i++) {
1:d54dc64:       minValue = blockletIndexList.get(i).getMinMaxIndex().getMinValues();
1:d54dc64:       maxValue = blockletIndexList.get(i).getMinMaxIndex().getMaxValues();
1:d54dc64:       for (int j = 0; j < maxValue.length; j++) {
1:d54dc64:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(currentMinValue[j], minValue[j]) > 0) {
1:d54dc64:           currentMinValue[j] = minValue[j].clone();
1:d54dc64:         }
1:d54dc64:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(currentMaxValue[j], maxValue[j]) < 0) {
1:d54dc64:           currentMaxValue[j] = maxValue[j].clone();
1:d54dc64:         }
1:d54dc64:       }
1:d54dc64:     }
1:d54dc64: 
1:d54dc64:     BlockletMinMaxIndex minMax = new BlockletMinMaxIndex();
1:d54dc64:     minMax.setMaxValues(currentMaxValue);
1:d54dc64:     minMax.setMinValues(currentMinValue);
1:d54dc64:     blockletIndex.setMinMaxIndex(minMax);
1:d54dc64:     return blockletIndex;
1:d54dc64:   }
1:d54dc64: 
1:8896a63:   protected ColumnSchema thriftColumnSchemaToWrapperColumnSchema(
1:d54dc64:       org.apache.carbondata.format.ColumnSchema externalColumnSchema) {
1:d54dc64:     ColumnSchema wrapperColumnSchema = new ColumnSchema();
1:d54dc64:     wrapperColumnSchema.setColumnUniqueId(externalColumnSchema.getColumn_id());
1:d54dc64:     wrapperColumnSchema.setColumnName(externalColumnSchema.getColumn_name());
1:fb6dffe:     DataType dataType = CarbonUtil.thriftDataTyopeToWrapperDataType(externalColumnSchema.data_type);
1:f209e8e:     if (DataTypes.isDecimal(dataType)) {
1:f209e8e:       DecimalType decimalType = (DecimalType) dataType;
1:f209e8e:       decimalType.setPrecision(externalColumnSchema.getPrecision());
1:f209e8e:       decimalType.setScale(externalColumnSchema.getScale());
1:f209e8e:     }
1:f209e8e:     wrapperColumnSchema.setDataType(dataType);
1:d54dc64:     wrapperColumnSchema.setDimensionColumn(externalColumnSchema.isDimension());
1:d54dc64:     List<Encoding> encoders = new ArrayList<Encoding>();
1:d54dc64:     for (org.apache.carbondata.format.Encoding encoder : externalColumnSchema.getEncoders()) {
1:d54dc64:       encoders.add(fromExternalToWrapperEncoding(encoder));
1:d54dc64:     }
1:d54dc64:     wrapperColumnSchema.setEncodingList(encoders);
1:d54dc64:     wrapperColumnSchema.setNumberOfChild(externalColumnSchema.getNum_child());
1:d54dc64:     wrapperColumnSchema.setPrecision(externalColumnSchema.getPrecision());
1:d54dc64:     wrapperColumnSchema.setScale(externalColumnSchema.getScale());
1:d54dc64:     wrapperColumnSchema.setDefaultValue(externalColumnSchema.getDefault_value());
1:9f94529:     Map<String, String> properties = externalColumnSchema.getColumnProperties();
1:9f94529:     if (properties != null) {
1:9f94529:       if (properties.get(CarbonCommonConstants.SORT_COLUMNS) != null) {
1:9f94529:         wrapperColumnSchema.setSortColumn(true);
1:49763b7:       }
1:49763b7:     }
1:54eedfe:     wrapperColumnSchema.setFunction(externalColumnSchema.getAggregate_function());
1:3169918:     List<org.apache.carbondata.format.ParentColumnTableRelation> parentColumnTableRelation =
1:3169918:         externalColumnSchema.getParentColumnTableRelations();
1:3169918:     if (null != parentColumnTableRelation) {
1:3169918:       wrapperColumnSchema.setParentColumnTableRelations(
1:3169918:           fromThriftToWrapperParentTableColumnRelations(parentColumnTableRelation));
1:3169918:     }
1:d54dc64:     return wrapperColumnSchema;
1:d54dc64:   }
1:d54dc64: 
1:3169918:   private List<ParentColumnTableRelation> fromThriftToWrapperParentTableColumnRelations(
1:3169918:       List<org.apache.carbondata.format.ParentColumnTableRelation> thirftParentColumnRelation) {
1:3169918:     List<ParentColumnTableRelation> parentColumnTableRelationList = new ArrayList<>();
1:3169918:     for (org.apache.carbondata.format.ParentColumnTableRelation carbonTableRelation :
1:3169918:         thirftParentColumnRelation) {
1:3169918:       RelationIdentifier relationIdentifier =
1:3169918:           new RelationIdentifier(carbonTableRelation.getRelationIdentifier().getDatabaseName(),
1:3169918:               carbonTableRelation.getRelationIdentifier().getTableName(),
1:3169918:               carbonTableRelation.getRelationIdentifier().getTableId());
1:3169918:       ParentColumnTableRelation parentColumnTableRelation =
1:3169918:           new ParentColumnTableRelation(relationIdentifier, carbonTableRelation.getColumnId(),
1:3169918:               carbonTableRelation.getColumnName());
1:3169918:       parentColumnTableRelationList.add(parentColumnTableRelation);
1:3169918:     }
1:3169918:     return parentColumnTableRelationList;
1:3169918:   }
1:3169918: 
1:3169918: 
1:3169918: 
1:d54dc64:   /**
1:d54dc64:    * Below method is convert the thrift encoding to wrapper encoding
1:d54dc64:    *
1:d54dc64:    * @param encoderThrift thrift encoding
1:d54dc64:    * @return wrapper encoding
1:d54dc64:    */
1:d54dc64:   protected Encoding fromExternalToWrapperEncoding(
1:d54dc64:       org.apache.carbondata.format.Encoding encoderThrift) {
1:d54dc64:     switch (encoderThrift) {
1:d54dc64:       case DICTIONARY:
1:d54dc64:         return Encoding.DICTIONARY;
1:d54dc64:       case DELTA:
1:d54dc64:         return Encoding.DELTA;
1:d54dc64:       case RLE:
1:d54dc64:         return Encoding.RLE;
1:d54dc64:       case INVERTED_INDEX:
1:d54dc64:         return Encoding.INVERTED_INDEX;
1:d54dc64:       case BIT_PACKED:
1:d54dc64:         return Encoding.BIT_PACKED;
1:d54dc64:       case DIRECT_DICTIONARY:
1:d54dc64:         return Encoding.DIRECT_DICTIONARY;
3:d54dc64:       default:
1:d54dc64:         throw new IllegalArgumentException(encoderThrift.toString() + " is not supported");
1:d54dc64:     }
1:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to convert thrift segment object to wrapper
1:d54dc64:    * segment object
1:d54dc64:    *
1:d54dc64:    * @param segmentInfo thrift segment info object
1:d54dc64:    * @return wrapper segment info object
1:d54dc64:    */
1:d54dc64:   protected SegmentInfo getSegmentInfo(org.apache.carbondata.format.SegmentInfo segmentInfo) {
1:d54dc64:     SegmentInfo info = new SegmentInfo();
1:d54dc64:     int[] cardinality = new int[segmentInfo.getColumn_cardinalities().size()];
1:d54dc64:     for (int i = 0; i < cardinality.length; i++) {
1:d54dc64:       cardinality[i] = segmentInfo.getColumn_cardinalities().get(i);
1:d54dc64:     }
1:d54dc64:     info.setColumnCardinality(cardinality);
1:d54dc64:     return info;
1:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to convert the blocklet index of thrift to
1:d54dc64:    * wrapper
1:d54dc64:    *
1:d54dc64:    * @param blockletIndexThrift
1:d54dc64:    * @return blocklet index wrapper
1:d54dc64:    */
1:d54dc64:   protected BlockletIndex getBlockletIndex(
1:d54dc64:       org.apache.carbondata.format.BlockletIndex blockletIndexThrift) {
1:d54dc64:     org.apache.carbondata.format.BlockletBTreeIndex btreeIndex =
1:d54dc64:         blockletIndexThrift.getB_tree_index();
1:d54dc64:     org.apache.carbondata.format.BlockletMinMaxIndex minMaxIndex =
1:d54dc64:         blockletIndexThrift.getMin_max_index();
1:d54dc64:     return new BlockletIndex(
1:d54dc64:         new BlockletBTreeIndex(btreeIndex.getStart_key(), btreeIndex.getEnd_key()),
1:d54dc64:         new BlockletMinMaxIndex(minMaxIndex.getMin_values(), minMaxIndex.getMax_values()));
1:d54dc64:   }
1:d54dc64: 
1:d54dc64:   /**
1:d54dc64:    * Below method will be used to convert the thrift data chunk to wrapper
1:d54dc64:    * data chunk
1:d54dc64:    *
1:d54dc64:    * @param datachunkThrift
1:d54dc64:    * @return wrapper data chunk
1:d54dc64:    */
1:d54dc64:   protected DataChunk getDataChunk(org.apache.carbondata.format.DataChunk datachunkThrift,
1:d54dc64:       boolean isPresenceMetaPresent) {
1:d54dc64:     DataChunk dataChunk = new DataChunk();
1:d54dc64:     dataChunk.setDataPageLength(datachunkThrift.getData_page_length());
1:d54dc64:     dataChunk.setDataPageOffset(datachunkThrift.getData_page_offset());
1:d54dc64:     if (isPresenceMetaPresent) {
1:d54dc64:       dataChunk.setNullValueIndexForColumn(getPresenceMeta(datachunkThrift.getPresence()));
1:d54dc64:     }
1:d54dc64:     dataChunk.setRlePageLength(datachunkThrift.getRle_page_length());
1:d54dc64:     dataChunk.setRlePageOffset(datachunkThrift.getRle_page_offset());
1:d54dc64:     dataChunk.setRowMajor(datachunkThrift.isRowMajor());
1:d54dc64:     dataChunk.setRowIdPageLength(datachunkThrift.getRowid_page_length());
1:d54dc64:     dataChunk.setRowIdPageOffset(datachunkThrift.getRowid_page_offset());
1:d54dc64:     List<Encoding> encodingList = new ArrayList<Encoding>(datachunkThrift.getEncoders().size());
1:d54dc64:     for (int i = 0; i < datachunkThrift.getEncoders().size(); i++) {
1:d54dc64:       encodingList.add(fromExternalToWrapperEncoding(datachunkThrift.getEncoders().get(i)));
1:d54dc64:     }
1:eaadc88:     dataChunk.setEncodingList(encodingList);
1:d54dc64:     if (encodingList.contains(Encoding.DELTA)) {
1:d54dc64:       List<ByteBuffer> thriftEncoderMeta = datachunkThrift.getEncoder_meta();
1:d54dc64:       List<ValueEncoderMeta> encodeMetaList =
1:d54dc64:           new ArrayList<ValueEncoderMeta>(thriftEncoderMeta.size());
1:d54dc64:       for (int i = 0; i < thriftEncoderMeta.size(); i++) {
1:dc83b2a:         encodeMetaList.add(CarbonUtil.deserializeEncoderMetaV2(thriftEncoderMeta.get(i).array()));
1:d54dc64:       }
1:d54dc64:       dataChunk.setValueEncoderMeta(encodeMetaList);
1:d54dc64:     }
1:d54dc64:     return dataChunk;
1:d54dc64:   }
1:d54dc64: 
1:d54dc64: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:8f1a029
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
1: 
1:   protected Configuration configuration;
1: 
1:   AbstractDataFileFooterConverter(Configuration configuration) {
1:     this.configuration = configuration;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:   public List<DataFileFooter> getIndexInfo(String filePath, List<TableBlockInfo>
1:       tableBlockInfoList)
/////////////////////////////////////////////////////////////////////////
1:     CarbonIndexFileReader indexReader = new CarbonIndexFileReader(configuration);
/////////////////////////////////////////////////////////////////////////
1:           BlockletInfo blockletInfo = new DataFileFooterConverterV3(configuration)
author:ravipesala
-------------------------------------------------------------------------------
commit:3894e1d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.executor.util.QueryUtil;
/////////////////////////////////////////////////////////////////////////
1:     return getIndexInfo(filePath, fileData, true);
1:   }
1: 
1:   /**
1:    * Below method will be used to get the index info from index file
1:    */
1:   public List<DataFileFooter> getIndexInfo(String filePath, byte[] fileData,
1:       boolean isTransactionalTable) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:       if (!isTransactionalTable) {
1:         QueryUtil.updateColumnUniqueIdForNonTransactionTable(columnSchemaList);
1:       }
commit:0586146
/////////////////////////////////////////////////////////////////////////
1:   public List<DataFileFooter> getIndexInfo(String filePath, byte[] fileData) throws IOException {
1:       if (fileData != null) {
1:         indexReader.openThriftReader(fileData);
1:       } else {
1:         indexReader.openThriftReader(filePath);
1:       }
commit:b681244
/////////////////////////////////////////////////////////////////////////
1:    * Below method will be used to get the index info from index file
1:    *
1:    * @param filePath           file path of the index file
1:    * @return list of index info
1:    * @throws IOException problem while reading the index file
1:    */
0:   public List<DataFileFooter> getIndexInfo(String filePath) throws IOException {
1:     CarbonIndexFileReader indexReader = new CarbonIndexFileReader();
1:     List<DataFileFooter> dataFileFooters = new ArrayList<DataFileFooter>();
1:     String parentPath = filePath.substring(0, filePath.lastIndexOf("/"));
1:     try {
1:       // open the reader
1:       indexReader.openThriftReader(filePath);
1:       // get the index header
1:       org.apache.carbondata.format.IndexHeader readIndexHeader = indexReader.readIndexHeader();
1:       List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:       List<org.apache.carbondata.format.ColumnSchema> table_columns =
1:           readIndexHeader.getTable_columns();
1:       for (int i = 0; i < table_columns.size(); i++) {
0:         columnSchemaList.add(thriftColumnSchmeaToWrapperColumnSchema(table_columns.get(i)));
1:       }
1:       // get the segment info
1:       SegmentInfo segmentInfo = getSegmentInfo(readIndexHeader.getSegment_info());
1:       BlockletIndex blockletIndex = null;
1:       DataFileFooter dataFileFooter = null;
1:       // read the block info from file
1:       while (indexReader.hasNext()) {
1:         BlockIndex readBlockIndexInfo = indexReader.readBlockIndexInfo();
1:         blockletIndex = getBlockletIndex(readBlockIndexInfo.getBlock_index());
1:         dataFileFooter = new DataFileFooter();
1:         TableBlockInfo tableBlockInfo = new TableBlockInfo();
1:         tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
1:         tableBlockInfo.setVersion(
1:             ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion()));
1:         int blockletSize = getBlockletSize(readBlockIndexInfo);
1:         tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
0:         tableBlockInfo.setFilePath(parentPath + "/" + readBlockIndexInfo.file_name);
1:         dataFileFooter.setBlockletIndex(blockletIndex);
1:         dataFileFooter.setColumnInTable(columnSchemaList);
1:         dataFileFooter.setNumberOfRows(readBlockIndexInfo.getNum_rows());
1:         dataFileFooter.setBlockInfo(new BlockInfo(tableBlockInfo));
1:         dataFileFooter.setSegmentInfo(segmentInfo);
1:         dataFileFooters.add(dataFileFooter);
1:       }
1:     } finally {
1:       indexReader.closeThriftReader();
1:     }
1:     return dataFileFooters;
1:   }
1: 
1:   /**
/////////////////////////////////////////////////////////////////////////
1:   public abstract List<ColumnSchema> getSchema(TableBlockInfo tableBlockInfo) throws IOException;
1: 
author:manishgupta88
-------------------------------------------------------------------------------
commit:fb6dffe
/////////////////////////////////////////////////////////////////////////
1:     DataType dataType = CarbonUtil.thriftDataTyopeToWrapperDataType(externalColumnSchema.data_type);
/////////////////////////////////////////////////////////////////////////
commit:7ed144c
/////////////////////////////////////////////////////////////////////////
1:         // In case of old schema time stamp will not be found in the index header
1:         if (readIndexHeader.isSetSchema_time_stamp()) {
1:           dataFileFooter.setSchemaUpdatedTimeStamp(readIndexHeader.getSchema_time_stamp());
1:         }
commit:e820006
/////////////////////////////////////////////////////////////////////////
1:         TableBlockInfo tableBlockInfo =
1:             getTableBlockInfo(readBlockIndexInfo, readIndexHeader, parentPath);
1:         dataFileFooter.setVersionId(tableBlockInfo.getVersion());
/////////////////////////////////////////////////////////////////////////
1:    * This method will create a table block info object from index file info
1:    *
1:    * @param readBlockIndexInfo
1:    * @param readIndexHeader
1:    * @param parentPath
1:    * @return
1:    */
1:   public TableBlockInfo getTableBlockInfo(BlockIndex readBlockIndexInfo,
1:       org.apache.carbondata.format.IndexHeader readIndexHeader, String parentPath) {
0:     TableBlockInfo tableBlockInfo = new TableBlockInfo();
1:     tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
1:     ColumnarFormatVersion version =
1:         ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion());
1:     tableBlockInfo.setVersion(version);
1:     int blockletSize = getBlockletSize(readBlockIndexInfo);
1:     tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
1:     String fileName = readBlockIndexInfo.file_name;
1:     // Take only name of file.
1:     if (fileName.lastIndexOf("/") > 0) {
1:       fileName = fileName.substring(fileName.lastIndexOf("/"));
1:     }
0:     tableBlockInfo.setFilePath(parentPath + "/" + fileName);
1:     return tableBlockInfo;
1:   }
1: 
1:   /**
author:sraghunandan
-------------------------------------------------------------------------------
commit:f911403
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
author:xuchuanyin
-------------------------------------------------------------------------------
commit:dc53dee
/////////////////////////////////////////////////////////////////////////
0:       case VARCHAR:
0:         return DataTypes.VARCHAR;
author:xubo245
-------------------------------------------------------------------------------
commit:8896a63
/////////////////////////////////////////////////////////////////////////
1:         columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
/////////////////////////////////////////////////////////////////////////
1:         columnSchemaList.add(thriftColumnSchemaToWrapperColumnSchema(table_columns.get(i)));
/////////////////////////////////////////////////////////////////////////
1:   protected ColumnSchema thriftColumnSchemaToWrapperColumnSchema(
commit:6abdd97
/////////////////////////////////////////////////////////////////////////
0:       case BOOLEAN:
0:         return DataTypes.BOOLEAN;
author:Raghunandan S
-------------------------------------------------------------------------------
commit:7ef9164
/////////////////////////////////////////////////////////////////////////
1:     final byte[] present_bit_stream = presentMetadataThrift.getPresent_bit_stream();
1:     if (null != present_bit_stream) {
1:       return BitSet.valueOf(present_bit_stream);
1:     } else {
1:       return new BitSet(1);
1:     }
author:Jacky Li
-------------------------------------------------------------------------------
commit:daa6465
/////////////////////////////////////////////////////////////////////////
commit:933e30c
/////////////////////////////////////////////////////////////////////////
0:         return DataTypes.createDefaultArrayType();
0:         return DataTypes.createDefaultStructType();
commit:f209e8e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DecimalType;
/////////////////////////////////////////////////////////////////////////
0:     DataType dataType = thriftDataTyopeToWrapperDataType(externalColumnSchema.data_type);
1:     if (DataTypes.isDecimal(dataType)) {
1:       DecimalType decimalType = (DecimalType) dataType;
1:       decimalType.setPrecision(externalColumnSchema.getPrecision());
1:       decimalType.setScale(externalColumnSchema.getScale());
1:     }
1:     wrapperColumnSchema.setDataType(dataType);
/////////////////////////////////////////////////////////////////////////
0:         return DataTypes.createDefaultDecimalType();
commit:956833e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.datatype.DataTypes;
/////////////////////////////////////////////////////////////////////////
0:         return DataTypes.STRING;
0:         return DataTypes.SHORT;
0:         return DataTypes.INT;
0:         return DataTypes.LONG;
0:         return DataTypes.DOUBLE;
0:         return DataTypes.DECIMAL;
0:         return DataTypes.DATE;
0:         return DataTypes.TIMESTAMP;
0:         return DataTypes.ARRAY;
0:         return DataTypes.STRUCT;
0:         return DataTypes.STRING;
commit:e6a4f64
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private static BitSet getPresenceMeta(
0:     return BitSet.valueOf(presentMetadataThrift.getPresent_bit_stream());
author:akashrn5
-------------------------------------------------------------------------------
commit:1202e20
/////////////////////////////////////////////////////////////////////////
1:     fileName = (CarbonCommonConstants.FILE_SEPARATOR + fileName).replaceAll("//", "/");
1:     tableBlockInfo.setFilePath(parentPath + fileName);
author:kumarvishal
-------------------------------------------------------------------------------
commit:54eedfe
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     wrapperColumnSchema.setFunction(externalColumnSchema.getAggregate_function());
commit:49763b7
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.preagg.TimeSeriesUDF;
/////////////////////////////////////////////////////////////////////////
0:     if (null != externalColumnSchema.getAggregate_function()) {
0:       if (TimeSeriesUDF.INSTANCE.TIMESERIES_FUNCTION
0:           .contains(externalColumnSchema.getAggregate_function().toLowerCase())) {
0:         wrapperColumnSchema
0:             .setTimeSeriesFunction(externalColumnSchema.getAggregate_function().toLowerCase());
0:       } else {
0:         wrapperColumnSchema.setAggFunction(externalColumnSchema.getAggregate_function());
1:       }
1:     }
commit:3169918
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.schema.table.RelationIdentifier;
1: import org.apache.carbondata.core.metadata.schema.table.column.ParentColumnTableRelation;
/////////////////////////////////////////////////////////////////////////
0:     wrapperColumnSchema.setAggFunction(externalColumnSchema.getAggregate_function());
1:     List<org.apache.carbondata.format.ParentColumnTableRelation> parentColumnTableRelation =
1:         externalColumnSchema.getParentColumnTableRelations();
1:     if (null != parentColumnTableRelation) {
1:       wrapperColumnSchema.setParentColumnTableRelations(
1:           fromThriftToWrapperParentTableColumnRelations(parentColumnTableRelation));
1:     }
1:   private List<ParentColumnTableRelation> fromThriftToWrapperParentTableColumnRelations(
1:       List<org.apache.carbondata.format.ParentColumnTableRelation> thirftParentColumnRelation) {
1:     List<ParentColumnTableRelation> parentColumnTableRelationList = new ArrayList<>();
1:     for (org.apache.carbondata.format.ParentColumnTableRelation carbonTableRelation :
1:         thirftParentColumnRelation) {
1:       RelationIdentifier relationIdentifier =
1:           new RelationIdentifier(carbonTableRelation.getRelationIdentifier().getDatabaseName(),
1:               carbonTableRelation.getRelationIdentifier().getTableName(),
1:               carbonTableRelation.getRelationIdentifier().getTableId());
1:       ParentColumnTableRelation parentColumnTableRelation =
1:           new ParentColumnTableRelation(relationIdentifier, carbonTableRelation.getColumnId(),
1:               carbonTableRelation.getColumnName());
1:       parentColumnTableRelationList.add(parentColumnTableRelation);
1:     }
1:     return parentColumnTableRelationList;
1:   }
1: 
1: 
1: 
commit:d54dc64
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
0:  * Unless required by applicable law or agreed to in writing,
0:  * software distributed under the License is distributed on an
0:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0:  * KIND, either express or implied.  See the License for the
0:  * specific language governing permissions and limitations
0:  * under the License.
1:  */
1: package org.apache.carbondata.core.util;
1: 
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
1: import java.util.ArrayList;
1: import java.util.BitSet;
1: import java.util.List;
1: 
0: import org.apache.carbondata.core.carbon.datastore.block.BlockInfo;
0: import org.apache.carbondata.core.carbon.datastore.block.TableBlockInfo;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.DataFileFooter;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.SegmentInfo;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.compressor.ChunkCompressorMeta;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.compressor.CompressionCodec;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.datachunk.DataChunk;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.datachunk.PresenceMeta;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.index.BlockletBTreeIndex;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.index.BlockletIndex;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.index.BlockletMinMaxIndex;
0: import org.apache.carbondata.core.carbon.metadata.blocklet.sort.SortState;
0: import org.apache.carbondata.core.carbon.metadata.datatype.DataType;
0: import org.apache.carbondata.core.carbon.metadata.encoder.Encoding;
0: import org.apache.carbondata.core.carbon.metadata.schema.table.column.ColumnSchema;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.metadata.ValueEncoderMeta;
1: import org.apache.carbondata.core.reader.CarbonIndexFileReader;
1: import org.apache.carbondata.format.BlockIndex;
1: 
1: /**
1:  * Footer reader class
1:  */
1: public abstract class AbstractDataFileFooterConverter {
1: 
1:   /**
1:    * Below method will be used to convert the thrift presence meta to wrapper
1:    * presence meta
1:    *
1:    * @param presentMetadataThrift
1:    * @return wrapper presence meta
1:    */
0:   private static PresenceMeta getPresenceMeta(
1:       org.apache.carbondata.format.PresenceMeta presentMetadataThrift) {
0:     PresenceMeta presenceMeta = new PresenceMeta();
0:     presenceMeta.setRepresentNullValues(presentMetadataThrift.isRepresents_presence());
0:     presenceMeta.setBitSet(BitSet.valueOf(presentMetadataThrift.getPresent_bit_stream()));
0:     return presenceMeta;
1:   }
1: 
1:   /**
1:    * Below method will be used to get the index info from index file
1:    *
1:    * @param filePath           file path of the index file
1:    * @param tableBlockInfoList table block index
1:    * @return list of index info
1:    * @throws IOException problem while reading the index file
1:    */
0:   public List<DataFileFooter> getIndexInfo(String filePath, List<TableBlockInfo> tableBlockInfoList)
0:       throws IOException, CarbonUtilException {
0:     CarbonIndexFileReader indexReader = new CarbonIndexFileReader();
1:     List<DataFileFooter> dataFileFooters = new ArrayList<DataFileFooter>();
1:     try {
1:       // open the reader
0:       indexReader.openThriftReader(filePath);
1:       // get the index header
1:       org.apache.carbondata.format.IndexHeader readIndexHeader = indexReader.readIndexHeader();
1:       List<ColumnSchema> columnSchemaList = new ArrayList<ColumnSchema>();
1:       List<org.apache.carbondata.format.ColumnSchema> table_columns =
1:           readIndexHeader.getTable_columns();
1:       for (int i = 0; i < table_columns.size(); i++) {
0:         columnSchemaList.add(thriftColumnSchmeaToWrapperColumnSchema(table_columns.get(i)));
1:       }
1:       // get the segment info
1:       SegmentInfo segmentInfo = getSegmentInfo(readIndexHeader.getSegment_info());
1:       BlockletIndex blockletIndex = null;
1:       int counter = 0;
1:       DataFileFooter dataFileFooter = null;
1:       // read the block info from file
1:       while (indexReader.hasNext()) {
1:         BlockIndex readBlockIndexInfo = indexReader.readBlockIndexInfo();
1:         blockletIndex = getBlockletIndex(readBlockIndexInfo.getBlock_index());
1:         dataFileFooter = new DataFileFooter();
0:         TableBlockInfo tableBlockInfo = tableBlockInfoList.get(counter++);
0:         tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
0:         tableBlockInfo.setVersion((short) readIndexHeader.getVersion());
0:         int blockletSize = getBlockletSize(readBlockIndexInfo);
0:         tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
1:         dataFileFooter.setBlockletIndex(blockletIndex);
1:         dataFileFooter.setColumnInTable(columnSchemaList);
1:         dataFileFooter.setNumberOfRows(readBlockIndexInfo.getNum_rows());
1:         dataFileFooter.setBlockInfo(new BlockInfo(tableBlockInfo));
1:         dataFileFooter.setSegmentInfo(segmentInfo);
1:         dataFileFooters.add(dataFileFooter);
1:       }
1:     } finally {
1:       indexReader.closeThriftReader();
1:     }
1:     return dataFileFooters;
1:   }
1: 
1:   /**
1:    * the methods returns the number of blocklets in a block
1:    *
1:    * @param readBlockIndexInfo
1:    * @return
1:    */
1:   protected int getBlockletSize(BlockIndex readBlockIndexInfo) {
1:     long num_rows = readBlockIndexInfo.getNum_rows();
1:     int blockletSize = Integer.parseInt(CarbonProperties.getInstance()
1:         .getProperty(CarbonCommonConstants.BLOCKLET_SIZE,
1:             CarbonCommonConstants.BLOCKLET_SIZE_DEFAULT_VAL));
1:     int remainder = (int) (num_rows % blockletSize);
1:     int noOfBlockLet = (int) (num_rows / blockletSize);
1:     // there could be some blocklets which will not
1:     // contain the total records equal to the blockletSize
1:     if (remainder > 0) {
1:       noOfBlockLet = noOfBlockLet + 1;
1:     }
1:     return noOfBlockLet;
1:   }
1: 
1:   /**
1:    * Below method will be used to convert thrift file meta to wrapper file meta
1:    */
1:   public abstract DataFileFooter readDataFileFooter(TableBlockInfo tableBlockInfo)
1:       throws IOException;
1: 
1:   /**
1:    * Below method will be used to get blocklet index for data file meta
1:    *
1:    * @param blockletIndexList
1:    * @return blocklet index
1:    */
1:   protected BlockletIndex getBlockletIndexForDataFileFooter(List<BlockletIndex> blockletIndexList) {
1:     BlockletIndex blockletIndex = new BlockletIndex();
1:     BlockletBTreeIndex blockletBTreeIndex = new BlockletBTreeIndex();
1:     blockletBTreeIndex.setStartKey(blockletIndexList.get(0).getBtreeIndex().getStartKey());
1:     blockletBTreeIndex
1:         .setEndKey(blockletIndexList.get(blockletIndexList.size() - 1).getBtreeIndex().getEndKey());
1:     blockletIndex.setBtreeIndex(blockletBTreeIndex);
1:     byte[][] currentMinValue = blockletIndexList.get(0).getMinMaxIndex().getMinValues().clone();
1:     byte[][] currentMaxValue = blockletIndexList.get(0).getMinMaxIndex().getMaxValues().clone();
1:     byte[][] minValue = null;
1:     byte[][] maxValue = null;
1:     for (int i = 1; i < blockletIndexList.size(); i++) {
1:       minValue = blockletIndexList.get(i).getMinMaxIndex().getMinValues();
1:       maxValue = blockletIndexList.get(i).getMinMaxIndex().getMaxValues();
1:       for (int j = 0; j < maxValue.length; j++) {
1:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(currentMinValue[j], minValue[j]) > 0) {
1:           currentMinValue[j] = minValue[j].clone();
1:         }
1:         if (ByteUtil.UnsafeComparer.INSTANCE.compareTo(currentMaxValue[j], maxValue[j]) < 0) {
1:           currentMaxValue[j] = maxValue[j].clone();
1:         }
1:       }
1:     }
1: 
1:     BlockletMinMaxIndex minMax = new BlockletMinMaxIndex();
1:     minMax.setMaxValues(currentMaxValue);
1:     minMax.setMinValues(currentMinValue);
1:     blockletIndex.setMinMaxIndex(minMax);
1:     return blockletIndex;
1:   }
1: 
0:   protected ColumnSchema thriftColumnSchmeaToWrapperColumnSchema(
1:       org.apache.carbondata.format.ColumnSchema externalColumnSchema) {
1:     ColumnSchema wrapperColumnSchema = new ColumnSchema();
1:     wrapperColumnSchema.setColumnUniqueId(externalColumnSchema.getColumn_id());
1:     wrapperColumnSchema.setColumnName(externalColumnSchema.getColumn_name());
0:     wrapperColumnSchema.setColumnar(externalColumnSchema.isColumnar());
0:     wrapperColumnSchema
0:         .setDataType(thriftDataTyopeToWrapperDataType(externalColumnSchema.data_type));
1:     wrapperColumnSchema.setDimensionColumn(externalColumnSchema.isDimension());
1:     List<Encoding> encoders = new ArrayList<Encoding>();
1:     for (org.apache.carbondata.format.Encoding encoder : externalColumnSchema.getEncoders()) {
1:       encoders.add(fromExternalToWrapperEncoding(encoder));
1:     }
1:     wrapperColumnSchema.setEncodingList(encoders);
1:     wrapperColumnSchema.setNumberOfChild(externalColumnSchema.getNum_child());
1:     wrapperColumnSchema.setPrecision(externalColumnSchema.getPrecision());
0:     wrapperColumnSchema.setColumnGroup(externalColumnSchema.getColumn_group_id());
1:     wrapperColumnSchema.setScale(externalColumnSchema.getScale());
1:     wrapperColumnSchema.setDefaultValue(externalColumnSchema.getDefault_value());
0:     wrapperColumnSchema.setAggregateFunction(externalColumnSchema.getAggregate_function());
1:     return wrapperColumnSchema;
1:   }
1: 
1:   /**
1:    * Below method is convert the thrift encoding to wrapper encoding
1:    *
1:    * @param encoderThrift thrift encoding
1:    * @return wrapper encoding
1:    */
1:   protected Encoding fromExternalToWrapperEncoding(
1:       org.apache.carbondata.format.Encoding encoderThrift) {
1:     switch (encoderThrift) {
1:       case DICTIONARY:
1:         return Encoding.DICTIONARY;
1:       case DELTA:
1:         return Encoding.DELTA;
1:       case RLE:
1:         return Encoding.RLE;
1:       case INVERTED_INDEX:
1:         return Encoding.INVERTED_INDEX;
1:       case BIT_PACKED:
1:         return Encoding.BIT_PACKED;
1:       case DIRECT_DICTIONARY:
1:         return Encoding.DIRECT_DICTIONARY;
1:       default:
1:         throw new IllegalArgumentException(encoderThrift.toString() + " is not supported");
1:     }
1:   }
1: 
1:   /**
0:    * Below method will be used to convert the thrift compression to wrapper
0:    * compression codec
1:    *
0:    * @param compressionCodecThrift
0:    * @return wrapper compression codec
1:    */
0:   protected CompressionCodec getCompressionCodec(
0:       org.apache.carbondata.format.CompressionCodec compressionCodecThrift) {
0:     switch (compressionCodecThrift) {
0:       case SNAPPY:
0:         return CompressionCodec.SNAPPY;
1:       default:
0:         return CompressionCodec.SNAPPY;
1:     }
1:   }
1: 
1:   /**
1:    * Below method will be used to convert thrift segment object to wrapper
1:    * segment object
1:    *
1:    * @param segmentInfo thrift segment info object
1:    * @return wrapper segment info object
1:    */
1:   protected SegmentInfo getSegmentInfo(org.apache.carbondata.format.SegmentInfo segmentInfo) {
1:     SegmentInfo info = new SegmentInfo();
1:     int[] cardinality = new int[segmentInfo.getColumn_cardinalities().size()];
1:     for (int i = 0; i < cardinality.length; i++) {
1:       cardinality[i] = segmentInfo.getColumn_cardinalities().get(i);
1:     }
1:     info.setColumnCardinality(cardinality);
0:     info.setNumberOfColumns(segmentInfo.getNum_cols());
1:     return info;
1:   }
1: 
1:   /**
1:    * Below method will be used to convert the blocklet index of thrift to
1:    * wrapper
1:    *
1:    * @param blockletIndexThrift
1:    * @return blocklet index wrapper
1:    */
1:   protected BlockletIndex getBlockletIndex(
1:       org.apache.carbondata.format.BlockletIndex blockletIndexThrift) {
1:     org.apache.carbondata.format.BlockletBTreeIndex btreeIndex =
1:         blockletIndexThrift.getB_tree_index();
1:     org.apache.carbondata.format.BlockletMinMaxIndex minMaxIndex =
1:         blockletIndexThrift.getMin_max_index();
1:     return new BlockletIndex(
1:         new BlockletBTreeIndex(btreeIndex.getStart_key(), btreeIndex.getEnd_key()),
1:         new BlockletMinMaxIndex(minMaxIndex.getMin_values(), minMaxIndex.getMax_values()));
1:   }
1: 
1:   /**
0:    * Below method will be used to convert the thrift compression meta to
0:    * wrapper chunk compression meta
1:    *
0:    * @param chunkCompressionMetaThrift
0:    * @return chunkCompressionMetaWrapper
1:    */
0:   protected ChunkCompressorMeta getChunkCompressionMeta(
0:       org.apache.carbondata.format.ChunkCompressionMeta chunkCompressionMetaThrift) {
0:     ChunkCompressorMeta compressorMeta = new ChunkCompressorMeta();
0:     compressorMeta
0:         .setCompressor(getCompressionCodec(chunkCompressionMetaThrift.getCompression_codec()));
0:     compressorMeta.setCompressedSize(chunkCompressionMetaThrift.getTotal_compressed_size());
0:     compressorMeta.setUncompressedSize(chunkCompressionMetaThrift.getTotal_uncompressed_size());
0:     return compressorMeta;
1:   }
1: 
1:   /**
0:    * Below method will be used to convert the thrift data type to wrapper data
0:    * type
1:    *
0:    * @param dataTypeThrift
0:    * @return dataType wrapper
1:    */
0:   protected DataType thriftDataTyopeToWrapperDataType(
0:       org.apache.carbondata.format.DataType dataTypeThrift) {
0:     switch (dataTypeThrift) {
0:       case STRING:
0:         return DataType.STRING;
0:       case SHORT:
0:         return DataType.SHORT;
0:       case INT:
0:         return DataType.INT;
0:       case LONG:
0:         return DataType.LONG;
0:       case DOUBLE:
0:         return DataType.DOUBLE;
0:       case DECIMAL:
0:         return DataType.DECIMAL;
0:       case TIMESTAMP:
0:         return DataType.TIMESTAMP;
0:       case ARRAY:
0:         return DataType.ARRAY;
0:       case STRUCT:
0:         return DataType.STRUCT;
1:       default:
0:         return DataType.STRING;
1:     }
1:   }
1: 
1:   /**
0:    * Below method will be used to convert the thrift object to wrapper object
1:    *
0:    * @param sortStateThrift
0:    * @return wrapper sort state object
1:    */
0:   protected SortState getSortState(org.apache.carbondata.format.SortState sortStateThrift) {
0:     if (sortStateThrift == org.apache.carbondata.format.SortState.SORT_EXPLICIT) {
0:       return SortState.SORT_EXPLICT;
0:     } else if (sortStateThrift == org.apache.carbondata.format.SortState.SORT_NATIVE) {
0:       return SortState.SORT_NATIVE;
0:     } else {
0:       return SortState.SORT_NONE;
1:     }
1:   }
1: 
1:   /**
1:    * Below method will be used to convert the thrift data chunk to wrapper
1:    * data chunk
1:    *
1:    * @param datachunkThrift
1:    * @return wrapper data chunk
1:    */
1:   protected DataChunk getDataChunk(org.apache.carbondata.format.DataChunk datachunkThrift,
1:       boolean isPresenceMetaPresent) {
1:     DataChunk dataChunk = new DataChunk();
0:     dataChunk.setColumnUniqueIdList(datachunkThrift.getColumn_ids());
1:     dataChunk.setDataPageLength(datachunkThrift.getData_page_length());
1:     dataChunk.setDataPageOffset(datachunkThrift.getData_page_offset());
1:     if (isPresenceMetaPresent) {
1:       dataChunk.setNullValueIndexForColumn(getPresenceMeta(datachunkThrift.getPresence()));
1:     }
1:     dataChunk.setRlePageLength(datachunkThrift.getRle_page_length());
1:     dataChunk.setRlePageOffset(datachunkThrift.getRle_page_offset());
1:     dataChunk.setRowMajor(datachunkThrift.isRowMajor());
1:     dataChunk.setRowIdPageLength(datachunkThrift.getRowid_page_length());
1:     dataChunk.setRowIdPageOffset(datachunkThrift.getRowid_page_offset());
0:     dataChunk.setSortState(getSortState(datachunkThrift.getSort_state()));
0:     dataChunk.setChunkCompressionMeta(getChunkCompressionMeta(datachunkThrift.getChunk_meta()));
1:     List<Encoding> encodingList = new ArrayList<Encoding>(datachunkThrift.getEncoders().size());
1:     for (int i = 0; i < datachunkThrift.getEncoders().size(); i++) {
1:       encodingList.add(fromExternalToWrapperEncoding(datachunkThrift.getEncoders().get(i)));
1:     }
0:     dataChunk.setEncoderList(encodingList);
1:     if (encodingList.contains(Encoding.DELTA)) {
1:       List<ByteBuffer> thriftEncoderMeta = datachunkThrift.getEncoder_meta();
1:       List<ValueEncoderMeta> encodeMetaList =
1:           new ArrayList<ValueEncoderMeta>(thriftEncoderMeta.size());
1:       for (int i = 0; i < thriftEncoderMeta.size(); i++) {
0:         encodeMetaList.add(CarbonUtil.deserializeEncoderMeta(thriftEncoderMeta.get(i).array()));
1:       }
1:       dataChunk.setValueEncoderMeta(encodeMetaList);
1:     }
1:     return dataChunk;
1:   }
1: 
1: }
author:Ravindra Pesala
-------------------------------------------------------------------------------
commit:133b303
/////////////////////////////////////////////////////////////////////////
0:         String fileName = readBlockIndexInfo.file_name;
0:         // Take only name of file.
0:         if (fileName.lastIndexOf("/") > 0) {
0:           fileName = fileName.substring(fileName.lastIndexOf("/"));
0:         }
0:         tableBlockInfo.setFilePath(parentPath + "/" + fileName);
commit:1e21cd1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.metadata.blocklet.BlockletInfo;
/////////////////////////////////////////////////////////////////////////
0:         ColumnarFormatVersion version =
0:             ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion());
0:         tableBlockInfo.setVersion(version);
/////////////////////////////////////////////////////////////////////////
0:         dataFileFooter.setVersionId(version);
1:         if (readBlockIndexInfo.isSetBlocklet_info()) {
1:           List<BlockletInfo> blockletInfoList = new ArrayList<BlockletInfo>();
0:           BlockletInfo blockletInfo = new DataFileFooterConverterV3()
1:               .getBlockletInfo(readBlockIndexInfo.getBlocklet_info(),
1:                   CarbonUtil.getNumberOfDimensionColumns(columnSchemaList));
1:           blockletInfo.setBlockletIndex(blockletIndex);
1:           blockletInfoList.add(blockletInfo);
1:           dataFileFooter.setBlockletList(blockletInfoList);
0:         }
author:jackylk
-------------------------------------------------------------------------------
commit:dc83b2a
/////////////////////////////////////////////////////////////////////////
1:         encodeMetaList.add(CarbonUtil.deserializeEncoderMetaV2(thriftEncoderMeta.get(i).array()));
commit:ce09aaa
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.datastore.block.BlockInfo;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.metadata.ColumnarFormatVersion;
1: import org.apache.carbondata.core.metadata.blocklet.DataFileFooter;
1: import org.apache.carbondata.core.metadata.blocklet.SegmentInfo;
1: import org.apache.carbondata.core.metadata.blocklet.datachunk.DataChunk;
0: import org.apache.carbondata.core.metadata.blocklet.datachunk.PresenceMeta;
1: import org.apache.carbondata.core.metadata.blocklet.index.BlockletBTreeIndex;
1: import org.apache.carbondata.core.metadata.blocklet.index.BlockletIndex;
1: import org.apache.carbondata.core.metadata.blocklet.index.BlockletMinMaxIndex;
1: import org.apache.carbondata.core.metadata.datatype.DataType;
1: import org.apache.carbondata.core.metadata.encoder.Encoding;
1: import org.apache.carbondata.core.metadata.schema.table.column.ColumnSchema;
commit:eaadc88
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       throws IOException {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     dataChunk.setEncodingList(encodingList);
commit:0ef3fb8
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.carbon.ColumnarFormatVersion;
/////////////////////////////////////////////////////////////////////////
0:         tableBlockInfo.setVersion(
0:             ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion()));
author:Sephiroth-Lin
-------------------------------------------------------------------------------
commit:ae4a30c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.path.CarbonTablePath;
/////////////////////////////////////////////////////////////////////////
1:       int index = 0;
1:         TableBlockInfo tableBlockInfo = tableBlockInfoList.get(index);
1:         if (Integer.parseInt(CarbonTablePath.DataFileUtil.getPartNo(
1:             tableBlockInfo.getFilePath())) == counter++) {
0:           tableBlockInfo.setBlockOffset(readBlockIndexInfo.getOffset());
0:           tableBlockInfo.setVersion(
0:               ColumnarFormatVersion.valueOf((short) readIndexHeader.getVersion()));
0:           int blockletSize = getBlockletSize(readBlockIndexInfo);
0:           tableBlockInfo.getBlockletInfos().setNoOfBlockLets(blockletSize);
0:           dataFileFooter.setBlockletIndex(blockletIndex);
0:           dataFileFooter.setColumnInTable(columnSchemaList);
0:           dataFileFooter.setNumberOfRows(readBlockIndexInfo.getNum_rows());
0:           dataFileFooter.setBlockInfo(new BlockInfo(tableBlockInfo));
0:           dataFileFooter.setSegmentInfo(segmentInfo);
0:           dataFileFooters.add(dataFileFooter);
1:           if (++index == tableBlockInfoList.size()) {
1:             break;
0:           }
0:         }
author:QiangCai
-------------------------------------------------------------------------------
commit:9f94529
/////////////////////////////////////////////////////////////////////////
1: import java.util.Map;
/////////////////////////////////////////////////////////////////////////
1:     Map<String, String> properties = externalColumnSchema.getColumnProperties();
1:     if (properties != null) {
1:       if (properties.get(CarbonCommonConstants.SORT_COLUMNS) != null) {
1:         wrapperColumnSchema.setSortColumn(true);
0:       }
0:     }
commit:41347d8
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
commit:d73f4bf
/////////////////////////////////////////////////////////////////////////
0:       case DATE:
0:         return DataType.DATE;
============================================================================
1:874764f: /*
1:874764f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:874764f:  * contributor license agreements.  See the NOTICE file distributed with
1:874764f:  * this work for additional information regarding copyright ownership.
1:874764f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:874764f:  * (the "License"); you may not use this file except in compliance with
1:874764f:  * the License.  You may obtain a copy of the License at
1:874764f:  *
1:874764f:  *    http://www.apache.org/licenses/LICENSE-2.0
1:874764f:  *
1:874764f:  * Unless required by applicable law or agreed to in writing, software
1:874764f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:874764f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:874764f:  * See the License for the specific language governing permissions and
1:874764f:  * limitations under the License.
1:874764f:  */
1:874764f: 
1:349c59c: package org.apache.carbondata.processing.partition.spliter;
1:874764f: 
1:874764f: import java.io.IOException;
1:874764f: import java.util.ArrayList;
1:874764f: import java.util.List;
1:874764f: import java.util.Map;
1:874764f: import java.util.Set;
1:874764f: 
1:874764f: import org.apache.carbondata.common.logging.LogService;
1:874764f: import org.apache.carbondata.common.logging.LogServiceFactory;
1:874764f: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1:874764f: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1:874764f: import org.apache.carbondata.core.datastore.block.TaskBlockInfo;
1:874764f: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1:874764f: import org.apache.carbondata.core.scan.executor.exception.QueryExecutionException;
1:3ff574d: import org.apache.carbondata.core.scan.model.QueryModelBuilder;
1:874764f: import org.apache.carbondata.core.scan.result.iterator.PartitionSpliterRawResultIterator;
1:982d03f: import org.apache.carbondata.core.util.DataTypeConverter;
1:874764f: 
1:2a9604c: import org.apache.hadoop.conf.Configuration;
1:2a9604c: 
1:874764f: /**
1:874764f:  * Used to read carbon blocks when add/split partition
1:874764f:  */
1:874764f: public class CarbonSplitExecutor extends AbstractCarbonQueryExecutor {
1:874764f: 
1:874764f:   private static final LogService LOGGER =
1:874764f:       LogServiceFactory.getLogService(CarbonSplitExecutor.class.getName());
1:874764f: 
1:874764f:   public CarbonSplitExecutor(Map<String, TaskBlockInfo> segmentMapping, CarbonTable carbonTable) {
1:874764f:     this.segmentMapping = segmentMapping;
1:874764f:     this.carbonTable = carbonTable;
1:874764f:   }
1:874764f: 
1:982d03f:   public List<PartitionSpliterRawResultIterator> processDataBlocks(
1:2a9604c:       String segmentId, DataTypeConverter converter, Configuration configuration)
1:874764f:       throws QueryExecutionException, IOException {
1:874764f:     List<TableBlockInfo> list = null;
1:3ff574d:     queryModel = new QueryModelBuilder(carbonTable)
1:3ff574d:         .projectAllColumns()
1:3ff574d:         .dataConverter(converter)
1:3ff574d:         .enableForcedDetailRawQuery()
1:3ff574d:         .build();
1:874764f:     List<PartitionSpliterRawResultIterator> resultList
1:874764f:         = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:874764f:     TaskBlockInfo taskBlockInfo = segmentMapping.get(segmentId);
1:874764f:     Set<String> taskBlockListMapping = taskBlockInfo.getTaskSet();
1:874764f:     for (String task : taskBlockListMapping) {
1:874764f:       list = taskBlockInfo.getTableBlockInfoList(task);
1:874764f:       LOGGER.info("for task -" + task + "-block size is -" + list.size());
1:874764f:       queryModel.setTableBlockInfos(list);
1:2a9604c:       resultList.add(new PartitionSpliterRawResultIterator(executeBlockList(list, configuration)));
1:874764f:     }
1:874764f:     return resultList;
1:874764f:   }
1:874764f: }
============================================================================
author:kunal642
-------------------------------------------------------------------------------
commit:2a9604c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
1: 
/////////////////////////////////////////////////////////////////////////
1:       String segmentId, DataTypeConverter converter, Configuration configuration)
/////////////////////////////////////////////////////////////////////////
1:       resultList.add(new PartitionSpliterRawResultIterator(executeBlockList(list, configuration)));
author:Jacky Li
-------------------------------------------------------------------------------
commit:3ff574d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.scan.model.QueryModelBuilder;
/////////////////////////////////////////////////////////////////////////
1:     queryModel = new QueryModelBuilder(carbonTable)
1:         .projectAllColumns()
1:         .dataConverter(converter)
1:         .enableForcedDetailRawQuery()
1:         .build();
commit:982d03f
/////////////////////////////////////////////////////////////////////////
1: import org.apache.carbondata.core.util.DataTypeConverter;
/////////////////////////////////////////////////////////////////////////
1:   public List<PartitionSpliterRawResultIterator> processDataBlocks(
0:       String segmentId, DataTypeConverter converter)
0:     queryModel = carbonTable.createQueryModelWithProjectAllColumns(converter);
commit:daa6465
/////////////////////////////////////////////////////////////////////////
0: import org.apache.carbondata.core.util.DataTypeConverterImpl;
/////////////////////////////////////////////////////////////////////////
0:     queryModel = carbonTable.createQueryModelWithProjectAllColumns(new DataTypeConverterImpl());
0:     queryModel.setForcedDetailRawQuery(true);
commit:349c59c
/////////////////////////////////////////////////////////////////////////
1: package org.apache.carbondata.processing.partition.spliter;
author:lionelcao
-------------------------------------------------------------------------------
commit:874764f
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *    http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.carbondata.processing.spliter;
1: 
1: import java.io.IOException;
1: import java.util.ArrayList;
1: import java.util.List;
1: import java.util.Map;
1: import java.util.Set;
1: 
1: import org.apache.carbondata.common.logging.LogService;
1: import org.apache.carbondata.common.logging.LogServiceFactory;
1: import org.apache.carbondata.core.constants.CarbonCommonConstants;
1: import org.apache.carbondata.core.datastore.block.TableBlockInfo;
1: import org.apache.carbondata.core.datastore.block.TaskBlockInfo;
1: import org.apache.carbondata.core.metadata.schema.table.CarbonTable;
1: import org.apache.carbondata.core.scan.executor.exception.QueryExecutionException;
1: import org.apache.carbondata.core.scan.result.iterator.PartitionSpliterRawResultIterator;
1: 
1: /**
1:  * Used to read carbon blocks when add/split partition
1:  */
1: public class CarbonSplitExecutor extends AbstractCarbonQueryExecutor {
1: 
1:   private static final LogService LOGGER =
1:       LogServiceFactory.getLogService(CarbonSplitExecutor.class.getName());
1: 
1:   public CarbonSplitExecutor(Map<String, TaskBlockInfo> segmentMapping, CarbonTable carbonTable) {
1:     this.segmentMapping = segmentMapping;
1:     this.carbonTable = carbonTable;
1:   }
1: 
0:   public List<PartitionSpliterRawResultIterator> processDataBlocks(String segmentId)
1:       throws QueryExecutionException, IOException {
1:     List<TableBlockInfo> list = null;
0:     queryModel = prepareQueryModel(list);
1:     List<PartitionSpliterRawResultIterator> resultList
1:         = new ArrayList<>(CarbonCommonConstants.DEFAULT_COLLECTION_SIZE);
1:     TaskBlockInfo taskBlockInfo = segmentMapping.get(segmentId);
1:     Set<String> taskBlockListMapping = taskBlockInfo.getTaskSet();
1:     for (String task : taskBlockListMapping) {
1:       list = taskBlockInfo.getTableBlockInfoList(task);
1:       LOGGER.info("for task -" + task + "-block size is -" + list.size());
1:       queryModel.setTableBlockInfos(list);
0:       resultList.add(new PartitionSpliterRawResultIterator(executeBlockList(list)));
1:     }
1:     return resultList;
1:   }
1: }
============================================================================
1:597a1d5: package org.apache.cassandra.stress.generate;
1:597a1d5: /*
1:597a1d5:  * 
1:597a1d5:  * Licensed to the Apache Software Foundation (ASF) under one
1:597a1d5:  * or more contributor license agreements.  See the NOTICE file
1:597a1d5:  * distributed with this work for additional information
1:597a1d5:  * regarding copyright ownership.  The ASF licenses this file
1:597a1d5:  * to you under the Apache License, Version 2.0 (the
1:597a1d5:  * "License"); you may not use this file except in compliance
1:597a1d5:  * with the License.  You may obtain a copy of the License at
1:597a1d5:  * 
1:597a1d5:  *   http://www.apache.org/licenses/LICENSE-2.0
1:597a1d5:  * 
1:597a1d5:  * Unless required by applicable law or agreed to in writing,
1:597a1d5:  * software distributed under the License is distributed on an
1:597a1d5:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:597a1d5:  * KIND, either express or implied.  See the License for the
1:597a1d5:  * specific language governing permissions and limitations
1:597a1d5:  * under the License.
1:597a1d5:  * 
1:597a1d5:  */
15:597a1d5: 
1:597a1d5: 
1:597a1d5: import java.nio.ByteBuffer;
1:597a1d5: import java.util.ArrayDeque;
1:597a1d5: import java.util.ArrayList;
1:597a1d5: import java.util.Arrays;
1:597a1d5: import java.util.Collections;
1:597a1d5: import java.util.Deque;
1:597a1d5: import java.util.HashSet;
1:597a1d5: import java.util.Iterator;
1:597a1d5: import java.util.List;
1:597a1d5: import java.util.NoSuchElementException;
1:597a1d5: import java.util.Queue;
1:597a1d5: import java.util.Set;
1:597a1d5: import java.util.UUID;
1:597a1d5: import java.util.concurrent.ThreadLocalRandom;
1:597a1d5: 
1:3bee990: import com.google.common.collect.Iterables;
1:3bee990: 
1:597a1d5: import org.apache.cassandra.db.marshal.AbstractType;
1:597a1d5: import org.apache.cassandra.db.marshal.BytesType;
1:597a1d5: import org.apache.cassandra.stress.generate.values.Generator;
1:3bee990: import org.apache.cassandra.utils.Pair;
1:597a1d5: 
1:597a1d5: // a partition is re-used to reduce garbage generation, as is its internal RowIterator
1:597a1d5: // TODO: we should batch the generation of clustering components so we can bound the time and size necessary to
1:597a1d5: // generate huge partitions with only a small number of clustering components; i.e. we should generate seeds for batches
1:597a1d5: // of a single component, and then generate the values within those batches as necessary. this will be difficult with
1:597a1d5: // generating sorted partitions, and may require generator support (e.g. we may need to support generating prefixes
1:597a1d5: // that are extended/suffixed to generate each batch, so that we can sort the prefixes)
1:597a1d5: public abstract class PartitionIterator implements Iterator<Row>
8:597a1d5: {
1:597a1d5: 
1:6d29ed0:     abstract boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order);
1:3bee990:     // picks random (inclusive) bounds to iterate, and returns them
1:3bee990:     public abstract Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth);
1:597a1d5: 
1:3bee990:     PartitionGenerator.Order order;
1:597a1d5:     long idseed;
1:597a1d5:     Seed seed;
1:1435b9a: 
1:597a1d5:     final PartitionGenerator generator;
1:597a1d5:     final SeedManager seedManager;
1:1435b9a: 
1:1435b9a:     // we reuse these objects to save garbage
1:1435b9a:     final Object[] partitionKey;
1:597a1d5:     final Row row;
1:597a1d5: 
1:597a1d5:     public static PartitionIterator get(PartitionGenerator generator, SeedManager seedManager)
1:597a1d5:     {
1:597a1d5:         if (generator.clusteringComponents.size() > 0)
1:597a1d5:             return new MultiRowIterator(generator, seedManager);
1:597a1d5:         else
1:597a1d5:             return new SingleRowIterator(generator, seedManager);
8:597a1d5:     }
1:597a1d5: 
1:597a1d5:     private PartitionIterator(PartitionGenerator generator, SeedManager seedManager)
1:597a1d5:     {
1:597a1d5:         this.generator = generator;
1:597a1d5:         this.seedManager = seedManager;
1:597a1d5:         this.partitionKey = new Object[generator.partitionKey.size()];
1:597a1d5:         this.row = new Row(partitionKey, new Object[generator.clusteringComponents.size() + generator.valueComponents.size()]);
1:597a1d5:     }
1:597a1d5: 
1:3bee990:     void setSeed(Seed seed)
1:597a1d5:     {
1:597a1d5:         long idseed = 0;
1:597a1d5:         for (int i = 0 ; i < partitionKey.length ; i++)
1:597a1d5:         {
1:597a1d5:             Generator generator = this.generator.partitionKey.get(i);
1:597a1d5:             // set the partition key seed based on the current work item we're processing
1:597a1d5:             generator.setSeed(seed.seed);
1:597a1d5:             Object key = generator.generate();
1:597a1d5:             partitionKey[i] = key;
1:597a1d5:             // then contribute this value to the data seed
1:597a1d5:             idseed = seed(key, generator.type, idseed);
1:597a1d5:         }
1:597a1d5:         this.seed = seed;
1:597a1d5:         this.idseed = idseed;
1:597a1d5:     }
1:597a1d5: 
1:6d29ed0:     public boolean reset(Seed seed, double useChance, double rowPopulationRatio, boolean isWrite)
1:597a1d5:     {
1:597a1d5:         setSeed(seed);
1:3bee990:         this.order = generator.order;
1:6d29ed0:         return reset(useChance, rowPopulationRatio, 0, isWrite, PartitionIterator.this.order);
1:597a1d5:     }
1:597a1d5: 
1:6d29ed0:     public boolean reset(Seed seed, int targetCount, double rowPopulationRatio,  boolean isWrite)
1:597a1d5:     {
1:597a1d5:         setSeed(seed);
1:3bee990:         this.order = generator.order;
1:6d29ed0:         return reset(Double.NaN, rowPopulationRatio,targetCount, isWrite,PartitionIterator.this.order);
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     static class SingleRowIterator extends PartitionIterator
1:597a1d5:     {
1:597a1d5:         boolean done;
1:597a1d5:         boolean isWrite;
1:6d29ed0:         double rowPopulationRatio;
1:6d29ed0:         final double totalValueColumns;
1:597a1d5: 
1:597a1d5:         private SingleRowIterator(PartitionGenerator generator, SeedManager seedManager)
1:597a1d5:         {
1:597a1d5:             super(generator, seedManager);
1:6d29ed0: 
1:6d29ed0:             this.totalValueColumns = generator.valueComponents.size();
1:597a1d5:         }
1:597a1d5: 
1:3bee990:         public Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth)
1:3bee990:         {
1:3bee990:             assert clusteringComponentDepth == 0;
1:3bee990:             setSeed(seed);
1:6d29ed0:             reset(1d, 1d, 1, false, PartitionGenerator.Order.SORTED);
1:3bee990:             return Pair.create(new Row(partitionKey), new Row(partitionKey));
1:3bee990:         }
1:3bee990: 
1:6d29ed0:         boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order)
1:597a1d5:         {
1:597a1d5:             done = false;
1:1435b9a:             this.isWrite = isWrite;
1:6d29ed0:             this.rowPopulationRatio = rowPopulationRatio;
1:597a1d5:             return true;
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         public boolean hasNext()
1:597a1d5:         {
1:597a1d5:             return !done;
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         public Row next()
1:597a1d5:         {
1:597a1d5:             if (done)
1:597a1d5:                 throw new NoSuchElementException();
1:6d29ed0: 
1:6d29ed0:             double valueColumn = 0.0;
1:597a1d5:             for (int i = 0 ; i < row.row.length ; i++)
1:597a1d5:             {
1:6d29ed0:                 if (generator.permitNulls(i) && (++valueColumn/totalValueColumns) > rowPopulationRatio)
1:6d29ed0:                 {
1:6d29ed0:                     row.row[i] = null;
1:6d29ed0:                 }
1:6d29ed0:                 else
1:6d29ed0:                 {
1:6d29ed0:                     Generator gen = generator.valueComponents.get(i);
1:6d29ed0:                     gen.setSeed(idseed);
1:6d29ed0:                     row.row[i] = gen.generate();
1:6d29ed0:                 }
1:597a1d5:             }
1:597a1d5:             done = true;
2:597a1d5:             if (isWrite)
1:597a1d5:             {
1:597a1d5:                 seedManager.markFirstWrite(seed, true);
1:597a1d5:                 seedManager.markLastWrite(seed, true);
1:597a1d5:             }
2:597a1d5:             return row;
1:597a1d5:         }
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     // permits iterating a random subset of the procedurally generated rows in this partition. this is the only mechanism for visiting rows.
1:597a1d5:     // we maintain a stack of clustering components and their seeds; for each clustering component we visit, we generate all values it takes at that level,
1:597a1d5:     // and then, using the average (total) number of children it takes we randomly choose whether or not we visit its children;
1:597a1d5:     // if we do, we generate all possible values the immediate children can take, and repeat the process. So at any one time we are using space proportional
1:597a1d5:     // to C.N, where N is the average number of values each clustering component takes, as opposed to N^C total values in the partition.
1:597a1d5:     // TODO : support first/last row, and constraining reads to rows we know are populated
1:597a1d5:     static class MultiRowIterator extends PartitionIterator
1:597a1d5:     {
1:597a1d5:         // the seed used to generate the current values for the clustering components at each depth;
1:597a1d5:         // used to save recalculating it for each row, so we only need to recalc from prior row.
1:597a1d5:         final long[] clusteringSeeds = new long[generator.clusteringComponents.size()];
1:597a1d5:         // the components remaining to be visited for each level of the current stack
1:597a1d5:         final Deque<Object>[] clusteringComponents = new ArrayDeque[generator.clusteringComponents.size()];
1:597a1d5: 
1:1435b9a:         // probability any single row will be generated in this iteration
1:1435b9a:         double useChance;
1:6d29ed0:         double rowPopulationRatio;
1:6d29ed0:         final double totalValueColumns;
1:597a1d5:         // we want our chance of selection to be applied uniformly, so we compound the roll we make at each level
1:597a1d5:         // so that we know with what chance we reached there, and we adjust our roll at that level by that amount
1:597a1d5:         final double[] chancemodifier = new double[generator.clusteringComponents.size()];
1:597a1d5:         final double[] rollmodifier = new double[generator.clusteringComponents.size()];
1:597a1d5: 
1:597a1d5:         // track where in the partition we are, and where we are limited to
1:1435b9a:         final int[] currentRow = new int[generator.clusteringComponents.size()];
1:1435b9a:         final int[] lastRow = new int[currentRow.length];
1:597a1d5:         boolean hasNext, isFirstWrite, isWrite;
1:597a1d5: 
1:597a1d5:         // reusable collections for generating unique and sorted clustering components
1:597a1d5:         final Set<Object> unique = new HashSet<>();
1:597a1d5:         final List<Object> tosort = new ArrayList<>();
1:597a1d5: 
1:597a1d5:         MultiRowIterator(PartitionGenerator generator, SeedManager seedManager)
1:597a1d5:         {
1:597a1d5:             super(generator, seedManager);
1:597a1d5:             for (int i = 0 ; i < clusteringComponents.length ; i++)
1:597a1d5:                 clusteringComponents[i] = new ArrayDeque<>();
1:597a1d5:             rollmodifier[0] = 1f;
1:597a1d5:             chancemodifier[0] = generator.clusteringDescendantAverages[0];
1:6d29ed0:             this.totalValueColumns = generator.valueComponents.size();
1:597a1d5:         }
1:597a1d5: 
1:1435b9a:         /**
1:1435b9a:          * initialise the iterator state
1:1435b9a:          *
1:1435b9a:          * if we're a write, the expected behaviour is that the requested
1:1435b9a:          * batch count is compounded with the seed's visit count to decide
1:1435b9a:          * how much we should return in one iteration
1:1435b9a:          *
1:1435b9a:          * @param useChance uniform chance of visiting any single row (NaN if targetCount provided)
1:1435b9a:          * @param targetCount number of rows we would like to visit (0 if useChance provided)
1:1435b9a:          * @param isWrite true if the action requires write semantics
1:1435b9a:          *
1:1435b9a:          * @return true if there is data to return, false otherwise
1:1435b9a:          */
1:6d29ed0:         boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order)
1:597a1d5:         {
1:1435b9a:             this.isWrite = isWrite;
1:6d29ed0:             this.rowPopulationRatio = rowPopulationRatio;
1:597a1d5: 
1:3bee990:             this.order = order;
1:597a1d5:             // set the seed for the first clustering component
1:597a1d5:             generator.clusteringComponents.get(0).setSeed(idseed);
1:597a1d5: 
1:597a1d5:             // calculate how many first clustering components we'll generate, and how many total rows this predicts
1:597a1d5:             int firstComponentCount = (int) generator.clusteringComponents.get(0).clusteringDistribution.next();
1:597a1d5:             int expectedRowCount;
1:597a1d5: 
1:597a1d5:             int position = seed.position();
1:597a1d5: 
1:597a1d5:             if (isWrite)
1:597a1d5:                 expectedRowCount = firstComponentCount * generator.clusteringDescendantAverages[0];
1:597a1d5:             else if (position != 0)
1:1435b9a:                 expectedRowCount = setLastRow(position - 1);
1:597a1d5:             else
1:1435b9a:                 expectedRowCount = setNoLastRow(firstComponentCount);
1:597a1d5: 
1:597a1d5:             if (Double.isNaN(useChance))
1:597a1d5:                 useChance = Math.max(0d, Math.min(1d, targetCount / (double) expectedRowCount));
1:3bee990:             setUseChance(useChance);
1:597a1d5: 
1:597a1d5:             while (true)
1:597a1d5:             {
1:1435b9a:                 // we loop in case we have picked an entirely non-existent range, in which case
1:1435b9a:                 // we will reset the seed's position, then try again (until we exhaust it or find
1:1435b9a:                 // some real range)
1:1435b9a: 
1:597a1d5:                 for (Queue<?> q : clusteringComponents)
1:597a1d5:                     q.clear();
1:3bee990:                 fill(0);
1:597a1d5: 
1:1435b9a:                 if (!isWrite)
1:597a1d5:                 {
1:1435b9a:                     if (seek(0) != State.SUCCESS)
1:1435b9a:                         throw new IllegalStateException();
1:1435b9a:                     return true;
1:597a1d5:                 }
1:1435b9a: 
1:3bee990:                 int count = seed.visits == 1 ? 1 + (int) generator.maxRowCount : Math.max(1, expectedRowCount / seed.visits);
1:1435b9a:                 position = seed.moveForwards(count);
1:1435b9a:                 isFirstWrite = position == 0;
1:1435b9a:                 setLastRow(position + count - 1);
1:1435b9a: 
1:597a1d5:                 // seek to our start position
1:1435b9a:                 switch (seek(position))
1:597a1d5:                 {
1:597a1d5:                     case END_OF_PARTITION:
1:597a1d5:                         return false;
1:597a1d5:                     case SUCCESS:
1:597a1d5:                         return true;
1:597a1d5:                 }
1:597a1d5:             }
1:597a1d5:         }
1:597a1d5: 
1:3bee990:         void setUseChance(double useChance)
1:3bee990:         {
1:3bee990:             if (this.useChance < 1d)
1:3bee990:             {
1:3bee990:                 // we clear our prior roll-modifiers if the use chance was previously less-than zero
1:3bee990:                 Arrays.fill(rollmodifier, 1d);
1:3bee990:                 Arrays.fill(chancemodifier, 1d);
1:3bee990:             }
1:3bee990:             this.useChance = useChance;
1:3bee990:         }
1:3bee990: 
1:3bee990:         public Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth)
1:3bee990:         {
1:3bee990:             setSeed(seed);
1:3bee990:             setUseChance(1d);
1:3bee990:             if (clusteringComponentDepth == 0)
1:3bee990:             {
1:6d29ed0:                 reset(1d, 1d, -1, false, PartitionGenerator.Order.SORTED);
1:3bee990:                 return Pair.create(new Row(partitionKey), new Row(partitionKey));
1:3bee990:             }
1:3bee990: 
1:3bee990:             this.order = PartitionGenerator.Order.SORTED;
1:3bee990:             assert clusteringComponentDepth <= clusteringComponents.length;
1:3bee990:             for (Queue<?> q : clusteringComponents)
1:3bee990:                 q.clear();
1:3bee990: 
1:3bee990:             fill(0);
1:3bee990:             Pair<int[], Object[]> bound1 = randomBound(clusteringComponentDepth);
1:3bee990:             Pair<int[], Object[]> bound2 = randomBound(clusteringComponentDepth);
1:3bee990:             if (compare(bound1.left, bound2.left) > 0) { Pair<int[], Object[]> tmp = bound1; bound1 = bound2; bound2 = tmp;}
1:3bee990:             Arrays.fill(lastRow, 0);
1:3bee990:             System.arraycopy(bound2.left, 0, lastRow, 0, bound2.left.length);
1:3bee990:             Arrays.fill(currentRow, 0);
1:3bee990:             System.arraycopy(bound1.left, 0, currentRow, 0, bound1.left.length);
1:3bee990:             seekToCurrentRow();
1:3bee990:             return Pair.create(new Row(partitionKey, bound1.right), new Row(partitionKey, bound2.right));
1:3bee990:         }
1:3bee990: 
1:1435b9a:         // returns expected row count
1:1435b9a:         private int setNoLastRow(int firstComponentCount)
1:1435b9a:         {
1:1435b9a:             Arrays.fill(lastRow, Integer.MAX_VALUE);
1:1435b9a:             return firstComponentCount * generator.clusteringDescendantAverages[0];
1:1435b9a:         }
1:1435b9a: 
1:1435b9a:         // sets the last row we will visit
1:1435b9a:         // returns expected distance from zero
1:1435b9a:         private int setLastRow(int position)
1:1435b9a:         {
1:1435b9a:             if (position < 0)
1:1435b9a:                 throw new IllegalStateException();
1:1435b9a: 
1:1435b9a:             decompose(position, lastRow);
1:1435b9a:             int expectedRowCount = 0;
1:1435b9a:             for (int i = 0 ; i < lastRow.length ; i++)
1:1435b9a:             {
1:1435b9a:                 int l = lastRow[i];
1:1435b9a:                 expectedRowCount += l * generator.clusteringDescendantAverages[i];
1:1435b9a:             }
1:1435b9a:             return expectedRowCount + 1;
1:1435b9a:         }
1:1435b9a: 
1:1435b9a:         // returns 0 if we are currently on the last row we are allocated to visit; 1 if it is after, -1 if it is before
1:1435b9a:         // this is defined by _limit_, which is wired up from expected (mean) row counts
1:1435b9a:         // the last row is where position == lastRow, except the last index is 1 less;
1:1435b9a:         // OR if that row does not exist, it is the last row prior to it
1:1435b9a:         private int compareToLastRow(int depth)
1:1435b9a:         {
1:3bee990:             int prev = 0;
1:1435b9a:             for (int i = 0 ; i <= depth ; i++)
1:1435b9a:             {
1:1435b9a:                 int p = currentRow[i], l = lastRow[i], r = clusteringComponents[i].size();
1:3bee990:                 if (prev < 0)
1:3bee990:                 {
1:3bee990:                     // if we're behind our last position in theory, and have known more items to visit in practice
1:3bee990:                     // we're definitely behind our last row
1:3bee990:                     if (r > 1)
1:3bee990:                         return -1;
1:3bee990:                     // otherwise move forwards to see if we might have more to visit
1:3bee990:                 }
1:3bee990:                 else if (p > l)
1:3bee990:                 {
1:3bee990:                     // prev must be == 0, so if p > l, we're after our last row
1:3bee990:                     return 1;
1:3bee990:                 }
1:3bee990:                 else if (p == l)
1:3bee990:                 {
1:3bee990:                     // if we're equal to our last row up to our current depth, then we need to loop and look forwards
1:3bee990:                 }
1:3bee990:                 else if (r == 1)
1:3bee990:                 {
1:3bee990:                     // if this is our last item in practice, store if we're behind our theoretical position
1:3bee990:                     // and move forwards; if every remaining practical item is 1, we're at the last row
1:3bee990:                     // otherwise we're before it
1:3bee990:                     prev = p - l;
1:3bee990:                 }
1:3bee990:                 else
1:3bee990:                 {
1:3bee990:                     // p < l, and r > 1, so we're definitely not at the end
1:3bee990:                     return -1;
1:3bee990:                 }
1:1435b9a:             }
1:1435b9a:             return 0;
1:1435b9a:         }
1:1435b9a: 
1:1435b9a:         /**
1:1435b9a:          * Translate the scalar position into a tiered position based on mean expected counts
1:1435b9a:          * @param scalar scalar position
1:1435b9a:          * @param decomposed target container
1:1435b9a:          */
1:597a1d5:         private void decompose(int scalar, int[] decomposed)
1:597a1d5:         {
1:597a1d5:             for (int i = 0 ; i < decomposed.length ; i++)
1:597a1d5:             {
1:597a1d5:                 int avg = generator.clusteringDescendantAverages[i];
1:597a1d5:                 decomposed[i] = scalar / avg;
1:597a1d5:                 scalar %= avg;
1:597a1d5:             }
1:1435b9a:             for (int i = lastRow.length - 1 ; i > 0 ; i--)
1:597a1d5:             {
1:597a1d5:                 int avg = generator.clusteringComponentAverages[i];
1:597a1d5:                 if (decomposed[i] >= avg)
1:597a1d5:                 {
1:597a1d5:                     decomposed[i - 1] += decomposed[i] / avg;
1:597a1d5:                     decomposed[i] %= avg;
1:597a1d5:                 }
1:597a1d5:             }
1:597a1d5:         }
1:597a1d5: 
1:3bee990:         private static int compare(int[] l, int[] r)
1:3bee990:         {
1:3bee990:             for (int i = 0 ; i < l.length ; i++)
1:3bee990:                 if (l[i] != r[i])
1:3bee990:                     return Integer.compare(l[i], r[i]);
1:3bee990:             return 0;
1:3bee990:         }
1:3bee990: 
1:597a1d5:         static enum State
1:597a1d5:         {
1:597a1d5:             END_OF_PARTITION, AFTER_LIMIT, SUCCESS;
1:597a1d5:         }
1:597a1d5: 
1:1435b9a:         /**
1:1435b9a:          * seek to the provided position to initialise the iterator
1:1435b9a:          *
1:1435b9a:          * @param scalar scalar position
1:1435b9a:          * @return resultant iterator state
1:1435b9a:          */
1:597a1d5:         private State seek(int scalar)
1:597a1d5:         {
1:597a1d5:             if (scalar == 0)
1:597a1d5:             {
1:1435b9a:                 this.currentRow[0] = -1;
1:597a1d5:                 clusteringComponents[0].addFirst(this);
1:597a1d5:                 return setHasNext(advance(0, true));
1:597a1d5:             }
1:3bee990:             decompose(scalar, this.currentRow);
1:3bee990:             return seekToCurrentRow();
1:3bee990:         }
1:3bee990:         private State seekToCurrentRow()
1:3bee990:         {
1:1435b9a:             int[] position = this.currentRow;
1:597a1d5:             for (int i = 0 ; i < position.length ; i++)
1:597a1d5:             {
1:597a1d5:                 if (i != 0)
1:597a1d5:                     fill(i);
1:597a1d5:                 for (int c = position[i] ; c > 0 ; c--)
1:597a1d5:                     clusteringComponents[i].poll();
1:597a1d5: 
1:597a1d5:                 // we can have started from a position that does not exist, in which
1:597a1d5:                 // case we need to ascend back up our clustering components, advancing as we go
2:597a1d5:                 if (clusteringComponents[i].isEmpty())
1:597a1d5:                 {
1:597a1d5:                     int j = i;
1:1435b9a:                     while (true)
1:597a1d5:                     {
1:1435b9a:                         // if we've exhausted the whole partition, we're done
1:1435b9a:                         if (--j < 0)
1:1435b9a:                             return setHasNext(false);
1:1435b9a: 
1:597a1d5:                         clusteringComponents[j].poll();
1:597a1d5:                         if (!clusteringComponents[j].isEmpty())
1:597a1d5:                             break;
1:597a1d5:                     }
1:597a1d5: 
1:1435b9a:                     // we don't check here to see if we've exceeded our lastRow,
1:1435b9a:                     // because if we came to a non-existent position and generated a lastRow
1:597a1d5:                     // we want to at least find the next real position, and set it on the seed
1:597a1d5:                     // in this case we do then yield false and select a different seed to continue with
1:597a1d5:                     position[j]++;
1:597a1d5:                     Arrays.fill(position, j + 1, position.length, 0);
1:597a1d5:                     while (j < i)
1:597a1d5:                         fill(++j);
1:597a1d5:                 }
1:1435b9a: 
1:597a1d5:                 row.row[i] = clusteringComponents[i].peek();
1:597a1d5:             }
1:597a1d5: 
1:1435b9a:             if (compareToLastRow(currentRow.length - 1) > 0)
2:597a1d5:                 return setHasNext(false);
1:597a1d5: 
1:597a1d5:             // call advance so we honour any select chance
1:1435b9a:             position[position.length - 1]--;
1:597a1d5:             clusteringComponents[position.length - 1].addFirst(this);
1:597a1d5:             return setHasNext(advance(position.length - 1, true));
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         // normal method for moving the iterator forward; maintains the row object, and delegates to advance(int)
1:597a1d5:         // to move the iterator to the next item
1:3bee990:         Row advance()
1:597a1d5:         {
1:597a1d5:             // we are always at the leaf level when this method is invoked
1:597a1d5:             // so we calculate the seed for generating the row by combining the seed that generated the clustering components
1:597a1d5:             int depth = clusteringComponents.length - 1;
1:597a1d5:             long parentSeed = clusteringSeeds[depth];
1:597a1d5:             long rowSeed = seed(clusteringComponents[depth].peek(), generator.clusteringComponents.get(depth).type, parentSeed);
1:597a1d5: 
1:3bee990:             Row result = row.copy();
1:597a1d5:             // and then fill the row with the _non-clustering_ values for the position we _were_ at, as this is what we'll deliver
1:6d29ed0:             double valueColumn = 0.0;
1:6d29ed0: 
1:597a1d5:             for (int i = clusteringSeeds.length ; i < row.row.length ; i++)
1:597a1d5:             {
1:597a1d5:                 Generator gen = generator.valueComponents.get(i - clusteringSeeds.length);
1:6d29ed0:                 if (++valueColumn / totalValueColumns > rowPopulationRatio)
1:6d29ed0:                 {
1:6d29ed0:                     result.row[i] = null;
1:6d29ed0:                 }
1:6d29ed0:                 else
1:6d29ed0:                 {
1:6d29ed0:                     gen.setSeed(rowSeed);
1:6d29ed0:                     result.row[i] = gen.generate();
1:6d29ed0:                 }
1:597a1d5:             }
1:597a1d5: 
1:597a1d5:             // then we advance the leaf level
1:597a1d5:             setHasNext(advance(depth, false));
1:3bee990:             return result;
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         private boolean advance(int depth, boolean first)
1:597a1d5:         {
1:f852401:             ThreadLocalRandom random = ThreadLocalRandom.current();
1:597a1d5:             // advance the leaf component
1:597a1d5:             clusteringComponents[depth].poll();
1:1435b9a:             currentRow[depth]++;
1:597a1d5:             while (true)
1:597a1d5:             {
1:597a1d5:                 if (clusteringComponents[depth].isEmpty())
1:597a1d5:                 {
1:597a1d5:                     // if we've run out of clustering components at this level, ascend
1:597a1d5:                     if (depth == 0)
1:597a1d5:                         return false;
1:597a1d5:                     depth--;
1:597a1d5:                     clusteringComponents[depth].poll();
1:1435b9a:                     if (++currentRow[depth] > lastRow[depth])
1:597a1d5:                         return false;
1:1435b9a:                     continue;
1:597a1d5:                 }
1:597a1d5: 
1:1435b9a:                 int compareToLastRow = compareToLastRow(depth);
1:1435b9a:                 if (compareToLastRow > 0)
1:1435b9a:                 {
1:1435b9a:                     assert !first;
1:597a1d5:                     return false;
1:1435b9a:                 }
1:1435b9a:                 boolean forceReturnOne = first && compareToLastRow == 0;
1:597a1d5: 
1:597a1d5:                 // the chance of descending is the uniform usechance, multiplied by the number of children
1:597a1d5:                 // we would on average generate (so if we have a 0.1 use chance, but should generate 10 children
1:597a1d5:                 // then we will always descend), multiplied by 1/(compound roll), where (compound roll) is the
1:597a1d5:                 // chance with which we reached this depth, i.e. if we already beat 50/50 odds, we double our
1:597a1d5:                 // chance of beating this next roll
1:597a1d5:                 double thischance = useChance * chancemodifier[depth];
1:597a1d5:                 if (forceReturnOne || thischance > 0.99999f || thischance >= random.nextDouble())
1:597a1d5:                 {
1:597a1d5:                     // if we're descending, we fill in our clustering component and increase our depth
1:597a1d5:                     row.row[depth] = clusteringComponents[depth].peek();
1:597a1d5:                     depth++;
1:597a1d5:                     if (depth == clusteringComponents.length)
1:597a1d5:                         return true;
1:597a1d5:                     // if we haven't reached the leaf, we update our probability statistics, fill in all of
1:597a1d5:                     // this level's clustering components, and repeat
1:597a1d5:                     if (useChance < 1d)
1:597a1d5:                     {
1:597a1d5:                         rollmodifier[depth] = rollmodifier[depth - 1] / Math.min(1d, thischance);
1:597a1d5:                         chancemodifier[depth] = generator.clusteringDescendantAverages[depth] * rollmodifier[depth];
1:597a1d5:                     }
1:1435b9a:                     currentRow[depth] = 0;
1:597a1d5:                     fill(depth);
2:597a1d5:                     continue;
1:597a1d5:                 }
1:597a1d5: 
1:597a1d5:                 if (compareToLastRow >= 0)
1:597a1d5:                     return false;
1:597a1d5: 
1:597a1d5:                 // if we don't descend, we remove the clustering suffix we've skipped and continue
1:597a1d5:                 clusteringComponents[depth].poll();
1:1435b9a:                 currentRow[depth]++;
1:597a1d5:             }
1:597a1d5:         }
1:597a1d5: 
1:3bee990:         private Pair<int[], Object[]> randomBound(int clusteringComponentDepth)
1:3bee990:         {
1:3bee990:             ThreadLocalRandom rnd = ThreadLocalRandom.current();
1:3bee990:             int[] position = new int[clusteringComponentDepth];
1:3bee990:             Object[] bound = new Object[clusteringComponentDepth];
1:3bee990:             position[0] = rnd.nextInt(clusteringComponents[0].size());
1:3bee990:             bound[0] = Iterables.get(clusteringComponents[0], position[0]);
1:3bee990:             for (int d = 1 ; d < clusteringComponentDepth ; d++)
1:3bee990:             {
1:3bee990:                 fill(d);
1:3bee990:                 position[d] = rnd.nextInt(clusteringComponents[d].size());
1:3bee990:                 bound[d] = Iterables.get(clusteringComponents[d], position[d]);
1:3bee990:             }
1:3bee990:             for (int d = 1 ; d < clusteringComponentDepth ; d++)
1:3bee990:                 clusteringComponents[d].clear();
1:3bee990:             return Pair.create(position, bound);
1:3bee990:         }
1:3bee990: 
1:597a1d5:         // generate the clustering components for the provided depth; requires preceding components
1:597a1d5:         // to have been generated and their seeds populated into clusteringSeeds
1:597a1d5:         void fill(int depth)
1:597a1d5:         {
1:3bee990:             long seed = depth == 0 ? idseed : clusteringSeeds[depth - 1];
1:597a1d5:             Generator gen = generator.clusteringComponents.get(depth);
1:597a1d5:             gen.setSeed(seed);
1:597a1d5:             fill(clusteringComponents[depth], (int) gen.clusteringDistribution.next(), gen);
1:3bee990:             clusteringSeeds[depth] = seed(clusteringComponents[depth].peek(), generator.clusteringComponents.get(depth).type, seed);
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         // generate the clustering components into the queue
1:597a1d5:         void fill(Queue<Object> queue, int count, Generator generator)
1:597a1d5:         {
1:597a1d5:             if (count == 1)
1:597a1d5:             {
1:597a1d5:                 queue.add(generator.generate());
1:597a1d5:                 return;
1:597a1d5:             }
1:597a1d5: 
1:3bee990:             switch (order)
1:597a1d5:             {
1:597a1d5:                 case SORTED:
1:597a1d5:                     if (Comparable.class.isAssignableFrom(generator.clazz))
1:597a1d5:                     {
1:597a1d5:                         tosort.clear();
1:597a1d5:                         for (int i = 0 ; i < count ; i++)
1:597a1d5:                             tosort.add(generator.generate());
1:597a1d5:                         Collections.sort((List<Comparable>) (List<?>) tosort);
1:597a1d5:                         for (int i = 0 ; i < count ; i++)
1:3bee990:                             if (i == 0 || ((Comparable) tosort.get(i - 1)).compareTo(tosort.get(i)) < 0)
1:597a1d5:                                 queue.add(tosort.get(i));
1:597a1d5:                         break;
1:597a1d5:                     }
1:597a1d5:                 case ARBITRARY:
1:597a1d5:                     unique.clear();
1:597a1d5:                     for (int i = 0 ; i < count ; i++)
1:597a1d5:                     {
1:597a1d5:                         Object next = generator.generate();
1:597a1d5:                         if (unique.add(next))
1:597a1d5:                             queue.add(next);
1:597a1d5:                     }
1:597a1d5:                     break;
1:597a1d5:                 case SHUFFLED:
1:597a1d5:                     unique.clear();
1:597a1d5:                     tosort.clear();
1:597a1d5:                     ThreadLocalRandom rand = ThreadLocalRandom.current();
1:597a1d5:                     for (int i = 0 ; i < count ; i++)
1:597a1d5:                     {
1:597a1d5:                         Object next = generator.generate();
1:597a1d5:                         if (unique.add(next))
1:597a1d5:                             tosort.add(next);
1:597a1d5:                     }
1:597a1d5:                     for (int i = 0 ; i < tosort.size() ; i++)
1:597a1d5:                     {
1:597a1d5:                         int index = rand.nextInt(i, tosort.size());
1:597a1d5:                         Object obj = tosort.get(index);
1:597a1d5:                         tosort.set(index, tosort.get(i));
1:597a1d5:                         queue.add(obj);
1:597a1d5:                     }
1:597a1d5:                     break;
1:597a1d5:                 default:
3:597a1d5:                     throw new IllegalStateException();
1:597a1d5:             }
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         public boolean hasNext()
1:597a1d5:         {
1:597a1d5:             return hasNext;
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         public Row next()
1:597a1d5:         {
1:597a1d5:             if (!hasNext())
1:597a1d5:                 throw new NoSuchElementException();
1:3bee990:             return advance();
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         public boolean finishedPartition()
1:597a1d5:         {
1:597a1d5:             return clusteringComponents[0].isEmpty();
1:597a1d5:         }
1:597a1d5: 
1:597a1d5:         private State setHasNext(boolean hasNext)
1:597a1d5:         {
1:f852401:             this.hasNext = hasNext;
1:597a1d5:             if (!hasNext)
1:597a1d5:             {
1:597a1d5:                 boolean isLast = finishedPartition();
1:597a1d5:                 if (isWrite)
1:597a1d5:                 {
1:597a1d5:                     boolean isFirst = isFirstWrite;
1:597a1d5:                     if (isFirst)
1:597a1d5:                         seedManager.markFirstWrite(seed, isLast);
1:597a1d5:                     if (isLast)
1:597a1d5:                         seedManager.markLastWrite(seed, isFirst);
1:597a1d5:                 }
1:597a1d5:                 return isLast ? State.END_OF_PARTITION : State.AFTER_LIMIT;
1:597a1d5:             }
1:597a1d5:             return State.SUCCESS;
1:597a1d5:         }
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     public void remove()
1:597a1d5:     {
1:597a1d5:         throw new UnsupportedOperationException();
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     // calculate a new seed based on the combination of a parent seed and the generated child, to generate
1:597a1d5:     // any children of this child
1:597a1d5:     static long seed(Object object, AbstractType type, long seed)
1:597a1d5:     {
1:597a1d5:         if (object instanceof ByteBuffer)
1:597a1d5:         {
1:597a1d5:             ByteBuffer buf = (ByteBuffer) object;
1:597a1d5:             for (int i = buf.position() ; i < buf.limit() ; i++)
1:597a1d5:                 seed = (31 * seed) + buf.get(i);
1:597a1d5:             return seed;
1:597a1d5:         }
1:597a1d5:         else if (object instanceof String)
1:597a1d5:         {
1:597a1d5:             String str = (String) object;
1:597a1d5:             for (int i = 0 ; i < str.length() ; i++)
1:597a1d5:                 seed = (31 * seed) + str.charAt(i);
1:597a1d5:             return seed;
1:597a1d5:         }
1:597a1d5:         else if (object instanceof Number)
1:597a1d5:         {
1:597a1d5:             return (seed * 31) + ((Number) object).longValue();
1:597a1d5:         }
1:597a1d5:         else if (object instanceof UUID)
1:597a1d5:         {
1:597a1d5:             return seed * 31 + (((UUID) object).getLeastSignificantBits() ^ ((UUID) object).getMostSignificantBits());
1:597a1d5:         }
1:597a1d5:         else
1:597a1d5:         {
1:597a1d5:             return seed(type.decompose(object), BytesType.instance, seed);
1:597a1d5:         }
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     public Object getPartitionKey(int i)
1:597a1d5:     {
1:597a1d5:         return partitionKey[i];
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     public String getKeyAsString()
1:597a1d5:     {
1:597a1d5:         StringBuilder sb = new StringBuilder();
1:597a1d5:         int i = 0;
1:597a1d5:         for (Object key : partitionKey)
1:597a1d5:         {
1:597a1d5:             if (i > 0)
1:597a1d5:                 sb.append("|");
1:597a1d5:             AbstractType type = generator.partitionKey.get(i++).type;
1:597a1d5:             sb.append(type.getString(type.decompose(key)));
1:597a1d5:         }
1:597a1d5:         return sb.toString();
1:597a1d5:     }
1:597a1d5: 
1:597a1d5:     // used for thrift smart routing - if it's a multi-part key we don't try to route correctly right now
1:597a1d5:     public ByteBuffer getToken()
1:597a1d5:     {
1:597a1d5:         return generator.partitionKey.get(0).type.decompose(partitionKey[0]);
1:597a1d5:     }
1:597a1d5: }
============================================================================
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:6d29ed0
/////////////////////////////////////////////////////////////////////////
1:     abstract boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order);
/////////////////////////////////////////////////////////////////////////
1:     public boolean reset(Seed seed, double useChance, double rowPopulationRatio, boolean isWrite)
1:         return reset(useChance, rowPopulationRatio, 0, isWrite, PartitionIterator.this.order);
1:     public boolean reset(Seed seed, int targetCount, double rowPopulationRatio,  boolean isWrite)
1:         return reset(Double.NaN, rowPopulationRatio,targetCount, isWrite,PartitionIterator.this.order);
1:         double rowPopulationRatio;
1:         final double totalValueColumns;
1: 
1:             this.totalValueColumns = generator.valueComponents.size();
1:             reset(1d, 1d, 1, false, PartitionGenerator.Order.SORTED);
1:         boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order)
1:             this.rowPopulationRatio = rowPopulationRatio;
/////////////////////////////////////////////////////////////////////////
1: 
1:             double valueColumn = 0.0;
1:                 if (generator.permitNulls(i) && (++valueColumn/totalValueColumns) > rowPopulationRatio)
1:                 {
1:                     row.row[i] = null;
1:                 }
1:                 else
1:                 {
1:                     Generator gen = generator.valueComponents.get(i);
1:                     gen.setSeed(idseed);
1:                     row.row[i] = gen.generate();
1:                 }
/////////////////////////////////////////////////////////////////////////
1:         double rowPopulationRatio;
1:         final double totalValueColumns;
/////////////////////////////////////////////////////////////////////////
1:             this.totalValueColumns = generator.valueComponents.size();
/////////////////////////////////////////////////////////////////////////
1:         boolean reset(double useChance, double rowPopulationRatio, int targetCount, boolean isWrite, PartitionGenerator.Order order)
1:             this.rowPopulationRatio = rowPopulationRatio;
/////////////////////////////////////////////////////////////////////////
1:                 reset(1d, 1d, -1, false, PartitionGenerator.Order.SORTED);
/////////////////////////////////////////////////////////////////////////
1:             double valueColumn = 0.0;
1: 
1:                 if (++valueColumn / totalValueColumns > rowPopulationRatio)
1:                 {
1:                     result.row[i] = null;
1:                 }
1:                 else
1:                 {
1:                     gen.setSeed(rowSeed);
1:                     result.row[i] = gen.generate();
1:                 }
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:3bee990
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.Iterables;
1: 
1: import org.apache.cassandra.utils.Pair;
/////////////////////////////////////////////////////////////////////////
0:     abstract boolean reset(double useChance, int targetCount, boolean isWrite, PartitionGenerator.Order order);
1:     // picks random (inclusive) bounds to iterate, and returns them
1:     public abstract Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth);
1:     PartitionGenerator.Order order;
/////////////////////////////////////////////////////////////////////////
1:     void setSeed(Seed seed)
/////////////////////////////////////////////////////////////////////////
1:         this.order = generator.order;
0:         return reset(useChance, 0, isWrite, PartitionIterator.this.order);
1:         this.order = generator.order;
0:         return reset(Double.NaN, targetCount, isWrite, PartitionIterator.this.order);
/////////////////////////////////////////////////////////////////////////
1:         public Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth)
1:         {
1:             assert clusteringComponentDepth == 0;
1:             setSeed(seed);
0:             reset(1d, 1, false, PartitionGenerator.Order.SORTED);
1:             return Pair.create(new Row(partitionKey), new Row(partitionKey));
1:         }
1: 
0:         boolean reset(double useChance, int targetCount, boolean isWrite, PartitionGenerator.Order order)
/////////////////////////////////////////////////////////////////////////
0:         boolean reset(double useChance, int targetCount, boolean isWrite, PartitionGenerator.Order order)
1:             this.order = order;
/////////////////////////////////////////////////////////////////////////
1:             setUseChance(useChance);
/////////////////////////////////////////////////////////////////////////
1:                 fill(0);
/////////////////////////////////////////////////////////////////////////
1:                 int count = seed.visits == 1 ? 1 + (int) generator.maxRowCount : Math.max(1, expectedRowCount / seed.visits);
/////////////////////////////////////////////////////////////////////////
1:         void setUseChance(double useChance)
1:         {
1:             if (this.useChance < 1d)
1:             {
1:                 // we clear our prior roll-modifiers if the use chance was previously less-than zero
1:                 Arrays.fill(rollmodifier, 1d);
1:                 Arrays.fill(chancemodifier, 1d);
1:             }
1:             this.useChance = useChance;
1:         }
1: 
1:         public Pair<Row, Row> resetToBounds(Seed seed, int clusteringComponentDepth)
1:         {
1:             setSeed(seed);
1:             setUseChance(1d);
1:             if (clusteringComponentDepth == 0)
1:             {
0:                 reset(1d, -1, false, PartitionGenerator.Order.SORTED);
1:                 return Pair.create(new Row(partitionKey), new Row(partitionKey));
1:             }
1: 
1:             this.order = PartitionGenerator.Order.SORTED;
1:             assert clusteringComponentDepth <= clusteringComponents.length;
1:             for (Queue<?> q : clusteringComponents)
1:                 q.clear();
1: 
1:             fill(0);
1:             Pair<int[], Object[]> bound1 = randomBound(clusteringComponentDepth);
1:             Pair<int[], Object[]> bound2 = randomBound(clusteringComponentDepth);
1:             if (compare(bound1.left, bound2.left) > 0) { Pair<int[], Object[]> tmp = bound1; bound1 = bound2; bound2 = tmp;}
1:             Arrays.fill(lastRow, 0);
1:             System.arraycopy(bound2.left, 0, lastRow, 0, bound2.left.length);
1:             Arrays.fill(currentRow, 0);
1:             System.arraycopy(bound1.left, 0, currentRow, 0, bound1.left.length);
1:             seekToCurrentRow();
1:             return Pair.create(new Row(partitionKey, bound1.right), new Row(partitionKey, bound2.right));
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:             int prev = 0;
1:                 if (prev < 0)
1:                 {
1:                     // if we're behind our last position in theory, and have known more items to visit in practice
1:                     // we're definitely behind our last row
1:                     if (r > 1)
1:                         return -1;
1:                     // otherwise move forwards to see if we might have more to visit
1:                 }
1:                 else if (p > l)
1:                 {
1:                     // prev must be == 0, so if p > l, we're after our last row
1:                     return 1;
1:                 }
1:                 else if (p == l)
1:                 {
1:                     // if we're equal to our last row up to our current depth, then we need to loop and look forwards
1:                 }
1:                 else if (r == 1)
1:                 {
1:                     // if this is our last item in practice, store if we're behind our theoretical position
1:                     // and move forwards; if every remaining practical item is 1, we're at the last row
1:                     // otherwise we're before it
1:                     prev = p - l;
1:                 }
1:                 else
1:                 {
1:                     // p < l, and r > 1, so we're definitely not at the end
1:                     return -1;
1:                 }
/////////////////////////////////////////////////////////////////////////
1:         private static int compare(int[] l, int[] r)
1:         {
1:             for (int i = 0 ; i < l.length ; i++)
1:                 if (l[i] != r[i])
1:                     return Integer.compare(l[i], r[i]);
1:             return 0;
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:             decompose(scalar, this.currentRow);
1:             return seekToCurrentRow();
1:         }
1:         private State seekToCurrentRow()
1:         {
/////////////////////////////////////////////////////////////////////////
1:         Row advance()
/////////////////////////////////////////////////////////////////////////
1:             Row result = row.copy();
0:                 result.row[i] = gen.generate();
1:             return result;
/////////////////////////////////////////////////////////////////////////
1:         private Pair<int[], Object[]> randomBound(int clusteringComponentDepth)
1:         {
1:             ThreadLocalRandom rnd = ThreadLocalRandom.current();
1:             int[] position = new int[clusteringComponentDepth];
1:             Object[] bound = new Object[clusteringComponentDepth];
1:             position[0] = rnd.nextInt(clusteringComponents[0].size());
1:             bound[0] = Iterables.get(clusteringComponents[0], position[0]);
1:             for (int d = 1 ; d < clusteringComponentDepth ; d++)
1:             {
1:                 fill(d);
1:                 position[d] = rnd.nextInt(clusteringComponents[d].size());
1:                 bound[d] = Iterables.get(clusteringComponents[d], position[d]);
1:             }
1:             for (int d = 1 ; d < clusteringComponentDepth ; d++)
1:                 clusteringComponents[d].clear();
1:             return Pair.create(position, bound);
1:         }
1: 
1:             long seed = depth == 0 ? idseed : clusteringSeeds[depth - 1];
1:             clusteringSeeds[depth] = seed(clusteringComponents[depth].peek(), generator.clusteringComponents.get(depth).type, seed);
/////////////////////////////////////////////////////////////////////////
1:             switch (order)
/////////////////////////////////////////////////////////////////////////
1:                             if (i == 0 || ((Comparable) tosort.get(i - 1)).compareTo(tosort.get(i)) < 0)
/////////////////////////////////////////////////////////////////////////
1:             return advance();
/////////////////////////////////////////////////////////////////////////
commit:1435b9a
/////////////////////////////////////////////////////////////////////////
0:     abstract boolean reset(double useChance, int targetCount, boolean isWrite);
1: 
1: 
1:     // we reuse these objects to save garbage
1:     final Object[] partitionKey;
/////////////////////////////////////////////////////////////////////////
0:     public boolean reset(Seed seed, double useChance, boolean isWrite)
0:         return reset(useChance, 0, isWrite);
0:     public boolean reset(Seed seed, int targetCount, boolean isWrite)
0:         return reset(Double.NaN, targetCount, isWrite);
/////////////////////////////////////////////////////////////////////////
0:         boolean reset(double useChance, int targetCount, boolean isWrite)
1:             this.isWrite = isWrite;
/////////////////////////////////////////////////////////////////////////
1:         // probability any single row will be generated in this iteration
1:         double useChance;
1:         final int[] currentRow = new int[generator.clusteringComponents.size()];
1:         final int[] lastRow = new int[currentRow.length];
/////////////////////////////////////////////////////////////////////////
1:         /**
1:          * initialise the iterator state
1:          *
1:          * if we're a write, the expected behaviour is that the requested
1:          * batch count is compounded with the seed's visit count to decide
1:          * how much we should return in one iteration
1:          *
1:          * @param useChance uniform chance of visiting any single row (NaN if targetCount provided)
1:          * @param targetCount number of rows we would like to visit (0 if useChance provided)
1:          * @param isWrite true if the action requires write semantics
1:          *
1:          * @return true if there is data to return, false otherwise
1:          */
0:         boolean reset(double useChance, int targetCount, boolean isWrite)
1:             this.isWrite = isWrite;
/////////////////////////////////////////////////////////////////////////
1:                 expectedRowCount = setLastRow(position - 1);
1:                 expectedRowCount = setNoLastRow(firstComponentCount);
/////////////////////////////////////////////////////////////////////////
1:                 // we loop in case we have picked an entirely non-existent range, in which case
1:                 // we will reset the seed's position, then try again (until we exhaust it or find
1:                 // some real range)
1: 
1:                 if (!isWrite)
1:                     if (seek(0) != State.SUCCESS)
1:                         throw new IllegalStateException();
1:                     return true;
1: 
0:                 int count = Math.max(1, expectedRowCount / seed.visits);
1:                 position = seed.moveForwards(count);
1:                 isFirstWrite = position == 0;
1:                 setLastRow(position + count - 1);
1: 
1:                 switch (seek(position))
1:         // returns expected row count
1:         private int setNoLastRow(int firstComponentCount)
1:         {
1:             Arrays.fill(lastRow, Integer.MAX_VALUE);
1:             return firstComponentCount * generator.clusteringDescendantAverages[0];
1:         }
1: 
1:         // sets the last row we will visit
1:         // returns expected distance from zero
1:         private int setLastRow(int position)
1:         {
1:             if (position < 0)
1:                 throw new IllegalStateException();
1: 
1:             decompose(position, lastRow);
1:             int expectedRowCount = 0;
1:             for (int i = 0 ; i < lastRow.length ; i++)
1:             {
1:                 int l = lastRow[i];
1:                 expectedRowCount += l * generator.clusteringDescendantAverages[i];
1:             }
1:             return expectedRowCount + 1;
1:         }
1: 
1:         // returns 0 if we are currently on the last row we are allocated to visit; 1 if it is after, -1 if it is before
1:         // this is defined by _limit_, which is wired up from expected (mean) row counts
1:         // the last row is where position == lastRow, except the last index is 1 less;
1:         // OR if that row does not exist, it is the last row prior to it
1:         private int compareToLastRow(int depth)
1:         {
1:             for (int i = 0 ; i <= depth ; i++)
1:             {
1:                 int p = currentRow[i], l = lastRow[i], r = clusteringComponents[i].size();
0:                 if ((p == l) | (r == 1))
1:                     continue;
0:                 return p - l;
1:             }
1:             return 0;
1:         }
1: 
1:         /**
1:          * Translate the scalar position into a tiered position based on mean expected counts
1:          * @param scalar scalar position
1:          * @param decomposed target container
1:          */
/////////////////////////////////////////////////////////////////////////
1:             for (int i = lastRow.length - 1 ; i > 0 ; i--)
/////////////////////////////////////////////////////////////////////////
1:         /**
1:          * seek to the provided position to initialise the iterator
1:          *
1:          * @param scalar scalar position
1:          * @return resultant iterator state
1:          */
1:                 this.currentRow[0] = -1;
1:             int[] position = this.currentRow;
/////////////////////////////////////////////////////////////////////////
1:                     while (true)
1:                         // if we've exhausted the whole partition, we're done
1:                         if (--j < 0)
1:                             return setHasNext(false);
1: 
1:                     // we don't check here to see if we've exceeded our lastRow,
1:                     // because if we came to a non-existent position and generated a lastRow
1: 
1:             if (compareToLastRow(currentRow.length - 1) > 0)
1:             position[position.length - 1]--;
/////////////////////////////////////////////////////////////////////////
1:             currentRow[depth]++;
/////////////////////////////////////////////////////////////////////////
1:                     if (++currentRow[depth] > lastRow[depth])
1:                 int compareToLastRow = compareToLastRow(depth);
1:                 if (compareToLastRow > 0)
1:                 {
1:                     assert !first;
1:                 }
1:                 boolean forceReturnOne = first && compareToLastRow == 0;
/////////////////////////////////////////////////////////////////////////
1:                     currentRow[depth] = 0;
/////////////////////////////////////////////////////////////////////////
1:                 currentRow[depth]++;
commit:f852401
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 switch (seek(isWrite ? position : 0))
/////////////////////////////////////////////////////////////////////////
1:             ThreadLocalRandom random = ThreadLocalRandom.current();
/////////////////////////////////////////////////////////////////////////
1:             this.hasNext = hasNext;
/////////////////////////////////////////////////////////////////////////
commit:597a1d5
/////////////////////////////////////////////////////////////////////////
1: package org.apache.cassandra.stress.generate;
1: /*
1:  * 
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  * 
1:  *   http://www.apache.org/licenses/LICENSE-2.0
1:  * 
1:  * Unless required by applicable law or agreed to in writing,
1:  * software distributed under the License is distributed on an
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:  * KIND, either express or implied.  See the License for the
1:  * specific language governing permissions and limitations
1:  * under the License.
1:  * 
1:  */
1: 
1: 
1: import java.nio.ByteBuffer;
1: import java.util.ArrayDeque;
1: import java.util.ArrayList;
1: import java.util.Arrays;
1: import java.util.Collections;
1: import java.util.Deque;
1: import java.util.HashSet;
1: import java.util.Iterator;
1: import java.util.List;
1: import java.util.NoSuchElementException;
1: import java.util.Queue;
1: import java.util.Set;
1: import java.util.UUID;
1: import java.util.concurrent.ThreadLocalRandom;
1: 
1: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.db.marshal.BytesType;
0: import org.apache.cassandra.stress.Operation;
1: import org.apache.cassandra.stress.generate.values.Generator;
1: 
1: // a partition is re-used to reduce garbage generation, as is its internal RowIterator
1: // TODO: we should batch the generation of clustering components so we can bound the time and size necessary to
1: // generate huge partitions with only a small number of clustering components; i.e. we should generate seeds for batches
1: // of a single component, and then generate the values within those batches as necessary. this will be difficult with
1: // generating sorted partitions, and may require generator support (e.g. we may need to support generating prefixes
1: // that are extended/suffixed to generate each batch, so that we can sort the prefixes)
1: public abstract class PartitionIterator implements Iterator<Row>
1: {
1: 
0:     // we reuse the row object to save garbage
0:     abstract boolean reset(double useChance, int targetCount, Operation op);
1: 
1:     long idseed;
1:     Seed seed;
0:     final Object[] partitionKey;
1:     final PartitionGenerator generator;
1:     final SeedManager seedManager;
1:     final Row row;
1: 
1:     public static PartitionIterator get(PartitionGenerator generator, SeedManager seedManager)
1:     {
1:         if (generator.clusteringComponents.size() > 0)
1:             return new MultiRowIterator(generator, seedManager);
1:         else
1:             return new SingleRowIterator(generator, seedManager);
1:     }
1: 
1:     private PartitionIterator(PartitionGenerator generator, SeedManager seedManager)
1:     {
1:         this.generator = generator;
1:         this.seedManager = seedManager;
1:         this.partitionKey = new Object[generator.partitionKey.size()];
1:         this.row = new Row(partitionKey, new Object[generator.clusteringComponents.size() + generator.valueComponents.size()]);
1:     }
1: 
0:     private void setSeed(Seed seed)
1:     {
1:         long idseed = 0;
1:         for (int i = 0 ; i < partitionKey.length ; i++)
1:         {
1:             Generator generator = this.generator.partitionKey.get(i);
1:             // set the partition key seed based on the current work item we're processing
1:             generator.setSeed(seed.seed);
1:             Object key = generator.generate();
1:             partitionKey[i] = key;
1:             // then contribute this value to the data seed
1:             idseed = seed(key, generator.type, idseed);
1:         }
1:         this.seed = seed;
1:         this.idseed = idseed;
1:     }
1: 
0:     public boolean reset(Seed seed, double useChance, Operation op)
1:     {
1:         setSeed(seed);
0:         return reset(useChance, 0, op);
1:     }
1: 
0:     public boolean reset(Seed seed, int targetCount, Operation op)
1:     {
1:         setSeed(seed);
0:         return reset(Double.NaN, targetCount, op);
1:     }
1: 
1:     static class SingleRowIterator extends PartitionIterator
1:     {
1:         boolean done;
1:         boolean isWrite;
1: 
1:         private SingleRowIterator(PartitionGenerator generator, SeedManager seedManager)
1:         {
1:             super(generator, seedManager);
1:         }
1: 
0:         boolean reset(double useChance, int targetCount, Operation op)
1:         {
1:             done = false;
0:             isWrite = op.isWrite();
1:             return true;
1:         }
1: 
1:         public boolean hasNext()
1:         {
1:             return !done;
1:         }
1: 
1:         public Row next()
1:         {
1:             if (done)
1:                 throw new NoSuchElementException();
1:             for (int i = 0 ; i < row.row.length ; i++)
1:             {
0:                 Generator gen = generator.valueComponents.get(i);
0:                 gen.setSeed(idseed);
0:                 row.row[i] = gen.generate();
1:             }
1:             done = true;
1:             if (isWrite)
1:             {
1:                 seedManager.markFirstWrite(seed, true);
1:                 seedManager.markLastWrite(seed, true);
1:             }
1:             return row;
1:         }
1:     }
1: 
1:     // permits iterating a random subset of the procedurally generated rows in this partition. this is the only mechanism for visiting rows.
1:     // we maintain a stack of clustering components and their seeds; for each clustering component we visit, we generate all values it takes at that level,
1:     // and then, using the average (total) number of children it takes we randomly choose whether or not we visit its children;
1:     // if we do, we generate all possible values the immediate children can take, and repeat the process. So at any one time we are using space proportional
1:     // to C.N, where N is the average number of values each clustering component takes, as opposed to N^C total values in the partition.
1:     // TODO : support first/last row, and constraining reads to rows we know are populated
1:     static class MultiRowIterator extends PartitionIterator
1:     {
1: 
0:         // probability any single row will be generated in this iteration
0:         double useChance;
1: 
1:         // the seed used to generate the current values for the clustering components at each depth;
1:         // used to save recalculating it for each row, so we only need to recalc from prior row.
1:         final long[] clusteringSeeds = new long[generator.clusteringComponents.size()];
1:         // the components remaining to be visited for each level of the current stack
1:         final Deque<Object>[] clusteringComponents = new ArrayDeque[generator.clusteringComponents.size()];
1: 
1:         // we want our chance of selection to be applied uniformly, so we compound the roll we make at each level
1:         // so that we know with what chance we reached there, and we adjust our roll at that level by that amount
1:         final double[] chancemodifier = new double[generator.clusteringComponents.size()];
1:         final double[] rollmodifier = new double[generator.clusteringComponents.size()];
0:         final ThreadLocalRandom random = ThreadLocalRandom.current();
1: 
1:         // track where in the partition we are, and where we are limited to
0:         final int[] position = new int[generator.clusteringComponents.size()];
0:         final int[] limit = new int[position.length];
1:         boolean hasNext, isFirstWrite, isWrite;
1: 
1:         // reusable collections for generating unique and sorted clustering components
1:         final Set<Object> unique = new HashSet<>();
1:         final List<Object> tosort = new ArrayList<>();
1: 
1:         MultiRowIterator(PartitionGenerator generator, SeedManager seedManager)
1:         {
1:             super(generator, seedManager);
1:             for (int i = 0 ; i < clusteringComponents.length ; i++)
1:                 clusteringComponents[i] = new ArrayDeque<>();
1:             rollmodifier[0] = 1f;
1:             chancemodifier[0] = generator.clusteringDescendantAverages[0];
1:         }
1: 
0:         // if we're a write, the expected behaviour is that the requested batch count is compounded with the seed's visit
0:         // count to decide how much we should return in one iteration
0:         boolean reset(double useChance, int targetCount, Operation op)
1:         {
0:             if (this.useChance < 1d)
1:             {
0:                 // we clear our prior roll-modifiers if the use chance was previously less-than zero
0:                 Arrays.fill(rollmodifier, 1d);
0:                 Arrays.fill(chancemodifier, 1d);
1:             }
1: 
1:             // set the seed for the first clustering component
1:             generator.clusteringComponents.get(0).setSeed(idseed);
1: 
1:             // calculate how many first clustering components we'll generate, and how many total rows this predicts
1:             int firstComponentCount = (int) generator.clusteringComponents.get(0).clusteringDistribution.next();
1:             int expectedRowCount;
1: 
1:             int position = seed.position();
0:             isWrite = op.isWrite();
1: 
1:             if (isWrite)
1:                 expectedRowCount = firstComponentCount * generator.clusteringDescendantAverages[0];
1:             else if (position != 0)
0:                 expectedRowCount = setLimit(position);
1:             else
0:                 expectedRowCount = setNoLimit(firstComponentCount);
1: 
1:             if (Double.isNaN(useChance))
1:                 useChance = Math.max(0d, Math.min(1d, targetCount / (double) expectedRowCount));
0:             this.useChance = useChance;
1: 
1:             while (true)
1:             {
0:                 // TODO: we could avoid repopulating these each loop, by tracking our prior position
1:                 for (Queue<?> q : clusteringComponents)
1:                     q.clear();
0:                 clusteringSeeds[0] = idseed;
0:                 fill(clusteringComponents[0], firstComponentCount, generator.clusteringComponents.get(0));
1: 
0:                 // we loop in case we have picked an entirely non-existent range, in which case
0:                 // we will reset the seed's position, then try again (until we exhaust it or find
0:                 // some real range) - this only happens for writes, so we only keep this logic in the loop
1: 
1:                 if (isWrite)
1:                 {
0:                     position = seed.moveForwards(Math.max(1, expectedRowCount / seed.visits));
0:                     isFirstWrite = position == 0;
1:                 }
1: 
1:                 // seek to our start position
0:                 switch (seek(isWrite ? position : null))
1:                 {
1:                     case END_OF_PARTITION:
1:                         return false;
1:                     case SUCCESS:
1:                         return true;
1:                 }
1: 
0:                 if (!isWrite)
1:                     throw new IllegalStateException();
1: 
0:                 // TODO: recompose our real position into the nearest scalar position, and ensure the seed position is >= this
1:             }
1:         }
1: 
1:         private void decompose(int scalar, int[] decomposed)
1:         {
1:             for (int i = 0 ; i < decomposed.length ; i++)
1:             {
1:                 int avg = generator.clusteringDescendantAverages[i];
1:                 decomposed[i] = scalar / avg;
1:                 scalar %= avg;
1:             }
0:             for (int i = limit.length - 1 ; i > 0 ; i--)
1:             {
1:                 int avg = generator.clusteringComponentAverages[i];
1:                 if (decomposed[i] >= avg)
1:                 {
1:                     decomposed[i - 1] += decomposed[i] / avg;
1:                     decomposed[i] %= avg;
1:                 }
1:             }
1:         }
1: 
0:         private int setNoLimit(int firstComponentCount)
1:         {
0:             Arrays.fill(limit, Integer.MAX_VALUE);
0:             return firstComponentCount * generator.clusteringDescendantAverages[0];
1:         }
1: 
0:         private int setLimit(int position)
1:         {
0:             decompose(position, limit);
0:             int expectedRowCount = 0;
0:             for (int i = 0 ; i < limit.length ; i++)
1:             {
0:                 int l = limit[i];
0:                 expectedRowCount += l * generator.clusteringDescendantAverages[i];
1:             }
0:             return expectedRowCount;
1:         }
1: 
1:         static enum State
1:         {
1:             END_OF_PARTITION, AFTER_LIMIT, SUCCESS;
1:         }
1: 
0:         // seek to the provided position (or the first entry if null)
1:         private State seek(int scalar)
1:         {
1:             if (scalar == 0)
1:             {
0:                 this.position[0] = -1;
1:                 clusteringComponents[0].addFirst(this);
1:                 return setHasNext(advance(0, true));
1:             }
1: 
0:             int[] position = this.position;
0:             decompose(scalar, position);
0:             boolean incremented = false;
1:             for (int i = 0 ; i < position.length ; i++)
1:             {
1:                 if (i != 0)
1:                     fill(i);
1:                 for (int c = position[i] ; c > 0 ; c--)
1:                     clusteringComponents[i].poll();
1: 
1:                 // we can have started from a position that does not exist, in which
1:                 // case we need to ascend back up our clustering components, advancing as we go
1:                 if (clusteringComponents[i].isEmpty())
1:                 {
1:                     int j = i;
0:                     while (--j >= 0)
1:                     {
1:                         clusteringComponents[j].poll();
1:                         if (!clusteringComponents[j].isEmpty())
1:                             break;
1:                     }
1: 
0:                     // if we've exhausted the whole partition, we're done
0:                     if (j < 0)
1:                         return setHasNext(false);
1: 
0:                     // we don't check here to see if we've exceeded our limit,
0:                     // because if we came to a non-existent position and generated a limit
1:                     // we want to at least find the next real position, and set it on the seed
1:                     // in this case we do then yield false and select a different seed to continue with
1:                     position[j]++;
1:                     Arrays.fill(position, j + 1, position.length, 0);
1:                     while (j < i)
1:                         fill(++j);
0:                     incremented = true;
1:                 }
1:                 if (clusteringComponents[i].isEmpty())
1:                     throw new IllegalStateException();
1:                 row.row[i] = clusteringComponents[i].peek();
1:             }
1: 
0:             if (incremented && compareToLastRow() > 0)
1:                 return setHasNext(false);
1: 
0:             position[position.length - 1]--;
1:             // call advance so we honour any select chance
1:             clusteringComponents[position.length - 1].addFirst(this);
1: 
1:             return setHasNext(advance(position.length - 1, true));
1:         }
1: 
1:         // normal method for moving the iterator forward; maintains the row object, and delegates to advance(int)
1:         // to move the iterator to the next item
0:         void advance()
1:         {
1:             // we are always at the leaf level when this method is invoked
1:             // so we calculate the seed for generating the row by combining the seed that generated the clustering components
1:             int depth = clusteringComponents.length - 1;
1:             long parentSeed = clusteringSeeds[depth];
1:             long rowSeed = seed(clusteringComponents[depth].peek(), generator.clusteringComponents.get(depth).type, parentSeed);
1: 
1:             // and then fill the row with the _non-clustering_ values for the position we _were_ at, as this is what we'll deliver
1:             for (int i = clusteringSeeds.length ; i < row.row.length ; i++)
1:             {
1:                 Generator gen = generator.valueComponents.get(i - clusteringSeeds.length);
0:                 gen.setSeed(rowSeed);
0:                 row.row[i] = gen.generate();
1:             }
1: 
1:             // then we advance the leaf level
1:             setHasNext(advance(depth, false));
1:         }
1: 
1:         private boolean advance(int depth, boolean first)
1:         {
1:             // advance the leaf component
1:             clusteringComponents[depth].poll();
0:             position[depth]++;
1:             while (true)
1:             {
1:                 if (clusteringComponents[depth].isEmpty())
1:                 {
1:                     // if we've run out of clustering components at this level, ascend
1:                     if (depth == 0)
1:                         return false;
1:                     depth--;
1:                     clusteringComponents[depth].poll();
0:                     if (++position[depth] > limit[depth])
1:                         return false;
1:                     continue;
1:                 }
1: 
0:                 int compareToLastRow = compareToLastRow();
0:                 if (compareToLastRow > 0 && !first)
1:                     return false;
0:                 boolean forceReturnOne = first && compareToLastRow >= 0;
1: 
1:                 // the chance of descending is the uniform usechance, multiplied by the number of children
1:                 // we would on average generate (so if we have a 0.1 use chance, but should generate 10 children
1:                 // then we will always descend), multiplied by 1/(compound roll), where (compound roll) is the
1:                 // chance with which we reached this depth, i.e. if we already beat 50/50 odds, we double our
1:                 // chance of beating this next roll
1:                 double thischance = useChance * chancemodifier[depth];
1:                 if (forceReturnOne || thischance > 0.99999f || thischance >= random.nextDouble())
1:                 {
1:                     // if we're descending, we fill in our clustering component and increase our depth
1:                     row.row[depth] = clusteringComponents[depth].peek();
1:                     depth++;
1:                     if (depth == clusteringComponents.length)
1:                         return true;
1:                     // if we haven't reached the leaf, we update our probability statistics, fill in all of
1:                     // this level's clustering components, and repeat
1:                     if (useChance < 1d)
1:                     {
1:                         rollmodifier[depth] = rollmodifier[depth - 1] / Math.min(1d, thischance);
1:                         chancemodifier[depth] = generator.clusteringDescendantAverages[depth] * rollmodifier[depth];
1:                     }
0:                     position[depth] = 0;
1:                     fill(depth);
1:                     continue;
1:                 }
1: 
1:                 if (compareToLastRow >= 0)
1:                     return false;
1: 
1:                 // if we don't descend, we remove the clustering suffix we've skipped and continue
1:                 clusteringComponents[depth].poll();
0:                 position[depth]++;
1:             }
1:         }
1: 
0:         private static int compare(int[] a, int[] b)
1:         {
0:             for (int i = 0 ; i != a.length ; i++)
0:                 if (a[i] != b[i])
0:                     return Integer.compare(a[i], b[i]);
0:             return 0;
1:         }
1: 
0:         private int compareToLastRow()
1:         {
0:             int c = position.length - 1;
0:             for (int i = 0 ; i <= c ; i++)
1:             {
0:                 int p = position[i], l = limit[i], r = clusteringComponents[i].size();
0:                 if (i == c && p == l - 1)
0:                     return 0;
0:                 if ((p < l) & (r > 1))
0:                     return -1;
0:                 if (p > l)
0:                     return 1;
1:             }
0:             return 1;
1:         }
1: 
1:         // generate the clustering components for the provided depth; requires preceding components
1:         // to have been generated and their seeds populated into clusteringSeeds
1:         void fill(int depth)
1:         {
0:             long seed = clusteringSeeds[depth - 1];
1:             Generator gen = generator.clusteringComponents.get(depth);
1:             gen.setSeed(seed);
0:             clusteringSeeds[depth] = seed(clusteringComponents[depth - 1].peek(), generator.clusteringComponents.get(depth - 1).type, seed);
1:             fill(clusteringComponents[depth], (int) gen.clusteringDistribution.next(), gen);
1:         }
1: 
1:         // generate the clustering components into the queue
1:         void fill(Queue<Object> queue, int count, Generator generator)
1:         {
1:             if (count == 1)
1:             {
1:                 queue.add(generator.generate());
1:                 return;
1:             }
1: 
0:             switch (this.generator.order)
1:             {
1:                 case SORTED:
1:                     if (Comparable.class.isAssignableFrom(generator.clazz))
1:                     {
1:                         tosort.clear();
1:                         for (int i = 0 ; i < count ; i++)
1:                             tosort.add(generator.generate());
1:                         Collections.sort((List<Comparable>) (List<?>) tosort);
1:                         for (int i = 0 ; i < count ; i++)
0:                             if (i == 0 || ((Comparable) tosort.get(i - 1)).compareTo(i) < 0)
1:                                 queue.add(tosort.get(i));
1:                         break;
1:                     }
1:                 case ARBITRARY:
1:                     unique.clear();
1:                     for (int i = 0 ; i < count ; i++)
1:                     {
1:                         Object next = generator.generate();
1:                         if (unique.add(next))
1:                             queue.add(next);
1:                     }
1:                     break;
1:                 case SHUFFLED:
1:                     unique.clear();
1:                     tosort.clear();
1:                     ThreadLocalRandom rand = ThreadLocalRandom.current();
1:                     for (int i = 0 ; i < count ; i++)
1:                     {
1:                         Object next = generator.generate();
1:                         if (unique.add(next))
1:                             tosort.add(next);
1:                     }
1:                     for (int i = 0 ; i < tosort.size() ; i++)
1:                     {
1:                         int index = rand.nextInt(i, tosort.size());
1:                         Object obj = tosort.get(index);
1:                         tosort.set(index, tosort.get(i));
1:                         queue.add(obj);
1:                     }
1:                     break;
1:                 default:
1:                     throw new IllegalStateException();
1:             }
1:         }
1: 
1:         public boolean hasNext()
1:         {
1:             return hasNext;
1:         }
1: 
1:         public Row next()
1:         {
1:             if (!hasNext())
1:                 throw new NoSuchElementException();
0:             advance();
1:             return row;
1:         }
1: 
1:         public boolean finishedPartition()
1:         {
1:             return clusteringComponents[0].isEmpty();
1:         }
1: 
1:         private State setHasNext(boolean hasNext)
1:         {
1:             if (!hasNext)
1:             {
0:                 this.hasNext = false;
1:                 boolean isLast = finishedPartition();
1:                 if (isWrite)
1:                 {
1:                     boolean isFirst = isFirstWrite;
1:                     if (isFirst)
1:                         seedManager.markFirstWrite(seed, isLast);
1:                     if (isLast)
1:                         seedManager.markLastWrite(seed, isFirst);
1:                 }
1:                 return isLast ? State.END_OF_PARTITION : State.AFTER_LIMIT;
1:             }
0:             this.hasNext = hasNext;
1:             return State.SUCCESS;
1:         }
1:     }
1: 
1:     public void remove()
1:     {
1:         throw new UnsupportedOperationException();
1:     }
1: 
1:     // calculate a new seed based on the combination of a parent seed and the generated child, to generate
1:     // any children of this child
1:     static long seed(Object object, AbstractType type, long seed)
1:     {
1:         if (object instanceof ByteBuffer)
1:         {
1:             ByteBuffer buf = (ByteBuffer) object;
1:             for (int i = buf.position() ; i < buf.limit() ; i++)
1:                 seed = (31 * seed) + buf.get(i);
1:             return seed;
1:         }
1:         else if (object instanceof String)
1:         {
1:             String str = (String) object;
1:             for (int i = 0 ; i < str.length() ; i++)
1:                 seed = (31 * seed) + str.charAt(i);
1:             return seed;
1:         }
1:         else if (object instanceof Number)
1:         {
1:             return (seed * 31) + ((Number) object).longValue();
1:         }
1:         else if (object instanceof UUID)
1:         {
1:             return seed * 31 + (((UUID) object).getLeastSignificantBits() ^ ((UUID) object).getMostSignificantBits());
1:         }
1:         else
1:         {
1:             return seed(type.decompose(object), BytesType.instance, seed);
1:         }
1:     }
1: 
1:     public Object getPartitionKey(int i)
1:     {
1:         return partitionKey[i];
1:     }
1: 
1:     public String getKeyAsString()
1:     {
1:         StringBuilder sb = new StringBuilder();
1:         int i = 0;
1:         for (Object key : partitionKey)
1:         {
1:             if (i > 0)
1:                 sb.append("|");
1:             AbstractType type = generator.partitionKey.get(i++).type;
1:             sb.append(type.getString(type.decompose(key)));
1:         }
1:         return sb.toString();
1:     }
1: 
1:     // used for thrift smart routing - if it's a multi-part key we don't try to route correctly right now
1:     public ByteBuffer getToken()
1:     {
1:         return generator.partitionKey.get(0).type.decompose(partitionKey[0]);
1:     }
1: 
1: }
============================================================================
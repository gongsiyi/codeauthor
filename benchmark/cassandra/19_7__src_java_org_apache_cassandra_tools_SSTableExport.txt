1:71b1c4a: /*
1:71b1c4a:  * Licensed to the Apache Software Foundation (ASF) under one
1:71b1c4a:  * or more contributor license agreements.  See the NOTICE file
1:71b1c4a:  * distributed with this work for additional information
1:71b1c4a:  * regarding copyright ownership.  The ASF licenses this file
1:71b1c4a:  * to you under the Apache License, Version 2.0 (the
1:71b1c4a:  * "License"); you may not use this file except in compliance
1:71b1c4a:  * with the License.  You may obtain a copy of the License at
2:71b1c4a:  *
1:71b1c4a:  *     http://www.apache.org/licenses/LICENSE-2.0
1:71b1c4a:  *
1:71b1c4a:  * Unless required by applicable law or agreed to in writing, software
1:71b1c4a:  * distributed under the License is distributed on an "AS IS" BASIS,
1:71b1c4a:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:71b1c4a:  * See the License for the specific language governing permissions and
1:71b1c4a:  * limitations under the License.
2:71b1c4a:  */
1:71b1c4a: package org.apache.cassandra.tools;
1:d569f87: 
1:71b1c4a: import java.io.File;
1:71b1c4a: import java.io.IOException;
1:71b1c4a: import java.util.*;
1:71b1c4a: import java.util.concurrent.atomic.AtomicLong;
1:71b1c4a: import java.util.stream.Collectors;
1:71b1c4a: import java.util.stream.Stream;
1:71b1c4a: import java.util.stream.StreamSupport;
1:d569f87: 
1:71b1c4a: import org.apache.commons.cli.*;
1:d569f87: 
1:71b1c4a: import org.apache.cassandra.config.CFMetaData;
1:9797511: import org.apache.cassandra.config.DatabaseDescriptor;
1:71b1c4a: import org.apache.cassandra.cql3.ColumnIdentifier;
1:d569f87: import org.apache.cassandra.db.DecoratedKey;
1:71b1c4a: import org.apache.cassandra.db.PartitionPosition;
1:71b1c4a: import org.apache.cassandra.db.SerializationHeader;
1:71b1c4a: import org.apache.cassandra.db.marshal.UTF8Type;
1:71b1c4a: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
1:0a5e220: import org.apache.cassandra.dht.*;
1:71b1c4a: import org.apache.cassandra.exceptions.ConfigurationException;
1:d569f87: import org.apache.cassandra.io.sstable.Descriptor;
1:71b1c4a: import org.apache.cassandra.io.sstable.ISSTableScanner;
1:d569f87: import org.apache.cassandra.io.sstable.KeyIterator;
1:71b1c4a: import org.apache.cassandra.io.sstable.format.SSTableReader;
1:71b1c4a: import org.apache.cassandra.io.sstable.metadata.MetadataComponent;
1:71b1c4a: import org.apache.cassandra.io.sstable.metadata.MetadataType;
1:71b1c4a: import org.apache.cassandra.utils.FBUtilities;
1:d569f87: 
2:71b1c4a: /**
1:71b1c4a:  * Export SSTables to JSON format.
1:71b1c4a:  */
1:71b1c4a: public class SSTableExport
1:d569f87: {
1:089f92b: 
1:71b1c4a:     private static final String KEY_OPTION = "k";
1:71b1c4a:     private static final String DEBUG_OUTPUT_OPTION = "d";
1:71b1c4a:     private static final String EXCLUDE_KEY_OPTION = "x";
1:71b1c4a:     private static final String ENUMERATE_KEYS_OPTION = "e";
1:620efdc:     private static final String RAW_TIMESTAMPS = "t";
9:71b1c4a: 
1:71b1c4a:     private static final Options options = new Options();
1:71b1c4a:     private static CommandLine cmd;
1:71b1c4a: 
1:71b1c4a:     static
1:d569f87:     {
1:9797511:         DatabaseDescriptor.toolInitialization();
1:71b1c4a: 
1:5a77bd1:         Option optKey = new Option(KEY_OPTION, true, "Partition key");
1:71b1c4a:         // Number of times -k <key> can be passed on the command line.
1:71b1c4a:         optKey.setArgs(500);
1:71b1c4a:         options.addOption(optKey);
1:71b1c4a: 
1:5a77bd1:         Option excludeKey = new Option(EXCLUDE_KEY_OPTION, true, "Excluded partition key");
1:71b1c4a:         // Number of times -x <key> can be passed on the command line.
1:71b1c4a:         excludeKey.setArgs(500);
1:71b1c4a:         options.addOption(excludeKey);
1:71b1c4a: 
1:5a77bd1:         Option optEnumerate = new Option(ENUMERATE_KEYS_OPTION, false, "enumerate partition keys only");
1:71b1c4a:         options.addOption(optEnumerate);
1:71b1c4a: 
1:71b1c4a:         Option debugOutput = new Option(DEBUG_OUTPUT_OPTION, false, "CQL row per line internal representation");
1:71b1c4a:         options.addOption(debugOutput);
1:620efdc: 
1:620efdc:         Option rawTimestamps = new Option(RAW_TIMESTAMPS, false, "Print raw timestamps instead of iso8601 date strings");
1:620efdc:         options.addOption(rawTimestamps);
6:71b1c4a:     }
1:d569f87: 
1:d569f87:     /**
1:71b1c4a:      * Construct table schema from info stored in SSTable's Stats.db
1:d569f87:      *
1:71b1c4a:      * @param desc SSTable's descriptor
1:71b1c4a:      * @return Restored CFMetaData
1:71b1c4a:      * @throws IOException when Stats.db cannot be read
1:d569f87:      */
1:71b1c4a:     public static CFMetaData metadataFromSSTable(Descriptor desc) throws IOException
1:d569f87:     {
1:71b1c4a:         if (!desc.version.storeRows())
1:71b1c4a:             throw new IOException("pre-3.0 SSTable is not supported.");
1:d569f87: 
1:de86ab1:         EnumSet<MetadataType> types = EnumSet.of(MetadataType.STATS, MetadataType.HEADER);
1:71b1c4a:         Map<MetadataType, MetadataComponent> sstableMetadata = desc.getMetadataSerializer().deserialize(desc, types);
1:71b1c4a:         SerializationHeader.Component header = (SerializationHeader.Component) sstableMetadata.get(MetadataType.HEADER);
1:de86ab1:         IPartitioner partitioner = FBUtilities.newPartitioner(desc);
1:0a5e220: 
1:71b1c4a:         CFMetaData.Builder builder = CFMetaData.Builder.create("keyspace", "table").withPartitioner(partitioner);
1:71b1c4a:         header.getStaticColumns().entrySet().stream()
1:71b1c4a:                 .forEach(entry -> {
1:71b1c4a:                     ColumnIdentifier ident = ColumnIdentifier.getInterned(UTF8Type.instance.getString(entry.getKey()), true);
1:71b1c4a:                     builder.addStaticColumn(ident, entry.getValue());
1:71b1c4a:                 });
1:71b1c4a:         header.getRegularColumns().entrySet().stream()
1:71b1c4a:                 .forEach(entry -> {
1:71b1c4a:                     ColumnIdentifier ident = ColumnIdentifier.getInterned(UTF8Type.instance.getString(entry.getKey()), true);
1:71b1c4a:                     builder.addRegularColumn(ident, entry.getValue());
1:71b1c4a:                 });
1:0a5e220:         builder.addPartitionKey("PartitionKey", header.getKeyType());
1:71b1c4a:         for (int i = 0; i < header.getClusteringTypes().size(); i++)
1:d569f87:         {
1:71b1c4a:             builder.addClusteringColumn("clustering" + (i > 0 ? i : ""), header.getClusteringTypes().get(i));
1:d569f87:         }
1:71b1c4a:         return builder.build();
1:d569f87:     }
1:d569f87: 
1:71b1c4a:     private static <T> Stream<T> iterToStream(Iterator<T> iter)
1:d569f87:     {
1:71b1c4a:         Spliterator<T> splititer = Spliterators.spliteratorUnknownSize(iter, Spliterator.IMMUTABLE);
1:71b1c4a:         return StreamSupport.stream(splititer, false);
1:d569f87:     }
1:71b1c4a: 
1:71b1c4a:     /**
1:71b1c4a:      * Given arguments specifying an SSTable, and optionally an output file, export the contents of the SSTable to JSON.
1:71b1c4a:      *
1:71b1c4a:      * @param args
1:71b1c4a:      *            command lines arguments
1:71b1c4a:      * @throws ConfigurationException
1:71b1c4a:      *             on configuration failure (wrong params given)
1:71b1c4a:      */
1:5b0ec50:     public static void main(String[] args) throws ConfigurationException
1:d569f87:     {
1:71b1c4a:         CommandLineParser parser = new PosixParser();
1:71b1c4a:         try
5:71b1c4a:         {
1:71b1c4a:             cmd = parser.parse(options, args);
1:d569f87:         }
1:71b1c4a:         catch (ParseException e1)
1:71b1c4a:         {
1:71b1c4a:             System.err.println(e1.getMessage());
1:71b1c4a:             printUsage();
1:71b1c4a:             System.exit(1);
1:d569f87:         }
1:71b1c4a: 
1:71b1c4a:         if (cmd.getArgs().length != 1)
1:71b1c4a:         {
1:71b1c4a:             System.err.println("You must supply exactly one sstable");
1:71b1c4a:             printUsage();
1:71b1c4a:             System.exit(1);
1:d569f87:         }
1:71b1c4a: 
1:71b1c4a:         String[] keys = cmd.getOptionValues(KEY_OPTION);
1:71b1c4a:         HashSet<String> excludes = new HashSet<>(Arrays.asList(
1:71b1c4a:                 cmd.getOptionValues(EXCLUDE_KEY_OPTION) == null
1:71b1c4a:                         ? new String[0]
1:71b1c4a:                         : cmd.getOptionValues(EXCLUDE_KEY_OPTION)));
1:71b1c4a:         String ssTableFileName = new File(cmd.getArgs()[0]).getAbsolutePath();
1:71b1c4a: 
1:71b1c4a:         if (Descriptor.isLegacyFile(new File(ssTableFileName)))
1:71b1c4a:         {
1:71b1c4a:             System.err.println("Unsupported legacy sstable");
1:71b1c4a:             System.exit(1);
1:71b1c4a:         }
1:71b1c4a:         if (!new File(ssTableFileName).exists())
1:71b1c4a:         {
1:71b1c4a:             System.err.println("Cannot find file " + ssTableFileName);
1:71b1c4a:             System.exit(1);
1:71b1c4a:         }
1:71b1c4a:         Descriptor desc = Descriptor.fromFilename(ssTableFileName);
1:71b1c4a:         try
1:71b1c4a:         {
1:71b1c4a:             CFMetaData metadata = metadataFromSSTable(desc);
1:71b1c4a:             if (cmd.hasOption(ENUMERATE_KEYS_OPTION))
1:71b1c4a:             {
1:0fd07e8:                 try (KeyIterator iter = new KeyIterator(desc, metadata))
1:0fd07e8:                 {
1:0fd07e8:                     JsonTransformer.keysToJson(null, iterToStream(iter),
1:0fd07e8:                                                cmd.hasOption(RAW_TIMESTAMPS),
1:0fd07e8:                                                metadata,
1:0fd07e8:                                                System.out);
1:0fd07e8:                 }
1:71b1c4a:             }
1:71b1c4a:             else
1:71b1c4a:             {
1:71b1c4a:                 SSTableReader sstable = SSTableReader.openNoValidation(desc, metadata);
1:71b1c4a:                 IPartitioner partitioner = sstable.getPartitioner();
1:71b1c4a:                 final ISSTableScanner currentScanner;
1:71b1c4a:                 if ((keys != null) && (keys.length > 0))
1:71b1c4a:                 {
1:71b1c4a:                     List<AbstractBounds<PartitionPosition>> bounds = Arrays.stream(keys)
1:71b1c4a:                             .filter(key -> !excludes.contains(key))
1:71b1c4a:                             .map(metadata.getKeyValidator()::fromString)
1:71b1c4a:                             .map(partitioner::decorateKey)
1:71b1c4a:                             .sorted()
1:71b1c4a:                             .map(DecoratedKey::getToken)
1:71b1c4a:                             .map(token -> new Bounds<>(token.minKeyBound(), token.maxKeyBound())).collect(Collectors.toList());
1:71b1c4a:                     currentScanner = sstable.getScanner(bounds.iterator());
1:71b1c4a:                 }
1:71b1c4a:                 else
1:71b1c4a:                 {
1:71b1c4a:                     currentScanner = sstable.getScanner();
1:71b1c4a:                 }
1:71b1c4a:                 Stream<UnfilteredRowIterator> partitions = iterToStream(currentScanner).filter(i ->
1:71b1c4a:                     excludes.isEmpty() || !excludes.contains(metadata.getKeyValidator().getString(i.partitionKey().getKey()))
1:71b1c4a:                 );
1:71b1c4a:                 if (cmd.hasOption(DEBUG_OUTPUT_OPTION))
1:71b1c4a:                 {
1:71b1c4a:                     AtomicLong position = new AtomicLong();
1:71b1c4a:                     partitions.forEach(partition ->
1:71b1c4a:                     {
1:71b1c4a:                         position.set(currentScanner.getCurrentPosition());
1:71b1c4a: 
1:48bdb41:                         if (!partition.partitionLevelDeletion().isLive())
1:71b1c4a:                         {
1:48bdb41:                             System.out.println("[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@" +
1:48bdb41:                                                position.get() + " " + partition.partitionLevelDeletion());
1:71b1c4a:                         }
1:48bdb41:                         if (!partition.staticRow().isEmpty())
1:71b1c4a:                         {
1:48bdb41:                             System.out.println("[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@" +
1:48bdb41:                                                position.get() + " " + partition.staticRow().toString(metadata, true));
1:71b1c4a:                         }
1:71b1c4a:                         partition.forEachRemaining(row ->
1:71b1c4a:                         {
1:71b1c4a:                             System.out.println(
1:71b1c4a:                                     "[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@"
1:71b1c4a:                                             + position.get() + " " + row.toString(metadata, false, true));
1:71b1c4a:                             position.set(currentScanner.getCurrentPosition());
1:71b1c4a:                         });
1:71b1c4a:                     });
1:71b1c4a:                 }
1:71b1c4a:                 else
1:71b1c4a:                 {
1:620efdc:                     JsonTransformer.toJson(currentScanner, partitions, cmd.hasOption(RAW_TIMESTAMPS), metadata, System.out);
1:71b1c4a:                 }
1:71b1c4a:             }
1:71b1c4a:         }
1:71b1c4a:         catch (IOException e)
1:71b1c4a:         {
1:71b1c4a:             // throwing exception outside main with broken pipe causes windows cmd to hang
1:71b1c4a:             e.printStackTrace(System.err);
1:71b1c4a:         }
1:71b1c4a: 
1:71b1c4a:         System.exit(0);
1:71b1c4a:     }
1:71b1c4a: 
1:71b1c4a:     private static void printUsage()
1:71b1c4a:     {
1:71b1c4a:         String usage = String.format("sstabledump <options> <sstable file path>%n");
1:71b1c4a:         String header = "Dump contents of given SSTable to standard output in JSON format.";
1:71b1c4a:         new HelpFormatter().printHelp(usage, header, options, "");
1:0a5e220:     }
1:71b1c4a: }
============================================================================
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:b834aed
commit:0fd07e8
/////////////////////////////////////////////////////////////////////////
1:                 try (KeyIterator iter = new KeyIterator(desc, metadata))
1:                 {
1:                     JsonTransformer.keysToJson(null, iterToStream(iter),
1:                                                cmd.hasOption(RAW_TIMESTAMPS),
1:                                                metadata,
1:                                                System.out);
1:                 }
commit:0a5e220
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.dht.*;
0: import org.apache.cassandra.index.SecondaryIndexManager;
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner partitioner = SecondaryIndexManager.isIndexColumnFamily(desc.cfname)
0:                                    ? new LocalPartitioner(header.getKeyType())
0:                                    : FBUtilities.newPartitioner(validationMetadata.partitioner);
1: 
/////////////////////////////////////////////////////////////////////////
1:         builder.addPartitionKey("PartitionKey", header.getKeyType());
/////////////////////////////////////////////////////////////////////////
1: }
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.config.DatabaseDescriptor;
/////////////////////////////////////////////////////////////////////////
1:         DatabaseDescriptor.toolInitialization();
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:de86ab1
/////////////////////////////////////////////////////////////////////////
1:         EnumSet<MetadataType> types = EnumSet.of(MetadataType.STATS, MetadataType.HEADER);
1:         IPartitioner partitioner = FBUtilities.newPartitioner(desc);
commit:27ad2db
commit:3a5f79e
commit:2bf63f6
/////////////////////////////////////////////////////////////////////////
0:         DatabaseDescriptor.loadSchemas(false);
commit:d569f87
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.cassandra.utils.ByteBufferUtil.bytesToHex;
0: import static org.apache.cassandra.utils.ByteBufferUtil.hexToBytes;
1: 
0: import java.util.ArrayList;
0: import java.util.Arrays;
0: import java.util.Collection;
0: import java.util.HashSet;
0: import java.util.Iterator;
0: import java.util.List;
0: import java.util.Set;
1: 
0: import org.apache.commons.cli.CommandLine;
0: import org.apache.commons.cli.CommandLineParser;
0: import org.apache.commons.cli.Option;
0: import org.apache.commons.cli.Options;
0: import org.apache.commons.cli.ParseException;
0: import org.apache.commons.cli.PosixParser;
0: import org.apache.cassandra.config.ConfigurationException;
0: import org.apache.cassandra.db.AbstractColumnContainer;
0: import org.apache.cassandra.db.ColumnFamily;
0: import org.apache.cassandra.db.CounterColumn;
1: import org.apache.cassandra.db.DecoratedKey;
0: import org.apache.cassandra.db.DeletedColumn;
0: import org.apache.cassandra.db.DeletionInfo;
0: import org.apache.cassandra.db.DeletionTime;
0: import org.apache.cassandra.db.ExpiringColumn;
0: import org.apache.cassandra.db.IColumn;
0: import org.apache.cassandra.db.OnDiskAtom;
0: import org.apache.cassandra.db.RangeTombstone;
0: import org.apache.cassandra.db.SuperColumn;
1: import org.apache.cassandra.io.sstable.Descriptor;
1: import org.apache.cassandra.io.sstable.KeyIterator;
0: import org.apache.cassandra.io.sstable.SSTableIdentityIterator;
0: import org.apache.cassandra.io.sstable.SSTableReader;
0: import org.apache.cassandra.io.sstable.SSTableScanner;
/////////////////////////////////////////////////////////////////////////
0:      * JSON ColumnFamily metadata serializer.</br> Serializes:
0:      * <ul>
0:      * <li>column family deletion info (if present)</li>
0:      * </ul>
1:      *
0:      * @param out
0:      *            The output steam to write data
0:      * @param columnFamily
0:      *            to which the metadata belongs
1:      */
0:     private static void writeMeta(PrintStream out, AbstractColumnContainer columnContainer)
1:     {
0:         if (columnContainer instanceof ColumnFamily)
1:         {
0:             ColumnFamily columnFamily = (ColumnFamily) columnContainer;
0:             if (!columnFamily.deletionInfo().equals(DeletionInfo.LIVE))
1:             {
0:                 // begin meta
0:                 writeKey(out, "metadata");
0:                 writeDeletionInfo(out, columnFamily.deletionInfo().getTopLevelDeletion());
0:                 out.print(",");
1:             }
0:             return;
1:         }
1: 
0:         if (columnContainer instanceof SuperColumn)
1:         {
0:             SuperColumn superColumn = (SuperColumn) columnContainer;
0:             DeletionInfo deletionInfo = new DeletionInfo(superColumn.getMarkedForDeleteAt(),
0:                     superColumn.getLocalDeletionTime());
0:             if (!deletionInfo.equals(DeletionInfo.LIVE))
1:             {
0:                 writeKey(out, "metadata");
0:                 writeDeletionInfo(out, deletionInfo.getTopLevelDeletion());
0:                 out.print(",");
1:             }
0:             return;
1:         }
1:     }
1: 
0:     private static void writeDeletionInfo(PrintStream out, DeletionTime deletionTime)
1:     {
0:         out.print("{");
0:         writeKey(out, "deletionInfo");
0:         // only store topLevelDeletion (serializeForSSTable only uses this)
0:         writeJSON(out, deletionTime);
0:         out.print("}");
1:     }
1: 
1:     /**
/////////////////////////////////////////////////////////////////////////
0:         out.print("{");
0:         writeKey(out, "key");
0:         writeJSON(out, bytesToHex(key.key));
0:         out.print(",");
1: 
0:         writeMeta(out, columnFamily);
1: 
0:         writeKey(out, "columns");
0:                 SuperColumn scol = (SuperColumn)row.next();
0:                 writeMeta(out, scol);
/////////////////////////////////////////////////////////////////////////
0:         out.print("}");
/////////////////////////////////////////////////////////////////////////
0:         outs.println("[");
/////////////////////////////////////////////////////////////////////////
0:         outs.println("\n]");
/////////////////////////////////////////////////////////////////////////
0:         outs.println("[");
/////////////////////////////////////////////////////////////////////////
0:         outs.println("\n]");
author:Dave Brosius
-------------------------------------------------------------------------------
commit:087264f
/////////////////////////////////////////////////////////////////////////
commit:d06fd78
/////////////////////////////////////////////////////////////////////////
0:     static void export(SSTableReader reader, PrintStream outs, String[] excludes) throws IOException
/////////////////////////////////////////////////////////////////////////
0:     public static void export(Descriptor desc, PrintStream outs, String[] excludes) throws IOException
0:         export(SSTableReader.open(desc), outs, excludes);
/////////////////////////////////////////////////////////////////////////
0:     public static void export(Descriptor desc, String[] excludes) throws IOException
0:         export(desc, System.out, excludes);
/////////////////////////////////////////////////////////////////////////
0:                     export(descriptor, excludes);
commit:222ea95
/////////////////////////////////////////////////////////////////////////
commit:93c99a6
/////////////////////////////////////////////////////////////////////////
0:             System.err.println(String.format("The provided table is not part of this cassandra keyspace: keyspace = %s, table = %s",
commit:e704905
commit:089f92b
/////////////////////////////////////////////////////////////////////////
1: 
0:             serializeRow(row, decoratedKey, outs);
commit:bac41da
commit:de2ee6e
/////////////////////////////////////////////////////////////////////////
0:             System.err.println(String.format("The provided column family is not part of this cassandra database: keyspace = %s, column family = %s",
commit:5b0ec50
/////////////////////////////////////////////////////////////////////////
1:     public static void main(String[] args) throws ConfigurationException
author:Chris Lohfink
-------------------------------------------------------------------------------
commit:0e9d6bf
/////////////////////////////////////////////////////////////////////////
0:         EnumSet<MetadataType> types = EnumSet.of(MetadataType.STATS, MetadataType.HEADER);
0:         IPartitioner partitioner = FBUtilities.newPartitioner(desc);
commit:620efdc
/////////////////////////////////////////////////////////////////////////
1:     private static final String RAW_TIMESTAMPS = "t";
/////////////////////////////////////////////////////////////////////////
1: 
1:         Option rawTimestamps = new Option(RAW_TIMESTAMPS, false, "Print raw timestamps instead of iso8601 date strings");
1:         options.addOption(rawTimestamps);
/////////////////////////////////////////////////////////////////////////
0:                 JsonTransformer.keysToJson(null, iterToStream(new KeyIterator(desc, metadata)),
0:                                                               cmd.hasOption(RAW_TIMESTAMPS),
0:                                                               metadata,
0:                                                               System.out);
/////////////////////////////////////////////////////////////////////////
1:                     JsonTransformer.toJson(currentScanner, partitions, cmd.hasOption(RAW_TIMESTAMPS), metadata, System.out);
commit:71b1c4a
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.tools;
1: 
1: import java.io.File;
1: import java.io.IOException;
1: import java.util.*;
1: import java.util.concurrent.atomic.AtomicLong;
1: import java.util.stream.Collectors;
1: import java.util.stream.Stream;
1: import java.util.stream.StreamSupport;
1: 
1: import org.apache.commons.cli.*;
1: 
1: import org.apache.cassandra.config.CFMetaData;
0: import org.apache.cassandra.config.Config;
1: import org.apache.cassandra.cql3.ColumnIdentifier;
0: import org.apache.cassandra.db.DecoratedKey;
1: import org.apache.cassandra.db.PartitionPosition;
1: import org.apache.cassandra.db.SerializationHeader;
1: import org.apache.cassandra.db.marshal.UTF8Type;
1: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
0: import org.apache.cassandra.dht.AbstractBounds;
0: import org.apache.cassandra.dht.Bounds;
0: import org.apache.cassandra.dht.IPartitioner;
1: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.io.sstable.Descriptor;
1: import org.apache.cassandra.io.sstable.ISSTableScanner;
0: import org.apache.cassandra.io.sstable.KeyIterator;
1: import org.apache.cassandra.io.sstable.format.SSTableReader;
1: import org.apache.cassandra.io.sstable.metadata.MetadataComponent;
1: import org.apache.cassandra.io.sstable.metadata.MetadataType;
0: import org.apache.cassandra.io.sstable.metadata.ValidationMetadata;
1: import org.apache.cassandra.utils.FBUtilities;
1: 
1: /**
1:  * Export SSTables to JSON format.
1:  */
1: public class SSTableExport
1: {
1: 
1:     private static final String KEY_OPTION = "k";
1:     private static final String DEBUG_OUTPUT_OPTION = "d";
1:     private static final String EXCLUDE_KEY_OPTION = "x";
1:     private static final String ENUMERATE_KEYS_OPTION = "e";
1: 
1:     private static final Options options = new Options();
1:     private static CommandLine cmd;
1: 
1:     static
1:     {
0:         Config.setClientMode(true);
1: 
0:         Option optKey = new Option(KEY_OPTION, true, "Row key");
1:         // Number of times -k <key> can be passed on the command line.
1:         optKey.setArgs(500);
1:         options.addOption(optKey);
1: 
0:         Option excludeKey = new Option(EXCLUDE_KEY_OPTION, true, "Excluded row key");
1:         // Number of times -x <key> can be passed on the command line.
1:         excludeKey.setArgs(500);
1:         options.addOption(excludeKey);
1: 
0:         Option optEnumerate = new Option(ENUMERATE_KEYS_OPTION, false, "enumerate keys only");
1:         options.addOption(optEnumerate);
1: 
1:         Option debugOutput = new Option(DEBUG_OUTPUT_OPTION, false, "CQL row per line internal representation");
1:         options.addOption(debugOutput);
1:     }
1: 
1:     /**
1:      * Construct table schema from info stored in SSTable's Stats.db
1:      *
1:      * @param desc SSTable's descriptor
1:      * @return Restored CFMetaData
1:      * @throws IOException when Stats.db cannot be read
1:      */
1:     public static CFMetaData metadataFromSSTable(Descriptor desc) throws IOException
1:     {
1:         if (!desc.version.storeRows())
1:             throw new IOException("pre-3.0 SSTable is not supported.");
1: 
0:         EnumSet<MetadataType> types = EnumSet.of(MetadataType.VALIDATION, MetadataType.STATS, MetadataType.HEADER);
1:         Map<MetadataType, MetadataComponent> sstableMetadata = desc.getMetadataSerializer().deserialize(desc, types);
0:         ValidationMetadata validationMetadata = (ValidationMetadata) sstableMetadata.get(MetadataType.VALIDATION);
1:         SerializationHeader.Component header = (SerializationHeader.Component) sstableMetadata.get(MetadataType.HEADER);
1: 
0:         IPartitioner partitioner = FBUtilities.newPartitioner(validationMetadata.partitioner);
1:         CFMetaData.Builder builder = CFMetaData.Builder.create("keyspace", "table").withPartitioner(partitioner);
1:         header.getStaticColumns().entrySet().stream()
1:                 .forEach(entry -> {
1:                     ColumnIdentifier ident = ColumnIdentifier.getInterned(UTF8Type.instance.getString(entry.getKey()), true);
1:                     builder.addStaticColumn(ident, entry.getValue());
1:                 });
1:         header.getRegularColumns().entrySet().stream()
1:                 .forEach(entry -> {
1:                     ColumnIdentifier ident = ColumnIdentifier.getInterned(UTF8Type.instance.getString(entry.getKey()), true);
1:                     builder.addRegularColumn(ident, entry.getValue());
1:                 });
0:         builder.addPartitionKey("PartitionKey", header.getKetType());
1:         for (int i = 0; i < header.getClusteringTypes().size(); i++)
1:         {
1:             builder.addClusteringColumn("clustering" + (i > 0 ? i : ""), header.getClusteringTypes().get(i));
1:         }
1:         return builder.build();
1:     }
1: 
1:     private static <T> Stream<T> iterToStream(Iterator<T> iter)
1:     {
1:         Spliterator<T> splititer = Spliterators.spliteratorUnknownSize(iter, Spliterator.IMMUTABLE);
1:         return StreamSupport.stream(splititer, false);
1:     }
1: 
1:     /**
1:      * Given arguments specifying an SSTable, and optionally an output file, export the contents of the SSTable to JSON.
1:      *
1:      * @param args
1:      *            command lines arguments
1:      * @throws ConfigurationException
1:      *             on configuration failure (wrong params given)
1:      */
0:     public static void main(String[] args) throws ConfigurationException
1:     {
1:         CommandLineParser parser = new PosixParser();
1:         try
1:         {
1:             cmd = parser.parse(options, args);
1:         }
1:         catch (ParseException e1)
1:         {
1:             System.err.println(e1.getMessage());
1:             printUsage();
1:             System.exit(1);
1:         }
1: 
1:         if (cmd.getArgs().length != 1)
1:         {
1:             System.err.println("You must supply exactly one sstable");
1:             printUsage();
1:             System.exit(1);
1:         }
1: 
1:         String[] keys = cmd.getOptionValues(KEY_OPTION);
1:         HashSet<String> excludes = new HashSet<>(Arrays.asList(
1:                 cmd.getOptionValues(EXCLUDE_KEY_OPTION) == null
1:                         ? new String[0]
1:                         : cmd.getOptionValues(EXCLUDE_KEY_OPTION)));
1:         String ssTableFileName = new File(cmd.getArgs()[0]).getAbsolutePath();
1: 
1:         if (Descriptor.isLegacyFile(new File(ssTableFileName)))
1:         {
1:             System.err.println("Unsupported legacy sstable");
1:             System.exit(1);
1:         }
1:         if (!new File(ssTableFileName).exists())
1:         {
1:             System.err.println("Cannot find file " + ssTableFileName);
1:             System.exit(1);
1:         }
1:         Descriptor desc = Descriptor.fromFilename(ssTableFileName);
1:         try
1:         {
1:             CFMetaData metadata = metadataFromSSTable(desc);
1:             if (cmd.hasOption(ENUMERATE_KEYS_OPTION))
1:             {
0:                 JsonTransformer.keysToJson(null, iterToStream(new KeyIterator(desc, metadata)), metadata, System.out);
1:             }
1:             else
1:             {
1:                 SSTableReader sstable = SSTableReader.openNoValidation(desc, metadata);
1:                 IPartitioner partitioner = sstable.getPartitioner();
1:                 final ISSTableScanner currentScanner;
1:                 if ((keys != null) && (keys.length > 0))
1:                 {
1:                     List<AbstractBounds<PartitionPosition>> bounds = Arrays.stream(keys)
1:                             .filter(key -> !excludes.contains(key))
1:                             .map(metadata.getKeyValidator()::fromString)
1:                             .map(partitioner::decorateKey)
1:                             .sorted()
1:                             .map(DecoratedKey::getToken)
1:                             .map(token -> new Bounds<>(token.minKeyBound(), token.maxKeyBound())).collect(Collectors.toList());
1:                     currentScanner = sstable.getScanner(bounds.iterator());
1:                 }
1:                 else
1:                 {
1:                     currentScanner = sstable.getScanner();
1:                 }
1:                 Stream<UnfilteredRowIterator> partitions = iterToStream(currentScanner).filter(i ->
1:                     excludes.isEmpty() || !excludes.contains(metadata.getKeyValidator().getString(i.partitionKey().getKey()))
1:                 );
1:                 if (cmd.hasOption(DEBUG_OUTPUT_OPTION))
1:                 {
1:                     AtomicLong position = new AtomicLong();
1:                     partitions.forEach(partition ->
1:                     {
1:                         position.set(currentScanner.getCurrentPosition());
1:                         partition.forEachRemaining(row ->
1:                         {
1:                             System.out.println(
1:                                     "[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@"
1:                                             + position.get() + " " + row.toString(metadata, false, true));
1:                             position.set(currentScanner.getCurrentPosition());
1:                         });
1:                     });
1:                 }
1:                 else
1:                 {
0:                     JsonTransformer.toJson(currentScanner, partitions, metadata, System.out);
1:                 }
1:             }
1:         }
1:         catch (IOException e)
1:         {
1:             // throwing exception outside main with broken pipe causes windows cmd to hang
1:             e.printStackTrace(System.err);
1:         }
1: 
1:         System.exit(0);
1:     }
1: 
1:     private static void printUsage()
1:     {
1:         String usage = String.format("sstabledump <options> <sstable file path>%n");
1:         String header = "Dump contents of given SSTable to standard output in JSON format.";
1:         new HelpFormatter().printHelp(usage, header, options, "");
1:     }
1: }
author:Jon Haddad
-------------------------------------------------------------------------------
commit:5a77bd1
/////////////////////////////////////////////////////////////////////////
1:         Option optKey = new Option(KEY_OPTION, true, "Partition key");
1:         Option excludeKey = new Option(EXCLUDE_KEY_OPTION, true, "Excluded partition key");
1:         Option optEnumerate = new Option(ENUMERATE_KEYS_OPTION, false, "enumerate partition keys only");
author:Andrew Tolbert
-------------------------------------------------------------------------------
commit:48bdb41
/////////////////////////////////////////////////////////////////////////
0: 
1:                         if (!partition.partitionLevelDeletion().isLive())
0:                         {
1:                             System.out.println("[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@" +
1:                                                position.get() + " " + partition.partitionLevelDeletion());
0:                         }
1:                         if (!partition.staticRow().isEmpty())
0:                         {
1:                             System.out.println("[" + metadata.getKeyValidator().getString(partition.partitionKey().getKey()) + "]@" +
1:                                                position.get() + " " + partition.staticRow().toString(metadata, true));
0:                         }
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:a991b64
/////////////////////////////////////////////////////////////////////////
commit:affb10c
/////////////////////////////////////////////////////////////////////////
0:         System.err.println("WARNING: please note that sstable2json is now deprecated and will be removed in Cassandra 3.0. "
0:                          + "Please see https://issues.apache.org/jira/browse/CASSANDRA-9618 for details.");
0: 
commit:eea547c
commit:f3f69cb
/////////////////////////////////////////////////////////////////////////
0:         try
0:             DecoratedKey lastKey = null;
0:             while (iter.hasNext())
0:             {
0:                 DecoratedKey key = iter.next();
0:                 // validate order of the keys in the sstable
0:                 if (lastKey != null && lastKey.compareTo(key) > 0)
0:                     throw new IOException("Key out of order! " + lastKey + " > " + key);
0:                 lastKey = key;
0:                 outs.println(bytesToHex(key.key));
0:                 checkStream(outs); // flushes
0:             }
0:         finally
0:         {
0:             iter.close();
0:         }
/////////////////////////////////////////////////////////////////////////
0:         try
0:             IPartitioner<?> partitioner = sstable.partitioner;
0:             if (excludes != null)
0:                 toExport.removeAll(Arrays.asList(excludes));
0:             outs.println("[");
0:             int i = 0;
0:             // last key to compare order
0:             DecoratedKey lastKey = null;
0:             for (String key : toExport)
0:             {
0:                 DecoratedKey decoratedKey = partitioner.decorateKey(hexToBytes(key));
0:                 if (lastKey != null && lastKey.compareTo(decoratedKey) > 0)
0:                     throw new IOException("Key out of order! " + lastKey + " > " + decoratedKey);
0:                 lastKey = decoratedKey;
0: 
0:                 RowIndexEntry entry = sstable.getPosition(decoratedKey, SSTableReader.Operator.EQ);
0:                 if (entry == null)
0:                     continue;
0: 
0:                 dfile.seek(entry.position);
0:                 ByteBufferUtil.readWithShortLength(dfile); // row key
0:                 if (sstable.descriptor.version.hasRowSizeAndColumnCount)
0:                     dfile.readLong(); // row size
0:                 DeletionInfo deletionInfo = new DeletionInfo(DeletionTime.serializer.deserialize(dfile));
0:                 int columnCount = sstable.descriptor.version.hasRowSizeAndColumnCount ? dfile.readInt()
0:                         : Integer.MAX_VALUE;
0: 
0:                 Iterator<OnDiskAtom> atomIterator = sstable.metadata.getOnDiskIterator(dfile, columnCount,
0:                         sstable.descriptor.version);
0: 
0:                 checkStream(outs);
0: 
0:                 if (i != 0)
0:                     outs.println(",");
0:                 i++;
0:                 serializeRow(deletionInfo, atomIterator, sstable.metadata, decoratedKey, outs);
0:             }
0: 
0:             outs.println("\n]");
0:             outs.flush();
0:         finally
0:         {
0:             dfile.close();
0:         }
/////////////////////////////////////////////////////////////////////////
0:         try
0:             outs.println("[");
0:             int i = 0;
0:             // collecting keys to export
0:             while (scanner.hasNext())
0:             {
0:                 row = (SSTableIdentityIterator) scanner.next();
0:                 String currentKey = bytesToHex(row.getKey().key);
0:                 if (excludeSet.contains(currentKey))
0:                     continue;
0:                 else if (i != 0)
0:                     outs.println(",");
0: 
0:                 serializeRow(row, row.getKey(), outs);
0:                 checkStream(outs);
0: 
0:                 i++;
0:             }
0: 
0:             outs.println("\n]");
0:             outs.flush();
0:         finally
0:         {
0:             scanner.close();
0:         }
commit:b42feea
/////////////////////////////////////////////////////////////////////////
0:             AbstractType<?> validator = cfMetaData.getValueValidatorFromColumnName(name);
commit:8e172c8
/////////////////////////////////////////////////////////////////////////
0:             Iterator<OnDiskAtom> atomIterator = sstable.metadata.getOnDiskIterator(dfile, sstable.descriptor.version);
commit:e50d6af
/////////////////////////////////////////////////////////////////////////
0:         if (atom instanceof Cell)
0:             return serializeColumn((Cell) atom, cfMetaData);
/////////////////////////////////////////////////////////////////////////
0:      * Serialize a given cell to the JSON format
0:      * @param cell     cell presentation
0:      * @return cell as serialized list
0:     private static List<Object> serializeColumn(Cell cell, CFMetaData cfMetaData)
0:         ByteBuffer value = ByteBufferUtil.clone(cell.value());
0:         serializedColumn.add(comparator.getString(cell.name()));
0:         if (cell instanceof DeletedCell)
0:             AbstractType<?> validator = cfMetaData.getValueValidator(cell.name());
0:         serializedColumn.add(cell.timestamp());
0:         if (cell instanceof DeletedCell)
0:         else if (cell instanceof ExpiringCell)
0:             serializedColumn.add(((ExpiringCell) cell).getTimeToLive());
0:             serializedColumn.add(cell.getLocalDeletionTime());
0:         else if (cell instanceof CounterCell)
0:             serializedColumn.add(((CounterCell) cell).timestampOfLastDelete());
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.composites.CellNameType;
/////////////////////////////////////////////////////////////////////////
0:             return serializeColumn((Column) atom, cfMetaData);
0:             serializedColumn.add(cfMetaData.comparator.getString(rt.min));
0:             serializedColumn.add(cfMetaData.comparator.getString(rt.max));
/////////////////////////////////////////////////////////////////////////
0:     private static List<Object> serializeColumn(Column column, CFMetaData cfMetaData)
0:         CellNameType comparator = cfMetaData.comparator;
0:         serializedColumn.add(comparator.getString(column.name()));
0:             AbstractType<?> validator = cfMetaData.getValueValidator(column.name());
commit:5f5905d
/////////////////////////////////////////////////////////////////////////
0:             AbstractType<?> validator = cfMetaData.getValueValidator(cfMetaData.getColumnDefinitionFromCellName(name));
commit:88f65a1
/////////////////////////////////////////////////////////////////////////
0:         if (!deletionInfo.isLive())
/////////////////////////////////////////////////////////////////////////
0:             DeletionInfo deletionInfo = new DeletionInfo(DeletionTime.serializer.deserialize(dfile));
commit:6e81f81
/////////////////////////////////////////////////////////////////////////
0:             if (!columnFamily.deletionInfo().isLive())
/////////////////////////////////////////////////////////////////////////
0:             if (!deletionInfo.isLive())
commit:bdcf2cf
/////////////////////////////////////////////////////////////////////////
0:             AbstractType<?> validator = cfMetaData.getValueValidator(cfMetaData.getColumnDefinitionFromColumnName(name));
commit:3a005df
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.Column;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeAtoms(Iterator<OnDiskAtom> atoms, PrintStream out, AbstractType<?> comparator, CFMetaData cfMetaData)
0:     {
0:         while (atoms.hasNext())
0:         {
0:             writeJSON(out, serializeAtom(atoms.next(), comparator, cfMetaData));
0: 
0:             if (atoms.hasNext())
0:                 out.print(", ");
0:         }
0:     }
0: 
0:     private static void serializeColumns(Iterator<Column> columns, PrintStream out, AbstractType<?> comparator, CFMetaData cfMetaData)
/////////////////////////////////////////////////////////////////////////
0:     private static List<Object> serializeAtom(OnDiskAtom atom, AbstractType<?> comparator, CFMetaData cfMetaData)
0:         if (atom instanceof Column)
0:             return serializeColumn((Column)atom, comparator, cfMetaData);
0:             assert atom instanceof RangeTombstone;
0:             RangeTombstone rt = (RangeTombstone)atom;
/////////////////////////////////////////////////////////////////////////
0:     private static List<Object> serializeColumn(Column column, AbstractType<?> comparator, CFMetaData cfMetaData)
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         out.print("[");
0:         serializeAtoms(row, out, comparator, cfMetaData);
0:         out.print("]");
commit:3a2faf9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.exceptions.ConfigurationException;
commit:4d34917
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeColumns(Iterator<OnDiskAtom> columns, PrintStream out, AbstractType<?> comparator, CFMetaData cfMetaData)
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeIColumns(Iterator<IColumn> columns, PrintStream out, AbstractType<?> comparator, CFMetaData cfMetaData)
0:     {
0:         while (columns.hasNext())
0:         {
0:             writeJSON(out, serializeColumn(columns.next(), comparator, cfMetaData));
0: 
0:             if (columns.hasNext())
0:                 out.print(", ");
0:         }
0:     }
0: 
0:     private static List<Object> serializeColumn(OnDiskAtom column, AbstractType<?> comparator, CFMetaData cfMetaData)
0:     {
0:         if (column instanceof IColumn)
0:         {
0:             return serializeColumn((IColumn)column, comparator, cfMetaData);
0:         }
0:         else
0:         {
0:             assert column instanceof RangeTombstone;
0:             RangeTombstone rt = (RangeTombstone)column;
0:             ArrayList<Object> serializedColumn = new ArrayList<Object>();
0:             serializedColumn.add(comparator.getString(rt.min));
0:             serializedColumn.add(comparator.getString(rt.max));
0:             serializedColumn.add(rt.data.markedForDeleteAt);
0:             serializedColumn.add("t");
0:             serializedColumn.add(rt.data.localDeletionTime);
0:             return serializedColumn;
0:         }
0:     }
0: 
/////////////////////////////////////////////////////////////////////////
0:                 OnDiskAtom scol = row.next();
0:                 assert scol instanceof IColumn;
0:                 IColumn column = (IColumn)scol;
/////////////////////////////////////////////////////////////////////////
0:                 serializeIColumns(column.getSubColumns().iterator(), out, columnFamily.getSubComparator(), cfMetaData);
commit:07cdfd0
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0: 
commit:2fd3268
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0: 
commit:5a6e2b0
/////////////////////////////////////////////////////////////////////////
0:     private static final ObjectMapper jsonMapper = new ObjectMapper();
0:     private static final Options options = new Options();
commit:07cf56f
/////////////////////////////////////////////////////////////////////////
0: /*
/////////////////////////////////////////////////////////////////////////
commit:4669c40
/////////////////////////////////////////////////////////////////////////
0:         {
0:         }
0:         {
0:             AbstractType validator = cfMetaData.getValueValidator(name);
0:         }
commit:cb5d567
/////////////////////////////////////////////////////////////////////////
0:         {
0:         }
0:         {
0:             AbstractType validator = cfMetaData.getValueValidator(name);
0:         }
commit:84de35d
/////////////////////////////////////////////////////////////////////////
0:         if (column instanceof DeletedColumn)
0:             serializedColumn.add(ByteBufferUtil.bytesToHex(value));
0:         else
0:             serializedColumn.add(validator.getString(value));
commit:bc281a7
/////////////////////////////////////////////////////////////////////////
0:         if (column instanceof DeletedColumn)
0:             serializedColumn.add(ByteBufferUtil.bytesToHex(value));
0:         else
0:             serializedColumn.add(validator.getString(value));
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:7aafe05
/////////////////////////////////////////////////////////////////////////
0:         try (KeyIterator iter = new KeyIterator(desc))
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 
0:         try (RandomAccessReader dfile = sstable.openDataReader())
/////////////////////////////////////////////////////////////////////////
commit:c44cd01
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:3e9d345
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         Schema.instance.loadFromDisk();
commit:0e96e58
/////////////////////////////////////////////////////////////////////////
0:      * @param desc     the descriptor of the sstable to read from
/////////////////////////////////////////////////////////////////////////
0:      * @param desc     the descriptor of the sstable to read from
/////////////////////////////////////////////////////////////////////////
0:      * @param desc     the descriptor of the sstable to read from
/////////////////////////////////////////////////////////////////////////
0:         Keyspace keyspace = Keyspace.open(descriptor.ksname);
/////////////////////////////////////////////////////////////////////////
0:             keyspace.getColumnFamilyStore(baseName);
author:Joshua McKenzie
-------------------------------------------------------------------------------
commit:bee53d7
commit:1fec4a4
/////////////////////////////////////////////////////////////////////////
0:         ISSTableScanner scanner = reader.getScanner();
commit:49768fe
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:ad84e4d
/////////////////////////////////////////////////////////////////////////
0:             IPartitioner partitioner = sstable.partitioner;
author:Jake Luciani
-------------------------------------------------------------------------------
commit:0368e97
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.compaction.ICompactionScanner;
0: import org.apache.cassandra.io.sstable.format.SSTableReader;
/////////////////////////////////////////////////////////////////////////
0:      * Serialize a given cell to a List of Objects that jsonMapper knows how to turn into strings.  Type is
/////////////////////////////////////////////////////////////////////////
0:             excludeSet = new HashSet<>(Arrays.asList(excludes));
0:         ICompactionScanner scanner = reader.getScanner();
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:f95b40c
commit:24d8571
commit:5019182
commit:91d61b3
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         writeJSON(out, metadata.getKeyValidator().getString(key.getKey()));
/////////////////////////////////////////////////////////////////////////
0:      * @param metadata Metadata to print keys in a proper format
0:     public static void enumeratekeys(Descriptor desc, PrintStream outs, CFMetaData metadata)
/////////////////////////////////////////////////////////////////////////
0:             outs.println(metadata.getKeyValidator().getString(key.getKey()));
/////////////////////////////////////////////////////////////////////////
0:      * @param metadata Metadata to print keys in a proper format
0:     public static void export(Descriptor desc, PrintStream outs, Collection<String> toExport, String[] excludes, CFMetaData metadata) throws IOException
/////////////////////////////////////////////////////////////////////////
0:             DecoratedKey decoratedKey = partitioner.decorateKey(metadata.getKeyValidator().fromString(key));
/////////////////////////////////////////////////////////////////////////
0:     static void export(SSTableReader reader, PrintStream outs, String[] excludes, CFMetaData metadata) throws IOException
/////////////////////////////////////////////////////////////////////////
0:             String currentKey = row.getColumnFamily().metadata().getKeyValidator().getString(row.getKey().getKey());
/////////////////////////////////////////////////////////////////////////
0:      * @param metadata Metadata to print keys in a proper format
0:     public static void export(Descriptor desc, PrintStream outs, String[] excludes, CFMetaData metadata) throws IOException
0:         export(SSTableReader.open(desc), outs, excludes, metadata);
/////////////////////////////////////////////////////////////////////////
0:      * @param metadata Metadata to print keys in a proper format
0:     public static void export(Descriptor desc, String[] excludes, CFMetaData metadata) throws IOException
0:         export(desc, System.out, excludes, metadata);
/////////////////////////////////////////////////////////////////////////
0:         // Make it works for indexes too - find parent cf if necessary
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamilyStore cfStore = null;
0:             cfStore = keyspace.getColumnFamilyStore(baseName);
/////////////////////////////////////////////////////////////////////////
0:                 enumeratekeys(descriptor, System.out, cfStore.metadata);
0:                     export(descriptor, System.out, Arrays.asList(keys), excludes, cfStore.metadata);
0:                     export(descriptor, excludes, cfStore.metadata);
commit:647bfc6
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:      * Serialize a given cell to a List of Objects that jsonMapper knows how to turn into strings.  Format is
0:      *
0:      * human_readable_name, value, timestamp, [flag, [options]]
0:      *
0:      * Value is normally the human readable value as rendered by the validator, but for deleted cells we
0:      * give the local deletion time instead.
0:      *
0:      * Flag may be exactly one of {d,e,c} for deleted, expiring, or counter:
0:      *  - No options for deleted cells
0:      *  - If expiring, options will include the TTL and local deletion time.
0:      *  - If counter, options will include timestamp of last delete
/////////////////////////////////////////////////////////////////////////
0: 
0:             serializedColumn.add(cell.getLocalDeletionTime());
0:             serializedColumn.add(validator.getString(cell.value()));
0: 
/////////////////////////////////////////////////////////////////////////
0:         out.print(",\n");
0:         if (!deletionInfo.isLive())
0:         {
0:             out.print(" ");
0:             writeKey(out, "metadata");
0:             out.print("{");
0:             writeKey(out, "deletionInfo");
0:             writeJSON(out, deletionInfo.getTopLevelDeletion());
0:             out.print("}");
0:             out.print(",\n");
0:         }
0:         out.print(" ");
0:         writeKey(out, "cells");
0:         while (atoms.hasNext())
0:         {
0:             writeJSON(out, serializeAtom(atoms.next(), metadata));
0:             if (atoms.hasNext())
0:                 out.print(",\n           ");
0:         }
0: 
commit:81619fe
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
0: import org.apache.commons.cli.*;
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.io.sstable.*;
0: import static org.apache.cassandra.utils.ByteBufferUtil.bytesToHex;
0: import static org.apache.cassandra.utils.ByteBufferUtil.hexToBytes;
0: 
commit:a684ee0
commit:07c627a
/////////////////////////////////////////////////////////////////////////
0: 
0:         // Start by validating keyspace name
0:         if (Schema.instance.getKSMetaData(descriptor.ksname) == null)
0:             System.err.println(String.format("Filename %s references to nonexistent keyspace: %s!",
0:                                              ssTableFileName, descriptor.ksname));
0:             System.exit(1);
0:         }
0:         Table table = Table.open(descriptor.ksname);
0: 
0:         // Make it work for indexes too - find parent cf if necessary
0:         String baseName = descriptor.cfname;
0:         if (descriptor.cfname.contains("."))
0:         {
0:             String[] parts = descriptor.cfname.split("\\.", 2);
0:             baseName = parts[0];
0:         }
0: 
0:         // IllegalArgumentException will be thrown here if ks/cf pair does not exist
0:         try
0:         {
0:             table.getColumnFamilyStore(baseName);
0:         }
0:         catch (IllegalArgumentException e)
0:         {
0:             System.err.println(String.format("The provided column family is not part of this cassandra keyspace: keyspace = %s, column family = %s",
commit:a9bd531
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.RandomAccessReader;
/////////////////////////////////////////////////////////////////////////
0:      * @param deletionInfo
0:     private static void writeMeta(PrintStream out, DeletionInfo deletionInfo)
0:         if (!deletionInfo.equals(DeletionInfo.LIVE))
0:             writeDeletionInfo(out, deletionInfo.getTopLevelDeletion());
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeAtoms(Iterator<OnDiskAtom> atoms, PrintStream out, CFMetaData cfMetaData)
0:             writeJSON(out, serializeAtom(atoms.next(), cfMetaData));
0:     private static List<Object> serializeAtom(OnDiskAtom atom, CFMetaData cfMetaData)
0:         AbstractType<?> comparator = cfMetaData.comparator;
/////////////////////////////////////////////////////////////////////////
0:         serializeRow(row.getColumnFamily().deletionInfo(), row, row.getColumnFamily().metadata(), key, out);
0:     }
0:     private static void serializeRow(DeletionInfo deletionInfo, Iterator<OnDiskAtom> atoms, CFMetaData metadata, DecoratedKey key, PrintStream out)
0:     {
0:         writeMeta(out, deletionInfo);
0:         serializeAtoms(atoms, out, metadata);
/////////////////////////////////////////////////////////////////////////
0:         SSTableReader sstable = SSTableReader.open(desc);
0:         RandomAccessReader dfile = sstable.openDataReader();
0:         IPartitioner<?> partitioner = sstable.partitioner;
/////////////////////////////////////////////////////////////////////////
0:             RowIndexEntry entry = sstable.getPosition(decoratedKey, SSTableReader.Operator.EQ);
0:             if (entry == null)
0:             dfile.seek(entry.position);
0:             ByteBufferUtil.readWithShortLength(dfile); // row key
0:             if (sstable.descriptor.version.hasRowSizeAndColumnCount)
0:                 dfile.readLong(); // row size
0:             DeletionInfo deletionInfo = DeletionInfo.serializer().deserializeFromSSTable(dfile, sstable.descriptor.version);
0:             int columnCount = sstable.descriptor.version.hasRowSizeAndColumnCount ? dfile.readInt() : Integer.MAX_VALUE;
0:             Iterator<OnDiskAtom> atomIterator = sstable.metadata.getOnDiskIterator(dfile, columnCount, sstable.descriptor.version);
0: 
0:             serializeRow(deletionInfo, atomIterator, sstable.metadata, decoratedKey, outs);
/////////////////////////////////////////////////////////////////////////
commit:976c388
/////////////////////////////////////////////////////////////////////////
commit:b6be683
/////////////////////////////////////////////////////////////////////////
0:      * Checks if PrintStream error and throw exception
0:      *
0:      * @param out The PrintStream to be check
0:      */
0:     private static void checkStream(PrintStream out) throws IOException
0:     {
0:         if (out.checkError())
0:             throw new IOException("Error writing output stream");
0:     }
0: 
0:     /**
0:      * @param out   The output steam to write data
/////////////////////////////////////////////////////////////////////////
0:      * @param out The output steam to write data
0:      * @param cf  to which the metadata belongs
/////////////////////////////////////////////////////////////////////////
0:      * @param atoms      column iterator
0:      * @param out        output stream
/////////////////////////////////////////////////////////////////////////
0:             return serializeColumn((Column) atom, comparator, cfMetaData);
0:             RangeTombstone rt = (RangeTombstone) atom;
/////////////////////////////////////////////////////////////////////////
0:      * @param column     column presentation
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:             if (lastKey != null && lastKey.compareTo(key) > 0)
0:             checkStream(outs); // flushes
0:      * @param desc     the descriptor of the sstable table to read from
0:      * @param outs     PrintStream to write the output to
/////////////////////////////////////////////////////////////////////////
0:             checkStream(outs);
/////////////////////////////////////////////////////////////////////////
0:             checkStream(outs);
/////////////////////////////////////////////////////////////////////////
0:      * @param desc     the descriptor of the sstable table to read from
0:      * @param outs     PrintStream to write the output to
/////////////////////////////////////////////////////////////////////////
0:      * @param desc     the descriptor of the sstable table to read from
/////////////////////////////////////////////////////////////////////////
0:      * @throws IOException            on failure to open/read/write files or output streams
/////////////////////////////////////////////////////////////////////////
0:         try
0:             if (cmd.hasOption(ENUMERATEKEYS_OPTION))
0:             {
0:                 enumeratekeys(descriptor, System.out);
0:             }
0:             {
0:                 if ((keys != null) && (keys.length > 0))
0:                     export(descriptor, System.out, Arrays.asList(keys), excludes);
0:                 else
0:                     export(descriptor, excludes);
0:             }
0:         }
0:         catch (IOException e)
0:         {
0:             // throwing exception outside main with broken pipe causes windows cmd to hang
0:             e.printStackTrace(System.err);
commit:74f37b5
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
0: import org.apache.commons.cli.*;
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.exceptions.ConfigurationException;
0: import org.apache.cassandra.io.sstable.*;
0: import static org.apache.cassandra.utils.ByteBufferUtil.bytesToHex;
0: import static org.apache.cassandra.utils.ByteBufferUtil.hexToBytes;
0: 
/////////////////////////////////////////////////////////////////////////
0:      * @param atoms column iterator
commit:2b0797b
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.util.concurrent.RateLimiter;
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(null);
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(null);
commit:255db50
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:      * @param cf
0:     private static void writeMeta(PrintStream out, ColumnFamily cf)
0:         if (!cf.deletionInfo().equals(DeletionInfo.LIVE))
0:             // begin meta
0:             writeKey(out, "metadata");
0:             writeDeletionInfo(out, cf.deletionInfo().getTopLevelDeletion());
0:             out.print(",");
commit:01bc564
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner();
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner();
commit:d41d5f6
/////////////////////////////////////////////////////////////////////////
commit:681e2de
commit:98dc413
/////////////////////////////////////////////////////////////////////////
0:      * @param desc the descriptor of the file to export the rows from
0:     public static void enumeratekeys(Descriptor desc, PrintStream outs)
/////////////////////////////////////////////////////////////////////////
0:      * @param desc the descriptor of the sstable table to read from
0:     public static void export(Descriptor desc, PrintStream outs, Collection<String> toExport, String[] excludes) throws IOException
0:         SSTableReader reader = SSTableReader.open(desc);
/////////////////////////////////////////////////////////////////////////
0:      * @param desc the descriptor of the sstable table to read from
0:     public static void export(Descriptor desc, PrintStream outs, String[] excludes) throws IOException
0:         export(SSTableReader.open(desc), outs, excludes);
0:      * @param desc the descriptor of the sstable table to read from
0:     public static void export(Descriptor desc, String[] excludes) throws IOException
0:         export(desc, System.out, excludes);
/////////////////////////////////////////////////////////////////////////
0:         Descriptor descriptor = Descriptor.fromFilename(ssTableFileName);
0:         if (Schema.instance.getCFMetaData(descriptor) == null)
0:         {
0:             System.err.println(String.format("The provided column family is not part of this cassandra database: keysapce = %s, column family = %s",
0:                                              descriptor.ksname, descriptor.cfname));
0:             System.exit(1);
0:         }
0:             enumeratekeys(descriptor, System.out);
0:                 export(descriptor, System.out, Arrays.asList(keys), excludes);
0:                 export(descriptor, excludes);
commit:4169620
commit:492d44e
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner<?> partitioner = reader.partitioner;
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:         export(SSTableReader.open(Descriptor.fromFilename(ssTableFile)), outs, excludes);
commit:2bc0d4d
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeColumns(Iterator<IColumn> columns, PrintStream out, AbstractType<?> comparator, CFMetaData cfMetaData)
/////////////////////////////////////////////////////////////////////////
0:     private static List<Object> serializeColumn(IColumn column, AbstractType<?> comparator, CFMetaData cfMetaData)
/////////////////////////////////////////////////////////////////////////
0:             AbstractType<?> validator = cfMetaData.getValueValidator(name);
/////////////////////////////////////////////////////////////////////////
0:         AbstractType<?> comparator = columnFamily.getComparator();
commit:a4b1e10
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner();
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner();
commit:b6e29b4
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.index.keys.KeysIndex;
/////////////////////////////////////////////////////////////////////////
0:             CFMetaData parent = Schema.instance.getCFMetaData(descriptor.ksname, parentName);
0:             metadata = CFMetaData.newIndexMetadata(parent, def, KeysIndex.indexComparator());
0:             metadata = Schema.instance.getCFMetaData(descriptor.ksname, descriptor.cfname);
commit:91b5dd0
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.ColumnDefinition;
/////////////////////////////////////////////////////////////////////////
0:         Descriptor descriptor = Descriptor.fromFilename(ssTableFile);
0:         CFMetaData metadata;
0:         if (descriptor.cfname.contains("."))
0:         {
0:             // look up index metadata from parent
0:             int i = descriptor.cfname.indexOf(".");
0:             String parentName = descriptor.cfname.substring(0, i);
0:             CFMetaData parent = DatabaseDescriptor.getCFMetaData(descriptor.ksname, parentName);
0:             ColumnDefinition def = parent.getColumnDefinitionForIndex(descriptor.cfname.substring(i + 1));
0:             metadata = CFMetaData.newIndexMetadata(parent, def, ColumnFamilyStore.indexComparator());
0:         }
0:         else
0:         {
0:             metadata = DatabaseDescriptor.getCFMetaData(descriptor.ksname, descriptor.cfname);
0:         }
0: 
0:         export(SSTableReader.open(descriptor, metadata), outs, excludes);
commit:d389047
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.RandomAccessReader;
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(RandomAccessReader.DEFAULT_BUFFER_SIZE);
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(RandomAccessReader.DEFAULT_BUFFER_SIZE);
commit:f491265
commit:6772d1a
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: package org.apache.cassandra.tools;
0: 
0: import java.io.File;
0: import java.io.IOException;
0: import java.io.PrintStream;
0: import java.nio.ByteBuffer;
0: import java.util.*;
0: 
0: import org.apache.cassandra.config.CFMetaData;
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.db.marshal.AbstractType;
0: import org.apache.cassandra.io.util.BufferedRandomAccessFile;
0: import org.apache.cassandra.service.StorageService;
0: 
0: import org.apache.commons.cli.*;
0: 
0: import org.apache.cassandra.config.ConfigurationException;
0: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.dht.IPartitioner;
0: import org.apache.cassandra.io.sstable.*;
0: import org.apache.cassandra.utils.ByteBufferUtil;
0: import org.apache.cassandra.utils.Pair;
0: 
0: import static org.apache.cassandra.utils.ByteBufferUtil.bytesToHex;
0: import static org.apache.cassandra.utils.ByteBufferUtil.hexToBytes;
0: 
0: /**
0:  * Export SSTables to JSON format.
0:  */
0: public class SSTableExport
0: {
0:     // size of the columns page
0:     private static final int PAGE_SIZE = 1000;
0: 
0:     private static final String KEY_OPTION = "k";
0:     private static final String EXCLUDEKEY_OPTION = "x";
0:     private static final String ENUMERATEKEYS_OPTION = "e";
0:     private static Options options;
0:     private static CommandLine cmd;
0:     
0:     static
0:     {
0:         options = new Options();
0: 
0:         Option optKey = new Option(KEY_OPTION, true, "Row key");
0:         // Number of times -k <key> can be passed on the command line.
0:         optKey.setArgs(500);
0:         options.addOption(optKey);
0: 
0:         Option excludeKey = new Option(EXCLUDEKEY_OPTION, true, "Excluded row key");
0:         // Number of times -x <key> can be passed on the command line.
0:         excludeKey.setArgs(500);
0:         options.addOption(excludeKey);
0: 
0:         Option optEnumerate = new Option(ENUMERATEKEYS_OPTION, false, "enumerate keys only");
0:         options.addOption(optEnumerate);
0:     }
0: 
0:     /**
0:      * Wraps given string into quotes
0:      * @param val string to quote
0:      * @return quoted string
0:      */
0:     private static String quote(String val)
0:     {
0:         return String.format("\"%s\"", val);
0:     }
0: 
0:     /**
0:      * JSON Hash Key serializer
0:      * @param val value to set as a key
0:      * @return JSON Hash key
0:      */
0:     private static String asKey(String val)
0:     {
0:         return String.format("%s: ", quote(val));
0:     }
0: 
0:     /**
0:      * Serialize columns using given column iterator
0:      * @param columns column iterator
0:      * @param out output stream
0:      * @param comparator columns comparator
0:      * @param cfMetaData Column Family metadata (to get validator)
0:      * @return pair of (number of columns serialized, last column serialized)
0:      */
0:     private static void serializeColumns(Iterator<IColumn> columns, PrintStream out, AbstractType comparator, CFMetaData cfMetaData)
0:     {
0:         while (columns.hasNext())
0:         {
0:             IColumn column = columns.next();
0:             serializeColumn(column, out, comparator, cfMetaData);
0: 
0:             if (columns.hasNext())
0:                 out.print(", ");
0:         }
0:     }
0: 
0:     /**
0:      * Serialize a given column to the JSON format
0:      * @param column column presentation
0:      * @param out output stream
0:      * @param comparator columns comparator
0:      * @param cfMetaData Column Family metadata (to get validator)
0:      */
0:     private static void serializeColumn(IColumn column, PrintStream out, AbstractType comparator, CFMetaData cfMetaData)
0:     {
0:         ByteBuffer name = ByteBufferUtil.clone(column.name());
0:         ByteBuffer value = ByteBufferUtil.clone(column.value());
0:         AbstractType validator = cfMetaData.getValueValidator(name);
0: 
0:         out.print("[");
0:         out.print(quote(comparator.getString(name)));
0:         out.print(", ");
0:         out.print(quote(validator.getString(value)));
0:         out.print(", ");
0:         out.print(column.timestamp());
0: 
0:         if (column instanceof DeletedColumn)
0:         {
0:             out.print(", ");
0:             out.print("\"d\"");
0:         }
0:         else if (column instanceof ExpiringColumn)
0:         {
0:             out.print(", ");
0:             out.print("\"e\"");
0:             out.print(", ");
0:             out.print(((ExpiringColumn) column).getTimeToLive());
0:             out.print(", ");
0:             out.print(column.getLocalDeletionTime());
0:         }
0:         else if (column instanceof CounterColumn)
0:         {
0:             out.print(", ");
0:             out.print("\"c\"");
0:             out.print(", ");
0:             out.print(((CounterColumn) column).timestampOfLastDelete());
0:         }
0: 
0:         out.print("]");
0:     }
0: 
0:     /**
0:      * Get portion of the columns and serialize in loop while not more columns left in the row
0:      * @param row SSTableIdentityIterator row representation with Column Family
0:      * @param key Decorated Key for the required row
0:      * @param out output stream
0:      */
0:     private static void serializeRow(SSTableIdentityIterator row, DecoratedKey key, PrintStream out)
0:     {
0:         ColumnFamily columnFamily = row.getColumnFamily();
0:         boolean isSuperCF = columnFamily.isSuper();
0:         CFMetaData cfMetaData = columnFamily.metadata();
0:         AbstractType comparator = columnFamily.getComparator();
0: 
0:         out.print(asKey(bytesToHex(key.key)));
0:         out.print(isSuperCF ? "{" : "[");
0: 
0:         if (isSuperCF)
0:         {
0:             while (row.hasNext())
0:             {
0:                 IColumn column = row.next();
0: 
0:                 out.print(asKey(comparator.getString(column.name())));
0:                 out.print("{");
0:                 out.print(asKey("deletedAt"));
0:                 out.print(column.getMarkedForDeleteAt());
0:                 out.print(", ");
0:                 out.print(asKey("subColumns"));
0:                 out.print("[");
0:                 serializeColumns(column.getSubColumns().iterator(), out, columnFamily.getSubComparator(), cfMetaData);
0:                 out.print("]");
0:                 out.print("}");
0: 
0:                 if (row.hasNext())
0:                     out.print(", ");
0:             }
0:         }
0:         else
0:         {
0:             serializeColumns(row, out, comparator, cfMetaData);
0:         }
0: 
0:         out.print(isSuperCF ? "}" : "]");
0:     }
0: 
0:     /**
0:      * Enumerate row keys from an SSTableReader and write the result to a PrintStream.
0:      * 
0:      * @param ssTableFile the file to export the rows from
0:      * @param outs PrintStream to write the output to
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void enumeratekeys(String ssTableFile, PrintStream outs)
0:     throws IOException
0:     {
0:         Descriptor desc = Descriptor.fromFilename(ssTableFile);
0:         KeyIterator iter = new KeyIterator(desc);
0:         DecoratedKey lastKey = null;
0:         while (iter.hasNext())
0:         {
0:             DecoratedKey key = iter.next();
0: 
0:             // validate order of the keys in the sstable
0:             if (lastKey != null && lastKey.compareTo(key) > 0 )
0:                 throw new IOException("Key out of order! " + lastKey + " > " + key);
0:             lastKey = key;
0: 
0:             outs.println(bytesToHex(key.key));
0:         }
0:         iter.close();
0:         outs.flush();
0:     }
0: 
0:     /**
0:      * Export specific rows from an SSTable and write the resulting JSON to a PrintStream.
0:      * 
0:      * @param ssTableFile the SSTableScanner to export the rows from
0:      * @param outs PrintStream to write the output to
0:      * @param toExport the keys corresponding to the rows to export
0:      * @param excludes keys to exclude from export
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, PrintStream outs, Collection<String> toExport, String[] excludes) throws IOException
0:     {
0:         SSTableReader reader = SSTableReader.open(Descriptor.fromFilename(ssTableFile));
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0: 
0:         IPartitioner<?> partitioner = StorageService.getPartitioner();
0: 
0:         if (excludes != null)
0:             toExport.removeAll(Arrays.asList(excludes));
0: 
0:         outs.println("{");
0: 
0:         int i = 0;
0: 
0:         // last key to compare order
0:         DecoratedKey lastKey = null;
0: 
0:         for (String key : toExport)
0:         {
0:             DecoratedKey decoratedKey = partitioner.decorateKey(hexToBytes(key));
0: 
0:             if (lastKey != null && lastKey.compareTo(decoratedKey) > 0)
0:                 throw new IOException("Key out of order! " + lastKey + " > " + decoratedKey);
0: 
0:             lastKey = decoratedKey;
0: 
0:             scanner.seekTo(decoratedKey);
0: 
0:             if (!scanner.hasNext())
0:                 continue;
0: 
0:             SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
0:             if (!row.getKey().equals(decoratedKey))
0:                 continue;
0: 
0:             serializeRow(row, decoratedKey, outs);
0: 
0:             if (i != 0)
0:                 outs.println(",");
0: 
0:             i++;
0:         }
0: 
0:         outs.println("\n}");
0:         outs.flush();
0: 
0:         scanner.close();
0:     }
0: 
0:     // This is necessary to accommodate the test suite since you cannot open a Reader more
0:     // than once from within the same process.
0:     static void export(SSTableReader reader, PrintStream outs, String[] excludes) throws IOException
0:     {
0:         Set<String> excludeSet = new HashSet<String>();
0: 
0:         if (excludes != null)
0:             excludeSet = new HashSet<String>(Arrays.asList(excludes));
0: 
0: 
0:         SSTableIdentityIterator row;
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0: 
0:         outs.println("{");
0: 
0:         int i = 0;
0: 
0:         // collecting keys to export
0:         while (scanner.hasNext())
0:         {
0:             row = (SSTableIdentityIterator) scanner.next();
0: 
0:             String currentKey = bytesToHex(row.getKey().key);
0: 
0:             if (excludeSet.contains(currentKey))
0:                 continue;
0:             else if (i != 0)
0:                 outs.println(",");
0: 
0:             serializeRow(row, row.getKey(), outs);
0: 
0:             i++;
0:         }
0: 
0:         outs.println("\n}");
0:         outs.flush();
0: 
0:         scanner.close();
0:     }
0:     
0:     /**
0:      * Export an SSTable and write the resulting JSON to a PrintStream.
0:      * 
0:      * @param ssTableFile the SSTable to export
0:      * @param outs PrintStream to write the output to
0:      * @param excludes keys to exclude from export
0:      *
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, PrintStream outs, String[] excludes) throws IOException
0:     {
0:         export(SSTableReader.open(Descriptor.fromFilename(ssTableFile)), outs, excludes);
0:     }
0: 
0:     /**
0:      * Export an SSTable and write the resulting JSON to standard out.
0:      * 
0:      * @param ssTableFile SSTable to export
0:      * @param excludes keys to exclude from export
0:      *
0:      * @throws IOException on failure to read/write SSTable/standard out
0:      */
0:     public static void export(String ssTableFile, String[] excludes) throws IOException
0:     {
0:         export(ssTableFile, System.out, excludes);
0:     }
0: 
0:     /**
0:      * Given arguments specifying an SSTable, and optionally an output file,
0:      * export the contents of the SSTable to JSON.
0:      *  
0:      * @param args command lines arguments
0:      *
0:      * @throws IOException on failure to open/read/write files or output streams
0:      * @throws ConfigurationException on configuration failure (wrong params given)
0:      */
0:     public static void main(String[] args) throws IOException, ConfigurationException
0:     {
0:         String usage = String.format("Usage: %s <sstable> [-k key [-k key [...]] -x key [-x key [...]]]%n", SSTableExport.class.getName());
0:         
0:         CommandLineParser parser = new PosixParser();
0:         try
0:         {
0:             cmd = parser.parse(options, args);
0:         }
0:         catch (ParseException e1)
0:         {
0:             System.err.println(e1.getMessage());
0:             System.err.println(usage);
0:             System.exit(1);
0:         }
0: 
0: 
0:         if (cmd.getArgs().length != 1)
0:         {
0:             System.err.println("You must supply exactly one sstable");
0:             System.err.println(usage);
0:             System.exit(1);
0:         }
0:         
0: 
0:         String[] keys = cmd.getOptionValues(KEY_OPTION);
0:         String[] excludes = cmd.getOptionValues(EXCLUDEKEY_OPTION);
0:         String ssTableFileName = new File(cmd.getArgs()[0]).getAbsolutePath();
0: 
0:         DatabaseDescriptor.loadSchemas();
0:         if (DatabaseDescriptor.getNonSystemTables().size() < 1)
0:         {
0:             String msg = "no non-system tables are defined";
0:             System.err.println(msg);
0:             throw new ConfigurationException(msg);
0:         }
0: 
0:         if (cmd.hasOption(ENUMERATEKEYS_OPTION))
0:         {
0:             enumeratekeys(ssTableFileName, System.out);
0:         }
0:         else
0:         {
0:             if ((keys != null) && (keys.length > 0))
0:                 export(ssTableFileName, System.out, Arrays.asList(keys), excludes);
0:             else
0:                 export(ssTableFileName, excludes);
0:         }
0: 
0:         System.exit(0);
0:     }
0: }
commit:04bb3e4
commit:c49a01b
commit:139203d
commit:34a3c9d
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeColumns(Iterator<IColumn> columns, PrintStream out)
0:             IColumn column = columns.next();
commit:b381717
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeRow(SSTableIdentityIterator row, DecoratedKey key, PrintStream out)
0:         if (isSuperCF)
0:             while (row.hasNext())
0:                 IColumn column = row.next();
/////////////////////////////////////////////////////////////////////////
0:                 serializeColumns(column.getSubColumns().iterator(), out);
0:                 if (row.hasNext())
0:             serializeColumns(row, out);
0: 
0:         out.print(isSuperCF ? "}" : "]");
/////////////////////////////////////////////////////////////////////////
0:             serializeRow(row, decoratedKey, outs);
/////////////////////////////////////////////////////////////////////////
0:             serializeRow(row, row.getKey(), outs);
commit:1a5d09c
commit:c7df15d
/////////////////////////////////////////////////////////////////////////
0: import java.io.IOError;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.utils.Pair;
/////////////////////////////////////////////////////////////////////////
0:      * @return pair of (number of columns serialized, last column serialized)
0:     private static Pair<Integer, ByteBuffer> serializeColumns(Iterator<IColumn> columns, PrintStream out)
0:         int n = 0;
0:         IColumn column = null;
0:             column = columns.next();
0:             n++;
0:             serializeColumn(column, out);
0: 
0:         return new Pair<Integer, ByteBuffer>(n, column == null ? null : column.name());
/////////////////////////////////////////////////////////////////////////
0:             Pair<Integer, ByteBuffer> serialized;
0:                 serialized = serializeRow(columns, isSuperCF, out);
0:                 continue;
0:             }
0:             finally
0:             {
0:                 try
0:                 {
0:                     columns.close();
0:                 }
0:                 catch (IOException e)
0:                 {
0:                     throw new IOError(e);
0:                 }
0:             if (serialized.left < PAGE_SIZE)
/////////////////////////////////////////////////////////////////////////
0:      * @return pair of (number of columns serialized, last column serialized)
0:     private static Pair<Integer, ByteBuffer> serializeRow(IColumnIterator columns, boolean isSuper, PrintStream out) throws IOException
0:             int n = 0;
0:             IColumn column = null;
0:                 column = columns.next();
0:                 n++;
/////////////////////////////////////////////////////////////////////////
0: 
0:             return new Pair<Integer, ByteBuffer>(n, column == null ? null : column.name());
0:             return serializeColumns(columns, out);
commit:f516cc8
/////////////////////////////////////////////////////////////////////////
0:         if (excludes != null)
0:             toExport.removeAll(Arrays.asList(excludes));
/////////////////////////////////////////////////////////////////////////
0:             SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
0:             if (!row.getKey().equals(decoratedKey))
0:                 continue;
0: 
0:             serializeRow(reader, row, decoratedKey, outs);
commit:7364c09
/////////////////////////////////////////////////////////////////////////
0:         if (column instanceof DeletedColumn)
0:             out.print("\"d\"");
0:         }
0:         else if (column instanceof ExpiringColumn)
0:         {
0:             out.print(", ");
0:             out.print("\"e\"");
0:             out.print(", ");
0:         else if (column instanceof CounterColumn)
0:         {
0:             out.print(", ");
0:             out.print("\"c\"");
0:             out.print(", ");
0:             out.print(((CounterColumn) column).timestampOfLastDelete());
0:         }
commit:b9495d8
/////////////////////////////////////////////////////////////////////////
0: 
0:             out.print(",");
commit:f3a286d
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0:                     continue;
0:                     continue;
0: 
0:                 if (i != 1)
0:                     outs.println(",");
/////////////////////////////////////////////////////////////////////////
0:                 elementWritten = false;
0:                 elementWritten = false;
commit:d19c9e9
/////////////////////////////////////////////////////////////////////////
0: 
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0:                 if (i != 1)
0:                     outs.println(",");
/////////////////////////////////////////////////////////////////////////
0:                 elementWritten = false;
0:                 elementWritten = false;
commit:6350c16
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.cassandra.utils.ByteBufferUtil.bytesToHex;
0: import static org.apache.cassandra.utils.ByteBufferUtil.hexToBytes;
/////////////////////////////////////////////////////////////////////////
0:             DecoratedKey<?> dk = partitioner.decorateKey(hexToBytes(key));
commit:3991fba
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(INPUT_FILE_BUFFER_SIZE);
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(INPUT_FILE_BUFFER_SIZE);
commit:ef25537
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.IColumn;
commit:24246c2
/////////////////////////////////////////////////////////////////////////
0:         DecoratedKey lastKey = null;
0: 
0:             // validate order of the keys in the sstable
0:             if (lastKey != null && lastKey.compareTo(key) > 0 )
0:                 throw new IOException("Key out of order! " + lastKey + " > " + key);
0:             lastKey = key;
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0:         // last key to compare order 
0:         DecoratedKey lastKey = null;
0: 
0:             // validate order of the keys in the sstable
0:             if (lastKey != null && lastKey.compareTo(dk) > 0 )
0:                 throw new IOException("Key out of order! " + lastKey + " > " + dk);
0:             lastKey = dk;
0: 
commit:33add1f
/////////////////////////////////////////////////////////////////////////
0:             if (column instanceof ExpiringColumn)
0:             {
0:                 outs.print(", ");
0:                 outs.print(((ExpiringColumn) column).getTimeToLive());
0:                 outs.print(", ");
0:                 outs.print(column.getLocalDeletionTime());
/////////////////////////////////////////////////////////////////////////
0:         }
0:         catch (ParseException e1)
0: 
/////////////////////////////////////////////////////////////////////////
0:         {
0:         }
0:         else
0:         {
0: 
commit:fb2ce87
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeColumns(PrintStream outs, Collection<IColumn> cols, AbstractType comp)
0:         outs.print("[");
0: 
0:             outs.print("[");
0:             outs.print(quote(bytesToHex(column.name())));
0:             outs.print(", ");
0:             outs.print(quote(bytesToHex(column.value())));
0:             outs.print(", ");
0:             outs.print(column.timestamp());
0:             outs.print(", ");
0:             outs.print(column.isMarkedForDelete());
0:               outs.print(", ");
0:               outs.print(((ExpiringColumn)column).getTimeToLive());
0:               outs.print(", ");
0:               outs.print(column.getLocalDeletionTime());
0:             outs.print("]");
0:                 outs.print(", ");
0:         outs.print("]");
0:     private static void serializeRow(PrintStream outs, SSTableIdentityIterator row) throws IOException
0:         outs.print(asKey(bytesToHex(row.getKey().key)));
0: 
0:             outs.print("{ ");
0:                 outs.print(asKey(bytesToHex(column.name())));
0:                 outs.print("{");
0:                 outs.print(asKey("deletedAt"));
0:                 outs.print(column.getMarkedForDeleteAt());
0:                 outs.print(", ");
0:                 outs.print(asKey("subColumns"));
0:                 serializeColumns(outs, column.getSubColumns(), comparator);
0:                 outs.print("}");
0:                     outs.print(", ");
0:             outs.print("}");
0:             serializeColumns(outs, cf.getSortedColumns(), comparator);
/////////////////////////////////////////////////////////////////////////
0:                     serializeRow(outs, row);
/////////////////////////////////////////////////////////////////////////
0:                 serializeRow(outs, row);
0:                 outs.print("  ");
commit:19dd60b
/////////////////////////////////////////////////////////////////////////
0:               json.append(column.getLocalDeletionTime());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         Set<String> excludeSet = new HashSet<String>();
/////////////////////////////////////////////////////////////////////////
0: 
0:         Set<String> excludeSet = new HashSet<String>();
/////////////////////////////////////////////////////////////////////////
0: 
commit:a44a150
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.ExpiringColumn;
/////////////////////////////////////////////////////////////////////////
0:             if (column instanceof ExpiringColumn) {
0:               json.append(", ");
0:               json.append(((ExpiringColumn)column).getTimeToLive());
0:               json.append(", ");
0:               json.append(((ExpiringColumn)column).getLocalDeletionTime());
0:             }
commit:e7a385a
/////////////////////////////////////////////////////////////////////////
0: import java.nio.ByteBuffer;
/////////////////////////////////////////////////////////////////////////
0:             DecoratedKey<?> dk = partitioner.decorateKey(ByteBuffer.wrap(hexToBytes(key)));
commit:9d32382
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             json.append(column.timestamp());
/////////////////////////////////////////////////////////////////////////
0:                 json.append(column.getMarkedForDeleteAt());
commit:4c530a1
/////////////////////////////////////////////////////////////////////////
0: import org.apache.commons.cli.*;
0: 
0: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.io.sstable.*;
/////////////////////////////////////////////////////////////////////////
0:         KeyIterator iter = new KeyIterator(desc);
0:         while (iter.hasNext())
0:             DecoratedKey key = iter.next();
0:             outs.println(bytesToHex(key.key));
0:         iter.close();
commit:b324537
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.Component;
/////////////////////////////////////////////////////////////////////////
0:         BufferedRandomAccessFile input = new BufferedRandomAccessFile(desc.filenameFor(Component.PRIMARY_INDEX), "r");
commit:b4386e7
/////////////////////////////////////////////////////////////////////////
0:         SSTableReader reader = SSTableReader.open(Descriptor.fromFilename(ssTableFile));
/////////////////////////////////////////////////////////////////////////
0:         SSTableReader reader = SSTableReader.open(Descriptor.fromFilename(ssTableFile));
commit:b6b1053
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.Descriptor;
/////////////////////////////////////////////////////////////////////////
0:         Descriptor desc = Descriptor.fromFilename(ssTableFile);
0:             DecoratedKey decoratedKey = SSTableReader.decodeKey(partitioner,
0:                                                                 desc,
0:                                                                 FBUtilities.readShortByteArray(input));
commit:35db73c
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamily cf = row.getColumnFamilyWithColumns();
/////////////////////////////////////////////////////////////////////////
0: 
0:         while (scanner.hasNext())
commit:cba59a8
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.TimestampClock;
/////////////////////////////////////////////////////////////////////////
0:             json.append(((TimestampClock) column.clock()).timestamp());
/////////////////////////////////////////////////////////////////////////
0:                 json.append(((TimestampClock) column.getMarkedForDeleteAt()).timestamp());
commit:ee88039
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.SSTableIdentityIterator;
/////////////////////////////////////////////////////////////////////////
0:     private static String serializeRow(SSTableIdentityIterator row) throws IOException
/////////////////////////////////////////////////////////////////////////
0:                 SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
/////////////////////////////////////////////////////////////////////////
0:             SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
commit:59c09e2
/////////////////////////////////////////////////////////////////////////
0:         Set<String> excludeSet = new HashSet();
0: 
0:         if (excludes != null)
0:             excludeSet = new HashSet<String>(Arrays.asList(excludes));
/////////////////////////////////////////////////////////////////////////
0:         Set<String> excludeSet = new HashSet();
0: 
0:         if (excludes != null)
0:             excludeSet = new HashSet<String>(Arrays.asList(excludes));
commit:86eaf90
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.SSTable;
0: import org.apache.cassandra.io.sstable.SSTableReader;
0: import org.apache.cassandra.io.sstable.SSTableScanner;
commit:8f1376b
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
0: 
/////////////////////////////////////////////////////////////////////////
0:     private static final String EXCLUDEKEY_OPTION = "x";
/////////////////////////////////////////////////////////////////////////
0:         Option excludeKey = new Option(EXCLUDEKEY_OPTION, true, "Excluded row key");
0:         // Number of times -x <key> can be passed on the command line.
0:         excludeKey.setArgs(500);
0:         options.addOption(excludeKey);
0: 
/////////////////////////////////////////////////////////////////////////
0:     public static void export(String ssTableFile, PrintStream outs, String[] keys, String[] excludes)
0:         Set<String> excludeSet = new HashSet<String>(Arrays.asList(excludes));
0:             if (excludeSet.contains(key))
0:                 continue;
/////////////////////////////////////////////////////////////////////////
0:     public static void export(String ssTableFile, String outFile, String[] keys, String[] excludes) throws IOException
0:         export(ssTableFile, outs, keys, excludes);
0:     static void export(SSTableReader reader, PrintStream outs, String[] excludes) throws IOException
0:         Set<String> excludeSet = new HashSet<String>(Arrays.asList(excludes));
0: 
0:             if (excludeSet.contains(row.getKey().key))
0:                 continue;
/////////////////////////////////////////////////////////////////////////
0:     public static void export(String ssTableFile, PrintStream outs, String[] excludes) throws IOException
0:         export(reader, outs, excludes);
/////////////////////////////////////////////////////////////////////////
0:     public static void export(String ssTableFile, String outFile, String[] excludes) throws IOException
0:         export(ssTableFile, outs, excludes);
/////////////////////////////////////////////////////////////////////////
0:     public static void export(String ssTableFile, String[] excludes) throws IOException
0:         export(ssTableFile, System.out, excludes);
/////////////////////////////////////////////////////////////////////////
0:         String usage = String.format("Usage: %s <sstable> [-k key [-k key [...]] -x key [-x key [...]]]%n", SSTableExport.class.getName());
/////////////////////////////////////////////////////////////////////////
0:         String[] excludes = cmd.getOptionValues(EXCLUDEKEY_OPTION);
0:                 export(ssTableFileName, System.out, keys, excludes);
0:                 export(ssTableFileName, excludes);
commit:ef6f023
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:         String usage = String.format("Usage: %s <sstable> [-k key [-k key [...]]]%n", SSTableExport.class.getName());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         if (cmd.hasOption(ENUMERATEKEYS_OPTION))
0:             enumeratekeys(ssTableFileName, System.out);
0:         else {
0:             if ((keys != null) && (keys.length > 0))
0:                 export(ssTableFileName, System.out, keys);
0:             else
0:                 export(ssTableFileName);
commit:820390f
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.SSTable;
0: import org.apache.cassandra.io.util.BufferedRandomAccessFile;
0: import org.apache.cassandra.service.StorageService;
0: 
/////////////////////////////////////////////////////////////////////////
0:     private static final String ENUMERATEKEYS_OPTION = "e";
/////////////////////////////////////////////////////////////////////////
0: 
0:         options = new Options();
0:         Option optEnumerate = new Option(ENUMERATEKEYS_OPTION, false, "enumerate keys only");
0:         optOutfile.setRequired(false);
0:         options.addOption(optEnumerate);
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
0:      * Enumerate row keys from an SSTableReader and write the result to a PrintStream.
0:      * 
0:      * @param ssTableFile the file to export the rows from
0:      * @param outs PrintStream to write the output to
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void enumeratekeys(String ssTableFile, PrintStream outs)
0:     throws IOException
0:     {
0:         IPartitioner partitioner = StorageService.getPartitioner();
0:         BufferedRandomAccessFile input = new BufferedRandomAccessFile(SSTable.indexFilename(ssTableFile), "r");
0:         while (!input.isEOF())
0:         {
0:             DecoratedKey decoratedKey = partitioner.convertFromDiskFormat(input.readUTF());
0:             long dataPosition = input.readLong();
0:             outs.println(decoratedKey.key);
0:         }
0: 
0:         outs.flush();
0:     }
0: 
0:     /**
0:      * Enumerate row keys from an SSTable and write the result to a file.
0:      * 
0:      * @param ssTableFile the SSTable to export the rows from
0:      * @param outFile file to write the output to
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void enumeratekeys(String ssTableFile, String outFile)
0:     throws IOException
0:     {
0:         PrintStream outs = new PrintStream(outFile);
0:         enumeratekeys(ssTableFile, outs);
0:     }
/////////////////////////////////////////////////////////////////////////
0: 
0:             if (cmd.hasOption(ENUMERATEKEYS_OPTION))
0:                 enumeratekeys(ssTableFileName, outFile);
0:             else {
0:                 if ((keys != null) && (keys.length > 0))
0:                     export(ssTableFileName, outFile, keys);
0:                 else
0:                     export(ssTableFileName, outFile);
0:             }
0:             if (cmd.hasOption(ENUMERATEKEYS_OPTION))
0:                 enumeratekeys(ssTableFileName, System.out);
0:             else {
0:                 if ((keys != null) && (keys.length > 0))
0:                     export(ssTableFileName, System.out, keys);
0:                 else
0:                     export(ssTableFileName);
0:             }
commit:0cf4bcd
/////////////////////////////////////////////////////////////////////////
0:     private static int INPUT_FILE_BUFFER_SIZE = 8 * 1024 * 1024;
0: 
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getScanner(INPUT_FILE_BUFFER_SIZE);
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getScanner(INPUT_FILE_BUFFER_SIZE);
/////////////////////////////////////////////////////////////////////////
0: }
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:8541cca
/////////////////////////////////////////////////////////////////////////
0:         writeJSON(out, bytesToHex(key.getKey()));
/////////////////////////////////////////////////////////////////////////
0:             outs.println(bytesToHex(key.getKey()));
/////////////////////////////////////////////////////////////////////////
0:             String currentKey = bytesToHex(row.getKey().getKey());
commit:480a1a8
commit:27ed655
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getScanner();
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getScanner();
commit:7b532bc
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.Schema;
/////////////////////////////////////////////////////////////////////////
0:         if (Schema.instance.getNonSystemTables().size() < 1)
author:belliottsmith
-------------------------------------------------------------------------------
commit:75508ec
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         ByteBuffer value = cell.value();
author:Brandon Williams
-------------------------------------------------------------------------------
commit:049352f
commit:33a6640
/////////////////////////////////////////////////////////////////////////
0:         SSTableIdentityIterator row;
0: 
0:         boolean elementWritten = false;
0:             row = (SSTableIdentityIterator) scanner.next();
0: 
0:             else if (elementWritten)
0:                 outs.println(",");
0: 
0: 
0:                 // used to decide should we put ',' after previous row or not
0:                 if (!elementWritten)
0:                     elementWritten = true;
/////////////////////////////////////////////////////////////////////////
0:         outs.printf("%n}%n");
author:Gary Dusbabek
-------------------------------------------------------------------------------
commit:4e11242
commit:dd02495
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.ConfigurationException;
/////////////////////////////////////////////////////////////////////////
0:     public static void main(String[] args) throws IOException, ConfigurationException
/////////////////////////////////////////////////////////////////////////
0: 
0:         DatabaseDescriptor.loadSchemas();
0:         if (DatabaseDescriptor.getNonSystemTables().size() < 1)
0:         {
0:             String msg = "no non-system tables are defined";
0:             System.err.println(msg);
0:             throw new ConfigurationException(msg);
0:         }
0: 
commit:64f443a
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.cassandra.utils.FBUtilities.hexToBytes;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         StringBuilder json = new StringBuilder(asKey(bytesToHex(row.getKey().key)));
/////////////////////////////////////////////////////////////////////////
0:             outs.println(bytesToHex(decoratedKey.key));
/////////////////////////////////////////////////////////////////////////
0:             DecoratedKey<?> dk = partitioner.decorateKey(hexToBytes(key));
/////////////////////////////////////////////////////////////////////////
0:             if (excludeSet.contains(bytesToHex(row.getKey().key)))
/////////////////////////////////////////////////////////////////////////
0:                 System.err.println("WARNING: Corrupt row " + bytesToHex(row.getKey().key) + " (skipping).");
0:                 System.err.println("ERROR: Out of memory deserializing row " + bytesToHex(row.getKey().key));
commit:434564d
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.cassandra.utils.FBUtilities.UTF8;
/////////////////////////////////////////////////////////////////////////
0:             // FIXME: assuming string keys
0:             DecoratedKey<?> dk = partitioner.decorateKey(key.getBytes(UTF8));
commit:f3bb9ac
/////////////////////////////////////////////////////////////////////////
0:             DecoratedKey decoratedKey = partitioner.convertFromDiskFormat(FBUtilities.readShortByteArray(input));
commit:c1d34fb
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.utils.FBUtilities;
/////////////////////////////////////////////////////////////////////////
0:     @Deprecated
0:     private static String asStr(byte[] val)
0:     {
0:         // FIXME: should not interpret as a string
0:         return new String(val, FBUtilities.UTF8);
0:     }
0:     
/////////////////////////////////////////////////////////////////////////
0:         StringBuilder json = new StringBuilder(asKey(asStr(row.getKey().key)));
/////////////////////////////////////////////////////////////////////////
0:             outs.println(asStr(decoratedKey.key));
/////////////////////////////////////////////////////////////////////////
0:             if (excludeSet.contains(asStr(row.getKey().key)))
/////////////////////////////////////////////////////////////////////////
0:                 System.err.println("WARNING: Corrupt row " + asStr(row.getKey().key) + " (skipping).");
0:                 System.err.println("ERROR: Out of memory deserializing row " + asStr(row.getKey().key));
author:Eric Evans
-------------------------------------------------------------------------------
commit:0cb95c2
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.db.marshal.AbstractType;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:      * @param ssTableFile the SSTableScanner to export the rows from
0:      * @param excludes keys to exclude from export
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes keys to exclude from export
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes keys to exclude from export
/////////////////////////////////////////////////////////////////////////
0:      *
0:      * @throws ConfigurationException on configuration failure (wrong params given)
commit:fcf21d2
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.columniterator.IColumnIterator;
0: import org.apache.cassandra.db.filter.QueryFilter;
0: import org.apache.cassandra.db.filter.QueryPath;
0: import org.apache.cassandra.io.util.BufferedRandomAccessFile;
0: import org.apache.cassandra.service.StorageService;
0: import org.apache.cassandra.utils.ByteBufferUtil;
/////////////////////////////////////////////////////////////////////////
0:     // size of the columns page
0:     private static final int PAGE_SIZE = 1000;
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
0:      * Wraps given string into quotes
0:      * @param val string to quote
0:      * @return quoted string
0:      */
0: 
0:     /**
0:      * JSON Hash Key serializer
0:      * @param val value to set as a key
0:      * @return JSON Hash key
0:      */
0: 
0:     /**
0:      * Serialize columns using given column iterator
0:      * @param columns column iterator
0:      * @param out output stream
0:      * @param comparator columns comparator
0:      * @param cfMetaData Column Family metadata (to get validator)
0:      */
0:     private static void serializeColumns(Iterator<IColumn> columns, PrintStream out, AbstractType comparator, CFMetaData cfMetaData)
0:         while (columns.hasNext())
0:             serializeColumn(columns.next(), out, comparator, cfMetaData);
0:             if (columns.hasNext())
0:                 out.print(", ");
0: 
0:     /**
0:      * Serialize a collection of the columns
0:      * @param columns collection of the columns to serialize
0:      * @param out output stream
0:      * @param comparator columns comparator
0:      * @param cfMetaData Column Family metadata (to get validator)
0:      */
0:     private static void serializeColumns(Collection<IColumn> columns, PrintStream out, AbstractType comparator, CFMetaData cfMetaData)
0:         serializeColumns(columns.iterator(), out, comparator, cfMetaData);
0:     }
0: 
0:     /**
0:      * Serialize a given column to the JSON format
0:      * @param column column presentation
0:      * @param out output stream
0:      * @param comparator columns comparator
0:      * @param cfMetaData Column Family metadata (to get validator)
0:      */
0:     private static void serializeColumn(IColumn column, PrintStream out, AbstractType comparator, CFMetaData cfMetaData)
0:     {
0:         ByteBuffer name = ByteBufferUtil.clone(column.name());
0:         ByteBuffer value = ByteBufferUtil.clone(column.value());
0:         AbstractType validator = cfMetaData.getValueValidator(name);
0: 
0:         out.print("[");
0:         out.print(quote(comparator.getString(name)));
0:         out.print(", ");
0:         out.print(quote(validator.getString(value)));
0:         out.print(", ");
0:         out.print(column.timestamp());
0:         out.print(", ");
0:         out.print(column.isMarkedForDelete());
0: 
0:         if (column instanceof ExpiringColumn)
0:         {
0:             out.print(", ");
0:             out.print(((ExpiringColumn) column).getTimeToLive());
0:             out.print(", ");
0:             out.print(column.getLocalDeletionTime());
0:         }
0: 
0:         out.print("]");
0:     }
0: 
0:     /**
0:      * Get portion of the columns and serialize in loop while not more columns left in the row
0:      * @param reader SSTableReader for given SSTable
0:      * @param row SSTableIdentityIterator row representation with Column Family
0:      * @param key Decorated Key for the required row
0:      * @param out output stream
0:      */
0:     private static void serializeRow(SSTableReader reader, SSTableIdentityIterator row, DecoratedKey key, PrintStream out)
0:     {
0:         ColumnFamily columnFamily = row.getColumnFamily();
0:         boolean isSuperCF = columnFamily.isSuper();
0:         ByteBuffer startColumn = ByteBufferUtil.EMPTY_BYTE_BUFFER; // initial column name, "blank" for first
0: 
0:         out.print(asKey(bytesToHex(key.key)));
0: 
0:         out.print(isSuperCF ? "{" : "[");
0: 
0:         while (true)
0:         {
0:             QueryFilter filter = QueryFilter.getSliceFilter(key,
0:                                                             new QueryPath(columnFamily.metadata().tableName),
0:                                                             startColumn,
0:                                                             ByteBufferUtil.EMPTY_BYTE_BUFFER,
0:                                                             false,
0:                                                             PAGE_SIZE);
0: 
0:             IColumnIterator columns = filter.getSSTableColumnIterator(reader);
0: 
0:             int columnCount = 0;
0:             while (columns.hasNext())
0:             {
0:                 // setting new start column to the last of the current columns
0:                 startColumn = columns.next().name();
0:                 columnCount++;
0:             }
0: 
0:             try
0:             {
0:                 columns = filter.getSSTableColumnIterator(reader); // iterator reset
0:                 serializeRow(columns, isSuperCF, out);
0:             }
0:             catch (IOException e)
0:             {
0:                 System.err.println("WARNING: Corrupt row " + key + " (skipping).");
0:             }
0: 
0:             if (columnCount < PAGE_SIZE)
0:                 break;
0:         }
0: 
0:         out.print(isSuperCF ? "}" : "]");
0:     }
0: 
0:     /**
0:      * Serialize a row with already given column iterator
0:      *
0:      * @param columns columns of the row
0:      * @param isSuper true if wrapping Column Family is Super
0:      * @param out output stream
0:      *
0:      * @throws IOException on any I/O error.
0:      */
0:     private static void serializeRow(IColumnIterator columns, boolean isSuper, PrintStream out) throws IOException
0:     {
0:         ColumnFamily columnFamily = columns.getColumnFamily();
0:         if (isSuper)
0:             while (columns.hasNext())
0:                 IColumn column = columns.next();
0:                 out.print(asKey(comparator.getString(column.name())));
0:                 out.print("{");
0:                 out.print(asKey("deletedAt"));
0:                 out.print(column.getMarkedForDeleteAt());
0:                 out.print(", ");
0:                 out.print(asKey("subColumns"));
0:                 out.print("[");
0:                 serializeColumns(column.getSubColumns(), out, columnFamily.getSubComparator(), cfMetaData);
0:                 out.print("]");
0:                 out.print("}");
0:                 if (columns.hasNext())
0:                     out.print(", ");
0:             serializeColumns(columns, out, comparator, cfMetaData);
/////////////////////////////////////////////////////////////////////////
0:      * @param toExport the keys corresponding to the rows to export
0:     public static void export(String ssTableFile, PrintStream outs, Collection<String> toExport, String[] excludes) throws IOException
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         IPartitioner<?> partitioner = StorageService.getPartitioner();
0: 
0:         for (String toExclude : excludes)
0:         {
0:             toExport.remove(toExclude); // excluding key from export
0:         }
0: 
0:         int i = 0;
0: 
0:         // last key to compare order
0: 
0:         for (String key : toExport)
0:             DecoratedKey decoratedKey = partitioner.decorateKey(hexToBytes(key));
0: 
0:             if (lastKey != null && lastKey.compareTo(decoratedKey) > 0)
0:                 throw new IOException("Key out of order! " + lastKey + " > " + decoratedKey);
0: 
0:             lastKey = decoratedKey;
0: 
0:             scanner.seekTo(decoratedKey);
0: 
0:             if (!scanner.hasNext())
0:             serializeRow(reader, (SSTableIdentityIterator) scanner.next(), decoratedKey, outs);
0:             if (i != 0)
0:                 outs.println(",");
0: 
0: 
0:         scanner.close();
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         outs.println("{");
0: 
0:         int i = 0;
0: 
0:         // collecting keys to export
0:             String currentKey = bytesToHex(row.getKey().key);
0: 
0:             if (excludeSet.contains(currentKey))
0:             else if (i != 0)
0:             serializeRow(reader, row, row.getKey(), outs);
0:             i++;
0: 
0:         outs.println("\n}");
0: 
0:         scanner.close();
/////////////////////////////////////////////////////////////////////////
0:         export(SSTableReader.open(Descriptor.fromFilename(ssTableFile)), outs, excludes);
/////////////////////////////////////////////////////////////////////////
0:                 export(ssTableFileName, System.out, Arrays.asList(keys), excludes);
commit:448dbc6
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.ColumnFamily;
0: import org.apache.cassandra.db.DecoratedKey;
0: import org.apache.cassandra.db.ExpiringColumn;
0: import org.apache.cassandra.db.IColumn;
0: import org.apache.cassandra.db.marshal.AbstractType;
/////////////////////////////////////////////////////////////////////////
0:     private static int INPUT_FILE_BUFFER_SIZE = 8 * 1024 * 1024;
/////////////////////////////////////////////////////////////////////////
0:     
0:     
/////////////////////////////////////////////////////////////////////////
0:         outs.print("[");
/////////////////////////////////////////////////////////////////////////
0:         
0:         outs.print("]");
0:     
0:     private static void serializeRow(PrintStream outs, SSTableIdentityIterator row) throws IOException
/////////////////////////////////////////////////////////////////////////
0:             outs.print("{ ");
/////////////////////////////////////////////////////////////////////////
0:             
0:             outs.print("}");
/////////////////////////////////////////////////////////////////////////
0:      * @param ssTableFile the SSTable to export the rows from
0:      * @param keys the keys corresponding to the rows to export
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(INPUT_FILE_BUFFER_SIZE);
0:         IPartitioner<?> partitioner = DatabaseDescriptor.getPartitioner();    
0:         Set<String> excludeSet = new HashSet<String>();
0:         if (excludes != null)
0:             excludeSet = new HashSet<String>(Arrays.asList(excludes));
0:         
0:         outs.println("{");
0:         // last key to compare order 
0:         DecoratedKey lastKey = null;
0:         
0:         for (String key : keys)
/////////////////////////////////////////////////////////////////////////
0:             scanner.seekTo(dk);
0:             
0:             if (scanner.hasNext())
0:             {
0:                 SSTableIdentityIterator row = (SSTableIdentityIterator) scanner.next();
0: 
0:                 try
0:                 {
0:                     serializeRow(outs, row);
0:                 }
0:                 catch (IOException ioexc)
0:                 {
0:                     System.err.println("WARNING: Corrupt row " + key + " (skipping).");
0:                     continue;
0:                 }
0:                 catch (OutOfMemoryError oom)
0:                 {
0:                     System.err.println("ERROR: Out of memory deserializing row " + key);
0:                     continue;
0:                 }
0: 
0:                 if (i != 1)
0:                     outs.println(",");
0:             }
0:         }
0:         
0:         SSTableScanner scanner = reader.getDirectScanner(INPUT_FILE_BUFFER_SIZE);
0:         SSTableIdentityIterator row;
0:         boolean elementWritten = false;
0:             if (excludeSet.contains(bytesToHex(row.getKey().key)))
0:             else if (elementWritten)
0:             try
0:             {
0:                 serializeRow(outs, row);
0:                 // used to decide should we put ',' after previous row or not
0:                 if (!elementWritten)
0:                     elementWritten = true;
0:             }
0:             catch (IOException ioexcep)
0:             {
0:                 System.err.println("WARNING: Corrupt row " + bytesToHex(row.getKey().key) + " (skipping).");
0:                 elementWritten = false;
0:             }
0:             catch (OutOfMemoryError oom)
0:             {
0:                 System.err.println("ERROR: Out of memory deserializing row " + bytesToHex(row.getKey().key));
0:                 elementWritten = false;
0:             }
0:         
0:         outs.printf("%n}%n");
/////////////////////////////////////////////////////////////////////////
0:         SSTableReader reader = SSTableReader.open(Descriptor.fromFilename(ssTableFile));
0:         export(reader, outs, excludes);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 export(ssTableFileName, System.out, keys, excludes);
commit:e708c46
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     // size of the columns page
0:     private static final int PAGE_SIZE = 1000;
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
0:      * Wraps given string into quotes
0:      * @param val string to quote
0:      * @return quoted string
0:      */
0: 
0:     /**
0:      * JSON Hash Key serializer
0:      * @param val value to set as a key
0:      * @return JSON Hash key
0:      */
/////////////////////////////////////////////////////////////////////////
0:         while (columns.hasNext())
0:         {
0:             serializeColumn(columns.next(), out);
/////////////////////////////////////////////////////////////////////////
0: 
0:         out.print("]");
0: 
0:     /**
0:      * Get portion of the columns and serialize in loop while not more columns left in the row
0:      * @param reader SSTableReader for given SSTable
0:      * @param row SSTableIdentityIterator row representation with Column Family
0:      * @param key Decorated Key for the required row
0:      * @param out output stream
0:      */
0:     private static void serializeRow(SSTableReader reader, SSTableIdentityIterator row, DecoratedKey key, PrintStream out)
/////////////////////////////////////////////////////////////////////////
0:             QueryFilter filter = QueryFilter.getSliceFilter(key,
0:                                                             new QueryPath(columnFamily.metadata().tableName),
0:                                                             startColumn,
0:                                                             ByteBufferUtil.EMPTY_BYTE_BUFFER,
0:                                                             false,
0:                                                             PAGE_SIZE);
/////////////////////////////////////////////////////////////////////////
0: 
0:             try
0:             {
0:                 columns = filter.getSSTableColumnIterator(reader); // iterator reset
0:                 serializeRow(columns, isSuperCF, out);
0:             }
0:             catch (IOException e)
0:             {
0:                 System.err.println("WARNING: Corrupt row " + key + " (skipping).");
0:             }
0: 
0:             if (columnCount < PAGE_SIZE)
0:                 break;
0:         }
0: 
0:         out.print(isSuperCF ? "}" : "]");
0:     }
0: 
0:     /**
0:      * Serialize a row with already given column iterator
0:      *
0:      * @param columns columns of the row
0:      * @param isSuper true if wrapping Column Family is Super
0:      * @param out output stream
0:      *
0:      * @throws IOException on any I/O error.
0:      */
0:     private static void serializeRow(IColumnIterator columns, boolean isSuper, PrintStream out) throws IOException
0:     {
0:         if (isSuper)
0:         {
0:             while (columns.hasNext())
0:             {
0:                 IColumn column = columns.next();
0: 
0:                 out.print(asKey(bytesToHex(column.name())));
0:                 out.print("{");
0:                 out.print(asKey("deletedAt"));
0:                 out.print(column.getMarkedForDeleteAt());
0:                 out.print(", ");
0:                 out.print(asKey("subColumns"));
0:                 out.print("[");
0:                 serializeColumns(column.getSubColumns(), out);
0:                 out.print("]");
0:                 out.print("}");
0: 
0:                 if (columns.hasNext())
0:                     out.print(", ");
0:             }
/////////////////////////////////////////////////////////////////////////
0:      * @param ssTableFile the SSTableScanner to export the rows from
0:      * @param toExport the keys corresponding to the rows to export
0:      * @param excludes keys to exclude from export
/////////////////////////////////////////////////////////////////////////
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         IPartitioner<?> partitioner = StorageService.getPartitioner();
0: 
0:         for (String toExclude : excludes)
0:         {
0:             toExport.remove(toExclude); // excluding key from export
0:         }
0: 
0:         int i = 0;
0: 
0:         // last key to compare order
0: 
0:         for (String key : toExport)
/////////////////////////////////////////////////////////////////////////
0:             lastKey = decoratedKey;
0: 
0:             scanner.seekTo(decoratedKey);
0: 
0:             if (!scanner.hasNext())
0:                 continue;
0: 
0:             serializeRow(reader, (SSTableIdentityIterator) scanner.next(), decoratedKey, outs);
0: 
0:             if (i != 0)
0:                 outs.println(",");
0: 
0: 
0: 
0:         scanner.close();
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         outs.println("{");
0: 
0:         int i = 0;
0: 
0:         // collecting keys to export
0:             String currentKey = bytesToHex(row.getKey().key);
0: 
0:             if (excludeSet.contains(currentKey))
0:             else if (i != 0)
0:             serializeRow(reader, row, row.getKey(), outs);
0:             i++;
0: 
0:         outs.println("\n}");
0: 
0:         scanner.close();
/////////////////////////////////////////////////////////////////////////
0:         export(SSTableReader.open(Descriptor.fromFilename(ssTableFile)), outs, excludes);
/////////////////////////////////////////////////////////////////////////
0:      *
/////////////////////////////////////////////////////////////////////////
0:                 export(ssTableFileName, System.out, Arrays.asList(keys), excludes);
commit:15c2bb3
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.*;
0: import org.apache.cassandra.db.columniterator.IColumnIterator;
0: import org.apache.cassandra.db.filter.QueryFilter;
0: import org.apache.cassandra.db.filter.QueryPath;
0: import org.apache.cassandra.io.util.BufferedRandomAccessFile;
0: import org.apache.cassandra.service.StorageService;
0: import org.apache.cassandra.utils.ByteBufferUtil;
/////////////////////////////////////////////////////////////////////////
0:     // size of the columns page
0:     private static final int PAGE_SIZE = 1000;
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
0:      * Wraps given string into quotes
0:      * @param val string to quote
0:      * @return quoted string
0:      */
0: 
0:     /**
0:      * JSON Hash Key serializer
0:      * @param val value to set as a key
0:      * @return JSON Hash key
0:      */
0:     /**
0:      * Serialize columns using given column iterator
0:      * @param columns column iterator
0:      * @param out output stream
0:      */
0:     private static void serializeColumns(Iterator<IColumn> columns, PrintStream out)
0:     {
0:         while (columns.hasNext())
0:             serializeColumn(columns.next(), out);
0: 
0:             if (columns.hasNext())
0:                 out.print(", ");
0: 
0:     /**
0:      * Serialize a collection of the columns
0:      * @param columns collection of the columns to serialize
0:      * @param out output stream
0:      */
0:     private static void serializeColumns(Collection<IColumn> columns, PrintStream out)
0:         serializeColumns(columns.iterator(), out);
0:     }
0:     /**
0:      * Serialize a given column to the JSON format
0:      * @param column column presentation
0:      * @param out output stream
0:      */
0:     private static void serializeColumn(IColumn column, PrintStream out)
0:     {
0:         out.print("[");
0:         out.print(quote(bytesToHex(column.name())));
0:         out.print(", ");
0:         out.print(quote(bytesToHex(column.value())));
0:         out.print(", ");
0:         out.print(column.timestamp());
0:         out.print(", ");
0:         out.print(column.isMarkedForDelete());
0: 
0:         if (column instanceof ExpiringColumn)
0:             out.print(", ");
0:             out.print(((ExpiringColumn) column).getTimeToLive());
0:             out.print(", ");
0:             out.print(column.getLocalDeletionTime());
0:         }
0:         out.print("]");
0:     }
0: 
0:     /**
0:      * Get portion of the columns and serialize in loop while not more columns left in the row
0:      * @param reader SSTableReader for given SSTable
0:      * @param row SSTableIdentityIterator row representation with Column Family
0:      * @param key Decorated Key for the required row
0:      * @param out output stream
0:      */
0:     private static void serializeRow(SSTableReader reader, SSTableIdentityIterator row, DecoratedKey key, PrintStream out)
0:     {
0:         ColumnFamily columnFamily = row.getColumnFamily();
0:         boolean isSuperCF = columnFamily.isSuper();
0:         ByteBuffer startColumn = ByteBufferUtil.EMPTY_BYTE_BUFFER; // initial column name, "blank" for first
0: 
0:         out.print(asKey(bytesToHex(key.key)));
0: 
0:         out.print(isSuperCF ? "{" : "[");
0: 
0:         while (true)
0:         {
0:             QueryFilter filter = QueryFilter.getSliceFilter(key,
0:                                                             new QueryPath(columnFamily.metadata().tableName),
0:                                                             startColumn,
0:                                                             ByteBufferUtil.EMPTY_BYTE_BUFFER,
0:                                                             false,
0:                                                             PAGE_SIZE);
0: 
0:             IColumnIterator columns = filter.getSSTableColumnIterator(reader);
0: 
0:             int columnCount = 0;
0:             while (columns.hasNext())
0:                 // setting new start column to the last of the current columns
0:                 startColumn = columns.next().name();
0:                 columnCount++;
0: 
0:             try
0:             {
0:                 columns = filter.getSSTableColumnIterator(reader); // iterator reset
0:                 serializeRow(columns, isSuperCF, out);
0:             }
0:             catch (IOException e)
0:             {
0:                 System.err.println("WARNING: Corrupt row " + key + " (skipping).");
0:             }
0: 
0:             if (columnCount < PAGE_SIZE)
0:                 break;
0:         }
0: 
0:         out.print(isSuperCF ? "}" : "]");
0:     }
0: 
0:     /**
0:      * Serialize a row with already given column iterator
0:      *
0:      * @param columns columns of the row
0:      * @param isSuper true if wrapping Column Family is Super
0:      * @param out output stream
0:      *
0:      * @throws IOException on any I/O error.
0:      */
0:     private static void serializeRow(IColumnIterator columns, boolean isSuper, PrintStream out) throws IOException
0:     {
0:         if (isSuper)
0:         {
0:             while (columns.hasNext())
0:             {
0:                 IColumn column = columns.next();
0: 
0:                 out.print(asKey(bytesToHex(column.name())));
0:                 out.print("{");
0:                 out.print(asKey("deletedAt"));
0:                 out.print(column.getMarkedForDeleteAt());
0:                 out.print(", ");
0:                 out.print(asKey("subColumns"));
0:                 out.print("[");
0:                 serializeColumns(column.getSubColumns(), out);
0:                 out.print("]");
0:                 out.print("}");
0: 
0:                 if (columns.hasNext())
0:                     out.print(", ");
0:             }
0:             serializeColumns(columns, out);
/////////////////////////////////////////////////////////////////////////
0:      * @param ssTableFile the SSTableScanner to export the rows from
0:      * @param toExport the keys corresponding to the rows to export
0:      * @param excludes keys to exclude from export
0:     public static void export(String ssTableFile, PrintStream outs, Collection<String> toExport, String[] excludes) throws IOException
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         IPartitioner<?> partitioner = StorageService.getPartitioner();
0: 
0:         for (String toExclude : excludes)
0:         {
0:             toExport.remove(toExclude); // excluding key from export
0:         }
0: 
0:         int i = 0;
0: 
0:         // last key to compare order
0: 
0:         for (String key : toExport)
0:             DecoratedKey decoratedKey = partitioner.decorateKey(hexToBytes(key));
0: 
0:             if (lastKey != null && lastKey.compareTo(decoratedKey) > 0)
0:                 throw new IOException("Key out of order! " + lastKey + " > " + decoratedKey);
0: 
0:             lastKey = decoratedKey;
0: 
0:             scanner.seekTo(decoratedKey);
0: 
0:             if (!scanner.hasNext())
0:             serializeRow(reader, (SSTableIdentityIterator) scanner.next(), decoratedKey, outs);
0:             if (i != 0)
0:                 outs.println(",");
0: 
0: 
0: 
0:         scanner.close();
0:         SSTableScanner scanner = reader.getDirectScanner(BufferedRandomAccessFile.DEFAULT_BUFFER_SIZE);
0:         outs.println("{");
0: 
0:         int i = 0;
0: 
0:         // collecting keys to export
0:             String currentKey = bytesToHex(row.getKey().key);
0: 
0:             if (excludeSet.contains(currentKey))
0:             else if (i != 0)
0:             serializeRow(reader, row, row.getKey(), outs);
0:             i++;
0: 
0:         outs.println("\n}");
0: 
0:         scanner.close();
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes keys to exclude from export
0:      *
0:         export(SSTableReader.open(Descriptor.fromFilename(ssTableFile)), outs, excludes);
0:      * @param excludes keys to exclude from export
0:      *
/////////////////////////////////////////////////////////////////////////
0:      *
0:      * @throws ConfigurationException on configuration failure (wrong params given)
/////////////////////////////////////////////////////////////////////////
0:                 export(ssTableFileName, System.out, Arrays.asList(keys), excludes);
commit:ebc25c1
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.CFMetaData;
/////////////////////////////////////////////////////////////////////////
0:     private static void serializeColumns(PrintStream outs, Collection<IColumn> columns, AbstractType comparator, CFMetaData cfMetaData)
0:         Iterator<IColumn> iter = columns.iterator();
0: 
0: 
0:             ByteBuffer name = column.name();
0:             AbstractType validator = cfMetaData.getValueValidator(name);
0: 
0:             outs.print(quote(comparator.getString(name)));
0:             outs.print(quote(validator.getString(column.value())));
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0:             {
0:             }
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamily columnFamily = row.getColumnFamilyWithColumns();
0:         CFMetaData cfMetaData = columnFamily.metadata();
0:         AbstractType comparator = columnFamily.getComparator();
0: 
0:         // key is represented as String according to current Partitioner
0:         outs.print("  " + asKey(bytesToHex(row.getKey().key)));
0: 
0:         if (columnFamily.isSuper())
0:             Iterator<IColumn> iter = columnFamily.getSortedColumns().iterator();
0: 
0:                 // header of the row
0:                 outs.print(asKey(comparator.getString(column.name())));
0: 
0:                 // columns
0:                 serializeColumns(outs, column.getSubColumns(), columnFamily.getSubComparator(), cfMetaData);
0: 
0: 
0:                 {
0:                 }
0:             serializeColumns(outs, columnFamily.getSortedColumns(), comparator, cfMetaData);
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes the keys to exclude from export
0:      *
0:     public static void export(String ssTableFile, PrintStream outs, String[] keys, String[] excludes) throws IOException
/////////////////////////////////////////////////////////////////////////
0: 
0: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes the keys to exclude from export
0:      *
/////////////////////////////////////////////////////////////////////////
0:      * @param excludes the keys to exclude from export
0:      *
/////////////////////////////////////////////////////////////////////////
0:      * @throws ConfigurationException if configuration is invalid
commit:dc519a1
/////////////////////////////////////////////////////////////////////////
0: import java.io.File;
/////////////////////////////////////////////////////////////////////////
0:         String ssTableFileName = new File(cmd.getArgs()[0]).getAbsolutePath();
0:                 export(ssTableFileName, outFile, keys);
0:                 export(ssTableFileName, outFile);
0:                 export(ssTableFileName, System.out, keys);
0:                 export(ssTableFileName);
commit:93d9a81
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.cassandra.utils.FBUtilities.bytesToHex;
/////////////////////////////////////////////////////////////////////////
0:             json.append(quote(bytesToHex(column.name())));
0:             json.append(quote(bytesToHex(column.value())));
/////////////////////////////////////////////////////////////////////////
0:                 json.append(asKey(bytesToHex(column.name())));
commit:36edc09
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.commons.cli.*;
/////////////////////////////////////////////////////////////////////////
0:         StringBuilder json = new StringBuilder("[");
0:             json.append("[");
0:             json.append(quote(comp.getString(column.name())));
0:             json.append(", ");
0:             json.append(", ");
0:             json.append(column.timestamp());
0:             json.append(", ");
0:             json.append(column.isMarkedForDelete());
0:             json.append("]");
0:         json.append("]");
/////////////////////////////////////////////////////////////////////////
0:                 json.append("{");
0:                 json.append(asKey("deletedAt"));
0:                 json.append(column.getMarkedForDeleteAt());
0:                 json.append(", ");
0:                 json.append(asKey("subColumns"));
0:                 json.append("}");
0:             json.append("}");
/////////////////////////////////////////////////////////////////////////
0:     // This is necessary to accommodate the test suite since you cannot open a Reader more
0:     // than once from within the same process.
0:     static void export(SSTableReader reader, PrintStream outs) throws IOException
/////////////////////////////////////////////////////////////////////////
0:      * Export an SSTable and write the resulting JSON to a PrintStream.
0:      * 
0:      * @param ssTableFile the SSTable to export
0:      * @param outs PrintStream to write the output to
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, PrintStream outs) throws IOException
0:     {
0:         SSTableReader reader = SSTableReader.open(ssTableFile);
0:         export(reader, outs);
0:     }
0:     
0:     /**
commit:dcdb8e1
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.db.DecoratedKey;
0: import org.apache.cassandra.dht.IPartitioner;
/////////////////////////////////////////////////////////////////////////
0:     private static final String KEY_OPTION = "k";
/////////////////////////////////////////////////////////////////////////
0:         
0:         Option optKey = new Option(KEY_OPTION, true, "Row key");
0:         // Number of times -k <key> can be passed on the command line.
0:         optKey.setArgs(500);
0:         optKey.setRequired(false);
0:         options.addOption(optKey);
/////////////////////////////////////////////////////////////////////////
0:      * Export specific rows from an SSTable and write the resulting JSON to a PrintStream.
0:      * 
0:      * @param ssTableFile the SSTable to export the rows from
0:      * @param outs PrintStream to write the output to
0:      * @param keys the keys corresponding to the rows to export
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, PrintStream outs, String[] keys)
0:     throws IOException
0:     {
0:         SSTableReader reader = SSTableReader.open(ssTableFile);
0:         SSTableScanner scanner = reader.getScanner();
0:         IPartitioner<?> partitioner = DatabaseDescriptor.getPartitioner();    
0:         int i = 0;
0:         
0:         outs.println("{");
0:         
0:         for (String key : keys)
0:         {
0:             DecoratedKey<?> dk = partitioner.decorateKey(key);
0:             scanner.seekTo(dk);
0:             
0:             i++;
0:             
0:             if (scanner.hasNext())
0:             {
0:                 IteratingRow row = scanner.next();
0:                 try
0:                 {
0:                     String jsonOut = serializeRow(row);
0:                     if (i != 1)
0:                         outs.println(",");
0:                     outs.print("  " + jsonOut);
0:                 }
0:                 catch (IOException ioexc)
0:                 {
0:                     System.err.println("WARNING: Corrupt row " + key + " (skipping).");
0:                     continue;
0:                 }
0:                 catch (OutOfMemoryError oom)
0:                 {
0:                     System.err.println("ERROR: Out of memory deserializing row " + key);
0:                     continue;
0:                 }
0:             }
0:         }
0:         
0:         outs.println("\n}");
0:         outs.flush();
0:     }
0:     
0:     /**
0:      * Export specific rows from an SSTable and write the resulting JSON to a file.
0:      * 
0:      * @param ssTableFile the SSTable to export the rows from
0:      * @param outFile file to write output to
0:      * @param keys the keys corresponding to the rows to export
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, String outFile, String[] keys) throws IOException
0:     {
0:         PrintStream outs = new PrintStream(outFile);
0:         export(ssTableFile, outs, keys);
0:     }
0:     
0:     /**
/////////////////////////////////////////////////////////////////////////
0:         String usage = String.format("Usage: %s [-f outfile] <sstable> [-k key [-k key [...]]]%n",
0:                 SSTableExport.class.getName());
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:         String[] keys = cmd.getOptionValues(KEY_OPTION);
0:         
0:             if ((keys != null) && (keys.length > 0))
0:                 export(cmd.getArgs()[0], outFile, keys);
0:             else
0:                 export(cmd.getArgs()[0], outFile);
0:             if ((keys != null) && (keys.length > 0))
0:                 export(cmd.getArgs()[0], System.out, keys);
0:             else
0:                 export(cmd.getArgs()[0]);
commit:417e7c0
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one
0:  * or more contributor license agreements.  See the NOTICE file
0:  * distributed with this work for additional information
0:  * regarding copyright ownership.  The ASF licenses this file
0:  * to you under the Apache License, Version 2.0 (the
0:  * "License"); you may not use this file except in compliance
0:  * with the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: package org.apache.cassandra.tools;
0: 
0: import java.io.EOFException;
0: import java.io.IOException;
0: import java.io.PrintStream;
0: import java.util.Collection;
0: import java.util.Iterator;
0: 
0: import org.apache.cassandra.db.ColumnFamily;
0: import org.apache.cassandra.db.IColumn;
0: import org.apache.cassandra.db.marshal.AbstractType;
0: import org.apache.cassandra.io.IteratingRow;
0: import org.apache.cassandra.io.SSTableReader;
0: import org.apache.cassandra.io.SSTableScanner;
0: import org.apache.cassandra.utils.FBUtilities;
0: import org.apache.commons.cli.CommandLine;
0: import org.apache.commons.cli.CommandLineParser;
0: import org.apache.commons.cli.Option;
0: import org.apache.commons.cli.Options;
0: import org.apache.commons.cli.ParseException;
0: import org.apache.commons.cli.PosixParser;
0: 
0: /**
0:  * Export SSTables to JSON format.
0:  */
0: public class SSTableExport
0: {
0:     private static final String OUTFILE_OPTION = "f";
0:     private static Options options;
0:     private static CommandLine cmd;
0:     
0:     static
0:     {
0:         options = new Options();
0:         Option optOutfile = new Option(OUTFILE_OPTION, true, "output file");
0:         optOutfile.setRequired(false);
0:         options.addOption(optOutfile);
0:     }
0:     
0:     private static String quote(String val)
0:     {
0:         return String.format("\"%s\"", val);
0:     }
0:     
0:     private static String asKey(String val)
0:     {
0:         return String.format("%s: ", quote(val));
0:     }
0:     
0:     private static String serializeColumns(Collection<IColumn> cols, AbstractType comp)
0:     {
0:         StringBuilder json = new StringBuilder("{");
0:         
0:         Iterator<IColumn> iter = cols.iterator();
0:         while (iter.hasNext())
0:         {
0:             IColumn column = iter.next();
0:             json.append(asKey(comp.getString(column.name())));
0:             json.append(quote(FBUtilities.bytesToHex(column.value())));
0:             if (iter.hasNext())
0:                 json.append(", ");
0:         }
0:         
0:         json.append(" }");
0:         
0:         return json.toString();
0:     }
0:     
0:     private static String serializeRow(IteratingRow row) throws IOException
0:     {
0:         ColumnFamily cf = row.getColumnFamily();
0:         AbstractType comparator = cf.getComparator();
0:         StringBuilder json = new StringBuilder(asKey(row.getKey().key));
0:         
0:         if (cf.isSuper())
0:         {
0:             json.append("{ ");
0: 
0:             Iterator<IColumn> iter = cf.getSortedColumns().iterator();
0:             while (iter.hasNext())
0:             {
0:                 IColumn column = iter.next();
0:                 json.append(asKey(comparator.getString(column.name())));
0:                 json.append(serializeColumns(column.getSubColumns(), comparator));
0:                 if (iter.hasNext())
0:                     json.append(", ");
0:             }
0:             
0:             json.append(" }");
0:         }
0:         else
0:         {
0:             json.append(serializeColumns(cf.getSortedColumns(), comparator));
0:         }
0:      
0:         return json.toString();
0:     }
0:     
0:     /**
0:      * Export an SSTable and write the resulting JSON to a PrintStream.
0:      * 
0:      * @param ssTableFile the SSTable to export
0:      * @param outs PrintStream to write the output to
0:      * @throws IOException on failure to read/write input/output
0:      */
0:     public static void export(String ssTableFile, PrintStream outs) throws IOException
0:     {
0:         SSTableReader reader = SSTableReader.open(ssTableFile);
0:         SSTableScanner scanner = reader.getScanner();
0:         
0:         outs.println("{");
0:         
0:         while(scanner.hasNext())
0:         {
0:             IteratingRow row = scanner.next();
0:             try
0:             {
0:                 String jsonOut = serializeRow(row);
0:                 outs.print("  " + jsonOut);
0:                 if (scanner.hasNext())
0:                     outs.println(",");
0:                 else
0:                     outs.println();
0:             }
0:             catch (IOException ioexcep)
0:             {
0:                 System.err.println("WARNING: Corrupt row " + row.getKey().key + " (skipping).");
0:                 continue;
0:             }
0:             catch (OutOfMemoryError oom)
0:             {
0:                 System.err.println("ERROR: Out of memory deserializing row " + row.getKey().key);
0:                 continue;
0:             }
0:         }
0:         
0:         outs.println("}");
0:         outs.flush();
0:     }
0:     
0:     /**
0:      * Export an SSTable and write the resulting JSON to a file.
0:      * 
0:      * @param ssTableFile SSTable to export
0:      * @param outFile file to write output to
0:      * @throws IOException on failure to read/write SSTable/output file
0:      */
0:     public static void export(String ssTableFile, String outFile) throws IOException
0:     {
0:         PrintStream outs = new PrintStream(outFile);
0:         export(ssTableFile, outs);
0:     }
0:     
0:     /**
0:      * Export an SSTable and write the resulting JSON to standard out.
0:      * 
0:      * @param ssTableFile SSTable to export
0:      * @throws IOException on failure to read/write SSTable/standard out
0:      */
0:     public static void export(String ssTableFile) throws IOException
0:     {
0:         export(ssTableFile, System.out);
0:     }
0: 
0:     /**
0:      * Given arguments specifying an SSTable, and optionally an output file,
0:      * export the contents of the SSTable to JSON.
0:      *  
0:      * @param args command lines arguments
0:      * @throws IOException on failure to open/read/write files or output streams
0:      */
0:     public static void main(String[] args) throws IOException
0:     {
0:         String usage = String.format("Usage: %s [-f outfile] <sstable>%n", SSTableExport.class.getName());
0:         
0:         CommandLineParser parser = new PosixParser();
0:         try
0:         {
0:             cmd = parser.parse(options, args);
0:         } catch (ParseException e1)
0:         {
0:             System.err.println(e1.getMessage());
0:             System.err.println(usage);
0:             System.exit(1);
0:         }
0:         
0:         String outFile = cmd.getOptionValue(OUTFILE_OPTION);
0:         
0:         if (cmd.getArgs().length != 1)
0:         {
0:             System.err.println("You must supply exactly one sstable");
0:             System.err.println(usage);
0:             System.exit(1);
0:         }
0:         
0:         if (outFile != null)
0:         {
0:             export(cmd.getArgs()[0], outFile);
0:         }
0:         else
0:         {
0:             export(cmd.getArgs()[0]);
0:         }
0:         System.exit(0);
0:     }
0: }
============================================================================
1:b09e60f: /*
1:b09e60f:  * Licensed to the Apache Software Foundation (ASF) under one
1:b09e60f:  * or more contributor license agreements.  See the NOTICE file
1:b09e60f:  * distributed with this work for additional information
1:b09e60f:  * regarding copyright ownership.  The ASF licenses this file
1:b09e60f:  * to you under the Apache License, Version 2.0 (the
1:b09e60f:  * "License"); you may not use this file except in compliance
1:b09e60f:  * with the License.  You may obtain a copy of the License at
1:b09e60f:  *
1:b09e60f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:b09e60f:  *
1:b09e60f:  * Unless required by applicable law or agreed to in writing, software
1:b09e60f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b09e60f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b09e60f:  * See the License for the specific language governing permissions and
1:b09e60f:  * limitations under the License.
1:b09e60f:  */
1:b09e60f: 
1:b09e60f: package org.apache.cassandra.io.sstable;
1:b09e60f: 
1:47d3b7e: import java.io.IOException;
1:9ed2727: import java.util.Collection;
1:9ed2727: 
1:9ed2727: import org.apache.cassandra.config.CFMetaData;
1:9ed2727: import org.apache.cassandra.db.ColumnFamilyStore;
1:0026e4e: import org.apache.cassandra.db.Keyspace;
1:b09e60f: import org.apache.cassandra.db.SerializationHeader;
1:b09e60f: import org.apache.cassandra.db.compaction.OperationType;
1:b09e60f: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1:b09e60f: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
1:f81a91d: import org.apache.cassandra.index.Index;
1:47d3b7e: import org.apache.cassandra.io.sstable.format.RangeAwareSSTableWriter;
1:47d3b7e: import org.apache.cassandra.io.sstable.format.SSTableFormat;
1:b09e60f: import org.apache.cassandra.io.sstable.format.SSTableReader;
1:9ed2727: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
1:b09e60f: import org.apache.cassandra.utils.concurrent.Transactional;
1:b09e60f: 
1:b09e60f: /**
1:b09e60f:  * A wrapper for SSTableWriter and LifecycleTransaction to be used when
1:b09e60f:  * the writer is the only participant in the transaction and therefore
1:b09e60f:  * it can safely own the transaction.
1:b09e60f:  */
1:b09e60f: public class SSTableTxnWriter extends Transactional.AbstractTransactional implements Transactional
1:b09e60f: {
1:b09e60f:     private final LifecycleTransaction txn;
1:9ed2727:     private final SSTableMultiWriter writer;
1:b09e60f: 
1:9ed2727:     public SSTableTxnWriter(LifecycleTransaction txn, SSTableMultiWriter writer)
1:b09e60f:     {
1:b09e60f:         this.txn = txn;
1:b09e60f:         this.writer = writer;
1:b09e60f:     }
1:b09e60f: 
1:9ed2727:     public boolean append(UnfilteredRowIterator iterator)
1:b09e60f:     {
1:b09e60f:         return writer.append(iterator);
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     public String getFilename()
1:b09e60f:     {
1:b09e60f:         return writer.getFilename();
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     public long getFilePointer()
1:b09e60f:     {
1:b09e60f:         return writer.getFilePointer();
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     protected Throwable doCommit(Throwable accumulate)
1:b09e60f:     {
1:605bcdc:         return writer.commit(txn.commit(accumulate));
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     protected Throwable doAbort(Throwable accumulate)
1:b09e60f:     {
1:c163d0b:         return txn.abort(writer.abort(accumulate));
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     protected void doPrepare()
1:b09e60f:     {
1:605bcdc:         writer.prepareToCommit();
1:c163d0b:         txn.prepareToCommit();
1:b09e60f:     }
1:b09e60f: 
1:e777301:     @Override
1:e777301:     protected Throwable doPostCleanup(Throwable accumulate)
1:b09e60f:     {
1:e777301:         txn.close();
1:e777301:         writer.close();
1:e777301:         return super.doPostCleanup(accumulate);
1:e777301:     }
1:e777301: 
1:9ed2727:     public Collection<SSTableReader> finish(boolean openResult)
1:e777301:     {
1:b09e60f:         writer.setOpenResult(openResult);
1:b09e60f:         finish();
1:b09e60f:         return writer.finished();
1:b09e60f:     }
1:b09e60f: 
1:05660a5:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
1:9ed2727:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, Descriptor descriptor, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
1:b09e60f:     {
1:73781a9:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
1:9ed2727:         SSTableMultiWriter writer = cfs.createSSTableMultiWriter(descriptor, keyCount, repairedAt, sstableLevel, header, txn);
1:b09e60f:         return new SSTableTxnWriter(txn, writer);
1:b09e60f:     }
1:47d3b7e: 
1:b09e60f: 
1:05660a5:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
1:0026e4e:     public static SSTableTxnWriter createRangeAware(CFMetaData cfm,
1:0026e4e:                                                     long keyCount,
1:0026e4e:                                                     long repairedAt,
1:0026e4e:                                                     SSTableFormat.Type type,
1:0026e4e:                                                     int sstableLevel,
1:0026e4e:                                                     SerializationHeader header)
1:47d3b7e:     {
1:0026e4e: 
1:0026e4e:         ColumnFamilyStore cfs = Keyspace.open(cfm.ksName).getColumnFamilyStore(cfm.cfName);
1:47d3b7e:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
1:47d3b7e:         SSTableMultiWriter writer;
1:47d3b7e:         try
1:47d3b7e:         {
1:47d3b7e:             writer = new RangeAwareSSTableWriter(cfs, keyCount, repairedAt, type, sstableLevel, 0, txn, header);
1:47d3b7e:         }
1:47d3b7e:         catch (IOException e)
1:47d3b7e:         {
1:47d3b7e:             //We don't know the total size so this should never happen
1:47d3b7e:             //as we send in 0
1:47d3b7e:             throw new RuntimeException(e);
1:47d3b7e:         }
1:47d3b7e: 
1:47d3b7e:         return new SSTableTxnWriter(txn, writer);
1:47d3b7e:     }
1:47d3b7e: 
1:05660a5:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
1:f81a91d:     public static SSTableTxnWriter create(CFMetaData cfm,
1:f81a91d:                                           Descriptor descriptor,
1:f81a91d:                                           long keyCount,
1:f81a91d:                                           long repairedAt,
1:f81a91d:                                           int sstableLevel,
1:f81a91d:                                           SerializationHeader header,
1:f81a91d:                                           Collection<Index> indexes)
1:b09e60f:     {
1:9ed2727:         // if the column family store does not exist, we create a new default SSTableMultiWriter to use:
1:73781a9:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
1:9ed2727:         MetadataCollector collector = new MetadataCollector(cfm.comparator).sstableLevel(sstableLevel);
1:f81a91d:         SSTableMultiWriter writer = SimpleSSTableMultiWriter.create(descriptor, keyCount, repairedAt, cfm, collector, header, indexes, txn);
1:9ed2727:         return new SSTableTxnWriter(txn, writer);
1:b09e60f:     }
2:9ed2727: 
1:9ed2727:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, String filename, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
2:9ed2727:     {
1:b09e60f:         Descriptor desc = Descriptor.fromFilename(filename);
1:9ed2727:         return create(cfs, desc, keyCount, repairedAt, sstableLevel, header);
1:b09e60f:     }
1:b09e60f: 
1:9ed2727:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, String filename, long keyCount, long repairedAt, SerializationHeader header)
1:b09e60f:     {
1:9ed2727:         return create(cfs, filename, keyCount, repairedAt, 0, header);
1:b09e60f:     }
2:9ed2727: }
============================================================================
author:Jeremiah D Jordan
-------------------------------------------------------------------------------
commit:0026e4e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.Keyspace;
/////////////////////////////////////////////////////////////////////////
1:     public static SSTableTxnWriter createRangeAware(CFMetaData cfm,
1:                                                     long keyCount,
1:                                                     long repairedAt,
1:                                                     SSTableFormat.Type type,
1:                                                     int sstableLevel,
1:                                                     SerializationHeader header)
1: 
1:         ColumnFamilyStore cfs = Keyspace.open(cfm.ksName).getColumnFamilyStore(cfm.cfName);
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:05660a5
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("resource") // log and writer closed during doPostCleanup
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:47d3b7e
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.sstable.format.RangeAwareSSTableWriter;
1: import org.apache.cassandra.io.sstable.format.SSTableFormat;
/////////////////////////////////////////////////////////////////////////
1: 
0:     public static SSTableTxnWriter createRangeAware(ColumnFamilyStore cfs, long keyCount, long repairedAt, SSTableFormat.Type type, int sstableLevel, SerializationHeader header)
1:     {
1:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
1:         SSTableMultiWriter writer;
1:         try
1:         {
1:             writer = new RangeAwareSSTableWriter(cfs, keyCount, repairedAt, type, sstableLevel, 0, txn, header);
1:         }
1:         catch (IOException e)
1:         {
1:             //We don't know the total size so this should never happen
1:             //as we send in 0
1:             throw new RuntimeException(e);
1:         }
1: 
1:         return new SSTableTxnWriter(txn, writer);
1:     }
1: 
author:Dave Brosius
-------------------------------------------------------------------------------
commit:087264f
/////////////////////////////////////////////////////////////////////////
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:f81a91d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.index.Index;
/////////////////////////////////////////////////////////////////////////
1:     public static SSTableTxnWriter create(CFMetaData cfm,
1:                                           Descriptor descriptor,
1:                                           long keyCount,
1:                                           long repairedAt,
1:                                           int sstableLevel,
1:                                           SerializationHeader header,
1:                                           Collection<Index> indexes)
1:         SSTableMultiWriter writer = SimpleSSTableMultiWriter.create(descriptor, keyCount, repairedAt, cfm, collector, header, indexes, txn);
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:73781a9
/////////////////////////////////////////////////////////////////////////
1:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
/////////////////////////////////////////////////////////////////////////
1:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE);
commit:c163d0b
/////////////////////////////////////////////////////////////////////////
1:         return txn.abort(writer.abort(accumulate));
1:         txn.prepareToCommit();
commit:605bcdc
/////////////////////////////////////////////////////////////////////////
1:         return writer.commit(txn.commit(accumulate));
0:         return writer.abort(txn.abort(accumulate));
1:         writer.prepareToCommit();
commit:b09e60f
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.cassandra.io.sstable;
1: 
0: import org.apache.cassandra.db.RowIndexEntry;
1: import org.apache.cassandra.db.SerializationHeader;
1: import org.apache.cassandra.db.compaction.OperationType;
1: import org.apache.cassandra.db.lifecycle.LifecycleTransaction;
1: import org.apache.cassandra.db.rows.UnfilteredRowIterator;
1: import org.apache.cassandra.io.sstable.format.SSTableReader;
0: import org.apache.cassandra.io.sstable.format.SSTableWriter;
1: import org.apache.cassandra.utils.concurrent.Transactional;
1: 
1: /**
1:  * A wrapper for SSTableWriter and LifecycleTransaction to be used when
1:  * the writer is the only participant in the transaction and therefore
1:  * it can safely own the transaction.
1:  */
1: public class SSTableTxnWriter extends Transactional.AbstractTransactional implements Transactional
1: {
1:     private final LifecycleTransaction txn;
0:     private final SSTableWriter writer;
1: 
0:     public SSTableTxnWriter(LifecycleTransaction txn, SSTableWriter writer)
1:     {
1:         this.txn = txn;
1:         this.writer = writer;
1:     }
1: 
0:     public RowIndexEntry append(UnfilteredRowIterator iterator)
1:     {
1:         return writer.append(iterator);
1:     }
1: 
1:     public String getFilename()
1:     {
1:         return writer.getFilename();
1:     }
1: 
1:     public long getFilePointer()
1:     {
1:         return writer.getFilePointer();
1:     }
1: 
1:     protected Throwable doCommit(Throwable accumulate)
1:     {
0:         return txn.commit(writer.commit(accumulate));
1:     }
1: 
1:     protected Throwable doAbort(Throwable accumulate)
1:     {
0:         return txn.abort(writer.abort(accumulate));
1:     }
1: 
1:     protected void doPrepare()
1:     {
0:         writer.prepareToCommit();
0:         txn.prepareToCommit();
1:     }
1: 
0:     public SSTableReader finish(boolean openResult)
1:     {
1:         writer.setOpenResult(openResult);
1:         finish();
1:         return writer.finished();
1:     }
1: 
0:     public static SSTableTxnWriter create(Descriptor descriptor, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
1:     {
0:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE, descriptor.directory);
0:         SSTableWriter writer = SSTableWriter.create(descriptor, keyCount, repairedAt, sstableLevel, header, txn);
1:         return new SSTableTxnWriter(txn, writer);
1:     }
1: 
0:     public static SSTableTxnWriter create(String filename, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
1:     {
1:         Descriptor desc = Descriptor.fromFilename(filename);
0:         return create(desc, keyCount, repairedAt, sstableLevel, header);
1:     }
1: 
0:     public static SSTableTxnWriter create(String filename, long keyCount, long repairedAt, SerializationHeader header)
1:     {
0:         return create(filename, keyCount, repairedAt, 0, header);
1:     }
1: }
author:Carl Yeksigian
-------------------------------------------------------------------------------
commit:9415c84
/////////////////////////////////////////////////////////////////////////
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:e777301
/////////////////////////////////////////////////////////////////////////
1:     @Override
1:     protected Throwable doPostCleanup(Throwable accumulate)
1:     {
1:         txn.close();
1:         writer.close();
1:         return super.doPostCleanup(accumulate);
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("resource") // log and writer closed during postCleanup
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("resource") // log and writer closed during postCleanup
author:Blake Eggleston
-------------------------------------------------------------------------------
commit:9ed2727
/////////////////////////////////////////////////////////////////////////
1: import java.util.Collection;
1: 
1: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.db.ColumnFamilyStore;
0: import org.apache.cassandra.db.Keyspace;
1: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
/////////////////////////////////////////////////////////////////////////
1:     private final SSTableMultiWriter writer;
1:     public SSTableTxnWriter(LifecycleTransaction txn, SSTableMultiWriter writer)
1:     public boolean append(UnfilteredRowIterator iterator)
/////////////////////////////////////////////////////////////////////////
1:     public Collection<SSTableReader> finish(boolean openResult)
1:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, Descriptor descriptor, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
1:         SSTableMultiWriter writer = cfs.createSSTableMultiWriter(descriptor, keyCount, repairedAt, sstableLevel, header, txn);
0:     public static SSTableTxnWriter create(CFMetaData cfm, Descriptor descriptor, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
0:         if (Keyspace.open(cfm.ksName).hasColumnFamilyStore(cfm.cfId))
1:         {
0:             ColumnFamilyStore cfs = Keyspace.open(cfm.ksName).getColumnFamilyStore(cfm.cfId);
0:             return create(cfs, descriptor, keyCount, repairedAt, sstableLevel, header);
1:         }
1: 
1:         // if the column family store does not exist, we create a new default SSTableMultiWriter to use:
0:         LifecycleTransaction txn = LifecycleTransaction.offline(OperationType.WRITE, descriptor.directory);
1:         MetadataCollector collector = new MetadataCollector(cfm.comparator).sstableLevel(sstableLevel);
0:         SSTableMultiWriter writer = SimpleSSTableMultiWriter.create(descriptor, keyCount, repairedAt, cfm, collector, header, txn);
1:         return new SSTableTxnWriter(txn, writer);
1:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, String filename, long keyCount, long repairedAt, int sstableLevel, SerializationHeader header)
0:         Descriptor desc = Descriptor.fromFilename(filename);
1:         return create(cfs, desc, keyCount, repairedAt, sstableLevel, header);
1:     }
1: 
1:     public static SSTableTxnWriter create(ColumnFamilyStore cfs, String filename, long keyCount, long repairedAt, SerializationHeader header)
1:     {
1:         return create(cfs, filename, keyCount, repairedAt, 0, header);
============================================================================
1:72790dc: /*
1:72790dc:  * Licensed to the Apache Software Foundation (ASF) under one
1:72790dc:  * or more contributor license agreements.  See the NOTICE file
1:72790dc:  * distributed with this work for additional information
1:72790dc:  * regarding copyright ownership.  The ASF licenses this file
1:72790dc:  * to you under the Apache License, Version 2.0 (the
1:72790dc:  * "License"); you may not use this file except in compliance
1:72790dc:  * with the License.  You may obtain a copy of the License at
1:72790dc:  *
1:72790dc:  *     http://www.apache.org/licenses/LICENSE-2.0
1:72790dc:  *
1:72790dc:  * Unless required by applicable law or agreed to in writing, software
1:72790dc:  * distributed under the License is distributed on an "AS IS" BASIS,
1:72790dc:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:72790dc:  * See the License for the specific language governing permissions and
1:72790dc:  * limitations under the License.
1:72790dc:  */
1:72790dc: package org.apache.cassandra.index.sasi.disk;
17:72790dc: 
1:72790dc: import java.io.File;
1:72790dc: import java.io.IOException;
1:72790dc: import java.util.*;
1:72790dc: 
1:72790dc: import com.google.common.collect.Iterators;
1:72790dc: import com.google.common.collect.PeekingIterator;
1:9797511: 
1:7d857b4: import com.carrotsearch.hppc.cursors.LongObjectCursor;
1:9797511: import org.apache.cassandra.config.DatabaseDescriptor;
1:72790dc: import org.apache.cassandra.db.BufferDecoratedKey;
1:7d857b4: import org.apache.cassandra.db.ClusteringComparator;
1:72790dc: import org.apache.cassandra.db.DecoratedKey;
1:7d857b4: import org.apache.cassandra.db.marshal.LongType;
1:72790dc: import org.apache.cassandra.dht.Murmur3Partitioner;
1:72790dc: import org.apache.cassandra.index.sasi.disk.TokenTreeBuilder.EntryType;
1:7d857b4: import org.apache.cassandra.index.sasi.utils.*;
1:7d857b4: import org.apache.cassandra.io.util.*;
1:72790dc: 
1:72790dc: import junit.framework.Assert;
1:9797511: 
1:9797511: import org.junit.BeforeClass;
1:72790dc: import org.junit.Test;
1:72790dc: import org.apache.commons.lang3.builder.HashCodeBuilder;
1:72790dc: 
1:72790dc: public class TokenTreeTest
11:72790dc: {
1:7d857b4:     private static final ClusteringComparator CLUSTERING_COMPARATOR = new ClusteringComparator(LongType.instance);
1:72790dc: 
1:9797511:     @BeforeClass
1:9797511:     public static void setupDD()
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:9797511:     }
1:9797511: 
1:7d857b4:     static KeyOffsets singleOffset = new KeyOffsets() {{ put(1L, KeyOffsets.asArray(10L)); }};
1:7d857b4:     static KeyOffsets bigSingleOffset = new KeyOffsets() {{ put(2147521562L, KeyOffsets.asArray(10)); }};
1:7d857b4:     static KeyOffsets shortPackableCollision = new KeyOffsets() {{
1:7d857b4:         put(2L, KeyOffsets.asArray(10));
1:7d857b4:         put(3L, KeyOffsets.asArray(10));
1:7d857b4:     }}; // can pack two shorts
1:7d857b4:     static KeyOffsets intPackableCollision = new KeyOffsets()
1:7d857b4:     {{
1:7d857b4:         put(6L, KeyOffsets.asArray(10));
1:7d857b4:         put(((long) Short.MAX_VALUE) + 1, KeyOffsets.asArray(10));
1:7d857b4:     }}; // can pack int & short
1:7d857b4:     static KeyOffsets multiCollision = new KeyOffsets()
1:7d857b4:     {{
1:7d857b4:         put(3L, KeyOffsets.asArray(10));
1:7d857b4:         put(4L, KeyOffsets.asArray(10));
1:7d857b4:         put(5L, KeyOffsets.asArray(10));
1:7d857b4:     }}; // can't pack
1:7d857b4:     static KeyOffsets unpackableCollision = new KeyOffsets()
1:7d857b4:     {{
1:7d857b4:         put(((long) Short.MAX_VALUE) + 1, KeyOffsets.asArray(10));
1:7d857b4:         put(((long) Short.MAX_VALUE) + 2, KeyOffsets.asArray(10));
1:7d857b4:     }}; // can't pack
1:72790dc: 
1:7d857b4:     final static SortedMap<Long, KeyOffsets> simpleTokenMap = new TreeMap<Long, KeyOffsets>()
1:72790dc:     {{
1:72790dc:             put(1L, bigSingleOffset); put(3L, shortPackableCollision); put(4L, intPackableCollision); put(6L, singleOffset);
1:72790dc:             put(9L, multiCollision); put(10L, unpackableCollision); put(12L, singleOffset); put(13L, singleOffset);
1:72790dc:             put(15L, singleOffset); put(16L, singleOffset); put(20L, singleOffset); put(22L, singleOffset);
1:72790dc:             put(25L, singleOffset); put(26L, singleOffset); put(27L, singleOffset); put(28L, singleOffset);
1:72790dc:             put(40L, singleOffset); put(50L, singleOffset); put(100L, singleOffset); put(101L, singleOffset);
1:72790dc:             put(102L, singleOffset); put(103L, singleOffset); put(108L, singleOffset); put(110L, singleOffset);
1:72790dc:             put(112L, singleOffset); put(115L, singleOffset); put(116L, singleOffset); put(120L, singleOffset);
1:72790dc:             put(121L, singleOffset); put(122L, singleOffset); put(123L, singleOffset); put(125L, singleOffset);
1:72790dc:     }};
1:72790dc: 
1:7d857b4:     final static SortedMap<Long, KeyOffsets> bigTokensMap = new TreeMap<Long, KeyOffsets>()
1:72790dc:     {{
1:72790dc:             for (long i = 0; i < 1000000; i++)
1:72790dc:                 put(i, singleOffset);
1:72790dc:     }};
1:72790dc: 
1:7d857b4:     final static SortedMap<Long, KeyOffsets> collidingTokensMap = new TreeMap<Long, KeyOffsets>()
1:72790dc:     {{
1:7d857b4:         put(1L, singleOffset);
1:7d857b4:         put(7L, singleOffset);
1:7d857b4:         put(8L, singleOffset);
1:72790dc:     }};
1:72790dc: 
1:7d857b4:     final static SortedMap<Long, KeyOffsets> tokens = bigTokensMap;
1:72790dc: 
1:fb22109:     final static SequentialWriterOption DEFAULT_OPT = SequentialWriterOption.newBuilder().bufferSize(4096).build();
1:fb22109: 
2:72790dc:     @Test
1:5c4d5c7:     public void testSerializedSizeDynamic() throws Exception
1:72790dc:     {
1:5c4d5c7:         testSerializedSize(new DynamicTokenTreeBuilder(tokens));
10:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void testSerializedSizeStatic() throws Exception
1:72790dc:     {
1:5c4d5c7:         testSerializedSize(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)));
1:72790dc:     }
1:72790dc: 
1:72790dc: 
1:5c4d5c7:     public void testSerializedSize(final TokenTreeBuilder builder) throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         builder.finish();
1:72790dc:         final File treeFile = File.createTempFile("token-tree-size-test", "tt");
1:72790dc:         treeFile.deleteOnExit();
1:72790dc: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:72790dc:         {
1:72790dc:             builder.write(writer);
1:72790dc:             writer.sync();
1:72790dc:         }
1:72790dc: 
1:72790dc:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:72790dc:         Assert.assertEquals((int) reader.bytesRemaining(), builder.serializedSize());
1:5c4d5c7:         reader.close();
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void buildSerializeAndIterateDynamic() throws Exception
1:72790dc:     {
1:5c4d5c7:         buildSerializeAndIterate(new DynamicTokenTreeBuilder(simpleTokenMap), simpleTokenMap);
1:5c4d5c7:     }
1:72790dc: 
1:5c4d5c7:     @Test
1:5c4d5c7:     public void buildSerializeAndIterateStatic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         buildSerializeAndIterate(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)), tokens);
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7: 
1:7d857b4:     public void buildSerializeAndIterate(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokenMap) throws Exception
1:5c4d5c7:     {
1:5c4d5c7: 
1:5c4d5c7:         builder.finish();
1:72790dc:         final File treeFile = File.createTempFile("token-tree-iterate-test1", "tt");
1:72790dc:         treeFile.deleteOnExit();
1:72790dc: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:72790dc:         {
1:72790dc:             builder.write(writer);
1:72790dc:             writer.sync();
1:72790dc:         }
1:72790dc: 
1:72790dc:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:72790dc:         final TokenTree tokenTree = new TokenTree(new MappedBuffer(reader));
1:72790dc: 
1:7d857b4:         final Iterator<Token> tokenIterator = tokenTree.iterator(KeyConverter.instance);
1:7d857b4:         final Iterator<Map.Entry<Long, KeyOffsets>> listIterator = tokenMap.entrySet().iterator();
3:72790dc:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:72790dc:         {
1:72790dc:             Token treeNext = tokenIterator.next();
1:7d857b4:             Map.Entry<Long, KeyOffsets> listNext = listIterator.next();
1:72790dc: 
1:72790dc:             Assert.assertEquals(listNext.getKey(), treeNext.get());
1:72790dc:             Assert.assertEquals(convert(listNext.getValue()), convert(treeNext));
1:72790dc:         }
1:72790dc: 
3:72790dc:         Assert.assertFalse("token iterator not finished", tokenIterator.hasNext());
3:72790dc:         Assert.assertFalse("list iterator not finished", listIterator.hasNext());
1:72790dc: 
1:72790dc:         reader.close();
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void buildSerializeAndGetDynamic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         buildSerializeAndGet(false);
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     @Test
1:5c4d5c7:     public void buildSerializeAndGetStatic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         buildSerializeAndGet(true);
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public void buildSerializeAndGet(boolean isStatic) throws Exception
1:72790dc:     {
1:72790dc:         final long tokMin = 0;
1:72790dc:         final long tokMax = 1000;
1:72790dc: 
1:5c4d5c7:         final TokenTree tokenTree = generateTree(tokMin, tokMax, isStatic);
1:72790dc: 
1:72790dc:         for (long i = 0; i <= tokMax; i++)
1:72790dc:         {
1:7d857b4:             TokenTree.OnDiskToken result = tokenTree.get(i, KeyConverter.instance);
1:72790dc:             Assert.assertNotNull("failed to find object for token " + i, result);
1:72790dc: 
1:7d857b4:             KeyOffsets found = result.getOffsets();
1:72790dc:             Assert.assertEquals(1, found.size());
1:7d857b4:             Assert.assertEquals(i, found.iterator().next().key);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         Assert.assertNull("found missing object", tokenTree.get(tokMax + 10, KeyConverter.instance));
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void buildSerializeIterateAndSkipDynamic() throws Exception
1:72790dc:     {
1:5c4d5c7:         buildSerializeIterateAndSkip(new DynamicTokenTreeBuilder(tokens), tokens);
1:5c4d5c7:     }
1:72790dc: 
1:5c4d5c7:     @Test
1:5c4d5c7:     public void buildSerializeIterateAndSkipStatic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         buildSerializeIterateAndSkip(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)), tokens);
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public void buildSerializeIterateAndSkip(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokens) throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         builder.finish();
1:72790dc:         final File treeFile = File.createTempFile("token-tree-iterate-test2", "tt");
1:72790dc:         treeFile.deleteOnExit();
1:72790dc: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:72790dc:         {
1:72790dc:             builder.write(writer);
1:72790dc:             writer.sync();
1:72790dc:         }
1:72790dc: 
1:72790dc:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:72790dc:         final TokenTree tokenTree = new TokenTree(new MappedBuffer(reader));
1:72790dc: 
1:7d857b4:         final RangeIterator<Long, Token> treeIterator = tokenTree.iterator(KeyConverter.instance);
1:72790dc:         final RangeIterator<Long, TokenWithOffsets> listIterator = new EntrySetSkippableIterator(tokens);
1:72790dc: 
1:72790dc:         long lastToken = 0L;
1:72790dc:         while (treeIterator.hasNext() && lastToken < 12)
1:72790dc:         {
1:72790dc:             Token treeNext = treeIterator.next();
1:72790dc:             TokenWithOffsets listNext = listIterator.next();
1:72790dc: 
1:72790dc:             Assert.assertEquals(listNext.token, (lastToken = treeNext.get()));
1:72790dc:             Assert.assertEquals(convert(listNext.offsets), convert(treeNext));
1:72790dc:         }
1:72790dc: 
1:72790dc:         treeIterator.skipTo(100548L);
1:72790dc:         listIterator.skipTo(100548L);
1:72790dc: 
1:72790dc:         while (treeIterator.hasNext() && listIterator.hasNext())
1:72790dc:         {
1:72790dc:             Token treeNext = treeIterator.next();
1:72790dc:             TokenWithOffsets listNext = listIterator.next();
1:72790dc: 
1:72790dc:             Assert.assertEquals(listNext.token, (long) treeNext.get());
1:72790dc:             Assert.assertEquals(convert(listNext.offsets), convert(treeNext));
1:72790dc: 
1:72790dc:         }
1:72790dc: 
1:72790dc:         Assert.assertFalse("Tree iterator not completed", treeIterator.hasNext());
1:72790dc:         Assert.assertFalse("List iterator not completed", listIterator.hasNext());
1:72790dc: 
1:72790dc:         reader.close();
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void skipPastEndDynamic() throws Exception
1:72790dc:     {
1:5c4d5c7:         skipPastEnd(new DynamicTokenTreeBuilder(simpleTokenMap), simpleTokenMap);
1:5c4d5c7:     }
1:72790dc: 
1:5c4d5c7:     @Test
1:5c4d5c7:     public void skipPastEndStatic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         skipPastEnd(new StaticTokenTreeBuilder(new FakeCombinedTerm(simpleTokenMap)), simpleTokenMap);
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public void skipPastEnd(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokens) throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         builder.finish();
1:72790dc:         final File treeFile = File.createTempFile("token-tree-skip-past-test", "tt");
1:72790dc:         treeFile.deleteOnExit();
1:72790dc: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:72790dc:         {
1:72790dc:             builder.write(writer);
1:72790dc:             writer.sync();
1:72790dc:         }
1:72790dc: 
1:72790dc:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:7d857b4:         final RangeIterator<Long, Token> tokenTree = new TokenTree(new MappedBuffer(reader)).iterator(KeyConverter.instance);
1:72790dc: 
1:5c4d5c7:         tokenTree.skipTo(tokens.lastKey() + 10);
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:5c4d5c7:     public void testTokenMergeDyanmic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         testTokenMerge(false);
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     @Test
1:5c4d5c7:     public void testTokenMergeStatic() throws Exception
1:5c4d5c7:     {
1:5c4d5c7:         testTokenMerge(true);
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public void testTokenMerge(boolean isStatic) throws Exception
1:72790dc:     {
1:72790dc:         final long min = 0, max = 1000;
1:72790dc: 
1:72790dc:         // two different trees with the same offsets
1:5c4d5c7:         TokenTree treeA = generateTree(min, max, isStatic);
1:5c4d5c7:         TokenTree treeB = generateTree(min, max, isStatic);
1:72790dc: 
1:7d857b4:         RangeIterator<Long, Token> a = treeA.iterator(KeyConverter.instance);
1:7d857b4:         RangeIterator<Long, Token> b = treeB.iterator(KeyConverter.instance);
1:72790dc: 
1:72790dc:         long count = min;
1:72790dc:         while (a.hasNext() && b.hasNext())
1:72790dc:         {
1:72790dc:             final Token tokenA = a.next();
1:72790dc:             final Token tokenB = b.next();
1:72790dc: 
1:72790dc:             // merging of two OnDiskToken
1:72790dc:             tokenA.merge(tokenB);
1:72790dc:             // merging with RAM Token with different offset
1:72790dc:             tokenA.merge(new TokenWithOffsets(tokenA.get(), convert(count + 1)));
1:72790dc:             // and RAM token with the same offset
1:72790dc:             tokenA.merge(new TokenWithOffsets(tokenA.get(), convert(count)));
1:72790dc: 
1:72790dc:             // should fail when trying to merge different tokens
1:72790dc:             try
1:72790dc:             {
1:7d857b4:                 long l = tokenA.get();
1:7d857b4:                 tokenA.merge(new TokenWithOffsets(l + 1, convert(count)));
1:72790dc:                 Assert.fail();
1:72790dc:             }
1:72790dc:             catch (IllegalArgumentException e)
1:72790dc:             {
1:72790dc:                 // expected
1:72790dc:             }
1:72790dc: 
1:72790dc:             final Set<Long> offsets = new TreeSet<>();
1:7d857b4:             for (RowKey key : tokenA)
1:7d857b4:                 offsets.add(LongType.instance.compose(key.decoratedKey.getKey()));
1:72790dc: 
1:72790dc:             Set<Long> expected = new TreeSet<>();
1:72790dc:             {
1:72790dc:                 expected.add(count);
1:72790dc:                 expected.add(count + 1);
1:72790dc:             }
1:72790dc: 
1:72790dc:             Assert.assertEquals(expected, offsets);
1:72790dc:             count++;
1:72790dc:         }
1:72790dc: 
1:72790dc:         Assert.assertEquals(max, count - 1);
1:72790dc:     }
1:72790dc: 
1:72790dc:     @Test
1:72790dc:     public void testEntryTypeOrdinalLookup()
1:72790dc:     {
1:72790dc:         Assert.assertEquals(EntryType.SIMPLE, EntryType.of(EntryType.SIMPLE.ordinal()));
1:72790dc:         Assert.assertEquals(EntryType.PACKED, EntryType.of(EntryType.PACKED.ordinal()));
1:72790dc:         Assert.assertEquals(EntryType.FACTORED, EntryType.of(EntryType.FACTORED.ordinal()));
1:72790dc:         Assert.assertEquals(EntryType.OVERFLOW, EntryType.of(EntryType.OVERFLOW.ordinal()));
1:72790dc:     }
1:020dd2d: 
1:020dd2d:     @Test
1:020dd2d:     public void testMergingOfEqualTokenTrees() throws Exception
1:020dd2d:     {
1:020dd2d:         testMergingOfEqualTokenTrees(simpleTokenMap);
1:020dd2d:         testMergingOfEqualTokenTrees(bigTokensMap);
1:020dd2d:     }
1:020dd2d: 
1:7d857b4:     public void testMergingOfEqualTokenTrees(SortedMap<Long, KeyOffsets> tokensMap) throws Exception
1:020dd2d:     {
1:020dd2d:         TokenTreeBuilder tokensA = new DynamicTokenTreeBuilder(tokensMap);
1:020dd2d:         TokenTreeBuilder tokensB = new DynamicTokenTreeBuilder(tokensMap);
1:020dd2d: 
1:020dd2d:         TokenTree a = buildTree(tokensA);
1:020dd2d:         TokenTree b = buildTree(tokensB);
1:020dd2d: 
1:020dd2d:         TokenTreeBuilder tokensC = new StaticTokenTreeBuilder(new CombinedTerm(null, null)
1:020dd2d:         {
1:020dd2d:             public RangeIterator<Long, Token> getTokenIterator()
1:020dd2d:             {
1:020dd2d:                 RangeIterator.Builder<Long, Token> union = RangeUnionIterator.builder();
1:7d857b4:                 union.add(a.iterator(KeyConverter.instance));
1:7d857b4:                 union.add(b.iterator(KeyConverter.instance));
1:020dd2d: 
1:020dd2d:                 return union.build();
1:020dd2d:             }
1:020dd2d:         });
1:020dd2d: 
1:020dd2d:         TokenTree c = buildTree(tokensC);
1:020dd2d:         Assert.assertEquals(tokensMap.size(), c.getCount());
1:7d857b4:         Iterator<Token> tokenIterator = c.iterator(KeyConverter.instance);
1:7d857b4:         Iterator<Map.Entry<Long, KeyOffsets>> listIterator = tokensMap.entrySet().iterator();
1:020dd2d: 
1:020dd2d:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:020dd2d:         {
1:020dd2d:             Token treeNext = tokenIterator.next();
1:7d857b4:             Map.Entry<Long, KeyOffsets> listNext = listIterator.next();
1:020dd2d: 
1:020dd2d:             Assert.assertEquals(listNext.getKey(), treeNext.get());
1:020dd2d:             Assert.assertEquals(convert(listNext.getValue()), convert(treeNext));
1:020dd2d:         }
1:020dd2d: 
1:7d857b4:         for (Map.Entry<Long, KeyOffsets> entry : tokensMap.entrySet())
1:020dd2d:         {
1:7d857b4:             TokenTree.OnDiskToken result = c.get(entry.getKey(), KeyConverter.instance);
1:020dd2d:             Assert.assertNotNull("failed to find object for token " + entry.getKey(), result);
1:7d857b4:             KeyOffsets found = result.getOffsets();
1:020dd2d:             Assert.assertEquals(entry.getValue(), found);
1:020dd2d: 
1:020dd2d:         }
1:020dd2d:     }
1:020dd2d: 
1:020dd2d: 
1:7d857b4:     private TokenTree buildTree(TokenTreeBuilder builder) throws Exception
1:020dd2d:     {
1:020dd2d:         builder.finish();
1:020dd2d:         final File treeFile = File.createTempFile("token-tree-", "db");
1:020dd2d:         treeFile.deleteOnExit();
1:020dd2d: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:020dd2d:         {
1:020dd2d:             builder.write(writer);
1:020dd2d:             writer.sync();
1:020dd2d:         }
1:020dd2d: 
1:020dd2d:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:020dd2d:         return new TokenTree(new MappedBuffer(reader));
1:020dd2d:     }
1:020dd2d: 
1:72790dc:     private static class EntrySetSkippableIterator extends RangeIterator<Long, TokenWithOffsets>
1:72790dc:     {
1:7d857b4:         private final PeekingIterator<Map.Entry<Long, KeyOffsets>> elements;
1:72790dc: 
1:7d857b4:         EntrySetSkippableIterator(SortedMap<Long, KeyOffsets> elms)
1:72790dc:         {
1:72790dc:             super(elms.firstKey(), elms.lastKey(), elms.size());
1:72790dc:             elements = Iterators.peekingIterator(elms.entrySet().iterator());
1:72790dc:         }
1:72790dc: 
2:72790dc:         @Override
1:72790dc:         public TokenWithOffsets computeNext()
1:5c4d5c7:         {
1:72790dc:             if (!elements.hasNext())
1:72790dc:                 return endOfData();
1:72790dc: 
1:7d857b4:             Map.Entry<Long, KeyOffsets> next = elements.next();
1:72790dc:             return new TokenWithOffsets(next.getKey(), next.getValue());
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         protected void performSkipTo(Long nextToken)
1:72790dc:         {
1:72790dc:             while (elements.hasNext())
1:72790dc:             {
1:72790dc:                 if (Long.compare(elements.peek().getKey(), nextToken) >= 0)
1:72790dc:                 {
1:72790dc:                     break;
1:72790dc:                 }
1:72790dc: 
1:72790dc:                 elements.next();
1:72790dc:             }
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         public void close() throws IOException
1:72790dc:         {
1:72790dc:             // nothing to do here
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:5c4d5c7:     public static class FakeCombinedTerm extends CombinedTerm
1:5c4d5c7:     {
1:7d857b4:         private final SortedMap<Long, KeyOffsets> tokens;
1:5c4d5c7: 
1:7d857b4:         public FakeCombinedTerm(SortedMap<Long, KeyOffsets> tokens)
1:5c4d5c7:         {
1:5c4d5c7:             super(null, null);
1:5c4d5c7:             this.tokens = tokens;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public RangeIterator<Long, Token> getTokenIterator()
1:5c4d5c7:         {
1:5c4d5c7:             return new TokenMapIterator(tokens);
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public static class TokenMapIterator extends RangeIterator<Long, Token>
1:5c4d5c7:     {
1:7d857b4:         public final Iterator<Map.Entry<Long, KeyOffsets>> iterator;
1:5c4d5c7: 
1:7d857b4:         public TokenMapIterator(SortedMap<Long, KeyOffsets> tokens)
1:5c4d5c7:         {
1:5c4d5c7:             super(tokens.firstKey(), tokens.lastKey(), tokens.size());
1:5c4d5c7:             iterator = tokens.entrySet().iterator();
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public Token computeNext()
1:5c4d5c7:         {
1:5c4d5c7:             if (!iterator.hasNext())
1:5c4d5c7:                 return endOfData();
1:5c4d5c7: 
1:7d857b4:             Map.Entry<Long, KeyOffsets> entry = iterator.next();
1:5c4d5c7:             return new TokenWithOffsets(entry.getKey(), entry.getValue());
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void close() throws IOException
1:5c4d5c7:         {
1:5c4d5c7: 
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void performSkipTo(Long next)
1:5c4d5c7:         {
1:5c4d5c7:             throw new UnsupportedOperationException();
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:72790dc:     public static class TokenWithOffsets extends Token
1:72790dc:     {
1:7d857b4:         private final KeyOffsets offsets;
1:72790dc: 
1:7d857b4:         public TokenWithOffsets(Long token, final KeyOffsets offsets)
1:72790dc:         {
1:72790dc:             super(token);
1:72790dc:             this.offsets = offsets;
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:7d857b4:         public KeyOffsets getOffsets()
1:72790dc:         {
1:5c4d5c7:             return offsets;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         @Override
1:72790dc:         public void merge(CombinedValue<Long> other)
1:72790dc:         {}
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         public int compareTo(CombinedValue<Long> o)
1:72790dc:         {
1:72790dc:             return Long.compare(token, o.get());
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         public boolean equals(Object other)
1:72790dc:         {
1:72790dc:             if (!(other instanceof TokenWithOffsets))
1:72790dc:                 return false;
1:72790dc: 
1:72790dc:             TokenWithOffsets o = (TokenWithOffsets) other;
1:72790dc:             return token == o.token && offsets.equals(o.offsets);
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         public int hashCode()
1:72790dc:         {
1:72790dc:             return new HashCodeBuilder().append(token).build();
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:72790dc:         public String toString()
1:72790dc:         {
1:72790dc:             return String.format("TokenValue(token: %d, offsets: %s)", token, offsets);
1:72790dc:         }
1:72790dc: 
1:72790dc:         @Override
1:7d857b4:         public Iterator<RowKey> iterator()
1:72790dc:         {
1:7d857b4:             List<RowKey> keys = new ArrayList<>(offsets.size());
1:7d857b4:             for (LongObjectCursor<long[]> offset : offsets)
1:7d857b4:                 for (long l : offset.value)
1:7d857b4:                     keys.add(KeyConverter.instance.getRowKey(offset.key, l));
1:72790dc:             return keys.iterator();
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:7d857b4:     private static Set<RowKey> convert(KeyOffsets offsets)
1:72790dc:     {
1:7d857b4:         Set<RowKey> keys = new HashSet<>();
1:7d857b4:         for (LongObjectCursor<long[]> offset : offsets)
1:7d857b4:             for (long l : offset.value)
1:7d857b4:                 keys.add(new RowKey(KeyConverter.dk(offset.key),
1:7d857b4:                                     KeyConverter.ck(l),
1:7d857b4:                                     CLUSTERING_COMPARATOR));
1:72790dc: 
1:72790dc:         return keys;
1:72790dc:     }
1:72790dc: 
1:7d857b4:     private static Set<RowKey> convert(Token results)
1:72790dc:     {
1:7d857b4:         Set<RowKey> keys = new HashSet<>();
1:7d857b4:         for (RowKey key : results)
1:72790dc:             keys.add(key);
1:72790dc: 
1:72790dc:         return keys;
1:72790dc:     }
1:72790dc: 
1:7d857b4:     private static KeyOffsets convert(long... values)
1:72790dc:     {
1:7d857b4:         KeyOffsets result = new KeyOffsets(values.length);
1:72790dc:         for (long v : values)
1:7d857b4:             result.put(v, KeyOffsets.asArray(v + 5));
1:72790dc: 
1:72790dc:         return result;
1:72790dc:     }
1:72790dc: 
1:7d857b4:     private TokenTree generateTree(final long minToken, final long maxToken, boolean isStatic) throws IOException
1:72790dc:     {
1:7d857b4:         final SortedMap<Long, KeyOffsets> toks = new TreeMap<Long, KeyOffsets>()
1:72790dc:         {{
1:7d857b4:             for (long i = minToken; i <= maxToken; i++)
1:7d857b4:             {
1:7d857b4:                 KeyOffsets offsetSet = new KeyOffsets();
1:7d857b4:                 offsetSet.put(i, KeyOffsets.asArray(i + 5));
1:7d857b4:                 put(i, offsetSet);
1:7d857b4:             }
1:72790dc:         }};
1:72790dc: 
1:5c4d5c7:         final TokenTreeBuilder builder = isStatic ? new StaticTokenTreeBuilder(new FakeCombinedTerm(toks)) : new DynamicTokenTreeBuilder(toks);
1:5c4d5c7:         builder.finish();
1:72790dc:         final File treeFile = File.createTempFile("token-tree-get-test", "tt");
1:72790dc:         treeFile.deleteOnExit();
1:72790dc: 
1:fb22109:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
1:72790dc:         {
1:72790dc:             builder.write(writer);
1:72790dc:             writer.sync();
1:72790dc:         }
1:72790dc: 
1:72790dc:         RandomAccessReader reader = null;
1:72790dc: 
1:72790dc:         try
1:72790dc:         {
1:72790dc:             reader = RandomAccessReader.open(treeFile);
1:72790dc:             return new TokenTree(new MappedBuffer(reader));
1:72790dc:         }
1:72790dc:         finally
1:72790dc:         {
1:72790dc:             FileUtils.closeQuietly(reader);
1:72790dc:         }
1:72790dc:     }
1:72790dc: }
============================================================================
author:Alex Petrov
-------------------------------------------------------------------------------
commit:7d857b4
/////////////////////////////////////////////////////////////////////////
1: import com.carrotsearch.hppc.cursors.LongObjectCursor;
1: import org.apache.cassandra.db.ClusteringComparator;
1: import org.apache.cassandra.db.marshal.LongType;
1: import org.apache.cassandra.index.sasi.utils.*;
1: import org.apache.cassandra.io.util.*;
1:     private static final ClusteringComparator CLUSTERING_COMPARATOR = new ClusteringComparator(LongType.instance);
/////////////////////////////////////////////////////////////////////////
1:     static KeyOffsets singleOffset = new KeyOffsets() {{ put(1L, KeyOffsets.asArray(10L)); }};
1:     static KeyOffsets bigSingleOffset = new KeyOffsets() {{ put(2147521562L, KeyOffsets.asArray(10)); }};
1:     static KeyOffsets shortPackableCollision = new KeyOffsets() {{
1:         put(2L, KeyOffsets.asArray(10));
1:         put(3L, KeyOffsets.asArray(10));
1:     }}; // can pack two shorts
1:     static KeyOffsets intPackableCollision = new KeyOffsets()
1:     {{
1:         put(6L, KeyOffsets.asArray(10));
1:         put(((long) Short.MAX_VALUE) + 1, KeyOffsets.asArray(10));
1:     }}; // can pack int & short
1:     static KeyOffsets multiCollision = new KeyOffsets()
1:     {{
1:         put(3L, KeyOffsets.asArray(10));
1:         put(4L, KeyOffsets.asArray(10));
1:         put(5L, KeyOffsets.asArray(10));
1:     }}; // can't pack
1:     static KeyOffsets unpackableCollision = new KeyOffsets()
1:     {{
1:         put(((long) Short.MAX_VALUE) + 1, KeyOffsets.asArray(10));
1:         put(((long) Short.MAX_VALUE) + 2, KeyOffsets.asArray(10));
1:     }}; // can't pack
1:     final static SortedMap<Long, KeyOffsets> simpleTokenMap = new TreeMap<Long, KeyOffsets>()
/////////////////////////////////////////////////////////////////////////
1:     final static SortedMap<Long, KeyOffsets> bigTokensMap = new TreeMap<Long, KeyOffsets>()
1:     final static SortedMap<Long, KeyOffsets> collidingTokensMap = new TreeMap<Long, KeyOffsets>()
1:         put(1L, singleOffset);
1:         put(7L, singleOffset);
1:         put(8L, singleOffset);
1:     final static SortedMap<Long, KeyOffsets> tokens = bigTokensMap;
/////////////////////////////////////////////////////////////////////////
1:     public void buildSerializeAndIterate(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokenMap) throws Exception
/////////////////////////////////////////////////////////////////////////
1:         final Iterator<Token> tokenIterator = tokenTree.iterator(KeyConverter.instance);
1:         final Iterator<Map.Entry<Long, KeyOffsets>> listIterator = tokenMap.entrySet().iterator();
1:             Map.Entry<Long, KeyOffsets> listNext = listIterator.next();
/////////////////////////////////////////////////////////////////////////
1:             TokenTree.OnDiskToken result = tokenTree.get(i, KeyConverter.instance);
1:             KeyOffsets found = result.getOffsets();
1:             Assert.assertEquals(i, found.iterator().next().key);
1:         Assert.assertNull("found missing object", tokenTree.get(tokMax + 10, KeyConverter.instance));
/////////////////////////////////////////////////////////////////////////
1:     public void buildSerializeIterateAndSkip(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokens) throws Exception
/////////////////////////////////////////////////////////////////////////
1:         final RangeIterator<Long, Token> treeIterator = tokenTree.iterator(KeyConverter.instance);
/////////////////////////////////////////////////////////////////////////
1:     public void skipPastEnd(TokenTreeBuilder builder, SortedMap<Long, KeyOffsets> tokens) throws Exception
/////////////////////////////////////////////////////////////////////////
1:         final RangeIterator<Long, Token> tokenTree = new TokenTree(new MappedBuffer(reader)).iterator(KeyConverter.instance);
/////////////////////////////////////////////////////////////////////////
1:         RangeIterator<Long, Token> a = treeA.iterator(KeyConverter.instance);
1:         RangeIterator<Long, Token> b = treeB.iterator(KeyConverter.instance);
/////////////////////////////////////////////////////////////////////////
1:                 long l = tokenA.get();
1:                 tokenA.merge(new TokenWithOffsets(l + 1, convert(count)));
/////////////////////////////////////////////////////////////////////////
1:             for (RowKey key : tokenA)
1:                 offsets.add(LongType.instance.compose(key.decoratedKey.getKey()));
/////////////////////////////////////////////////////////////////////////
1:     public void testMergingOfEqualTokenTrees(SortedMap<Long, KeyOffsets> tokensMap) throws Exception
/////////////////////////////////////////////////////////////////////////
1:                 union.add(a.iterator(KeyConverter.instance));
1:                 union.add(b.iterator(KeyConverter.instance));
/////////////////////////////////////////////////////////////////////////
1:         Iterator<Token> tokenIterator = c.iterator(KeyConverter.instance);
1:         Iterator<Map.Entry<Long, KeyOffsets>> listIterator = tokensMap.entrySet().iterator();
1:             Map.Entry<Long, KeyOffsets> listNext = listIterator.next();
1:         for (Map.Entry<Long, KeyOffsets> entry : tokensMap.entrySet())
1:             TokenTree.OnDiskToken result = c.get(entry.getKey(), KeyConverter.instance);
1:             KeyOffsets found = result.getOffsets();
1:     private TokenTree buildTree(TokenTreeBuilder builder) throws Exception
/////////////////////////////////////////////////////////////////////////
1:         private final PeekingIterator<Map.Entry<Long, KeyOffsets>> elements;
1:         EntrySetSkippableIterator(SortedMap<Long, KeyOffsets> elms)
/////////////////////////////////////////////////////////////////////////
1:             Map.Entry<Long, KeyOffsets> next = elements.next();
/////////////////////////////////////////////////////////////////////////
1:         private final SortedMap<Long, KeyOffsets> tokens;
1:         public FakeCombinedTerm(SortedMap<Long, KeyOffsets> tokens)
/////////////////////////////////////////////////////////////////////////
1:         public final Iterator<Map.Entry<Long, KeyOffsets>> iterator;
1:         public TokenMapIterator(SortedMap<Long, KeyOffsets> tokens)
/////////////////////////////////////////////////////////////////////////
1:             Map.Entry<Long, KeyOffsets> entry = iterator.next();
/////////////////////////////////////////////////////////////////////////
1:         private final KeyOffsets offsets;
1:         public TokenWithOffsets(Long token, final KeyOffsets offsets)
1:         public KeyOffsets getOffsets()
/////////////////////////////////////////////////////////////////////////
1:         public Iterator<RowKey> iterator()
1:             List<RowKey> keys = new ArrayList<>(offsets.size());
1:             for (LongObjectCursor<long[]> offset : offsets)
1:                 for (long l : offset.value)
1:                     keys.add(KeyConverter.instance.getRowKey(offset.key, l));
1:     private static Set<RowKey> convert(KeyOffsets offsets)
1:         Set<RowKey> keys = new HashSet<>();
1:         for (LongObjectCursor<long[]> offset : offsets)
1:             for (long l : offset.value)
1:                 keys.add(new RowKey(KeyConverter.dk(offset.key),
1:                                     KeyConverter.ck(l),
1:                                     CLUSTERING_COMPARATOR));
1:     private static Set<RowKey> convert(Token results)
1:         Set<RowKey> keys = new HashSet<>();
1:         for (RowKey key : results)
1:     private static KeyOffsets convert(long... values)
1:         KeyOffsets result = new KeyOffsets(values.length);
1:             result.put(v, KeyOffsets.asArray(v + 5));
1:     private TokenTree generateTree(final long minToken, final long maxToken, boolean isStatic) throws IOException
1:         final SortedMap<Long, KeyOffsets> toks = new TreeMap<Long, KeyOffsets>()
1:             for (long i = minToken; i <= maxToken; i++)
1:             {
1:                 KeyOffsets offsetSet = new KeyOffsets();
1:                 offsetSet.put(i, KeyOffsets.asArray(i + 5));
1:                 put(i, offsetSet);
1:             }
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.apache.cassandra.config.DatabaseDescriptor;
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.junit.BeforeClass;
/////////////////////////////////////////////////////////////////////////
1:     @BeforeClass
1:     public static void setupDD()
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
1: 
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:fb22109
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.SequentialWriterOption;
/////////////////////////////////////////////////////////////////////////
1:     final static SequentialWriterOption DEFAULT_OPT = SequentialWriterOption.newBuilder().bufferSize(4096).build();
1: 
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new SequentialWriter(treeFile, DEFAULT_OPT))
author:Jordan West
-------------------------------------------------------------------------------
commit:020dd2d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.index.sasi.utils.RangeUnionIterator;
/////////////////////////////////////////////////////////////////////////
0:     static LongSet bigSingleOffset = new LongOpenHashSet() {{ add(2147521562L); }};
/////////////////////////////////////////////////////////////////////////
1:     @Test
1:     public void testMergingOfEqualTokenTrees() throws Exception
1:     {
1:         testMergingOfEqualTokenTrees(simpleTokenMap);
1:         testMergingOfEqualTokenTrees(bigTokensMap);
1:     }
1: 
0:     public void testMergingOfEqualTokenTrees(SortedMap<Long, LongSet> tokensMap) throws Exception
1:     {
1:         TokenTreeBuilder tokensA = new DynamicTokenTreeBuilder(tokensMap);
1:         TokenTreeBuilder tokensB = new DynamicTokenTreeBuilder(tokensMap);
1: 
1:         TokenTree a = buildTree(tokensA);
1:         TokenTree b = buildTree(tokensB);
1: 
1:         TokenTreeBuilder tokensC = new StaticTokenTreeBuilder(new CombinedTerm(null, null)
1:         {
1:             public RangeIterator<Long, Token> getTokenIterator()
1:             {
1:                 RangeIterator.Builder<Long, Token> union = RangeUnionIterator.builder();
0:                 union.add(a.iterator(new KeyConverter()));
0:                 union.add(b.iterator(new KeyConverter()));
1: 
1:                 return union.build();
1:             }
1:         });
1: 
1:         TokenTree c = buildTree(tokensC);
1:         Assert.assertEquals(tokensMap.size(), c.getCount());
1: 
0:         Iterator<Token> tokenIterator = c.iterator(KEY_CONVERTER);
0:         Iterator<Map.Entry<Long, LongSet>> listIterator = tokensMap.entrySet().iterator();
1:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:         {
1:             Token treeNext = tokenIterator.next();
0:             Map.Entry<Long, LongSet> listNext = listIterator.next();
1: 
1:             Assert.assertEquals(listNext.getKey(), treeNext.get());
1:             Assert.assertEquals(convert(listNext.getValue()), convert(treeNext));
1:         }
1: 
0:         for (Map.Entry<Long, LongSet> entry : tokensMap.entrySet())
1:         {
0:             TokenTree.OnDiskToken result = c.get(entry.getKey(), KEY_CONVERTER);
1:             Assert.assertNotNull("failed to find object for token " + entry.getKey(), result);
1: 
0:             LongSet found = result.getOffsets();
1:             Assert.assertEquals(entry.getValue(), found);
1: 
1:         }
1:     }
1: 
1: 
0:     private static TokenTree buildTree(TokenTreeBuilder builder) throws Exception
1:     {
1:         builder.finish();
1:         final File treeFile = File.createTempFile("token-tree-", "db");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:         return new TokenTree(new MappedBuffer(reader));
1:     }
1: 
commit:5c4d5c7
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.index.sasi.utils.CombinedTerm;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     public void testSerializedSizeDynamic() throws Exception
1:         testSerializedSize(new DynamicTokenTreeBuilder(tokens));
1:     public void testSerializedSizeStatic() throws Exception
1:         testSerializedSize(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)));
1:     public void testSerializedSize(final TokenTreeBuilder builder) throws Exception
1:     {
1:         builder.finish();
/////////////////////////////////////////////////////////////////////////
1:         reader.close();
1:     public void buildSerializeAndIterateDynamic() throws Exception
1:         buildSerializeAndIterate(new DynamicTokenTreeBuilder(simpleTokenMap), simpleTokenMap);
1:     }
1:     @Test
1:     public void buildSerializeAndIterateStatic() throws Exception
1:     {
1:         buildSerializeAndIterate(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)), tokens);
1:     }
1: 
1: 
0:     public void buildSerializeAndIterate(TokenTreeBuilder builder, SortedMap<Long, LongSet> tokenMap) throws Exception
1:     {
1: 
1:         builder.finish();
/////////////////////////////////////////////////////////////////////////
0:         final Iterator<Map.Entry<Long, LongSet>> listIterator = tokenMap.entrySet().iterator();
/////////////////////////////////////////////////////////////////////////
1:     public void buildSerializeAndGetDynamic() throws Exception
1:     {
1:         buildSerializeAndGet(false);
1:     }
1: 
1:     @Test
1:     public void buildSerializeAndGetStatic() throws Exception
1:     {
1:         buildSerializeAndGet(true);
1:     }
1: 
1:     public void buildSerializeAndGet(boolean isStatic) throws Exception
1:         final TokenTree tokenTree = generateTree(tokMin, tokMax, isStatic);
0:             LongSet found = result.getOffsets();
/////////////////////////////////////////////////////////////////////////
1:     public void buildSerializeIterateAndSkipDynamic() throws Exception
1:         buildSerializeIterateAndSkip(new DynamicTokenTreeBuilder(tokens), tokens);
1:     }
1:     @Test
1:     public void buildSerializeIterateAndSkipStatic() throws Exception
1:     {
1:         buildSerializeIterateAndSkip(new StaticTokenTreeBuilder(new FakeCombinedTerm(tokens)), tokens);
1:     }
1: 
0:     public void buildSerializeIterateAndSkip(TokenTreeBuilder builder, SortedMap<Long, LongSet> tokens) throws Exception
1:     {
1:         builder.finish();
/////////////////////////////////////////////////////////////////////////
1:     public void skipPastEndDynamic() throws Exception
1:         skipPastEnd(new DynamicTokenTreeBuilder(simpleTokenMap), simpleTokenMap);
1:     }
1:     @Test
1:     public void skipPastEndStatic() throws Exception
1:     {
1:         skipPastEnd(new StaticTokenTreeBuilder(new FakeCombinedTerm(simpleTokenMap)), simpleTokenMap);
1:     }
1: 
0:     public void skipPastEnd(TokenTreeBuilder builder, SortedMap<Long, LongSet> tokens) throws Exception
1:     {
1:         builder.finish();
/////////////////////////////////////////////////////////////////////////
1:         tokenTree.skipTo(tokens.lastKey() + 10);
1:     public void testTokenMergeDyanmic() throws Exception
1:     {
1:         testTokenMerge(false);
1:     }
1: 
1:     @Test
1:     public void testTokenMergeStatic() throws Exception
1:     {
1:         testTokenMerge(true);
1:     }
1: 
1:     public void testTokenMerge(boolean isStatic) throws Exception
1:         TokenTree treeA = generateTree(min, max, isStatic);
1:         TokenTree treeB = generateTree(min, max, isStatic);
/////////////////////////////////////////////////////////////////////////
1:     public static class FakeCombinedTerm extends CombinedTerm
1:     {
0:         private final SortedMap<Long, LongSet> tokens;
1: 
0:         public FakeCombinedTerm(SortedMap<Long, LongSet> tokens)
1:         {
1:             super(null, null);
1:             this.tokens = tokens;
1:         }
1: 
1:         public RangeIterator<Long, Token> getTokenIterator()
1:         {
1:             return new TokenMapIterator(tokens);
1:         }
1:     }
1: 
1:     public static class TokenMapIterator extends RangeIterator<Long, Token>
1:     {
0:         public final Iterator<Map.Entry<Long, LongSet>> iterator;
1: 
0:         public TokenMapIterator(SortedMap<Long, LongSet> tokens)
1:         {
1:             super(tokens.firstKey(), tokens.lastKey(), tokens.size());
1:             iterator = tokens.entrySet().iterator();
1:         }
1: 
1:         public Token computeNext()
1:         {
1:             if (!iterator.hasNext())
1:                 return endOfData();
1: 
0:             Map.Entry<Long, LongSet> entry = iterator.next();
1:             return new TokenWithOffsets(entry.getKey(), entry.getValue());
1:         }
1: 
1:         public void close() throws IOException
1:         {
1: 
1:         }
1: 
1:         public void performSkipTo(Long next)
1:         {
1:             throw new UnsupportedOperationException();
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
0:         public LongSet getOffsets()
1:         {
1:             return offsets;
1:         }
1: 
1:         @Override
/////////////////////////////////////////////////////////////////////////
0:     private static TokenTree generateTree(final long minToken, final long maxToken, boolean isStatic) throws IOException
/////////////////////////////////////////////////////////////////////////
1:         final TokenTreeBuilder builder = isStatic ? new StaticTokenTreeBuilder(new FakeCombinedTerm(toks)) : new DynamicTokenTreeBuilder(toks);
1:         builder.finish();
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:72790dc
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.index.sasi.disk;
1: 
1: import java.io.File;
1: import java.io.IOException;
0: import java.nio.ByteBuffer;
1: import java.util.*;
1: 
1: import com.google.common.collect.Iterators;
1: import com.google.common.collect.PeekingIterator;
1: import org.apache.cassandra.db.BufferDecoratedKey;
1: import org.apache.cassandra.db.DecoratedKey;
1: import org.apache.cassandra.dht.Murmur3Partitioner;
1: import org.apache.cassandra.index.sasi.disk.TokenTreeBuilder.EntryType;
0: import org.apache.cassandra.index.sasi.utils.CombinedValue;
0: import org.apache.cassandra.index.sasi.utils.MappedBuffer;
0: import org.apache.cassandra.index.sasi.utils.RangeIterator;
0: import org.apache.cassandra.db.marshal.LongType;
0: import org.apache.cassandra.io.compress.BufferType;
0: import org.apache.cassandra.io.util.FileUtils;
0: import org.apache.cassandra.utils.MurmurHash;
0: import org.apache.cassandra.utils.Pair;
0: import org.apache.cassandra.io.util.RandomAccessReader;
0: import org.apache.cassandra.io.util.SequentialWriter;
1: 
1: import junit.framework.Assert;
1: import org.junit.Test;
1: import org.apache.commons.lang3.builder.HashCodeBuilder;
0: import com.carrotsearch.hppc.LongOpenHashSet;
0: import com.carrotsearch.hppc.LongSet;
0: import com.carrotsearch.hppc.cursors.LongCursor;
0: import com.google.common.base.Function;
1: 
1: public class TokenTreeTest
1: {
0:     private static final Function<Long, DecoratedKey> KEY_CONVERTER = new KeyConverter();
1: 
0:     static LongSet singleOffset = new LongOpenHashSet() {{ add(1); }};
0:     static LongSet bigSingleOffset = new LongOpenHashSet() {{ add(((long) Integer.MAX_VALUE) + 10); }};
0:     static LongSet shortPackableCollision = new LongOpenHashSet() {{ add(2L); add(3L); }}; // can pack two shorts
0:     static LongSet intPackableCollision = new LongOpenHashSet() {{ add(6L); add(((long) Short.MAX_VALUE) + 1); }}; // can pack int & short
0:     static LongSet multiCollision =  new LongOpenHashSet() {{ add(3L); add(4L); add(5L); }}; // can't pack
0:     static LongSet unpackableCollision = new LongOpenHashSet() {{ add(((long) Short.MAX_VALUE) + 1); add(((long) Short.MAX_VALUE) + 2); }}; // can't pack
1: 
0:     final static SortedMap<Long, LongSet> simpleTokenMap = new TreeMap<Long, LongSet>()
1:     {{
1:             put(1L, bigSingleOffset); put(3L, shortPackableCollision); put(4L, intPackableCollision); put(6L, singleOffset);
1:             put(9L, multiCollision); put(10L, unpackableCollision); put(12L, singleOffset); put(13L, singleOffset);
1:             put(15L, singleOffset); put(16L, singleOffset); put(20L, singleOffset); put(22L, singleOffset);
1:             put(25L, singleOffset); put(26L, singleOffset); put(27L, singleOffset); put(28L, singleOffset);
1:             put(40L, singleOffset); put(50L, singleOffset); put(100L, singleOffset); put(101L, singleOffset);
1:             put(102L, singleOffset); put(103L, singleOffset); put(108L, singleOffset); put(110L, singleOffset);
1:             put(112L, singleOffset); put(115L, singleOffset); put(116L, singleOffset); put(120L, singleOffset);
1:             put(121L, singleOffset); put(122L, singleOffset); put(123L, singleOffset); put(125L, singleOffset);
1:     }};
1: 
0:     final static SortedMap<Long, LongSet> bigTokensMap = new TreeMap<Long, LongSet>()
1:     {{
1:             for (long i = 0; i < 1000000; i++)
1:                 put(i, singleOffset);
1:     }};
1: 
0:     final static SortedMap<Long, LongSet> collidingTokensMap = new TreeMap<Long, LongSet>()
1:     {{
0:             put(1L, singleOffset); put(7L, singleOffset); put(8L, singleOffset);
1:     }};
1: 
0:     final static SortedMap<Long, LongSet> tokens = bigTokensMap;
1: 
1:     @Test
0:     public void buildAndIterate() throws Exception
1:     {
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(tokens).finish();
0:         final Iterator<Pair<Long, LongSet>> tokenIterator = builder.iterator();
0:         final Iterator<Map.Entry<Long, LongSet>> listIterator = tokens.entrySet().iterator();
1:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:         {
0:             Pair<Long, LongSet> tokenNext = tokenIterator.next();
0:             Map.Entry<Long, LongSet> listNext = listIterator.next();
1: 
0:             Assert.assertEquals(listNext.getKey(), tokenNext.left);
0:             Assert.assertEquals(listNext.getValue(), tokenNext.right);
1:         }
1: 
1:         Assert.assertFalse("token iterator not finished", tokenIterator.hasNext());
1:         Assert.assertFalse("list iterator not finished", listIterator.hasNext());
1:     }
1: 
1:     @Test
0:     public void buildWithMultipleMapsAndIterate() throws Exception
1:     {
0:         final SortedMap<Long, LongSet> merged = new TreeMap<>();
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(simpleTokenMap).finish();
0:         builder.add(collidingTokensMap);
1: 
0:         merged.putAll(collidingTokensMap);
0:         for (Map.Entry<Long, LongSet> entry : simpleTokenMap.entrySet())
1:         {
0:             if (merged.containsKey(entry.getKey()))
1:             {
0:                 LongSet mergingOffsets  = entry.getValue();
0:                 LongSet existingOffsets = merged.get(entry.getKey());
1: 
0:                 if (mergingOffsets.equals(existingOffsets))
0:                     continue;
1: 
0:                 Set<Long> mergeSet = new HashSet<>();
0:                 for (LongCursor merging : mergingOffsets)
0:                     mergeSet.add(merging.value);
1: 
0:                 for (LongCursor existing : existingOffsets)
0:                     mergeSet.add(existing.value);
1: 
0:                 LongSet mergedResults = new LongOpenHashSet();
0:                 for (Long result : mergeSet)
0:                     mergedResults.add(result);
1: 
0:                 merged.put(entry.getKey(), mergedResults);
1:             }
0:             else
1:             {
0:                 merged.put(entry.getKey(), entry.getValue());
1:             }
1:         }
1: 
0:         final Iterator<Pair<Long, LongSet>> tokenIterator = builder.iterator();
0:         final Iterator<Map.Entry<Long, LongSet>> listIterator = merged.entrySet().iterator();
1:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:         {
0:             Pair<Long, LongSet> tokenNext = tokenIterator.next();
0:             Map.Entry<Long, LongSet> listNext = listIterator.next();
1: 
0:             Assert.assertEquals(listNext.getKey(), tokenNext.left);
0:             Assert.assertEquals(listNext.getValue(), tokenNext.right);
1:         }
1: 
1:         Assert.assertFalse("token iterator not finished", tokenIterator.hasNext());
1:         Assert.assertFalse("list iterator not finished", listIterator.hasNext());
1: 
1:     }
1: 
1:     @Test
0:     public void testSerializedSize() throws Exception
1:     {
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(tokens).finish();
1: 
1:         final File treeFile = File.createTempFile("token-tree-size-test", "tt");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:         Assert.assertEquals((int) reader.bytesRemaining(), builder.serializedSize());
1:     }
1: 
1:     @Test
0:     public void buildSerializeAndIterate() throws Exception
1:     {
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(simpleTokenMap).finish();
1: 
1:         final File treeFile = File.createTempFile("token-tree-iterate-test1", "tt");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:         final TokenTree tokenTree = new TokenTree(new MappedBuffer(reader));
1: 
0:         final Iterator<Token> tokenIterator = tokenTree.iterator(KEY_CONVERTER);
0:         final Iterator<Map.Entry<Long, LongSet>> listIterator = simpleTokenMap.entrySet().iterator();
1:         while (tokenIterator.hasNext() && listIterator.hasNext())
1:         {
1:             Token treeNext = tokenIterator.next();
0:             Map.Entry<Long, LongSet> listNext = listIterator.next();
1: 
1:             Assert.assertEquals(listNext.getKey(), treeNext.get());
1:             Assert.assertEquals(convert(listNext.getValue()), convert(treeNext));
1:         }
1: 
1:         Assert.assertFalse("token iterator not finished", tokenIterator.hasNext());
1:         Assert.assertFalse("list iterator not finished", listIterator.hasNext());
1: 
1:         reader.close();
1:     }
1: 
1:     @Test
0:     public void buildSerializeAndGet() throws Exception
1:     {
1:         final long tokMin = 0;
1:         final long tokMax = 1000;
1: 
0:         final TokenTree tokenTree = generateTree(tokMin, tokMax);
1: 
1:         for (long i = 0; i <= tokMax; i++)
1:         {
0:             TokenTree.OnDiskToken result = tokenTree.get(i, KEY_CONVERTER);
1:             Assert.assertNotNull("failed to find object for token " + i, result);
1: 
0:             Set<Long> found = result.getOffsets();
1:             Assert.assertEquals(1, found.size());
0:             Assert.assertEquals(i, found.toArray()[0]);
1:         }
1: 
0:         Assert.assertNull("found missing object", tokenTree.get(tokMax + 10, KEY_CONVERTER));
1:     }
1: 
1:     @Test
0:     public void buildSerializeIterateAndSkip() throws Exception
1:     {
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(tokens).finish();
1: 
1:         final File treeFile = File.createTempFile("token-tree-iterate-test2", "tt");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
1:         final TokenTree tokenTree = new TokenTree(new MappedBuffer(reader));
1: 
0:         final RangeIterator<Long, Token> treeIterator = tokenTree.iterator(KEY_CONVERTER);
1:         final RangeIterator<Long, TokenWithOffsets> listIterator = new EntrySetSkippableIterator(tokens);
1: 
1:         long lastToken = 0L;
1:         while (treeIterator.hasNext() && lastToken < 12)
1:         {
1:             Token treeNext = treeIterator.next();
1:             TokenWithOffsets listNext = listIterator.next();
1: 
1:             Assert.assertEquals(listNext.token, (lastToken = treeNext.get()));
1:             Assert.assertEquals(convert(listNext.offsets), convert(treeNext));
1:         }
1: 
1:         treeIterator.skipTo(100548L);
1:         listIterator.skipTo(100548L);
1: 
1:         while (treeIterator.hasNext() && listIterator.hasNext())
1:         {
1:             Token treeNext = treeIterator.next();
1:             TokenWithOffsets listNext = listIterator.next();
1: 
1:             Assert.assertEquals(listNext.token, (long) treeNext.get());
1:             Assert.assertEquals(convert(listNext.offsets), convert(treeNext));
1: 
1:         }
1: 
1:         Assert.assertFalse("Tree iterator not completed", treeIterator.hasNext());
1:         Assert.assertFalse("List iterator not completed", listIterator.hasNext());
1: 
1:         reader.close();
1:     }
1: 
1:     @Test
0:     public void skipPastEnd() throws Exception
1:     {
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(simpleTokenMap).finish();
1: 
1:         final File treeFile = File.createTempFile("token-tree-skip-past-test", "tt");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         final RandomAccessReader reader = RandomAccessReader.open(treeFile);
0:         final RangeIterator<Long, Token> tokenTree = new TokenTree(new MappedBuffer(reader)).iterator(KEY_CONVERTER);
1: 
0:         tokenTree.skipTo(simpleTokenMap.lastKey() + 10);
1:     }
1: 
1:     @Test
0:     public void testTokenMerge() throws Exception
1:     {
1:         final long min = 0, max = 1000;
1: 
1:         // two different trees with the same offsets
0:         TokenTree treeA = generateTree(min, max);
0:         TokenTree treeB = generateTree(min, max);
1: 
0:         RangeIterator<Long, Token> a = treeA.iterator(new KeyConverter());
0:         RangeIterator<Long, Token> b = treeB.iterator(new KeyConverter());
1: 
1:         long count = min;
1:         while (a.hasNext() && b.hasNext())
1:         {
1:             final Token tokenA = a.next();
1:             final Token tokenB = b.next();
1: 
1:             // merging of two OnDiskToken
1:             tokenA.merge(tokenB);
1:             // merging with RAM Token with different offset
1:             tokenA.merge(new TokenWithOffsets(tokenA.get(), convert(count + 1)));
1:             // and RAM token with the same offset
1:             tokenA.merge(new TokenWithOffsets(tokenA.get(), convert(count)));
1: 
1:             // should fail when trying to merge different tokens
1:             try
1:             {
0:                 tokenA.merge(new TokenWithOffsets(tokenA.get() + 1, convert(count)));
1:                 Assert.fail();
1:             }
1:             catch (IllegalArgumentException e)
1:             {
1:                 // expected
1:             }
1: 
1:             final Set<Long> offsets = new TreeSet<>();
0:             for (DecoratedKey key : tokenA)
0:                  offsets.add(LongType.instance.compose(key.getKey()));
1: 
1:             Set<Long> expected = new TreeSet<>();
1:             {
1:                 expected.add(count);
1:                 expected.add(count + 1);
1:             }
1: 
1:             Assert.assertEquals(expected, offsets);
1:             count++;
1:         }
1: 
1:         Assert.assertEquals(max, count - 1);
1:     }
1: 
1:     @Test
1:     public void testEntryTypeOrdinalLookup()
1:     {
1:         Assert.assertEquals(EntryType.SIMPLE, EntryType.of(EntryType.SIMPLE.ordinal()));
1:         Assert.assertEquals(EntryType.PACKED, EntryType.of(EntryType.PACKED.ordinal()));
1:         Assert.assertEquals(EntryType.FACTORED, EntryType.of(EntryType.FACTORED.ordinal()));
1:         Assert.assertEquals(EntryType.OVERFLOW, EntryType.of(EntryType.OVERFLOW.ordinal()));
1:     }
1: 
1:     private static class EntrySetSkippableIterator extends RangeIterator<Long, TokenWithOffsets>
1:     {
0:         private final PeekingIterator<Map.Entry<Long, LongSet>> elements;
1: 
0:         EntrySetSkippableIterator(SortedMap<Long, LongSet> elms)
1:         {
1:             super(elms.firstKey(), elms.lastKey(), elms.size());
1:             elements = Iterators.peekingIterator(elms.entrySet().iterator());
1:         }
1: 
1:         @Override
1:         public TokenWithOffsets computeNext()
1:         {
1:             if (!elements.hasNext())
1:                 return endOfData();
1: 
0:             Map.Entry<Long, LongSet> next = elements.next();
1:             return new TokenWithOffsets(next.getKey(), next.getValue());
1:         }
1: 
1:         @Override
1:         protected void performSkipTo(Long nextToken)
1:         {
1:             while (elements.hasNext())
1:             {
1:                 if (Long.compare(elements.peek().getKey(), nextToken) >= 0)
1:                 {
1:                     break;
1:                 }
1: 
1:                 elements.next();
1:             }
1:         }
1: 
1:         @Override
1:         public void close() throws IOException
1:         {
1:             // nothing to do here
1:         }
1:     }
1: 
1:     public static class TokenWithOffsets extends Token
1:     {
0:         private final LongSet offsets;
1: 
0:         public TokenWithOffsets(long token, final LongSet offsets)
1:         {
1:             super(token);
1:             this.offsets = offsets;
1:         }
1: 
1:         @Override
1:         public void merge(CombinedValue<Long> other)
1:         {}
1: 
1:         @Override
1:         public int compareTo(CombinedValue<Long> o)
1:         {
1:             return Long.compare(token, o.get());
1:         }
1: 
1:         @Override
1:         public boolean equals(Object other)
1:         {
1:             if (!(other instanceof TokenWithOffsets))
1:                 return false;
1: 
1:             TokenWithOffsets o = (TokenWithOffsets) other;
1:             return token == o.token && offsets.equals(o.offsets);
1:         }
1: 
1:         @Override
1:         public int hashCode()
1:         {
1:             return new HashCodeBuilder().append(token).build();
1:         }
1: 
1:         @Override
1:         public String toString()
1:         {
1:             return String.format("TokenValue(token: %d, offsets: %s)", token, offsets);
1:         }
1: 
1:         @Override
0:         public Iterator<DecoratedKey> iterator()
1:         {
0:             List<DecoratedKey> keys = new ArrayList<>(offsets.size());
0:             for (LongCursor offset : offsets)
0:                  keys.add(dk(offset.value));
1: 
1:             return keys.iterator();
1:         }
1:     }
1: 
0:     private static Set<DecoratedKey> convert(LongSet offsets)
1:     {
0:         Set<DecoratedKey> keys = new HashSet<>();
0:         for (LongCursor offset : offsets)
0:             keys.add(KEY_CONVERTER.apply(offset.value));
1: 
1:         return keys;
1:     }
1: 
0:     private static Set<DecoratedKey> convert(Token results)
1:     {
0:         Set<DecoratedKey> keys = new HashSet<>();
0:         for (DecoratedKey key : results)
1:             keys.add(key);
1: 
1:         return keys;
1:     }
1: 
0:     private static LongSet convert(long... values)
1:     {
0:         LongSet result = new LongOpenHashSet(values.length);
1:         for (long v : values)
0:             result.add(v);
1: 
1:         return result;
1:     }
1: 
0:     private static class KeyConverter implements Function<Long, DecoratedKey>
1:     {
1:         @Override
0:         public DecoratedKey apply(Long offset)
1:         {
0:             return dk(offset);
1:         }
1:     }
1: 
0:     private static DecoratedKey dk(Long token)
1:     {
0:         ByteBuffer buf = ByteBuffer.allocate(8);
0:         buf.putLong(token);
0:         buf.flip();
0:         Long hashed = MurmurHash.hash2_64(buf, buf.position(), buf.remaining(), 0);
0:         return new BufferDecoratedKey(new Murmur3Partitioner.LongToken(hashed), buf);
1:     }
1: 
0:     private static TokenTree generateTree(final long minToken, final long maxToken) throws IOException
1:     {
0:         final SortedMap<Long, LongSet> toks = new TreeMap<Long, LongSet>()
1:         {{
0:                 for (long i = minToken; i <= maxToken; i++)
1:                 {
0:                     LongSet offsetSet = new LongOpenHashSet();
0:                     offsetSet.add(i);
0:                     put(i, offsetSet);
1:                 }
1:         }};
1: 
0:         final TokenTreeBuilder builder = new TokenTreeBuilder(toks).finish();
1:         final File treeFile = File.createTempFile("token-tree-get-test", "tt");
1:         treeFile.deleteOnExit();
1: 
0:         try (SequentialWriter writer = new SequentialWriter(treeFile, 4096, BufferType.ON_HEAP))
1:         {
1:             builder.write(writer);
1:             writer.sync();
1:         }
1: 
1:         RandomAccessReader reader = null;
1: 
1:         try
1:         {
1:             reader = RandomAccessReader.open(treeFile);
1:             return new TokenTree(new MappedBuffer(reader));
1:         }
1:         finally
1:         {
1:             FileUtils.closeQuietly(reader);
1:         }
1:     }
1: }
============================================================================
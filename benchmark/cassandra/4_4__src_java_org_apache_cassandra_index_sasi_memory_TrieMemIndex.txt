1:72790dc: /*
1:72790dc:  * Licensed to the Apache Software Foundation (ASF) under one
1:72790dc:  * or more contributor license agreements.  See the NOTICE file
1:72790dc:  * distributed with this work for additional information
1:72790dc:  * regarding copyright ownership.  The ASF licenses this file
1:72790dc:  * to you under the Apache License, Version 2.0 (the
1:72790dc:  * "License"); you may not use this file except in compliance
1:72790dc:  * with the License.  You may obtain a copy of the License at
1:72790dc:  *
1:72790dc:  *     http://www.apache.org/licenses/LICENSE-2.0
1:72790dc:  *
1:72790dc:  * Unless required by applicable law or agreed to in writing, software
1:72790dc:  * distributed under the License is distributed on an "AS IS" BASIS,
1:72790dc:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:72790dc:  * See the License for the specific language governing permissions and
1:72790dc:  * limitations under the License.
1:72790dc:  */
1:72790dc: package org.apache.cassandra.index.sasi.memory;
2:72790dc: 
1:72790dc: import java.nio.ByteBuffer;
1:3928665: import java.util.Collections;
1:72790dc: import java.util.List;
1:72790dc: import java.util.concurrent.ConcurrentSkipListSet;
1:72790dc: 
1:72790dc: import org.apache.cassandra.config.ColumnDefinition;
1:72790dc: import org.apache.cassandra.index.sasi.conf.ColumnIndex;
1:7d857b4: import org.apache.cassandra.index.sasi.disk.*;
1:72790dc: import org.apache.cassandra.index.sasi.disk.Token;
1:72790dc: import org.apache.cassandra.index.sasi.plan.Expression;
1:3928665: import org.apache.cassandra.index.sasi.plan.Expression.Op;
1:72790dc: import org.apache.cassandra.index.sasi.analyzer.AbstractAnalyzer;
1:72790dc: import org.apache.cassandra.index.sasi.utils.RangeUnionIterator;
1:72790dc: import org.apache.cassandra.index.sasi.utils.RangeIterator;
1:72790dc: import org.apache.cassandra.db.marshal.AbstractType;
1:72790dc: 
1:72790dc: import com.googlecode.concurrenttrees.radix.ConcurrentRadixTree;
1:72790dc: import com.googlecode.concurrenttrees.suffix.ConcurrentSuffixTree;
1:72790dc: import com.googlecode.concurrenttrees.radix.node.concrete.SmartArrayBasedNodeFactory;
1:72790dc: import com.googlecode.concurrenttrees.radix.node.Node;
1:7d857b4: import org.apache.cassandra.utils.*;
1:72790dc: 
1:72790dc: 
1:72790dc: import org.slf4j.Logger;
1:72790dc: import org.slf4j.LoggerFactory;
1:72790dc: 
1:72790dc: import static org.apache.cassandra.index.sasi.memory.SkipListMemIndex.CSLM_OVERHEAD;
1:72790dc: 
1:72790dc: public class TrieMemIndex extends MemIndex
1:72790dc: {
1:72790dc:     private static final Logger logger = LoggerFactory.getLogger(TrieMemIndex.class);
1:72790dc: 
1:72790dc:     private final ConcurrentTrie index;
1:72790dc: 
1:72790dc:     public TrieMemIndex(AbstractType<?> keyValidator, ColumnIndex columnIndex)
1:72790dc:     {
1:72790dc:         super(keyValidator, columnIndex);
1:72790dc: 
1:72790dc:         switch (columnIndex.getMode().mode)
1:72790dc:         {
1:72790dc:             case CONTAINS:
1:72790dc:                 index = new ConcurrentSuffixTrie(columnIndex.getDefinition());
1:72790dc:                 break;
1:72790dc: 
1:72790dc:             case PREFIX:
1:72790dc:                 index = new ConcurrentPrefixTrie(columnIndex.getDefinition());
1:72790dc:                 break;
1:72790dc: 
1:72790dc:             default:
1:72790dc:                 throw new IllegalStateException("Unsupported mode: " + columnIndex.getMode().mode);
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:7d857b4:     public long add(RowKey key, ByteBuffer value)
1:72790dc:     {
1:72790dc:         AbstractAnalyzer analyzer = columnIndex.getAnalyzer();
1:72790dc:         analyzer.reset(value.duplicate());
1:72790dc: 
1:72790dc:         long size = 0;
1:72790dc:         while (analyzer.hasNext())
1:72790dc:         {
1:72790dc:             ByteBuffer term = analyzer.next();
1:72790dc: 
1:72790dc:             if (term.remaining() >= OnDiskIndexBuilder.MAX_TERM_SIZE)
1:72790dc:             {
1:db68ac9:                 logger.info("Can't add term of column {} to index for key: {}, term size {}, max allowed size {}, use analyzed = true (if not yet set) for that column.",
1:72790dc:                             columnIndex.getColumnName(),
1:7d857b4:                             keyValidator.getString(key.decoratedKey.getKey()),
1:db68ac9:                             FBUtilities.prettyPrintMemory(term.remaining()),
1:db68ac9:                             FBUtilities.prettyPrintMemory(OnDiskIndexBuilder.MAX_TERM_SIZE));
1:72790dc:                 continue;
1:72790dc:             }
1:72790dc: 
1:72790dc:             size += index.add(columnIndex.getValidator().getString(term), key);
1:72790dc:         }
1:72790dc: 
1:72790dc:         return size;
1:72790dc:     }
1:72790dc: 
1:72790dc:     public RangeIterator<Long, Token> search(Expression expression)
1:72790dc:     {
1:72790dc:         return index.search(expression);
1:72790dc:     }
1:72790dc: 
1:72790dc:     private static abstract class ConcurrentTrie
1:72790dc:     {
1:72790dc:         public static final SizeEstimatingNodeFactory NODE_FACTORY = new SizeEstimatingNodeFactory();
1:72790dc: 
1:72790dc:         protected final ColumnDefinition definition;
1:72790dc: 
1:72790dc:         public ConcurrentTrie(ColumnDefinition column)
1:72790dc:         {
1:72790dc:             definition = column;
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public long add(String value, RowKey key)
1:72790dc:         {
1:72790dc:             long overhead = CSLM_OVERHEAD;
1:7d857b4:             ConcurrentSkipListSet<RowKey> keys = get(value);
1:72790dc:             if (keys == null)
1:72790dc:             {
1:7d857b4:                 ConcurrentSkipListSet<RowKey> newKeys = new ConcurrentSkipListSet<>();
1:72790dc:                 keys = putIfAbsent(value, newKeys);
1:72790dc:                 if (keys == null)
1:72790dc:                 {
1:72790dc:                     overhead += CSLM_OVERHEAD + value.length();
1:72790dc:                     keys = newKeys;
1:72790dc:                 }
1:72790dc:             }
1:72790dc: 
1:72790dc:             keys.add(key);
1:72790dc: 
1:72790dc:             // get and reset new memory size allocated by current thread
1:72790dc:             overhead += NODE_FACTORY.currentUpdateSize();
1:72790dc:             NODE_FACTORY.reset();
1:72790dc: 
1:72790dc:             return overhead;
1:72790dc:         }
1:72790dc: 
1:72790dc:         public RangeIterator<Long, Token> search(Expression expression)
1:72790dc:         {
1:72790dc:             ByteBuffer prefix = expression.lower == null ? null : expression.lower.value;
1:72790dc: 
1:7d857b4:             Iterable<ConcurrentSkipListSet<RowKey>> search = search(expression.getOp(), definition.cellValueType().getString(prefix));
1:72790dc: 
1:72790dc:             RangeUnionIterator.Builder<Long, Token> builder = RangeUnionIterator.builder();
1:7d857b4:             for (ConcurrentSkipListSet<RowKey> keys : search)
1:72790dc:             {
1:72790dc:                 if (!keys.isEmpty())
1:72790dc:                     builder.add(new KeyRangeIterator(keys));
1:72790dc:             }
1:72790dc: 
1:72790dc:             return builder.build();
1:72790dc:         }
1:72790dc: 
1:7d857b4:         protected abstract ConcurrentSkipListSet<RowKey> get(String value);
1:7d857b4:         protected abstract Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value);
1:7d857b4:         protected abstract ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> key);
1:72790dc:     }
1:72790dc: 
1:72790dc:     protected static class ConcurrentPrefixTrie extends ConcurrentTrie
1:72790dc:     {
1:7d857b4:         private final ConcurrentRadixTree<ConcurrentSkipListSet<RowKey>> trie;
1:72790dc: 
1:72790dc:         private ConcurrentPrefixTrie(ColumnDefinition column)
1:72790dc:         {
1:72790dc:             super(column);
1:72790dc:             trie = new ConcurrentRadixTree<>(NODE_FACTORY);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public ConcurrentSkipListSet<RowKey> get(String value)
1:72790dc:         {
1:72790dc:             return trie.getValueForExactKey(value);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> newKeys)
1:72790dc:         {
1:72790dc:             return trie.putIfAbsent(value, newKeys);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value)
1:72790dc:         {
1:3928665:             switch (operator)
1:3928665:             {
1:3928665:                 case EQ:
1:479e8af:                 case MATCH:
1:7d857b4:                     ConcurrentSkipListSet<RowKey> keys = trie.getValueForExactKey(value);
1:3928665:                     return keys == null ? Collections.emptyList() : Collections.singletonList(keys);
1:3928665: 
1:3928665:                 case PREFIX:
1:3928665:                     return trie.getValuesForKeysStartingWith(value);
1:3928665: 
1:3928665:                 default:
1:3928665:                     throw new UnsupportedOperationException(String.format("operation %s is not supported.", operator));
1:3928665:             }
1:72790dc:         }
1:72790dc:     }
1:3928665: 
1:72790dc:     protected static class ConcurrentSuffixTrie extends ConcurrentTrie
1:3928665:     {
1:7d857b4:         private final ConcurrentSuffixTree<ConcurrentSkipListSet<RowKey>> trie;
1:72790dc: 
1:72790dc:         private ConcurrentSuffixTrie(ColumnDefinition column)
1:72790dc:         {
1:72790dc:             super(column);
1:72790dc:             trie = new ConcurrentSuffixTree<>(NODE_FACTORY);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public ConcurrentSkipListSet<RowKey> get(String value)
1:72790dc:         {
1:72790dc:             return trie.getValueForExactKey(value);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> newKeys)
1:72790dc:         {
1:72790dc:             return trie.putIfAbsent(value, newKeys);
1:72790dc:         }
1:72790dc: 
1:7d857b4:         public Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value)
1:72790dc:         {
1:3928665:             switch (operator)
1:72790dc:             {
1:3928665:                 case EQ:
1:479e8af:                 case MATCH:
1:7d857b4:                     ConcurrentSkipListSet<RowKey> keys = trie.getValueForExactKey(value);
1:3928665:                     return keys == null ? Collections.emptyList() : Collections.singletonList(keys);
1:72790dc: 
1:3928665:                 case SUFFIX:
1:3928665:                     return trie.getValuesForKeysEndingWith(value);
1:3928665: 
1:2ca2fff:                 case PREFIX:
1:3928665:                 case CONTAINS:
1:3928665:                     return trie.getValuesForKeysContaining(value);
1:3928665: 
1:3928665:                 default:
1:3928665:                     throw new UnsupportedOperationException(String.format("operation %s is not supported.", operator));
1:3928665:             }
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:72790dc:     // This relies on the fact that all of the tree updates are done under exclusive write lock,
1:72790dc:     // method would overestimate in certain circumstances e.g. when nodes are replaced in place,
1:72790dc:     // but it's still better comparing to underestimate since it gives more breathing room for other memory users.
1:72790dc:     private static class SizeEstimatingNodeFactory extends SmartArrayBasedNodeFactory
1:72790dc:     {
1:72790dc:         private final ThreadLocal<Long> updateSize = ThreadLocal.withInitial(() -> 0L);
1:72790dc: 
1:72790dc:         public Node createNode(CharSequence edgeCharacters, Object value, List<Node> childNodes, boolean isRoot)
1:72790dc:         {
1:72790dc:             Node node = super.createNode(edgeCharacters, value, childNodes, isRoot);
1:72790dc:             updateSize.set(updateSize.get() + measure(node));
1:72790dc:             return node;
1:72790dc:         }
1:72790dc: 
1:72790dc:         public long currentUpdateSize()
1:72790dc:         {
1:72790dc:             return updateSize.get();
1:72790dc:         }
1:72790dc: 
1:72790dc:         public void reset()
1:72790dc:         {
1:72790dc:             updateSize.set(0L);
1:72790dc:         }
1:72790dc: 
1:72790dc:         private long measure(Node node)
1:72790dc:         {
1:72790dc:             // node with max overhead is CharArrayNodeLeafWithValue = 24B
1:72790dc:             long overhead = 24;
1:72790dc: 
1:72790dc:             // array of chars (2 bytes) + CharSequence overhead
1:72790dc:             overhead += 24 + node.getIncomingEdge().length() * 2;
1:72790dc: 
1:72790dc:             if (node.getOutgoingEdges() != null)
1:72790dc:             {
1:72790dc:                 // 16 bytes for AtomicReferenceArray
1:72790dc:                 overhead += 16;
1:72790dc:                 overhead += 24 * node.getOutgoingEdges().size();
1:72790dc:             }
1:72790dc: 
1:72790dc:             return overhead;
1:72790dc:         }
1:72790dc:     }
1:72790dc: }
============================================================================
author:Alex Petrov
-------------------------------------------------------------------------------
commit:7d857b4
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.index.sasi.disk.*;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.*;
/////////////////////////////////////////////////////////////////////////
1:     public long add(RowKey key, ByteBuffer value)
/////////////////////////////////////////////////////////////////////////
1:                             keyValidator.getString(key.decoratedKey.getKey()),
/////////////////////////////////////////////////////////////////////////
1:         public long add(String value, RowKey key)
1:             ConcurrentSkipListSet<RowKey> keys = get(value);
1:                 ConcurrentSkipListSet<RowKey> newKeys = new ConcurrentSkipListSet<>();
/////////////////////////////////////////////////////////////////////////
1:             Iterable<ConcurrentSkipListSet<RowKey>> search = search(expression.getOp(), definition.cellValueType().getString(prefix));
1:             for (ConcurrentSkipListSet<RowKey> keys : search)
/////////////////////////////////////////////////////////////////////////
1:         protected abstract ConcurrentSkipListSet<RowKey> get(String value);
1:         protected abstract Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value);
1:         protected abstract ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> key);
1:         private final ConcurrentRadixTree<ConcurrentSkipListSet<RowKey>> trie;
/////////////////////////////////////////////////////////////////////////
1:         public ConcurrentSkipListSet<RowKey> get(String value)
1:         public ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> newKeys)
1:         public Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value)
1:                     ConcurrentSkipListSet<RowKey> keys = trie.getValueForExactKey(value);
/////////////////////////////////////////////////////////////////////////
1:         private final ConcurrentSuffixTree<ConcurrentSkipListSet<RowKey>> trie;
/////////////////////////////////////////////////////////////////////////
1:         public ConcurrentSkipListSet<RowKey> get(String value)
1:         public ConcurrentSkipListSet<RowKey> putIfAbsent(String value, ConcurrentSkipListSet<RowKey> newKeys)
1:         public Iterable<ConcurrentSkipListSet<RowKey>> search(Op operator, String value)
1:                     ConcurrentSkipListSet<RowKey> keys = trie.getValueForExactKey(value);
author:Jordan West
-------------------------------------------------------------------------------
commit:2ca2fff
/////////////////////////////////////////////////////////////////////////
1:                 case PREFIX:
author:Giampaolo Trapasso
-------------------------------------------------------------------------------
commit:db68ac9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.utils.FBUtilities;
/////////////////////////////////////////////////////////////////////////
1:                 logger.info("Can't add term of column {} to index for key: {}, term size {}, max allowed size {}, use analyzed = true (if not yet set) for that column.",
1:                             FBUtilities.prettyPrintMemory(term.remaining()),
1:                             FBUtilities.prettyPrintMemory(OnDiskIndexBuilder.MAX_TERM_SIZE));
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:479e8af
/////////////////////////////////////////////////////////////////////////
1:                 case MATCH:
/////////////////////////////////////////////////////////////////////////
1:                 case MATCH:
commit:3928665
/////////////////////////////////////////////////////////////////////////
1: import java.util.Collections;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.index.sasi.plan.Expression.Op;
/////////////////////////////////////////////////////////////////////////
0:             Iterable<ConcurrentSkipListSet<DecoratedKey>> search = search(expression.getOp(), definition.cellValueType().getString(prefix));
/////////////////////////////////////////////////////////////////////////
0:         protected abstract Iterable<ConcurrentSkipListSet<DecoratedKey>> search(Op operator, String value);
/////////////////////////////////////////////////////////////////////////
0:         public Iterable<ConcurrentSkipListSet<DecoratedKey>> search(Op operator, String value)
1:             switch (operator)
1:             {
1:                 case EQ:
0:                     ConcurrentSkipListSet<DecoratedKey> keys = trie.getValueForExactKey(value);
1:                     return keys == null ? Collections.emptyList() : Collections.singletonList(keys);
1: 
1:                 case PREFIX:
1:                     return trie.getValuesForKeysStartingWith(value);
1: 
1:                 default:
1:                     throw new UnsupportedOperationException(String.format("operation %s is not supported.", operator));
1:             }
/////////////////////////////////////////////////////////////////////////
0:         public Iterable<ConcurrentSkipListSet<DecoratedKey>> search(Op operator, String value)
1:             switch (operator)
1:             {
1:                 case EQ:
0:                     ConcurrentSkipListSet<DecoratedKey> keys = trie.getValueForExactKey(value);
1:                     return keys == null ? Collections.emptyList() : Collections.singletonList(keys);
1: 
1:                 case SUFFIX:
1:                     return trie.getValuesForKeysEndingWith(value);
1: 
1:                 case CONTAINS:
1:                     return trie.getValuesForKeysContaining(value);
1: 
1:                 default:
1:                     throw new UnsupportedOperationException(String.format("operation %s is not supported.", operator));
1:             }
commit:72790dc
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.index.sasi.memory;
1: 
1: import java.nio.ByteBuffer;
1: import java.util.List;
1: import java.util.concurrent.ConcurrentSkipListSet;
1: 
1: import org.apache.cassandra.config.ColumnDefinition;
0: import org.apache.cassandra.db.DecoratedKey;
1: import org.apache.cassandra.index.sasi.conf.ColumnIndex;
0: import org.apache.cassandra.index.sasi.disk.OnDiskIndexBuilder;
1: import org.apache.cassandra.index.sasi.disk.Token;
1: import org.apache.cassandra.index.sasi.plan.Expression;
1: import org.apache.cassandra.index.sasi.analyzer.AbstractAnalyzer;
1: import org.apache.cassandra.index.sasi.utils.RangeUnionIterator;
1: import org.apache.cassandra.index.sasi.utils.RangeIterator;
1: import org.apache.cassandra.db.marshal.AbstractType;
1: 
1: import com.googlecode.concurrenttrees.radix.ConcurrentRadixTree;
1: import com.googlecode.concurrenttrees.suffix.ConcurrentSuffixTree;
1: import com.googlecode.concurrenttrees.radix.node.concrete.SmartArrayBasedNodeFactory;
1: import com.googlecode.concurrenttrees.radix.node.Node;
1: 
1: 
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: import static org.apache.cassandra.index.sasi.memory.SkipListMemIndex.CSLM_OVERHEAD;
1: 
1: public class TrieMemIndex extends MemIndex
1: {
1:     private static final Logger logger = LoggerFactory.getLogger(TrieMemIndex.class);
1: 
1:     private final ConcurrentTrie index;
1: 
1:     public TrieMemIndex(AbstractType<?> keyValidator, ColumnIndex columnIndex)
1:     {
1:         super(keyValidator, columnIndex);
1: 
1:         switch (columnIndex.getMode().mode)
1:         {
1:             case CONTAINS:
1:                 index = new ConcurrentSuffixTrie(columnIndex.getDefinition());
1:                 break;
1: 
1:             case PREFIX:
1:                 index = new ConcurrentPrefixTrie(columnIndex.getDefinition());
1:                 break;
1: 
1:             default:
1:                 throw new IllegalStateException("Unsupported mode: " + columnIndex.getMode().mode);
1:         }
1:     }
1: 
0:     public long add(DecoratedKey key, ByteBuffer value)
1:     {
1:         AbstractAnalyzer analyzer = columnIndex.getAnalyzer();
1:         analyzer.reset(value.duplicate());
1: 
1:         long size = 0;
1:         while (analyzer.hasNext())
1:         {
1:             ByteBuffer term = analyzer.next();
1: 
1:             if (term.remaining() >= OnDiskIndexBuilder.MAX_TERM_SIZE)
1:             {
0:                 logger.info("Can't add term of column {} to index for key: {}, term size {} bytes, max allowed size {} bytes, use analyzed = true (if not yet set) for that column.",
1:                             columnIndex.getColumnName(),
0:                             keyValidator.getString(key.getKey()),
0:                             term.remaining(),
0:                             OnDiskIndexBuilder.MAX_TERM_SIZE);
1:                 continue;
1:             }
1: 
1:             size += index.add(columnIndex.getValidator().getString(term), key);
1:         }
1: 
1:         return size;
1:     }
1: 
1:     public RangeIterator<Long, Token> search(Expression expression)
1:     {
1:         return index.search(expression);
1:     }
1: 
1:     private static abstract class ConcurrentTrie
1:     {
1:         public static final SizeEstimatingNodeFactory NODE_FACTORY = new SizeEstimatingNodeFactory();
1: 
1:         protected final ColumnDefinition definition;
1: 
1:         public ConcurrentTrie(ColumnDefinition column)
1:         {
1:             definition = column;
1:         }
1: 
0:         public long add(String value, DecoratedKey key)
1:         {
1:             long overhead = CSLM_OVERHEAD;
0:             ConcurrentSkipListSet<DecoratedKey> keys = get(value);
1:             if (keys == null)
1:             {
0:                 ConcurrentSkipListSet<DecoratedKey> newKeys = new ConcurrentSkipListSet<>(DecoratedKey.comparator);
1:                 keys = putIfAbsent(value, newKeys);
1:                 if (keys == null)
1:                 {
1:                     overhead += CSLM_OVERHEAD + value.length();
1:                     keys = newKeys;
1:                 }
1:             }
1: 
1:             keys.add(key);
1: 
1:             // get and reset new memory size allocated by current thread
1:             overhead += NODE_FACTORY.currentUpdateSize();
1:             NODE_FACTORY.reset();
1: 
1:             return overhead;
1:         }
1: 
1:         public RangeIterator<Long, Token> search(Expression expression)
1:         {
0:             assert expression.getOp() == Expression.Op.EQ; // means that min == max
1: 
1:             ByteBuffer prefix = expression.lower == null ? null : expression.lower.value;
1: 
0:             Iterable<ConcurrentSkipListSet<DecoratedKey>> search = search(definition.cellValueType().getString(prefix));
1: 
1:             RangeUnionIterator.Builder<Long, Token> builder = RangeUnionIterator.builder();
0:             for (ConcurrentSkipListSet<DecoratedKey> keys : search)
1:             {
1:                 if (!keys.isEmpty())
1:                     builder.add(new KeyRangeIterator(keys));
1:             }
1: 
1:             return builder.build();
1:         }
1: 
0:         protected abstract ConcurrentSkipListSet<DecoratedKey> get(String value);
0:         protected abstract Iterable<ConcurrentSkipListSet<DecoratedKey>> search(String value);
0:         protected abstract ConcurrentSkipListSet<DecoratedKey> putIfAbsent(String value, ConcurrentSkipListSet<DecoratedKey> key);
1:     }
1: 
1:     protected static class ConcurrentPrefixTrie extends ConcurrentTrie
1:     {
0:         private final ConcurrentRadixTree<ConcurrentSkipListSet<DecoratedKey>> trie;
1: 
1:         private ConcurrentPrefixTrie(ColumnDefinition column)
1:         {
1:             super(column);
1:             trie = new ConcurrentRadixTree<>(NODE_FACTORY);
1:         }
1: 
0:         public ConcurrentSkipListSet<DecoratedKey> get(String value)
1:         {
1:             return trie.getValueForExactKey(value);
1:         }
1: 
0:         public ConcurrentSkipListSet<DecoratedKey> putIfAbsent(String value, ConcurrentSkipListSet<DecoratedKey> newKeys)
1:         {
1:             return trie.putIfAbsent(value, newKeys);
1:         }
1: 
0:         public Iterable<ConcurrentSkipListSet<DecoratedKey>> search(String value)
1:         {
0:             return trie.getValuesForKeysStartingWith(value);
1:         }
1:     }
1: 
1:     protected static class ConcurrentSuffixTrie extends ConcurrentTrie
1:     {
0:         private final ConcurrentSuffixTree<ConcurrentSkipListSet<DecoratedKey>> trie;
1: 
1:         private ConcurrentSuffixTrie(ColumnDefinition column)
1:         {
1:             super(column);
1:             trie = new ConcurrentSuffixTree<>(NODE_FACTORY);
1:         }
1: 
0:         public ConcurrentSkipListSet<DecoratedKey> get(String value)
1:         {
1:             return trie.getValueForExactKey(value);
1:         }
1: 
0:         public ConcurrentSkipListSet<DecoratedKey> putIfAbsent(String value, ConcurrentSkipListSet<DecoratedKey> newKeys)
1:         {
1:             return trie.putIfAbsent(value, newKeys);
1:         }
1: 
0:         public Iterable<ConcurrentSkipListSet<DecoratedKey>> search(String value)
1:         {
0:             return trie.getValuesForKeysContaining(value);
1:         }
1:     }
1: 
1:     // This relies on the fact that all of the tree updates are done under exclusive write lock,
1:     // method would overestimate in certain circumstances e.g. when nodes are replaced in place,
1:     // but it's still better comparing to underestimate since it gives more breathing room for other memory users.
1:     private static class SizeEstimatingNodeFactory extends SmartArrayBasedNodeFactory
1:     {
1:         private final ThreadLocal<Long> updateSize = ThreadLocal.withInitial(() -> 0L);
1: 
1:         public Node createNode(CharSequence edgeCharacters, Object value, List<Node> childNodes, boolean isRoot)
1:         {
1:             Node node = super.createNode(edgeCharacters, value, childNodes, isRoot);
1:             updateSize.set(updateSize.get() + measure(node));
1:             return node;
1:         }
1: 
1:         public long currentUpdateSize()
1:         {
1:             return updateSize.get();
1:         }
1: 
1:         public void reset()
1:         {
1:             updateSize.set(0L);
1:         }
1: 
1:         private long measure(Node node)
1:         {
1:             // node with max overhead is CharArrayNodeLeafWithValue = 24B
1:             long overhead = 24;
1: 
1:             // array of chars (2 bytes) + CharSequence overhead
1:             overhead += 24 + node.getIncomingEdge().length() * 2;
1: 
1:             if (node.getOutgoingEdges() != null)
1:             {
1:                 // 16 bytes for AtomicReferenceArray
1:                 overhead += 16;
1:                 overhead += 24 * node.getOutgoingEdges().size();
1:             }
1: 
1:             return overhead;
1:         }
1:     }
1: }
============================================================================
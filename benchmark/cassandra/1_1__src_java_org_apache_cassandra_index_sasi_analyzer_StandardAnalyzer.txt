1:72790dc: /*
1:72790dc:  * Licensed to the Apache Software Foundation (ASF) under one
1:72790dc:  * or more contributor license agreements.  See the NOTICE file
1:72790dc:  * distributed with this work for additional information
1:72790dc:  * regarding copyright ownership.  The ASF licenses this file
1:72790dc:  * to you under the Apache License, Version 2.0 (the
1:72790dc:  * "License"); you may not use this file except in compliance
1:72790dc:  * with the License.  You may obtain a copy of the License at
1:72790dc:  *
1:72790dc:  *     http://www.apache.org/licenses/LICENSE-2.0
1:72790dc:  *
1:72790dc:  * Unless required by applicable law or agreed to in writing, software
1:72790dc:  * distributed under the License is distributed on an "AS IS" BASIS,
1:72790dc:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:72790dc:  * See the License for the specific language governing permissions and
1:72790dc:  * limitations under the License.
1:72790dc:  */
1:72790dc: package org.apache.cassandra.index.sasi.analyzer;
1:72790dc: 
1:72790dc: import java.io.IOException;
1:72790dc: import java.io.InputStream;
1:72790dc: import java.io.InputStreamReader;
1:72790dc: import java.io.Reader;
1:72790dc: import java.nio.ByteBuffer;
1:72790dc: import java.util.Map;
1:72790dc: 
1:72790dc: import org.apache.cassandra.index.sasi.analyzer.filter.*;
1:72790dc: import org.apache.cassandra.db.marshal.AbstractType;
1:72790dc: import org.apache.cassandra.db.marshal.UTF8Type;
1:72790dc: import org.apache.cassandra.io.util.DataInputBuffer;
1:72790dc: import org.apache.cassandra.utils.ByteBufferUtil;
1:72790dc: 
1:72790dc: import com.google.common.annotations.VisibleForTesting;
1:72790dc: 
1:72790dc: import com.carrotsearch.hppc.IntObjectMap;
1:72790dc: import com.carrotsearch.hppc.IntObjectOpenHashMap;
1:72790dc: 
1:72790dc: public class StandardAnalyzer extends AbstractAnalyzer
1:72790dc: {
1:72790dc:     public enum TokenType
1:72790dc:     {
1:72790dc:         EOF(-1),
1:72790dc:         ALPHANUM(0),
1:72790dc:         NUM(6),
1:72790dc:         SOUTHEAST_ASIAN(9),
1:72790dc:         IDEOGRAPHIC(10),
1:72790dc:         HIRAGANA(11),
1:72790dc:         KATAKANA(12),
1:72790dc:         HANGUL(13);
1:72790dc: 
1:72790dc:         private static final IntObjectMap<TokenType> TOKENS = new IntObjectOpenHashMap<>();
1:72790dc: 
1:72790dc:         static
1:72790dc:         {
1:72790dc:             for (TokenType type : TokenType.values())
1:72790dc:                 TOKENS.put(type.value, type);
1:72790dc:         }
1:72790dc: 
1:72790dc:         public final int value;
1:72790dc: 
1:72790dc:         TokenType(int value)
1:72790dc:         {
1:72790dc:             this.value = value;
1:72790dc:         }
1:72790dc: 
1:72790dc:         public int getValue()
1:72790dc:         {
1:72790dc:             return value;
1:72790dc:         }
1:72790dc: 
1:72790dc:         public static TokenType fromValue(int val)
1:72790dc:         {
1:72790dc:             return TOKENS.get(val);
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:72790dc:     private AbstractType validator;
1:72790dc: 
1:72790dc:     private StandardTokenizerInterface scanner;
1:72790dc:     private StandardTokenizerOptions options;
1:72790dc:     private FilterPipelineTask filterPipeline;
1:72790dc: 
1:72790dc:     protected Reader inputReader = null;
1:72790dc: 
1:72790dc:     public String getToken()
1:72790dc:     {
1:72790dc:         return scanner.getText();
1:72790dc:     }
1:72790dc: 
1:72790dc:     public final boolean incrementToken() throws IOException
1:72790dc:     {
1:72790dc:         while(true)
1:72790dc:         {
1:72790dc:             TokenType currentTokenType = TokenType.fromValue(scanner.getNextToken());
1:72790dc:             if (currentTokenType == TokenType.EOF)
1:72790dc:                 return false;
1:72790dc:             if (scanner.yylength() <= options.getMaxTokenLength()
1:72790dc:                     && scanner.yylength() >= options.getMinTokenLength())
1:72790dc:                 return true;
1:72790dc:         }
1:72790dc:     }
1:72790dc: 
1:72790dc:     protected String getFilteredCurrentToken() throws IOException
1:72790dc:     {
1:72790dc:         String token = getToken();
1:72790dc:         Object pipelineRes;
1:72790dc: 
1:72790dc:         while (true)
1:72790dc:         {
1:72790dc:             pipelineRes = FilterPipelineExecutor.execute(filterPipeline, token);
1:72790dc:             if (pipelineRes != null)
1:72790dc:                 break;
1:72790dc: 
1:72790dc:             boolean reachedEOF = incrementToken();
1:72790dc:             if (!reachedEOF)
1:72790dc:                 break;
1:72790dc: 
1:72790dc:             token = getToken();
1:72790dc:         }
1:72790dc: 
1:72790dc:         return (String) pipelineRes;
1:72790dc:     }
1:72790dc: 
1:72790dc:     private FilterPipelineTask getFilterPipeline()
1:72790dc:     {
1:72790dc:         FilterPipelineBuilder builder = new FilterPipelineBuilder(new BasicResultFilters.NoOperation());
1:72790dc:         if (!options.isCaseSensitive() && options.shouldLowerCaseTerms())
1:72790dc:             builder = builder.add("to_lower", new BasicResultFilters.LowerCase());
1:72790dc:         if (!options.isCaseSensitive() && options.shouldUpperCaseTerms())
1:72790dc:             builder = builder.add("to_upper", new BasicResultFilters.UpperCase());
1:72790dc:         if (options.shouldIgnoreStopTerms())
1:72790dc:             builder = builder.add("skip_stop_words", new StopWordFilters.DefaultStopWordFilter(options.getLocale()));
1:c253f08:         if (options.shouldStemTerms())
1:c253f08:             builder = builder.add("term_stemming", new StemmingFilters.DefaultStemmingFilter(options.getLocale()));
1:72790dc:         return builder.build();
1:72790dc:     }
1:72790dc: 
1:72790dc:     public void init(Map<String, String> options, AbstractType validator)
1:72790dc:     {
1:72790dc:         init(StandardTokenizerOptions.buildFromMap(options), validator);
1:72790dc:     }
1:72790dc: 
1:72790dc:     @VisibleForTesting
1:72790dc:     protected void init(StandardTokenizerOptions options)
1:72790dc:     {
1:72790dc:         init(options, UTF8Type.instance);
1:72790dc:     }
1:72790dc: 
1:72790dc:     public void init(StandardTokenizerOptions tokenizerOptions, AbstractType validator)
1:72790dc:     {
1:72790dc:         this.validator = validator;
1:72790dc:         this.options = tokenizerOptions;
1:72790dc:         this.filterPipeline = getFilterPipeline();
1:72790dc: 
1:72790dc:         Reader reader = new InputStreamReader(new DataInputBuffer(ByteBufferUtil.EMPTY_BYTE_BUFFER, false));
1:72790dc:         this.scanner = new StandardTokenizerImpl(reader);
1:72790dc:         this.inputReader = reader;
1:72790dc:     }
1:72790dc: 
1:72790dc:     public boolean hasNext()
1:72790dc:     {
1:72790dc:         try
1:72790dc:         {
1:72790dc:             if (incrementToken())
1:72790dc:             {
1:72790dc:                 if (getFilteredCurrentToken() != null)
1:72790dc:                 {
1:72790dc:                     this.next = validator.fromString(normalize(getFilteredCurrentToken()));
1:72790dc:                     return true;
1:72790dc:                 }
1:72790dc:             }
1:72790dc:         }
1:72790dc:         catch (IOException e)
1:72790dc:         {}
1:72790dc: 
1:72790dc:         return false;
1:72790dc:     }
1:72790dc: 
1:72790dc:     public void reset(ByteBuffer input)
1:72790dc:     {
1:72790dc:         this.next = null;
1:72790dc:         Reader reader = new InputStreamReader(new DataInputBuffer(input, false));
1:72790dc:         scanner.yyreset(reader);
1:72790dc:         this.inputReader = reader;
1:72790dc:     }
1:479e8af: 
1:72790dc:     public void reset(InputStream input)
1:72790dc:     {
1:72790dc:         this.next = null;
1:72790dc:         Reader reader = new InputStreamReader(input);
1:72790dc:         scanner.yyreset(reader);
1:72790dc:         this.inputReader = reader;
1:72790dc:     }
1:72790dc: 
1:479e8af:     public boolean isTokenizing()
1:479e8af:     {
1:479e8af:         return true;
1:479e8af:     }
1:72790dc: }
============================================================================
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:c253f08
/////////////////////////////////////////////////////////////////////////
1:         if (options.shouldStemTerms())
1:             builder = builder.add("term_stemming", new StemmingFilters.DefaultStemmingFilter(options.getLocale()));
commit:479e8af
/////////////////////////////////////////////////////////////////////////
1: 
1:     public boolean isTokenizing()
1:     {
1:         return true;
1:     }
commit:72790dc
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.index.sasi.analyzer;
1: 
1: import java.io.IOException;
1: import java.io.InputStream;
1: import java.io.InputStreamReader;
1: import java.io.Reader;
1: import java.nio.ByteBuffer;
1: import java.util.Map;
1: 
1: import org.apache.cassandra.index.sasi.analyzer.filter.*;
1: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.db.marshal.UTF8Type;
1: import org.apache.cassandra.io.util.DataInputBuffer;
1: import org.apache.cassandra.utils.ByteBufferUtil;
1: 
1: import com.google.common.annotations.VisibleForTesting;
1: 
1: import com.carrotsearch.hppc.IntObjectMap;
1: import com.carrotsearch.hppc.IntObjectOpenHashMap;
1: 
1: public class StandardAnalyzer extends AbstractAnalyzer
1: {
1:     public enum TokenType
1:     {
1:         EOF(-1),
1:         ALPHANUM(0),
1:         NUM(6),
1:         SOUTHEAST_ASIAN(9),
1:         IDEOGRAPHIC(10),
1:         HIRAGANA(11),
1:         KATAKANA(12),
1:         HANGUL(13);
1: 
1:         private static final IntObjectMap<TokenType> TOKENS = new IntObjectOpenHashMap<>();
1: 
1:         static
1:         {
1:             for (TokenType type : TokenType.values())
1:                 TOKENS.put(type.value, type);
1:         }
1: 
1:         public final int value;
1: 
1:         TokenType(int value)
1:         {
1:             this.value = value;
1:         }
1: 
1:         public int getValue()
1:         {
1:             return value;
1:         }
1: 
1:         public static TokenType fromValue(int val)
1:         {
1:             return TOKENS.get(val);
1:         }
1:     }
1: 
1:     private AbstractType validator;
1: 
1:     private StandardTokenizerInterface scanner;
1:     private StandardTokenizerOptions options;
1:     private FilterPipelineTask filterPipeline;
1: 
1:     protected Reader inputReader = null;
1: 
1:     public String getToken()
1:     {
1:         return scanner.getText();
1:     }
1: 
1:     public final boolean incrementToken() throws IOException
1:     {
1:         while(true)
1:         {
1:             TokenType currentTokenType = TokenType.fromValue(scanner.getNextToken());
1:             if (currentTokenType == TokenType.EOF)
1:                 return false;
1:             if (scanner.yylength() <= options.getMaxTokenLength()
1:                     && scanner.yylength() >= options.getMinTokenLength())
1:                 return true;
1:         }
1:     }
1: 
1:     protected String getFilteredCurrentToken() throws IOException
1:     {
1:         String token = getToken();
1:         Object pipelineRes;
1: 
1:         while (true)
1:         {
1:             pipelineRes = FilterPipelineExecutor.execute(filterPipeline, token);
1:             if (pipelineRes != null)
1:                 break;
1: 
1:             boolean reachedEOF = incrementToken();
1:             if (!reachedEOF)
1:                 break;
1: 
1:             token = getToken();
1:         }
1: 
1:         return (String) pipelineRes;
1:     }
1: 
1:     private FilterPipelineTask getFilterPipeline()
1:     {
1:         FilterPipelineBuilder builder = new FilterPipelineBuilder(new BasicResultFilters.NoOperation());
1:         if (!options.isCaseSensitive() && options.shouldLowerCaseTerms())
1:             builder = builder.add("to_lower", new BasicResultFilters.LowerCase());
1:         if (!options.isCaseSensitive() && options.shouldUpperCaseTerms())
1:             builder = builder.add("to_upper", new BasicResultFilters.UpperCase());
0:         if (options.shouldStemTerms())
0:             builder = builder.add("term_stemming", new StemmingFilters.DefaultStemmingFilter(options.getLocale()));
1:         if (options.shouldIgnoreStopTerms())
1:             builder = builder.add("skip_stop_words", new StopWordFilters.DefaultStopWordFilter(options.getLocale()));
1:         return builder.build();
1:     }
1: 
1:     public void init(Map<String, String> options, AbstractType validator)
1:     {
1:         init(StandardTokenizerOptions.buildFromMap(options), validator);
1:     }
1: 
1:     @VisibleForTesting
1:     protected void init(StandardTokenizerOptions options)
1:     {
1:         init(options, UTF8Type.instance);
1:     }
1: 
1:     public void init(StandardTokenizerOptions tokenizerOptions, AbstractType validator)
1:     {
1:         this.validator = validator;
1:         this.options = tokenizerOptions;
1:         this.filterPipeline = getFilterPipeline();
1: 
1:         Reader reader = new InputStreamReader(new DataInputBuffer(ByteBufferUtil.EMPTY_BYTE_BUFFER, false));
1:         this.scanner = new StandardTokenizerImpl(reader);
1:         this.inputReader = reader;
1:     }
1: 
1:     public boolean hasNext()
1:     {
1:         try
1:         {
1:             if (incrementToken())
1:             {
1:                 if (getFilteredCurrentToken() != null)
1:                 {
1:                     this.next = validator.fromString(normalize(getFilteredCurrentToken()));
1:                     return true;
1:                 }
1:             }
1:         }
1:         catch (IOException e)
1:         {}
1: 
1:         return false;
1:     }
1: 
1:     public void reset(ByteBuffer input)
1:     {
1:         this.next = null;
1:         Reader reader = new InputStreamReader(new DataInputBuffer(input, false));
1:         scanner.yyreset(reader);
1:         this.inputReader = reader;
1:     }
1: 
1:     public void reset(InputStream input)
1:     {
1:         this.next = null;
1:         Reader reader = new InputStreamReader(input);
1:         scanner.yyreset(reader);
1:         this.inputReader = reader;
1:     }
1: }
============================================================================
1:5c4d5c7: /*
1:5c4d5c7:  * Licensed to the Apache Software Foundation (ASF) under one
1:5c4d5c7:  * or more contributor license agreements.  See the NOTICE file
1:5c4d5c7:  * distributed with this work for additional information
1:5c4d5c7:  * regarding copyright ownership.  The ASF licenses this file
1:5c4d5c7:  * to you under the Apache License, Version 2.0 (the
1:5c4d5c7:  * "License"); you may not use this file except in compliance
1:5c4d5c7:  * with the License.  You may obtain a copy of the License at
1:5c4d5c7:  *
1:5c4d5c7:  *     http://www.apache.org/licenses/LICENSE-2.0
1:5c4d5c7:  *
1:5c4d5c7:  * Unless required by applicable law or agreed to in writing, software
1:5c4d5c7:  * distributed under the License is distributed on an "AS IS" BASIS,
1:5c4d5c7:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:5c4d5c7:  * See the License for the specific language governing permissions and
1:5c4d5c7:  * limitations under the License.
1:5c4d5c7:  */
1:5c4d5c7: package org.apache.cassandra.index.sasi.disk;
7:5c4d5c7: 
1:5c4d5c7: import java.io.IOException;
1:5c4d5c7: import java.nio.ByteBuffer;
1:7d857b4: import java.util.*;
1:5c4d5c7: 
1:5c4d5c7: import org.apache.cassandra.index.sasi.utils.CombinedTerm;
1:5c4d5c7: import org.apache.cassandra.index.sasi.utils.RangeIterator;
1:5c4d5c7: import org.apache.cassandra.io.util.DataOutputPlus;
1:5c4d5c7: import org.apache.cassandra.utils.AbstractIterator;
1:5c4d5c7: import org.apache.cassandra.utils.Pair;
1:5c4d5c7: 
1:5c4d5c7: import com.google.common.collect.Iterators;
1:5c4d5c7: 
1:5c4d5c7: /**
1:5c4d5c7:  * Intended usage of this class is to be used in place of {@link DynamicTokenTreeBuilder}
1:5c4d5c7:  * when multiple index segments produced by {@link PerSSTableIndexWriter} are stitched together
1:5c4d5c7:  * by {@link PerSSTableIndexWriter#complete()}.
1:5c4d5c7:  *
1:5c4d5c7:  * This class uses the RangeIterator, now provided by
1:5c4d5c7:  * {@link CombinedTerm#getTokenIterator()}, to iterate the data twice.
1:5c4d5c7:  * The first iteration builds the tree with leaves that contain only enough
1:5c4d5c7:  * information to build the upper layers -- these leaves do not store more
1:5c4d5c7:  * than their minimum and maximum tokens plus their total size, which makes them
1:5c4d5c7:  * un-serializable.
1:5c4d5c7:  *
1:5c4d5c7:  * When the tree is written to disk the final layer is not
1:5c4d5c7:  * written. Its at this point the data is iterated once again to write
1:5c4d5c7:  * the leaves to disk. This (logarithmically) reduces copying of the
1:5c4d5c7:  * token values while building and writing upper layers of the tree,
1:5c4d5c7:  * removes the use of SortedMap when combining SAs, and relies on the
1:5c4d5c7:  * memory mapped SAs otherwise, greatly improving performance and no
1:5c4d5c7:  * longer causing OOMs when TokenTree sizes are big.
1:5c4d5c7:  *
1:5c4d5c7:  * See https://issues.apache.org/jira/browse/CASSANDRA-11383 for more details.
1:5c4d5c7:  */
1:05660a5: @SuppressWarnings("resource")
1:5c4d5c7: public class StaticTokenTreeBuilder extends AbstractTokenTreeBuilder
3:5c4d5c7: {
1:5c4d5c7:     private final CombinedTerm combinedTerm;
1:5c4d5c7: 
1:5c4d5c7:     public StaticTokenTreeBuilder(CombinedTerm term)
1:5c4d5c7:     {
1:5c4d5c7:         combinedTerm = term;
3:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public void add(Long token, long partitionOffset, long rowOffset)
1:5c4d5c7:     {
1:5c4d5c7:         throw new UnsupportedOperationException();
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public void add(SortedMap<Long, KeyOffsets> data)
1:5c4d5c7:     {
1:5c4d5c7:         throw new UnsupportedOperationException();
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public void add(Iterator<Pair<Long, KeyOffsets>> data)
1:5c4d5c7:     {
1:5c4d5c7:         throw new UnsupportedOperationException();
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public boolean isEmpty()
1:5c4d5c7:     {
1:020dd2d:         return tokenCount == 0;
1:5c4d5c7:     }
1:5c4d5c7: 
1:7d857b4:     public Iterator<Pair<Long, KeyOffsets>> iterator()
1:5c4d5c7:     {
1:7d857b4:         @SuppressWarnings("resource") Iterator<Token> iterator = combinedTerm.getTokenIterator();
1:7d857b4:         return new AbstractIterator<Pair<Long, KeyOffsets>>()
1:5c4d5c7:         {
1:7d857b4:             protected Pair<Long, KeyOffsets> computeNext()
1:5c4d5c7:             {
1:5c4d5c7:                 if (!iterator.hasNext())
1:5c4d5c7:                     return endOfData();
1:5c4d5c7: 
1:5c4d5c7:                 Token token = iterator.next();
1:5c4d5c7:                 return Pair.create(token.get(), token.getOffsets());
1:5c4d5c7:             }
1:5c4d5c7:         };
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     public long getTokenCount()
1:5c4d5c7:     {
1:020dd2d:         return tokenCount;
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     @Override
1:5c4d5c7:     public void write(DataOutputPlus out) throws IOException
1:5c4d5c7:     {
1:5c4d5c7:         // if the root is not a leaf then none of the leaves have been written (all are PartialLeaf)
1:5c4d5c7:         // so write out the last layer of the tree by converting PartialLeaf to StaticLeaf and
1:5c4d5c7:         // iterating the data once more
1:5c4d5c7:         super.write(out);
1:5c4d5c7:         if (root.isLeaf())
1:5c4d5c7:             return;
1:5c4d5c7: 
1:5c4d5c7:         RangeIterator<Long, Token> tokens = combinedTerm.getTokenIterator();
1:5c4d5c7:         ByteBuffer blockBuffer = ByteBuffer.allocate(BLOCK_BYTES);
1:5c4d5c7:         Iterator<Node> leafIterator = leftmostLeaf.levelIterator();
1:5c4d5c7:         while (leafIterator.hasNext())
1:5c4d5c7:         {
1:5c4d5c7:             Leaf leaf = (Leaf) leafIterator.next();
1:5c4d5c7:             Leaf writeableLeaf = new StaticLeaf(Iterators.limit(tokens, leaf.tokenCount()), leaf);
1:5c4d5c7:             writeableLeaf.serialize(-1, blockBuffer);
1:5c4d5c7:             flushBuffer(blockBuffer, out, true);
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     protected void constructTree()
1:5c4d5c7:     {
1:5c4d5c7:         RangeIterator<Long, Token> tokens = combinedTerm.getTokenIterator();
1:5c4d5c7: 
1:020dd2d:         tokenCount = 0;
1:5c4d5c7:         treeMinToken = tokens.getMinimum();
1:5c4d5c7:         treeMaxToken = tokens.getMaximum();
1:5c4d5c7:         numBlocks = 1;
1:5c4d5c7: 
1:020dd2d:         root = new InteriorNode();
1:020dd2d:         rightmostParent = (InteriorNode) root;
1:020dd2d:         Leaf lastLeaf = null;
1:020dd2d:         Long lastToken, firstToken = null;
1:020dd2d:         int leafSize = 0;
1:020dd2d:         while (tokens.hasNext())
1:5c4d5c7:         {
1:020dd2d:             Long token = tokens.next().get();
1:020dd2d:             if (firstToken == null)
1:020dd2d:                 firstToken = token;
1:020dd2d: 
1:020dd2d:             tokenCount++;
1:020dd2d:             leafSize++;
1:020dd2d: 
1:020dd2d:             // skip until the last token in the leaf
1:020dd2d:             if (tokenCount % TOKENS_PER_BLOCK != 0 && token != treeMaxToken)
1:020dd2d:                 continue;
1:020dd2d: 
1:020dd2d:             lastToken = token;
1:020dd2d:             Leaf leaf = new PartialLeaf(firstToken, lastToken, leafSize);
1:020dd2d:             if (lastLeaf == null) // first leaf created
1:020dd2d:                 leftmostLeaf = leaf;
1:020dd2d:             else
1:020dd2d:                 lastLeaf.next = leaf;
1:020dd2d: 
1:020dd2d: 
1:020dd2d:             rightmostParent.add(leaf);
1:020dd2d:             lastLeaf = rightmostLeaf = leaf;
1:020dd2d:             firstToken = null;
1:020dd2d:             numBlocks++;
1:020dd2d:             leafSize = 0;
1:5c4d5c7:         }
1:020dd2d: 
1:020dd2d:         // if the tree is really a single leaf the empty root interior
1:020dd2d:         // node must be discarded
1:020dd2d:         if (root.tokenCount() == 0)
1:5c4d5c7:         {
1:020dd2d:             numBlocks = 1;
1:020dd2d:             root = new StaticLeaf(combinedTerm.getTokenIterator(), treeMinToken, treeMaxToken, tokenCount, true);
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     // This denotes the leaf which only has min/max and token counts
1:5c4d5c7:     // but doesn't have any associated data yet, so it can't be serialized.
1:5c4d5c7:     private class PartialLeaf extends Leaf
1:5c4d5c7:     {
1:5c4d5c7:         private final int size;
1:5c4d5c7:         public PartialLeaf(Long min, Long max, int count)
1:5c4d5c7:         {
1:5c4d5c7:             super(min, max);
1:5c4d5c7:             size = count;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public int tokenCount()
1:5c4d5c7:         {
1:5c4d5c7:             return size;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void serializeData(ByteBuffer buf)
1:5c4d5c7:         {
1:5c4d5c7:             throw new UnsupportedOperationException();
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public boolean isSerializable()
1:5c4d5c7:         {
1:5c4d5c7:             return false;
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: 
1:5c4d5c7:     // This denotes the leaf which has been filled with data and is ready to be serialized
1:5c4d5c7:     private class StaticLeaf extends Leaf
1:5c4d5c7:     {
1:5c4d5c7:         private final Iterator<Token> tokens;
1:5c4d5c7:         private final int count;
1:5c4d5c7:         private final boolean isLast;
1:5c4d5c7: 
1:5c4d5c7:         public StaticLeaf(Iterator<Token> tokens, Leaf leaf)
1:5c4d5c7:         {
1:5c4d5c7:             this(tokens, leaf.smallestToken(), leaf.largestToken(), leaf.tokenCount(), leaf.isLastLeaf());
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public StaticLeaf(Iterator<Token> tokens, Long min, Long max, long count, boolean isLastLeaf)
1:5c4d5c7:         {
1:5c4d5c7:             super(min, max);
1:5c4d5c7: 
1:5c4d5c7:             this.count = (int) count; // downcast is safe since leaf size is always < Integer.MAX_VALUE
1:5c4d5c7:             this.tokens = tokens;
1:5c4d5c7:             this.isLast = isLastLeaf;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public boolean isLastLeaf()
1:5c4d5c7:         {
1:5c4d5c7:             return isLast;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public int tokenCount()
1:5c4d5c7:         {
1:5c4d5c7:             return count;
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public void serializeData(ByteBuffer buf)
1:5c4d5c7:         {
2:5c4d5c7:             while (tokens.hasNext())
1:5c4d5c7:             {
1:5c4d5c7:                 Token entry = tokens.next();
1:5c4d5c7:                 createEntry(entry.get(), entry.getOffsets()).serialize(buf);
1:5c4d5c7:             }
1:5c4d5c7:         }
1:5c4d5c7: 
1:5c4d5c7:         public boolean isSerializable()
1:5c4d5c7:         {
1:5c4d5c7:             return true;
1:5c4d5c7:         }
1:5c4d5c7:     }
1:5c4d5c7: }
============================================================================
author:Alex Petrov
-------------------------------------------------------------------------------
commit:7d857b4
/////////////////////////////////////////////////////////////////////////
1: import java.util.*;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     public void add(Long token, long partitionOffset, long rowOffset)
1:     public void add(SortedMap<Long, KeyOffsets> data)
1:     public void add(Iterator<Pair<Long, KeyOffsets>> data)
/////////////////////////////////////////////////////////////////////////
1:     public Iterator<Pair<Long, KeyOffsets>> iterator()
1:         @SuppressWarnings("resource") Iterator<Token> iterator = combinedTerm.getTokenIterator();
1:         return new AbstractIterator<Pair<Long, KeyOffsets>>()
1:             protected Pair<Long, KeyOffsets> computeNext()
author:Sam Tunnicliffe
-------------------------------------------------------------------------------
commit:05660a5
/////////////////////////////////////////////////////////////////////////
1: @SuppressWarnings("resource")
author:Jordan West
-------------------------------------------------------------------------------
commit:020dd2d
/////////////////////////////////////////////////////////////////////////
1:         return tokenCount == 0;
/////////////////////////////////////////////////////////////////////////
1:         return tokenCount;
/////////////////////////////////////////////////////////////////////////
1:         tokenCount = 0;
1:         root = new InteriorNode();
1:         rightmostParent = (InteriorNode) root;
1:         Leaf lastLeaf = null;
1:         Long lastToken, firstToken = null;
1:         int leafSize = 0;
1:         while (tokens.hasNext())
1:             Long token = tokens.next().get();
1:             if (firstToken == null)
1:                 firstToken = token;
1: 
1:             tokenCount++;
1:             leafSize++;
1: 
1:             // skip until the last token in the leaf
1:             if (tokenCount % TOKENS_PER_BLOCK != 0 && token != treeMaxToken)
1:                 continue;
1: 
1:             lastToken = token;
1:             Leaf leaf = new PartialLeaf(firstToken, lastToken, leafSize);
1:             if (lastLeaf == null) // first leaf created
1:                 leftmostLeaf = leaf;
1:             else
1:                 lastLeaf.next = leaf;
1: 
1: 
1:             rightmostParent.add(leaf);
1:             lastLeaf = rightmostLeaf = leaf;
1:             firstToken = null;
1:             numBlocks++;
1:             leafSize = 0;
1: 
1:         // if the tree is really a single leaf the empty root interior
1:         // node must be discarded
1:         if (root.tokenCount() == 0)
1:             numBlocks = 1;
1:             root = new StaticLeaf(combinedTerm.getTokenIterator(), treeMinToken, treeMaxToken, tokenCount, true);
commit:5c4d5c7
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.index.sasi.disk;
1: 
1: import java.io.IOException;
1: import java.nio.ByteBuffer;
0: import java.util.Iterator;
0: import java.util.SortedMap;
1: 
1: import org.apache.cassandra.index.sasi.utils.CombinedTerm;
1: import org.apache.cassandra.index.sasi.utils.RangeIterator;
1: import org.apache.cassandra.io.util.DataOutputPlus;
1: import org.apache.cassandra.utils.AbstractIterator;
1: import org.apache.cassandra.utils.Pair;
1: 
0: import com.carrotsearch.hppc.LongSet;
1: import com.google.common.collect.Iterators;
1: 
1: /**
1:  * Intended usage of this class is to be used in place of {@link DynamicTokenTreeBuilder}
1:  * when multiple index segments produced by {@link PerSSTableIndexWriter} are stitched together
1:  * by {@link PerSSTableIndexWriter#complete()}.
1:  *
1:  * This class uses the RangeIterator, now provided by
1:  * {@link CombinedTerm#getTokenIterator()}, to iterate the data twice.
1:  * The first iteration builds the tree with leaves that contain only enough
1:  * information to build the upper layers -- these leaves do not store more
1:  * than their minimum and maximum tokens plus their total size, which makes them
1:  * un-serializable.
1:  *
1:  * When the tree is written to disk the final layer is not
1:  * written. Its at this point the data is iterated once again to write
1:  * the leaves to disk. This (logarithmically) reduces copying of the
1:  * token values while building and writing upper layers of the tree,
1:  * removes the use of SortedMap when combining SAs, and relies on the
1:  * memory mapped SAs otherwise, greatly improving performance and no
1:  * longer causing OOMs when TokenTree sizes are big.
1:  *
1:  * See https://issues.apache.org/jira/browse/CASSANDRA-11383 for more details.
1:  */
1: public class StaticTokenTreeBuilder extends AbstractTokenTreeBuilder
1: {
1:     private final CombinedTerm combinedTerm;
1: 
1:     public StaticTokenTreeBuilder(CombinedTerm term)
1:     {
1:         combinedTerm = term;
1:     }
1: 
0:     public void add(Long token, long keyPosition)
1:     {
1:         throw new UnsupportedOperationException();
1:     }
1: 
0:     public void add(SortedMap<Long, LongSet> data)
1:     {
1:         throw new UnsupportedOperationException();
1:     }
1: 
0:     public void add(Iterator<Pair<Long, LongSet>> data)
1:     {
1:         throw new UnsupportedOperationException();
1:     }
1: 
1:     public boolean isEmpty()
1:     {
0:         return combinedTerm.getTokenIterator().getCount() == 0;
1:     }
1: 
0:     public Iterator<Pair<Long, LongSet>> iterator()
1:     {
0:         Iterator<Token> iterator = combinedTerm.getTokenIterator();
0:         return new AbstractIterator<Pair<Long, LongSet>>()
1:         {
0:             protected Pair<Long, LongSet> computeNext()
1:             {
1:                 if (!iterator.hasNext())
1:                     return endOfData();
1: 
1:                 Token token = iterator.next();
1:                 return Pair.create(token.get(), token.getOffsets());
1:             }
1:         };
1:     }
1: 
1:     public long getTokenCount()
1:     {
0:         return combinedTerm.getTokenIterator().getCount();
1:     }
1: 
1:     @Override
1:     public void write(DataOutputPlus out) throws IOException
1:     {
1:         // if the root is not a leaf then none of the leaves have been written (all are PartialLeaf)
1:         // so write out the last layer of the tree by converting PartialLeaf to StaticLeaf and
1:         // iterating the data once more
1:         super.write(out);
1:         if (root.isLeaf())
1:             return;
1: 
1:         RangeIterator<Long, Token> tokens = combinedTerm.getTokenIterator();
1:         ByteBuffer blockBuffer = ByteBuffer.allocate(BLOCK_BYTES);
1:         Iterator<Node> leafIterator = leftmostLeaf.levelIterator();
1:         while (leafIterator.hasNext())
1:         {
1:             Leaf leaf = (Leaf) leafIterator.next();
1:             Leaf writeableLeaf = new StaticLeaf(Iterators.limit(tokens, leaf.tokenCount()), leaf);
1:             writeableLeaf.serialize(-1, blockBuffer);
1:             flushBuffer(blockBuffer, out, true);
1:         }
1: 
1:     }
1: 
1:     protected void constructTree()
1:     {
1:         RangeIterator<Long, Token> tokens = combinedTerm.getTokenIterator();
1: 
0:         tokenCount = tokens.getCount();
1:         treeMinToken = tokens.getMinimum();
1:         treeMaxToken = tokens.getMaximum();
1:         numBlocks = 1;
1: 
0:         if (tokenCount <= TOKENS_PER_BLOCK)
1:         {
0:             leftmostLeaf = new StaticLeaf(tokens, tokens.getMinimum(), tokens.getMaximum(), tokens.getCount(), true);
0:             rightmostLeaf = leftmostLeaf;
0:             root = leftmostLeaf;
1:         }
0:         else
1:         {
0:             root = new InteriorNode();
0:             rightmostParent = (InteriorNode) root;
1: 
0:             // build all the leaves except for maybe
0:             // the last leaf which is not completely full .
0:             // This loop relies on the fact that multiple index segments
0:             // will never have token intersection for a single term,
0:             // because it's impossible to encounter the same value for
0:             // the same column multiple times in a single key/sstable.
0:             Leaf lastLeaf = null;
0:             long numFullLeaves = tokenCount / TOKENS_PER_BLOCK;
0:             for (long i = 0; i < numFullLeaves; i++)
1:             {
0:                 Long firstToken = tokens.next().get();
0:                 for (int j = 1; j < (TOKENS_PER_BLOCK - 1); j++)
0:                     tokens.next();
1: 
0:                 Long lastToken = tokens.next().get();
0:                 Leaf leaf = new PartialLeaf(firstToken, lastToken, TOKENS_PER_BLOCK);
1: 
0:                 if (lastLeaf == null)
0:                     leftmostLeaf = leaf;
0:                 else
0:                     lastLeaf.next = leaf;
1: 
0:                 rightmostParent.add(leaf);
0:                 lastLeaf = rightmostLeaf = leaf;
0:                 numBlocks++;
1:             }
1: 
0:             // build the last leaf out of any remaining tokens if necessary
0:             // safe downcast since TOKENS_PER_BLOCK is an int
0:             int remainingTokens = (int) (tokenCount % TOKENS_PER_BLOCK);
0:             if (remainingTokens != 0)
1:             {
0:                 Long firstToken = tokens.next().get();
0:                 Long lastToken = firstToken;
1:                 while (tokens.hasNext())
0:                     lastToken = tokens.next().get();
1: 
0:                 Leaf leaf = new PartialLeaf(firstToken, lastToken, remainingTokens);
0:                 rightmostParent.add(leaf);
0:                 lastLeaf.next = rightmostLeaf = leaf;
0:                 numBlocks++;
1:             }
1:         }
1:     }
1: 
1:     // This denotes the leaf which only has min/max and token counts
1:     // but doesn't have any associated data yet, so it can't be serialized.
1:     private class PartialLeaf extends Leaf
1:     {
1:         private final int size;
1:         public PartialLeaf(Long min, Long max, int count)
1:         {
1:             super(min, max);
1:             size = count;
1:         }
1: 
1:         public int tokenCount()
1:         {
1:             return size;
1:         }
1: 
1:         public void serializeData(ByteBuffer buf)
1:         {
1:             throw new UnsupportedOperationException();
1:         }
1: 
1:         public boolean isSerializable()
1:         {
1:             return false;
1:         }
1:     }
1: 
1:     // This denotes the leaf which has been filled with data and is ready to be serialized
1:     private class StaticLeaf extends Leaf
1:     {
1:         private final Iterator<Token> tokens;
1:         private final int count;
1:         private final boolean isLast;
1: 
1:         public StaticLeaf(Iterator<Token> tokens, Leaf leaf)
1:         {
1:             this(tokens, leaf.smallestToken(), leaf.largestToken(), leaf.tokenCount(), leaf.isLastLeaf());
1:         }
1: 
1:         public StaticLeaf(Iterator<Token> tokens, Long min, Long max, long count, boolean isLastLeaf)
1:         {
1:             super(min, max);
1: 
1:             this.count = (int) count; // downcast is safe since leaf size is always < Integer.MAX_VALUE
1:             this.tokens = tokens;
1:             this.isLast = isLastLeaf;
1:         }
1: 
1:         public boolean isLastLeaf()
1:         {
1:             return isLast;
1:         }
1: 
1:         public int tokenCount()
1:         {
1:             return count;
1:         }
1: 
1:         public void serializeData(ByteBuffer buf)
1:         {
1:             while (tokens.hasNext())
1:             {
1:                 Token entry = tokens.next();
1:                 createEntry(entry.get(), entry.getOffsets()).serialize(buf);
1:             }
1:         }
1: 
1:         public boolean isSerializable()
1:         {
1:             return true;
1:         }
1:     }
1: }
============================================================================
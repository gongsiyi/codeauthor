1:6b2ea26: /*
1:6b2ea26:  * Licensed to the Apache Software Foundation (ASF) under one
1:6b2ea26:  * or more contributor license agreements.  See the NOTICE file
1:6b2ea26:  * distributed with this work for additional information
1:6b2ea26:  * regarding copyright ownership.  The ASF licenses this file
1:6b2ea26:  * to you under the Apache License, Version 2.0 (the
1:6b2ea26:  * "License"); you may not use this file except in compliance
1:6b2ea26:  * with the License.  You may obtain a copy of the License at
1:6b2ea26:  *
1:6b2ea26:  *     http://www.apache.org/licenses/LICENSE-2.0
1:6b2ea26:  *
1:6b2ea26:  * Unless required by applicable law or agreed to in writing, software
1:6b2ea26:  * distributed under the License is distributed on an "AS IS" BASIS,
1:6b2ea26:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:6b2ea26:  * See the License for the specific language governing permissions and
1:6b2ea26:  * limitations under the License.
1:6b2ea26:  */
1:6b2ea26: package org.apache.cassandra.utils;
7:6b2ea26: 
1:6b2ea26: import java.io.IOException;
1:6b2ea26: import java.util.*;
1:74bf5aa: 
1:278a5e8: import com.google.common.base.Objects;
1:6b2ea26: 
1:74bf5aa: import org.apache.cassandra.db.TypeSizes;
1:74bf5aa: import org.apache.cassandra.io.ISerializer;
1:03f72ac: import org.apache.cassandra.io.util.DataInputPlus;
1:75508ec: import org.apache.cassandra.io.util.DataOutputPlus;
1:74bf5aa: 
1:6b2ea26: /**
1:6b2ea26:  * Histogram that can be constructed from streaming of data.
1:6b2ea26:  *
1:6b2ea26:  * The algorithm is taken from following paper:
1:6b2ea26:  * Yael Ben-Haim and Elad Tom-Tov, "A Streaming Parallel Decision Tree Algorithm" (2010)
1:6b2ea26:  * http://jmlr.csail.mit.edu/papers/volume11/ben-haim10a/ben-haim10a.pdf
1:6b2ea26:  */
1:6b2ea26: public class StreamingHistogram
3:6b2ea26: {
1:6b2ea26:     public static final StreamingHistogramSerializer serializer = new StreamingHistogramSerializer();
1:6b2ea26: 
1:6b2ea26:     // TreeMap to hold bins of histogram.
1:1e92ce4:     // The key is a numeric type so we can avoid boxing/unboxing streams of different key types
1:1e92ce4:     // The value is a unboxed long array always of length == 1
1:1e92ce4:     // Serialized Histograms always writes with double keys for backwards compatibility
1:1e92ce4:     private final TreeMap<Number, long[]> bin;
1:6b2ea26: 
1:6b2ea26:     // maximum bin size for this histogram
1:6b2ea26:     private final int maxBinSize;
1:6b2ea26: 
1:6b2ea26:     /**
1:6b2ea26:      * Creates a new histogram with max bin size of maxBinSize
1:6b2ea26:      * @param maxBinSize maximum number of bins this histogram can have
1:6b2ea26:      */
1:6b2ea26:     public StreamingHistogram(int maxBinSize)
1:6b2ea26:     {
2:6b2ea26:         this.maxBinSize = maxBinSize;
1:1e92ce4:         bin = new TreeMap<>((o1, o2) -> {
1:1e92ce4:             if (o1.getClass().equals(o2.getClass()))
1:1e92ce4:                 return ((Comparable)o1).compareTo(o2);
1:1e92ce4:             else
1:f1cabca:             	return Double.compare(o1.doubleValue(), o2.doubleValue());
1:1e92ce4:         });
3:6b2ea26:     }
1:278a5e8: 
1:6b2ea26:     private StreamingHistogram(int maxBinSize, Map<Double, Long> bin)
1:0e28478:     {
1:1e92ce4:         this(maxBinSize);
1:1e92ce4:         for (Map.Entry<Double, Long> entry : bin.entrySet())
1:1e92ce4:             this.bin.put(entry.getKey(), new long[]{entry.getValue()});
1:0e28478:     }
1:0e28478: 
1:6b2ea26:     /**
1:6b2ea26:      * Adds new point p to this histogram.
1:6b2ea26:      * @param p
1:6b2ea26:      */
1:1e92ce4:     public void update(Number p)
1:0e28478:     {
1:1e92ce4:         update(p, 1L);
1:6b2ea26:     }
1:0e28478: 
1:6b2ea26:     /**
1:6b2ea26:      * Adds new point p with value m to this histogram.
1:6b2ea26:      * @param p
1:6b2ea26:      * @param m
1:6b2ea26:      */
1:1e92ce4:     public void update(Number p, long m)
1:6b2ea26:     {
1:1e92ce4:         long[] mi = bin.get(p);
1:6b2ea26:         if (mi != null)
1:6b2ea26:         {
1:6b2ea26:             // we found the same p so increment that counter
1:1e92ce4:             mi[0] += m;
1:6b2ea26:         }
1:6b2ea26:         else
1:6b2ea26:         {
1:1e92ce4:             mi = new long[]{m};
1:1e92ce4:             bin.put(p, mi);
1:6b2ea26:             // if bin size exceeds maximum bin size then trim down to max size
1:6b2ea26:             while (bin.size() > maxBinSize)
1:6b2ea26:             {
1:6b2ea26:                 // find points p1, p2 which have smallest difference
1:1e92ce4:                 Iterator<Number> keys = bin.keySet().iterator();
1:1e92ce4:                 double p1 = keys.next().doubleValue();
1:1e92ce4:                 double p2 = keys.next().doubleValue();
1:6b2ea26:                 double smallestDiff = p2 - p1;
1:6b2ea26:                 double q1 = p1, q2 = p2;
1:6b2ea26:                 while (keys.hasNext())
1:6b2ea26:                 {
1:6b2ea26:                     p1 = p2;
1:1e92ce4:                     p2 = keys.next().doubleValue();
1:6b2ea26:                     double diff = p2 - p1;
1:6b2ea26:                     if (diff < smallestDiff)
1:6b2ea26:                     {
1:6b2ea26:                         smallestDiff = diff;
1:6b2ea26:                         q1 = p1;
1:6b2ea26:                         q2 = p2;
1:6b2ea26:                     }
1:6b2ea26:                 }
1:6b2ea26:                 // merge those two
1:1e92ce4:                 long[] a1 = bin.remove(q1);
1:1e92ce4:                 long[] a2 = bin.remove(q2);
1:1e92ce4:                 long k1 = a1[0];
1:1e92ce4:                 long k2 = a2[0];
1:1e92ce4: 
1:1e92ce4:                 a1[0] += k2;
1:1e92ce4:                 bin.put((q1 * k1 + q2 * k2) / (k1 + k2), a1);
1:6b2ea26:             }
1:6b2ea26:         }
1:6b2ea26:     }
1:0e28478: 
1:6b2ea26:     /**
1:6b2ea26:      * Merges given histogram with this histogram.
1:6b2ea26:      *
1:6b2ea26:      * @param other histogram to merge
1:6b2ea26:      */
1:6b2ea26:     public void merge(StreamingHistogram other)
1:6b2ea26:     {
1:6b2ea26:         if (other == null)
1:6b2ea26:             return;
1:0e28478: 
1:1e92ce4:         for (Map.Entry<Number, long[]> entry : other.getAsMap().entrySet())
1:1e92ce4:             update(entry.getKey(), entry.getValue()[0]);
1:6b2ea26:     }
1:0e28478: 
1:6b2ea26:     /**
1:bf2d343:      * Calculates estimated number of points in interval [-inf,b].
1:6b2ea26:      *
1:6b2ea26:      * @param b upper bound of a interval to calculate sum
1:bf2d343:      * @return estimated number of points in a interval [-inf,b].
1:6b2ea26:      */
1:6b2ea26:     public double sum(double b)
1:6b2ea26:     {
1:6b2ea26:         double sum = 0;
1:6b2ea26:         // find the points pi, pnext which satisfy pi <= b < pnext
1:1e92ce4:         Map.Entry<Number, long[]> pnext = bin.higherEntry(b);
1:6b2ea26:         if (pnext == null)
1:6b2ea26:         {
1:6b2ea26:             // if b is greater than any key in this histogram,
1:6b2ea26:             // just count all appearance and return
1:1e92ce4:             for (long[] value : bin.values())
1:1e92ce4:                 sum += value[0];
1:6b2ea26:         }
1:6b2ea26:         else
1:6b2ea26:         {
1:1e92ce4:             Map.Entry<Number, long[]> pi = bin.floorEntry(b);
1:d8742aa:             if (pi == null)
1:d8742aa:                 return 0;
1:6b2ea26:             // calculate estimated count mb for point b
1:1e92ce4:             double weight = (b - pi.getKey().doubleValue()) / (pnext.getKey().doubleValue() - pi.getKey().doubleValue());
1:1e92ce4:             double mb = pi.getValue()[0] + (pnext.getValue()[0] - pi.getValue()[0]) * weight;
1:1e92ce4:             sum += (pi.getValue()[0] + mb) * weight / 2;
1:6b2ea26: 
1:1e92ce4:             sum += pi.getValue()[0] / 2.0;
1:1e92ce4:             for (long[] value : bin.headMap(pi.getKey(), false).values())
1:1e92ce4:                 sum += value[0];
1:6b2ea26:         }
1:6b2ea26:         return sum;
1:6b2ea26:     }
1:6b2ea26: 
1:1e92ce4:     public Map<Number, long[]> getAsMap()
1:6b2ea26:     {
1:6b2ea26:         return Collections.unmodifiableMap(bin);
1:6b2ea26:     }
1:6b2ea26: 
1:6b2ea26:     public static class StreamingHistogramSerializer implements ISerializer<StreamingHistogram>
1:6b2ea26:     {
1:75508ec:         public void serialize(StreamingHistogram histogram, DataOutputPlus out) throws IOException
1:6b2ea26:         {
1:60d9c7f:             out.writeInt(histogram.maxBinSize);
1:1e92ce4:             Map<Number, long[]> entries = histogram.getAsMap();
1:60d9c7f:             out.writeInt(entries.size());
1:1e92ce4:             for (Map.Entry<Number, long[]> entry : entries.entrySet())
1:6b2ea26:             {
1:1e92ce4:                 out.writeDouble(entry.getKey().doubleValue());
1:1e92ce4:                 out.writeLong(entry.getValue()[0]);
1:6b2ea26:             }
1:6b2ea26:         }
1:6b2ea26: 
1:03f72ac:         public StreamingHistogram deserialize(DataInputPlus in) throws IOException
1:6b2ea26:         {
1:60d9c7f:             int maxBinSize = in.readInt();
1:60d9c7f:             int size = in.readInt();
1:74bf5aa:             Map<Double, Long> tmp = new HashMap<>(size);
1:6b2ea26:             for (int i = 0; i < size; i++)
1:6b2ea26:             {
1:60d9c7f:                 tmp.put(in.readDouble(), in.readLong());
1:6b2ea26:             }
1:6b2ea26: 
1:6b2ea26:             return new StreamingHistogram(maxBinSize, tmp);
1:6b2ea26:         }
1:6b2ea26: 
1:03f72ac:         public long serializedSize(StreamingHistogram histogram)
1:6b2ea26:         {
1:03f72ac:             long size = TypeSizes.sizeof(histogram.maxBinSize);
1:1e92ce4:             Map<Number, long[]> entries = histogram.getAsMap();
1:03f72ac:             size += TypeSizes.sizeof(entries.size());
1:74bf5aa:             // size of entries = size * (8(double) + 8(long))
1:5a09483:             size += entries.size() * (8L + 8L);
1:74bf5aa:             return size;
1:6b2ea26:         }
1:6b2ea26:     }
1:6b2ea26: 
1:278a5e8:     @Override
1:278a5e8:     public boolean equals(Object o)
1:278a5e8:     {
1:278a5e8:         if (this == o)
1:278a5e8:             return true;
1:278a5e8: 
1:278a5e8:         if (!(o instanceof StreamingHistogram))
1:278a5e8:             return false;
1:278a5e8: 
1:278a5e8:         StreamingHistogram that = (StreamingHistogram) o;
1:278a5e8:         return maxBinSize == that.maxBinSize && bin.equals(that.bin);
1:278a5e8:     }
1:278a5e8: 
1:278a5e8:     @Override
1:278a5e8:     public int hashCode()
1:278a5e8:     {
1:278a5e8:         return Objects.hashCode(bin.hashCode(), maxBinSize);
1:278a5e8:     }
1:278a5e8: 
1:0e28478: }
============================================================================
author:Dave Brosius
-------------------------------------------------------------------------------
commit:f1cabca
/////////////////////////////////////////////////////////////////////////
1:             	return Double.compare(o1.doubleValue(), o2.doubleValue());
commit:5a09483
/////////////////////////////////////////////////////////////////////////
1:             size += entries.size() * (8L + 8L);
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:1e92ce4
/////////////////////////////////////////////////////////////////////////
1:     // The key is a numeric type so we can avoid boxing/unboxing streams of different key types
1:     // The value is a unboxed long array always of length == 1
1:     // Serialized Histograms always writes with double keys for backwards compatibility
1:     private final TreeMap<Number, long[]> bin;
/////////////////////////////////////////////////////////////////////////
1:         bin = new TreeMap<>((o1, o2) -> {
1:             if (o1.getClass().equals(o2.getClass()))
1:                 return ((Comparable)o1).compareTo(o2);
1:             else
0:                 return ((Double)o1.doubleValue()).compareTo(o2.doubleValue());
1:         });
1:         this(maxBinSize);
1:         for (Map.Entry<Double, Long> entry : bin.entrySet())
1:             this.bin.put(entry.getKey(), new long[]{entry.getValue()});
1:     public void update(Number p)
1:         update(p, 1L);
/////////////////////////////////////////////////////////////////////////
1:     public void update(Number p, long m)
1:         long[] mi = bin.get(p);
1:             mi[0] += m;
1:             mi = new long[]{m};
1:             bin.put(p, mi);
1:                 Iterator<Number> keys = bin.keySet().iterator();
1:                 double p1 = keys.next().doubleValue();
1:                 double p2 = keys.next().doubleValue();
1:                     p2 = keys.next().doubleValue();
/////////////////////////////////////////////////////////////////////////
1:                 long[] a1 = bin.remove(q1);
1:                 long[] a2 = bin.remove(q2);
1:                 long k1 = a1[0];
1:                 long k2 = a2[0];
1: 
1:                 a1[0] += k2;
1:                 bin.put((q1 * k1 + q2 * k2) / (k1 + k2), a1);
/////////////////////////////////////////////////////////////////////////
1:         for (Map.Entry<Number, long[]> entry : other.getAsMap().entrySet())
1:             update(entry.getKey(), entry.getValue()[0]);
/////////////////////////////////////////////////////////////////////////
1:         Map.Entry<Number, long[]> pnext = bin.higherEntry(b);
1:             for (long[] value : bin.values())
1:                 sum += value[0];
1:             Map.Entry<Number, long[]> pi = bin.floorEntry(b);
1:             double weight = (b - pi.getKey().doubleValue()) / (pnext.getKey().doubleValue() - pi.getKey().doubleValue());
1:             double mb = pi.getValue()[0] + (pnext.getValue()[0] - pi.getValue()[0]) * weight;
1:             sum += (pi.getValue()[0] + mb) * weight / 2;
1:             sum += pi.getValue()[0] / 2.0;
1:             for (long[] value : bin.headMap(pi.getKey(), false).values())
1:                 sum += value[0];
1:     public Map<Number, long[]> getAsMap()
/////////////////////////////////////////////////////////////////////////
1:             Map<Number, long[]> entries = histogram.getAsMap();
1:             for (Map.Entry<Number, long[]> entry : entries.entrySet())
1:                 out.writeDouble(entry.getKey().doubleValue());
1:                 out.writeLong(entry.getValue()[0]);
/////////////////////////////////////////////////////////////////////////
1:             Map<Number, long[]> entries = histogram.getAsMap();
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus;
/////////////////////////////////////////////////////////////////////////
1:         public StreamingHistogram deserialize(DataInputPlus in) throws IOException
/////////////////////////////////////////////////////////////////////////
1:         public long serializedSize(StreamingHistogram histogram)
1:             long size = TypeSizes.sizeof(histogram.maxBinSize);
1:             size += TypeSizes.sizeof(entries.size());
author:belliottsmith
-------------------------------------------------------------------------------
commit:75508ec
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataOutputPlus;
/////////////////////////////////////////////////////////////////////////
1:         public void serialize(StreamingHistogram histogram, DataOutputPlus out) throws IOException
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:74bf5aa
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.apache.cassandra.db.TypeSizes;
1: import org.apache.cassandra.io.ISerializer;
1: 
/////////////////////////////////////////////////////////////////////////
0:         bin = new TreeMap<>();
0:         this.bin = new TreeMap<>(bin);
/////////////////////////////////////////////////////////////////////////
1:             Map<Double, Long> tmp = new HashMap<>(size);
/////////////////////////////////////////////////////////////////////////
0:             long size = typeSizes.sizeof(histogram.maxBinSize);
0:             Map<Double, Long> entries = histogram.getAsMap();
0:             size += typeSizes.sizeof(entries.size());
1:             // size of entries = size * (8(double) + 8(long))
0:             size += entries.size() * (8 + 8);
1:             return size;
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:60d9c7f
/////////////////////////////////////////////////////////////////////////
0:         public void serialize(StreamingHistogram histogram, DataOutput out) throws IOException
1:             out.writeInt(histogram.maxBinSize);
1:             out.writeInt(entries.size());
0:                 out.writeDouble(entry.getKey());
0:                 out.writeLong(entry.getValue());
0:         public StreamingHistogram deserialize(DataInput in) throws IOException
1:             int maxBinSize = in.readInt();
1:             int size = in.readInt();
1:                 tmp.put(in.readDouble(), in.readLong());
commit:278a5e8
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.base.Objects;
/////////////////////////////////////////////////////////////////////////
1: 
1:     @Override
1:     public boolean equals(Object o)
1:     {
1:         if (this == o)
1:             return true;
1: 
1:         if (!(o instanceof StreamingHistogram))
1:             return false;
1: 
1:         StreamingHistogram that = (StreamingHistogram) o;
1:         return maxBinSize == that.maxBinSize && bin.equals(that.bin);
1:     }
1: 
1:     @Override
1:     public int hashCode()
1:     {
1:         return Objects.hashCode(bin.hashCode(), maxBinSize);
1:     }
1: 
commit:5bd57cb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:0e28478
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Objects;
/////////////////////////////////////////////////////////////////////////
1: 
0:     @Override
0:     public boolean equals(Object o)
1:     {
0:         if (this == o)
0:             return true;
1: 
0:         if (!(o instanceof StreamingHistogram))
0:             return false;
1: 
0:         StreamingHistogram that = (StreamingHistogram) o;
0:         return maxBinSize == that.maxBinSize && bin.equals(that.bin);
1:     }
1: 
0:     @Override
0:     public int hashCode()
1:     {
0:         return Objects.hashCode(bin.hashCode(), maxBinSize);
1:     }
1: 
commit:2ae5272
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.TypeSizes;
/////////////////////////////////////////////////////////////////////////
0:         public long serializedSize(StreamingHistogram histogram, TypeSizes typeSizes)
commit:6b2ea26
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.utils;
1: 
0: import org.apache.cassandra.db.DBConstants;
0: import org.apache.cassandra.io.ISerializer;
1: 
0: import java.io.DataInput;
0: import java.io.DataOutput;
1: import java.io.IOException;
1: import java.util.*;
1: 
1: /**
1:  * Histogram that can be constructed from streaming of data.
1:  *
1:  * The algorithm is taken from following paper:
1:  * Yael Ben-Haim and Elad Tom-Tov, "A Streaming Parallel Decision Tree Algorithm" (2010)
1:  * http://jmlr.csail.mit.edu/papers/volume11/ben-haim10a/ben-haim10a.pdf
1:  */
1: public class StreamingHistogram
1: {
1:     public static final StreamingHistogramSerializer serializer = new StreamingHistogramSerializer();
1: 
1:     // TreeMap to hold bins of histogram.
0:     private final TreeMap<Double, Long> bin;
1: 
1:     // maximum bin size for this histogram
1:     private final int maxBinSize;
1: 
1:     /**
1:      * Creates a new histogram with max bin size of maxBinSize
1:      * @param maxBinSize maximum number of bins this histogram can have
1:      */
1:     public StreamingHistogram(int maxBinSize)
1:     {
1:         this.maxBinSize = maxBinSize;
0:         bin = new TreeMap<Double, Long>();
1:     }
1: 
1:     private StreamingHistogram(int maxBinSize, Map<Double, Long> bin)
1:     {
1:         this.maxBinSize = maxBinSize;
0:         this.bin = new TreeMap<Double, Long>(bin);
1:     }
1: 
1:     /**
1:      * Adds new point p to this histogram.
1:      * @param p
1:      */
0:     public void update(double p)
1:     {
0:         update(p, 1);
1:     }
1: 
1:     /**
1:      * Adds new point p with value m to this histogram.
1:      * @param p
1:      * @param m
1:      */
0:     public void update(double p, long m)
1:     {
0:         Long mi = bin.get(p);
1:         if (mi != null)
1:         {
1:             // we found the same p so increment that counter
0:             bin.put(p, mi + m);
1:         }
1:         else
1:         {
0:             bin.put(p, m);
1:             // if bin size exceeds maximum bin size then trim down to max size
1:             while (bin.size() > maxBinSize)
1:             {
1:                 // find points p1, p2 which have smallest difference
0:                 Iterator<Double> keys = bin.keySet().iterator();
0:                 double p1 = keys.next();
0:                 double p2 = keys.next();
1:                 double smallestDiff = p2 - p1;
1:                 double q1 = p1, q2 = p2;
1:                 while (keys.hasNext())
1:                 {
1:                     p1 = p2;
0:                     p2 = keys.next();
1:                     double diff = p2 - p1;
1:                     if (diff < smallestDiff)
1:                     {
1:                         smallestDiff = diff;
1:                         q1 = p1;
1:                         q2 = p2;
1:                     }
1:                 }
1:                 // merge those two
0:                 long k1 = bin.remove(q1);
0:                 long k2 = bin.remove(q2);
0:                 bin.put((q1 * k1 + q2 * k2) / (k1 + k2), k1 + k2);
1:             }
1:         }
1:     }
1: 
1:     /**
1:      * Merges given histogram with this histogram.
1:      *
1:      * @param other histogram to merge
1:      */
1:     public void merge(StreamingHistogram other)
1:     {
1:         if (other == null)
1:             return;
1: 
0:         for (Map.Entry<Double, Long> entry : other.getAsMap().entrySet())
0:             update(entry.getKey(), entry.getValue());
1:     }
1: 
1:     /**
0:      * Calculates estimated number of points in interval [-âˆ?,b].
1:      *
1:      * @param b upper bound of a interval to calculate sum
0:      * @return estimated number of points in a interval [-âˆ?,b].
1:      */
1:     public double sum(double b)
1:     {
1:         double sum = 0;
1:         // find the points pi, pnext which satisfy pi <= b < pnext
0:         Map.Entry<Double, Long> pnext = bin.higherEntry(b);
1:         if (pnext == null)
1:         {
1:             // if b is greater than any key in this histogram,
1:             // just count all appearance and return
0:             for (Long value : bin.values())
0:                 sum += value;
1:         }
1:         else
1:         {
0:             Map.Entry<Double, Long> pi = bin.floorEntry(b);
1:             // calculate estimated count mb for point b
0:             double weight = (b - pi.getKey()) / (pnext.getKey() - pi.getKey());
0:             double mb = pi.getValue() + (pnext.getValue() - pi.getValue()) * weight;
0:             sum += (pi.getValue() + mb) * weight / 2;
1: 
0:             sum += pi.getValue() / 2;
0:             for (Long value : bin.headMap(pi.getKey(), false).values())
0:                 sum += value;
1:         }
1:         return sum;
1:     }
1: 
0:     public Map<Double, Long> getAsMap()
1:     {
1:         return Collections.unmodifiableMap(bin);
1:     }
1: 
1:     public static class StreamingHistogramSerializer implements ISerializer<StreamingHistogram>
1:     {
0:         public void serialize(StreamingHistogram histogram, DataOutput dos) throws IOException
1:         {
0:             dos.writeInt(histogram.maxBinSize);
0:             Map<Double, Long> entries = histogram.getAsMap();
0:             dos.writeInt(entries.size());
0:             for (Map.Entry<Double, Long> entry : entries.entrySet())
1:             {
0:                 dos.writeDouble(entry.getKey());
0:                 dos.writeLong(entry.getValue());
1:             }
1:         }
1: 
0:         public StreamingHistogram deserialize(DataInput dis) throws IOException
1:         {
0:             int maxBinSize = dis.readInt();
0:             int size = dis.readInt();
0:             Map<Double, Long> tmp = new HashMap<Double, Long>(size);
1:             for (int i = 0; i < size; i++)
1:             {
0:                 tmp.put(dis.readDouble(), dis.readLong());
1:             }
1: 
1:             return new StreamingHistogram(maxBinSize, tmp);
1:         }
1: 
0:         public long serializedSize(StreamingHistogram histogram)
1:         {
0:             throw new UnsupportedOperationException();
1:         }
1:     }
1: }
author:Pierre-Yves Ritschard
-------------------------------------------------------------------------------
commit:bf2d343
/////////////////////////////////////////////////////////////////////////
1:      * Calculates estimated number of points in interval [-inf,b].
1:      * @return estimated number of points in a interval [-inf,b].
author:Vijay Parthasarathy
-------------------------------------------------------------------------------
commit:cb25a8f
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.DBTypeSizes;
/////////////////////////////////////////////////////////////////////////
0:         public long serializedSize(StreamingHistogram histogram, DBTypeSizes typeSizes)
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:23b1c52
/////////////////////////////////////////////////////////////////////////
0:             sum += pi.getValue() / 2.0;
author:Brandon Williams
-------------------------------------------------------------------------------
commit:d8742aa
/////////////////////////////////////////////////////////////////////////
1:             if (pi == null)
1:                 return 0;
============================================================================
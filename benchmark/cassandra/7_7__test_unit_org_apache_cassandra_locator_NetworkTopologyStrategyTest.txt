1:34e241a: /*
1:a991b64:  * Licensed to the Apache Software Foundation (ASF) under one
1:a991b64:  * or more contributor license agreements.  See the NOTICE file
1:a991b64:  * distributed with this work for additional information
1:a991b64:  * regarding copyright ownership.  The ASF licenses this file
1:a991b64:  * to you under the Apache License, Version 2.0 (the
1:a991b64:  * "License"); you may not use this file except in compliance
1:a991b64:  * with the License.  You may obtain a copy of the License at
1:a991b64:  *
1:a991b64:  *     http://www.apache.org/licenses/LICENSE-2.0
1:a991b64:  *
1:a991b64:  * Unless required by applicable law or agreed to in writing, software
1:a991b64:  * distributed under the License is distributed on an "AS IS" BASIS,
1:a991b64:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:a991b64:  * See the License for the specific language governing permissions and
1:a991b64:  * limitations under the License.
1:a991b64:  */
1:9688a79: 
1:5a45534: package org.apache.cassandra.locator;
1:34e241a: 
1:5a45534: import java.io.IOException;
1:5a45534: import java.net.InetAddress;
1:5a45534: import java.net.UnknownHostException;
1:c000da1: import java.util.*;
1:c000da1: import java.util.stream.Collectors;
6:5a45534: 
1:a991b64: import com.google.common.collect.HashMultimap;
1:c000da1: import com.google.common.collect.ImmutableMap;
1:a991b64: import com.google.common.collect.Multimap;
1:c000da1: 
1:83a43f1: import org.junit.Assert;
1:9797511: import org.junit.BeforeClass;
1:34e241a: import org.junit.Test;
1:c000da1: 
1:9688a79: import org.slf4j.Logger;
1:9688a79: import org.slf4j.LoggerFactory;
1:34e241a: 
1:9688a79: import org.apache.cassandra.config.DatabaseDescriptor;
1:c000da1: import org.apache.cassandra.dht.Murmur3Partitioner;
1:07893d7: import org.apache.cassandra.dht.OrderPreservingPartitioner.StringToken;
1:5a45534: import org.apache.cassandra.dht.Token;
1:a991b64: import org.apache.cassandra.exceptions.ConfigurationException;
1:c000da1: import org.apache.cassandra.locator.TokenMetadata.Topology;
1:c000da1: import org.apache.cassandra.service.StorageService;
1:e85afdc: 
1:916c810: public class NetworkTopologyStrategyTest
1:5a45534: {
1:0e96e58:     private String keyspaceName = "Keyspace1";
1:9688a79:     private static final Logger logger = LoggerFactory.getLogger(NetworkTopologyStrategyTest.class);
1:5a45534: 
1:9797511:     @BeforeClass
1:9797511:     public static void setupDD()
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:9797511:     }
1:9797511: 
1:402e1ed:     @Test
1:9688a79:     public void testProperties() throws IOException, ConfigurationException
1:5a45534:     {
1:df8a933:         IEndpointSnitch snitch = new PropertyFileSnitch();
1:9688a79:         DatabaseDescriptor.setEndpointSnitch(snitch);
1:5a45534:         TokenMetadata metadata = new TokenMetadata();
1:402e1ed:         createDummyTokens(metadata, true);
1:df8a933: 
1:df8a933:         Map<String, String> configOptions = new HashMap<String, String>();
1:df8a933:         configOptions.put("DC1", "3");
1:df8a933:         configOptions.put("DC2", "2");
1:df8a933:         configOptions.put("DC3", "1");
1:df8a933: 
1:df8a933:         // Set the localhost to the tokenmetadata. Embedded cassandra way?
1:0e96e58:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
1:df8a933:         assert strategy.getReplicationFactor("DC1") == 3;
1:df8a933:         assert strategy.getReplicationFactor("DC2") == 2;
1:df8a933:         assert strategy.getReplicationFactor("DC3") == 1;
1:5a45534:         // Query for the natural hosts
1:df8a933:         ArrayList<InetAddress> endpoints = strategy.getNaturalEndpoints(new StringToken("123"));
1:5a45534:         assert 6 == endpoints.size();
1:91aa0d5:         assert 6 == new HashSet<InetAddress>(endpoints).size(); // ensure uniqueness
1:5a45534:     }
1:5a45534: 
1:9688a79:     @Test
1:9688a79:     public void testPropertiesWithEmptyDC() throws IOException, ConfigurationException
1:402e1ed:     {
1:402e1ed:         IEndpointSnitch snitch = new PropertyFileSnitch();
1:9688a79:         DatabaseDescriptor.setEndpointSnitch(snitch);
1:402e1ed:         TokenMetadata metadata = new TokenMetadata();
1:402e1ed:         createDummyTokens(metadata, false);
1:402e1ed: 
1:402e1ed:         Map<String, String> configOptions = new HashMap<String, String>();
1:402e1ed:         configOptions.put("DC1", "3");
1:402e1ed:         configOptions.put("DC2", "3");
1:402e1ed:         configOptions.put("DC3", "0");
1:402e1ed: 
1:402e1ed:         // Set the localhost to the tokenmetadata. Embedded cassandra way?
1:0e96e58:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
1:402e1ed:         assert strategy.getReplicationFactor("DC1") == 3;
1:402e1ed:         assert strategy.getReplicationFactor("DC2") == 3;
1:402e1ed:         assert strategy.getReplicationFactor("DC3") == 0;
1:402e1ed:         // Query for the natural hosts
1:402e1ed:         ArrayList<InetAddress> endpoints = strategy.getNaturalEndpoints(new StringToken("123"));
1:402e1ed:         assert 6 == endpoints.size();
1:402e1ed:         assert 6 == new HashSet<InetAddress>(endpoints).size(); // ensure uniqueness
1:402e1ed:     }
1:402e1ed: 
1:5a45534:     @Test
1:9688a79:     public void testLargeCluster() throws UnknownHostException, ConfigurationException
1:9688a79:     {
1:9688a79:         int[] dcRacks = new int[]{2, 4, 8};
1:9688a79:         int[] dcEndpoints = new int[]{128, 256, 512};
1:9688a79:         int[] dcReplication = new int[]{2, 6, 6};
1:9688a79: 
1:9688a79:         IEndpointSnitch snitch = new RackInferringSnitch();
1:9688a79:         DatabaseDescriptor.setEndpointSnitch(snitch);
1:9688a79:         TokenMetadata metadata = new TokenMetadata();
1:9688a79:         Map<String, String> configOptions = new HashMap<String, String>();
1:e85afdc:         Multimap<InetAddress, Token> tokens = HashMultimap.create();
1:9688a79: 
1:9688a79:         int totalRF = 0;
1:9688a79:         for (int dc = 0; dc < dcRacks.length; ++dc)
1:9688a79:         {
1:9688a79:             totalRF += dcReplication[dc];
1:9688a79:             configOptions.put(Integer.toString(dc), Integer.toString(dcReplication[dc]));
1:9688a79:             for (int rack = 0; rack < dcRacks[dc]; ++rack)
1:9688a79:             {
1:9688a79:                 for (int ep = 1; ep <= dcEndpoints[dc]/dcRacks[dc]; ++ep)
1:9688a79:                 {
1:9688a79:                     byte[] ipBytes = new byte[]{10, (byte)dc, (byte)rack, (byte)ep};
1:9688a79:                     InetAddress address = InetAddress.getByAddress(ipBytes);
1:9688a79:                     StringToken token = new StringToken(String.format("%02x%02x%02x", ep, rack, dc));
1:b74c2ad:                     logger.debug("adding node {} at {}", address, token);
1:e85afdc:                     tokens.put(address, token);
1:9688a79:                 }
1:9688a79:             }
1:9688a79:         }
1:9688a79:         metadata.updateNormalTokens(tokens);
1:9688a79: 
1:0e96e58:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
1:9688a79: 
1:9688a79:         for (String testToken : new String[]{"123456", "200000", "000402", "ffffff", "400200"})
1:9688a79:         {
1:9688a79:             List<InetAddress> endpoints = strategy.calculateNaturalEndpoints(new StringToken(testToken), metadata);
1:9688a79:             Set<InetAddress> epSet = new HashSet<InetAddress>(endpoints);
1:9688a79: 
1:9688a79:             Assert.assertEquals(totalRF, endpoints.size());
1:9688a79:             Assert.assertEquals(totalRF, epSet.size());
1:b74c2ad:             logger.debug("{}: {}", testToken, endpoints);
1:9688a79:         }
1:9688a79:     }
1:9688a79: 
1:402e1ed:     public void createDummyTokens(TokenMetadata metadata, boolean populateDC3) throws UnknownHostException
1:5a45534:     {
1:5a45534:         // DC 1
1:5a45534:         tokenFactory(metadata, "123", new byte[]{ 10, 0, 0, 10 });
1:5a45534:         tokenFactory(metadata, "234", new byte[]{ 10, 0, 0, 11 });
1:5a45534:         tokenFactory(metadata, "345", new byte[]{ 10, 0, 0, 12 });
1:5a45534:         // Tokens for DC 2
1:5a45534:         tokenFactory(metadata, "789", new byte[]{ 10, 20, 114, 10 });
1:5a45534:         tokenFactory(metadata, "890", new byte[]{ 10, 20, 114, 11 });
1:5a45534:         //tokens for DC3
1:402e1ed:         if (populateDC3)
1:402e1ed:         {
1:402e1ed:             tokenFactory(metadata, "456", new byte[]{ 10, 21, 119, 13 });
1:402e1ed:             tokenFactory(metadata, "567", new byte[]{ 10, 21, 119, 10 });
1:402e1ed:         }
1:5a45534:         // Extra Tokens
1:5a45534:         tokenFactory(metadata, "90A", new byte[]{ 10, 0, 0, 13 });
1:402e1ed:         if (populateDC3)
1:402e1ed:             tokenFactory(metadata, "0AB", new byte[]{ 10, 21, 119, 14 });
1:5a45534:         tokenFactory(metadata, "ABC", new byte[]{ 10, 20, 114, 15 });
1:5a45534:     }
1:5a45534: 
1:5a45534:     public void tokenFactory(TokenMetadata metadata, String token, byte[] bytes) throws UnknownHostException
1:5a45534:     {
1:5a45534:         Token token1 = new StringToken(token);
1:5a45534:         InetAddress add1 = InetAddress.getByAddress(bytes);
1:5a45534:         metadata.updateNormalToken(token1, add1);
1:5a45534:     }
1:c000da1: 
1:c000da1:     @Test
1:c000da1:     public void testCalculateEndpoints() throws UnknownHostException
1:c000da1:     {
1:c000da1:         final int NODES = 100;
1:c000da1:         final int VNODES = 64;
1:c000da1:         final int RUNS = 10;
1:c000da1:         StorageService.instance.setPartitionerUnsafe(Murmur3Partitioner.instance);
1:c000da1:         Map<String, Integer> datacenters = ImmutableMap.of("rf1", 1, "rf3", 3, "rf5_1", 5, "rf5_2", 5, "rf5_3", 5);
1:c000da1:         List<InetAddress> nodes = new ArrayList<>(NODES);
1:c000da1:         for (byte i=0; i<NODES; ++i)
1:c000da1:             nodes.add(InetAddress.getByAddress(new byte[]{127, 0, 0, i}));
1:c000da1:         for (int run=0; run<RUNS; ++run)
1:c000da1:         {
1:c000da1:             Random rand = new Random();
1:c000da1:             IEndpointSnitch snitch = generateSnitch(datacenters, nodes, rand);
1:c000da1:             DatabaseDescriptor.setEndpointSnitch(snitch);
1:c000da1: 
1:c000da1:             TokenMetadata meta = new TokenMetadata();
1:c000da1:             for (int i=0; i<NODES; ++i)  // Nodes
1:c000da1:                 for (int j=0; j<VNODES; ++j) // tokens/vnodes per node
1:c000da1:                     meta.updateNormalToken(Murmur3Partitioner.instance.getRandomToken(rand), nodes.get(i));
1:c000da1:             testEquivalence(meta, snitch, datacenters, rand);
1:c000da1:         }
1:c000da1:     }
1:c000da1: 
1:c000da1:     void testEquivalence(TokenMetadata tokenMetadata, IEndpointSnitch snitch, Map<String, Integer> datacenters, Random rand)
1:c000da1:     {
1:c000da1:         NetworkTopologyStrategy nts = new NetworkTopologyStrategy("ks", tokenMetadata, snitch,
1:c000da1:                                                                   datacenters.entrySet().stream().
1:c000da1:                                                                       collect(Collectors.toMap(x -> x.getKey(), x -> Integer.toString(x.getValue()))));
1:c000da1:         for (int i=0; i<1000; ++i)
1:c000da1:         {
1:c000da1:             Token token = Murmur3Partitioner.instance.getRandomToken(rand);
1:c000da1:             List<InetAddress> expected = calculateNaturalEndpoints(token, tokenMetadata, datacenters, snitch);
1:c000da1:             List<InetAddress> actual = nts.calculateNaturalEndpoints(token, tokenMetadata);
1:c000da1:             if (endpointsDiffer(expected, actual))
1:c000da1:             {
1:c000da1:                 System.err.println("Endpoints mismatch for token " + token);
1:c000da1:                 System.err.println(" expected: " + expected);
1:c000da1:                 System.err.println(" actual  : " + actual);
1:c000da1:                 Assert.assertEquals("Endpoints for token " + token + " mismatch.", expected, actual);
1:c000da1:             }
1:c000da1:         }
1:c000da1:     }
1:c000da1: 
1:c000da1:     private boolean endpointsDiffer(List<InetAddress> ep1, List<InetAddress> ep2)
1:c000da1:     {
1:c000da1:         // Because the old algorithm does not put the nodes in the correct order in the case where more replicas
1:c000da1:         // are required than there are racks in a dc, we accept different order as long as the primary
1:c000da1:         // replica is the same.
1:c000da1:         if (ep1.equals(ep2))
1:c000da1:             return false;
1:c000da1:         if (!ep1.get(0).equals(ep2.get(0)))
1:c000da1:             return true;
1:c000da1:         Set<InetAddress> s1 = new HashSet<>(ep1);
1:c000da1:         Set<InetAddress> s2 = new HashSet<>(ep2);
1:c000da1:         return !s1.equals(s2);
1:c000da1:     }
1:c000da1: 
1:c000da1:     IEndpointSnitch generateSnitch(Map<String, Integer> datacenters, Collection<InetAddress> nodes, Random rand)
1:c000da1:     {
1:c000da1:         final Map<InetAddress, String> nodeToRack = new HashMap<>();
1:c000da1:         final Map<InetAddress, String> nodeToDC = new HashMap<>();
1:c000da1:         Map<String, List<String>> racksPerDC = new HashMap<>();
1:c000da1:         datacenters.forEach((dc, rf) -> racksPerDC.put(dc, randomRacks(rf, rand)));
1:c000da1:         int rf = datacenters.values().stream().mapToInt(x -> x).sum();
1:c000da1:         String[] dcs = new String[rf];
1:c000da1:         int pos = 0;
1:c000da1:         for (Map.Entry<String, Integer> dce : datacenters.entrySet())
1:c000da1:         {
1:c000da1:             for (int i = 0; i < dce.getValue(); ++i)
1:c000da1:                 dcs[pos++] = dce.getKey();
1:c000da1:         }
1:c000da1: 
1:c000da1:         for (InetAddress node : nodes)
1:c000da1:         {
1:c000da1:             String dc = dcs[rand.nextInt(rf)];
1:c000da1:             List<String> racks = racksPerDC.get(dc);
1:c000da1:             String rack = racks.get(rand.nextInt(racks.size()));
1:c000da1:             nodeToRack.put(node, rack);
1:c000da1:             nodeToDC.put(node, dc);
1:c000da1:         }
1:c000da1: 
1:c000da1:         return new AbstractNetworkTopologySnitch()
1:c000da1:         {
1:c000da1:             public String getRack(InetAddress endpoint)
1:c000da1:             {
1:c000da1:                 return nodeToRack.get(endpoint);
1:c000da1:             }
1:c000da1: 
1:c000da1:             public String getDatacenter(InetAddress endpoint)
1:c000da1:             {
1:c000da1:                 return nodeToDC.get(endpoint);
1:c000da1:             }
1:c000da1:         };
1:c000da1:     }
1:c000da1: 
1:c000da1:     private List<String> randomRacks(int rf, Random rand)
1:c000da1:     {
1:c000da1:         int rc = rand.nextInt(rf * 3 - 1) + 1;
1:c000da1:         List<String> racks = new ArrayList<>(rc);
1:c000da1:         for (int i=0; i<rc; ++i)
1:c000da1:             racks.add(Integer.toString(i));
1:c000da1:         return racks;
1:c000da1:     }
1:c000da1: 
1:c000da1:     // Copy of older endpoints calculation algorithm for comparison
1:c000da1:     public static List<InetAddress> calculateNaturalEndpoints(Token searchToken, TokenMetadata tokenMetadata, Map<String, Integer> datacenters, IEndpointSnitch snitch)
1:c000da1:     {
1:c000da1:         // we want to preserve insertion order so that the first added endpoint becomes primary
1:c000da1:         Set<InetAddress> replicas = new LinkedHashSet<>();
1:c000da1:         // replicas we have found in each DC
1:c000da1:         Map<String, Set<InetAddress>> dcReplicas = new HashMap<>(datacenters.size());
1:c000da1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:c000da1:             dcReplicas.put(dc.getKey(), new HashSet<InetAddress>(dc.getValue()));
1:c000da1: 
1:c000da1:         Topology topology = tokenMetadata.getTopology();
1:c000da1:         // all endpoints in each DC, so we can check when we have exhausted all the members of a DC
1:c000da1:         Multimap<String, InetAddress> allEndpoints = topology.getDatacenterEndpoints();
1:c000da1:         // all racks in a DC so we can check when we have exhausted all racks in a DC
1:c000da1:         Map<String, Multimap<String, InetAddress>> racks = topology.getDatacenterRacks();
1:c000da1:         assert !allEndpoints.isEmpty() && !racks.isEmpty() : "not aware of any cluster members";
1:c000da1: 
1:c000da1:         // tracks the racks we have already placed replicas in
1:c000da1:         Map<String, Set<String>> seenRacks = new HashMap<>(datacenters.size());
1:c000da1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:c000da1:             seenRacks.put(dc.getKey(), new HashSet<String>());
1:c000da1: 
1:c000da1:         // tracks the endpoints that we skipped over while looking for unique racks
1:c000da1:         // when we relax the rack uniqueness we can append this to the current result so we don't have to wind back the iterator
1:c000da1:         Map<String, Set<InetAddress>> skippedDcEndpoints = new HashMap<>(datacenters.size());
1:c000da1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:c000da1:             skippedDcEndpoints.put(dc.getKey(), new LinkedHashSet<InetAddress>());
1:c000da1: 
1:c000da1:         Iterator<Token> tokenIter = TokenMetadata.ringIterator(tokenMetadata.sortedTokens(), searchToken, false);
1:c000da1:         while (tokenIter.hasNext() && !hasSufficientReplicas(dcReplicas, allEndpoints, datacenters))
1:c000da1:         {
1:c000da1:             Token next = tokenIter.next();
1:c000da1:             InetAddress ep = tokenMetadata.getEndpoint(next);
1:c000da1:             String dc = snitch.getDatacenter(ep);
1:c000da1:             // have we already found all replicas for this dc?
1:c000da1:             if (!datacenters.containsKey(dc) || hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:c000da1:                 continue;
1:c000da1:             // can we skip checking the rack?
1:c000da1:             if (seenRacks.get(dc).size() == racks.get(dc).keySet().size())
1:c000da1:             {
1:c000da1:                 dcReplicas.get(dc).add(ep);
1:c000da1:                 replicas.add(ep);
1:c000da1:             }
1:c000da1:             else
1:c000da1:             {
1:c000da1:                 String rack = snitch.getRack(ep);
1:c000da1:                 // is this a new rack?
1:c000da1:                 if (seenRacks.get(dc).contains(rack))
1:c000da1:                 {
1:c000da1:                     skippedDcEndpoints.get(dc).add(ep);
1:c000da1:                 }
1:c000da1:                 else
1:c000da1:                 {
1:c000da1:                     dcReplicas.get(dc).add(ep);
1:c000da1:                     replicas.add(ep);
1:c000da1:                     seenRacks.get(dc).add(rack);
1:c000da1:                     // if we've run out of distinct racks, add the hosts we skipped past already (up to RF)
1:c000da1:                     if (seenRacks.get(dc).size() == racks.get(dc).keySet().size())
1:c000da1:                     {
1:c000da1:                         Iterator<InetAddress> skippedIt = skippedDcEndpoints.get(dc).iterator();
1:c000da1:                         while (skippedIt.hasNext() && !hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:c000da1:                         {
1:c000da1:                             InetAddress nextSkipped = skippedIt.next();
1:c000da1:                             dcReplicas.get(dc).add(nextSkipped);
1:c000da1:                             replicas.add(nextSkipped);
1:c000da1:                         }
1:c000da1:                     }
1:c000da1:                 }
1:c000da1:             }
1:c000da1:         }
1:c000da1: 
1:c000da1:         return new ArrayList<InetAddress>(replicas);
1:c000da1:     }
1:c000da1: 
1:c000da1:     private static boolean hasSufficientReplicas(String dc, Map<String, Set<InetAddress>> dcReplicas, Multimap<String, InetAddress> allEndpoints, Map<String, Integer> datacenters)
1:c000da1:     {
1:c000da1:         return dcReplicas.get(dc).size() >= Math.min(allEndpoints.get(dc).size(), getReplicationFactor(dc, datacenters));
1:c000da1:     }
1:c000da1: 
1:c000da1:     private static boolean hasSufficientReplicas(Map<String, Set<InetAddress>> dcReplicas, Multimap<String, InetAddress> allEndpoints, Map<String, Integer> datacenters)
1:c000da1:     {
1:c000da1:         for (String dc : datacenters.keySet())
1:c000da1:             if (!hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:c000da1:                 return false;
1:c000da1:         return true;
1:c000da1:     }
1:c000da1: 
1:c000da1:     public static int getReplicationFactor(String dc, Map<String, Integer> datacenters)
1:c000da1:     {
1:c000da1:         Integer replicas = datacenters.get(dc);
1:c000da1:         return replicas == null ? 0 : replicas;
1:c000da1:     }
1:5a45534: }
============================================================================
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: import org.junit.BeforeClass;
/////////////////////////////////////////////////////////////////////////
1:     @BeforeClass
1:     public static void setupDD()
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
1: 
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:c000da1
/////////////////////////////////////////////////////////////////////////
1: import java.util.*;
1: import java.util.stream.Collectors;
1: import com.google.common.collect.ImmutableMap;
1: 
1: 
1: import org.apache.cassandra.dht.Murmur3Partitioner;
1: import org.apache.cassandra.locator.TokenMetadata.Topology;
1: import org.apache.cassandra.service.StorageService;
/////////////////////////////////////////////////////////////////////////
1: 
1:     @Test
1:     public void testCalculateEndpoints() throws UnknownHostException
1:     {
1:         final int NODES = 100;
1:         final int VNODES = 64;
1:         final int RUNS = 10;
1:         StorageService.instance.setPartitionerUnsafe(Murmur3Partitioner.instance);
1:         Map<String, Integer> datacenters = ImmutableMap.of("rf1", 1, "rf3", 3, "rf5_1", 5, "rf5_2", 5, "rf5_3", 5);
1:         List<InetAddress> nodes = new ArrayList<>(NODES);
1:         for (byte i=0; i<NODES; ++i)
1:             nodes.add(InetAddress.getByAddress(new byte[]{127, 0, 0, i}));
1:         for (int run=0; run<RUNS; ++run)
1:         {
1:             Random rand = new Random();
1:             IEndpointSnitch snitch = generateSnitch(datacenters, nodes, rand);
1:             DatabaseDescriptor.setEndpointSnitch(snitch);
1: 
1:             TokenMetadata meta = new TokenMetadata();
1:             for (int i=0; i<NODES; ++i)  // Nodes
1:                 for (int j=0; j<VNODES; ++j) // tokens/vnodes per node
1:                     meta.updateNormalToken(Murmur3Partitioner.instance.getRandomToken(rand), nodes.get(i));
1:             testEquivalence(meta, snitch, datacenters, rand);
1:         }
1:     }
1: 
1:     void testEquivalence(TokenMetadata tokenMetadata, IEndpointSnitch snitch, Map<String, Integer> datacenters, Random rand)
1:     {
1:         NetworkTopologyStrategy nts = new NetworkTopologyStrategy("ks", tokenMetadata, snitch,
1:                                                                   datacenters.entrySet().stream().
1:                                                                       collect(Collectors.toMap(x -> x.getKey(), x -> Integer.toString(x.getValue()))));
1:         for (int i=0; i<1000; ++i)
1:         {
1:             Token token = Murmur3Partitioner.instance.getRandomToken(rand);
1:             List<InetAddress> expected = calculateNaturalEndpoints(token, tokenMetadata, datacenters, snitch);
1:             List<InetAddress> actual = nts.calculateNaturalEndpoints(token, tokenMetadata);
1:             if (endpointsDiffer(expected, actual))
1:             {
1:                 System.err.println("Endpoints mismatch for token " + token);
1:                 System.err.println(" expected: " + expected);
1:                 System.err.println(" actual  : " + actual);
1:                 Assert.assertEquals("Endpoints for token " + token + " mismatch.", expected, actual);
1:             }
1:         }
1:     }
1: 
1:     private boolean endpointsDiffer(List<InetAddress> ep1, List<InetAddress> ep2)
1:     {
1:         // Because the old algorithm does not put the nodes in the correct order in the case where more replicas
1:         // are required than there are racks in a dc, we accept different order as long as the primary
1:         // replica is the same.
1:         if (ep1.equals(ep2))
1:             return false;
1:         if (!ep1.get(0).equals(ep2.get(0)))
1:             return true;
1:         Set<InetAddress> s1 = new HashSet<>(ep1);
1:         Set<InetAddress> s2 = new HashSet<>(ep2);
1:         return !s1.equals(s2);
1:     }
1: 
1:     IEndpointSnitch generateSnitch(Map<String, Integer> datacenters, Collection<InetAddress> nodes, Random rand)
1:     {
1:         final Map<InetAddress, String> nodeToRack = new HashMap<>();
1:         final Map<InetAddress, String> nodeToDC = new HashMap<>();
1:         Map<String, List<String>> racksPerDC = new HashMap<>();
1:         datacenters.forEach((dc, rf) -> racksPerDC.put(dc, randomRacks(rf, rand)));
1:         int rf = datacenters.values().stream().mapToInt(x -> x).sum();
1:         String[] dcs = new String[rf];
1:         int pos = 0;
1:         for (Map.Entry<String, Integer> dce : datacenters.entrySet())
1:         {
1:             for (int i = 0; i < dce.getValue(); ++i)
1:                 dcs[pos++] = dce.getKey();
1:         }
1: 
1:         for (InetAddress node : nodes)
1:         {
1:             String dc = dcs[rand.nextInt(rf)];
1:             List<String> racks = racksPerDC.get(dc);
1:             String rack = racks.get(rand.nextInt(racks.size()));
1:             nodeToRack.put(node, rack);
1:             nodeToDC.put(node, dc);
1:         }
1: 
1:         return new AbstractNetworkTopologySnitch()
1:         {
1:             public String getRack(InetAddress endpoint)
1:             {
1:                 return nodeToRack.get(endpoint);
1:             }
1: 
1:             public String getDatacenter(InetAddress endpoint)
1:             {
1:                 return nodeToDC.get(endpoint);
1:             }
1:         };
1:     }
1: 
1:     private List<String> randomRacks(int rf, Random rand)
1:     {
1:         int rc = rand.nextInt(rf * 3 - 1) + 1;
1:         List<String> racks = new ArrayList<>(rc);
1:         for (int i=0; i<rc; ++i)
1:             racks.add(Integer.toString(i));
1:         return racks;
1:     }
1: 
1:     // Copy of older endpoints calculation algorithm for comparison
1:     public static List<InetAddress> calculateNaturalEndpoints(Token searchToken, TokenMetadata tokenMetadata, Map<String, Integer> datacenters, IEndpointSnitch snitch)
1:     {
1:         // we want to preserve insertion order so that the first added endpoint becomes primary
1:         Set<InetAddress> replicas = new LinkedHashSet<>();
1:         // replicas we have found in each DC
1:         Map<String, Set<InetAddress>> dcReplicas = new HashMap<>(datacenters.size());
1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:             dcReplicas.put(dc.getKey(), new HashSet<InetAddress>(dc.getValue()));
1: 
1:         Topology topology = tokenMetadata.getTopology();
1:         // all endpoints in each DC, so we can check when we have exhausted all the members of a DC
1:         Multimap<String, InetAddress> allEndpoints = topology.getDatacenterEndpoints();
1:         // all racks in a DC so we can check when we have exhausted all racks in a DC
1:         Map<String, Multimap<String, InetAddress>> racks = topology.getDatacenterRacks();
1:         assert !allEndpoints.isEmpty() && !racks.isEmpty() : "not aware of any cluster members";
1: 
1:         // tracks the racks we have already placed replicas in
1:         Map<String, Set<String>> seenRacks = new HashMap<>(datacenters.size());
1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:             seenRacks.put(dc.getKey(), new HashSet<String>());
1: 
1:         // tracks the endpoints that we skipped over while looking for unique racks
1:         // when we relax the rack uniqueness we can append this to the current result so we don't have to wind back the iterator
1:         Map<String, Set<InetAddress>> skippedDcEndpoints = new HashMap<>(datacenters.size());
1:         for (Map.Entry<String, Integer> dc : datacenters.entrySet())
1:             skippedDcEndpoints.put(dc.getKey(), new LinkedHashSet<InetAddress>());
1: 
1:         Iterator<Token> tokenIter = TokenMetadata.ringIterator(tokenMetadata.sortedTokens(), searchToken, false);
1:         while (tokenIter.hasNext() && !hasSufficientReplicas(dcReplicas, allEndpoints, datacenters))
1:         {
1:             Token next = tokenIter.next();
1:             InetAddress ep = tokenMetadata.getEndpoint(next);
1:             String dc = snitch.getDatacenter(ep);
1:             // have we already found all replicas for this dc?
1:             if (!datacenters.containsKey(dc) || hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:                 continue;
1:             // can we skip checking the rack?
1:             if (seenRacks.get(dc).size() == racks.get(dc).keySet().size())
1:             {
1:                 dcReplicas.get(dc).add(ep);
1:                 replicas.add(ep);
1:             }
1:             else
1:             {
1:                 String rack = snitch.getRack(ep);
1:                 // is this a new rack?
1:                 if (seenRacks.get(dc).contains(rack))
1:                 {
1:                     skippedDcEndpoints.get(dc).add(ep);
1:                 }
1:                 else
1:                 {
1:                     dcReplicas.get(dc).add(ep);
1:                     replicas.add(ep);
1:                     seenRacks.get(dc).add(rack);
1:                     // if we've run out of distinct racks, add the hosts we skipped past already (up to RF)
1:                     if (seenRacks.get(dc).size() == racks.get(dc).keySet().size())
1:                     {
1:                         Iterator<InetAddress> skippedIt = skippedDcEndpoints.get(dc).iterator();
1:                         while (skippedIt.hasNext() && !hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:                         {
1:                             InetAddress nextSkipped = skippedIt.next();
1:                             dcReplicas.get(dc).add(nextSkipped);
1:                             replicas.add(nextSkipped);
1:                         }
1:                     }
1:                 }
1:             }
1:         }
1: 
1:         return new ArrayList<InetAddress>(replicas);
1:     }
1: 
1:     private static boolean hasSufficientReplicas(String dc, Map<String, Set<InetAddress>> dcReplicas, Multimap<String, InetAddress> allEndpoints, Map<String, Integer> datacenters)
1:     {
1:         return dcReplicas.get(dc).size() >= Math.min(allEndpoints.get(dc).size(), getReplicationFactor(dc, datacenters));
1:     }
1: 
1:     private static boolean hasSufficientReplicas(Map<String, Set<InetAddress>> dcReplicas, Multimap<String, InetAddress> allEndpoints, Map<String, Integer> datacenters)
1:     {
1:         for (String dc : datacenters.keySet())
1:             if (!hasSufficientReplicas(dc, dcReplicas, allEndpoints, datacenters))
1:                 return false;
1:         return true;
1:     }
1: 
1:     public static int getReplicationFactor(String dc, Map<String, Integer> datacenters)
1:     {
1:         Integer replicas = datacenters.get(dc);
1:         return replicas == null ? 0 : replicas;
1:     }
commit:07893d7
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.dht.OrderPreservingPartitioner.StringToken;
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.HashMultimap;
1: import com.google.common.collect.Multimap;
1: import org.apache.cassandra.exceptions.ConfigurationException;
commit:3a2faf9
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.exceptions.ConfigurationException;
author:Dave Brosius
-------------------------------------------------------------------------------
commit:b74c2ad
/////////////////////////////////////////////////////////////////////////
1:                     logger.debug("adding node {} at {}", address, token);
/////////////////////////////////////////////////////////////////////////
1:             logger.debug("{}: {}", testToken, endpoints);
commit:83a43f1
/////////////////////////////////////////////////////////////////////////
1: import org.junit.Assert;
commit:f650d3e
/////////////////////////////////////////////////////////////////////////
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:0e96e58
/////////////////////////////////////////////////////////////////////////
1:     private String keyspaceName = "Keyspace1";
/////////////////////////////////////////////////////////////////////////
1:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
/////////////////////////////////////////////////////////////////////////
1:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
/////////////////////////////////////////////////////////////////////////
1:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(keyspaceName, metadata, snitch, configOptions);
author:Eric Evans
-------------------------------------------------------------------------------
commit:e85afdc
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.HashMultimap;
0: import com.google.common.collect.Multimap;
1: 
/////////////////////////////////////////////////////////////////////////
1:         Multimap<InetAddress, Token> tokens = HashMultimap.create();
/////////////////////////////////////////////////////////////////////////
1:                     tokens.put(address, token);
commit:df8a933
/////////////////////////////////////////////////////////////////////////
0: import java.util.HashMap;
0: import java.util.Map;
/////////////////////////////////////////////////////////////////////////
1:         IEndpointSnitch snitch = new PropertyFileSnitch();
1: 
1:         Map<String, String> configOptions = new HashMap<String, String>();
1:         configOptions.put("DC1", "3");
1:         configOptions.put("DC2", "2");
1:         configOptions.put("DC3", "1");
1: 
1:         // Set the localhost to the tokenmetadata. Embedded cassandra way?
0:         DatacenterShardStrategy strategy = new DatacenterShardStrategy(table, metadata, snitch, configOptions);
1:         assert strategy.getReplicationFactor("DC1") == 3;
1:         assert strategy.getReplicationFactor("DC2") == 2;
1:         assert strategy.getReplicationFactor("DC3") == 1;
1:         ArrayList<InetAddress> endpoints = strategy.getNaturalEndpoints(new StringToken("123"));
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:9688a79
/////////////////////////////////////////////////////////////////////////
0: import java.util.List;
0: import java.util.Set;
1: 
0: import junit.framework.Assert;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: import org.apache.cassandra.config.DatabaseDescriptor;
0: import org.apache.cassandra.utils.Pair;
1:     private static final Logger logger = LoggerFactory.getLogger(NetworkTopologyStrategyTest.class);
1:     public void testProperties() throws IOException, ConfigurationException
1:         DatabaseDescriptor.setEndpointSnitch(snitch);
/////////////////////////////////////////////////////////////////////////
1:     public void testPropertiesWithEmptyDC() throws IOException, ConfigurationException
1:         DatabaseDescriptor.setEndpointSnitch(snitch);
/////////////////////////////////////////////////////////////////////////
1:     @Test
1:     public void testLargeCluster() throws UnknownHostException, ConfigurationException
1:     {
1:         int[] dcRacks = new int[]{2, 4, 8};
1:         int[] dcEndpoints = new int[]{128, 256, 512};
1:         int[] dcReplication = new int[]{2, 6, 6};
1: 
1:         IEndpointSnitch snitch = new RackInferringSnitch();
1:         DatabaseDescriptor.setEndpointSnitch(snitch);
1:         TokenMetadata metadata = new TokenMetadata();
1:         Map<String, String> configOptions = new HashMap<String, String>();
0:         Set<Pair<Token, InetAddress>> tokens = new HashSet<Pair<Token, InetAddress>>();
1: 
1:         int totalRF = 0;
1:         for (int dc = 0; dc < dcRacks.length; ++dc)
1:         {
1:             totalRF += dcReplication[dc];
1:             configOptions.put(Integer.toString(dc), Integer.toString(dcReplication[dc]));
1:             for (int rack = 0; rack < dcRacks[dc]; ++rack)
1:             {
1:                 for (int ep = 1; ep <= dcEndpoints[dc]/dcRacks[dc]; ++ep)
1:                 {
1:                     byte[] ipBytes = new byte[]{10, (byte)dc, (byte)rack, (byte)ep};
1:                     InetAddress address = InetAddress.getByAddress(ipBytes);
1:                     StringToken token = new StringToken(String.format("%02x%02x%02x", ep, rack, dc));
0:                     logger.debug("adding node " + address + " at " + token);
0:                     tokens.add(new Pair<Token, InetAddress>(token, address));
1:                 }
1:             }
1:         }
1:         metadata.updateNormalTokens(tokens);
1: 
0:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(table, metadata, snitch, configOptions);
1: 
1:         for (String testToken : new String[]{"123456", "200000", "000402", "ffffff", "400200"})
1:         {
1:             List<InetAddress> endpoints = strategy.calculateNaturalEndpoints(new StringToken(testToken), metadata);
1:             Set<InetAddress> epSet = new HashSet<InetAddress>(endpoints);
1: 
1:             Assert.assertEquals(totalRF, endpoints.size());
1:             Assert.assertEquals(totalRF, epSet.size());
0:             logger.debug(testToken + ": " + endpoints.toString());
1:         }
1:     }
1: 
commit:402e1ed
/////////////////////////////////////////////////////////////////////////
1:         createDummyTokens(metadata, true);
/////////////////////////////////////////////////////////////////////////
1:     @Test
0:     public void testPropertiesWithEmptyDC() throws IOException, ParserConfigurationException, SAXException, ConfigurationException
1:     {
1:         IEndpointSnitch snitch = new PropertyFileSnitch();
1:         TokenMetadata metadata = new TokenMetadata();
1:         createDummyTokens(metadata, false);
1: 
1:         Map<String, String> configOptions = new HashMap<String, String>();
1:         configOptions.put("DC1", "3");
1:         configOptions.put("DC2", "3");
1:         configOptions.put("DC3", "0");
1: 
1:         // Set the localhost to the tokenmetadata. Embedded cassandra way?
0:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(table, metadata, snitch, configOptions);
1:         assert strategy.getReplicationFactor("DC1") == 3;
1:         assert strategy.getReplicationFactor("DC2") == 3;
1:         assert strategy.getReplicationFactor("DC3") == 0;
1:         // Query for the natural hosts
1:         ArrayList<InetAddress> endpoints = strategy.getNaturalEndpoints(new StringToken("123"));
1:         assert 6 == endpoints.size();
1:         assert 6 == new HashSet<InetAddress>(endpoints).size(); // ensure uniqueness
1:     }
1: 
1:     public void createDummyTokens(TokenMetadata metadata, boolean populateDC3) throws UnknownHostException
/////////////////////////////////////////////////////////////////////////
1:         if (populateDC3)
1:         {
1:             tokenFactory(metadata, "456", new byte[]{ 10, 21, 119, 13 });
1:             tokenFactory(metadata, "567", new byte[]{ 10, 21, 119, 10 });
1:         }
1:         if (populateDC3)
1:             tokenFactory(metadata, "0AB", new byte[]{ 10, 21, 119, 14 });
commit:916c810
/////////////////////////////////////////////////////////////////////////
1: public class NetworkTopologyStrategyTest
/////////////////////////////////////////////////////////////////////////
0:         NetworkTopologyStrategy strategy = new NetworkTopologyStrategy(table, metadata, snitch, configOptions);
commit:34e241a
/////////////////////////////////////////////////////////////////////////
1: /*
0: * Licensed to the Apache Software Foundation (ASF) under one
0: * or more contributor license agreements.  See the NOTICE file
0: * distributed with this work for additional information
0: * regarding copyright ownership.  The ASF licenses this file
0: * to you under the Apache License, Version 2.0 (the
0: * "License"); you may not use this file except in compliance
0: * with the License.  You may obtain a copy of the License at
0: *
0: *    http://www.apache.org/licenses/LICENSE-2.0
0: *
0: * Unless required by applicable law or agreed to in writing,
0: * software distributed under the License is distributed on an
0: * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
0: * KIND, either express or implied.  See the License for the
0: * specific language governing permissions and limitations
0: * under the License.
0: */
1: 
/////////////////////////////////////////////////////////////////////////
1: import org.junit.Test;
1: 
commit:91aa0d5
/////////////////////////////////////////////////////////////////////////
0: import java.util.HashSet;
/////////////////////////////////////////////////////////////////////////
1:         assert 6 == new HashSet<InetAddress>(endpoints).size(); // ensure uniqueness
commit:5a45534
/////////////////////////////////////////////////////////////////////////
1: package org.apache.cassandra.locator;
1: 
1: import java.io.IOException;
1: import java.net.InetAddress;
1: import java.net.UnknownHostException;
0: import java.util.ArrayList;
1: 
0: import javax.xml.parsers.ParserConfigurationException;
1: 
0: import org.apache.cassandra.config.ConfigurationException;
0: import org.apache.cassandra.dht.StringToken;
1: import org.apache.cassandra.dht.Token;
1: 
0: import org.junit.Test;
1: 
0: import org.xml.sax.SAXException;
1: 
0: public class DatacenterShardStrategyTest
1: {
0:     private String table = "Keyspace1";
1: 
1:     @Test
0:     public void testProperties() throws IOException, ParserConfigurationException, SAXException, ConfigurationException
1:     {
0:         PropertyFileSnitch snitch = new PropertyFileSnitch();
1:         TokenMetadata metadata = new TokenMetadata();
0:         createDummyTokens(metadata);
0:         // Set the localhost to the tokenmetadata. Embeded cassandra way?
0:         DatacenterShardStrategy strategy = new DatacenterShardStrategy(metadata, snitch);
0:         assert strategy.getReplicationFactor("DC1", table) == 3;
0:         assert strategy.getReplicationFactor("DC2", table) == 2;
0:         assert strategy.getReplicationFactor("DC3", table) == 1;
1:         // Query for the natural hosts
0:         ArrayList<InetAddress> endpoints = strategy.getNaturalEndpoints(new StringToken("123"), table);
1:         assert 6 == endpoints.size();
1:     }
1: 
0:     public void createDummyTokens(TokenMetadata metadata) throws UnknownHostException
1:     {
1:         // DC 1
1:         tokenFactory(metadata, "123", new byte[]{ 10, 0, 0, 10 });
1:         tokenFactory(metadata, "234", new byte[]{ 10, 0, 0, 11 });
1:         tokenFactory(metadata, "345", new byte[]{ 10, 0, 0, 12 });
1:         // Tokens for DC 2
1:         tokenFactory(metadata, "789", new byte[]{ 10, 20, 114, 10 });
1:         tokenFactory(metadata, "890", new byte[]{ 10, 20, 114, 11 });
1:         //tokens for DC3
0:         tokenFactory(metadata, "456", new byte[]{ 10, 21, 119, 13 });
0:         tokenFactory(metadata, "567", new byte[]{ 10, 21, 119, 10 });
1:         // Extra Tokens
1:         tokenFactory(metadata, "90A", new byte[]{ 10, 0, 0, 13 });
0:         tokenFactory(metadata, "0AB", new byte[]{ 10, 21, 119, 14 });
1:         tokenFactory(metadata, "ABC", new byte[]{ 10, 20, 114, 15 });
1:     }
1: 
1:     public void tokenFactory(TokenMetadata metadata, String token, byte[] bytes) throws UnknownHostException
1:     {
1:         Token token1 = new StringToken(token);
1:         InetAddress add1 = InetAddress.getByAddress(bytes);
1:         metadata.updateNormalToken(token1, add1);
1:     }
1: }
============================================================================
1:407a76f: /*
1:407a76f:  * Licensed to the Apache Software Foundation (ASF) under one
1:407a76f:  * or more contributor license agreements.  See the NOTICE file
1:407a76f:  * distributed with this work for additional information
1:407a76f:  * regarding copyright ownership.  The ASF licenses this file
1:407a76f:  * to you under the Apache License, Version 2.0 (the
1:407a76f:  * "License"); you may not use this file except in compliance
1:407a76f:  * with the License.  You may obtain a copy of the License at
1:07cdfd0:  *
1:407a76f:  *   http://www.apache.org/licenses/LICENSE-2.0
3:07cdfd0:  *
1:407a76f:  * Unless required by applicable law or agreed to in writing,
1:407a76f:  * software distributed under the License is distributed on an
1:407a76f:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:407a76f:  * KIND, either express or implied.  See the License for the
1:407a76f:  * specific language governing permissions and limitations
1:407a76f:  * under the License.
1:407a76f:  */
1:f81cc74: package org.apache.cassandra.utils;
1:7f2c3a8: 
1:a991b64: import java.io.DataInputStream;
1:a991b64: import java.io.IOException;
1:a22ce89: 
1:a991b64: import org.junit.Assert;
1:9797511: import org.junit.BeforeClass;
1:a991b64: import org.junit.Test;
1:0a08525: 
1:434636a: import org.apache.cassandra.AbstractSerializationsTester;
1:0a08525: import org.apache.cassandra.Util;
1:9797511: import org.apache.cassandra.config.DatabaseDescriptor;
1:23fd75f: import org.apache.cassandra.db.DecoratedKey;
1:23fd75f: import org.apache.cassandra.db.marshal.Int32Type;
1:03f72ac: import org.apache.cassandra.io.util.DataInputPlus.DataInputStreamPlus;
1:16499ca: import org.apache.cassandra.io.util.DataOutputStreamPlus;
1:0a08525: import org.apache.cassandra.dht.IPartitioner;
1:23fd75f: import org.apache.cassandra.dht.Murmur3Partitioner;
1:23fd75f: 
1:23fd75f: import java.io.File;
1:23fd75f: import java.io.FileInputStream;
1:69f77cb: 
1:434636a: public class SerializationsTest extends AbstractSerializationsTester
5:434636a: {
1:9797511:     @BeforeClass
1:9797511:     public static void initDD()
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:9797511:     }
1:9797511: 
1:23fd75f:     private static void testBloomFilterWrite(boolean offheap, boolean oldBfHashOrder) throws IOException
1:2e22bc9:     {
1:0a08525:         IPartitioner partitioner = Util.testPartitioner();
1:23fd75f:         try (IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap, oldBfHashOrder))
1:434636a:         {
1:2e22bc9:             for (int i = 0; i < 100; i++)
1:18d8f26:                 bf.add(partitioner.decorateKey(partitioner.getTokenFactory().toByteArray(partitioner.getRandomToken())));
1:23fd75f:             try (DataOutputStreamPlus out = getOutput(oldBfHashOrder ? "2.1" : "3.0", "utils.BloomFilter.bin"))
1:23fd75f:             {
1:23fd75f:                 FilterFactory.serialize(bf, out);
1:23fd75f:             }
1:23fd75f:         }
1:23fd75f:     }
1:23fd75f: 
1:23fd75f:     private static void testBloomFilterWrite1000(boolean offheap, boolean oldBfHashOrder) throws IOException
1:23fd75f:     {
1:23fd75f:         try (IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap, oldBfHashOrder))
1:23fd75f:         {
1:23fd75f:             for (int i = 0; i < 1000; i++)
1:0a08525:                 bf.add(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:             try (DataOutputStreamPlus out = getOutput(oldBfHashOrder ? "2.1" : "3.0", "utils.BloomFilter1000.bin"))
1:2e22bc9:             {
1:7f2c3a8:                 FilterFactory.serialize(bf, out);
1:2e22bc9:             }
1:2e22bc9:         }
5:434636a:     }
1:a991b64: 
3:434636a:     @Test
1:23fd75f:     public void testBloomFilterRead1000() throws IOException
1:23fd75f:     {
1:23fd75f:         if (EXECUTE_WRITES)
1:23fd75f:         {
1:23fd75f:             testBloomFilterWrite1000(true, false);
1:23fd75f:             testBloomFilterWrite1000(true, true);
1:23fd75f:         }
1:23fd75f: 
1:23fd75f:         try (DataInputStream in = getInput("3.0", "utils.BloomFilter1000.bin");
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:23fd75f:         {
1:23fd75f:             boolean present;
1:23fd75f:             for (int i = 0 ; i < 1000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 Assert.assertTrue(present);
1:23fd75f:             }
1:23fd75f:             for (int i = 1000 ; i < 2000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 Assert.assertFalse(present);
1:23fd75f:             }
1:23fd75f:         }
1:23fd75f: 
1:23fd75f:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter1000.bin");
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, true))
1:23fd75f:         {
1:23fd75f:             boolean present;
1:23fd75f:             for (int i = 0 ; i < 1000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 Assert.assertTrue(present);
1:23fd75f:             }
1:23fd75f:             for (int i = 1000 ; i < 2000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 Assert.assertFalse(present);
1:23fd75f:             }
1:23fd75f:         }
1:23fd75f: 
1:23fd75f:         // eh - reading version version 'ka' (2.1) with 3.0 BloomFilter
1:23fd75f:         int falsePositive = 0;
1:23fd75f:         int falseNegative = 0;
1:23fd75f:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter1000.bin");
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:23fd75f:         {
1:23fd75f:             boolean present;
1:23fd75f:             for (int i = 0 ; i < 1000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 if (!present)
1:23fd75f:                     falseNegative ++;
1:23fd75f:             }
1:23fd75f:             for (int i = 1000 ; i < 2000 ; i++)
1:23fd75f:             {
1:0a08525:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:23fd75f:                 if (present)
1:23fd75f:                     falsePositive ++;
1:23fd75f:             }
1:23fd75f:         }
1:23fd75f:         Assert.assertEquals(1000, falseNegative);
1:23fd75f:         Assert.assertEquals(0, falsePositive);
1:23fd75f:     }
1:23fd75f: 
1:23fd75f:     @Test
1:23fd75f:     public void testBloomFilterTable() throws Exception
1:23fd75f:     {
1:23fd75f:         testBloomFilterTable("test/data/bloom-filter/ka/foo/foo-atable-ka-1-Filter.db", true);
1:23fd75f:         testBloomFilterTable("test/data/bloom-filter/la/foo/la-1-big-Filter.db", false);
1:23fd75f:     }
1:23fd75f: 
1:23fd75f:     private static void testBloomFilterTable(String file, boolean oldBfHashOrder) throws Exception
1:23fd75f:     {
1:23fd75f:         Murmur3Partitioner partitioner = new Murmur3Partitioner();
1:23fd75f: 
1:23fd75f:         try (DataInputStream in = new DataInputStream(new FileInputStream(new File(file)));
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, oldBfHashOrder))
1:23fd75f:         {
1:23fd75f:             for (int i = 1; i <= 10; i++)
1:23fd75f:             {
1:23fd75f:                 DecoratedKey decoratedKey = partitioner.decorateKey(Int32Type.instance.decompose(i));
1:23fd75f:                 boolean present = filter.isPresent(decoratedKey);
1:23fd75f:                 Assert.assertTrue(present);
1:23fd75f:             }
1:23fd75f: 
1:23fd75f:             int positives = 0;
1:23fd75f:             for (int i = 11; i <= 1000010; i++)
1:23fd75f:             {
1:23fd75f:                 DecoratedKey decoratedKey = partitioner.decorateKey(Int32Type.instance.decompose(i));
1:23fd75f:                 boolean present = filter.isPresent(decoratedKey);
1:23fd75f:                 if (present)
1:23fd75f:                     positives++;
1:23fd75f:             }
1:23fd75f:             double fpr = positives;
1:23fd75f:             fpr /= 1000000;
1:23fd75f:             Assert.assertTrue(fpr <= 0.011d);
1:23fd75f:         }
1:23fd75f:     }
1:23fd75f: 
1:23fd75f:     @Test
1:d765b24:     public void testBloomFilterReadMURMUR3() throws IOException
1:2e22bc9:     {
1:d765b24:         if (EXECUTE_WRITES)
1:23fd75f:             testBloomFilterWrite(true, true);
1:a991b64: 
1:23fd75f:         try (DataInputStream in = getInput("3.0", "utils.BloomFilter.bin");
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, true))
1:d765b24:         {
1:2e22bc9:             Assert.assertNotNull(filter);
1:2e22bc9:         }
1:d765b24:     }
1:07cdfd0: 
1:23fd75f:     @Test
1:23fd75f:     public void testBloomFilterReadMURMUR3pre30() throws IOException
1:23fd75f:     {
1:23fd75f:         if (EXECUTE_WRITES)
1:23fd75f:             testBloomFilterWrite(true, false);
1:23fd75f: 
1:23fd75f:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter.bin");
1:23fd75f:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:23fd75f:         {
1:23fd75f:             Assert.assertNotNull(filter);
1:23fd75f:         }
1:23fd75f:     }
1:23fd75f: 
1:23fd75f:     private static void testEstimatedHistogramWrite() throws IOException
1:434636a:     {
1:434636a:         EstimatedHistogram hist0 = new EstimatedHistogram();
1:434636a:         EstimatedHistogram hist1 = new EstimatedHistogram(5000);
1:434636a:         long[] offsets = new long[1000];
1:434636a:         long[] data = new long[offsets.length + 1];
1:434636a:         for (int i = 0; i < offsets.length; i++)
1:434636a:         {
1:434636a:             offsets[i] = i;
1:434636a:             data[i] = 10 * i;
1:434636a:         }
1:434636a:         data[offsets.length] = 100000;
1:434636a:         EstimatedHistogram hist2 = new EstimatedHistogram(offsets, data);
1:07cdfd0: 
1:16499ca:         try (DataOutputStreamPlus out = getOutput("utils.EstimatedHistogram.bin"))
1:2e22bc9:         {
1:2e22bc9:             EstimatedHistogram.serializer.serialize(hist0, out);
1:2e22bc9:             EstimatedHistogram.serializer.serialize(hist1, out);
1:2e22bc9:             EstimatedHistogram.serializer.serialize(hist2, out);
1:2e22bc9:         }
1:434636a:     }
1:07cdfd0: 
1:d765b24:     @Test
1:434636a:     public void testEstimatedHistogramRead() throws IOException
1:434636a:     {
3:434636a:         if (EXECUTE_WRITES)
1:434636a:             testEstimatedHistogramWrite();
1:07cdfd0: 
1:03f72ac:         try (DataInputStreamPlus in = getInput("utils.EstimatedHistogram.bin"))
1:2e22bc9:         {
1:2e22bc9:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:2e22bc9:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:2e22bc9:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:2e22bc9:         }
1:434636a:     }
1:434636a: }
============================================================================
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: import org.junit.BeforeClass;
1: import org.apache.cassandra.config.DatabaseDescriptor;
/////////////////////////////////////////////////////////////////////////
1:     @BeforeClass
1:     public static void initDD()
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
1: 
commit:23fd75f
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.DecoratedKey;
1: import org.apache.cassandra.db.marshal.Int32Type;
1: import org.apache.cassandra.dht.Murmur3Partitioner;
1: 
1: import java.io.File;
1: import java.io.FileInputStream;
1:     private static void testBloomFilterWrite(boolean offheap, boolean oldBfHashOrder) throws IOException
1:         try (IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap, oldBfHashOrder))
1:             try (DataOutputStreamPlus out = getOutput(oldBfHashOrder ? "2.1" : "3.0", "utils.BloomFilter.bin"))
1:             {
1:                 FilterFactory.serialize(bf, out);
1:             }
1:         }
1:     }
1: 
1:     private static void testBloomFilterWrite1000(boolean offheap, boolean oldBfHashOrder) throws IOException
1:     {
0:         IPartitioner partitioner = StorageService.getPartitioner();
1:         try (IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap, oldBfHashOrder))
1:         {
1:             for (int i = 0; i < 1000; i++)
0:                 bf.add(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:             try (DataOutputStreamPlus out = getOutput(oldBfHashOrder ? "2.1" : "3.0", "utils.BloomFilter1000.bin"))
/////////////////////////////////////////////////////////////////////////
1:     public void testBloomFilterRead1000() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
1:         {
1:             testBloomFilterWrite1000(true, false);
1:             testBloomFilterWrite1000(true, true);
1:         }
1: 
0:         IPartitioner partitioner = StorageService.getPartitioner();
1:         try (DataInputStream in = getInput("3.0", "utils.BloomFilter1000.bin");
1:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:         {
1:             boolean present;
1:             for (int i = 0 ; i < 1000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 Assert.assertTrue(present);
1:             }
1:             for (int i = 1000 ; i < 2000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 Assert.assertFalse(present);
1:             }
1:         }
1: 
1:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter1000.bin");
1:              IFilter filter = FilterFactory.deserialize(in, true, true))
1:         {
1:             boolean present;
1:             for (int i = 0 ; i < 1000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 Assert.assertTrue(present);
1:             }
1:             for (int i = 1000 ; i < 2000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 Assert.assertFalse(present);
1:             }
1:         }
1: 
1:         // eh - reading version version 'ka' (2.1) with 3.0 BloomFilter
1:         int falsePositive = 0;
1:         int falseNegative = 0;
1:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter1000.bin");
1:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:         {
1:             boolean present;
1:             for (int i = 0 ; i < 1000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 if (!present)
1:                     falseNegative ++;
1:             }
1:             for (int i = 1000 ; i < 2000 ; i++)
1:             {
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
1:                 if (present)
1:                     falsePositive ++;
1:             }
1:         }
1:         Assert.assertEquals(1000, falseNegative);
1:         Assert.assertEquals(0, falsePositive);
1:     }
1: 
1:     @Test
1:     public void testBloomFilterTable() throws Exception
1:     {
1:         testBloomFilterTable("test/data/bloom-filter/ka/foo/foo-atable-ka-1-Filter.db", true);
1:         testBloomFilterTable("test/data/bloom-filter/la/foo/la-1-big-Filter.db", false);
1:     }
1: 
1:     private static void testBloomFilterTable(String file, boolean oldBfHashOrder) throws Exception
1:     {
1:         Murmur3Partitioner partitioner = new Murmur3Partitioner();
1: 
1:         try (DataInputStream in = new DataInputStream(new FileInputStream(new File(file)));
1:              IFilter filter = FilterFactory.deserialize(in, true, oldBfHashOrder))
1:         {
1:             for (int i = 1; i <= 10; i++)
1:             {
1:                 DecoratedKey decoratedKey = partitioner.decorateKey(Int32Type.instance.decompose(i));
1:                 boolean present = filter.isPresent(decoratedKey);
1:                 Assert.assertTrue(present);
1:             }
1: 
1:             int positives = 0;
1:             for (int i = 11; i <= 1000010; i++)
1:             {
1:                 DecoratedKey decoratedKey = partitioner.decorateKey(Int32Type.instance.decompose(i));
1:                 boolean present = filter.isPresent(decoratedKey);
1:                 if (present)
1:                     positives++;
1:             }
1:             double fpr = positives;
1:             fpr /= 1000000;
1:             Assert.assertTrue(fpr <= 0.011d);
1:         }
1:     }
1: 
1:     @Test
1:             testBloomFilterWrite(true, true);
1:         try (DataInputStream in = getInput("3.0", "utils.BloomFilter.bin");
1:              IFilter filter = FilterFactory.deserialize(in, true, true))
1:     @Test
1:     public void testBloomFilterReadMURMUR3pre30() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
1:             testBloomFilterWrite(true, false);
1: 
1:         try (DataInputStream in = getInput("2.1", "utils.BloomFilter.bin");
1:              IFilter filter = FilterFactory.deserialize(in, true, false))
1:         {
1:             Assert.assertNotNull(filter);
1:         }
1:     }
1: 
1:     private static void testEstimatedHistogramWrite() throws IOException
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:0a08525
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.apache.cassandra.Util;
1: import org.apache.cassandra.dht.IPartitioner;
/////////////////////////////////////////////////////////////////////////
1:         IPartitioner partitioner = Util.testPartitioner();
/////////////////////////////////////////////////////////////////////////
1:                 bf.add(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
1:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:a22ce89
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.dht.IPartitioner;
0: import org.apache.cassandra.service.StorageService;
/////////////////////////////////////////////////////////////////////////
1: 
0:         IPartitioner partitioner = StorageService.getPartitioner();
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner partitioner = StorageService.getPartitioner();
0:                 bf.add(partitioner.decorateKey(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner partitioner = StorageService.getPartitioner();
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(partitioner.decorateKey(Int32Type.instance.decompose(i)));
commit:7f2c3a8
/////////////////////////////////////////////////////////////////////////
1: 
0:     private void testBloomFilterWrite(boolean offheap) throws IOException
0:         IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap);
1:         FilterFactory.serialize(bf, out);
0:             testBloomFilterWrite(true);
0:         assert FilterFactory.deserialize(in, true) != null;
commit:a15500e
/////////////////////////////////////////////////////////////////////////
0:         IFilter bf = FilterFactory.getFilter(1000000, 0.0001, murmur, offheap);
commit:dc37dea
/////////////////////////////////////////////////////////////////////////
0:     private void testBloomFilterWrite(Type murmur, boolean offheap) throws IOException
0:         Filter bf = FilterFactory.getFilter(1000000, 0.0001, murmur, offheap);
/////////////////////////////////////////////////////////////////////////
0:             testBloomFilterWrite(FilterFactory.Type.MURMUR2, false);
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR2, false) != null;
/////////////////////////////////////////////////////////////////////////
0:             testBloomFilterWrite(FilterFactory.Type.MURMUR3, true);
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR3, true) != null;
/////////////////////////////////////////////////////////////////////////
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.SHA, false) != null;
commit:1c9637f
commit:d3c5dbd
commit:56302ce
/////////////////////////////////////////////////////////////////////////
0:         // We never write out a new LBF.  Copy the data file from 0.7 instead.
0:         // if (EXECUTE_WRITES)
0:         //      testLegacyBloomFilterWrite();
commit:84eeb28
/////////////////////////////////////////////////////////////////////////
0:         LegacyBloomFilter.serializer().serialize(a, out);
0:         LegacyBloomFilter.serializer().serialize(b, out);
/////////////////////////////////////////////////////////////////////////
0:         assert LegacyBloomFilter.serializer().deserialize(in) != null;
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:69f77cb
/////////////////////////////////////////////////////////////////////////
1: 
0: import org.apache.cassandra.Util;
0: import org.apache.cassandra.dht.IPartitioner;
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner partitioner = Util.testPartitioner();
/////////////////////////////////////////////////////////////////////////
0:                 bf.add(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
/////////////////////////////////////////////////////////////////////////
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
0:                 present = filter.isPresent(Util.dk(Int32Type.instance.decompose(i)));
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus.DataInputStreamPlus;
/////////////////////////////////////////////////////////////////////////
1:         try (DataInputStreamPlus in = getInput("utils.EstimatedHistogram.bin"))
commit:16499ca
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataOutputStreamPlus;
/////////////////////////////////////////////////////////////////////////
0:             try (DataOutputStreamPlus out = getOutput("utils.BloomFilter.bin"))
/////////////////////////////////////////////////////////////////////////
1:         try (DataOutputStreamPlus out = getOutput("utils.EstimatedHistogram.bin"))
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: import java.io.DataInputStream;
1: import java.io.IOException;
1: 
1: import org.junit.Assert;
1: import org.junit.Test;
1: 
commit:07cdfd0
/////////////////////////////////////////////////////////////////////////
1:  *
/////////////////////////////////////////////////////////////////////////
1:  *
1:  *
1:  *
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
0:             ByteBuffer key = StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken());
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0: 
commit:2fd3268
/////////////////////////////////////////////////////////////////////////
0:  *
/////////////////////////////////////////////////////////////////////////
0:  *
0:  *
0:  *
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0: 
0:             ByteBuffer key = StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken());
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0: 
0: 
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:18d8f26
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.dht.IPartitioner;
/////////////////////////////////////////////////////////////////////////
0:         IPartitioner partitioner = StorageService.getPartitioner();
1:                 bf.add(partitioner.decorateKey(partitioner.getTokenFactory().toByteArray(partitioner.getRandomToken())));
author:Dave Brosius
-------------------------------------------------------------------------------
commit:2e22bc9
/////////////////////////////////////////////////////////////////////////
0: import org.junit.Assert;
/////////////////////////////////////////////////////////////////////////
0:         try (IFilter bf = FilterFactory.getFilter(1000000, 0.0001, offheap))
1:         {
1:             for (int i = 0; i < 100; i++)
0:                 bf.add(StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken()));
0:             try (DataOutputStreamAndChannel out = getOutput("utils.BloomFilter.bin")) 
1:             {
0:                 FilterFactory.serialize(bf, out);
1:             }
1:         }
/////////////////////////////////////////////////////////////////////////
0:         try (DataInputStream in = getInput("utils.BloomFilter.bin");
0:              IFilter filter = FilterFactory.deserialize(in, true))
1:         {
1:             Assert.assertNotNull(filter);
1:         }
/////////////////////////////////////////////////////////////////////////
0:         try (DataOutputStreamAndChannel out = getOutput("utils.EstimatedHistogram.bin"))
1:         {
1:             EstimatedHistogram.serializer.serialize(hist0, out);
1:             EstimatedHistogram.serializer.serialize(hist1, out);
1:             EstimatedHistogram.serializer.serialize(hist2, out);
1:         }
/////////////////////////////////////////////////////////////////////////
0:         try (DataInputStream in = getInput("utils.EstimatedHistogram.bin"))
1:         {
1:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:             Assert.assertNotNull(EstimatedHistogram.serializer.deserialize(in));
1:         }
commit:b30cdd9
/////////////////////////////////////////////////////////////////////////
author:belliottsmith
-------------------------------------------------------------------------------
commit:75508ec
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.DataOutputStreamAndChannel;
/////////////////////////////////////////////////////////////////////////
0:         DataOutputStreamAndChannel out = getOutput("utils.BloomFilter.bin");
/////////////////////////////////////////////////////////////////////////
0:         DataOutputStreamAndChannel out = getOutput("utils.EstimatedHistogram.bin");
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:f81cc74
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: package org.apache.cassandra.utils;
/////////////////////////////////////////////////////////////////////////
0:         Filter bf = FilterFactory.getFilter(1000000, 0.0001, murmur);
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:d765b24
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.utils.FilterFactory.Type;
/////////////////////////////////////////////////////////////////////////
0:     private void testBloomFilterWrite(Type murmur) throws IOException
0:         Filter bf = FilterFactory.getFilter(1000000, 0.0001);
0:         FilterFactory.serialize(bf, out, murmur);
0:     public void testBloomFilterReadMURMUR2() throws IOException
0:             testBloomFilterWrite(FilterFactory.Type.MURMUR2);
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR2) != null;
0:         in.close();
1:     }
0: 
1:     @Test
1:     public void testBloomFilterReadMURMUR3() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
0:             testBloomFilterWrite(FilterFactory.Type.MURMUR3);
0: 
0:         DataInputStream in = getInput("utils.BloomFilter.bin");
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.MURMUR3) != null;
/////////////////////////////////////////////////////////////////////////
0:         FilterFactory.serialize(a, out, FilterFactory.Type.SHA);
0:         FilterFactory.serialize(b, out, FilterFactory.Type.SHA);
/////////////////////////////////////////////////////////////////////////
0:         assert FilterFactory.deserialize(in, FilterFactory.Type.SHA) != null;
author:Gary Dusbabek
-------------------------------------------------------------------------------
commit:1ecdd7f
/////////////////////////////////////////////////////////////////////////
0:         LegacyBloomFilter.serializer().serialize(a, out, getVersion());
0:         LegacyBloomFilter.serializer().serialize(b, out, getVersion());
/////////////////////////////////////////////////////////////////////////
0:         assert LegacyBloomFilter.serializer().deserialize(in, getVersion()) != null;
commit:434636a
/////////////////////////////////////////////////////////////////////////
0: package org.apache.cassandra.utils;
0: 
1: import org.apache.cassandra.AbstractSerializationsTester;
0: import org.apache.cassandra.service.StorageService;
0: import org.junit.Test;
0: 
0: import java.io.DataInputStream;
0: import java.io.DataOutputStream;
0: import java.io.IOException;
0: import java.nio.ByteBuffer;
0: 
1: public class SerializationsTest extends AbstractSerializationsTester
1: {
0:     
0:     private void testBloomFilterWrite() throws IOException
1:     {
0:         BloomFilter bf = BloomFilter.getFilter(1000000, 0.0001);
0:         for (int i = 0; i < 100; i++)
0:             bf.add(StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken()));
0:         DataOutputStream out = getOutput("utils.BloomFilter.bin");
0:         BloomFilter.serializer().serialize(bf, out);
0:         out.close();
1:     }
0:     
1:     @Test
0:     public void testBloomFilterRead() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
0:             testBloomFilterWrite();
0:         
0:         DataInputStream in = getInput("utils.BloomFilter.bin");
0:         assert BloomFilter.serializer().deserialize(in) != null;
0:         in.close();
1:     }
0:     
0:     private void testLegacyBloomFilterWrite() throws IOException
1:     {
0:         LegacyBloomFilter a = LegacyBloomFilter.getFilter(1000000, 1000);
0:         LegacyBloomFilter b = LegacyBloomFilter.getFilter(1000000, 0.0001);
0:         for (int i = 0; i < 100; i++)
1:         {
0:             ByteBuffer key = StorageService.getPartitioner().getTokenFactory().toByteArray(StorageService.getPartitioner().getRandomToken()); 
0:             a.add(key);
0:             b.add(key);
1:         }
0:         DataOutputStream out = getOutput("utils.LegacyBloomFilter.bin");
0:         LegacyBloomFilter.serializer().serialize(a, out);
0:         LegacyBloomFilter.serializer().serialize(b, out);
0:         out.close();
1:     }
0:     
1:     @Test
0:     public void testLegacyBloomFilterRead() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
0:             testLegacyBloomFilterWrite();
0:         
0:         DataInputStream in = getInput("utils.LegacyBloomFilter.bin");
0:         assert LegacyBloomFilter.serializer().deserialize(in) != null;
0:         in.close();
1:     }
0:     
0:     private void testEstimatedHistogramWrite() throws IOException
1:     {
1:         EstimatedHistogram hist0 = new EstimatedHistogram();
1:         EstimatedHistogram hist1 = new EstimatedHistogram(5000);
1:         long[] offsets = new long[1000];
1:         long[] data = new long[offsets.length + 1];
1:         for (int i = 0; i < offsets.length; i++)
1:         {
1:             offsets[i] = i;
1:             data[i] = 10 * i;
1:         }
1:         data[offsets.length] = 100000;
1:         EstimatedHistogram hist2 = new EstimatedHistogram(offsets, data);
0:         
0:         DataOutputStream out = getOutput("utils.EstimatedHistogram.bin");
0:         EstimatedHistogram.serializer.serialize(hist0, out);
0:         EstimatedHistogram.serializer.serialize(hist1, out);
0:         EstimatedHistogram.serializer.serialize(hist2, out);
0:         out.close();
1:     }
0:     
1:     @Test
1:     public void testEstimatedHistogramRead() throws IOException
1:     {
1:         if (EXECUTE_WRITES)
1:             testEstimatedHistogramWrite();
0:         
0:         DataInputStream in = getInput("utils.EstimatedHistogram.bin");
0:         assert EstimatedHistogram.serializer.deserialize(in) != null;
0:         assert EstimatedHistogram.serializer.deserialize(in) != null;
0:         assert EstimatedHistogram.serializer.deserialize(in) != null;
0:         in.close();
1:     }
1: }
author:Eric Evans
-------------------------------------------------------------------------------
commit:407a76f
/////////////////////////////////////////////////////////////////////////
1: /*
0:  * 
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
0:  * 
1:  *   http://www.apache.org/licenses/LICENSE-2.0
0:  * 
1:  * Unless required by applicable law or agreed to in writing,
1:  * software distributed under the License is distributed on an
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:  * KIND, either express or implied.  See the License for the
1:  * specific language governing permissions and limitations
1:  * under the License.
0:  * 
1:  */
0: 
============================================================================
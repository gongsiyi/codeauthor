1:b4133f3: /*
1:1ecabe6:  * Licensed to the Apache Software Foundation (ASF) under one
1:1ecabe6:  * or more contributor license agreements.  See the NOTICE file
1:1ecabe6:  * distributed with this work for additional information
1:1ecabe6:  * regarding copyright ownership.  The ASF licenses this file
1:1ecabe6:  * to you under the Apache License, Version 2.0 (the
1:1ecabe6:  * "License"); you may not use this file except in compliance
1:1ecabe6:  * with the License.  You may obtain a copy of the License at
1:1ecabe6:  *
1:1ecabe6:  *   http://www.apache.org/licenses/LICENSE-2.0
1:1ecabe6:  *
1:1ecabe6:  * Unless required by applicable law or agreed to in writing,
1:1ecabe6:  * software distributed under the License is distributed on an
1:1ecabe6:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:1ecabe6:  * KIND, either express or implied.  See the License for the
1:1ecabe6:  * specific language governing permissions and limitations
1:1ecabe6:  * under the License.
1:1ecabe6:  */
1:1ecabe6: package org.apache.cassandra.io.compress;
1:1ecabe6: 
1:4e95953: import java.io.File;
1:4e95953: import java.io.IOException;
1:4e95953: import java.io.RandomAccessFile;
1:e9ea5e0: import java.util.Arrays;
1:ba1821f: import java.util.Random;
1:a991b64: 
1:9797511: import org.junit.BeforeClass;
1:1ecabe6: import org.junit.Test;
1:9797511: 
1:9797511: import org.apache.cassandra.config.DatabaseDescriptor;
1:a991b64: import org.apache.cassandra.db.ClusteringComparator;
1:0ad499e: import org.apache.cassandra.db.marshal.BytesType;
1:41d8a5f: import org.apache.cassandra.exceptions.ConfigurationException;
1:debb15e: import org.apache.cassandra.io.sstable.CorruptSSTableException;
1:74bf5aa: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
1:fb22109: import org.apache.cassandra.io.util.*;
1:b31845c: import org.apache.cassandra.schema.CompressionParams;
1:5baf28d: import org.apache.cassandra.utils.ChecksumType;
1:91187b5: import org.apache.cassandra.utils.SyncUtil;
1:1ecabe6: 
1:ba1821f: import static org.junit.Assert.assertEquals;
1:debb15e: import static org.junit.Assert.assertNotNull;
1:ce63ccc: import static org.junit.Assert.assertSame;
1:7e220bc: import static org.junit.Assert.assertTrue;
1:1ecabe6: 
1:1ecabe6: public class CompressedRandomAccessReaderTest
1:1ecabe6: {
1:9797511:     @BeforeClass
1:9797511:     public static void setupDD()
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:e9ea5e0:     }
1:9797511: 
1:1ecabe6:     @Test
1:1ecabe6:     public void testResetAndTruncate() throws IOException
1:1ecabe6:     {
1:1ecabe6:         // test reset in current buffer or previous one
1:ce63ccc:         testResetAndTruncate(File.createTempFile("normal", "1"), false, false, 10);
1:ce63ccc:         testResetAndTruncate(File.createTempFile("normal", "2"), false, false, CompressionParams.DEFAULT_CHUNK_LENGTH);
1:9797511:     }
1:1ecabe6: 
1:1ecabe6:     @Test
1:1ecabe6:     public void testResetAndTruncateCompressed() throws IOException
1:1ecabe6:     {
1:1ecabe6:         // test reset in current buffer or previous one
1:ce63ccc:         testResetAndTruncate(File.createTempFile("compressed", "1"), true, false, 10);
1:ce63ccc:         testResetAndTruncate(File.createTempFile("compressed", "2"), true, false, CompressionParams.DEFAULT_CHUNK_LENGTH);
1:1ecabe6:     }
1:1ecabe6: 
1:7e220bc:     @Test
1:ce63ccc:     public void testResetAndTruncateCompressedMmap() throws IOException
1:1ecabe6:     {
1:ce63ccc:         // test reset in current buffer or previous one
1:ce63ccc:         testResetAndTruncate(File.createTempFile("compressed_mmap", "1"), true, true, 10);
1:ce63ccc:         testResetAndTruncate(File.createTempFile("compressed_mmap", "2"), true, true, CompressionParams.DEFAULT_CHUNK_LENGTH);
1:1ecabe6:     }
1:1ecabe6: 
1:ce63ccc:     @Test
1:41d8a5f:     public void test6791() throws IOException, ConfigurationException
1:1ecabe6:     {
1:41d8a5f:         File f = File.createTempFile("compressed6791_", "3");
1:41d8a5f:         String filename = f.getAbsolutePath();
1:b4133f3:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
1:b4133f3:         try(CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata",
1:b4133f3:                                                                                null, SequentialWriterOption.DEFAULT,
1:b4133f3:                                                                                CompressionParams.snappy(32),
1:b4133f3:                                                                                sstableMetadataCollector))
1:7e220bc:         {
1:1ecabe6: 
1:b4133f3:             for (int i = 0; i < 20; i++)
1:b4133f3:                 writer.write("x".getBytes());
1:1ecabe6: 
1:b4133f3:             DataPosition mark = writer.mark();
1:b4133f3:             // write enough garbage to create new chunks:
1:b4133f3:             for (int i = 0; i < 40; ++i)
1:b4133f3:                 writer.write("y".getBytes());
1:1ecabe6: 
1:b4133f3:             writer.resetAndTruncate(mark);
1:7e220bc: 
1:b4133f3:             for (int i = 0; i < 20; i++)
1:b4133f3:                 writer.write("x".getBytes());
1:b4133f3:             writer.finish();
1:b4133f3:         }
2:7e220bc: 
1:b4133f3:         try (FileHandle.Builder builder = new FileHandle.Builder(filename)
1:b4133f3:                                                               .withCompressionMetadata(new CompressionMetadata(filename + ".metadata",
1:b4133f3:                                                                                                                f.length(),
1:b4133f3:                                                                                                                ChecksumType.CRC32));
1:b4133f3:              FileHandle fh = builder.complete();
1:b4133f3:              RandomAccessReader reader = fh.createReader())
1:b4133f3:         {
1:b4133f3:             String res = reader.readLine();
1:b4133f3:             assertEquals(res, "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx");
1:b4133f3:             assertEquals(40, res.length());
1:7e220bc:         }
1:b4133f3:         finally
1:b4133f3:         {
1:41d8a5f:             if (f.exists())
1:ce63ccc:                 assertTrue(f.delete());
1:41d8a5f:             File metadata = new File(filename+ ".metadata");
1:a991b64:             if (metadata.exists())
1:a991b64:                 metadata.delete();
1:ce63ccc:         }
2:ce63ccc:     }
1:7e220bc: 
1:ce63ccc:     private static void testResetAndTruncate(File f, boolean compressed, boolean usemmap, int junkSize) throws IOException
1:7e220bc:     {
1:d531140:         final String filename = f.getAbsolutePath();
1:b4133f3:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
1:b4133f3:         try(SequentialWriter writer = compressed
1:fb22109:                 ? new CompressedSequentialWriter(f, filename + ".metadata",
1:b4133f3:                 null, SequentialWriterOption.DEFAULT,
1:b4133f3:                 CompressionParams.snappy(), sstableMetadataCollector)
1:fb22109:                 : new SequentialWriter(f))
1:b4133f3:         {
1:b4133f3:             writer.write("The quick ".getBytes());
1:b4133f3:             DataPosition mark = writer.mark();
1:b4133f3:             writer.write("blue fox jumps over the lazy dog".getBytes());
1:b4133f3: 
1:b4133f3:             // write enough to be sure to change chunk
1:b4133f3:             for (int i = 0; i < junkSize; ++i)
1:1ecabe6:             {
1:b4133f3:                 writer.write((byte) 1);
1:1ecabe6:             }
1:1ecabe6: 
1:b4133f3:             writer.resetAndTruncate(mark);
1:b4133f3:             writer.write("brown fox jumps over the lazy dog".getBytes());
1:b4133f3:             writer.finish();
1:b4133f3:         }
1:b4133f3:         assert f.exists();
1:1ecabe6: 
1:b4133f3:         CompressionMetadata compressionMetadata = compressed ? new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32) : null;
1:b4133f3:         try (FileHandle.Builder builder = new FileHandle.Builder(filename).mmapped(usemmap).withCompressionMetadata(compressionMetadata);
1:b4133f3:              FileHandle fh = builder.complete();
1:b4133f3:              RandomAccessReader reader = fh.createReader())
1:b4133f3:         {
1:b4133f3:             String expected = "The quick brown fox jumps over the lazy dog";
1:b4133f3:             assertEquals(expected.length(), reader.length());
1:b4133f3:             byte[] b = new byte[expected.length()];
1:b4133f3:             reader.readFully(b);
1:b4133f3:             assert new String(b).equals(expected) : "Expecting '" + expected + "', got '" + new String(b) + '\'';
1:1ecabe6:         }
1:1ecabe6:         finally
1:1ecabe6:         {
1:1ecabe6:             if (f.exists())
1:ce63ccc:                 assertTrue(f.delete());
1:1ecabe6:             File metadata = new File(filename + ".metadata");
1:1ecabe6:             if (compressed && metadata.exists())
1:1ecabe6:                 metadata.delete();
1:ce63ccc:         }
1:ce63ccc:     }
1:7e220bc: 
1:e9ea5e0:     /**
1:e9ea5e0:      * If the data read out doesn't match the checksum, an exception should be thrown
1:e9ea5e0:      */
1:41d8a5f:     @Test
1:ba1821f:     public void testDataCorruptionDetection() throws IOException
1:ce63ccc:     {
1:7e220bc:         String CONTENT = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam vitae.";
1:7e220bc: 
1:ba1821f:         File file = new File("testDataCorruptionDetection");
1:7e220bc:         file.deleteOnExit();
1:7e220bc: 
1:7e220bc:         File metadata = new File(file.getPath() + ".meta");
1:7e220bc:         metadata.deleteOnExit();
1:7e220bc: 
1:ce63ccc:         assertTrue(file.createNewFile());
1:ce63ccc:         assertTrue(metadata.createNewFile());
1:7e220bc: 
1:a991b64:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
1:fb22109:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(),
1:fb22109:                                                                       null, SequentialWriterOption.DEFAULT,
1:fb22109:                                                                       CompressionParams.snappy(), sstableMetadataCollector))
1:8704006:         {
1:8704006:             writer.write(CONTENT.getBytes());
1:8704006:             writer.finish();
1:8704006:         }
1:7e220bc: 
1:b4133f3:         // open compression metadata and get chunk information
1:b4133f3:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length(), ChecksumType.CRC32);
1:b4133f3:         CompressionMetadata.Chunk chunk = meta.chunkFor(0);
1:7e220bc: 
1:b4133f3:         try (FileHandle.Builder builder = new FileHandle.Builder(file.getPath()).withCompressionMetadata(meta);
1:b4133f3:              FileHandle fh = builder.complete();
1:b4133f3:              RandomAccessReader reader = fh.createReader())
1:b4133f3:         {// read and verify compressed data
1:b4133f3:             assertEquals(CONTENT, reader.readLine());
1:e9ea5e0:             Random random = new Random();
1:e9ea5e0:             try(RandomAccessFile checksumModifier = new RandomAccessFile(file, "rw"))
1:e9ea5e0:             {
1:e9ea5e0:                 byte[] checksum = new byte[4];
1:b4133f3: 
1:e9ea5e0:                 // seek to the end of the compressed chunk
1:e9ea5e0:                 checksumModifier.seek(chunk.length);
1:e9ea5e0:                 // read checksum bytes
1:e9ea5e0:                 checksumModifier.read(checksum);
1:e9ea5e0: 
1:e9ea5e0:                 byte[] corruptChecksum = new byte[4];
1:e9ea5e0:                 do
1:7e220bc:                 {
1:e9ea5e0:                     random.nextBytes(corruptChecksum);
1:e9ea5e0:                 } while (Arrays.equals(corruptChecksum, checksum));
1:b4133f3: 
1:e9ea5e0:                 updateChecksum(checksumModifier, chunk.length, corruptChecksum);
1:b4133f3: 
1:b4133f3:                 try (final RandomAccessReader r = fh.createReader())
1:e9ea5e0:                 {
1:e9ea5e0:                     Throwable exception = null;
1:e9ea5e0:                     try
1:7e220bc:                     {
1:e9ea5e0:                         r.readLine();
1:1ecabe6:                     }
1:e9ea5e0:                     catch (Throwable t)
1:b4133f3:                     {
1:e9ea5e0:                         exception = t;
1:b4133f3:                     }
1:e9ea5e0:                     assertNotNull(exception);
1:e9ea5e0:                     assertSame(exception.getClass(), CorruptSSTableException.class);
1:e9ea5e0:                     assertSame(exception.getCause().getClass(), CorruptBlockException.class);
1:1ecabe6:                 }
1:e9ea5e0: 
1:e9ea5e0:                 // lets write original checksum and check if we can read data
1:e9ea5e0:                 updateChecksum(checksumModifier, chunk.length, checksum);
1:e9ea5e0: 
1:e9ea5e0:                 // read and verify compressed data
1:b4133f3:                 try (RandomAccessReader cr = fh.createReader())
1:b4133f3:                 {
1:e9ea5e0:                     assertEquals(CONTENT, cr.readLine());
1:b4133f3:                 }
1:1ecabe6:             }
1:7e220bc:         }
1:7e220bc:     }
1:b4133f3: 
1:ce63ccc:     private static void updateChecksum(RandomAccessFile file, long checksumOffset, byte[] checksum) throws IOException
1:7e220bc:     {
1:ba1821f:         file.seek(checksumOffset);
1:ba1821f:         file.write(checksum);
1:91187b5:         SyncUtil.sync(file);
1:7e220bc:     }
1:ce63ccc: }
============================================================================
author:mck
-------------------------------------------------------------------------------
commit:2538013
commit:e9ea5e0
/////////////////////////////////////////////////////////////////////////
1: import java.util.Arrays;
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * If the data read out doesn't match the checksum, an exception should be thrown
1:      */
/////////////////////////////////////////////////////////////////////////
1:             }
1:             Random random = new Random();
1:             try(RandomAccessFile checksumModifier = new RandomAccessFile(file, "rw"))
1:             {
1:                 byte[] checksum = new byte[4];
1:                 // seek to the end of the compressed chunk
1:                 checksumModifier.seek(chunk.length);
1:                 // read checksum bytes
1:                 checksumModifier.read(checksum);
1: 
1:                 byte[] corruptChecksum = new byte[4];
1:                 do
1:                     random.nextBytes(corruptChecksum);
1:                 } while (Arrays.equals(corruptChecksum, checksum));
1:                 updateChecksum(checksumModifier, chunk.length, corruptChecksum);
0:                 try (final RandomAccessReader r = new CompressedRandomAccessReader.Builder(channel, meta).build())
1:                 {
1:                     Throwable exception = null;
1:                     try
1:                         r.readLine();
1:                     catch (Throwable t)
1:                         exception = t;
1:                     assertNotNull(exception);
1:                     assertSame(exception.getClass(), CorruptSSTableException.class);
1:                     assertSame(exception.getCause().getClass(), CorruptBlockException.class);
1: 
1:                 // lets write original checksum and check if we can read data
1:                 updateChecksum(checksumModifier, chunk.length, checksum);
1: 
1:                 // read and verify compressed data
0:                 try (RandomAccessReader cr = new CompressedRandomAccessReader.Builder(channel, meta).build())
1:                     assertEquals(CONTENT, cr.readLine());
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: import org.junit.BeforeClass;
1: 
1: import org.apache.cassandra.config.DatabaseDescriptor;
/////////////////////////////////////////////////////////////////////////
1:     @BeforeClass
1:     public static void setupDD()
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
1: 
author:Yuki Morishita
-------------------------------------------------------------------------------
commit:b4133f3
/////////////////////////////////////////////////////////////////////////
1: /*
/////////////////////////////////////////////////////////////////////////
1:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
1:         try(CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata",
1:                                                                                null, SequentialWriterOption.DEFAULT,
1:                                                                                CompressionParams.snappy(32),
1:                                                                                sstableMetadataCollector))
1:             for (int i = 0; i < 20; i++)
1:                 writer.write("x".getBytes());
1:             DataPosition mark = writer.mark();
1:             // write enough garbage to create new chunks:
1:             for (int i = 0; i < 40; ++i)
1:                 writer.write("y".getBytes());
1:             writer.resetAndTruncate(mark);
1:             for (int i = 0; i < 20; i++)
1:                 writer.write("x".getBytes());
1:             writer.finish();
1:         }
1:         try (FileHandle.Builder builder = new FileHandle.Builder(filename)
1:                                                               .withCompressionMetadata(new CompressionMetadata(filename + ".metadata",
1:                                                                                                                f.length(),
1:                                                                                                                ChecksumType.CRC32));
1:              FileHandle fh = builder.complete();
1:              RandomAccessReader reader = fh.createReader())
1:         {
1:             String res = reader.readLine();
1:             assertEquals(res, "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx");
1:             assertEquals(40, res.length());
/////////////////////////////////////////////////////////////////////////
1:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
1:         try(SequentialWriter writer = compressed
1:                 null, SequentialWriterOption.DEFAULT,
1:                 CompressionParams.snappy(), sstableMetadataCollector)
1:         {
1:             writer.write("The quick ".getBytes());
1:             DataPosition mark = writer.mark();
1:             writer.write("blue fox jumps over the lazy dog".getBytes());
1: 
1:             // write enough to be sure to change chunk
1:             for (int i = 0; i < junkSize; ++i)
1:                 writer.write((byte) 1);
1:             writer.resetAndTruncate(mark);
1:             writer.write("brown fox jumps over the lazy dog".getBytes());
1:             writer.finish();
1:         }
1:         assert f.exists();
1:         CompressionMetadata compressionMetadata = compressed ? new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32) : null;
1:         try (FileHandle.Builder builder = new FileHandle.Builder(filename).mmapped(usemmap).withCompressionMetadata(compressionMetadata);
1:              FileHandle fh = builder.complete();
1:              RandomAccessReader reader = fh.createReader())
1:         {
1:             String expected = "The quick brown fox jumps over the lazy dog";
1:             assertEquals(expected.length(), reader.length());
1:             byte[] b = new byte[expected.length()];
1:             reader.readFully(b);
1:             assert new String(b).equals(expected) : "Expecting '" + expected + "', got '" + new String(b) + '\'';
/////////////////////////////////////////////////////////////////////////
1:         // open compression metadata and get chunk information
1:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length(), ChecksumType.CRC32);
1:         CompressionMetadata.Chunk chunk = meta.chunkFor(0);
1:         try (FileHandle.Builder builder = new FileHandle.Builder(file.getPath()).withCompressionMetadata(meta);
1:              FileHandle fh = builder.complete();
1:              RandomAccessReader reader = fh.createReader())
1:         {// read and verify compressed data
1:             assertEquals(CONTENT, reader.readLine());
0:             Random random = new Random();
0:             RandomAccessFile checksumModifier = null;
0:             try
1:             {
0:                 checksumModifier = new RandomAccessFile(file, "rw");
0:                 byte[] checksum = new byte[4];
1: 
0:                 // seek to the end of the compressed chunk
0:                 checksumModifier.seek(chunk.length);
0:                 // read checksum bytes
0:                 checksumModifier.read(checksum);
0:                 // seek back to the chunk end
0:                 checksumModifier.seek(chunk.length);
1: 
0:                 // lets modify one byte of the checksum on each iteration
0:                 for (int i = 0; i < checksum.length; i++)
0:                     checksumModifier.write(random.nextInt());
0:                     SyncUtil.sync(checksumModifier); // making sure that change was synced with disk
1:                     try (final RandomAccessReader r = fh.createReader())
0:                         Throwable exception = null;
0:                         try
0:                             r.readLine();
0:                         catch (Throwable t)
1:                         {
0:                             exception = t;
1:                         }
0:                         assertNotNull(exception);
0:                         assertSame(exception.getClass(), CorruptSSTableException.class);
0:                         assertSame(exception.getCause().getClass(), CorruptBlockException.class);
1: 
0:                 // lets write original checksum and check if we can read data
0:                 updateChecksum(checksumModifier, chunk.length, checksum);
1: 
1:                 try (RandomAccessReader cr = fh.createReader())
0:                     // read and verify compressed data
0:                     assertEquals(CONTENT, cr.readLine());
0:                     // close reader
1:             finally
1:             {
0:                 if (checksumModifier != null)
0:                     checksumModifier.close();
1:             }
commit:fb22109
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.*;
/////////////////////////////////////////////////////////////////////////
0:             try(CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata",
1:                                                                                    null, SequentialWriterOption.DEFAULT,
0:                                                                                    CompressionParams.snappy(32),
0:                                                                                    sstableMetadataCollector))
/////////////////////////////////////////////////////////////////////////
1:                 ? new CompressedSequentialWriter(f, filename + ".metadata",
0:                                                  null, SequentialWriterOption.DEFAULT,
0:                                                  CompressionParams.snappy(), sstableMetadataCollector)
1:                 : new SequentialWriter(f))
/////////////////////////////////////////////////////////////////////////
1:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(),
0:                                                                       null, SequentialWriterOption.DEFAULT,
1:                                                                       CompressionParams.snappy(), sstableMetadataCollector))
commit:74bf5aa
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.sstable.metadata.MetadataCollector;
/////////////////////////////////////////////////////////////////////////
0:             MetadataCollector sstableMetadataCollector = new MetadataCollector(BytesType.instance).replayPosition(null);
/////////////////////////////////////////////////////////////////////////
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(BytesType.instance).replayPosition(null);
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:c9ac050
commit:78a3d2b
commit:a991b64
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.apache.cassandra.db.ClusteringComparator;
/////////////////////////////////////////////////////////////////////////
1:             MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance));
/////////////////////////////////////////////////////////////////////////
1:             if (metadata.exists())
1:                 metadata.delete();
/////////////////////////////////////////////////////////////////////////
0:             MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance)).replayPosition(null);
/////////////////////////////////////////////////////////////////////////
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new ClusteringComparator(BytesType.instance)).replayPosition(null);
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.composites.*;
/////////////////////////////////////////////////////////////////////////
0:             MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance)).replayPosition(null);
/////////////////////////////////////////////////////////////////////////
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance)).replayPosition(null);
commit:1ecabe6
/////////////////////////////////////////////////////////////////////////
0: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *   http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing,
1:  * software distributed under the License is distributed on an
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:  * KIND, either express or implied.  See the License for the
1:  * specific language governing permissions and limitations
1:  * under the License.
1:  */
1: package org.apache.cassandra.io.compress;
1: 
0: import java.io.*;
1: 
1: import org.junit.Test;
1: 
0: import org.apache.cassandra.io.util.*;
1: 
1: public class CompressedRandomAccessReaderTest
1: {
1:     @Test
1:     public void testResetAndTruncate() throws IOException
1:     {
1:         // test reset in current buffer or previous one
0:         testResetAndTruncate(false, 10);
0:         testResetAndTruncate(false, CompressedSequentialWriter.CHUNK_LENGTH);
1:     }
1: 
1:     @Test
1:     public void testResetAndTruncateCompressed() throws IOException
1:     {
1:         // test reset in current buffer or previous one
0:         testResetAndTruncate(true, 10);
0:         testResetAndTruncate(true, CompressedSequentialWriter.CHUNK_LENGTH);
1:     }
1: 
0:     private void testResetAndTruncate(boolean compressed, int junkSize) throws IOException
1:     {
0:         String filename = "corruptFile";
0:         File f = new File(filename);
1: 
0:         try
1:         {
0:             SequentialWriter writer = compressed
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", false)
0:                 : new SequentialWriter(f, CompressedSequentialWriter.CHUNK_LENGTH, false);
1: 
0:             writer.write("The quick ".getBytes());
0:             FileMark mark = writer.mark();
0:             writer.write("blue fox jumps over the lazy dog".getBytes());
1: 
0:             // write enough to be sure to change chunk
0:             for (int i = 0; i < junkSize; ++i)
1:             {
0:                 writer.write((byte)1);
1:             }
1: 
0:             writer.resetAndTruncate(mark);
0:             writer.write("brown fox jumps over the lazy dog".getBytes());
0:             writer.close();
1: 
0:             assert f.exists();
0:             RandomAccessReader reader = compressed
0:                 ? new CompressedRandomAccessReader(filename, new CompressionMetadata(filename + ".metadata", f.length()), false)
0:                 : new RandomAccessReader(f, CompressedSequentialWriter.CHUNK_LENGTH, false);
0:             String expected = "The quick brown fox jumps over the lazy dog";
0:             assert reader.length() == expected.length();
0:             byte[] b = new byte[expected.length()];
0:             reader.readFully(b);
0:             assert new String(b).equals(expected) : "Expecting '" + expected + "', got '" + new String(b) + "'";
1:         }
1:         finally
1:         {
0:             // cleanup
1:             if (f.exists())
0:                 f.delete();
1:             File metadata = new File(filename + ".metadata");
1:             if (compressed && metadata.exists())
1:                 metadata.delete();
1:         }
1:     }
1: }
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:849a438
/////////////////////////////////////////////////////////////////////////
0:             MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance));
/////////////////////////////////////////////////////////////////////////
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance));
/////////////////////////////////////////////////////////////////////////
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance));
commit:8704006
/////////////////////////////////////////////////////////////////////////
1:             writer.finish();
/////////////////////////////////////////////////////////////////////////
0:             writer.finish();
/////////////////////////////////////////////////////////////////////////
0:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector))
1:         {
1:             writer.write(CONTENT.getBytes());
0:             writer.finish();
1:         }
/////////////////////////////////////////////////////////////////////////
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:30bb255
/////////////////////////////////////////////////////////////////////////
0:             try(RandomAccessReader reader = RandomAccessReader.builder(channel)
0:                                             .compression(new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32))
/////////////////////////////////////////////////////////////////////////
0:             RandomAccessReader.Builder builder = RandomAccessReader.builder(channel);
0:             if (compressed)
0:                 builder.compression(compressionMetadata);
0:             MmappedRegions regions = null;
0:                 regions = compressed
0:                         ? MmappedRegions.map(channel, compressionMetadata)
0:                         : MmappedRegions.map(channel, f.length());
0:                 builder.regions(regions);
/////////////////////////////////////////////////////////////////////////
0:             if (regions != null)
0:                 regions.close();
/////////////////////////////////////////////////////////////////////////
0:             try(RandomAccessReader reader = RandomAccessReader.builder(channel).compression(meta).build())
/////////////////////////////////////////////////////////////////////////
0:                         try (final RandomAccessReader r = RandomAccessReader.builder(channel).compression(meta).build())
/////////////////////////////////////////////////////////////////////////
0:                     try (RandomAccessReader cr = RandomAccessReader.builder(channel).compression(meta).build())
commit:3adfd15
/////////////////////////////////////////////////////////////////////////
0:                 : SequentialWriter.open(f);
author:Paulo Motta
-------------------------------------------------------------------------------
commit:e8651b6
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.DataPosition;
/////////////////////////////////////////////////////////////////////////
0:                 DataPosition mark = writer.mark();
/////////////////////////////////////////////////////////////////////////
0:                 DataPosition mark = writer.mark();
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:7e220bc
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.util.concurrent.RateLimiter;
1: 
0: import org.apache.cassandra.io.util.CompressedPoolingSegmentedFile;
0: import org.apache.cassandra.io.util.FileDataInput;
0: import static org.junit.Assert.assertFalse;
1: import static org.junit.Assert.assertTrue;
/////////////////////////////////////////////////////////////////////////
1:     @Test
0:     public void testThrottledReadersAreNotCached() throws IOException
1:     {
1:         String CONTENT = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam vitae.";
1: 
0:         File file = new File("testThrottledReadersAreNotCached");
1:         file.deleteOnExit();
1: 
1:         File metadata = new File(file.getPath() + ".meta");
1:         metadata.deleteOnExit();
1: 
0:         MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance)).replayPosition(null);
0:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector))
1:         {
0:             writer.write(CONTENT.getBytes());
0:             writer.finish();
1:         }
1: 
0:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length());
1: 
0:         try(ChannelProxy channel = new ChannelProxy(file);
0:             CompressedPoolingSegmentedFile segmentedFile = new CompressedPoolingSegmentedFile(channel, meta))
1:         {
0:             //The cache bucket is only initialized by a call to FileCacheService.instance.get() so first
0:             // we must create a reader using the interface for accessing segments
0:             FileDataInput reader = segmentedFile.getSegment(0);
0:             assertNotNull(reader);
0:             reader.close();
1: 
0:             //Now we create a throttled reader, this should not be added to the cache
0:             RateLimiter limiter = RateLimiter.create(1024);
0:             reader = segmentedFile.createThrottledReader(limiter);
0:             assertNotNull(reader);
0:             assertTrue(reader instanceof CompressedThrottledReader);
0:             reader.close();
1: 
0:             //We retrieve 2 readers, neither should be a throttled reader
0:             FileDataInput[] readers =
1:             {
0:                 segmentedFile.getSegment(0),
0:                 segmentedFile.getSegment(0)
0:             };
1: 
0:             for (FileDataInput r : readers)
1:             {
0:                 assertNotNull(r);
0:                 assertFalse(r instanceof CompressedThrottledReader);
1:             }
1: 
0:             for (FileDataInput r : readers)
0:                 r.close();
1:         }
1:     }
1: 
commit:ce63ccc
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.MmappedRegions;
/////////////////////////////////////////////////////////////////////////
1: import static org.junit.Assert.assertSame;
0: import static org.junit.Assert.assertTrue;
/////////////////////////////////////////////////////////////////////////
1:         testResetAndTruncate(File.createTempFile("normal", "1"), false, false, 10);
1:         testResetAndTruncate(File.createTempFile("normal", "2"), false, false, CompressionParams.DEFAULT_CHUNK_LENGTH);
1:         testResetAndTruncate(File.createTempFile("compressed", "1"), true, false, 10);
1:         testResetAndTruncate(File.createTempFile("compressed", "2"), true, false, CompressionParams.DEFAULT_CHUNK_LENGTH);
1:     }
0: 
1:     @Test
1:     public void testResetAndTruncateCompressedMmap() throws IOException
1:     {
1:         // test reset in current buffer or previous one
1:         testResetAndTruncate(File.createTempFile("compressed_mmap", "1"), true, true, 10);
1:         testResetAndTruncate(File.createTempFile("compressed_mmap", "2"), true, true, CompressionParams.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:         try(ChannelProxy channel = new ChannelProxy(f))
0:             try(CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata", CompressionParams.snappy(32), sstableMetadataCollector))
0:             {
0:                 for (int i = 0; i < 20; i++)
0:                     writer.write("x".getBytes());
0:                 FileMark mark = writer.mark();
0:                 // write enough garbage to create new chunks:
0:                 for (int i = 0; i < 40; ++i)
0:                     writer.write("y".getBytes());
0:                 writer.resetAndTruncate(mark);
0:                 for (int i = 0; i < 20; i++)
0:                     writer.write("x".getBytes());
0:                 writer.finish();
1:             }
0:             try(RandomAccessReader reader = new CompressedRandomAccessReader.Builder(channel,
0:                                                                                      new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32))
0:                                             .build())
0:             {
0:                 String res = reader.readLine();
0:                 assertEquals(res, "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx");
0:                 assertEquals(40, res.length());
1:             }
1:                 assertTrue(f.delete());
1:     private static void testResetAndTruncate(File f, boolean compressed, boolean usemmap, int junkSize) throws IOException
0:         try(ChannelProxy channel = new ChannelProxy(f))
0:             try(SequentialWriter writer = compressed
0:                 : SequentialWriter.open(f))
0:                 writer.write("The quick ".getBytes());
0:                 FileMark mark = writer.mark();
0:                 writer.write("blue fox jumps over the lazy dog".getBytes());
0: 
0:                 // write enough to be sure to change chunk
0:                 for (int i = 0; i < junkSize; ++i)
0:                 {
0:                     writer.write((byte) 1);
1:                 }
0: 
0:                 writer.resetAndTruncate(mark);
0:                 writer.write("brown fox jumps over the lazy dog".getBytes());
0:                 writer.finish();
1:             }
0:             assert f.exists();
0: 
0:             CompressionMetadata compressionMetadata = compressed ? new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32) : null;
0:             RandomAccessReader.Builder builder = compressed
0:                                                  ? new CompressedRandomAccessReader.Builder(channel, compressionMetadata)
0:                                                  : new RandomAccessReader.Builder(channel);
0: 
0:             if (usemmap)
0:             {
0:                 if (compressed)
0:                     builder.regions(MmappedRegions.map(channel, compressionMetadata));
0:                 else
0:                     builder.regions(MmappedRegions.map(channel, f.length()));
0:             try(RandomAccessReader reader = builder.build())
0:             {
0:                 String expected = "The quick brown fox jumps over the lazy dog";
0:                 assertEquals(expected.length(), reader.length());
0:                 byte[] b = new byte[expected.length()];
0:                 reader.readFully(b);
0:                 assert new String(b).equals(expected) : "Expecting '" + expected + "', got '" + new String(b) + '\'';
1:             }
0:             if (usemmap)
0:                 builder.regions.close();
1:                 assertTrue(f.delete());
/////////////////////////////////////////////////////////////////////////
1:         assertTrue(file.createNewFile());
1:         assertTrue(metadata.createNewFile());
0: 
/////////////////////////////////////////////////////////////////////////
0:         try(ChannelProxy channel = new ChannelProxy(file))
0:             // open compression metadata and get chunk information
0:             CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length(), ChecksumType.CRC32);
0:             CompressionMetadata.Chunk chunk = meta.chunkFor(0);
0:             try(RandomAccessReader reader = new CompressedRandomAccessReader.Builder(channel, meta).build())
0:             {// read and verify compressed data
0:                 assertEquals(CONTENT, reader.readLine());
0:                 Random random = new Random();
0:                 RandomAccessFile checksumModifier = null;
0:                     checksumModifier = new RandomAccessFile(file, "rw");
0:                     byte[] checksum = new byte[4];
0: 
0:                     // seek to the end of the compressed chunk
0:                     checksumModifier.seek(chunk.length);
0:                     // read checksum bytes
0:                     checksumModifier.read(checksum);
0:                     // seek back to the chunk end
0:                     checksumModifier.seek(chunk.length);
0: 
0:                     // lets modify one byte of the checksum on each iteration
0:                     for (int i = 0; i < checksum.length; i++)
0:                     {
0:                         checksumModifier.write(random.nextInt());
0:                         SyncUtil.sync(checksumModifier); // making sure that change was synced with disk
0: 
0:                         try (final RandomAccessReader r = new CompressedRandomAccessReader.Builder(channel, meta).build())
0:                         {
0:                             Throwable exception = null;
0:                             try
0:                             {
0:                                 r.readLine();
0:                             }
0:                             catch (Throwable t)
0:                             {
0:                                 exception = t;
0:                             }
0:                             assertNotNull(exception);
0:                             assertSame(exception.getClass(), CorruptSSTableException.class);
0:                             assertSame(exception.getCause().getClass(), CorruptBlockException.class);
0:                         }
0:                     }
0: 
0:                     // lets write original checksum and check if we can read data
0:                     updateChecksum(checksumModifier, chunk.length, checksum);
0: 
0:                     try (RandomAccessReader cr = new CompressedRandomAccessReader.Builder(channel, meta).build())
0:                     {
0:                         // read and verify compressed data
0:                         assertEquals(CONTENT, cr.readLine());
0:                         // close reader
0:                     }
0:                 finally
0:                     if (checksumModifier != null)
0:                         checksumModifier.close();
1:     private static void updateChecksum(RandomAccessFile file, long checksumOffset, byte[] checksum) throws IOException
commit:4e29b7a
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.util.ChannelProxy;
/////////////////////////////////////////////////////////////////////////
0:         ChannelProxy channel = new ChannelProxy(f);
/////////////////////////////////////////////////////////////////////////
0:             CompressedRandomAccessReader reader = CompressedRandomAccessReader.open(channel, new CompressionMetadata(filename + ".metadata", f.length()));
/////////////////////////////////////////////////////////////////////////
0:             channel.close();
0: 
/////////////////////////////////////////////////////////////////////////
0:         ChannelProxy channel = new ChannelProxy(f);
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(channel, new CompressionMetadata(filename + ".metadata", f.length()))
/////////////////////////////////////////////////////////////////////////
0:             channel.close();
0: 
/////////////////////////////////////////////////////////////////////////
0:         ChannelProxy channel = new ChannelProxy(file);
0: 
0:         RandomAccessReader reader = CompressedRandomAccessReader.open(channel, meta);
/////////////////////////////////////////////////////////////////////////
0:                 final RandomAccessReader r = CompressedRandomAccessReader.open(channel, meta);
/////////////////////////////////////////////////////////////////////////
0:             reader = CompressedRandomAccessReader.open(channel, meta);
/////////////////////////////////////////////////////////////////////////
0:             channel.close();
0: 
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:5baf28d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.ChecksumType;
/////////////////////////////////////////////////////////////////////////
0:             CompressedRandomAccessReader reader = CompressedRandomAccessReader.open(channel, new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32));
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(channel, new CompressionMetadata(filename + ".metadata", f.length(), ChecksumType.CRC32))
/////////////////////////////////////////////////////////////////////////
0:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length(), ChecksumType.CRC32);
commit:91187b5
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.utils.SyncUtil;
/////////////////////////////////////////////////////////////////////////
0:                 SyncUtil.sync(checksumModifier); // making sure that change was synced with disk
/////////////////////////////////////////////////////////////////////////
1:         SyncUtil.sync(file);
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:b31845c
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.schema.CompressionParams;
/////////////////////////////////////////////////////////////////////////
0:         testResetAndTruncate(File.createTempFile("normal", "2"), false, CompressionParams.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:         testResetAndTruncate(File.createTempFile("compressed", "2"), true, CompressionParams.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:             CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata", CompressionParams.snappy(32), sstableMetadataCollector);
/////////////////////////////////////////////////////////////////////////
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", CompressionParams.snappy(), sstableMetadataCollector)
/////////////////////////////////////////////////////////////////////////
0:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), CompressionParams.snappy(), sstableMetadataCollector))
author:blerer
-------------------------------------------------------------------------------
commit:056115f
/////////////////////////////////////////////////////////////////////////
0:             CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata",  CompressionParameters.snappy(32), sstableMetadataCollector);
/////////////////////////////////////////////////////////////////////////
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", CompressionParameters.snappy(), sstableMetadataCollector)
/////////////////////////////////////////////////////////////////////////
0:         try (SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), CompressionParameters.snappy(), sstableMetadataCollector))
author:Joshua McKenzie
-------------------------------------------------------------------------------
commit:bc7941c
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:                 : new SequentialWriter(f, CompressionParameters.DEFAULT_CHUNK_LENGTH, false);
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:895ec3e
/////////////////////////////////////////////////////////////////////////
0:             CompressedRandomAccessReader reader = CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length()));
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length()))
/////////////////////////////////////////////////////////////////////////
0:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length());
author:belliottsmith
-------------------------------------------------------------------------------
commit:4e95953
/////////////////////////////////////////////////////////////////////////
1: import java.io.File;
1: import java.io.IOException;
1: import java.io.RandomAccessFile;
0: import org.apache.cassandra.db.composites.SimpleDenseCellNameType;
0: import org.apache.cassandra.io.util.FileMark;
0: import org.apache.cassandra.io.util.RandomAccessReader;
0: import org.apache.cassandra.io.util.SequentialWriter;
/////////////////////////////////////////////////////////////////////////
0:             CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata", new CompressionParameters(SnappyCompressor.instance, 32, Collections.<String, String>emptyMap()), sstableMetadataCollector);
/////////////////////////////////////////////////////////////////////////
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector)
0:                 : new SequentialWriter(f, CompressionParameters.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector);
author:Marcus Eriksson
-------------------------------------------------------------------------------
commit:0439531
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.metadata.StatsMetadata;
/////////////////////////////////////////////////////////////////////////
0:             MetadataCollector sstableMetadataCollector = new MetadataCollector(new SimpleDenseCellNameType(BytesType.instance));
commit:e4437bc
commit:41d8a5f
/////////////////////////////////////////////////////////////////////////
0: import java.util.Collections;
1: import org.apache.cassandra.exceptions.ConfigurationException;
/////////////////////////////////////////////////////////////////////////
1:     @Test
1:     public void test6791() throws IOException, ConfigurationException
0:     {
1:         File f = File.createTempFile("compressed6791_", "3");
1:         String filename = f.getAbsolutePath();
0:         try
0:         {
0: 
0:             SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector(BytesType.instance).replayPosition(null);
0:             CompressedSequentialWriter writer = new CompressedSequentialWriter(f, filename + ".metadata", false, new CompressionParameters(SnappyCompressor.instance, 32, Collections.<String, String>emptyMap()), sstableMetadataCollector);
0: 
0:             for (int i = 0; i < 20; i++)
0:                 writer.write("x".getBytes());
0: 
0:             FileMark mark = writer.mark();
0:             // write enough garbage to create new chunks:
0:             for (int i = 0; i < 40; ++i)
0:                 writer.write("y".getBytes());
0: 
0:             writer.resetAndTruncate(mark);
0: 
0:             for (int i = 0; i < 20; i++)
0:                 writer.write("x".getBytes());
0:             writer.close();
0: 
0:             CompressedRandomAccessReader reader = CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length(), true));
0:             String res = reader.readLine();
0:             assertEquals(res, "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx");
0:             assertEquals(40, res.length());
0:         }
0:         finally
0:         {
0:             // cleanup
1:             if (f.exists())
0:                 f.delete();
1:             File metadata = new File(filename+ ".metadata");
0:                 if (metadata.exists())
0:                     metadata.delete();
0:         }
0:     }
author:Jake Luciani
-------------------------------------------------------------------------------
commit:815b238
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length(), true))
/////////////////////////////////////////////////////////////////////////
0:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length(), true);
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:0ad499e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.marshal.BytesType;
/////////////////////////////////////////////////////////////////////////
0:             SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector(BytesType.instance).replayPosition(null);
/////////////////////////////////////////////////////////////////////////
0:         SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector(BytesType.instance).replayPosition(null);
commit:01bc564
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length()), false)
/////////////////////////////////////////////////////////////////////////
0:         RandomAccessReader reader = CompressedRandomAccessReader.open(file.getPath(), meta, false);
/////////////////////////////////////////////////////////////////////////
0:                 final RandomAccessReader r = CompressedRandomAccessReader.open(file.getPath(), meta, false);
/////////////////////////////////////////////////////////////////////////
0:             reader = CompressedRandomAccessReader.open(file.getPath(), meta, false);
commit:edcc7f1
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length()), false)
0:                                       : RandomAccessReader.open(f);
commit:debb15e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.sstable.CorruptSSTableException;
1: import static org.junit.Assert.assertNotNull;
/////////////////////////////////////////////////////////////////////////
0:                 Throwable exception = null;
0:                 try
0:                     r.readLine();
0:                 }
0:                 catch (Throwable t)
0:                 {
0:                     exception = t;
0:                 }
0:                 assertNotNull(exception);
0:                 assertEquals(exception.getClass(), CorruptSSTableException.class);
0:                 assertEquals(exception.getCause().getClass(), CorruptBlockException.class);
commit:41c7424
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", false, new CompressionParameters(SnappyCompressor.instance))
/////////////////////////////////////////////////////////////////////////
0: 
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), false, new CompressionParameters(SnappyCompressor.instance));
commit:3682eb7
/////////////////////////////////////////////////////////////////////////
0:             assertEquals(expected.length(), reader.length());
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:27ed655
/////////////////////////////////////////////////////////////////////////
0:                                       ? CompressedRandomAccessReader.open(filename, new CompressionMetadata(filename + ".metadata", f.length()))
/////////////////////////////////////////////////////////////////////////
0:         RandomAccessReader reader = CompressedRandomAccessReader.open(file.getPath(), meta);
/////////////////////////////////////////////////////////////////////////
0:                 final RandomAccessReader r = CompressedRandomAccessReader.open(file.getPath(), meta);
/////////////////////////////////////////////////////////////////////////
0:             reader = CompressedRandomAccessReader.open(file.getPath(), meta);
commit:0b54c99
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.SSTableMetadata;
/////////////////////////////////////////////////////////////////////////
0:             SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector().replayPosition(null);
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", false, new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector)
/////////////////////////////////////////////////////////////////////////
0:         SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector().replayPosition(null);
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), false, new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector);
commit:84a03ab
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.io.sstable.SSTableMetadata;
/////////////////////////////////////////////////////////////////////////
0:             SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector().replayPosition(null);
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", false, new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector)
/////////////////////////////////////////////////////////////////////////
0:         SSTableMetadata.Collector sstableMetadataCollector = SSTableMetadata.createCollector().replayPosition(null);
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), false, new CompressionParameters(SnappyCompressor.instance), sstableMetadataCollector);
commit:d531140
/////////////////////////////////////////////////////////////////////////
0:         testResetAndTruncate(File.createTempFile("normal", "1"), false, 10);
0:         testResetAndTruncate(File.createTempFile("normal", "2"), false, CompressionParameters.DEFAULT_CHUNK_LENGTH);
0:         testResetAndTruncate(File.createTempFile("compressed", "1"), true, 10);
0:         testResetAndTruncate(File.createTempFile("compressed", "2"), true, CompressionParameters.DEFAULT_CHUNK_LENGTH);
0:     private void testResetAndTruncate(File f, boolean compressed, int junkSize) throws IOException
1:         final String filename = f.getAbsolutePath();
commit:c8afd76
/////////////////////////////////////////////////////////////////////////
0:         testResetAndTruncate(false, CompressionParameters.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:         testResetAndTruncate(true, CompressionParameters.DEFAULT_CHUNK_LENGTH);
/////////////////////////////////////////////////////////////////////////
0:                 ? new CompressedSequentialWriter(f, filename + ".metadata", false, new CompressionParameters(SnappyCompressor.instance))
0:                 : new SequentialWriter(f, CompressionParameters.DEFAULT_CHUNK_LENGTH, false);
/////////////////////////////////////////////////////////////////////////
0:                 : new RandomAccessReader(f, CompressionParameters.DEFAULT_CHUNK_LENGTH, false);
/////////////////////////////////////////////////////////////////////////
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), false, new CompressionParameters(SnappyCompressor.instance));
commit:ba1821f
/////////////////////////////////////////////////////////////////////////
1: import java.util.Random;
0: import java.util.concurrent.Callable;
1: import static org.junit.Assert.assertEquals;
0: 
0: import static org.apache.cassandra.Util.expectException;
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0:     @Test
1:     public void testDataCorruptionDetection() throws IOException
0:     {
0:         String CONTENT = "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Etiam vitae.";
0: 
1:         File file = new File("testDataCorruptionDetection");
0:         file.deleteOnExit();
0: 
0:         File metadata = new File(file.getPath() + ".meta");
0:         metadata.deleteOnExit();
0: 
0:         SequentialWriter writer = new CompressedSequentialWriter(file, metadata.getPath(), false);
0: 
0:         writer.write(CONTENT.getBytes());
0:         writer.close();
0: 
0:         // open compression metadata and get chunk information
0:         CompressionMetadata meta = new CompressionMetadata(metadata.getPath(), file.length());
0:         CompressionMetadata.Chunk chunk = meta.chunkFor(0);
0: 
0:         RandomAccessReader reader = CompressedRandomAccessReader.open(file.getPath(), meta, false);
0:         // read and verify compressed data
0:         assertEquals(CONTENT, reader.readLine());
0:         // close reader
0:         reader.close();
0: 
0:         Random random = new Random();
0:         RandomAccessFile checksumModifier = null;
0: 
0:         try
0:         {
0:             checksumModifier = new RandomAccessFile(file, "rw");
0:             byte[] checksum = new byte[4];
0: 
0:             // seek to the end of the compressed chunk
0:             checksumModifier.seek(chunk.length);
0:             // read checksum bytes
0:             checksumModifier.read(checksum);
0:             // seek back to the chunk end
0:             checksumModifier.seek(chunk.length);
0: 
0:             // lets modify one byte of the checksum on each iteration
0:             for (int i = 0; i < checksum.length; i++)
0:             {
0:                 checksumModifier.write(random.nextInt());
0:                 checksumModifier.getFD().sync(); // making sure that change was synced with disk
0: 
0:                 final RandomAccessReader r = CompressedRandomAccessReader.open(file.getPath(), meta, false);
0: 
0:                 expectException(new Callable<String>()
0:                 {
0:                     public String call() throws Exception
0:                     {
0:                         return r.readLine();
0:                     }
0:                 }, CorruptedBlockException.class);
0: 
0:                 r.close();
0:             }
0: 
0:             // lets write original checksum and check if we can read data
0:             updateChecksum(checksumModifier, chunk.length, checksum);
0: 
0:             reader = CompressedRandomAccessReader.open(file.getPath(), meta, false);
0:             // read and verify compressed data
0:             assertEquals(CONTENT, reader.readLine());
0:             // close reader
0:             reader.close();
0:         }
0:         finally
0:         {
0:             if (checksumModifier != null)
0:                 checksumModifier.close();
0:         }
0:     }
0: 
0:     private void updateChecksum(RandomAccessFile file, long checksumOffset, byte[] checksum) throws IOException
0:     {
1:         file.seek(checksumOffset);
1:         file.write(checksum);
0:         file.getFD().sync();
0:     }
============================================================================
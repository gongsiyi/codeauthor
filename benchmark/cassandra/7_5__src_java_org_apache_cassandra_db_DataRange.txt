2:e48ff29: /*
1:e48ff29:  * Licensed to the Apache Software Foundation (ASF) under one
1:e48ff29:  * or more contributor license agreements.  See the NOTICE file
1:e48ff29:  * distributed with this work for additional information
1:e48ff29:  * regarding copyright ownership.  The ASF licenses this file
1:e48ff29:  * to you under the Apache License, Version 2.0 (the
1:e48ff29:  * "License"); you may not use this file except in compliance
1:e48ff29:  * with the License.  You may obtain a copy of the License at
1:e48ff29:  *     http://www.apache.org/licenses/LICENSE-2.0
4:e48ff29:  *
1:e48ff29:  * Unless required by applicable law or agreed to in writing, software
1:e48ff29:  * distributed under the License is distributed on an "AS IS" BASIS,
1:e48ff29:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:e48ff29:  * See the License for the specific language governing permissions and
1:e48ff29:  * limitations under the License.
2:e48ff29:  */
1:e48ff29: package org.apache.cassandra.db;
19:e48ff29: 
1:a991b64: import java.io.IOException;
1:e48ff29: import java.nio.ByteBuffer;
1:d075540: 
1:d075540: import org.apache.cassandra.config.CFMetaData;
1:a991b64: import org.apache.cassandra.config.ColumnDefinition;
1:e48ff29: import org.apache.cassandra.db.filter.*;
1:a991b64: import org.apache.cassandra.db.marshal.AbstractType;
1:a991b64: import org.apache.cassandra.db.marshal.CompositeType;
1:e48ff29: import org.apache.cassandra.dht.*;
1:2457599: import org.apache.cassandra.io.util.DataInputPlus;
1:a991b64: import org.apache.cassandra.io.util.DataOutputPlus;
1:d075540: 
1:e48ff29: /**
1:a991b64:  * Groups both the range of partitions to query, and the clustering index filter to
1:a991b64:  * apply for each partition (for a (partition) range query).
1:a991b64:  * <p>
1:a991b64:  * The main "trick" is that the clustering index filter can only be obtained by
1:a991b64:  * providing the partition key on which the filter will be applied. This is
1:a991b64:  * necessary when paging range queries, as we might need a different filter
1:a991b64:  * for the starting key than for other keys (because the previous page we had
1:a991b64:  * queried may have ended in the middle of a partition).
1:a991b64:  */
1:e48ff29: public class DataRange
1:d075540: {
1:a991b64:     public static final Serializer serializer = new Serializer();
1:d075540: 
1:bd7d119:     protected final AbstractBounds<PartitionPosition> keyRange;
1:a991b64:     protected final ClusteringIndexFilter clusteringIndexFilter;
1:2acbab6: 
1:a991b64:     /**
1:a991b64:      * Creates a {@code DataRange} given a range of partition keys and a clustering index filter. The
1:a991b64:      * return {@code DataRange} will return the same filter for all keys.
1:a991b64:      *
1:a991b64:      * @param range the range over partition keys to use.
1:a991b64:      * @param clusteringIndexFilter the clustering index filter to use.
1:a991b64:      */
1:a991b64:     public DataRange(AbstractBounds<PartitionPosition> range, ClusteringIndexFilter clusteringIndexFilter)
1:d075540:     {
1:e48ff29:         this.keyRange = range;
1:a991b64:         this.clusteringIndexFilter = clusteringIndexFilter;
1:d075540:     }
1:d075540: 
1:2acbab6:     /**
1:a991b64:      * Creates a {@code DataRange} to query all data (over the whole ring).
1:a991b64:      *
1:a991b64:      * @param partitioner the partitioner in use for the table.
1:a991b64:      *
1:a991b64:      * @return the newly create {@code DataRange}.
1:2acbab6:      */
1:e48ff29:     public static DataRange allData(IPartitioner partitioner)
1:d075540:     {
1:69542a9:         return forTokenRange(new Range<Token>(partitioner.getMinimumToken(), partitioner.getMinimumToken()));
1:d075540:     }
1:d075540: 
1:2acbab6:     /**
1:a991b64:      * Creates a {@code DataRange} to query all rows over the provided token range.
1:a991b64:      *
1:a991b64:      * @param tokenRange the (partition key) token range to query.
1:a991b64:      *
1:a991b64:      * @return the newly create {@code DataRange}.
1:2acbab6:      */
1:a991b64:     public static DataRange forTokenRange(Range<Token> tokenRange)
1:d075540:     {
1:a991b64:         return forKeyRange(Range.makeRowRange(tokenRange));
1:d075540:     }
1:2acbab6: 
1:a991b64:     /**
1:a991b64:      * Creates a {@code DataRange} to query all rows over the provided key range.
1:a991b64:      *
1:a991b64:      * @param keyRange the (partition key) range to query.
1:a991b64:      *
1:a991b64:      * @return the newly create {@code DataRange}.
1:a991b64:      */
1:a991b64:     public static DataRange forKeyRange(Range<PartitionPosition> keyRange)
12:e48ff29:     {
1:a991b64:         return new DataRange(keyRange, new ClusteringIndexSliceFilter(Slices.ALL, false));
1:d075540:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Creates a {@code DataRange} to query all partitions of the ring using the provided
1:a991b64:      * clustering index filter.
1:a991b64:      *
1:a991b64:      * @param partitioner the partitioner in use for the table queried.
1:a991b64:      * @param filter the clustering index filter to use.
1:a991b64:      *
1:a991b64:      * @return the newly create {@code DataRange}.
1:a991b64:      */
1:a991b64:     public static DataRange allData(IPartitioner partitioner, ClusteringIndexFilter filter)
1:a991b64:     {
1:a991b64:         return new DataRange(Range.makeRowRange(new Range<Token>(partitioner.getMinimumToken(), partitioner.getMinimumToken())), filter);
1:a991b64:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * The range of partition key queried by this {@code DataRange}.
1:a991b64:      *
1:a991b64:      * @return the range of partition key queried by this {@code DataRange}.
1:a991b64:      */
1:a991b64:     public AbstractBounds<PartitionPosition> keyRange()
1:e48ff29:     {
1:e48ff29:         return keyRange;
12:e48ff29:     }
1:e48ff29: 
1:a991b64:     /**
1:a991b64:      * The start of the partition key range queried by this {@code DataRange}.
1:a991b64:      *
1:a991b64:      * @return the start of the partition key range queried by this {@code DataRange}.
1:a991b64:      */
1:a991b64:     public PartitionPosition startKey()
1:e48ff29:     {
1:e48ff29:         return keyRange.left;
1:e48ff29:     }
1:e48ff29: 
1:a991b64:     /**
1:a991b64:      * The end of the partition key range queried by this {@code DataRange}.
1:a991b64:      *
1:a991b64:      * @return the end of the partition key range queried by this {@code DataRange}.
1:a991b64:      */
1:a991b64:     public PartitionPosition stopKey()
1:e48ff29:     {
1:e48ff29:         return keyRange.right;
1:dd62f7b:     }
1:dd62f7b: 
1:dd62f7b:     /**
1:a991b64:      * Whether the underlying clustering index filter is a names filter or not.
1:a991b64:      *
1:a991b64:      * @return Whether the underlying clustering index filter is a names filter or not.
1:a991b64:      */
1:a991b64:     public boolean isNamesQuery()
1:dd62f7b:     {
1:a991b64:         return clusteringIndexFilter instanceof ClusteringIndexNamesFilter;
1:e48ff29:     }
1:dd62f7b: 
1:a991b64:     /**
1:8c64cef:      * Whether the data range is for a paged request or not.
1:8c64cef:      *
1:8c64cef:      * @return true if for paging, false otherwise
1:8c64cef:      */
1:8c64cef:     public boolean isPaging()
1:8c64cef:     {
1:8c64cef:         return false;
1:8c64cef:     }
1:8c64cef: 
1:8c64cef:     /**
1:a991b64:      * Whether the range queried by this {@code DataRange} actually wraps around.
1:a991b64:      *
1:a991b64:      * @return whether the range queried by this {@code DataRange} actually wraps around.
1:a991b64:      */
1:4f0d7b4:     public boolean isWrapAround()
1:4f0d7b4:     {
1:a991b64:         // Only range can ever wrap
1:69542a9:         return keyRange instanceof Range && ((Range<?>)keyRange).isWrapAround();
1:4f0d7b4:     }
1:bd7d119: 
1:a991b64:     /**
1:a991b64:      * Whether the provided ring position is covered by this {@code DataRange}.
1:a991b64:      *
1:a991b64:      * @return whether the provided ring position is covered by this {@code DataRange}.
1:a991b64:      */
1:a991b64:     public boolean contains(PartitionPosition pos)
1:e48ff29:     {
1:e48ff29:         return keyRange.contains(pos);
1:e48ff29:     }
1:4f0d7b4: 
1:a991b64:     /**
1:a991b64:      * Whether this {@code DataRange} queries everything (has no restriction neither on the
1:a991b64:      * partition queried, nor within the queried partition).
1:a991b64:      *
1:a991b64:      * @return Whether this {@code DataRange} queries everything.
1:a991b64:      */
1:a991b64:     public boolean isUnrestricted()
1:e48ff29:     {
1:a991b64:         return startKey().isMinimum() && stopKey().isMinimum() && clusteringIndexFilter.selectsAllPartition();
1:e48ff29:     }
1:e48ff29: 
1:a991b64:     /**
1:a991b64:      * The clustering index filter to use for the provided key.
1:a991b64:      * <p>
1:a991b64:      * This may or may not be the same filter for all keys (that is, paging range
1:a991b64:      * use a different filter for their start key).
1:a991b64:      *
1:a991b64:      * @param key the partition key for which we want the clustering index filter.
1:a991b64:      *
1:a991b64:      * @return the clustering filter to use for {@code key}.
1:a991b64:      */
1:a991b64:     public ClusteringIndexFilter clusteringIndexFilter(DecoratedKey key)
1:e48ff29:     {
1:a991b64:         return clusteringIndexFilter;
1:a991b64:     }
1:e48ff29: 
1:a991b64:     /**
1:a991b64:      * Returns a new {@code DataRange} for use when paging {@code this} range.
1:a991b64:      *
1:a991b64:      * @param range the range of partition keys to query.
1:a991b64:      * @param comparator the comparator for the table queried.
1:a991b64:      * @param lastReturned the clustering for the last result returned by the previous page, i.e. the result we want to start our new page
1:bd7d119:      * from. This last returned <b>must</b> correspond to left bound of {@code range} (in other words, {@code range.left} must be the
1:a991b64:      * partition key for that {@code lastReturned} result).
1:a991b64:      * @param inclusive whether or not we want to include the {@code lastReturned} in the newly returned page of results.
1:a991b64:      *
1:a991b64:      * @return a new {@code DataRange} suitable for paging {@code this} range given the {@code lastRetuned} result of the previous page.
1:e48ff29:      */
1:a991b64:     public DataRange forPaging(AbstractBounds<PartitionPosition> range, ClusteringComparator comparator, Clustering lastReturned, boolean inclusive)
1:e48ff29:     {
1:a991b64:         return new Paging(range, clusteringIndexFilter, comparator, lastReturned, inclusive);
1:a991b64:     }
1:e48ff29: 
1:a991b64:     /**
1:a991b64:      * Returns a new {@code DataRange} equivalent to {@code this} one but restricted to the provided sub-range.
1:a991b64:      *
1:a991b64:      * @param range the sub-range to use for the newly returned data range. Note that assumes that {@code range} is a proper
1:a991b64:      * sub-range of the initial range but doesn't validate it. You should make sure to only provided sub-ranges however or this
1:a991b64:      * might throw off the paging case (see Paging.forSubRange()).
1:a991b64:      *
1:a991b64:      * @return a new {@code DataRange} using {@code range} as partition key range and the clustering index filter filter from {@code this}.
1:a991b64:      */
1:a991b64:     public DataRange forSubRange(AbstractBounds<PartitionPosition> range)
1:a991b64:     {
1:a991b64:         return new DataRange(range, clusteringIndexFilter);
1:a991b64:     }
1:e48ff29: 
1:a991b64:     public String toString(CFMetaData metadata)
1:a991b64:     {
1:a991b64:         return String.format("range=%s pfilter=%s", keyRange.getString(metadata.getKeyValidator()), clusteringIndexFilter.toString(metadata));
1:a991b64:     }
1:e48ff29: 
1:a991b64:     public String toCQLString(CFMetaData metadata)
1:a991b64:     {
1:a991b64:         if (isUnrestricted())
1:a991b64:             return "UNRESTRICTED";
1:e48ff29: 
1:a991b64:         StringBuilder sb = new StringBuilder();
1:e48ff29: 
1:a991b64:         boolean needAnd = false;
1:a991b64:         if (!startKey().isMinimum())
1:a991b64:         {
1:a991b64:             appendClause(startKey(), sb, metadata, true, keyRange.isStartInclusive());
1:a991b64:             needAnd = true;
1:a991b64:         }
1:a991b64:         if (!stopKey().isMinimum())
1:a991b64:         {
1:a991b64:             if (needAnd)
1:a991b64:                 sb.append(" AND ");
1:a991b64:             appendClause(stopKey(), sb, metadata, false, keyRange.isEndInclusive());
1:a991b64:             needAnd = true;
1:a991b64:         }
1:e48ff29: 
1:a991b64:         String filterString = clusteringIndexFilter.toCQLString(metadata);
1:a991b64:         if (!filterString.isEmpty())
1:a991b64:             sb.append(needAnd ? " AND " : "").append(filterString);
1:a991b64: 
1:a991b64:         return sb.toString();
1:a991b64:     }
1:a991b64: 
1:a991b64:     private void appendClause(PartitionPosition pos, StringBuilder sb, CFMetaData metadata, boolean isStart, boolean isInclusive)
1:a991b64:     {
1:a991b64:         sb.append("token(");
1:a991b64:         sb.append(ColumnDefinition.toCQLString(metadata.partitionKeyColumns()));
1:a991b64:         sb.append(") ").append(getOperator(isStart, isInclusive)).append(" ");
1:a991b64:         if (pos instanceof DecoratedKey)
1:a991b64:         {
1:a991b64:             sb.append("token(");
1:a991b64:             appendKeyString(sb, metadata.getKeyValidator(), ((DecoratedKey)pos).getKey());
1:a991b64:             sb.append(")");
1:a991b64:         }
1:d075540:         else
1:d075540:         {
1:a991b64:             sb.append(((Token.KeyBound)pos).getToken());
1:d075540:         }
1:d075540:     }
1:d075540: 
1:a991b64:     private static String getOperator(boolean isStart, boolean isInclusive)
1:d075540:     {
1:a991b64:         return isStart
1:a991b64:              ? (isInclusive ? ">=" : ">")
1:a991b64:              : (isInclusive ? "<=" : "<");
1:a991b64:     }
1:d075540: 
1:a991b64:     // TODO: this is reused in SinglePartitionReadCommand but this should not really be here. Ideally
1:a991b64:     // we need a more "native" handling of composite partition keys.
1:a991b64:     public static void appendKeyString(StringBuilder sb, AbstractType<?> type, ByteBuffer key)
1:a991b64:     {
1:a991b64:         if (type instanceof CompositeType)
1:a991b64:         {
1:a991b64:             CompositeType ct = (CompositeType)type;
1:a991b64:             ByteBuffer[] values = ct.split(key);
1:a991b64:             for (int i = 0; i < ct.types.size(); i++)
1:a991b64:                 sb.append(i == 0 ? "" : ", ").append(ct.types.get(i).getString(values[i]));
1:a991b64:         }
1:a991b64:         else
1:a991b64:         {
1:a991b64:             sb.append(type.getString(key));
1:a991b64:         }
1:a991b64:     }
1:a991b64: 
1:a991b64:     /**
1:a991b64:      * Specialized {@code DataRange} used for the paging case.
1:a991b64:      * <p>
1:a991b64:      * It uses the clustering of the last result of the previous page to restrict the filter on the
1:a991b64:      * first queried partition (the one for that last result) so it only fetch results that follow that
1:a991b64:      * last result. In other words, this makes sure this resume paging where we left off.
1:a991b64:      */
1:8c64cef:     public static class Paging extends DataRange
1:a991b64:     {
1:a991b64:         private final ClusteringComparator comparator;
1:a991b64:         private final Clustering lastReturned;
1:a991b64:         private final boolean inclusive;
1:2acbab6: 
1:a991b64:         private Paging(AbstractBounds<PartitionPosition> range,
1:a991b64:                        ClusteringIndexFilter filter,
1:a991b64:                        ClusteringComparator comparator,
1:a991b64:                        Clustering lastReturned,
1:a991b64:                        boolean inclusive)
1:a991b64:         {
1:e48ff29:             super(range, filter);
1:a991b64: 
1:4f0d7b4:             // When using a paging range, we don't allow wrapped ranges, as it's unclear how to handle them properly.
1:a991b64:             // This is ok for now since we only need this in range queries, and the range are "unwrapped" in that case.
1:69542a9:             assert !(range instanceof Range) || !((Range<?>)range).isWrapAround() || range.right.isMinimum() : range;
1:a991b64:             assert lastReturned != null;
1:a991b64: 
1:e48ff29:             this.comparator = comparator;
1:a991b64:             this.lastReturned = lastReturned;
1:a991b64:             this.inclusive = inclusive;
1:e48ff29:         }
1:4f0d7b4: 
1:d075540:         @Override
1:a991b64:         public ClusteringIndexFilter clusteringIndexFilter(DecoratedKey key)
1:d075540:         {
1:a991b64:             return key.equals(startKey())
1:a991b64:                  ? clusteringIndexFilter.forPaging(comparator, lastReturned, inclusive)
1:a991b64:                  : clusteringIndexFilter;
1:d075540:         }
1:e48ff29: 
1:bd7d119:         @Override
1:a991b64:         public DataRange forSubRange(AbstractBounds<PartitionPosition> range)
1:bd7d119:         {
1:a991b64:             // This is called for subrange of the initial range. So either it's the beginning of the initial range,
1:a991b64:             // and we need to preserver lastReturned, or it's not, and we don't care about it anymore.
1:a991b64:             return range.left.equals(keyRange().left)
1:a991b64:                  ? new Paging(range, clusteringIndexFilter, comparator, lastReturned, inclusive)
1:a991b64:                  : new DataRange(range, clusteringIndexFilter);
1:a991b64:         }
1:a991b64: 
1:8c64cef:         /**
1:8c64cef:          * @return the last Clustering that was returned (in the previous page)
1:8c64cef:          */
1:8c64cef:         public Clustering getLastReturned()
1:8c64cef:         {
1:8c64cef:             return lastReturned;
1:8c64cef:         }
1:8c64cef: 
1:8c64cef:         @Override
1:8c64cef:         public boolean isPaging()
1:8c64cef:         {
1:8c64cef:             return true;
1:8c64cef:         }
1:8c64cef: 
1:a991b64:         @Override
1:a991b64:         public boolean isUnrestricted()
1:a991b64:         {
1:dd62f7b:             return false;
1:a991b64:         }
1:a991b64: 
3:e48ff29:         @Override
1:bd7d119:         public String toString(CFMetaData metadata)
1:e48ff29:         {
1:8c64cef:             return String.format("range=%s (paging) pfilter=%s lastReturned=%s (%s)",
1:bd7d119:                                  keyRange.getString(metadata.getKeyValidator()),
1:bd7d119:                                  clusteringIndexFilter.toString(metadata),
1:bd7d119:                                  lastReturned.toString(metadata),
1:bd7d119:                                  inclusive ? "included" : "excluded");
1:bd7d119:         }
1:a991b64:     }
1:e48ff29: 
1:a991b64:     public static class Serializer
1:a991b64:     {
1:a991b64:         public void serialize(DataRange range, DataOutputPlus out, int version, CFMetaData metadata) throws IOException
1:a991b64:         {
1:a991b64:             AbstractBounds.rowPositionSerializer.serialize(range.keyRange, out, version);
1:a991b64:             ClusteringIndexFilter.serializer.serialize(range.clusteringIndexFilter, out, version);
1:a991b64:             boolean isPaging = range instanceof Paging;
1:a991b64:             out.writeBoolean(isPaging);
1:a991b64:             if (isPaging)
1:e48ff29:             {
1:a991b64:                 Clustering.serializer.serialize(((Paging)range).lastReturned, out, version, metadata.comparator.subtypes());
1:a991b64:                 out.writeBoolean(((Paging)range).inclusive);
1:a991b64:             }
1:a991b64:         }
1:a991b64: 
1:2457599:         public DataRange deserialize(DataInputPlus in, int version, CFMetaData metadata) throws IOException
1:a991b64:         {
1:0a08525:             AbstractBounds<PartitionPosition> range = AbstractBounds.rowPositionSerializer.deserialize(in, metadata.partitioner, version);
1:a991b64:             ClusteringIndexFilter filter = ClusteringIndexFilter.serializer.deserialize(in, version, metadata);
1:a991b64:             if (in.readBoolean())
1:a991b64:             {
1:a991b64:                 ClusteringComparator comparator = metadata.comparator;
1:a991b64:                 Clustering lastReturned = Clustering.serializer.deserialize(in, version, comparator.subtypes());
1:a991b64:                 boolean inclusive = in.readBoolean();
1:a991b64:                 return new Paging(range, filter, comparator, lastReturned, inclusive);
1:e48ff29:             }
1:a991b64:             else
1:e48ff29:             {
1:a991b64:                 return new DataRange(range, filter);
1:e48ff29:             }
1:e48ff29:         }
1:e48ff29: 
1:a991b64:         public long serializedSize(DataRange range, int version, CFMetaData metadata)
1:e48ff29:         {
1:a991b64:             long size = AbstractBounds.rowPositionSerializer.serializedSize(range.keyRange, version)
1:a991b64:                       + ClusteringIndexFilter.serializer.serializedSize(range.clusteringIndexFilter, version)
1:a991b64:                       + 1; // isPaging boolean
1:e48ff29: 
1:a991b64:             if (range instanceof Paging)
1:e48ff29:             {
1:03f72ac:                 size += Clustering.serializer.serializedSize(((Paging)range).lastReturned, version, metadata.comparator.subtypes());
1:a991b64:                 size += 1; // inclusive boolean
1:e48ff29:             }
1:a991b64:             return size;
1:e48ff29:         }
1:e48ff29:     }
1:e48ff29: }
============================================================================
author:Tyler Hobbs
-------------------------------------------------------------------------------
commit:8c64cef
/////////////////////////////////////////////////////////////////////////
1:      * Whether the data range is for a paged request or not.
1:      *
1:      * @return true if for paging, false otherwise
1:      */
1:     public boolean isPaging()
1:     {
1:         return false;
1:     }
1: 
1:     /**
/////////////////////////////////////////////////////////////////////////
1:     public static class Paging extends DataRange
/////////////////////////////////////////////////////////////////////////
1:         /**
1:          * @return the last Clustering that was returned (in the previous page)
1:          */
1:         public Clustering getLastReturned()
1:         {
1:             return lastReturned;
1:         }
1: 
1:         @Override
1:         public boolean isPaging()
1:         {
1:             return true;
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:             return String.format("range=%s (paging) pfilter=%s lastReturned=%s (%s)",
commit:80ba11c
commit:a8dce22
commit:d075540
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Objects;
1: import org.apache.cassandra.config.CFMetaData;
0: import org.apache.cassandra.utils.ByteBufferUtil;
/////////////////////////////////////////////////////////////////////////
0:     protected final AbstractBounds<RowPosition> keyRange;
/////////////////////////////////////////////////////////////////////////
0:         private final CFMetaData cfm;
1: 
/////////////////////////////////////////////////////////////////////////
0:         // tracks the last key that we updated the filter for to avoid duplicating work
0:         private ByteBuffer lastKeyFilterWasUpdatedFor;
1: 
0:         private Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, ByteBuffer firstPartitionColumnStart,
0:                        ByteBuffer lastPartitionColumnFinish, CFMetaData cfm, Comparator<ByteBuffer> comparator)
/////////////////////////////////////////////////////////////////////////
0:             this.cfm = cfm;
0:             this.lastKeyFilterWasUpdatedFor = null;
0:         public Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, ByteBuffer columnStart, ByteBuffer columnFinish, CFMetaData cfm)
0:             this(range, filter, columnStart, columnFinish, cfm, filter.isReversed() ? cfm.comparator.reverseComparator : cfm.comparator);
/////////////////////////////////////////////////////////////////////////
0:                 return true;
/////////////////////////////////////////////////////////////////////////
0:             if (equals(startKey(), rowKey) || equals(stopKey(), rowKey))
1:             {
0:                 if (!rowKey.equals(lastKeyFilterWasUpdatedFor))
1:                 {
0:                     this.lastKeyFilterWasUpdatedFor = rowKey;
0:                     columnFilter = sliceFilter.withUpdatedSlices(slicesForKey(rowKey));
1:                 }
1:             }
1:             else
1:             {
0:                 columnFilter = sliceFilter;
1:             }
1: 
0:         /** Returns true if the slice includes static columns, false otherwise. */
0:         private boolean sliceIncludesStatics(ColumnSlice slice, boolean reversed, CFMetaData cfm)
1:         {
0:             return cfm.hasStaticColumns() &&
0:                     cfm.getStaticColumnNameBuilder().build().compareTo(reversed ? slice.finish : slice.start) >= 0;
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
0:             // in the common case, we'll have the same number of slices
0:             List<ColumnSlice> newSlices = new ArrayList<>(sliceFilter.slices.length);
0:             // Check our slices to see if any fall before the page start (in which case they can be removed) or
0:             // if they contain the page start (in which case they should start from the page start).  However, if the
0:             // slices would include static columns, we need to ensure they are also fetched, and so a separate
0:             // slice for the static columns may be required.
0:             // Note that if the query is reversed, we can't handle statics by simply adding a separate slice here, so
0:             // the reversed case is handled by SliceFromReadCommand instead. See CASSANDRA-8502 for more details.
1:                     {
0:                         if (!sliceFilter.reversed && sliceIncludesStatics(slice, false, cfm))
0:                             newSlices.add(new ColumnSlice(ByteBufferUtil.EMPTY_BYTE_BUFFER, cfm.getStaticColumnNameBuilder().buildAsEndOfRange()));
1: 
0:                         continue;
1:                     }
1:                     {
0:                         if (!sliceFilter.reversed && sliceIncludesStatics(slice, false, cfm) && !newStart.equals(ByteBufferUtil.EMPTY_BYTE_BUFFER))
0:                             newSlices.add(new ColumnSlice(ByteBufferUtil.EMPTY_BYTE_BUFFER, cfm.getStaticColumnNameBuilder().buildAsEndOfRange()));
0:                         slice = new ColumnSlice(newStart, slice.finish);
1:                     }
1: 
0:                     // once we see a slice that either includes the page start or is after it, we can stop checking
0:                     // against the page start (because the slices are ordered)
/////////////////////////////////////////////////////////////////////////
1: 
1:         @Override
0:         public String toString()
1:         {
0:             return Objects.toStringHelper(this)
0:                           .add("keyRange", keyRange)
0:                           .add("sliceFilter", sliceFilter)
0:                           .add("columnFilter", columnFilter)
0:                           .add("firstPartitionColumnStart", firstPartitionColumnStart == null ? "null" : ByteBufferUtil.bytesToHex(firstPartitionColumnStart))
0:                           .add("lastPartitionColumnFinish", lastPartitionColumnFinish == null ? "null" : ByteBufferUtil.bytesToHex(lastPartitionColumnFinish))
0:                           .toString();
1:         }
commit:7f62e29
commit:dd62f7b
/////////////////////////////////////////////////////////////////////////
1:     /**
0:      * Returns true if tombstoned partitions should not be included in results or count towards the limit.
0:      * See CASSANDRA-8490 for more details on why this is needed (and done this way).
0:      * */
0:     public boolean ignoredTombstonedPartitions()
1:     {
0:         if (!(columnFilter instanceof SliceQueryFilter))
1:             return false;
1: 
0:         return ((SliceQueryFilter) columnFilter).compositesToGroup == SliceQueryFilter.IGNORE_TOMBSTONED_PARTITIONS;
1:     }
1: 
commit:6fe6d65
commit:2acbab6
/////////////////////////////////////////////////////////////////////////
1:     /**
0:      * Returns a column filter that should be used for a particular row key.  Note that in the case of paging,
0:      * slice starts and ends may change depending on the row key.
1:      */
1:     /**
0:      * Sets a new limit on the number of (grouped) cells to fetch. This is currently only used when the query limit applies
0:      * to CQL3 rows.
1:      */
/////////////////////////////////////////////////////////////////////////
0:         // The slice of columns that we want to fetch for each row, ignoring page start/end issues.
0:         private final Comparator<ByteBuffer> comparator;
1: 
0:         // used to restrict the start of the slice for the first partition in the range
0:         private final ByteBuffer firstPartitionColumnStart;
1: 
0:         // used to restrict the end of the slice for the last partition in the range
0:         private final ByteBuffer lastPartitionColumnFinish;
1: 
0:         private Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, ByteBuffer firstPartitionColumnStart, ByteBuffer lastPartitionColumnFinish, Comparator<ByteBuffer> comparator)
/////////////////////////////////////////////////////////////////////////
0:             this.firstPartitionColumnStart = firstPartitionColumnStart;
0:             this.lastPartitionColumnFinish = lastPartitionColumnFinish;
/////////////////////////////////////////////////////////////////////////
0:             // Also note that firstPartitionColumnStart and lastPartitionColumnFinish, when used, only "restrict" the filter slices,
0:             ByteBuffer newStart = equals(startKey(), key) && firstPartitionColumnStart.hasRemaining() ? firstPartitionColumnStart : null;
0:             ByteBuffer newFinish = equals(stopKey(), key) && lastPartitionColumnFinish.hasRemaining() ? lastPartitionColumnFinish : null;
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:bd7d119
/////////////////////////////////////////////////////////////////////////
1:     protected final AbstractBounds<PartitionPosition> keyRange;
/////////////////////////////////////////////////////////////////////////
1:      * from. This last returned <b>must</b> correspond to left bound of {@code range} (in other words, {@code range.left} must be the
/////////////////////////////////////////////////////////////////////////
1: 
1:         @Override
1:         public String toString(CFMetaData metadata)
1:         {
0:             return String.format("range=%s pfilter=%s lastReturned=%s (%s)",
1:                                  keyRange.getString(metadata.getKeyValidator()),
1:                                  clusteringIndexFilter.toString(metadata),
1:                                  lastReturned.toString(metadata),
1:                                  inclusive ? "included" : "excluded");
1:         }
commit:2457599
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputPlus;
/////////////////////////////////////////////////////////////////////////
1:         public DataRange deserialize(DataInputPlus in, int version, CFMetaData metadata) throws IOException
commit:a991b64
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import java.io.DataInput;
1: import java.io.IOException;
1: import org.apache.cassandra.config.ColumnDefinition;
1: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.db.marshal.CompositeType;
1: import org.apache.cassandra.io.util.DataOutputPlus;
0: import org.apache.cassandra.net.MessagingService;
1:  * Groups both the range of partitions to query, and the clustering index filter to
1:  * apply for each partition (for a (partition) range query).
1:  * <p>
1:  * The main "trick" is that the clustering index filter can only be obtained by
1:  * providing the partition key on which the filter will be applied. This is
1:  * necessary when paging range queries, as we might need a different filter
1:  * for the starting key than for other keys (because the previous page we had
1:  * queried may have ended in the middle of a partition).
1:     public static final Serializer serializer = new Serializer();
0:     private final AbstractBounds<PartitionPosition> keyRange;
1:     protected final ClusteringIndexFilter clusteringIndexFilter;
1: 
1:     /**
1:      * Creates a {@code DataRange} given a range of partition keys and a clustering index filter. The
1:      * return {@code DataRange} will return the same filter for all keys.
1:      *
1:      * @param range the range over partition keys to use.
1:      * @param clusteringIndexFilter the clustering index filter to use.
1:      */
1:     public DataRange(AbstractBounds<PartitionPosition> range, ClusteringIndexFilter clusteringIndexFilter)
1:         this.clusteringIndexFilter = clusteringIndexFilter;
1:     /**
1:      * Creates a {@code DataRange} to query all data (over the whole ring).
1:      *
1:      * @param partitioner the partitioner in use for the table.
1:      *
1:      * @return the newly create {@code DataRange}.
1:      */
1:     /**
1:      * Creates a {@code DataRange} to query all rows over the provided token range.
1:      *
1:      * @param tokenRange the (partition key) token range to query.
1:      *
1:      * @return the newly create {@code DataRange}.
1:      */
1:     public static DataRange forTokenRange(Range<Token> tokenRange)
1:         return forKeyRange(Range.makeRowRange(tokenRange));
1:     /**
1:      * Creates a {@code DataRange} to query all rows over the provided key range.
1:      *
1:      * @param keyRange the (partition key) range to query.
1:      *
1:      * @return the newly create {@code DataRange}.
1:      */
1:     public static DataRange forKeyRange(Range<PartitionPosition> keyRange)
1:         return new DataRange(keyRange, new ClusteringIndexSliceFilter(Slices.ALL, false));
1:     /**
1:      * Creates a {@code DataRange} to query all partitions of the ring using the provided
1:      * clustering index filter.
1:      *
1:      * @param partitioner the partitioner in use for the table queried.
1:      * @param filter the clustering index filter to use.
1:      *
1:      * @return the newly create {@code DataRange}.
1:      */
1:     public static DataRange allData(IPartitioner partitioner, ClusteringIndexFilter filter)
1:     {
1:         return new DataRange(Range.makeRowRange(new Range<Token>(partitioner.getMinimumToken(), partitioner.getMinimumToken())), filter);
1:     }
1: 
1:     /**
1:      * The range of partition key queried by this {@code DataRange}.
1:      *
1:      * @return the range of partition key queried by this {@code DataRange}.
1:      */
1:     public AbstractBounds<PartitionPosition> keyRange()
1:     /**
1:      * The start of the partition key range queried by this {@code DataRange}.
1:      *
1:      * @return the start of the partition key range queried by this {@code DataRange}.
1:      */
1:     public PartitionPosition startKey()
1:     /**
1:      * The end of the partition key range queried by this {@code DataRange}.
1:      *
1:      * @return the end of the partition key range queried by this {@code DataRange}.
1:      */
1:     public PartitionPosition stopKey()
1:      * Whether the underlying clustering index filter is a names filter or not.
1:      *
1:      * @return Whether the underlying clustering index filter is a names filter or not.
1:      */
1:     public boolean isNamesQuery()
1:         return clusteringIndexFilter instanceof ClusteringIndexNamesFilter;
1:     /**
1:      * Whether the range queried by this {@code DataRange} actually wraps around.
1:      *
1:      * @return whether the range queried by this {@code DataRange} actually wraps around.
1:      */
1:         // Only range can ever wrap
1:     /**
1:      * Whether the provided ring position is covered by this {@code DataRange}.
1:      *
1:      * @return whether the provided ring position is covered by this {@code DataRange}.
1:      */
1:     public boolean contains(PartitionPosition pos)
1:     /**
1:      * Whether this {@code DataRange} queries everything (has no restriction neither on the
1:      * partition queried, nor within the queried partition).
1:      *
1:      * @return Whether this {@code DataRange} queries everything.
1:      */
1:     public boolean isUnrestricted()
1:         return startKey().isMinimum() && stopKey().isMinimum() && clusteringIndexFilter.selectsAllPartition();
1:      * The clustering index filter to use for the provided key.
1:      * <p>
1:      * This may or may not be the same filter for all keys (that is, paging range
1:      * use a different filter for their start key).
1:      *
1:      * @param key the partition key for which we want the clustering index filter.
1:      *
1:      * @return the clustering filter to use for {@code key}.
1:     public ClusteringIndexFilter clusteringIndexFilter(DecoratedKey key)
1:         return clusteringIndexFilter;
1:      * Returns a new {@code DataRange} for use when paging {@code this} range.
1:      *
1:      * @param range the range of partition keys to query.
1:      * @param comparator the comparator for the table queried.
1:      * @param lastReturned the clustering for the last result returned by the previous page, i.e. the result we want to start our new page
0:      * from. This last returned must <b>must</b> correspond to left bound of {@code range} (in other words, {@code range.left} must be the
1:      * partition key for that {@code lastReturned} result).
1:      * @param inclusive whether or not we want to include the {@code lastReturned} in the newly returned page of results.
1:      *
1:      * @return a new {@code DataRange} suitable for paging {@code this} range given the {@code lastRetuned} result of the previous page.
1:     public DataRange forPaging(AbstractBounds<PartitionPosition> range, ClusteringComparator comparator, Clustering lastReturned, boolean inclusive)
1:         return new Paging(range, clusteringIndexFilter, comparator, lastReturned, inclusive);
1:     /**
1:      * Returns a new {@code DataRange} equivalent to {@code this} one but restricted to the provided sub-range.
1:      *
1:      * @param range the sub-range to use for the newly returned data range. Note that assumes that {@code range} is a proper
1:      * sub-range of the initial range but doesn't validate it. You should make sure to only provided sub-ranges however or this
1:      * might throw off the paging case (see Paging.forSubRange()).
1:      *
1:      * @return a new {@code DataRange} using {@code range} as partition key range and the clustering index filter filter from {@code this}.
1:      */
1:     public DataRange forSubRange(AbstractBounds<PartitionPosition> range)
1:         return new DataRange(range, clusteringIndexFilter);
1:     }
1:     public String toString(CFMetaData metadata)
1:     {
1:         return String.format("range=%s pfilter=%s", keyRange.getString(metadata.getKeyValidator()), clusteringIndexFilter.toString(metadata));
1:     }
1:     public String toCQLString(CFMetaData metadata)
1:     {
1:         if (isUnrestricted())
1:             return "UNRESTRICTED";
1:         StringBuilder sb = new StringBuilder();
1:         boolean needAnd = false;
1:         if (!startKey().isMinimum())
1:         {
1:             appendClause(startKey(), sb, metadata, true, keyRange.isStartInclusive());
1:             needAnd = true;
1:         }
1:         if (!stopKey().isMinimum())
1:         {
1:             if (needAnd)
1:                 sb.append(" AND ");
1:             appendClause(stopKey(), sb, metadata, false, keyRange.isEndInclusive());
1:             needAnd = true;
1:         }
1:         String filterString = clusteringIndexFilter.toCQLString(metadata);
1:         if (!filterString.isEmpty())
1:             sb.append(needAnd ? " AND " : "").append(filterString);
1:         return sb.toString();
1:     }
1: 
1:     private void appendClause(PartitionPosition pos, StringBuilder sb, CFMetaData metadata, boolean isStart, boolean isInclusive)
1:     {
1:         sb.append("token(");
1:         sb.append(ColumnDefinition.toCQLString(metadata.partitionKeyColumns()));
1:         sb.append(") ").append(getOperator(isStart, isInclusive)).append(" ");
1:         if (pos instanceof DecoratedKey)
1:         {
1:             sb.append("token(");
1:             appendKeyString(sb, metadata.getKeyValidator(), ((DecoratedKey)pos).getKey());
1:             sb.append(")");
1:         }
1:         else
1:         {
1:             sb.append(((Token.KeyBound)pos).getToken());
1:         }
1:     }
1: 
1:     private static String getOperator(boolean isStart, boolean isInclusive)
1:     {
1:         return isStart
1:              ? (isInclusive ? ">=" : ">")
1:              : (isInclusive ? "<=" : "<");
1:     }
1: 
1:     // TODO: this is reused in SinglePartitionReadCommand but this should not really be here. Ideally
1:     // we need a more "native" handling of composite partition keys.
1:     public static void appendKeyString(StringBuilder sb, AbstractType<?> type, ByteBuffer key)
1:     {
1:         if (type instanceof CompositeType)
1:         {
1:             CompositeType ct = (CompositeType)type;
1:             ByteBuffer[] values = ct.split(key);
1:             for (int i = 0; i < ct.types.size(); i++)
1:                 sb.append(i == 0 ? "" : ", ").append(ct.types.get(i).getString(values[i]));
1:         }
1:         else
1:         {
1:             sb.append(type.getString(key));
1:         }
1:     }
1: 
1:     /**
1:      * Specialized {@code DataRange} used for the paging case.
1:      * <p>
1:      * It uses the clustering of the last result of the previous page to restrict the filter on the
1:      * first queried partition (the one for that last result) so it only fetch results that follow that
1:      * last result. In other words, this makes sure this resume paging where we left off.
1:      */
0:     private static class Paging extends DataRange
1:     {
1:         private final ClusteringComparator comparator;
1:         private final Clustering lastReturned;
1:         private final boolean inclusive;
1: 
1:         private Paging(AbstractBounds<PartitionPosition> range,
1:                        ClusteringIndexFilter filter,
1:                        ClusteringComparator comparator,
1:                        Clustering lastReturned,
1:                        boolean inclusive)
1:             // This is ok for now since we only need this in range queries, and the range are "unwrapped" in that case.
1:             assert lastReturned != null;
1:             this.lastReturned = lastReturned;
1:             this.inclusive = inclusive;
1:         public ClusteringIndexFilter clusteringIndexFilter(DecoratedKey key)
1:             return key.equals(startKey())
1:                  ? clusteringIndexFilter.forPaging(comparator, lastReturned, inclusive)
1:                  : clusteringIndexFilter;
1:         public DataRange forSubRange(AbstractBounds<PartitionPosition> range)
1:             // This is called for subrange of the initial range. So either it's the beginning of the initial range,
1:             // and we need to preserver lastReturned, or it's not, and we don't care about it anymore.
1:             return range.left.equals(keyRange().left)
1:                  ? new Paging(range, clusteringIndexFilter, comparator, lastReturned, inclusive)
1:                  : new DataRange(range, clusteringIndexFilter);
1:         }
1: 
1:         @Override
1:         public boolean isUnrestricted()
1:         {
0:             return false;
1:         }
1:     }
1: 
1:     public static class Serializer
1:     {
1:         public void serialize(DataRange range, DataOutputPlus out, int version, CFMetaData metadata) throws IOException
1:         {
1:             AbstractBounds.rowPositionSerializer.serialize(range.keyRange, out, version);
1:             ClusteringIndexFilter.serializer.serialize(range.clusteringIndexFilter, out, version);
1:             boolean isPaging = range instanceof Paging;
1:             out.writeBoolean(isPaging);
1:             if (isPaging)
1:                 Clustering.serializer.serialize(((Paging)range).lastReturned, out, version, metadata.comparator.subtypes());
1:                 out.writeBoolean(((Paging)range).inclusive);
1:             }
1:         }
1: 
0:         public DataRange deserialize(DataInput in, int version, CFMetaData metadata) throws IOException
1:         {
0:             AbstractBounds<PartitionPosition> range = AbstractBounds.rowPositionSerializer.deserialize(in, MessagingService.globalPartitioner(), version);
1:             ClusteringIndexFilter filter = ClusteringIndexFilter.serializer.deserialize(in, version, metadata);
1:             if (in.readBoolean())
1:             {
1:                 ClusteringComparator comparator = metadata.comparator;
1:                 Clustering lastReturned = Clustering.serializer.deserialize(in, version, comparator.subtypes());
1:                 boolean inclusive = in.readBoolean();
1:                 return new Paging(range, filter, comparator, lastReturned, inclusive);
1:                 return new DataRange(range, filter);
1:         public long serializedSize(DataRange range, int version, CFMetaData metadata)
1:             long size = AbstractBounds.rowPositionSerializer.serializedSize(range.keyRange, version)
1:                       + ClusteringIndexFilter.serializer.serializedSize(range.clusteringIndexFilter, version)
1:                       + 1; // isPaging boolean
1:             if (range instanceof Paging)
0:                 size += Clustering.serializer.serializedSize(((Paging)range).lastReturned, version, metadata.comparator.subtypes(), TypeSizes.NATIVE);
1:                 size += 1; // inclusive boolean
1:             return size;
commit:8f17bbd
/////////////////////////////////////////////////////////////////////////
0:             // it doesn't expand on them. As such, we can ignore the case where they are empty and we do
0:             // as it screw up with the logic below (see #6592)
0:             Composite newStart = equals(startKey(), key) && !columnStart.isEmpty() ? columnStart : null;
0:             Composite newFinish = equals(stopKey(), key) && !columnFinish.isEmpty() ? columnFinish : null;
commit:0be4246
/////////////////////////////////////////////////////////////////////////
0:             // Also note that columnStart and columnFinish, when used, only "restrict" the filter slices,
0:             // it doesn't expand on them. As such, we can ignore the case where they are empty and we do
0:             // as it screw up with the logic below (see #6592)
0:             ByteBuffer newStart = equals(startKey(), key) && columnStart.hasRemaining() ? columnStart : null;
0:             ByteBuffer newFinish = equals(stopKey(), key) && columnFinish.hasRemaining() ? columnFinish : null;
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.composites.CellNameType;
0: import org.apache.cassandra.db.composites.Composite;
/////////////////////////////////////////////////////////////////////////
0:             && filter.start().isEmpty()
0:             && filter.finish().isEmpty()
/////////////////////////////////////////////////////////////////////////
0:         private final Comparator<Composite> comparator;
0:         private final Composite columnStart;
0:         private final Composite columnFinish;
0:         private Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, Composite columnStart, Composite columnFinish, Comparator<Composite> comparator)
/////////////////////////////////////////////////////////////////////////
0:         public Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, Composite columnStart, Composite columnFinish, CellNameType comparator)
0:             this(range, filter, columnStart, columnFinish, filter.isReversed() ? comparator.reverseComparator() : comparator);
/////////////////////////////////////////////////////////////////////////
0:             Composite newStart = equals(startKey(), key) ? columnStart : null;
0:             Composite newFinish = equals(stopKey(), key) ? columnFinish : null;
commit:4f0d7b4
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     // Whether the bounds of this DataRange actually wraps around.
1:     public boolean isWrapAround()
1:     {
0:         // On range can ever wrap
0:         return keyRange instanceof Range && ((Range)keyRange).isWrapAround();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:             // When using a paging range, we don't allow wrapped ranges, as it's unclear how to handle them properly.
0:             // This is ok for now since we only need this in range slice queries, and the range are "unwrapped" in that case.
0:             assert !(range instanceof Range) || !((Range)range).isWrapAround() || range.right.isMinimum() : range;
1: 
commit:e48ff29
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.db;
1: 
1: import java.nio.ByteBuffer;
0: import java.util.ArrayList;
0: import java.util.Comparator;
0: import java.util.List;
1: 
0: import org.apache.cassandra.db.columniterator.IdentityQueryFilter;
1: import org.apache.cassandra.db.filter.*;
0: import org.apache.cassandra.db.marshal.AbstractType;
1: import org.apache.cassandra.dht.*;
1: 
1: /**
0:  * Groups key range and column filter for range queries.
1:  *
0:  * The main "trick" of this class is that the column filter can only
0:  * be obtained by providing the row key on which the column filter will
0:  * be applied (which we always know before actually querying the columns).
1:  *
0:  * This allows the paging DataRange to return a filter for most rows but a
0:  * potentially different ones for the starting and stopping key. Could
0:  * allow more fancy stuff in the future too, like column filters that
0:  * depend on the actual key value :)
1:  */
1: public class DataRange
1: {
0:     private final AbstractBounds<RowPosition> keyRange;
0:     protected IDiskAtomFilter columnFilter;
0:     protected final boolean selectFullRow;
1: 
0:     public DataRange(AbstractBounds<RowPosition> range, IDiskAtomFilter columnFilter)
1:     {
0:         assert !(range instanceof Range) || !((Range)range).isWrapAround() || range.right.isMinimum() : range;
1: 
1:         this.keyRange = range;
0:         this.columnFilter = columnFilter;
0:         this.selectFullRow = columnFilter instanceof SliceQueryFilter
0:                            ? isFullRowSlice((SliceQueryFilter)columnFilter)
0:                            : false;
1:     }
1: 
0:     public static boolean isFullRowSlice(SliceQueryFilter filter)
1:     {
0:         return filter.slices.length == 1
0:             && filter.start().remaining() == 0
0:             && filter.finish().remaining() == 0
0:             && filter.count == Integer.MAX_VALUE;
1:     }
1: 
1:     public static DataRange allData(IPartitioner partitioner)
1:     {
0:         return forKeyRange(new Range<Token>(partitioner.getMinimumToken(), partitioner.getMinimumToken()));
1:     }
1: 
0:     public static DataRange forKeyRange(Range<Token> keyRange)
1:     {
0:         return new DataRange(keyRange.toRowBounds(), new IdentityQueryFilter());
1:     }
1: 
0:     public AbstractBounds<RowPosition> keyRange()
1:     {
1:         return keyRange;
1:     }
1: 
0:     public RowPosition startKey()
1:     {
1:         return keyRange.left;
1:     }
1: 
0:     public RowPosition stopKey()
1:     {
1:         return keyRange.right;
1:     }
1: 
0:     public boolean contains(RowPosition pos)
1:     {
1:         return keyRange.contains(pos);
1:     }
1: 
0:     public int getLiveCount(ColumnFamily data, long now)
1:     {
0:         return columnFilter instanceof SliceQueryFilter
0:              ? ((SliceQueryFilter)columnFilter).lastCounted()
0:              : columnFilter.getLiveCount(data, now);
1:     }
1: 
0:     public boolean selectsFullRowFor(ByteBuffer rowKey)
1:     {
0:         return selectFullRow;
1:     }
1: 
0:     public IDiskAtomFilter columnFilter(ByteBuffer rowKey)
1:     {
0:         return columnFilter;
1:     }
1: 
0:     public void updateColumnsLimit(int count)
1:     {
0:         columnFilter.updateColumnsLimit(count);
1:     }
1: 
0:     public static class Paging extends DataRange
1:     {
0:         private final SliceQueryFilter sliceFilter;
0:         private final Comparator<ByteBuffer> comparator;
0:         private final ByteBuffer columnStart;
0:         private final ByteBuffer columnFinish;
1: 
0:         private Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, ByteBuffer columnStart, ByteBuffer columnFinish, Comparator<ByteBuffer> comparator)
1:         {
1:             super(range, filter);
1: 
0:             this.sliceFilter = filter;
1:             this.comparator = comparator;
0:             this.columnStart = columnStart;
0:             this.columnFinish = columnFinish;
1:         }
1: 
0:         public Paging(AbstractBounds<RowPosition> range, SliceQueryFilter filter, ByteBuffer columnStart, ByteBuffer columnFinish, AbstractType<?> comparator)
1:         {
0:             this(range, filter, columnStart, columnFinish, filter.isReversed() ? comparator.reverseComparator : comparator);
1:         }
1: 
1:         @Override
0:         public boolean selectsFullRowFor(ByteBuffer rowKey)
1:         {
0:             // If we initial filter is not the full filter, don't bother
0:             if (!selectFullRow)
0:                 return false;
1: 
0:             if (!equals(startKey(), rowKey) && !equals(stopKey(), rowKey))
0:                 return selectFullRow;
1: 
0:             return isFullRowSlice((SliceQueryFilter)columnFilter(rowKey));
1:         }
1: 
0:         private boolean equals(RowPosition pos, ByteBuffer rowKey)
1:         {
0:             return pos instanceof DecoratedKey && ((DecoratedKey)pos).key.equals(rowKey);
1:         }
1: 
1:         @Override
0:         public IDiskAtomFilter columnFilter(ByteBuffer rowKey)
1:         {
1:             /*
0:              * We have that ugly hack that for slice queries, when we ask for
0:              * the live count, we reach into the query filter to get the last
0:              * counter number of columns to avoid recounting.
0:              * Maybe we should just remove that hack, but in the meantime, we
0:              * need to keep a reference the last returned filter.
1:              */
0:             columnFilter = equals(startKey(), rowKey) || equals(stopKey(), rowKey)
0:                          ? sliceFilter.withUpdatedSlices(slicesForKey(rowKey))
0:                          : sliceFilter;
0:             return columnFilter;
1:         }
1: 
0:         private ColumnSlice[] slicesForKey(ByteBuffer key)
1:         {
0:             // We don't call that until it's necessary, so assume we have to do some hard work
0:             ByteBuffer newStart = equals(startKey(), key) ? columnStart : null;
0:             ByteBuffer newFinish = equals(stopKey(), key) ? columnFinish : null;
1: 
0:             List<ColumnSlice> newSlices = new ArrayList<ColumnSlice>(sliceFilter.slices.length); // in the common case, we'll have the same number of slices
1: 
0:             for (ColumnSlice slice : sliceFilter.slices)
1:             {
0:                 if (newStart != null)
1:                 {
0:                     if (slice.isBefore(comparator, newStart))
0:                         continue; // we skip that slice
1: 
0:                     if (slice.includes(comparator, newStart))
0:                         slice = new ColumnSlice(newStart, slice.finish);
1: 
0:                     // Whether we've updated the slice or not, we don't have to bother about newStart anymore
0:                     newStart = null;
1:                 }
1: 
0:                 assert newStart == null;
0:                 if (newFinish != null && !slice.isBefore(comparator, newFinish))
1:                 {
0:                     if (slice.includes(comparator, newFinish))
0:                         newSlices.add(new ColumnSlice(slice.start, newFinish));
0:                     // In any case, we're done
0:                     break;
1:                 }
0:                 newSlices.add(slice);
1:             }
1: 
0:             return newSlices.toArray(new ColumnSlice[newSlices.size()]);
1:         }
1: 
1:         @Override
0:         public void updateColumnsLimit(int count)
1:         {
0:             columnFilter.updateColumnsLimit(count);
0:             sliceFilter.updateColumnsLimit(count);
1:         }
1:     }
1: }
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:0a08525
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             AbstractBounds<PartitionPosition> range = AbstractBounds.rowPositionSerializer.deserialize(in, metadata.partitioner, version);
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:a22ce89
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.net.MessagingService;
/////////////////////////////////////////////////////////////////////////
0:             AbstractBounds<PartitionPosition> range = AbstractBounds.rowPositionSerializer.deserialize(in, MessagingService.globalPartitioner(), version);
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:69f77cb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             AbstractBounds<PartitionPosition> range = AbstractBounds.rowPositionSerializer.deserialize(in, metadata.partitioner, version);
commit:69542a9
/////////////////////////////////////////////////////////////////////////
1:         return forTokenRange(new Range<Token>(partitioner.getMinimumToken(), partitioner.getMinimumToken()));
0:     public static DataRange forTokenRange(Range<Token> keyRange)
0:         return forKeyRange(Range.makeRowRange(keyRange));
0:     }
0: 
0:     public static DataRange forKeyRange(Range<RowPosition> keyRange)
0:     {
0:         return new DataRange(keyRange, new IdentityQueryFilter());
/////////////////////////////////////////////////////////////////////////
1:         return keyRange instanceof Range && ((Range<?>)keyRange).isWrapAround();
/////////////////////////////////////////////////////////////////////////
1:             assert !(range instanceof Range) || !((Range<?>)range).isWrapAround() || range.right.isMinimum() : range;
author:Ariel Weisberg
-------------------------------------------------------------------------------
commit:03f72ac
/////////////////////////////////////////////////////////////////////////
1:                 size += Clustering.serializer.serializedSize(((Paging)range).lastReturned, version, metadata.comparator.subtypes());
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:8541cca
/////////////////////////////////////////////////////////////////////////
0:             return pos instanceof DecoratedKey && ((DecoratedKey)pos).getKey().equals(rowKey);
============================================================================
1:ab8a28e: /*
1:ab8a28e:  * Licensed to the Apache Software Foundation (ASF) under one
1:ab8a28e:  * or more contributor license agreements.  See the NOTICE file
1:ab8a28e:  * distributed with this work for additional information
1:ab8a28e:  * regarding copyright ownership.  The ASF licenses this file
1:ab8a28e:  * to you under the Apache License, Version 2.0 (the
1:ab8a28e:  * "License"); you may not use this file except in compliance
1:ab8a28e:  * with the License.  You may obtain a copy of the License at
1:ab8a28e:  *
1:ab8a28e:  *     http://www.apache.org/licenses/LICENSE-2.0
1:ab8a28e:  *
1:ab8a28e:  * Unless required by applicable law or agreed to in writing, software
1:ab8a28e:  * distributed under the License is distributed on an "AS IS" BASIS,
1:ab8a28e:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:ab8a28e:  * See the License for the specific language governing permissions and
1:ab8a28e:  * limitations under the License.
1:ab8a28e:  */
1:ab8a28e: package org.apache.cassandra.io.sstable;
1:a991b64: 
1:ab8a28e: import java.io.File;
1:8afc76a: import java.util.Collections;
1:ab8a28e: import java.util.List;
1:8afc76a: import java.util.concurrent.CountDownLatch;
1:a991b64: 
1:ab8a28e: import com.google.common.io.Files;
1:8afc76a: 
1:b09e60f: import org.junit.After;
1:b09e60f: import org.junit.Before;
1:ab8a28e: import org.junit.BeforeClass;
1:ab8a28e: import org.junit.Test;
5:ab8a28e: 
1:ab8a28e: import org.apache.cassandra.SchemaLoader;
1:ab8a28e: import org.apache.cassandra.Util;
1:ab8a28e: import org.apache.cassandra.config.CFMetaData;
1:ab8a28e: import org.apache.cassandra.config.Schema;
1:2457599: import org.apache.cassandra.db.*;
1:a991b64: import org.apache.cassandra.db.partitions.*;
1:a991b64: import org.apache.cassandra.db.marshal.AsciiType;
1:ab8a28e: import org.apache.cassandra.dht.Range;
1:ab8a28e: import org.apache.cassandra.dht.Token;
1:66b0e1d: import org.apache.cassandra.io.FSWriteError;
1:b09e60f: import org.apache.cassandra.io.util.FileUtils;
1:31e3f61: import org.apache.cassandra.schema.KeyspaceParams;
1:ab8a28e: import org.apache.cassandra.service.StorageService;
1:8afc76a: import org.apache.cassandra.streaming.StreamEvent;
1:8afc76a: import org.apache.cassandra.streaming.StreamEventHandler;
1:8afc76a: import org.apache.cassandra.streaming.StreamState;
1:ab8a28e: import org.apache.cassandra.utils.ByteBufferUtil;
1:ab8a28e: import org.apache.cassandra.utils.FBUtilities;
1:ab8a28e: import org.apache.cassandra.utils.OutputHandler;
1:ab8a28e: 
1:83a43f1: import static org.junit.Assert.assertEquals;
1:b09e60f: import static org.junit.Assert.assertTrue;
1:ab8a28e: 
1:d2a3827: public class SSTableLoaderTest
4:ab8a28e: {
1:d2a3827:     public static final String KEYSPACE1 = "SSTableLoaderTest";
1:b09e60f:     public static final String CF_STANDARD1 = "Standard1";
1:b09e60f:     public static final String CF_STANDARD2 = "Standard2";
1:b09e60f: 
1:b09e60f:     private File tmpdir;
1:ab8a28e: 
1:ab8a28e:     @BeforeClass
1:d2a3827:     public static void defineSchema() throws Exception
1:ab8a28e:     {
1:d2a3827:         SchemaLoader.prepareServer();
1:d2a3827:         SchemaLoader.createKeyspace(KEYSPACE1,
1:31e3f61:                                     KeyspaceParams.simple(1),
1:b09e60f:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD1),
1:b09e60f:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD2));
1:b09e60f: 
1:b09e60f:         StorageService.instance.initServer();
2:ab8a28e:     }
1:ab8a28e: 
1:b09e60f:     @Before
1:b09e60f:     public void setup() throws Exception
1:ab8a28e:     {
1:b09e60f:         tmpdir = Files.createTempDir();
1:b09e60f:     }
1:b09e60f: 
1:b09e60f:     @After
1:b09e60f:     public void cleanup()
1:b09e60f:     {
1:66b0e1d:         try {
1:b09e60f:             FileUtils.deleteRecursive(tmpdir);
1:66b0e1d:         } catch (FSWriteError e) {
1:66b0e1d:             /**
1:66b0e1d:              * Windows does not allow a mapped file to be deleted, so we probably forgot to clean the buffers somewhere.
1:66b0e1d:              * We force a GC here to force buffer deallocation, and then try deleting the directory again.
1:66b0e1d:              * For more information, see: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=4715154
1:66b0e1d:              * If this is not the problem, the exception will be rethrown anyway.
1:66b0e1d:              */
1:66b0e1d:             System.gc();
2:66b0e1d:             FileUtils.deleteRecursive(tmpdir);
1:b09e60f:         }
1:66b0e1d:     }
1:b09e60f: 
1:b09e60f:     private static final class TestClient extends SSTableLoader.Client
1:b09e60f:     {
1:b09e60f:         private String keyspace;
1:b09e60f: 
1:b09e60f:         public void init(String keyspace)
1:b09e60f:         {
1:b09e60f:             this.keyspace = keyspace;
1:b09e60f:             for (Range<Token> range : StorageService.instance.getLocalRanges(KEYSPACE1))
1:b09e60f:                 addRangeForEndpoint(range, FBUtilities.getBroadcastAddress());
1:b09e60f:         }
1:b09e60f: 
1:b09e60f:         public CFMetaData getTableMetadata(String tableName)
1:b09e60f:         {
1:b09e60f:             return Schema.instance.getCFMetaData(keyspace, tableName);
1:b09e60f:         }
1:ab8a28e:     }
1:ab8a28e: 
1:ab8a28e:     @Test
1:ab8a28e:     public void testLoadingSSTable() throws Exception
1:ab8a28e:     {
1:b09e60f:         File dataDir = new File(tmpdir.getAbsolutePath() + File.separator + KEYSPACE1 + File.separator + CF_STANDARD1);
1:ab8a28e:         assert dataDir.mkdirs();
1:b09e60f:         CFMetaData cfmeta = Schema.instance.getCFMetaData(KEYSPACE1, CF_STANDARD1);
1:b09e60f: 
1:b09e60f:         String schema = "CREATE TABLE %s.%s (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name))";
1:b09e60f:         String query = "INSERT INTO %s.%s (key, name, val) VALUES (?, ?, ?)";
1:47d3b7e: 
1:a991b64:         try (CQLSSTableWriter writer = CQLSSTableWriter.builder()
1:a991b64:                                                        .inDirectory(dataDir)
1:b09e60f:                                                        .forTable(String.format(schema, KEYSPACE1, CF_STANDARD1))
1:b09e60f:                                                        .using(String.format(query, KEYSPACE1, CF_STANDARD1))
1:a991b64:                                                        .build())
1:ab8a28e:         {
1:a991b64:             writer.addRow("key1", "col1", "100");
1:ab8a28e:         }
1:c163d0b: 
1:0026e4e:         ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD1);
1:0026e4e:         cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them
1:0026e4e: 
1:8afc76a:         final CountDownLatch latch = new CountDownLatch(1);
1:0026e4e:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
1:8afc76a:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
1:47d3b7e: 
1:0026e4e:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());
1:47d3b7e: 
1:0026e4e:         assertEquals(1, partitions.size());
1:0026e4e:         assertEquals("key1", AsciiType.instance.getString(partitions.get(0).partitionKey().getKey()));
1:0026e4e:         assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(Clustering.make(ByteBufferUtil.bytes("col1")))
1:0026e4e:                                                                    .getCell(cfmeta.getColumnDefinition(ByteBufferUtil.bytes("val")))
1:0026e4e:                                                                    .value());
1:b09e60f: 
1:8afc76a:         // The stream future is signalled when the work is complete but before releasing references. Wait for release
1:8afc76a:         // before cleanup (CASSANDRA-10118).
1:8afc76a:         latch.await();
1:8afc76a:     }
1:8afc76a: 
1:b09e60f:     @Test
1:b09e60f:     public void testLoadingIncompleteSSTable() throws Exception
1:b09e60f:     {
1:b09e60f:         File dataDir = new File(tmpdir.getAbsolutePath() + File.separator + KEYSPACE1 + File.separator + CF_STANDARD2);
1:b09e60f:         assert dataDir.mkdirs();
1:b09e60f: 
1:b09e60f:         //make sure we have no tables...
1:b09e60f:         assertTrue(dataDir.listFiles().length == 0);
1:b09e60f: 
1:0026e4e:         String schema = "CREATE TABLE %s.%s (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name))";
1:0026e4e:         String query = "INSERT INTO %s.%s (key, name, val) VALUES (?, ?, ?)";
1:b09e60f: 
1:b09e60f:         CQLSSTableWriter writer = CQLSSTableWriter.builder()
1:b09e60f:                                                   .inDirectory(dataDir)
1:b09e60f:                                                   .forTable(String.format(schema, KEYSPACE1, CF_STANDARD2))
1:b09e60f:                                                   .using(String.format(query, KEYSPACE1, CF_STANDARD2))
1:b09e60f:                                                   .withBufferSizeInMB(1)
1:b09e60f:                                                   .build();
1:b09e60f: 
1:0026e4e:         int NB_PARTITIONS = 5000; // Enough to write >1MB and get at least one completed sstable before we've closed the writer
1:60e45c0: 
1:60e45c0:         for (int i = 0; i < NB_PARTITIONS; i++)
1:b09e60f:         {
1:b09e60f:             for (int j = 0; j < 100; j++)
1:b09e60f:                 writer.addRow(String.format("key%d", i), String.format("col%d", j), "100");
1:b09e60f:         }
1:b09e60f: 
1:c163d0b:         ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD2);
1:c163d0b:         cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them
1:c163d0b: 
1:b09e60f:         //make sure we have some tables...
1:0026e4e:         assertTrue(dataDir.listFiles().length > 0);
1:b09e60f: 
1:8afc76a:         final CountDownLatch latch = new CountDownLatch(2);
1:b09e60f:         //writer is still open so loader should not load anything
1:0026e4e:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
1:8afc76a:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
1:b09e60f: 
1:c163d0b:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());
1:b09e60f: 
1:60e45c0:         assertTrue(partitions.size() > 0 && partitions.size() < NB_PARTITIONS);
1:b09e60f: 
1:b09e60f:         // now we complete the write and the second loader should load the last sstable as well
1:b09e60f:         writer.close();
1:b09e60f: 
1:0026e4e:         loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
1:8afc76a:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
1:b09e60f: 
1:b09e60f:         partitions = Util.getAll(Util.cmd(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD2)).build());
1:60e45c0:         assertEquals(NB_PARTITIONS, partitions.size());
1:8afc76a: 
1:8afc76a:         // The stream future is signalled when the work is complete but before releasing references. Wait for release
1:8afc76a:         // before cleanup (CASSANDRA-10118).
1:8afc76a:         latch.await();
1:b09e60f:     }
1:8afc76a: 
1:8afc76a:     StreamEventHandler completionStreamListener(final CountDownLatch latch)
1:8afc76a:     {
1:8afc76a:         return new StreamEventHandler() {
1:8afc76a:             public void onFailure(Throwable arg0)
1:8afc76a:             {
1:8afc76a:                 latch.countDown();
1:8afc76a:             }
1:8afc76a: 
1:8afc76a:             public void onSuccess(StreamState arg0)
1:8afc76a:             {
1:8afc76a:                 latch.countDown();
1:8afc76a:             }
1:8afc76a: 
1:8afc76a:             public void handleStreamEvent(StreamEvent event) {}
1:8afc76a:         };
1:ab8a28e:     }
1:ab8a28e: }
============================================================================
author:Jeremiah D Jordan
-------------------------------------------------------------------------------
commit:0026e4e
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD1);
1:         cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them
1: 
1:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
1:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());
1:         assertEquals(1, partitions.size());
1:         assertEquals("key1", AsciiType.instance.getString(partitions.get(0).partitionKey().getKey()));
1:         assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(Clustering.make(ByteBufferUtil.bytes("col1")))
1:                                                                    .getCell(cfmeta.getColumnDefinition(ByteBufferUtil.bytes("val")))
1:                                                                    .value());
/////////////////////////////////////////////////////////////////////////
1:         String schema = "CREATE TABLE %s.%s (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name))";
1:         String query = "INSERT INTO %s.%s (key, name, val) VALUES (?, ?, ?)";
/////////////////////////////////////////////////////////////////////////
1:         int NB_PARTITIONS = 5000; // Enough to write >1MB and get at least one completed sstable before we've closed the writer
/////////////////////////////////////////////////////////////////////////
1:         assertTrue(dataDir.listFiles().length > 0);
1:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
/////////////////////////////////////////////////////////////////////////
1:         loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
author:T Jake Luciani
-------------------------------------------------------------------------------
commit:47d3b7e
/////////////////////////////////////////////////////////////////////////
0: import java.util.Iterator;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.cql3.QueryProcessor;
0: import org.apache.cassandra.cql3.UntypedResultSet;
/////////////////////////////////////////////////////////////////////////
1: 
0:         File outputDir;
/////////////////////////////////////////////////////////////////////////
0:             outputDir = writer.getInnermostDirectory();
0:         SSTableLoader loader = new SSTableLoader(outputDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
0:         UntypedResultSet rs = QueryProcessor.executeInternal(String.format("SELECT * FROM %s.%s;", KEYSPACE1, CF_STANDARD1));
0:         assertEquals(1, rs.size());
1: 
0:         Iterator<UntypedResultSet.Row> iter = rs.iterator();
0:         UntypedResultSet.Row row;
1: 
0:         row = iter.next();
0:         assertEquals("key1", row.getString("key"));
/////////////////////////////////////////////////////////////////////////
0:         //Since this is running in the same jvm we need to put it in a tmp keyspace
0:         String schema = "CREATE TABLE \"%stmp\".\"%s\" (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name)) with compression = {}";
0:         String query = "INSERT INTO \"%stmp\".\"%s\" (key, name, val) VALUES (?, ?, ?)";
/////////////////////////////////////////////////////////////////////////
0:         int NB_PARTITIONS = 4200; // Enough to write >1MB and get at least one completed sstable before we've closed the writer
/////////////////////////////////////////////////////////////////////////
0:         assertTrue(writer.getInnermostDirectory().listFiles().length > 0);
0:         SSTableLoader loader = new SSTableLoader(writer.getInnermostDirectory(), new TestClient(), new OutputHandler.SystemOutput(false, false), KEYSPACE1);
/////////////////////////////////////////////////////////////////////////
0:         loader = new SSTableLoader(writer.getInnermostDirectory(), new TestClient(), new OutputHandler.SystemOutput(false, false), KEYSPACE1);
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:2f41243
/////////////////////////////////////////////////////////////////////////
0:         assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(Clustering.make(ByteBufferUtil.bytes("col1")))
author:Stefania Alborghetti
-------------------------------------------------------------------------------
commit:c163d0b
/////////////////////////////////////////////////////////////////////////
0:         ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD1);
1:         cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them
1: 
1:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());
/////////////////////////////////////////////////////////////////////////
1:         ColumnFamilyStore cfs = Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD2);
0:         cfs.forceBlockingFlush(); // wait for sstables to be on disk else we won't be able to stream them
1: 
/////////////////////////////////////////////////////////////////////////
0:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(cfs).build());
commit:b09e60f
/////////////////////////////////////////////////////////////////////////
1: import org.junit.After;
1: import org.junit.Before;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.FileUtils;
/////////////////////////////////////////////////////////////////////////
1: import static org.junit.Assert.assertTrue;
1:     public static final String CF_STANDARD1 = "Standard1";
1:     public static final String CF_STANDARD2 = "Standard2";
1: 
1:     private File tmpdir;
/////////////////////////////////////////////////////////////////////////
1:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD1),
1:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD2));
1: 
1:         StorageService.instance.initServer();
1:     @Before
1:     public void setup() throws Exception
1:         tmpdir = Files.createTempDir();
1:     }
1: 
1:     @After
1:     public void cleanup()
1:     {
1:         FileUtils.deleteRecursive(tmpdir);
1:     }
1: 
1:     private static final class TestClient extends SSTableLoader.Client
1:     {
1:         private String keyspace;
1: 
1:         public void init(String keyspace)
1:         {
1:             this.keyspace = keyspace;
1:             for (Range<Token> range : StorageService.instance.getLocalRanges(KEYSPACE1))
1:                 addRangeForEndpoint(range, FBUtilities.getBroadcastAddress());
0:             setPartitioner(StorageService.getPartitioner());
1:         }
1: 
1:         public CFMetaData getTableMetadata(String tableName)
1:         {
1:             return Schema.instance.getCFMetaData(keyspace, tableName);
1:         }
1:         File dataDir = new File(tmpdir.getAbsolutePath() + File.separator + KEYSPACE1 + File.separator + CF_STANDARD1);
1:         CFMetaData cfmeta = Schema.instance.getCFMetaData(KEYSPACE1, CF_STANDARD1);
1: 
1:                                                        .forTable(String.format(schema, KEYSPACE1, CF_STANDARD1))
1:                                                        .using(String.format(query, KEYSPACE1, CF_STANDARD1))
0:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
0:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD1)).build());
/////////////////////////////////////////////////////////////////////////
1: 
1:     @Test
1:     public void testLoadingIncompleteSSTable() throws Exception
1:     {
1:         File dataDir = new File(tmpdir.getAbsolutePath() + File.separator + KEYSPACE1 + File.separator + CF_STANDARD2);
1:         assert dataDir.mkdirs();
1: 
1:         //make sure we have no tables...
1:         assertTrue(dataDir.listFiles().length == 0);
1: 
1:         String schema = "CREATE TABLE %s.%s (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name))";
1:         String query = "INSERT INTO %s.%s (key, name, val) VALUES (?, ?, ?)";
1: 
1:         CQLSSTableWriter writer = CQLSSTableWriter.builder()
1:                                                   .inDirectory(dataDir)
0:                                                   .withPartitioner(StorageService.getPartitioner())
1:                                                   .forTable(String.format(schema, KEYSPACE1, CF_STANDARD2))
1:                                                   .using(String.format(query, KEYSPACE1, CF_STANDARD2))
1:                                                   .withBufferSizeInMB(1)
1:                                                   .build();
1: 
0:         for (int i = 0; i < 1000; i++) // make sure to write more than 1 MB
1:         {
1:             for (int j = 0; j < 100; j++)
1:                 writer.addRow(String.format("key%d", i), String.format("col%d", j), "100");
1:         }
1: 
1:         //make sure we have some tables...
0:         assertTrue(dataDir.listFiles().length > 0);
1: 
1:         //writer is still open so loader should not load anything
0:         SSTableLoader loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
0:         loader.stream().get();
1: 
0:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD2)).build());
1: 
0:         assertTrue(partitions.size() > 0 && partitions.size() < 1000);
1: 
1:         // now we complete the write and the second loader should load the last sstable as well
1:         writer.close();
1: 
0:         loader = new SSTableLoader(dataDir, new TestClient(), new OutputHandler.SystemOutput(false, false));
0:         loader.stream().get();
1: 
1:         partitions = Util.getAll(Util.cmd(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD2)).build());
0:         assertEquals(1000, partitions.size());
1:     }
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:60e45c0
/////////////////////////////////////////////////////////////////////////
0:         int NB_PARTITIONS = 5000; // Enough to write >1MB and get at least one completed sstable before we've closed the writer
1: 
1:         for (int i = 0; i < NB_PARTITIONS; i++)
/////////////////////////////////////////////////////////////////////////
1:         assertTrue(partitions.size() > 0 && partitions.size() < NB_PARTITIONS);
/////////////////////////////////////////////////////////////////////////
1:         assertEquals(NB_PARTITIONS, partitions.size());
commit:2457599
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.db.*;
/////////////////////////////////////////////////////////////////////////
0:         assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(new Clustering(ByteBufferUtil.bytes("col1")))
commit:a991b64
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.db.SimpleClustering;
1: import org.apache.cassandra.db.partitions.*;
1: import org.apache.cassandra.db.marshal.AsciiType;
/////////////////////////////////////////////////////////////////////////
1: 
0:         String schema = "CREATE TABLE %s.%s (key ascii, name ascii, val ascii, val1 ascii, PRIMARY KEY (key, name))";
0:         String query = "INSERT INTO %s.%s (key, name, val) VALUES (?, ?, ?)";
0:                                                            ;
1:         try (CQLSSTableWriter writer = CQLSSTableWriter.builder()
1:                                                        .inDirectory(dataDir)
0:                                                        .withPartitioner(StorageService.getPartitioner())
0:                                                        .forTable(String.format(schema, KEYSPACE1, CF_STANDARD))
0:                                                        .using(String.format(query, KEYSPACE1, CF_STANDARD))
1:                                                        .build())
1:             writer.addRow("key1", "col1", "100");
/////////////////////////////////////////////////////////////////////////
0:         List<FilteredPartition> partitions = Util.getAll(Util.cmd(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD)).build());
1: 
0:         assertEquals(1, partitions.size());
0:         assertEquals("key1", AsciiType.instance.getString(partitions.get(0).partitionKey().getKey()));
0:         assertEquals(ByteBufferUtil.bytes("100"), partitions.get(0).getRow(new SimpleClustering(ByteBufferUtil.bytes("col1")))
0:                                                                    .getCell(cfmeta.getColumnDefinition(ByteBufferUtil.bytes("val")))
0:                                                                    .value());
commit:362cc05
/////////////////////////////////////////////////////////////////////////
0:         assertEquals(ByteBufferUtil.bytes(100), rows.get(0).cf.getColumn(Util.cellname("col1")).value());
author:Paulo Motta
-------------------------------------------------------------------------------
commit:66b0e1d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.FSWriteError;
/////////////////////////////////////////////////////////////////////////
1:         try {
1:             FileUtils.deleteRecursive(tmpdir);
1:         } catch (FSWriteError e) {
1:             /**
1:              * Windows does not allow a mapped file to be deleted, so we probably forgot to clean the buffers somewhere.
1:              * We force a GC here to force buffer deallocation, and then try deleting the directory again.
1:              * For more information, see: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=4715154
1:              * If this is not the problem, the exception will be rethrown anyway.
1:              */
1:             System.gc();
1:             FileUtils.deleteRecursive(tmpdir);
1:         }
author:Branimir Lambov
-------------------------------------------------------------------------------
commit:8afc76a
/////////////////////////////////////////////////////////////////////////
1: import java.util.Collections;
1: import java.util.concurrent.CountDownLatch;
1: 
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.streaming.StreamEvent;
1: import org.apache.cassandra.streaming.StreamEventHandler;
1: import org.apache.cassandra.streaming.StreamState;
/////////////////////////////////////////////////////////////////////////
1:         final CountDownLatch latch = new CountDownLatch(1);
1:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
/////////////////////////////////////////////////////////////////////////
1: 
1:         // The stream future is signalled when the work is complete but before releasing references. Wait for release
1:         // before cleanup (CASSANDRA-10118).
1:         latch.await();
/////////////////////////////////////////////////////////////////////////
1:         final CountDownLatch latch = new CountDownLatch(2);
1:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
/////////////////////////////////////////////////////////////////////////
1:         loader.stream(Collections.emptySet(), completionStreamListener(latch)).get();
1: 
1:         // The stream future is signalled when the work is complete but before releasing references. Wait for release
1:         // before cleanup (CASSANDRA-10118).
1:         latch.await();
1:     }
1: 
1:     StreamEventHandler completionStreamListener(final CountDownLatch latch)
1:     {
1:         return new StreamEventHandler() {
1:             public void onFailure(Throwable arg0)
1:             {
1:                 latch.countDown();
1:             }
1: 
1:             public void onSuccess(StreamState arg0)
1:             {
1:                 latch.countDown();
1:             }
1: 
1:             public void handleStreamEvent(StreamEvent event) {}
1:         };
commit:69f77cb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:0a08525
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:31e3f61
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.schema.KeyspaceParams;
/////////////////////////////////////////////////////////////////////////
1:                                     KeyspaceParams.simple(1),
author:Jonathan Ellis
-------------------------------------------------------------------------------
commit:a22ce89
/////////////////////////////////////////////////////////////////////////
0:             setPartitioner(StorageService.getPartitioner());
/////////////////////////////////////////////////////////////////////////
0:                                                        .withPartitioner(StorageService.getPartitioner())
/////////////////////////////////////////////////////////////////////////
0:                                                   .withPartitioner(StorageService.getPartitioner())
commit:5ab1a34
/////////////////////////////////////////////////////////////////////////
0:         Keyspace.setInitialized();
commit:1d6bed3
commit:ab8a28e
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements.  See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership.  The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.cassandra.io.sstable;
1: 
1: import java.io.File;
1: import java.util.List;
1: 
1: import com.google.common.io.Files;
1: import org.junit.BeforeClass;
1: import org.junit.Test;
1: 
1: import org.apache.cassandra.SchemaLoader;
1: import org.apache.cassandra.Util;
1: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.config.Schema;
0: import org.apache.cassandra.db.DecoratedKey;
0: import org.apache.cassandra.db.Row;
0: import org.apache.cassandra.db.Table;
1: import org.apache.cassandra.dht.Range;
1: import org.apache.cassandra.dht.Token;
0: import org.apache.cassandra.exceptions.ConfigurationException;
1: import org.apache.cassandra.service.StorageService;
1: import org.apache.cassandra.utils.ByteBufferUtil;
1: import org.apache.cassandra.utils.FBUtilities;
1: import org.apache.cassandra.utils.OutputHandler;
1: 
0: import static junit.framework.Assert.assertEquals;
1: 
0: public class SSTableLoaderTest extends SchemaLoader
1: {
1:     @BeforeClass
0:     public static void setup() throws Exception
1:     {
0:         StorageService.instance.initServer();
1:     }
1: 
1:     @Test
1:     public void testLoadingSSTable() throws Exception
1:     {
0:         File tempdir = Files.createTempDir();
0:         File dataDir = new File(tempdir.getAbsolutePath() + File.separator + "Keyspace1" + File.separator + "Standard1");
1:         assert dataDir.mkdirs();
0:         CFMetaData cfmeta = Schema.instance.getCFMetaData("Keyspace1", "Standard1");
0:         SSTableSimpleUnsortedWriter writer = new SSTableSimpleUnsortedWriter(dataDir,
0:                                                                              cfmeta,
0:                                                                              StorageService.getPartitioner(),
0:                                                                              1);
0:         DecoratedKey key = Util.dk("key1");
0:         writer.newRow(key.key);
0:         writer.addColumn(ByteBufferUtil.bytes("col1"), ByteBufferUtil.bytes(100), 1);
0:         writer.close();
1: 
0:         SSTableLoader loader = new SSTableLoader(dataDir, new SSTableLoader.Client()
1:         {
0:             @Override
0:             public void init(String keyspace)
1:             {
0:                 try
1:                 {
0:                     for (Range<Token> range : StorageService.instance.getLocalRanges("Keyspace1"))
0:                         addRangeForEndpoint(range, FBUtilities.getBroadcastAddress());
0:                     setPartitioner(StorageService.getPartitioner());
0:                 } catch (ConfigurationException e)
1:                 {
0:                     throw new RuntimeException(e);
1:                 }
1:             }
1: 
0:             @Override
0:             public boolean validateColumnFamily(String keyspace, String cfName)
1:             {
0:                 return true;
1:             }
0:         }, new OutputHandler.SystemOutput(false, false));
1: 
0:         loader.stream().get();
1: 
0:         List<Row> rows = Util.getRangeSlice(Table.open("Keyspace1").getColumnFamilyStore("Standard1"));
0:         assertEquals(1, rows.size());
0:         assertEquals(key, rows.get(0).key);
0:         assertEquals(ByteBufferUtil.bytes(100), rows.get(0).cf.getColumn(ByteBufferUtil.bytes("col1")).value());
1:     }
1: }
author:Philip Thompson
-------------------------------------------------------------------------------
commit:f698cc2
/////////////////////////////////////////////////////////////////////////
0:             private String keyspace;
0: 
0:                 this.keyspace = keyspace;
0:             public CFMetaData getTableMetadata(String tableName)
0:                 return Schema.instance.getCFMetaData(keyspace, tableName);
author:Dave Brosius
-------------------------------------------------------------------------------
commit:f0ea366
/////////////////////////////////////////////////////////////////////////
0:         DecoratedKey key = Util.dk("key1");
0:         
0:         try (SSTableSimpleUnsortedWriter writer = new SSTableSimpleUnsortedWriter(dataDir,
0:                                                                              1))
0:         {
0:             writer.newRow(key.getKey());
0:             writer.addColumn(ByteBufferUtil.bytes("col1"), ByteBufferUtil.bytes(100), 1);
0:         }
commit:83a43f1
/////////////////////////////////////////////////////////////////////////
1: import static org.junit.Assert.assertEquals;
author:lyubent
-------------------------------------------------------------------------------
commit:d2a3827
/////////////////////////////////////////////////////////////////////////
0: import org.apache.cassandra.config.KSMetaData;
0: import org.apache.cassandra.locator.SimpleStrategy;
/////////////////////////////////////////////////////////////////////////
1: public class SSTableLoaderTest
1:     public static final String KEYSPACE1 = "SSTableLoaderTest";
0:     public static final String CF_STANDARD = "Standard1";
0: 
1:     public static void defineSchema() throws Exception
0:     {
1:         SchemaLoader.prepareServer();
1:         SchemaLoader.createKeyspace(KEYSPACE1,
0:                                     SimpleStrategy.class,
0:                                     KSMetaData.optsWithRF(1),
0:                                     SchemaLoader.standardCFMD(KEYSPACE1, CF_STANDARD));
0:         setup();
0:     }
0: 
/////////////////////////////////////////////////////////////////////////
0:         File dataDir = new File(tempdir.getAbsolutePath() + File.separator + KEYSPACE1 + File.separator + CF_STANDARD);
0:         CFMetaData cfmeta = Schema.instance.getCFMetaData(KEYSPACE1, CF_STANDARD);
/////////////////////////////////////////////////////////////////////////
0:                 for (Range<Token> range : StorageService.instance.getLocalRanges(KEYSPACE1))
/////////////////////////////////////////////////////////////////////////
0:         List<Row> rows = Util.getRangeSlice(Keyspace.open(KEYSPACE1).getColumnFamilyStore(CF_STANDARD));
author:Pavel Yaskevich
-------------------------------------------------------------------------------
commit:8541cca
/////////////////////////////////////////////////////////////////////////
0:         writer.newRow(key.getKey());
============================================================================
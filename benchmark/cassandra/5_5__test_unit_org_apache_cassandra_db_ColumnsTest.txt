1:ace28c9: /*
1:ace28c9: * Licensed to the Apache Software Foundation (ASF) under one
1:ace28c9: * or more contributor license agreements.  See the NOTICE file
1:ace28c9: * distributed with this work for additional information
1:ace28c9: * regarding copyright ownership.  The ASF licenses this file
1:ace28c9: * to you under the Apache License, Version 2.0 (the
1:ace28c9: * "License"); you may not use this file except in compliance
1:ace28c9: * with the License.  You may obtain a copy of the License at
1:ace28c9: *
1:ace28c9: *    http://www.apache.org/licenses/LICENSE-2.0
1:ace28c9: *
1:ace28c9: * Unless required by applicable law or agreed to in writing,
1:ace28c9: * software distributed under the License is distributed on an
1:ace28c9: * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:ace28c9: * KIND, either express or implied.  See the License for the
1:ace28c9: * specific language governing permissions and limitations
1:ace28c9: * under the License.
1:ace28c9: */
1:ace28c9: package org.apache.cassandra.db;
1:ace28c9: 
1:fe388d4: import java.io.IOException;
1:fe388d4: import java.util.*;
1:ace28c9: import java.util.concurrent.ThreadLocalRandom;
1:ace28c9: import java.util.function.Predicate;
1:ace28c9: 
1:fe388d4: import com.google.common.collect.Iterators;
1:ace28c9: import com.google.common.collect.Lists;
1:ace28c9: 
1:ace28c9: import org.junit.AfterClass;
1:ace28c9: import org.junit.Test;
1:ace28c9: 
1:ace28c9: import junit.framework.Assert;
1:ace28c9: import org.apache.cassandra.MockSchema;
1:ace28c9: import org.apache.cassandra.config.CFMetaData;
1:ace28c9: import org.apache.cassandra.config.ColumnDefinition;
1:9797511: import org.apache.cassandra.config.DatabaseDescriptor;
1:ace28c9: import org.apache.cassandra.db.marshal.SetType;
1:ace28c9: import org.apache.cassandra.db.marshal.UTF8Type;
1:fe388d4: import org.apache.cassandra.io.util.DataInputBuffer;
1:fe388d4: import org.apache.cassandra.io.util.DataOutputBuffer;
1:ace28c9: import org.apache.cassandra.utils.btree.BTreeSet;
1:ace28c9: 
1:0790e48: import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
1:0790e48: 
1:ace28c9: public class ColumnsTest
1:ace28c9: {
1:9797511:     static
1:9797511:     {
1:9797511:         DatabaseDescriptor.daemonInitialization();
1:9797511:     }
1:ace28c9: 
1:0790e48:     private static final CFMetaData cfMetaData = MockSchema.newCFS().metadata;
1:ace28c9: 
1:fe388d4:     // this tests most of our functionality, since each subset we perform
1:fe388d4:     // reasonably comprehensive tests of basic functionality against
1:fe388d4:     @Test
1:ace28c9:     public void testContainsWithoutAndMergeTo()
1:ace28c9:     {
1:fe388d4:         for (ColumnsCheck randomColumns : randomSmall(true))
1:fe388d4:             testContainsWithoutAndMergeTo(randomColumns);
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private void testContainsWithoutAndMergeTo(ColumnsCheck input)
1:ace28c9:     {
1:ace28c9:         // pick some arbitrary groupings of columns to remove at-once (to avoid factorial complexity)
1:ace28c9:         // whatever is left after each removal, we perform this logic on again, recursively
1:fe388d4:         List<List<ColumnDefinition>> removeGroups = shuffleAndGroup(Lists.newArrayList(input.definitions));
1:ace28c9:         for (List<ColumnDefinition> defs : removeGroups)
1:ace28c9:         {
1:fe388d4:             ColumnsCheck subset = input.remove(defs);
1:ace28c9: 
1:ace28c9:             // test contents after .without
1:fe388d4:             subset.assertContents();
1:ace28c9: 
1:ace28c9:             // test .contains
1:fe388d4:             assertSubset(input.columns, subset.columns);
1:ace28c9: 
1:ace28c9:             // test .mergeTo
1:fe388d4:             Columns otherSubset = input.columns;
1:fe388d4:             for (ColumnDefinition def : subset.definitions)
1:ace28c9:             {
1:ace28c9:                 otherSubset = otherSubset.without(def);
1:fe388d4:                 assertContents(otherSubset.mergeTo(subset.columns), input.definitions);
1:ace28c9:             }
1:ace28c9: 
1:fe388d4:             testContainsWithoutAndMergeTo(subset);
1:ace28c9:         }
1:ace28c9:     }
1:ace28c9: 
1:ace28c9:     private void assertSubset(Columns superset, Columns subset)
1:ace28c9:     {
1:0d74c3e:         Assert.assertTrue(superset.containsAll(superset));
1:0d74c3e:         Assert.assertTrue(superset.containsAll(subset));
1:0d74c3e:         Assert.assertFalse(subset.containsAll(superset));
1:ace28c9:     }
1:ace28c9: 
1:ace28c9:     @Test
1:fe388d4:     public void testSerialize() throws IOException
1:fe388d4:     {
1:fe388d4:         testSerialize(Columns.NONE, Collections.emptyList());
1:fe388d4:         for (ColumnsCheck randomColumns : randomSmall(false))
1:fe388d4:             testSerialize(randomColumns.columns, randomColumns.definitions);
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     private void testSerialize(Columns columns, List<ColumnDefinition> definitions) throws IOException
1:fe388d4:     {
1:fe388d4:         try (DataOutputBuffer out = new DataOutputBuffer())
1:fe388d4:         {
1:fe388d4:             Columns.serializer.serialize(columns, out);
1:fe388d4:             Assert.assertEquals(Columns.serializer.serializedSize(columns), out.buffer().remaining());
1:fe388d4:             Columns deserialized = Columns.serializer.deserialize(new DataInputBuffer(out.buffer(), false), mock(columns));
1:fe388d4:             Assert.assertEquals(columns, deserialized);
1:fe388d4:             Assert.assertEquals(columns.hashCode(), deserialized.hashCode());
1:fe388d4:             assertContents(deserialized, definitions);
1:fe388d4:         }
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     @Test
1:fe388d4:     public void testSerializeSmallSubset() throws IOException
1:fe388d4:     {
1:fe388d4:         for (ColumnsCheck randomColumns : randomSmall(true))
1:fe388d4:             testSerializeSubset(randomColumns);
1:fe388d4:     }
1:fe388d4: 
1:ffe53de:     @Test
1:fe388d4:     public void testSerializeHugeSubset() throws IOException
1:ffe53de:     {
1:fe388d4:         for (ColumnsCheck randomColumns : randomHuge())
1:fe388d4:             testSerializeSubset(randomColumns);
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     @Test
1:8360f4b:     public void testContainsAllWithLargeNumberOfColumns()
1:fe388d4:     {
1:ffe53de:         List<String> names = new ArrayList<>();
1:ffe53de:         for (int i = 0; i < 50; i++)
1:ffe53de:             names.add("clustering_" + i);
1:ffe53de: 
1:ffe53de:         List<ColumnDefinition> defs = new ArrayList<>();
1:ffe53de:         addClustering(names, defs);
1:ffe53de: 
1:ffe53de:         Columns columns = Columns.from(new HashSet<>(defs));
1:ffe53de: 
1:ffe53de:         defs = new ArrayList<>();
1:ffe53de:         addClustering(names.subList(0, 8), defs);
1:ffe53de: 
1:ffe53de:         Columns subset = Columns.from(new HashSet<>(defs));
1:ffe53de: 
1:8360f4b:         Assert.assertTrue(columns.containsAll(subset));
1:ffe53de:     }
1:ffe53de: 
1:fe388d4:     private void testSerializeSubset(ColumnsCheck input) throws IOException
1:fe388d4:     {
1:fe388d4:         testSerializeSubset(input.columns, input.columns, input.definitions);
1:fe388d4:         testSerializeSubset(input.columns, Columns.NONE, Collections.emptyList());
1:fe388d4:         List<List<ColumnDefinition>> removeGroups = shuffleAndGroup(Lists.newArrayList(input.definitions));
1:fe388d4:         for (List<ColumnDefinition> defs : removeGroups)
1:fe388d4:         {
1:fe388d4:             Collections.sort(defs);
1:fe388d4:             ColumnsCheck subset = input.remove(defs);
1:fe388d4:             testSerializeSubset(input.columns, subset.columns, subset.definitions);
1:fe388d4:         }
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     private void testSerializeSubset(Columns superset, Columns subset, List<ColumnDefinition> subsetDefinitions) throws IOException
1:fe388d4:     {
1:fe388d4:         try (DataOutputBuffer out = new DataOutputBuffer())
1:fe388d4:         {
1:fe388d4:             Columns.serializer.serializeSubset(subset, superset, out);
1:fe388d4:             Assert.assertEquals(Columns.serializer.serializedSubsetSize(subset, superset), out.buffer().remaining());
1:fe388d4:             Columns deserialized = Columns.serializer.deserializeSubset(superset, new DataInputBuffer(out.buffer(), false));
1:fe388d4:             Assert.assertEquals(subset, deserialized);
1:fe388d4:             Assert.assertEquals(subset.hashCode(), deserialized.hashCode());
1:fe388d4:             assertContents(deserialized, subsetDefinitions);
1:fe388d4:         }
1:fe388d4:     }
1:fe388d4: 
1:ace28c9:     private static void assertContents(Columns columns, List<ColumnDefinition> defs)
1:ace28c9:     {
1:ace28c9:         Assert.assertEquals(defs, Lists.newArrayList(columns));
1:ace28c9:         boolean hasSimple = false, hasComplex = false;
1:ace28c9:         int firstComplexIdx = 0;
1:ace28c9:         int i = 0;
1:ace28c9:         Iterator<ColumnDefinition> simple = columns.simpleColumns();
1:ace28c9:         Iterator<ColumnDefinition> complex = columns.complexColumns();
1:ace28c9:         Iterator<ColumnDefinition> all = columns.iterator();
1:ace28c9:         Predicate<ColumnDefinition> predicate = columns.inOrderInclusionTester();
2:ace28c9:         for (ColumnDefinition def : defs)
1:ace28c9:         {
1:ace28c9:             Assert.assertEquals(def, all.next());
1:ace28c9:             Assert.assertTrue(columns.contains(def));
1:ace28c9:             Assert.assertTrue(predicate.test(def));
1:ace28c9:             if (def.isSimple())
1:ace28c9:             {
1:ace28c9:                 hasSimple = true;
1:ace28c9:                 Assert.assertEquals(i, columns.simpleIdx(def));
1:fe388d4:                 Assert.assertEquals(def, columns.getSimple(i));
1:ace28c9:                 Assert.assertEquals(def, simple.next());
1:ace28c9:                 ++firstComplexIdx;
1:ace28c9:             }
1:ace28c9:             else
1:ace28c9:             {
1:ace28c9:                 Assert.assertFalse(simple.hasNext());
1:ace28c9:                 hasComplex = true;
1:ace28c9:                 Assert.assertEquals(i - firstComplexIdx, columns.complexIdx(def));
1:fe388d4:                 Assert.assertEquals(def, columns.getComplex(i - firstComplexIdx));
1:ace28c9:                 Assert.assertEquals(def, complex.next());
1:ace28c9:             }
1:ace28c9:             i++;
1:ace28c9:         }
1:ace28c9:         Assert.assertEquals(defs.isEmpty(), columns.isEmpty());
1:ace28c9:         Assert.assertFalse(simple.hasNext());
1:ace28c9:         Assert.assertFalse(complex.hasNext());
1:ace28c9:         Assert.assertFalse(all.hasNext());
1:ace28c9:         Assert.assertEquals(hasSimple, columns.hasSimple());
1:ace28c9:         Assert.assertEquals(hasComplex, columns.hasComplex());
1:fe388d4: 
1:fe388d4:         // check select order
1:fe388d4:         if (!columns.hasSimple() || !columns.getSimple(0).kind.isPrimaryKeyKind())
1:fe388d4:         {
1:fe388d4:             List<ColumnDefinition> selectOrderDefs = new ArrayList<>(defs);
1:fe388d4:             Collections.sort(selectOrderDefs, (a, b) -> a.name.bytes.compareTo(b.name.bytes));
1:fe388d4:             List<ColumnDefinition> selectOrderColumns = new ArrayList<>();
1:fe388d4:             Iterators.addAll(selectOrderColumns, columns.selectOrderIterator());
1:fe388d4:             Assert.assertEquals(selectOrderDefs, selectOrderColumns);
1:fe388d4:         }
1:ace28c9:     }
1:ace28c9: 
1:ace28c9:     private static <V> List<List<V>> shuffleAndGroup(List<V> list)
1:ace28c9:     {
1:ace28c9:         // first shuffle
1:ace28c9:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:ace28c9:         for (int i = 0 ; i < list.size() - 1 ; i++)
1:ace28c9:         {
1:ace28c9:             int j = random.nextInt(i, list.size());
1:ace28c9:             V v = list.get(i);
1:ace28c9:             list.set(i, list.get(j));
1:ace28c9:             list.set(j, v);
1:ace28c9:         }
1:ace28c9: 
1:fe388d4:         // then group (logarithmically, to ensure our recursive functions don't explode the state space)
1:ace28c9:         List<List<V>> result = new ArrayList<>();
1:ace28c9:         for (int i = 0 ; i < list.size() ;)
1:ace28c9:         {
1:ace28c9:             List<V> group = new ArrayList<>();
1:ace28c9:             int maxCount = list.size() - i;
1:ace28c9:             int count = maxCount <= 2 ? maxCount : random.nextInt(1, maxCount);
1:ace28c9:             for (int j = 0 ; j < count ; j++)
1:ace28c9:                 group.add(list.get(i + j));
1:ace28c9:             i += count;
1:ace28c9:             result.add(group);
1:ace28c9:         }
1:ace28c9:         return result;
1:ace28c9:     }
1:ace28c9: 
1:ace28c9:     @AfterClass
1:ace28c9:     public static void cleanup()
1:ace28c9:     {
1:ace28c9:         MockSchema.cleanup();
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static class ColumnsCheck
1:ace28c9:     {
1:ace28c9:         final Columns columns;
1:ace28c9:         final List<ColumnDefinition> definitions;
1:ace28c9: 
1:fe388d4:         private ColumnsCheck(Columns columns, List<ColumnDefinition> definitions)
1:fe388d4:         {
1:fe388d4:             this.columns = columns;
1:fe388d4:             this.definitions = definitions;
1:fe388d4:         }
1:fe388d4: 
1:fe388d4:         private ColumnsCheck(List<ColumnDefinition> definitions)
1:ace28c9:         {
1:ace28c9:             this.columns = Columns.from(BTreeSet.of(definitions));
1:ace28c9:             this.definitions = definitions;
1:ace28c9:         }
1:fe388d4: 
1:fe388d4:         ColumnsCheck remove(List<ColumnDefinition> remove)
1:fe388d4:         {
1:fe388d4:             Columns subset = columns;
1:fe388d4:             for (ColumnDefinition def : remove)
1:fe388d4:                 subset = subset.without(def);
1:0d74c3e:             Assert.assertEquals(columns.size() - remove.size(), subset.size());
1:fe388d4:             List<ColumnDefinition> remainingDefs = Lists.newArrayList(columns);
1:fe388d4:             remainingDefs.removeAll(remove);
1:fe388d4:             return new ColumnsCheck(subset, remainingDefs);
1:fe388d4:         }
1:fe388d4: 
1:fe388d4:         void assertContents()
1:fe388d4:         {
1:fe388d4:             ColumnsTest.assertContents(columns, definitions);
1:fe388d4:         }
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static List<ColumnsCheck> randomHuge()
1:ace28c9:     {
1:fe388d4:         List<ColumnsCheck> result = new ArrayList<>();
1:fe388d4:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:fe388d4:         result.add(randomHuge(random.nextInt(64, 128), 0, 0, 0));
1:fe388d4:         result.add(randomHuge(0, random.nextInt(64, 128), 0, 0));
1:fe388d4:         result.add(randomHuge(0, 0, random.nextInt(64, 128), 0));
1:fe388d4:         result.add(randomHuge(0, 0, 0, random.nextInt(64, 128)));
1:fe388d4:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), 0, 0));
1:fe388d4:         result.add(randomHuge(0, random.nextInt(64, 128), random.nextInt(64, 128), 0));
1:fe388d4:         result.add(randomHuge(0, 0, random.nextInt(64, 128), random.nextInt(64, 128)));
1:fe388d4:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128), 0));
1:fe388d4:         result.add(randomHuge(0, random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128)));
1:fe388d4:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128)));
1:fe388d4:         return result;
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     private static List<ColumnsCheck> randomSmall(boolean permitMultiplePartitionKeys)
1:fe388d4:     {
1:fe388d4:         List<ColumnsCheck> random = new ArrayList<>();
1:ace28c9:         for (int i = 1 ; i <= 3 ; i++)
1:ace28c9:         {
1:fe388d4:             int pkCount = permitMultiplePartitionKeys ? i - 1 : 1;
1:fe388d4:             if (permitMultiplePartitionKeys)
1:fe388d4:                 random.add(randomSmall(i, i - 1, i - 1, i - 1));
1:fe388d4:             random.add(randomSmall(0, 0, i, i)); // both kinds of regular, no PK
1:fe388d4:             random.add(randomSmall(pkCount, i, i - 1, i - 1)); // PK + clustering, few or none regular
1:fe388d4:             random.add(randomSmall(pkCount, i - 1, i, i - 1)); // PK + few or none clustering, some regular, few or none complex
1:fe388d4:             random.add(randomSmall(pkCount, i - 1, i - 1, i)); // PK + few or none clustering or regular, some complex
1:ace28c9:         }
1:ace28c9:         return random;
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static ColumnsCheck randomSmall(int pkCount, int clCount, int regularCount, int complexCount)
1:ace28c9:     {
1:fe388d4:         List<String> names = new ArrayList<>();
1:ace28c9:         for (char c = 'a' ; c <= 'z' ; c++)
1:fe388d4:             names .add(Character.toString(c));
1:ace28c9: 
1:ace28c9:         List<ColumnDefinition> result = new ArrayList<>();
1:fe388d4:         addPartition(select(names, pkCount), result);
1:fe388d4:         addClustering(select(names, clCount), result);
1:fe388d4:         addRegular(select(names, regularCount), result);
1:fe388d4:         addComplex(select(names, complexCount), result);
1:ace28c9:         Collections.sort(result);
1:fe388d4:         return new ColumnsCheck(result);
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static List<String> select(List<String> names, int count)
1:ace28c9:     {
1:fe388d4:         List<String> result = new ArrayList<>();
1:ace28c9:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:ace28c9:         for (int i = 0 ; i < count ; i++)
1:ace28c9:         {
1:fe388d4:             int v = random.nextInt(names.size());
1:fe388d4:             result.add(names.get(v));
1:fe388d4:             names.remove(v);
1:ace28c9:         }
1:ace28c9:         return result;
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static ColumnsCheck randomHuge(int pkCount, int clCount, int regularCount, int complexCount)
1:ace28c9:     {
1:fe388d4:         List<ColumnDefinition> result = new ArrayList<>();
1:fe388d4:         Set<String> usedNames = new HashSet<>();
1:fe388d4:         addPartition(names(pkCount, usedNames), result);
1:fe388d4:         addClustering(names(clCount, usedNames), result);
1:fe388d4:         addRegular(names(regularCount, usedNames), result);
1:fe388d4:         addComplex(names(complexCount, usedNames), result);
1:fe388d4:         Collections.sort(result);
1:fe388d4:         return new ColumnsCheck(result);
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static List<String> names(int count, Set<String> usedNames)
1:ace28c9:     {
1:fe388d4:         List<String> names = new ArrayList<>();
1:fe388d4:         StringBuilder builder = new StringBuilder();
1:fe388d4:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:fe388d4:         for (int i = 0 ; i < count ; i++)
1:fe388d4:         {
1:fe388d4:             builder.setLength(0);
1:fe388d4:             for (int j = 0 ; j < 3 || usedNames.contains(builder.toString()) ; j++)
1:fe388d4:                 builder.append((char) random.nextInt('a', 'z' + 1));
1:fe388d4:             String name = builder.toString();
1:fe388d4:             names.add(name);
1:fe388d4:             usedNames.add(name);
1:fe388d4:         }
1:fe388d4:         return names;
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static void addPartition(List<String> names, List<ColumnDefinition> results)
1:ace28c9:     {
1:fe388d4:         for (String name : names)
1:5343a75:             results.add(ColumnDefinition.partitionKeyDef(cfMetaData, bytes(name), UTF8Type.instance, 0));
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static void addClustering(List<String> names, List<ColumnDefinition> results)
1:ace28c9:     {
1:fe388d4:         int i = 0;
1:fe388d4:         for (String name : names)
1:0790e48:             results.add(ColumnDefinition.clusteringDef(cfMetaData, bytes(name), UTF8Type.instance, i++));
1:ace28c9:     }
1:ace28c9: 
1:fe388d4:     private static void addRegular(List<String> names, List<ColumnDefinition> results)
1:ace28c9:     {
1:fe388d4:         for (String name : names)
1:0790e48:             results.add(ColumnDefinition.regularDef(cfMetaData, bytes(name), UTF8Type.instance));
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     private static <V> void addComplex(List<String> names, List<ColumnDefinition> results)
1:fe388d4:     {
1:fe388d4:         for (String name : names)
1:0790e48:             results.add(ColumnDefinition.regularDef(cfMetaData, bytes(name), SetType.getInstance(UTF8Type.instance, true)));
1:fe388d4:     }
1:fe388d4: 
1:fe388d4:     private static CFMetaData mock(Columns columns)
1:fe388d4:     {
1:fe388d4:         if (columns.isEmpty())
1:fe388d4:             return cfMetaData;
1:fe388d4:         CFMetaData.Builder builder = CFMetaData.Builder.create(cfMetaData.ksName, cfMetaData.cfName);
1:fe388d4:         boolean hasPartitionKey = false;
1:fe388d4:         for (ColumnDefinition def : columns)
1:fe388d4:         {
1:fe388d4:             switch (def.kind)
1:fe388d4:             {
1:fe388d4:                 case PARTITION_KEY:
1:fe388d4:                     builder.addPartitionKey(def.name, def.type);
1:fe388d4:                     hasPartitionKey = true;
1:fe388d4:                     break;
1:fe388d4:                 case CLUSTERING:
1:fe388d4:                     builder.addClusteringColumn(def.name, def.type);
1:fe388d4:                     break;
1:fe388d4:                 case REGULAR:
1:fe388d4:                     builder.addRegularColumn(def.name, def.type);
1:fe388d4:                     break;
1:fe388d4:             }
1:fe388d4:         }
1:fe388d4:         if (!hasPartitionKey)
1:fe388d4:             builder.addPartitionKey("219894021498309239rufejsfjdksfjheiwfhjes", UTF8Type.instance);
1:fe388d4:         return builder.build();
1:ace28c9:     }
1:ace28c9: }
============================================================================
author:Robert Stupp
-------------------------------------------------------------------------------
commit:9797511
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.config.DatabaseDescriptor;
/////////////////////////////////////////////////////////////////////////
1:     static
1:     {
1:         DatabaseDescriptor.daemonInitialization();
1:     }
author:Sylvain Lebresne
-------------------------------------------------------------------------------
commit:5343a75
/////////////////////////////////////////////////////////////////////////
1:             results.add(ColumnDefinition.partitionKeyDef(cfMetaData, bytes(name), UTF8Type.instance, 0));
author:Aleksey Yeschenko
-------------------------------------------------------------------------------
commit:0790e48
/////////////////////////////////////////////////////////////////////////
1: import static org.apache.cassandra.utils.ByteBufferUtil.bytes;
1: 
1:     private static final CFMetaData cfMetaData = MockSchema.newCFS().metadata;
/////////////////////////////////////////////////////////////////////////
0:             results.add(ColumnDefinition.partitionKeyDef(cfMetaData, bytes(name), UTF8Type.instance, ColumnDefinition.NO_POSITION));
1:             results.add(ColumnDefinition.clusteringDef(cfMetaData, bytes(name), UTF8Type.instance, i++));
1:             results.add(ColumnDefinition.regularDef(cfMetaData, bytes(name), UTF8Type.instance));
1:             results.add(ColumnDefinition.regularDef(cfMetaData, bytes(name), SetType.getInstance(UTF8Type.instance, true)));
author:blerer
-------------------------------------------------------------------------------
commit:8360f4b
/////////////////////////////////////////////////////////////////////////
1:     public void testContainsAllWithLargeNumberOfColumns()
/////////////////////////////////////////////////////////////////////////
1:         Assert.assertTrue(columns.containsAll(subset));
commit:ffe53de
/////////////////////////////////////////////////////////////////////////
1:     @Test
0:     public void testContainsColumnsWithLargeNumberOfColumns()
1:     {
1:         List<String> names = new ArrayList<>();
1:         for (int i = 0; i < 50; i++)
1:             names.add("clustering_" + i);
1: 
1:         List<ColumnDefinition> defs = new ArrayList<>();
1:         addClustering(names, defs);
1: 
1:         Columns columns = Columns.from(new HashSet<>(defs));
1: 
1:         defs = new ArrayList<>();
1:         addClustering(names.subList(0, 8), defs);
1: 
1:         Columns subset = Columns.from(new HashSet<>(defs));
1: 
0:         org.junit.Assert.assertTrue(columns.contains(subset));
1:     }
1: 
author:Benedict Elliott Smith
-------------------------------------------------------------------------------
commit:0d74c3e
/////////////////////////////////////////////////////////////////////////
1:         Assert.assertTrue(superset.containsAll(superset));
1:         Assert.assertTrue(superset.containsAll(subset));
1:         Assert.assertFalse(subset.containsAll(superset));
/////////////////////////////////////////////////////////////////////////
1:             Assert.assertEquals(columns.size() - remove.size(), subset.size());
commit:fe388d4
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import java.util.*;
1: import com.google.common.collect.Iterators;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.cassandra.io.util.DataInputBuffer;
1: import org.apache.cassandra.io.util.DataOutputBuffer;
/////////////////////////////////////////////////////////////////////////
1:     // this tests most of our functionality, since each subset we perform
1:     // reasonably comprehensive tests of basic functionality against
1:         for (ColumnsCheck randomColumns : randomSmall(true))
1:             testContainsWithoutAndMergeTo(randomColumns);
1:     private void testContainsWithoutAndMergeTo(ColumnsCheck input)
1:         List<List<ColumnDefinition>> removeGroups = shuffleAndGroup(Lists.newArrayList(input.definitions));
1:             ColumnsCheck subset = input.remove(defs);
1:             subset.assertContents();
1:             assertSubset(input.columns, subset.columns);
1:             Columns otherSubset = input.columns;
1:             for (ColumnDefinition def : subset.definitions)
1:                 assertContents(otherSubset.mergeTo(subset.columns), input.definitions);
1:             testContainsWithoutAndMergeTo(subset);
/////////////////////////////////////////////////////////////////////////
1:     @Test
1:     public void testSerialize() throws IOException
1:     {
1:         testSerialize(Columns.NONE, Collections.emptyList());
1:         for (ColumnsCheck randomColumns : randomSmall(false))
1:             testSerialize(randomColumns.columns, randomColumns.definitions);
1:     }
1: 
1:     private void testSerialize(Columns columns, List<ColumnDefinition> definitions) throws IOException
1:     {
1:         try (DataOutputBuffer out = new DataOutputBuffer())
1:         {
1:             Columns.serializer.serialize(columns, out);
1:             Assert.assertEquals(Columns.serializer.serializedSize(columns), out.buffer().remaining());
1:             Columns deserialized = Columns.serializer.deserialize(new DataInputBuffer(out.buffer(), false), mock(columns));
1:             Assert.assertEquals(columns, deserialized);
1:             Assert.assertEquals(columns.hashCode(), deserialized.hashCode());
1:             assertContents(deserialized, definitions);
1:         }
1:     }
1: 
1:     @Test
1:     public void testSerializeSmallSubset() throws IOException
1:     {
1:         for (ColumnsCheck randomColumns : randomSmall(true))
1:             testSerializeSubset(randomColumns);
1:     }
1: 
1:     @Test
1:     public void testSerializeHugeSubset() throws IOException
1:     {
1:         for (ColumnsCheck randomColumns : randomHuge())
1:             testSerializeSubset(randomColumns);
1:     }
1: 
1:     private void testSerializeSubset(ColumnsCheck input) throws IOException
1:     {
1:         testSerializeSubset(input.columns, input.columns, input.definitions);
1:         testSerializeSubset(input.columns, Columns.NONE, Collections.emptyList());
1:         List<List<ColumnDefinition>> removeGroups = shuffleAndGroup(Lists.newArrayList(input.definitions));
1:         for (List<ColumnDefinition> defs : removeGroups)
1:         {
1:             Collections.sort(defs);
1:             ColumnsCheck subset = input.remove(defs);
1:             testSerializeSubset(input.columns, subset.columns, subset.definitions);
1:         }
1:     }
1: 
1:     private void testSerializeSubset(Columns superset, Columns subset, List<ColumnDefinition> subsetDefinitions) throws IOException
1:     {
1:         try (DataOutputBuffer out = new DataOutputBuffer())
1:         {
1:             Columns.serializer.serializeSubset(subset, superset, out);
1:             Assert.assertEquals(Columns.serializer.serializedSubsetSize(subset, superset), out.buffer().remaining());
1:             Columns deserialized = Columns.serializer.deserializeSubset(superset, new DataInputBuffer(out.buffer(), false));
1:             Assert.assertEquals(subset, deserialized);
1:             Assert.assertEquals(subset.hashCode(), deserialized.hashCode());
1:             assertContents(deserialized, subsetDefinitions);
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 Assert.assertEquals(def, columns.getSimple(i));
/////////////////////////////////////////////////////////////////////////
1:                 Assert.assertEquals(def, columns.getComplex(i - firstComplexIdx));
/////////////////////////////////////////////////////////////////////////
1: 
1:         // check select order
1:         if (!columns.hasSimple() || !columns.getSimple(0).kind.isPrimaryKeyKind())
1:         {
1:             List<ColumnDefinition> selectOrderDefs = new ArrayList<>(defs);
1:             Collections.sort(selectOrderDefs, (a, b) -> a.name.bytes.compareTo(b.name.bytes));
1:             List<ColumnDefinition> selectOrderColumns = new ArrayList<>();
1:             Iterators.addAll(selectOrderColumns, columns.selectOrderIterator());
1:             Assert.assertEquals(selectOrderDefs, selectOrderColumns);
1:         }
/////////////////////////////////////////////////////////////////////////
1:         // then group (logarithmically, to ensure our recursive functions don't explode the state space)
/////////////////////////////////////////////////////////////////////////
1:     private static class ColumnsCheck
1:         private ColumnsCheck(Columns columns, List<ColumnDefinition> definitions)
1:         {
1:             this.columns = columns;
1:             this.definitions = definitions;
1:         }
1: 
1:         private ColumnsCheck(List<ColumnDefinition> definitions)
1: 
1:         ColumnsCheck remove(List<ColumnDefinition> remove)
1:         {
1:             Columns subset = columns;
1:             for (ColumnDefinition def : remove)
1:                 subset = subset.without(def);
0:             Assert.assertEquals(columns.columnCount() - remove.size(), subset.columnCount());
1:             List<ColumnDefinition> remainingDefs = Lists.newArrayList(columns);
1:             remainingDefs.removeAll(remove);
1:             return new ColumnsCheck(subset, remainingDefs);
1:         }
1: 
1:         void assertContents()
1:         {
1:             ColumnsTest.assertContents(columns, definitions);
1:         }
1:     private static List<ColumnsCheck> randomHuge()
1:         List<ColumnsCheck> result = new ArrayList<>();
1:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:         result.add(randomHuge(random.nextInt(64, 128), 0, 0, 0));
1:         result.add(randomHuge(0, random.nextInt(64, 128), 0, 0));
1:         result.add(randomHuge(0, 0, random.nextInt(64, 128), 0));
1:         result.add(randomHuge(0, 0, 0, random.nextInt(64, 128)));
1:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), 0, 0));
1:         result.add(randomHuge(0, random.nextInt(64, 128), random.nextInt(64, 128), 0));
1:         result.add(randomHuge(0, 0, random.nextInt(64, 128), random.nextInt(64, 128)));
1:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128), 0));
1:         result.add(randomHuge(0, random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128)));
1:         result.add(randomHuge(random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128), random.nextInt(64, 128)));
1:         return result;
1:     }
1: 
1:     private static List<ColumnsCheck> randomSmall(boolean permitMultiplePartitionKeys)
1:     {
1:         List<ColumnsCheck> random = new ArrayList<>();
1:             int pkCount = permitMultiplePartitionKeys ? i - 1 : 1;
1:             if (permitMultiplePartitionKeys)
1:                 random.add(randomSmall(i, i - 1, i - 1, i - 1));
1:             random.add(randomSmall(0, 0, i, i)); // both kinds of regular, no PK
1:             random.add(randomSmall(pkCount, i, i - 1, i - 1)); // PK + clustering, few or none regular
1:             random.add(randomSmall(pkCount, i - 1, i, i - 1)); // PK + few or none clustering, some regular, few or none complex
1:             random.add(randomSmall(pkCount, i - 1, i - 1, i)); // PK + few or none clustering or regular, some complex
1:     private static ColumnsCheck randomSmall(int pkCount, int clCount, int regularCount, int complexCount)
1:         List<String> names = new ArrayList<>();
1:             names .add(Character.toString(c));
1:         addPartition(select(names, pkCount), result);
1:         addClustering(select(names, clCount), result);
1:         addRegular(select(names, regularCount), result);
1:         addComplex(select(names, complexCount), result);
1:         return new ColumnsCheck(result);
1:     private static List<String> select(List<String> names, int count)
1:         List<String> result = new ArrayList<>();
1:             int v = random.nextInt(names.size());
1:             result.add(names.get(v));
1:             names.remove(v);
1:     private static ColumnsCheck randomHuge(int pkCount, int clCount, int regularCount, int complexCount)
1:         List<ColumnDefinition> result = new ArrayList<>();
1:         Set<String> usedNames = new HashSet<>();
1:         addPartition(names(pkCount, usedNames), result);
1:         addClustering(names(clCount, usedNames), result);
1:         addRegular(names(regularCount, usedNames), result);
1:         addComplex(names(complexCount, usedNames), result);
1:         Collections.sort(result);
1:         return new ColumnsCheck(result);
1:     private static List<String> names(int count, Set<String> usedNames)
1:         List<String> names = new ArrayList<>();
1:         StringBuilder builder = new StringBuilder();
1:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:         for (int i = 0 ; i < count ; i++)
1:         {
1:             builder.setLength(0);
1:             for (int j = 0 ; j < 3 || usedNames.contains(builder.toString()) ; j++)
1:                 builder.append((char) random.nextInt('a', 'z' + 1));
1:             String name = builder.toString();
1:             names.add(name);
1:             usedNames.add(name);
1:         }
1:         return names;
1:     private static void addPartition(List<String> names, List<ColumnDefinition> results)
1:         for (String name : names)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(name), UTF8Type.instance, null, ColumnDefinition.Kind.PARTITION_KEY));
1:     private static void addClustering(List<String> names, List<ColumnDefinition> results)
1:         int i = 0;
1:         for (String name : names)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(name), UTF8Type.instance, i++, ColumnDefinition.Kind.CLUSTERING));
1:     private static void addRegular(List<String> names, List<ColumnDefinition> results)
1:         for (String name : names)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(name), UTF8Type.instance, null, ColumnDefinition.Kind.REGULAR));
1:     }
1: 
1:     private static <V> void addComplex(List<String> names, List<ColumnDefinition> results)
1:     {
1:         for (String name : names)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(name), SetType.getInstance(UTF8Type.instance, true), null, ColumnDefinition.Kind.REGULAR));
1:     }
1: 
1:     private static CFMetaData mock(Columns columns)
1:     {
1:         if (columns.isEmpty())
1:             return cfMetaData;
1:         CFMetaData.Builder builder = CFMetaData.Builder.create(cfMetaData.ksName, cfMetaData.cfName);
1:         boolean hasPartitionKey = false;
1:         for (ColumnDefinition def : columns)
1:         {
1:             switch (def.kind)
1:             {
1:                 case PARTITION_KEY:
1:                     builder.addPartitionKey(def.name, def.type);
1:                     hasPartitionKey = true;
1:                     break;
1:                 case CLUSTERING:
1:                     builder.addClusteringColumn(def.name, def.type);
1:                     break;
1:                 case REGULAR:
1:                     builder.addRegularColumn(def.name, def.type);
1:                     break;
1:             }
1:         }
1:         if (!hasPartitionKey)
1:             builder.addPartitionKey("219894021498309239rufejsfjdksfjheiwfhjes", UTF8Type.instance);
1:         return builder.build();
commit:ace28c9
/////////////////////////////////////////////////////////////////////////
1: /*
1: * Licensed to the Apache Software Foundation (ASF) under one
1: * or more contributor license agreements.  See the NOTICE file
1: * distributed with this work for additional information
1: * regarding copyright ownership.  The ASF licenses this file
1: * to you under the Apache License, Version 2.0 (the
1: * "License"); you may not use this file except in compliance
1: * with the License.  You may obtain a copy of the License at
1: *
1: *    http://www.apache.org/licenses/LICENSE-2.0
1: *
1: * Unless required by applicable law or agreed to in writing,
1: * software distributed under the License is distributed on an
1: * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1: * KIND, either express or implied.  See the License for the
1: * specific language governing permissions and limitations
1: * under the License.
1: */
1: package org.apache.cassandra.db;
1: 
0: import java.util.ArrayList;
0: import java.util.Collections;
0: import java.util.Iterator;
0: import java.util.List;
1: import java.util.concurrent.ThreadLocalRandom;
1: import java.util.function.Predicate;
1: 
1: import com.google.common.collect.Lists;
1: 
1: import org.junit.AfterClass;
1: import org.junit.Test;
1: 
1: import junit.framework.Assert;
1: import org.apache.cassandra.MockSchema;
1: import org.apache.cassandra.config.CFMetaData;
1: import org.apache.cassandra.config.ColumnDefinition;
1: import org.apache.cassandra.db.marshal.SetType;
1: import org.apache.cassandra.db.marshal.UTF8Type;
0: import org.apache.cassandra.utils.ByteBufferUtil;
1: import org.apache.cassandra.utils.btree.BTreeSet;
1: 
1: public class ColumnsTest
1: {
1: 
0:     private static CFMetaData cfMetaData = MockSchema.newCFS().metadata;
1: 
1:     @Test
1:     public void testContainsWithoutAndMergeTo()
1:     {
0:         for (RandomColumns randomColumns : random())
0:             testContainsWithoutAndMergeTo(randomColumns.columns, randomColumns.definitions);
1:     }
1: 
0:     private void testContainsWithoutAndMergeTo(Columns columns, List<ColumnDefinition> definitions)
1:     {
1:         // pick some arbitrary groupings of columns to remove at-once (to avoid factorial complexity)
1:         // whatever is left after each removal, we perform this logic on again, recursively
0:         List<List<ColumnDefinition>> removeGroups = shuffleAndGroup(Lists.newArrayList(definitions));
1:         for (List<ColumnDefinition> defs : removeGroups)
1:         {
0:             Columns subset = columns;
1:             for (ColumnDefinition def : defs)
0:                 subset = subset.without(def);
0:             Assert.assertEquals(columns.columnCount() - defs.size(), subset.columnCount());
0:             List<ColumnDefinition> remainingDefs = Lists.newArrayList(columns);
0:             remainingDefs.removeAll(defs);
1: 
1:             // test contents after .without
0:             assertContents(subset, remainingDefs);
1: 
1:             // test .contains
0:             assertSubset(columns, subset);
1: 
1:             // test .mergeTo
0:             Columns otherSubset = columns;
0:             for (ColumnDefinition def : remainingDefs)
1:             {
1:                 otherSubset = otherSubset.without(def);
0:                 assertContents(otherSubset.mergeTo(subset), definitions);
1:             }
1: 
0:             testContainsWithoutAndMergeTo(subset, remainingDefs);
1:         }
1:     }
1: 
1:     private void assertSubset(Columns superset, Columns subset)
1:     {
0:         Assert.assertTrue(superset.contains(superset));
0:         Assert.assertTrue(superset.contains(subset));
0:         Assert.assertFalse(subset.contains(superset));
1:     }
1: 
1:     private static void assertContents(Columns columns, List<ColumnDefinition> defs)
1:     {
1:         Assert.assertEquals(defs, Lists.newArrayList(columns));
1:         boolean hasSimple = false, hasComplex = false;
1:         int firstComplexIdx = 0;
1:         int i = 0;
1:         Iterator<ColumnDefinition> simple = columns.simpleColumns();
1:         Iterator<ColumnDefinition> complex = columns.complexColumns();
1:         Iterator<ColumnDefinition> all = columns.iterator();
1:         Predicate<ColumnDefinition> predicate = columns.inOrderInclusionTester();
1:         for (ColumnDefinition def : defs)
1:         {
1:             Assert.assertEquals(def, all.next());
1:             Assert.assertTrue(columns.contains(def));
1:             Assert.assertTrue(predicate.test(def));
1:             if (def.isSimple())
1:             {
1:                 hasSimple = true;
1:                 Assert.assertEquals(i, columns.simpleIdx(def));
1:                 Assert.assertEquals(def, simple.next());
1:                 ++firstComplexIdx;
1:             }
1:             else
1:             {
1:                 Assert.assertFalse(simple.hasNext());
1:                 hasComplex = true;
1:                 Assert.assertEquals(i - firstComplexIdx, columns.complexIdx(def));
1:                 Assert.assertEquals(def, complex.next());
1:             }
1:             i++;
1:         }
1:         Assert.assertEquals(defs.isEmpty(), columns.isEmpty());
1:         Assert.assertFalse(simple.hasNext());
1:         Assert.assertFalse(complex.hasNext());
1:         Assert.assertFalse(all.hasNext());
1:         Assert.assertEquals(hasSimple, columns.hasSimple());
1:         Assert.assertEquals(hasComplex, columns.hasComplex());
1:     }
1: 
1:     private static <V> List<List<V>> shuffleAndGroup(List<V> list)
1:     {
1:         // first shuffle
1:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:         for (int i = 0 ; i < list.size() - 1 ; i++)
1:         {
1:             int j = random.nextInt(i, list.size());
1:             V v = list.get(i);
1:             list.set(i, list.get(j));
1:             list.set(j, v);
1:         }
1: 
0:         // then group
1:         List<List<V>> result = new ArrayList<>();
1:         for (int i = 0 ; i < list.size() ;)
1:         {
1:             List<V> group = new ArrayList<>();
1:             int maxCount = list.size() - i;
1:             int count = maxCount <= 2 ? maxCount : random.nextInt(1, maxCount);
1:             for (int j = 0 ; j < count ; j++)
1:                 group.add(list.get(i + j));
1:             i += count;
1:             result.add(group);
1:         }
1:         return result;
1:     }
1: 
1:     @AfterClass
1:     public static void cleanup()
1:     {
1:         MockSchema.cleanup();
1:     }
1: 
0:     private static class RandomColumns
1:     {
1:         final Columns columns;
1:         final List<ColumnDefinition> definitions;
1: 
0:         private RandomColumns(List<ColumnDefinition> definitions)
1:         {
1:             this.columns = Columns.from(BTreeSet.of(definitions));
1:             this.definitions = definitions;
1:         }
1:     }
1: 
0:     private static List<RandomColumns> random()
1:     {
0:         List<RandomColumns> random = new ArrayList<>();
1:         for (int i = 1 ; i <= 3 ; i++)
1:         {
0:             random.add(random(i, i - 1, i - 1, i - 1));
0:             random.add(random(i - 1, i, i - 1, i - 1));
0:             random.add(random(i - 1, i - 1, i, i - 1));
0:             random.add(random(i - 1, i - 1, i - 1, i));
1:         }
1:         return random;
1:     }
1: 
0:     private static RandomColumns random(int pkCount, int clCount, int regularCount, int complexCount)
1:     {
0:         List<Character> chars = new ArrayList<>();
1:         for (char c = 'a' ; c <= 'z' ; c++)
0:             chars.add(c);
1: 
1:         List<ColumnDefinition> result = new ArrayList<>();
0:         addPartition(select(chars, pkCount), result);
0:         addClustering(select(chars, clCount), result);
0:         addRegular(select(chars, regularCount), result);
0:         addComplex(select(chars, complexCount), result);
1:         Collections.sort(result);
0:         return new RandomColumns(result);
1:     }
1: 
0:     private static List<Character> select(List<Character> chars, int count)
1:     {
0:         List<Character> result = new ArrayList<>();
1:         ThreadLocalRandom random = ThreadLocalRandom.current();
1:         for (int i = 0 ; i < count ; i++)
1:         {
0:             int v = random.nextInt(chars.size());
0:             result.add(chars.get(v));
0:             chars.remove(v);
1:         }
1:         return result;
1:     }
1: 
0:     private static void addPartition(List<Character> chars, List<ColumnDefinition> results)
1:     {
0:         addSimple(ColumnDefinition.Kind.PARTITION_KEY, chars, results);
1:     }
1: 
0:     private static void addClustering(List<Character> chars, List<ColumnDefinition> results)
1:     {
0:         addSimple(ColumnDefinition.Kind.CLUSTERING, chars, results);
1:     }
1: 
0:     private static void addRegular(List<Character> chars, List<ColumnDefinition> results)
1:     {
0:         addSimple(ColumnDefinition.Kind.REGULAR, chars, results);
1:     }
1: 
0:     private static void addSimple(ColumnDefinition.Kind kind, List<Character> chars, List<ColumnDefinition> results)
1:     {
0:         for (Character c : chars)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(c.toString()), UTF8Type.instance, null, kind));
1:     }
1: 
0:     private static void addComplex(List<Character> chars, List<ColumnDefinition> results)
1:     {
0:         for (Character c : chars)
0:             results.add(new ColumnDefinition(cfMetaData, ByteBufferUtil.bytes(c.toString()), SetType.getInstance(UTF8Type.instance, true), null, ColumnDefinition.Kind.REGULAR));
1:     }
1: }
============================================================================
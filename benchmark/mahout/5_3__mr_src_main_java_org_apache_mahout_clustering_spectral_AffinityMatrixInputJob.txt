1:049e7dc: /**
1:049e7dc:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:049e7dc:  * contributor license agreements.  See the NOTICE file distributed with
1:049e7dc:  * this work for additional information regarding copyright ownership.
1:049e7dc:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:049e7dc:  * (the "License"); you may not use this file except in compliance with
1:049e7dc:  * the License.  You may obtain a copy of the License at
1:049e7dc:  *
1:049e7dc:  *     http://www.apache.org/licenses/LICENSE-2.0
1:049e7dc:  *
1:049e7dc:  * Unless required by applicable law or agreed to in writing, software
1:049e7dc:  * distributed under the License is distributed on an "AS IS" BASIS,
1:049e7dc:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:049e7dc:  * See the License for the specific language governing permissions and
1:049e7dc:  * limitations under the License.
1:049e7dc:  */
1:049e7dc: 
1:b60c909: package org.apache.mahout.clustering.spectral;
2:48d069f: 
1:48d069f: import java.io.IOException;
1:48d069f: 
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.fs.Path;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.mapreduce.Job;
1:48d069f: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:48d069f: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:48d069f: import org.apache.mahout.common.HadoopUtil;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: import org.apache.mahout.math.hadoop.DistributedRowMatrix;
1:48d069f: 
1:48d069f: public final class AffinityMatrixInputJob {
1:48d069f: 
1:049e7dc:   private AffinityMatrixInputJob() {
1:049e7dc:   }
1:049e7dc: 
1:48d069f:   /**
1:48d069f:    * Initializes and executes the job of reading the documents containing
1:48d069f:    * the data of the affinity matrix in (x_i, x_j, value) format.
1:48d069f:    */
1:48d069f:   public static void runJob(Path input, Path output, int rows, int cols)
1:48d069f:     throws IOException, InterruptedException, ClassNotFoundException {
1:48d069f:     Configuration conf = new Configuration();
1:a13b4b7:     HadoopUtil.delete(conf, output);
1:a13b4b7: 
1:b60c909:     conf.setInt(Keys.AFFINITY_DIMENSIONS, rows);
1:48d069f:     Job job = new Job(conf, "AffinityMatrixInputJob: " + input + " -> M/R -> " + output);
1:48d069f: 
1:48d069f:     job.setMapOutputKeyClass(IntWritable.class);
1:48d069f:     job.setMapOutputValueClass(DistributedRowMatrix.MatrixEntryWritable.class);
1:48d069f:     job.setOutputKeyClass(IntWritable.class);
1:48d069f:     job.setOutputValueClass(VectorWritable.class);
1:48d069f:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:48d069f:     job.setMapperClass(AffinityMatrixInputMapper.class);   
1:48d069f:     job.setReducerClass(AffinityMatrixInputReducer.class);
1:48d069f: 
1:48d069f:     FileInputFormat.addInputPath(job, input);
1:48d069f:     FileOutputFormat.setOutputPath(job, output);
1:48d069f: 
1:765834c:     job.setJarByClass(AffinityMatrixInputJob.class);
1:765834c: 
1:7c2b664:     boolean succeeded = job.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       throw new IllegalStateException("Job failed!");
1:7c2b664:     }
1:48d069f:   }
1:48d069f: 
1:48d069f:   /**
1:48d069f:    * A transparent wrapper for the above method which handles the tedious tasks
1:48d069f:    * of setting and retrieving system Paths. Hands back a fully-populated
1:48d069f:    * and initialized DistributedRowMatrix.
1:48d069f:    */
1:48d069f:   public static DistributedRowMatrix runJob(Path input, Path output, int dimensions)
1:48d069f:     throws IOException, InterruptedException, ClassNotFoundException {
1:48d069f:     Path seqFiles = new Path(output, "seqfiles-" + (System.nanoTime() & 0xFF));
1:049e7dc:     runJob(input, seqFiles, dimensions, dimensions);
1:d61a0ee:     DistributedRowMatrix a = new DistributedRowMatrix(seqFiles,
1:48d069f:         new Path(seqFiles, "seqtmp-" + (System.nanoTime() & 0xFF)), 
1:48d069f:         dimensions, dimensions);
1:d61a0ee:     a.setConf(new Configuration());
1:d61a0ee:     return a;
1:48d069f:   }
1:48d069f: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     conf.setInt(Keys.AFFINITY_DIMENSIONS, rows);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = job.waitForCompletion(true);
1:     if (!succeeded) {
1:       throw new IllegalStateException("Job failed!");
1:     }
commit:765834c
/////////////////////////////////////////////////////////////////////////
1:     job.setJarByClass(AffinityMatrixInputJob.class);
1: 
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
1:     HadoopUtil.delete(conf, output);
1: 
commit:d61a0ee
/////////////////////////////////////////////////////////////////////////
1:     DistributedRowMatrix a = new DistributedRowMatrix(seqFiles,
1:     a.setConf(new Configuration());
1:     return a;
commit:04a0324
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     A.setConf(new Configuration());
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
/////////////////////////////////////////////////////////////////////////
1:   private AffinityMatrixInputJob() {
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
1:     runJob(input, seqFiles, dimensions, dimensions);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:48d069f
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
0: import org.apache.hadoop.mapred.JobConf;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
0: import org.apache.mahout.clustering.spectral.eigencuts.EigencutsKeys;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.hadoop.DistributedRowMatrix;
1: 
1: public final class AffinityMatrixInputJob {
1: 
1:   /**
1:    * Initializes and executes the job of reading the documents containing
1:    * the data of the affinity matrix in (x_i, x_j, value) format.
0:    * 
0:    * @param input
0:    * @param output
0:    * @param rows
0:    * @param cols
0:    * @throws IOException
0:    * @throws InterruptedException
0:    * @throws ClassNotFoundException
1:    */
1:   public static void runJob(Path input, Path output, int rows, int cols)
1:     throws IOException, InterruptedException, ClassNotFoundException {
0:     HadoopUtil.overwriteOutput(output);
1: 
1:     Configuration conf = new Configuration();
0:     conf.setInt(EigencutsKeys.AFFINITY_DIMENSIONS, rows);
1:     Job job = new Job(conf, "AffinityMatrixInputJob: " + input + " -> M/R -> " + output);
1: 
1:     job.setMapOutputKeyClass(IntWritable.class);
1:     job.setMapOutputValueClass(DistributedRowMatrix.MatrixEntryWritable.class);
1:     job.setOutputKeyClass(IntWritable.class);
1:     job.setOutputValueClass(VectorWritable.class);
1:     job.setOutputFormatClass(SequenceFileOutputFormat.class);
1:     job.setMapperClass(AffinityMatrixInputMapper.class);   
1:     job.setReducerClass(AffinityMatrixInputReducer.class);
1: 
1:     FileInputFormat.addInputPath(job, input);
1:     FileOutputFormat.setOutputPath(job, output);
1: 
0:     job.waitForCompletion(true);
1:   }
1: 
1:   /**
1:    * A transparent wrapper for the above method which handles the tedious tasks
1:    * of setting and retrieving system Paths. Hands back a fully-populated
1:    * and initialized DistributedRowMatrix.
0:    * @param input
0:    * @param output
0:    * @param dimensions
0:    * @return
0:    * @throws IOException
0:    * @throws InterruptedException
0:    * @throws ClassNotFoundException
1:    */
1:   public static DistributedRowMatrix runJob(Path input, Path output, int dimensions)
1:     throws IOException, InterruptedException, ClassNotFoundException {
1:     Path seqFiles = new Path(output, "seqfiles-" + (System.nanoTime() & 0xFF));
0:     AffinityMatrixInputJob.runJob(input, seqFiles, dimensions, dimensions);
0:     DistributedRowMatrix A = new DistributedRowMatrix(seqFiles, 
1:         new Path(seqFiles, "seqtmp-" + (System.nanoTime() & 0xFF)), 
1:         dimensions, dimensions);
0:     A.configure(new JobConf());
0:     return A;
1:   }
1: }
============================================================================
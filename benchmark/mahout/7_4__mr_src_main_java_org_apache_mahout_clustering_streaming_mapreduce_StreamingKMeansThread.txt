1:16e1e41: /**
1:16e1e41:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:16e1e41:  * contributor license agreements.  See the NOTICE file distributed with
1:16e1e41:  * this work for additional information regarding copyright ownership.
1:16e1e41:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:16e1e41:  * (the "License"); you may not use this file except in compliance with
1:16e1e41:  * the License.  You may obtain a copy of the License at
1:16e1e41:  *
1:16e1e41:  *     http://www.apache.org/licenses/LICENSE-2.0
1:16e1e41:  *
1:16e1e41:  * Unless required by applicable law or agreed to in writing, software
1:16e1e41:  * distributed under the License is distributed on an "AS IS" BASIS,
1:16e1e41:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:16e1e41:  * See the License for the specific language governing permissions and
1:16e1e41:  * limitations under the License.
1:16e1e41:  */
1:16e1e41: 
1:1d6dc49: package org.apache.mahout.clustering.streaming.mapreduce;
5:1d6dc49: 
1:85f9ece: import java.util.ArrayList;
1:6b6b8a0: import java.util.Iterator;
1:6b6b8a0: import java.util.List;
1:1d6dc49: import java.util.concurrent.Callable;
1:1d6dc49: 
1:1d6dc49: import org.apache.hadoop.conf.Configuration;
1:1d6dc49: import org.apache.hadoop.fs.Path;
1:1d6dc49: import org.apache.mahout.clustering.ClusteringUtils;
1:1d6dc49: import org.apache.mahout.clustering.streaming.cluster.StreamingKMeans;
1:1d6dc49: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterable;
1:1d6dc49: import org.apache.mahout.math.Centroid;
1:1d6dc49: import org.apache.mahout.math.VectorWritable;
1:1d6dc49: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1:40907b1: import org.slf4j.Logger;
1:40907b1: import org.slf4j.LoggerFactory;
1:1d6dc49: 
1:1d6dc49: public class StreamingKMeansThread implements Callable<Iterable<Centroid>> {
1:40907b1:   private static final Logger log = LoggerFactory.getLogger(StreamingKMeansThread.class);
1:40907b1: 
1:6b6b8a0:   private static final int NUM_ESTIMATE_POINTS = 1000;
1:6b6b8a0: 
1:335a993:   private final Configuration conf;
1:40907b1:   private final Iterable<Centroid> dataPoints;
1:1d6dc49: 
1:1d6dc49:   public StreamingKMeansThread(Path input, Configuration conf) {
1:7f431a0:     this(StreamingKMeansUtilsMR.getCentroidsFromVectorWritable(
1:7f431a0:         new SequenceFileValueIterable<VectorWritable>(input, false, conf)), conf);
1:7f431a0:   }
1:7f431a0: 
1:40907b1:   public StreamingKMeansThread(Iterable<Centroid> dataPoints, Configuration conf) {
1:40907b1:     this.dataPoints = dataPoints;
2:1d6dc49:     this.conf = conf;
2:1d6dc49:   }
1:1d6dc49: 
1:1d6dc49:   @Override
1:6b6b8a0:   public Iterable<Centroid> call() {
1:1d6dc49:     UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);
1:1d6dc49:     int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);
1:1d6dc49:     double estimateDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF,
1:6b6b8a0:         StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);
1:6b6b8a0: 
1:40907b1:     Iterator<Centroid> dataPointsIterator = dataPoints.iterator();
1:6a8cfcd: 
1:6b6b8a0:     if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
1:85f9ece:       List<Centroid> estimatePoints = new ArrayList<>(NUM_ESTIMATE_POINTS);
1:40907b1:       while (dataPointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
1:40907b1:         Centroid centroid = dataPointsIterator.next();
1:40907b1:         estimatePoints.add(centroid);
1:40907b1:       }
1:40907b1: 
1:40907b1:       if (log.isInfoEnabled()) {
1:40907b1:         log.info("Estimated Points: {}", estimatePoints.size());
1:6b6b8a0:       }
1:6b6b8a0:       estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
1:6b6b8a0:     }
1:40907b1: 
1:40907b1:     StreamingKMeans streamingKMeans = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
1:6a8cfcd: 
1:6a8cfcd:     // datapointsIterator could be empty if no estimate distance was initially provided
1:6a8cfcd:     // hence creating the iterator again here for the clustering
1:6a8cfcd:     if (!dataPointsIterator.hasNext()) {
1:6a8cfcd:       dataPointsIterator = dataPoints.iterator();
1:6b6b8a0:     }
1:6a8cfcd: 
1:6a8cfcd:     while (dataPointsIterator.hasNext()) {
1:6a8cfcd:       streamingKMeans.cluster(dataPointsIterator.next());
1:6a8cfcd:     }
1:6a8cfcd: 
1:40907b1:     streamingKMeans.reindexCentroids();
1:40907b1:     return streamingKMeans;
1:1d6dc49:   }
1:1d6dc49: 
1:1d6dc49: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.ArrayList;
/////////////////////////////////////////////////////////////////////////
1:       List<Centroid> estimatePoints = new ArrayList<>(NUM_ESTIMATE_POINTS);
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:6a8cfcd
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:     // datapointsIterator could be empty if no estimate distance was initially provided
1:     // hence creating the iterator again here for the clustering
1:     if (!dataPointsIterator.hasNext()) {
1:       dataPointsIterator = dataPoints.iterator();
1: 
1:     while (dataPointsIterator.hasNext()) {
1:       streamingKMeans.cluster(dataPointsIterator.next());
1:     }
1: 
commit:40907b1
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Iterators;
/////////////////////////////////////////////////////////////////////////
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1:   private static final Logger log = LoggerFactory.getLogger(StreamingKMeansThread.class);
1: 
1:   private final Iterable<Centroid> dataPoints;
1:   public StreamingKMeansThread(Iterable<Centroid> dataPoints, Configuration conf) {
1:     this.dataPoints = dataPoints;
/////////////////////////////////////////////////////////////////////////
1:     Iterator<Centroid> dataPointsIterator = dataPoints.iterator();
0:     List<Centroid> dataPointsList = Lists.newArrayList();
1:       while (dataPointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
1:         Centroid centroid = dataPointsIterator.next();
1:         estimatePoints.add(centroid);
0:         dataPointsList.add(centroid);
1:       }
1: 
1:       if (log.isInfoEnabled()) {
1:         log.info("Estimated Points: {}", estimatePoints.size());
1: 
0:     } else {
0:       Iterators.addAll(dataPointsList, dataPointsIterator);
1:     StreamingKMeans streamingKMeans = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
0:     for (Centroid aDataPoints : dataPointsList) {
0:       streamingKMeans.cluster(aDataPoints);
1:     streamingKMeans.reindexCentroids();
1:     return streamingKMeans;
commit:16e1e41
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:335a993
/////////////////////////////////////////////////////////////////////////
1:   private final Configuration conf;
0:   private final Iterable<Centroid> datapoints;
author:dfilimon
-------------------------------------------------------------------------------
commit:7f431a0
/////////////////////////////////////////////////////////////////////////
1:     this(StreamingKMeansUtilsMR.getCentroidsFromVectorWritable(
1:         new SequenceFileValueIterable<VectorWritable>(input, false, conf)), conf);
1:   }
1: 
0:   public StreamingKMeansThread(Iterable<Centroid> datapoints, Configuration conf) {
0:     this.datapoints = datapoints;
commit:6b6b8a0
/////////////////////////////////////////////////////////////////////////
1: import java.util.Iterator;
1: import java.util.List;
0: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
1:   private static final int NUM_ESTIMATE_POINTS = 1000;
1: 
/////////////////////////////////////////////////////////////////////////
1:   public Iterable<Centroid> call() {
1:         StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF);
1: 
0:     Iterator<Centroid> datapointsIterator = datapoints.iterator();
1:     if (estimateDistanceCutoff == StreamingKMeansDriver.INVALID_DISTANCE_CUTOFF) {
0:       List<Centroid> estimatePoints = Lists.newArrayListWithExpectedSize(NUM_ESTIMATE_POINTS);
0:       while (datapointsIterator.hasNext() && estimatePoints.size() < NUM_ESTIMATE_POINTS) {
0:         estimatePoints.add(datapointsIterator.next());
1:       }
1:       estimateDistanceCutoff = ClusteringUtils.estimateDistanceCutoff(estimatePoints, searcher.getDistanceMeasure());
1:     }
0:     while (datapointsIterator.hasNext()) {
0:       clusterer.cluster(datapointsIterator.next());
1:     }
commit:1d6dc49
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.streaming.mapreduce;
1: 
1: import java.util.concurrent.Callable;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.mahout.clustering.ClusteringUtils;
1: import org.apache.mahout.clustering.streaming.cluster.StreamingKMeans;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterable;
1: import org.apache.mahout.math.Centroid;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.neighborhood.UpdatableSearcher;
1: 
1: public class StreamingKMeansThread implements Callable<Iterable<Centroid>> {
0:   private Configuration conf;
0:   private Iterable<Centroid> datapoints;
1: 
1:   public StreamingKMeansThread(Path input, Configuration conf) {
0:     this.datapoints = StreamingKMeansUtilsMR.getCentroidsFromVectorWritable(new SequenceFileValueIterable<VectorWritable>(input, false, conf));
1:     this.conf = conf;
1:   }
1: 
0:   public StreamingKMeansThread(Iterable<Centroid> datapoints, Configuration conf) {
0:     this.datapoints = datapoints;
1:     this.conf = conf;
1:   }
1: 
1:   @Override
0:   public Iterable<Centroid> call() throws Exception {
1:     UpdatableSearcher searcher = StreamingKMeansUtilsMR.searcherFromConfiguration(conf);
1:     int numClusters = conf.getInt(StreamingKMeansDriver.ESTIMATED_NUM_MAP_CLUSTERS, 1);
1: 
1:     double estimateDistanceCutoff = conf.getFloat(StreamingKMeansDriver.ESTIMATED_DISTANCE_CUTOFF,
0:         (float) ClusteringUtils.estimateDistanceCutoff(datapoints, searcher.getDistanceMeasure(), 100));
1: 
0:     StreamingKMeans clusterer = new StreamingKMeans(searcher, numClusters, estimateDistanceCutoff);
0:     clusterer.cluster(datapoints);
0:     clusterer.reindexCentroids();
1: 
0:     return clusterer;
1:   }
1: 
1: }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
0:     this.datapoints = StreamingKMeansUtilsMR.getCentroidsFromVectorWritable(
0:         new SequenceFileValueIterable<VectorWritable>(input, false, conf));
============================================================================
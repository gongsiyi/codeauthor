2:27d33a2: /**
1:27d33a2:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:27d33a2:  * contributor license agreements.  See the NOTICE file distributed with
1:27d33a2:  * this work for additional information regarding copyright ownership.
1:27d33a2:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:27d33a2:  * (the "License"); you may not use this file except in compliance with
1:27d33a2:  * the License.  You may obtain a copy of the License at
2:27d33a2:  *
1:27d33a2:  *     http://www.apache.org/licenses/LICENSE-2.0
1:27d33a2:  *
1:27d33a2:  * Unless required by applicable law or agreed to in writing, software
1:27d33a2:  * distributed under the License is distributed on an "AS IS" BASIS,
1:27d33a2:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:27d33a2:  * See the License for the specific language governing permissions and
1:27d33a2:  * limitations under the License.
2:27d33a2:  */
2:27d33a2: 
1:27d33a2: package org.apache.mahout.classifier.sequencelearning.hmm;
1:27d33a2: 
1:f3a9cc1: import com.google.common.io.Resources;
1:4ef9d31: import org.apache.commons.io.Charsets;
1:27d33a2: import org.apache.mahout.math.Matrix;
1:d53cf4a: import org.slf4j.Logger;
1:d53cf4a: import org.slf4j.LoggerFactory;
1:27d33a2: 
1:4ef9d31: import java.io.IOException;
1:4ef9d31: import java.net.URL;
1:4ef9d31: import java.util.Arrays;
1:4ef9d31: import java.util.HashMap;
1:4ef9d31: import java.util.LinkedList;
1:4ef9d31: import java.util.List;
1:4ef9d31: import java.util.Map;
1:4ef9d31: import java.util.regex.Pattern;
1:4ef9d31: 
1:27d33a2: /**
1:27d33a2:  * This class implements a sample program that uses a pre-tagged training data
1:27d33a2:  * set to train an HMM model as a POS tagger. The training data is automatically
1:27d33a2:  * downloaded from the following URL:
1:27d33a2:  * http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt It then
1:27d33a2:  * trains an HMM Model using supervised learning and tests the model on the
1:27d33a2:  * following test data set:
1:27d33a2:  * http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/test.txt Further
1:27d33a2:  * details regarding the data files can be found at
1:27d33a2:  * http://flexcrfs.sourceforge.net/#Case_Study
1:27d33a2:  */
1:27d33a2: public final class PosTagger {
1:27d33a2: 
1:d53cf4a:   private static final Logger log = LoggerFactory.getLogger(PosTagger.class);
1:d53cf4a: 
1:3a1adb7:   private static final Pattern SPACE = Pattern.compile(" ");
1:3a1adb7:   private static final Pattern SPACES = Pattern.compile("[ ]+");
1:3a1adb7: 
1:27d33a2:   /**
1:27d33a2:    * No public constructors for utility classes.
1:27d33a2:    */
1:27d33a2:   private PosTagger() {
1:27d33a2:     // nothing to do here really.
1:d53cf4a:   }
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Model trained in the example.
1:27d33a2:    */
1:27d33a2:   private static HmmModel taggingModel;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Map for storing the IDs for the POS tags (hidden states)
1:27d33a2:    */
1:27d33a2:   private static Map<String, Integer> tagIDs;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Counter for the next assigned POS tag ID The value of 0 is reserved for
1:27d33a2:    * "unknown POS tag"
1:27d33a2:    */
1:27d33a2:   private static int nextTagId;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Map for storing the IDs for observed words (observed states)
1:27d33a2:    */
1:27d33a2:   private static Map<String, Integer> wordIDs;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Counter for the next assigned word ID The value of 0 is reserved for
1:27d33a2:    * "unknown word"
1:27d33a2:    */
1:27d33a2:   private static int nextWordId = 1; // 0 is reserved for "unknown word"
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Used for storing a list of POS tags of read sentences.
1:27d33a2:    */
1:27d33a2:   private static List<int[]> hiddenSequences;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Used for storing a list of word tags of read sentences.
1:27d33a2:    */
1:27d33a2:   private static List<int[]> observedSequences;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * number of read lines
1:27d33a2:    */
1:27d33a2:   private static int readLines;
1:27d33a2: 
1:27d33a2:   /**
1:27d33a2:    * Given an URL, this function fetches the data file, parses it, assigns POS
1:27d33a2:    * Tag/word IDs and fills the hiddenSequences/observedSequences lists with
1:27d33a2:    * data from those files. The data is expected to be in the following format
1:27d33a2:    * (one word per line): word pos-tag np-tag sentences are closed with the .
1:27d33a2:    * pos tag
1:27d33a2:    *
1:27d33a2:    * @param url       Where the data file is stored
1:27d33a2:    * @param assignIDs Should IDs for unknown words/tags be assigned? (Needed for
1:27d33a2:    *                  training data, not needed for test data)
1:27d33a2:    * @throws IOException in case data file cannot be read.
1:27d33a2:    */
1:27d33a2:   private static void readFromURL(String url, boolean assignIDs) throws IOException {
1:27d33a2:     // initialize the data structure
1:4ef9d31:     hiddenSequences = new LinkedList<>();
1:4ef9d31:     observedSequences = new LinkedList<>();
1:27d33a2:     readLines = 0;
1:27d33a2: 
1:27d33a2:     // now read line by line of the input file
1:4ef9d31:     List<Integer> observedSequence = new LinkedList<>();
1:4ef9d31:     List<Integer> hiddenSequence = new LinkedList<>();
1:3a1adb7: 
1:87c15be:     for (String line :Resources.readLines(new URL(url), Charsets.UTF_8)) {
1:f3a9cc1:       if (line.isEmpty()) {
1:f3a9cc1:         // new sentence starts
1:f3a9cc1:         int[] observedSequenceArray = new int[observedSequence.size()];
1:f3a9cc1:         int[] hiddenSequenceArray = new int[hiddenSequence.size()];
1:f3a9cc1:         for (int i = 0; i < observedSequence.size(); ++i) {
1:f3a9cc1:           observedSequenceArray[i] = observedSequence.get(i);
1:f3a9cc1:           hiddenSequenceArray[i] = hiddenSequence.get(i);
1:3a1adb7:         }
1:f3a9cc1:         // now register those arrays
1:f3a9cc1:         hiddenSequences.add(hiddenSequenceArray);
1:f3a9cc1:         observedSequences.add(observedSequenceArray);
1:f3a9cc1:         // and reset the linked lists
1:f3a9cc1:         observedSequence.clear();
1:f3a9cc1:         hiddenSequence.clear();
1:f3a9cc1:         continue;
1:3a1adb7:       }
1:f3a9cc1:       readLines++;
1:f3a9cc1:       // we expect the format [word] [POS tag] [NP tag]
1:f3a9cc1:       String[] tags = SPACE.split(line);
1:f3a9cc1:       // when analyzing the training set, assign IDs
1:f3a9cc1:       if (assignIDs) {
1:f3a9cc1:         if (!wordIDs.containsKey(tags[0])) {
1:f3a9cc1:           wordIDs.put(tags[0], nextWordId++);
1:f3a9cc1:         }
1:f3a9cc1:         if (!tagIDs.containsKey(tags[1])) {
1:f3a9cc1:           tagIDs.put(tags[1], nextTagId++);
1:f3a9cc1:         }
1:f3a9cc1:       }
1:f3a9cc1:       // determine the IDs
1:f3a9cc1:       Integer wordID = wordIDs.get(tags[0]);
1:f3a9cc1:       Integer tagID = tagIDs.get(tags[1]);
1:f3a9cc1:       // now construct the current sequence
1:58cc1ae:       if (wordID == null) {
1:58cc1ae:         observedSequence.add(0);
1:58cc1ae:       } else {
1:58cc1ae:         observedSequence.add(wordID);
1:58cc1ae:       }
1:58cc1ae: 
1:58cc1ae:       if (tagID == null) {
1:58cc1ae:         hiddenSequence.add(0);
1:58cc1ae:       } else {
1:58cc1ae:         hiddenSequence.add(tagID);
1:58cc1ae:       }
1:3a1adb7:     }
1:f3a9cc1: 
1:27d33a2:     // if there is still something in the pipe, register it
1:27d33a2:     if (!observedSequence.isEmpty()) {
1:3a1adb7:       int[] observedSequenceArray = new int[observedSequence.size()];
1:3a1adb7:       int[] hiddenSequenceArray = new int[hiddenSequence.size()];
1:3a1adb7:       for (int i = 0; i < observedSequence.size(); ++i) {
1:3a1adb7:         observedSequenceArray[i] = observedSequence.get(i);
1:3a1adb7:         hiddenSequenceArray[i] = hiddenSequence.get(i);
1:3a1adb7:       }
1:3a1adb7:       // now register those arrays
1:3a1adb7:       hiddenSequences.add(hiddenSequenceArray);
1:3a1adb7:       observedSequences.add(observedSequenceArray);
1:d53cf4a:     }
8:27d33a2:   }
1:27d33a2: 
1:27d33a2:   private static void trainModel(String trainingURL) throws IOException {
1:4ef9d31:     tagIDs = new HashMap<>(44); // we expect 44 distinct tags
1:4ef9d31:     wordIDs = new HashMap<>(19122); // we expect 19122
1:27d33a2:     // distinct words
1:d53cf4a:     log.info("Reading and parsing training data file from URL: {}", trainingURL);
1:27d33a2:     long start = System.currentTimeMillis();
1:27d33a2:     readFromURL(trainingURL, true);
1:27d33a2:     long end = System.currentTimeMillis();
1:d53cf4a:     double duration = (end - start) / 1000.0;
1:d53cf4a:     log.info("Parsing done in {} seconds!", duration);
1:d53cf4a:     log.info("Read {} lines containing {} sentences with a total of {} distinct words and {} distinct POS tags.",
1:8396a27:              readLines, hiddenSequences.size(), nextWordId - 1, nextTagId - 1);
1:27d33a2:     start = System.currentTimeMillis();
1:27d33a2:     taggingModel = HmmTrainer.trainSupervisedSequence(nextTagId, nextWordId,
1:27d33a2:         hiddenSequences, observedSequences, 0.05);
1:27d33a2:     // we have to adjust the model a bit,
1:27d33a2:     // since we assume a higher probability that a given unknown word is NNP
1:27d33a2:     // than anything else
1:27d33a2:     Matrix emissions = taggingModel.getEmissionMatrix();
1:d53cf4a:     for (int i = 0; i < taggingModel.getNrOfHiddenStates(); ++i) {
1:4ca6b86:       emissions.setQuick(i, 0, 0.1 / taggingModel.getNrOfHiddenStates());
1:d53cf4a:     }
1:27d33a2:     int nnptag = tagIDs.get("NNP");
1:d53cf4a:     emissions.setQuick(nnptag, 0, 1 / (double) taggingModel.getNrOfHiddenStates());
1:27d33a2:     // re-normalize the emission probabilities
1:27d33a2:     HmmUtils.normalizeModel(taggingModel);
1:27d33a2:     // now register the names
1:27d33a2:     taggingModel.registerHiddenStateNames(tagIDs);
1:27d33a2:     taggingModel.registerOutputStateNames(wordIDs);
1:27d33a2:     end = System.currentTimeMillis();
1:d53cf4a:     duration = (end - start) / 1000.0;
1:d53cf4a:     log.info("Trained HMM models in {} seconds!", duration);
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   private static void testModel(String testingURL) throws IOException {
1:4194a28:     log.info("Reading and parsing test data file from URL: {}", testingURL);
1:27d33a2:     long start = System.currentTimeMillis();
1:27d33a2:     readFromURL(testingURL, false);
1:27d33a2:     long end = System.currentTimeMillis();
1:d53cf4a:     double duration = (end - start) / 1000.0;
1:d53cf4a:     log.info("Parsing done in {} seconds!", duration);
1:d53cf4a:     log.info("Read {} lines containing {} sentences.", readLines, hiddenSequences.size());
1:27d33a2: 
1:27d33a2:     start = System.currentTimeMillis();
1:27d33a2:     int errorCount = 0;
1:27d33a2:     int totalCount = 0;
1:27d33a2:     for (int i = 0; i < observedSequences.size(); ++i) {
1:27d33a2:       // fetch the viterbi path as the POS tag for this observed sequence
1:d53cf4a:       int[] posEstimate = HmmEvaluator.decode(taggingModel, observedSequences.get(i), false);
1:27d33a2:       // compare with the expected
1:27d33a2:       int[] posExpected = hiddenSequences.get(i);
1:27d33a2:       for (int j = 0; j < posExpected.length; ++j) {
1:27d33a2:         totalCount++;
1:d53cf4a:         if (posEstimate[j] != posExpected[j]) {
1:27d33a2:           errorCount++;
1:d53cf4a:         }
1:27d33a2:       }
1:27d33a2:     }
1:27d33a2:     end = System.currentTimeMillis();
1:d53cf4a:     duration = (end - start) / 1000.0;
1:d53cf4a:     log.info("POS tagged test file in {} seconds!", duration);
1:4ca6b86:     double errorRate = (double) errorCount / totalCount;
1:d53cf4a:     log.info("Tagged the test file with an error rate of: {}", errorRate);
1:27d33a2:   }
1:27d33a2: 
1:d53cf4a:   private static List<String> tagSentence(String sentence) {
1:27d33a2:     // first, we need to isolate all punctuation characters, so that they
1:27d33a2:     // can be recognized
1:27d33a2:     sentence = sentence.replaceAll("[,.!?:;\"]", " $0 ");
1:27d33a2:     sentence = sentence.replaceAll("''", " '' ");
1:27d33a2:     // now we tokenize the sentence
1:3a1adb7:     String[] tokens = SPACES.split(sentence);
1:27d33a2:     // now generate the observed sequence
1:d53cf4a:     int[] observedSequence = HmmUtils.encodeStateSequence(taggingModel, Arrays.asList(tokens), true, 0);
1:27d33a2:     // POS tag this observedSequence
1:d53cf4a:     int[] hiddenSequence = HmmEvaluator.decode(taggingModel, observedSequence, false);
1:27d33a2:     // and now decode the tag names
1:d53cf4a:     return HmmUtils.decodeStateSequence(taggingModel, hiddenSequence, false, null);
1:27d33a2:   }
1:27d33a2: 
1:27d33a2:   public static void main(String[] args) throws IOException {
1:27d33a2:     // generate the model from URL
1:27d33a2:     trainModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt");
1:27d33a2:     testModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/test.txt");
1:27d33a2:     // tag an exemplary sentence
1:27d33a2:     String test = "McDonalds is a huge company with many employees .";
1:3a1adb7:     String[] testWords = SPACE.split(test);
1:d53cf4a:     List<String> posTags = tagSentence(test);
1:d53cf4a:     for (int i = 0; i < posTags.size(); ++i) {
1:d53cf4a:       log.info("{}[{}]", testWords[i], posTags.get(i));
1:d53cf4a:     }
1:27d33a2:   }
1:27d33a2: 
1:27d33a2: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:4ef9d31
/////////////////////////////////////////////////////////////////////////
1: import org.apache.commons.io.Charsets;
1: import java.io.IOException;
1: import java.net.URL;
1: import java.util.Arrays;
1: import java.util.HashMap;
1: import java.util.LinkedList;
1: import java.util.List;
1: import java.util.Map;
1: import java.util.regex.Pattern;
1: 
/////////////////////////////////////////////////////////////////////////
1:     hiddenSequences = new LinkedList<>();
1:     observedSequences = new LinkedList<>();
1:     List<Integer> observedSequence = new LinkedList<>();
1:     List<Integer> hiddenSequence = new LinkedList<>();
/////////////////////////////////////////////////////////////////////////
1:     tagIDs = new HashMap<>(44); // we expect 44 distinct tags
1:     wordIDs = new HashMap<>(19122); // we expect 19122
commit:87c15be
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     for (String line :Resources.readLines(new URL(url), Charsets.UTF_8)) {
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Lists;
/////////////////////////////////////////////////////////////////////////
0:     hiddenSequences = Lists.newLinkedList();
0:     observedSequences = Lists.newLinkedList();
0:     List<Integer> observedSequence = Lists.newLinkedList();
0:     List<Integer> hiddenSequence = Lists.newLinkedList();
/////////////////////////////////////////////////////////////////////////
1:       if (wordID == null) {
1:         observedSequence.add(0);
1:       } else {
1:         observedSequence.add(wordID);
1:       }
1: 
1:       if (tagID == null) {
1:         hiddenSequence.add(0);
1:       } else {
1:         hiddenSequence.add(tagID);
1:       }
commit:74f849b
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Maps;
/////////////////////////////////////////////////////////////////////////
0:     tagIDs = Maps.newHashMapWithExpectedSize(44); // we expect 44 distinct tags
0:     wordIDs = Maps.newHashMapWithExpectedSize(19122); // we expect 19122
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
1:       emissions.setQuick(i, 0, 0.1 / taggingModel.getNrOfHiddenStates());
/////////////////////////////////////////////////////////////////////////
1:     double errorRate = (double) errorCount / totalCount;
commit:8396a27
/////////////////////////////////////////////////////////////////////////
1:              readLines, hiddenSequences.size(), nextWordId - 1, nextTagId - 1);
commit:229aeff
/////////////////////////////////////////////////////////////////////////
0:       observedSequence.add(wordID == null ? 0 : wordID);
0:       hiddenSequence.add(tagID == null ? 0 : tagID);
commit:4194a28
/////////////////////////////////////////////////////////////////////////
1:     log.info("Reading and parsing test data file from URL: {}", testingURL);
commit:39fe224
/////////////////////////////////////////////////////////////////////////
0:       wordID = wordID == null ? 0 : wordID;
0:       tagID = tagID == null ? 0 : tagID;
commit:f3a9cc1
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.CharStreams;
1: import com.google.common.io.Resources;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     for (String line : CharStreams.readLines(Resources.newReaderSupplier(new URL(url), Charsets.UTF_8))) {
1:       if (line.isEmpty()) {
1:         // new sentence starts
1:         int[] observedSequenceArray = new int[observedSequence.size()];
1:         int[] hiddenSequenceArray = new int[hiddenSequence.size()];
1:         for (int i = 0; i < observedSequence.size(); ++i) {
1:           observedSequenceArray[i] = observedSequence.get(i);
1:           hiddenSequenceArray[i] = hiddenSequence.get(i);
1:         // now register those arrays
1:         hiddenSequences.add(hiddenSequenceArray);
1:         observedSequences.add(observedSequenceArray);
1:         // and reset the linked lists
1:         observedSequence.clear();
1:         hiddenSequence.clear();
1:         continue;
1:       readLines++;
1:       // we expect the format [word] [POS tag] [NP tag]
1:       String[] tags = SPACE.split(line);
1:       // when analyzing the training set, assign IDs
1:       if (assignIDs) {
1:         if (!wordIDs.containsKey(tags[0])) {
1:           wordIDs.put(tags[0], nextWordId++);
1:         }
1:         if (!tagIDs.containsKey(tags[1])) {
1:           tagIDs.put(tags[1], nextTagId++);
1:         }
1:       }
1:       // determine the IDs
1:       Integer wordID = wordIDs.get(tags[0]);
1:       Integer tagID = tagIDs.get(tags[1]);
0:       // handle unknown values
0:       wordID = (wordID == null) ? 0 : wordID;
0:       tagID = (tagID == null) ? 0 : tagID;
1:       // now construct the current sequence
0:       observedSequence.add(wordID);
0:       hiddenSequence.add(tagID);
1: 
commit:80366ee
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Charsets;
/////////////////////////////////////////////////////////////////////////
0:         new BufferedReader(new InputStreamReader(connection.getInputStream(), Charsets.UTF_8));
commit:3a1adb7
/////////////////////////////////////////////////////////////////////////
0: import java.nio.charset.Charset;
0: import java.util.regex.Pattern;
0: import org.apache.mahout.common.IOUtils;
/////////////////////////////////////////////////////////////////////////
1:   private static final Pattern SPACE = Pattern.compile(" ");
1:   private static final Pattern SPACES = Pattern.compile("[ ]+");
1: 
/////////////////////////////////////////////////////////////////////////
1: 
0:     BufferedReader input =
0:         new BufferedReader(new InputStreamReader(connection.getInputStream(), Charset.forName("UTF-8")));
0:     try {
0:       String line;
0:       while ((line = input.readLine()) != null) {
0:         if (line.isEmpty()) {
0:           // new sentence starts
1:           int[] observedSequenceArray = new int[observedSequence.size()];
1:           int[] hiddenSequenceArray = new int[hiddenSequence.size()];
1:           for (int i = 0; i < observedSequence.size(); ++i) {
1:             observedSequenceArray[i] = observedSequence.get(i);
1:             hiddenSequenceArray[i] = hiddenSequence.get(i);
1:           }
1:           // now register those arrays
1:           hiddenSequences.add(hiddenSequenceArray);
1:           observedSequences.add(observedSequenceArray);
0:           // and reset the linked lists
0:           observedSequence.clear();
0:           hiddenSequence.clear();
0:           continue;
0:         readLines++;
0:         // we expect the format [word] [POS tag] [NP tag]
0:         String[] tags = SPACE.split(line);
0:         // when analyzing the training set, assign IDs
0:         if (assignIDs) {
0:           if (!wordIDs.containsKey(tags[0])) {
0:             wordIDs.put(tags[0], nextWordId++);
1:           }
0:           if (!tagIDs.containsKey(tags[1])) {
0:             tagIDs.put(tags[1], nextTagId++);
1:           }
1:         }
0:         // determine the IDs
0:         Integer wordID = wordIDs.get(tags[0]);
0:         Integer tagID = tagIDs.get(tags[1]);
0:         // handle unknown values
0:         wordID = (wordID == null) ? 0 : wordID;
0:         tagID = (tagID == null) ? 0 : tagID;
0:         // now construct the current sequence
0:         observedSequence.add(wordID);
0:         hiddenSequence.add(tagID);
0:     } finally {
0:       IOUtils.quietClose(input);
/////////////////////////////////////////////////////////////////////////
1:     String[] tokens = SPACES.split(sentence);
/////////////////////////////////////////////////////////////////////////
1:     String[] testWords = SPACE.split(test);
commit:61ae2e7
/////////////////////////////////////////////////////////////////////////
0:              new Object[] {readLines, hiddenSequences.size(), nextWordId - 1, nextTagId - 1});
commit:d53cf4a
/////////////////////////////////////////////////////////////////////////
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
/////////////////////////////////////////////////////////////////////////
1:   private static final Logger log = LoggerFactory.getLogger(PosTagger.class);
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         if (!wordIDs.containsKey(tags[0])) {
1:         }
0:         if (!tagIDs.containsKey(tags[1])) {
1:         }
/////////////////////////////////////////////////////////////////////////
1:     log.info("Reading and parsing training data file from URL: {}", trainingURL);
1:     double duration = (end - start) / 1000.0;
1:     log.info("Parsing done in {} seconds!", duration);
1:     log.info("Read {} lines containing {} sentences with a total of {} distinct words and {} distinct POS tags.",
0:              new Object[] {readLines, hiddenSequences.size(), (nextWordId - 1), (nextTagId - 1)});
/////////////////////////////////////////////////////////////////////////
1:     for (int i = 0; i < taggingModel.getNrOfHiddenStates(); ++i) {
0:       emissions.setQuick(i, 0, 0.1 / (double) taggingModel.getNrOfHiddenStates());
1:     }
1:     emissions.setQuick(nnptag, 0, 1 / (double) taggingModel.getNrOfHiddenStates());
1:     duration = (end - start) / 1000.0;
1:     log.info("Trained HMM models in {} seconds!", duration);
0:     log.info("Reading and parsing test data file from URL:" + testingURL);
1:     double duration = (end - start) / 1000.0;
1:     log.info("Parsing done in {} seconds!", duration);
1:     log.info("Read {} lines containing {} sentences.", readLines, hiddenSequences.size());
1:       int[] posEstimate = HmmEvaluator.decode(taggingModel, observedSequences.get(i), false);
1:         if (posEstimate[j] != posExpected[j]) {
1:         }
1:     duration = (end - start) / 1000.0;
1:     log.info("POS tagged test file in {} seconds!", duration);
1:     log.info("Tagged the test file with an error rate of: {}", errorRate);
1:   private static List<String> tagSentence(String sentence) {
/////////////////////////////////////////////////////////////////////////
1:     int[] observedSequence = HmmUtils.encodeStateSequence(taggingModel, Arrays.asList(tokens), true, 0);
1:     int[] hiddenSequence = HmmEvaluator.decode(taggingModel, observedSequence, false);
1:     return HmmUtils.decodeStateSequence(taggingModel, hiddenSequence, false, null);
/////////////////////////////////////////////////////////////////////////
1:     List<String> posTags = tagSentence(test);
1:     for (int i = 0; i < posTags.size(); ++i) {
1:       log.info("{}[{}]", testWords[i], posTags.get(i));
1:     }
author:Isabel Drost
-------------------------------------------------------------------------------
commit:27d33a2
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.sequencelearning.hmm;
1: 
0: import java.io.BufferedReader;
0: import java.io.IOException;
0: import java.io.InputStreamReader;
0: import java.net.URL;
0: import java.net.URLConnection;
0: import java.util.Arrays;
0: import java.util.HashMap;
0: import java.util.LinkedList;
0: import java.util.List;
0: import java.util.Map;
1: 
0: import org.apache.commons.logging.Log;
0: import org.apache.commons.logging.LogFactory;
1: import org.apache.mahout.math.Matrix;
1: 
1: /**
1:  * This class implements a sample program that uses a pre-tagged training data
1:  * set to train an HMM model as a POS tagger. The training data is automatically
1:  * downloaded from the following URL:
1:  * http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt It then
1:  * trains an HMM Model using supervised learning and tests the model on the
1:  * following test data set:
1:  * http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/test.txt Further
1:  * details regarding the data files can be found at
1:  * http://flexcrfs.sourceforge.net/#Case_Study
1:  *
0:  * @author mheimel
1:  */
1: public final class PosTagger {
1: 
1:   /**
1:    * No public constructors for utility classes.
1:    */
1:   private PosTagger() {
1:     // nothing to do here really.
1:   }
1: 
1:   /**
0:    * Logger for this class.
1:    */
0:   private static final Log LOG = LogFactory.getLog(PosTagger.class);
1:   /**
1:    * Model trained in the example.
1:    */
1:   private static HmmModel taggingModel;
1: 
1:   /**
1:    * Map for storing the IDs for the POS tags (hidden states)
1:    */
1:   private static Map<String, Integer> tagIDs;
1: 
1:   /**
1:    * Counter for the next assigned POS tag ID The value of 0 is reserved for
1:    * "unknown POS tag"
1:    */
1:   private static int nextTagId;
1: 
1:   /**
1:    * Map for storing the IDs for observed words (observed states)
1:    */
1:   private static Map<String, Integer> wordIDs;
1: 
1:   /**
1:    * Counter for the next assigned word ID The value of 0 is reserved for
1:    * "unknown word"
1:    */
1:   private static int nextWordId = 1; // 0 is reserved for "unknown word"
1: 
1:   /**
1:    * Used for storing a list of POS tags of read sentences.
1:    */
1:   private static List<int[]> hiddenSequences;
1: 
1:   /**
1:    * Used for storing a list of word tags of read sentences.
1:    */
1:   private static List<int[]> observedSequences;
1: 
1:   /**
1:    * number of read lines
1:    */
1:   private static int readLines;
1: 
1:   /**
1:    * Given an URL, this function fetches the data file, parses it, assigns POS
1:    * Tag/word IDs and fills the hiddenSequences/observedSequences lists with
1:    * data from those files. The data is expected to be in the following format
1:    * (one word per line): word pos-tag np-tag sentences are closed with the .
1:    * pos tag
1:    *
1:    * @param url       Where the data file is stored
1:    * @param assignIDs Should IDs for unknown words/tags be assigned? (Needed for
1:    *                  training data, not needed for test data)
1:    * @throws IOException in case data file cannot be read.
1:    */
1:   private static void readFromURL(String url, boolean assignIDs) throws IOException {
0:     URLConnection connection = (new URL(url)).openConnection();
0:     BufferedReader input = new BufferedReader(new InputStreamReader(connection.getInputStream()));
1:     // initialize the data structure
0:     hiddenSequences = new LinkedList<int[]>();
0:     observedSequences = new LinkedList<int[]>();
1:     readLines = 0;
1: 
1:     // now read line by line of the input file
0:     String line;
0:     List<Integer> observedSequence = new LinkedList<Integer>();
0:     List<Integer> hiddenSequence = new LinkedList<Integer>();
0:     while ((line = input.readLine()) != null) {
0:       if (line.isEmpty()) {
0:         // new sentence starts
0:         int[] observedSequenceArray = new int[observedSequence.size()];
0:         int[] hiddenSequenceArray = new int[hiddenSequence.size()];
0:         for (int i = 0; i < observedSequence.size(); ++i) {
0:           observedSequenceArray[i] = observedSequence.get(i);
0:           hiddenSequenceArray[i] = hiddenSequence.get(i);
1:         }
0:         // now register those arrays
0:         hiddenSequences.add(hiddenSequenceArray);
0:         observedSequences.add(observedSequenceArray);
0:         // and reset the linked lists
0:         observedSequence.clear();
0:         hiddenSequence.clear();
0:         continue;
1:       }
0:       readLines++;
0:       // we expect the format [word] [POS tag] [NP tag]
0:       String[] tags = line.split(" ");
0:       // when analyzing the training set, assign IDs
0:       if (assignIDs) {
0:         if (!wordIDs.containsKey(tags[0]))
0:           wordIDs.put(tags[0], nextWordId++);
0:         if (!tagIDs.containsKey(tags[1]))
0:           tagIDs.put(tags[1], nextTagId++);
1:       }
0:       // determine the IDs
0:       Integer wordID = wordIDs.get(tags[0]);
0:       Integer tagID = tagIDs.get(tags[1]);
0:       // handle unknown values
0:       wordID = (wordID == null) ? 0 : wordID;
0:       tagID = (tagID == null) ? 0 : tagID;
0:       // now construct the current sequence
0:       observedSequence.add(wordID);
0:       hiddenSequence.add(tagID);
1:     }
1:     // if there is still something in the pipe, register it
1:     if (!observedSequence.isEmpty()) {
0:       int[] observedSequenceArray = new int[observedSequence.size()];
0:       int[] hiddenSequenceArray = new int[hiddenSequence.size()];
0:       for (int i = 0; i < observedSequence.size(); ++i) {
0:         observedSequenceArray[i] = observedSequence.get(i);
0:         hiddenSequenceArray[i] = hiddenSequence.get(i);
1:       }
0:       // now register those arrays
0:       hiddenSequences.add(hiddenSequenceArray);
0:       observedSequences.add(observedSequenceArray);
1:     }
1:   }
1: 
1:   private static void trainModel(String trainingURL) throws IOException {
0:     tagIDs = new HashMap<String, Integer>(44); // we expect 44 distinct tags
0:     wordIDs = new HashMap<String, Integer>(19122); // we expect 19122
1:     // distinct words
0:     LOG.info("Reading and parsing training data file from URL: " + trainingURL);
1:     long start = System.currentTimeMillis();
1:     readFromURL(trainingURL, true);
1:     long end = System.currentTimeMillis();
0:     double duration = (end - start) / (double) 1000;
0:     LOG.info("Parsing done in " + duration + " seconds!");
0:     LOG.info("Read " + readLines + " lines containing "
0:         + hiddenSequences.size() + " sentences with a total of "
0:         + (nextWordId - 1) + " distinct words and " + (nextTagId - 1)
0:         + " distinct POS tags.");
1:     start = System.currentTimeMillis();
1:     taggingModel = HmmTrainer.trainSupervisedSequence(nextTagId, nextWordId,
1:         hiddenSequences, observedSequences, 0.05);
1:     // we have to adjust the model a bit,
1:     // since we assume a higher probability that a given unknown word is NNP
1:     // than anything else
1:     Matrix emissions = taggingModel.getEmissionMatrix();
0:     for (int i = 0; i < taggingModel.getNrOfHiddenStates(); ++i)
0:       emissions.setQuick(i, 0, 0.1 / (double) taggingModel
0:           .getNrOfHiddenStates());
1:     int nnptag = tagIDs.get("NNP");
0:     emissions.setQuick(nnptag, 0, 1 / (double) taggingModel
0:         .getNrOfHiddenStates());
1:     // re-normalize the emission probabilities
1:     HmmUtils.normalizeModel(taggingModel);
1:     // now register the names
1:     taggingModel.registerHiddenStateNames(tagIDs);
1:     taggingModel.registerOutputStateNames(wordIDs);
1:     end = System.currentTimeMillis();
0:     duration = (end - start) / (double) 1000;
0:     LOG.info("Trained HMM model sin " + duration + " seconds!");
1:   }
1: 
1:   private static void testModel(String testingURL) throws IOException {
0:     LOG.info("Reading and parsing test data file from URL:" + testingURL);
1:     long start = System.currentTimeMillis();
1:     readFromURL(testingURL, false);
1:     long end = System.currentTimeMillis();
0:     double duration = (end - start) / (double) 1000;
0:     LOG.info("Parsing done in " + duration + " seconds!");
0:     LOG.info("Read " + readLines + " lines containing "
0:         + hiddenSequences.size() + " sentences.");
1: 
1:     start = System.currentTimeMillis();
1:     int errorCount = 0;
1:     int totalCount = 0;
1:     for (int i = 0; i < observedSequences.size(); ++i) {
1:       // fetch the viterbi path as the POS tag for this observed sequence
0:       int[] posEstimate = HmmEvaluator.decode(taggingModel, observedSequences
0:           .get(i), false);
1:       // compare with the expected
1:       int[] posExpected = hiddenSequences.get(i);
1:       for (int j = 0; j < posExpected.length; ++j) {
1:         totalCount++;
0:         if (posEstimate[j] != posExpected[j])
1:           errorCount++;
1:       }
1:     }
1:     end = System.currentTimeMillis();
0:     duration = (end - start) / (double) 1000;
0:     LOG.info("POS tagged test file in " + duration + " seconds!");
0:     double errorRate = (double) errorCount / (double) totalCount;
0:     LOG.info("Tagged the test file with an error rate of: " + errorRate);
1:   }
1: 
0:   private static java.util.Vector<String> tagSentence(String sentence) {
1:     // first, we need to isolate all punctuation characters, so that they
1:     // can be recognized
1:     sentence = sentence.replaceAll("[,.!?:;\"]", " $0 ");
1:     sentence = sentence.replaceAll("''", " '' ");
1:     // now we tokenize the sentence
0:     String[] tokens = sentence.split("[ ]+");
1:     // now generate the observed sequence
0:     int[] observedSequence = HmmUtils.encodeStateSequence(taggingModel, Arrays
0:         .asList(tokens), true, 0);
1:     // POS tag this observedSequence
0:     int[] hiddenSequence = HmmEvaluator.decode(taggingModel, observedSequence,
0:         false);
1:     // and now decode the tag names
0:     return HmmUtils.decodeStateSequence(taggingModel, hiddenSequence, false,
0:         null);
1:   }
1: 
1:   public static void main(String[] args) throws IOException {
1:     // generate the model from URL
1:     trainModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/train.txt");
1:     testModel("http://www.jaist.ac.jp/~hieuxuan/flexcrfs/CoNLL2000-NP/test.txt");
1:     // tag an exemplary sentence
1:     String test = "McDonalds is a huge company with many employees .";
0:     String[] testWords = test.split(" ");
0:     java.util.Vector<String> posTags;
0:     posTags = tagSentence(test);
0:     for (int i = 0; i < posTags.size(); ++i)
0:       LOG.info(testWords[i] + "[" + posTags.get(i) + "]");
1:   }
1: 
1: }
============================================================================
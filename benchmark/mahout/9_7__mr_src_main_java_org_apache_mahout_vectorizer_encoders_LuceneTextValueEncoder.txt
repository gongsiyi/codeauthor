1:6c34155: /*
1:6c34155:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:6c34155:  * contributor license agreements.  See the NOTICE file distributed with
1:6c34155:  * this work for additional information regarding copyright ownership.
1:6c34155:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:6c34155:  * (the "License"); you may not use this file except in compliance with
1:6c34155:  * the License.  You may obtain a copy of the License at
5:6c34155:  *
1:6c34155:  *     http://www.apache.org/licenses/LICENSE-2.0
1:6c34155:  *
1:6c34155:  * Unless required by applicable law or agreed to in writing, software
1:6c34155:  * distributed under the License is distributed on an "AS IS" BASIS,
1:6c34155:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:6c34155:  * See the License for the specific language governing permissions and
1:6c34155:  * limitations under the License.
4:6c34155:  */
9:6c34155: 
1:5a7067b: package org.apache.mahout.vectorizer.encoders;
1:6c34155: 
1:6c34155: import org.apache.lucene.analysis.Analyzer;
1:6c34155: import org.apache.lucene.analysis.TokenStream;
1:a4778a4: import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
1:a4778a4: import org.apache.mahout.common.lucene.TokenStreamIterator;
1:a4778a4: 
1:6c34155: import java.io.IOException;
1:6c34155: import java.io.Reader;
1:6c34155: import java.nio.CharBuffer;
1:6c34155: import java.util.Iterator;
1:6c34155: 
4:6c34155: /**
1:6c34155:  * Encodes text using a lucene style tokenizer.
1:6a4942c:  *
1:6c34155:  * @see TextValueEncoder
1:6c34155:  */
1:6c34155: public class LuceneTextValueEncoder extends TextValueEncoder {
1:6c34155:   private Analyzer analyzer;
1:6c34155: 
1:6c34155:   public LuceneTextValueEncoder(String name) {
1:6c34155:     super(name);
14:6c34155:   }
1:6c34155: 
1:6c34155:   public void setAnalyzer(Analyzer analyzer) {
1:6c34155:     this.analyzer = analyzer;
1:6c34155:   }
1:6c34155: 
1:6c34155:   /**
1:6c34155:    * Tokenizes a string using the simplest method.  This should be over-ridden for more subtle
1:6c34155:    * tokenization.
1:6c34155:    */
4:6c34155:   @Override
1:6c34155:   protected Iterable<String> tokenize(CharSequence originalForm) {
1:4d0cd66:     TokenStream ts = analyzer.tokenStream(getName(), new CharSequenceReader(originalForm));
1:4d0cd66:     ts.addAttribute(CharTermAttribute.class);
1:4d0cd66:     return new LuceneTokenIterable(ts, false);
1:d3ccbe0:   }
1:6c34155: 
1:5ce5992:   private static final class CharSequenceReader extends Reader {
1:5ce5992:     private final CharBuffer buf;
1:6c34155: 
1:6c34155:     /**
1:6c34155:      * Creates a new character-stream reader whose critical sections will synchronize on the reader
1:6c34155:      * itself.
1:6c34155:      */
1:6c34155:     private CharSequenceReader(CharSequence input) {
1:6c34155:       int n = input.length();
1:6c34155:       buf = CharBuffer.allocate(n);
1:6c34155:       for (int i = 0; i < n; i++) {
1:6c34155:         buf.put(input.charAt(i));
1:6c34155:       }
1:ac89aa3:       buf.rewind();
1:6c34155:     }
1:6c34155: 
1:6c34155:     /**
1:6c34155:      * Reads characters into a portion of an array.  This method will block until some input is
1:6c34155:      * available, an I/O error occurs, or the end of the stream is reached.
1:6c34155:      *
1:6c34155:      * @param cbuf Destination buffer
1:6c34155:      * @param off  Offset at which to start storing characters
1:6c34155:      * @param len  Maximum number of characters to read
1:6c34155:      * @return The number of characters read, or -1 if the end of the stream has been reached
1:6c34155:      */
1:6c34155:     @Override
1:5ce5992:     public int read(char[] cbuf, int off, int len) {
1:ac89aa3:       int toRead = Math.min(len, buf.remaining());
1:e64dd36:       if (toRead > 0) {
1:ac89aa3:         buf.get(cbuf, off, toRead);
1:ac89aa3:         return toRead;
1:ac89aa3:       } else {
1:ac89aa3:         return -1;
1:ac89aa3:       }
1:6c34155:     }
1:6c34155: 
1:6c34155:     @Override
1:6a4942c:     public void close() {
1:6c34155:       // do nothing
1:6c34155:     }
1:6c34155:   }
1:2e5449f: 
1:d61a0ee:   private static final class LuceneTokenIterable implements Iterable<String> {
1:6c34155:     private boolean firstTime = true;
1:5ce5992:     private final TokenStream tokenStream;
1:6c34155: 
1:6a4942c:     private LuceneTokenIterable(TokenStream ts, boolean firstTime) {
1:6a4942c:       this.tokenStream = ts;
1:6a4942c:       this.firstTime = firstTime;
1:6a4942c:     }
1:6a4942c: 
1:6c34155:     /**
1:6c34155:      * Returns an iterator over a set of elements of type T.
1:6c34155:      *
1:6c34155:      * @return an Iterator.
1:6c34155:      */
1:6c34155:     @Override
1:6c34155:     public Iterator<String> iterator() {
1:5ce5992:       if (firstTime) {
1:5ce5992:         firstTime = false;
1:5ce5992:       } else {
1:d3ccbe0:         try {
1:6c34155:           tokenStream.reset();
2:6c34155:         } catch (IOException e) {
1:6c34155:           throw new IllegalStateException("This token stream can't be reset");
1:6c34155:         }
1:6c34155:       }
1:6c34155: 
1:6c34155:       return new TokenStreamIterator(tokenStream);
1:6c34155:     }
1:6c34155:   }
1:6c34155: 
1:6c34155: }
============================================================================
author:smarthi
-------------------------------------------------------------------------------
commit:4d0cd66
/////////////////////////////////////////////////////////////////////////
1:     TokenStream ts = analyzer.tokenStream(getName(), new CharSequenceReader(originalForm));
1:     ts.addAttribute(CharTermAttribute.class);
1:     return new LuceneTokenIterable(ts, false);
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:2e5449f
/////////////////////////////////////////////////////////////////////////
1: 
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:4841efb
/////////////////////////////////////////////////////////////////////////
0:   //GSI: TODO: we really need a way to make sure we call the TokenStream workflow here (i.e. end and close when done)
commit:210b265
/////////////////////////////////////////////////////////////////////////
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6a4942c
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:  *
/////////////////////////////////////////////////////////////////////////
0:       TokenStream ts = analyzer.tokenStream(getName(), new CharSequenceReader(originalForm));
0:       return new LuceneTokenIterable(ts, false);
/////////////////////////////////////////////////////////////////////////
1:     public void close() {
0:   //GSI: TODO: we really need a way to make sure we call the TokenStream workflow here (i.e. end and close when we are done)
/////////////////////////////////////////////////////////////////////////
1:     private LuceneTokenIterable(TokenStream ts, boolean firstTime) {
1:       this.tokenStream = ts;
1:       this.firstTime = firstTime;
1:     }
1: 
commit:ac89aa3
/////////////////////////////////////////////////////////////////////////
1:       buf.rewind();
/////////////////////////////////////////////////////////////////////////
1:       int toRead = Math.min(len, buf.remaining());
0:       if (toRead > 0){
1:         buf.get(cbuf, off, toRead);
1:         return toRead;
1:       } else {
1:         return -1;
1:       }
commit:a4778a4
/////////////////////////////////////////////////////////////////////////
1: import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
1: import org.apache.mahout.common.lucene.TokenStreamIterator;
1: 
/////////////////////////////////////////////////////////////////////////
0:     ts.addAttribute(CharTermAttribute.class);
author:tcp
-------------------------------------------------------------------------------
commit:e64dd36
/////////////////////////////////////////////////////////////////////////
1:       if (toRead > 0) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:d3ccbe0
/////////////////////////////////////////////////////////////////////////
1:     try {
0:       TokenStream ts = analyzer.reusableTokenStream(getName(), new CharSequenceReader(originalForm));
0:       ts.addAttribute(CharTermAttribute.class);
0:       return new LuceneTokenIterable(ts);
0:     } catch (IOException ex) {
0:       throw new IllegalStateException(ex);
1:     }
commit:80366ee
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:d61a0ee
/////////////////////////////////////////////////////////////////////////
1:   private static final class LuceneTokenIterable implements Iterable<String> {
/////////////////////////////////////////////////////////////////////////
0:   private static final class TokenStreamIterator implements Iterator<String> {
/////////////////////////////////////////////////////////////////////////
0:   private static final class TokenizationException extends RuntimeException {
commit:5ce5992
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:   private static final class CharSequenceReader extends Reader {
1:     private final CharBuffer buf;
/////////////////////////////////////////////////////////////////////////
1:     public int read(char[] cbuf, int off, int len) {
0:     public void close()  {
0:   private static class LuceneTokenIterable implements Iterable<String> {
1:     private final TokenStream tokenStream;
0:     private LuceneTokenIterable(TokenStream ts) {
/////////////////////////////////////////////////////////////////////////
1:       if (firstTime) {
1:         firstTime = false;
1:       } else {
0:   private static class TokenStreamIterator implements Iterator<String> {
0:     private final TokenStream tokenStream;
0:     private String bufferedToken;
0:     private TokenStreamIterator(TokenStream tokenStream) {
/////////////////////////////////////////////////////////////////////////
0:         boolean r;
/////////////////////////////////////////////////////////////////////////
0:      * @throws NoSuchElementException iteration has no more elements.
/////////////////////////////////////////////////////////////////////////
0:   private static class TokenizationException extends RuntimeException {
0:     private TokenizationException(String msg, Throwable cause) {
author:Robin Anil
-------------------------------------------------------------------------------
commit:5a7067b
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.vectorizer.encoders;
author:Ted Dunning
-------------------------------------------------------------------------------
commit:fbf804b
/////////////////////////////////////////////////////////////////////////
0:           bufferedToken = tokenStream.getAttribute(TermAttribute.class).term();
commit:6c34155
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.vectors;
1: 
1: import org.apache.lucene.analysis.Analyzer;
1: import org.apache.lucene.analysis.TokenStream;
0: import org.apache.lucene.analysis.tokenattributes.TermAttribute;
1: 
1: import java.io.IOException;
1: import java.io.Reader;
1: import java.nio.CharBuffer;
1: import java.util.Iterator;
0: import java.util.NoSuchElementException;
1: 
1: /**
1:  * Encodes text using a lucene style tokenizer.
1:  * @see TextValueEncoder
1:  */
1: public class LuceneTextValueEncoder extends TextValueEncoder {
1:   private Analyzer analyzer;
1: 
1:   public LuceneTextValueEncoder(String name) {
1:     super(name);
1:   }
1: 
1:   public void setAnalyzer(Analyzer analyzer) {
1:     this.analyzer = analyzer;
1:   }
1: 
1:   /**
1:    * Tokenizes a string using the simplest method.  This should be over-ridden for more subtle
1:    * tokenization.
1:    *
0:    * @param originalForm
0:    * @return
0:    * @see org.apache.mahout.vectors.LuceneTextValueEncoder
1:    */
1:   @Override
1:   protected Iterable<String> tokenize(CharSequence originalForm) {
0:     TokenStream ts = analyzer.tokenStream(getName(), new CharSequenceReader(originalForm));
0:     ts.addAttribute(TermAttribute.class);
0:     return new LuceneTokenIterable(ts);
1:   }
1: 
0:   private static class CharSequenceReader extends Reader {
0:     private CharBuffer buf;
1: 
1:     /**
1:      * Creates a new character-stream reader whose critical sections will synchronize on the reader
1:      * itself.
1:      */
1:     private CharSequenceReader(CharSequence input) {
1:       int n = input.length();
1:       buf = CharBuffer.allocate(n);
1:       for (int i = 0; i < n; i++) {
1:         buf.put(input.charAt(i));
1:       }
1:     }
1: 
1:     /**
1:      * Reads characters into a portion of an array.  This method will block until some input is
1:      * available, an I/O error occurs, or the end of the stream is reached.
1:      *
1:      * @param cbuf Destination buffer
1:      * @param off  Offset at which to start storing characters
1:      * @param len  Maximum number of characters to read
1:      * @return The number of characters read, or -1 if the end of the stream has been reached
0:      * @throws java.io.IOException If an I/O error occurs
1:      */
1:     @Override
0:     public int read(char[] cbuf, int off, int len) throws IOException {
0:       buf.get(cbuf, off, len);
0:       return len;
1:     }
1: 
1:     /**
0:      * Closes the stream and releases any system resources associated with it.  Once the stream has
0:      * been closed, further read(), ready(), mark(), reset(), or skip() invocations will throw an
0:      * IOException. Closing a previously closed stream has no effect.
1:      *
0:      * @throws java.io.IOException If an I/O error occurs
1:      */
1:     @Override
0:     public void close() throws IOException {
1:       // do nothing
1:     }
1:   }
1: 
0:   private class LuceneTokenIterable implements Iterable<String> {
1:     private boolean firstTime = true;
0:     private TokenStream tokenStream;
1: 
0:     public LuceneTokenIterable(TokenStream ts) {
0:       this.tokenStream = ts;
1:     }
1: 
1:     /**
1:      * Returns an iterator over a set of elements of type T.
1:      *
1:      * @return an Iterator.
1:      */
1:     @Override
1:     public Iterator<String> iterator() {
0:       if (!firstTime) {
0:         try {
1:           tokenStream.reset();
1:         } catch (IOException e) {
1:           throw new IllegalStateException("This token stream can't be reset");
1:         }
0:       } else {
0:         firstTime = false;
1:       }
1: 
1:       return new TokenStreamIterator(tokenStream);
1:     }
1:   }
1: 
0:   private class TokenStreamIterator implements Iterator<String> {
0:     private TokenStream tokenStream;
0:     private String bufferedToken = null;
1: 
0:     public TokenStreamIterator(TokenStream tokenStream) {
0:       this.tokenStream = tokenStream;
1:     }
1: 
1:     /**
0:      * Returns <tt>true</tt> if the iteration has more elements. (In other words, returns <tt>true</tt>
0:      * if <tt>next</tt> would return an element rather than throwing an exception.)
1:      *
0:      * @return <tt>true</tt> if the iterator has more elements.
1:      */
1:     @Override
0:     public boolean hasNext() {
0:       if (bufferedToken == null) {
0:         boolean r = false;
0:         try {
0:           r = tokenStream.incrementToken();
1:         } catch (IOException e) {
0:           throw new TokenizationException("IO error while tokenizing", e);
1:         }
0:         if (r) {
0:           bufferedToken = tokenStream.getAttribute(TermAttribute.class).toString();
1:         }
0:         return r;
0:       } else {
0:         return true;
1:       }
1:     }
1: 
1:     /**
0:      * Returns the next element in the iteration.
1:      *
0:      * @return the next element in the iteration.
0:      * @throws java.util.NoSuchElementException
0:      *          iteration has no more elements.
1:      */
1:     @Override
0:     public String next() {
0:       if (bufferedToken != null) {
0:         String r = bufferedToken;
0:         bufferedToken = null;
0:         return r;
0:       } else if (hasNext()) {
0:         return next();
0:       } else {
0:         throw new NoSuchElementException("Ran off end if token stream");
1:       }
1:     }
1: 
1:     @Override
0:     public void remove() {
0:       throw new UnsupportedOperationException("Can't remove tokens");
1:     }
1:   }
1: 
0:   private class TokenizationException extends RuntimeException {
0:     public TokenizationException(String msg, Throwable cause) {
0:       super(msg, cause);
1:     }
1:   }
1: }
============================================================================
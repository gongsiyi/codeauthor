1:5fc5b65: /*
1:5fc5b65:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:5fc5b65:  * contributor license agreements.  See the NOTICE file distributed with
1:5fc5b65:  * this work for additional information regarding copyright ownership.
1:5fc5b65:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:5fc5b65:  * (the "License"); you may not use this file except in compliance with
1:5fc5b65:  * the License.  You may obtain a copy of the License at
1:5fc5b65:  *
1:5fc5b65:  *     http://www.apache.org/licenses/LICENSE-2.0
1:5fc5b65:  *
1:5fc5b65:  * Unless required by applicable law or agreed to in writing, software
1:5fc5b65:  * distributed under the License is distributed on an "AS IS" BASIS,
1:5fc5b65:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:5fc5b65:  * See the License for the specific language governing permissions and
1:5fc5b65:  * limitations under the License.
1:5fc5b65:  */
5:5fc5b65: 
1:5fc5b65: package org.apache.mahout.math.solver;
1:5fc5b65: 
1:5fc5b65: import org.apache.mahout.math.DenseVector;
1:5fc5b65: import org.apache.mahout.math.Matrix;
1:5fc5b65: import org.apache.mahout.math.Vector;
1:5fc5b65: import org.apache.mahout.math.function.Functions;
1:5fc5b65: import org.slf4j.Logger;
1:5fc5b65: import org.slf4j.LoggerFactory;
1:5fc5b65: 
1:5fc5b65: /**
1:5fc5b65:  * Solves sparse least-squares using the LSMR algorithm.
1:5fc5b65:  * <p/>
1:5fc5b65:  * LSMR solves the system of linear equations A * X = B. If the system is inconsistent, it solves
1:5fc5b65:  * the least-squares problem min ||b - Ax||_2. A is a rectangular matrix of dimension m-by-n, where
1:5fc5b65:  * all cases are allowed: m=n, m>n, or m&lt;n. B is a vector of length m. The matrix A may be dense
1:5fc5b65:  * or sparse (usually sparse).
1:5fc5b65:  * <p/>
1:5fc5b65:  * Some additional configurable properties adjust the behavior of the algorithm.
1:5fc5b65:  * <p/>
1:5fc5b65:  * If you set lambda to a non-zero value then LSMR solves the regularized least-squares problem min
1:5fc5b65:  * ||(B) - (   A    )X|| ||(0)   (lambda*I) ||_2 where LAMBDA is a scalar.  If LAMBDA is not set,
1:5fc5b65:  * the system is solved without regularization.
1:5fc5b65:  * <p/>
1:5fc5b65:  * You can also set aTolerance and bTolerance.  These cause LSMR to iterate until a certain backward
1:5fc5b65:  * error estimate is smaller than some quantity depending on ATOL and BTOL.  Let RES = B - A*X be
1:5fc5b65:  * the residual vector for the current approximate solution X.  If A*X = B seems to be consistent,
1:5fc5b65:  * LSMR terminates when NORM(RES) <= ATOL*NORM(A)*NORM(X) + BTOL*NORM(B). Otherwise, LSMR terminates
1:5fc5b65:  * when NORM(A'*RES) <= ATOL*NORM(A)*NORM(RES). If both tolerances are 1.0e-6 (say), the final
1:5fc5b65:  * NORM(RES) should be accurate to about 6 digits. (The final X will usually have fewer correct
1:5fc5b65:  * digits, depending on cond(A) and the size of LAMBDA.)
1:5fc5b65:  * <p/>
1:5fc5b65:  * The default value for ATOL and BTOL is 1e-6.
1:5fc5b65:  * <p/>
1:5fc5b65:  * Ideally, they should be estimates of the relative error in the entries of A and B respectively.
1:5fc5b65:  * For example, if the entries of A have 7 correct digits, set ATOL = 1e-7. This prevents the
1:5fc5b65:  * algorithm from doing unnecessary work beyond the uncertainty of the input data.
1:5fc5b65:  * <p/>
1:5fc5b65:  * You can also set conditionLimit.  In that case, LSMR terminates if an estimate of cond(A) exceeds
1:5fc5b65:  * conditionLimit. For compatible systems Ax = b, conditionLimit could be as large as 1.0e+12 (say).
1:5fc5b65:  * For least-squares problems, conditionLimit should be less than 1.0e+8. If conditionLimit is not
1:5fc5b65:  * set, the default value is 1e+8. Maximum precision can be obtained by setting aTolerance =
1:5fc5b65:  * bTolerance = conditionLimit = 0, but the number of iterations may then be excessive.
1:5fc5b65:  * <p/>
1:5fc5b65:  * Setting iterationLimit causes LSMR to terminate if the number of iterations reaches
1:5fc5b65:  * iterationLimit.  The default is iterationLimit = min(m,n).   For ill-conditioned systems, a
1:5fc5b65:  * larger value of ITNLIM may be needed.
1:5fc5b65:  * <p/>
1:5fc5b65:  * Setting localSize causes LSMR to run with rerorthogonalization on the last localSize v_k's.
1:5fc5b65:  * (v-vectors generated by Golub-Kahan bidiagonalization) If localSize is not set, LSMR runs without
1:5fc5b65:  * reorthogonalization. A localSize > max(n,m) performs reorthogonalization on all v_k's.
1:5fc5b65:  * Reorthgonalizing only u_k or both u_k and v_k are not an option here. Details are discussed in
1:5fc5b65:  * the SIAM paper.
1:5fc5b65:  * <p/>
1:5fc5b65:  * getTerminationReason() gives the reason for termination. ISTOP  = 0 means X=0 is a solution. = 1
1:5fc5b65:  * means X is an approximate solution to A*X = B, according to ATOL and BTOL. = 2 means X
1:5fc5b65:  * approximately solves the least-squares problem according to ATOL. = 3 means COND(A) seems to be
1:5fc5b65:  * greater than CONLIM. = 4 is the same as 1 with ATOL = BTOL = EPS. = 5 is the same as 2 with ATOL
1:5fc5b65:  * = EPS. = 6 is the same as 3 with CONLIM = 1/EPS. = 7 means ITN reached ITNLIM before the other
1:5fc5b65:  * stopping conditions were satisfied.
1:5fc5b65:  * <p/>
1:5fc5b65:  * getIterationCount() gives ITN = the number of LSMR iterations.
1:5fc5b65:  * <p/>
1:5fc5b65:  * getResidualNorm() gives an estimate of the residual norm: NORMR = norm(B-A*X).
1:5fc5b65:  * <p/>
1:5fc5b65:  * getNormalEquationResidual() gives an estimate of the residual for the normal equation: NORMAR =
1:5fc5b65:  * NORM(A'*(B-A*X)).
1:5fc5b65:  * <p/>
1:5fc5b65:  * getANorm() gives an estimate of the Frobenius norm of A.
1:5fc5b65:  * <p/>
1:5fc5b65:  * getCondition() gives an estimate of the condition number of A.
1:5fc5b65:  * <p/>
1:5fc5b65:  * getXNorm() gives an estimate of NORM(X).
1:5fc5b65:  * <p/>
1:5fc5b65:  * LSMR uses an iterative method. For further information, see D. C.-L. Fong and M. A. Saunders
1:5fc5b65:  * LSMR: An iterative algorithm for least-square problems Draft of 03 Apr 2010, to be submitted to
1:5fc5b65:  * SISC.
1:5fc5b65:  * <p/>
1:5fc5b65:  * David Chin-lung Fong            clfong@stanford.edu Institute for Computational and Mathematical
1:5fc5b65:  * Engineering Stanford University
1:5fc5b65:  * <p/>
1:5fc5b65:  * Michael Saunders                saunders@stanford.edu Systems Optimization Laboratory Dept of
1:5fc5b65:  * MS&E, Stanford University. -----------------------------------------------------------------------
1:5fc5b65:  */
1:8b6a26a: public final class LSMR {
1:e0ec7c1: 
1:e0ec7c1:   private static final Logger log = LoggerFactory.getLogger(LSMR.class);
1:e0ec7c1: 
1:8b6a26a:   private final double lambda;
1:5fc5b65:   private int localSize;
1:5fc5b65:   private int iterationLimit;
1:5fc5b65:   private double conditionLimit;
1:5fc5b65:   private double bTolerance;
1:5fc5b65:   private double aTolerance;
1:5fc5b65:   private int localPointer;
1:5fc5b65:   private Vector[] localV;
1:5fc5b65:   private double residualNorm;
1:5fc5b65:   private double normalEquationResidual;
1:5fc5b65:   private double xNorm;
1:5fc5b65:   private int iteration;
1:5fc5b65:   private double normA;
1:5fc5b65:   private double condA;
1:5fc5b65: 
1:5fc5b65:   public int getIterationCount() {
1:5fc5b65:     return iteration;
3:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getResidualNorm() {
1:5fc5b65:     return residualNorm;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getNormalEquationResidual() {
1:5fc5b65:     return normalEquationResidual;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getANorm() {
1:5fc5b65:     return normA;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getCondition() {
1:5fc5b65:     return condA;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getXNorm() {
1:5fc5b65:     return xNorm;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   /**
1:5fc5b65:    * LSMR uses an iterative method to solve a linear system. For further information, see D. C.-L.
1:5fc5b65:    * Fong and M. A. Saunders LSMR: An iterative algorithm for least-square problems Draft of 03 Apr
1:5fc5b65:    * 2010, to be submitted to SISC.
1:5fc5b65:    * <p/>
1:5fc5b65:    * 08 Dec 2009: First release version of LSMR. 09 Apr 2010: Updated documentation and default
1:5fc5b65:    * parameters. 14 Apr 2010: Updated documentation. 03 Jun 2010: LSMR with local
1:5fc5b65:    * reorthogonalization (full reorthogonalization is also implemented)
1:5fc5b65:    * <p/>
1:5fc5b65:    * David Chin-lung Fong            clfong@stanford.edu Institute for Computational and
1:5fc5b65:    * Mathematical Engineering Stanford University
1:5fc5b65:    * <p/>
1:5fc5b65:    * Michael Saunders                saunders@stanford.edu Systems Optimization Laboratory Dept of
1:5fc5b65:    * MS&E, Stanford University. -----------------------------------------------------------------------
1:5fc5b65:    */
1:5fc5b65: 
1:5fc5b65:   public LSMR() {
1:5fc5b65:     // Set default parameters.
1:e0ec7c1:     lambda = 0;
1:e0ec7c1:     aTolerance = 1.0e-6;
1:e0ec7c1:     bTolerance = 1.0e-6;
1:e0ec7c1:     conditionLimit = 1.0e8;
1:e0ec7c1:     iterationLimit = -1;
1:e0ec7c1:     localSize = 0;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public Vector solve(Matrix A, Vector b) {
1:5fc5b65:     /*
1:5fc5b65:         % Initialize.
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:         hdg1 = '   itn      x(1)       norm r    norm A''r';
1:5fc5b65:         hdg2 = ' compatible   LS      norm A   cond A';
1:5fc5b65:         pfreq  = 20;   % print frequency (for repeating the heading)
1:5fc5b65:         pcount = 0;    % print counter
1:5fc5b65: 
1:5fc5b65:         % Determine dimensions m and n, and
1:5fc5b65:         % form the first vectors u and v.
1:5fc5b65:         % These satisfy  beta*u = b,  alpha*v = A'u.
1:5fc5b65:     */
1:5fc5b65:     log.debug("   itn         x(1)     norm r   norm A'r");
1:5fc5b65:     log.debug("   compatible   LS      norm A   cond A");
1:5fc5b65: 
1:5fc5b65:     Matrix transposedA = A.transpose();
1:5fc5b65:     Vector u = b;
1:5fc5b65: 
1:5fc5b65:     double beta = u.norm(2);
1:5fc5b65:     if (beta > 0) {
1:5fc5b65:       u = u.divide(beta);
1:5fc5b65:     }
1:5fc5b65: 
1:e0ec7c1:     Vector v = transposedA.times(u);
1:5fc5b65:     int m = A.numRows();
1:5fc5b65:     int n = A.numCols();
1:5fc5b65: 
1:5fc5b65:     int minDim = Math.min(m, n);
1:5fc5b65:     if (iterationLimit == -1) {
1:e0ec7c1:       iterationLimit = minDim;
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65:     if (log.isDebugEnabled()) {
1:6d16230:       log.debug("LSMR - Least-squares solution of  Ax = b, based on Matlab Version 1.02, 14 Apr 2010, "
1:6d16230:         +  "Mahout version {}", getClass().getPackage().getImplementationVersion());
1:5fc5b65:       log.debug(String.format("The matrix A has %d rows  and %d cols, lambda = %.4g, atol = %g, btol = %g",
1:e0ec7c1:         m, n, lambda, aTolerance, bTolerance));
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65:     double alpha = v.norm(2);
1:5fc5b65:     if (alpha > 0) {
1:5fc5b65:       v.assign(Functions.div(alpha));
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:     // Initialization for local reorthogonalization
1:5fc5b65:     localPointer = 0;
1:5fc5b65: 
1:5fc5b65:     // Preallocate storage for storing the last few v_k. Since with
1:5fc5b65:     // orthogonal v_k's, Krylov subspace method would converge in not
1:5fc5b65:     // more iterations than the number of singular values, more
1:5fc5b65:     // space is not necessary.
1:5fc5b65:     localV = new Vector[Math.min(localSize, minDim)];
1:e0ec7c1:     boolean localOrtho = false;
1:5fc5b65:     if (localSize > 0) {
1:5fc5b65:       localOrtho = true;
1:5fc5b65:       localV[0] = v;
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:     // Initialize variables for 1st iteration.
1:5fc5b65: 
1:5fc5b65:     iteration = 0;
1:5fc5b65:     double zetabar = alpha * beta;
1:5fc5b65:     double alphabar = alpha;
1:5fc5b65: 
1:5fc5b65:     Vector h = v;
1:5fc5b65:     Vector hbar = zeros(n);
1:5fc5b65:     Vector x = zeros(n);
1:5fc5b65: 
1:5fc5b65:     // Initialize variables for estimation of ||r||.
1:5fc5b65: 
1:5fc5b65:     double betadd = beta;
1:5fc5b65: 
1:5fc5b65:     // Initialize variables for estimation of ||A|| and cond(A)
1:5fc5b65: 
1:e0ec7c1:     double aNorm = alpha * alpha;
1:5fc5b65: 
1:5fc5b65:     // Items for use in stopping rules.
1:5fc5b65:     double normb = beta;
1:5fc5b65: 
1:5fc5b65:     double ctol = 0;
1:5fc5b65:     if (conditionLimit > 0) {
1:5fc5b65:       ctol = 1 / conditionLimit;
1:5fc5b65:     }
1:5fc5b65:     residualNorm = beta;
1:5fc5b65: 
1:5fc5b65:     // Exit if b=0 or A'b = 0.
1:5fc5b65: 
1:5fc5b65:     normalEquationResidual = alpha * beta;
1:5fc5b65:     if (normalEquationResidual == 0) {
1:5fc5b65:       return x;
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65:     // Heading for iteration log.
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:     if (log.isDebugEnabled()) {
1:5fc5b65:       double test2 = alpha / beta;
1:5fc5b65: //      log.debug('{} {}', hdg1, hdg2);
1:5fc5b65:       log.debug("{} {}", iteration, x.get(0));
1:5fc5b65:       log.debug("{} {}", residualNorm, normalEquationResidual);
1:e0ec7c1:       double test1 = 1;
1:5fc5b65:       log.debug("{} {}", test1, test2);
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:     //------------------------------------------------------------------
1:5fc5b65:     //     Main iteration loop.
1:5fc5b65:     //------------------------------------------------------------------
1:e0ec7c1:     double rho = 1;
1:e0ec7c1:     double rhobar = 1;
1:e0ec7c1:     double cbar = 1;
1:e0ec7c1:     double sbar = 0;
1:e0ec7c1:     double betad = 0;
1:e0ec7c1:     double rhodold = 1;
1:e0ec7c1:     double tautildeold = 0;
1:e0ec7c1:     double thetatilde = 0;
1:e0ec7c1:     double zeta = 0;
1:e0ec7c1:     double d = 0;
1:e0ec7c1:     double maxrbar = 0;
1:e0ec7c1:     double minrbar = 1.0e+100;
1:e0ec7c1:     StopCode stop = StopCode.CONTINUE;
1:5fc5b65:     while (iteration <= iterationLimit && stop == StopCode.CONTINUE) {
1:5fc5b65: 
1:e0ec7c1:       iteration++;
1:5fc5b65: 
1:5fc5b65:       // Perform the next step of the bidiagonalization to obtain the
1:5fc5b65:       // next beta, u, alpha, v.  These satisfy the relations
1:5fc5b65:       //      beta*u  =  A*v  - alpha*u,
1:5fc5b65:       //      alpha*v  =  A'*u - beta*v.
1:5fc5b65: 
1:5fc5b65:       u = A.times(v).minus(u.times(alpha));
1:5fc5b65:       beta = u.norm(2);
1:5fc5b65:       if (beta > 0) {
1:5fc5b65:         u.assign(Functions.div(beta));
1:5fc5b65: 
1:5fc5b65:         // store data for local-reorthogonalization of V
1:5fc5b65:         if (localOrtho) {
1:5fc5b65:           localVEnqueue(v);
1:5fc5b65:         }
1:5fc5b65:         v = transposedA.times(u).minus(v.times(beta));
1:5fc5b65:         // local-reorthogonalization of V
1:5fc5b65:         if (localOrtho) {
1:5fc5b65:           v = localVOrtho(v);
1:5fc5b65:         }
1:5fc5b65:         alpha = v.norm(2);
1:5fc5b65:         if (alpha > 0) {
1:5fc5b65:           v.assign(Functions.div(alpha));
1:5fc5b65:         }
1:5fc5b65:       }
1:5fc5b65: 
1:5fc5b65:       // At this point, beta = beta_{k+1}, alpha = alpha_{k+1}.
1:5fc5b65: 
1:5fc5b65:       // Construct rotation Qhat_{k,2k+1}.
1:5fc5b65: 
1:5fc5b65:       double alphahat = Math.hypot(alphabar, lambda);
1:5fc5b65:       double chat = alphabar / alphahat;
1:5fc5b65:       double shat = lambda / alphahat;
1:5fc5b65: 
1:5fc5b65:       // Use a plane rotation (Q_i) to turn B_i to R_i
1:5fc5b65: 
1:5fc5b65:       double rhoold = rho;
1:5fc5b65:       rho = Math.hypot(alphahat, beta);
1:5fc5b65:       double c = alphahat / rho;
1:5fc5b65:       double s = beta / rho;
1:5fc5b65:       double thetanew = s * alpha;
1:5fc5b65:       alphabar = c * alpha;
1:5fc5b65: 
1:5fc5b65:       // Use a plane rotation (Qbar_i) to turn R_i^T to R_i^bar
1:5fc5b65: 
1:5fc5b65:       double rhobarold = rhobar;
1:5fc5b65:       double zetaold = zeta;
1:5fc5b65:       double thetabar = sbar * rho;
1:5fc5b65:       double rhotemp = cbar * rho;
1:5fc5b65:       rhobar = Math.hypot(cbar * rho, thetanew);
1:5fc5b65:       cbar = cbar * rho / rhobar;
1:5fc5b65:       sbar = thetanew / rhobar;
1:5fc5b65:       zeta = cbar * zetabar;
1:5fc5b65:       zetabar = -sbar * zetabar;
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:       // Update h, h_hat, x.
1:5fc5b65: 
1:5fc5b65:       hbar = h.minus(hbar.times(thetabar * rho / (rhoold * rhobarold)));
1:5fc5b65: 
1:5fc5b65:       x.assign(hbar.times(zeta / (rho * rhobar)), Functions.PLUS);
1:5fc5b65:       h = v.minus(h.times(thetanew / rho));
1:5fc5b65: 
1:5fc5b65:       // Estimate of ||r||.
1:5fc5b65: 
1:5fc5b65:       // Apply rotation Qhat_{k,2k+1}.
1:5fc5b65:       double betaacute = chat * betadd;
1:5fc5b65:       double betacheck = -shat * betadd;
1:5fc5b65: 
1:5fc5b65:       // Apply rotation Q_{k,k+1}.
1:5fc5b65:       double betahat = c * betaacute;
1:5fc5b65:       betadd = -s * betaacute;
1:5fc5b65: 
1:5fc5b65:       // Apply rotation Qtilde_{k-1}.
1:5fc5b65:       // betad = betad_{k-1} here.
1:5fc5b65: 
1:5fc5b65:       double thetatildeold = thetatilde;
1:5fc5b65:       double rhotildeold = Math.hypot(rhodold, thetabar);
1:5fc5b65:       double ctildeold = rhodold / rhotildeold;
1:5fc5b65:       double stildeold = thetabar / rhotildeold;
1:5fc5b65:       thetatilde = stildeold * rhobar;
1:5fc5b65:       rhodold = ctildeold * rhobar;
1:5fc5b65:       betad = -stildeold * betad + ctildeold * betahat;
1:5fc5b65: 
1:5fc5b65:       // betad   = betad_k here.
1:5fc5b65:       // rhodold = rhod_k  here.
1:5fc5b65: 
1:5fc5b65:       tautildeold = (zetaold - thetatildeold * tautildeold) / rhotildeold;
1:5fc5b65:       double taud = (zeta - thetatilde * tautildeold) / rhodold;
1:e0ec7c1:       d += betacheck * betacheck;
1:5fc5b65:       residualNorm = Math.sqrt(d + (betad - taud) * (betad - taud) + betadd * betadd);
1:5fc5b65: 
1:5fc5b65:       // Estimate ||A||.
1:e0ec7c1:       aNorm += beta * beta;
1:5fc5b65:       normA = Math.sqrt(aNorm);
1:e0ec7c1:       aNorm += alpha * alpha;
1:5fc5b65: 
1:5fc5b65:       // Estimate cond(A).
1:5fc5b65:       maxrbar = Math.max(maxrbar, rhobarold);
1:5fc5b65:       if (iteration > 1) {
1:5fc5b65:         minrbar = Math.min(minrbar, rhobarold);
1:5fc5b65:       }
1:5fc5b65:       condA = Math.max(maxrbar, rhotemp) / Math.min(minrbar, rhotemp);
1:5fc5b65: 
1:5fc5b65:       // Test for convergence.
1:5fc5b65: 
1:5fc5b65:       // Compute norms for convergence testing.
1:5fc5b65:       normalEquationResidual = Math.abs(zetabar);
1:5fc5b65:       xNorm = x.norm(2);
1:5fc5b65: 
1:5fc5b65:       // Now use these norms to estimate certain other quantities,
1:5fc5b65:       // some of which will be small near a solution.
1:5fc5b65: 
1:5fc5b65:       double test1 = residualNorm / normb;
1:5fc5b65:       double test2 = normalEquationResidual / (normA * residualNorm);
1:5fc5b65:       double test3 = 1 / condA;
1:5fc5b65:       double t1 = test1 / (1 + normA * xNorm / normb);
1:5fc5b65:       double rtol = bTolerance + aTolerance * normA * xNorm / normb;
1:5fc5b65: 
1:5fc5b65:       // The following tests guard against extremely small values of
1:5fc5b65:       // atol, btol or ctol.  (The user may have set any or all of
1:5fc5b65:       // the parameters atol, btol, conlim  to 0.)
1:5fc5b65:       // The effect is equivalent to the normAl tests using
1:5fc5b65:       // atol = eps,  btol = eps,  conlim = 1/eps.
1:5fc5b65: 
1:5fc5b65:       if (iteration > iterationLimit) {
1:5fc5b65:         stop = StopCode.ITERATION_LIMIT;
1:5fc5b65:       }
1:5fc5b65:       if (1 + test3 <= 1) {
1:5fc5b65:         stop = StopCode.CONDITION_MACHINE_TOLERANCE;
1:5fc5b65:       }
1:5fc5b65:       if (1 + test2 <= 1) {
1:5fc5b65:         stop = StopCode.LEAST_SQUARE_CONVERGED_MACHINE_TOLERANCE;
1:5fc5b65:       }
1:5fc5b65:       if (1 + t1 <= 1) {
1:5fc5b65:         stop = StopCode.CONVERGED_MACHINE_TOLERANCE;
1:5fc5b65:       }
1:5fc5b65: 
1:5fc5b65:       // Allow for tolerances set by the user.
1:5fc5b65: 
1:5fc5b65:       if (test3 <= ctol) {
1:5fc5b65:         stop = StopCode.CONDITION;
1:5fc5b65:       }
1:5fc5b65:       if (test2 <= aTolerance) {
1:5fc5b65:         stop = StopCode.CONVERGED;
1:5fc5b65:       }
1:5fc5b65:       if (test1 <= rtol) {
1:5fc5b65:         stop = StopCode.TRIVIAL;
1:5fc5b65:       }
1:5fc5b65: 
1:5fc5b65:       // See if it is time to print something.
1:5fc5b65:       if (log.isDebugEnabled()) {
1:6d16230:         if ((n <= 40) || (iteration <= 10) || (iteration >= iterationLimit - 10) || ((iteration % 10) == 0)
1:6d16230:               || (test3 <= 1.1 * ctol) || (test2 <= 1.1 * aTolerance) || (test1 <= 1.1 * rtol)
1:6d16230:               || (stop != StopCode.CONTINUE)) {
1:5fc5b65:           statusDump(x, normA, condA, test1, test2);
1:5fc5b65:         }
1:5fc5b65:       }
1:5fc5b65:     } // iteration loop
1:5fc5b65: 
1:5fc5b65:     // Print the stopping condition.
1:5fc5b65:     log.debug("Finished: {}", stop.getMessage());
1:5fc5b65: 
1:5fc5b65:     return x;
1:5fc5b65:     /*
1:5fc5b65: 
1:5fc5b65: 
1:5fc5b65:     if show
1:5fc5b65:       fprintf('\n\nLSMR finished')
1:5fc5b65:       fprintf('\n%s', msg(istop+1,:))
1:5fc5b65:       fprintf('\nistop =%8g    normr =%8.1e'     , istop, normr )
1:5fc5b65:       fprintf('    normA =%8.1e    normAr =%8.1e', normA, normAr)
1:5fc5b65:       fprintf('\nitn   =%8g    condA =%8.1e'     , itn  , condA )
1:5fc5b65:       fprintf('    normx =%8.1e\n', normx)
1:5fc5b65:     end
1:5fc5b65:     */
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   private void statusDump(Vector x, double normA, double condA, double test1, double test2) {
1:5fc5b65:     log.debug("{} {}", residualNorm, normalEquationResidual);
1:5fc5b65:     log.debug("{} {}", iteration, x.get(0));
1:5fc5b65:     log.debug("{} {}", test1, test2);
1:5fc5b65:     log.debug("{} {}", normA, condA);
1:5fc5b65:   }
1:5fc5b65: 
1:e0ec7c1:   private static Vector zeros(int n) {
1:5fc5b65:     return new DenseVector(n);
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   //-----------------------------------------------------------------------
1:5fc5b65:   // stores v into the circular buffer localV
1:5fc5b65:   //-----------------------------------------------------------------------
1:5fc5b65: 
1:5fc5b65:   private void localVEnqueue(Vector v) {
1:5fc5b65:     if (localV.length > 0) {
1:5fc5b65:       localV[localPointer] = v;
1:5fc5b65:       localPointer = (localPointer + 1) % localV.length;
1:5fc5b65:     }
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   //-----------------------------------------------------------------------
1:5fc5b65:   // Perform local reorthogonalization of V
1:5fc5b65:   //-----------------------------------------------------------------------
1:5fc5b65: 
1:5fc5b65:   private Vector localVOrtho(Vector v) {
1:5fc5b65:     for (Vector old : localV) {
1:5fc5b65:       if (old != null) {
1:5fc5b65:         double x = v.dot(old);
1:5fc5b65:         v = v.minus(old.times(x));
1:5fc5b65:       }
1:5fc5b65:     }
1:5fc5b65:     return v;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   private enum StopCode {
1:5fc5b65:     CONTINUE("Not done"),
1:5fc5b65:     TRIVIAL("The exact solution is  x = 0"),
1:6d16230:     CONVERGED("Ax - b is small enough, given atol, btol"),
1:6d16230:     LEAST_SQUARE_CONVERGED("The least-squares solution is good enough, given atol"),
1:5fc5b65:     CONDITION("The estimate of cond(Abar) has exceeded condition limit"),
1:5fc5b65:     CONVERGED_MACHINE_TOLERANCE("Ax - b is small enough for this machine"),
1:5fc5b65:     LEAST_SQUARE_CONVERGED_MACHINE_TOLERANCE("The least-squares solution is good enough for this machine"),
1:5fc5b65:     CONDITION_MACHINE_TOLERANCE("Cond(Abar) seems to be too large for this machine"),
1:5fc5b65:     ITERATION_LIMIT("The iteration limit has been reached");
1:5fc5b65: 
1:e0ec7c1:     private final String message;
1:5fc5b65: 
1:e0ec7c1:     StopCode(String message) {
1:5fc5b65:       this.message = message;
1:5fc5b65:     }
1:5fc5b65: 
1:5fc5b65:     public String getMessage() {
1:5fc5b65:       return message;
1:5fc5b65:     }
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public void setAtolerance(double aTolerance) {
1:5fc5b65:     this.aTolerance = aTolerance;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public void setBtolerance(double bTolerance) {
1:5fc5b65:     this.bTolerance = bTolerance;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public void setConditionLimit(double conditionLimit) {
1:5fc5b65:     this.conditionLimit = conditionLimit;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public void setIterationLimit(int iterationLimit) {
1:5fc5b65:     this.iterationLimit = iterationLimit;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public void setLocalSize(int localSize) {
1:5fc5b65:     this.localSize = localSize;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getLambda() {
1:5fc5b65:     return lambda;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getAtolerance() {
1:5fc5b65:     return aTolerance;
1:5fc5b65:   }
1:5fc5b65: 
1:5fc5b65:   public double getBtolerance() {
1:5fc5b65:     return bTolerance;
1:5fc5b65:   }
1:5fc5b65: }
============================================================================
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:       log.debug("LSMR - Least-squares solution of  Ax = b, based on Matlab Version 1.02, 14 Apr 2010, "
1:         +  "Mahout version {}", getClass().getPackage().getImplementationVersion());
/////////////////////////////////////////////////////////////////////////
1:         if ((n <= 40) || (iteration <= 10) || (iteration >= iterationLimit - 10) || ((iteration % 10) == 0)
1:               || (test3 <= 1.1 * ctol) || (test2 <= 1.1 * aTolerance) || (test1 <= 1.1 * rtol)
1:               || (stop != StopCode.CONTINUE)) {
/////////////////////////////////////////////////////////////////////////
1:     CONVERGED("Ax - b is small enough, given atol, btol"),
1:     LEAST_SQUARE_CONVERGED("The least-squares solution is good enough, given atol"),
author:Ted Dunning
-------------------------------------------------------------------------------
commit:441c8b3
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         if ((n <= 40) || (iteration <= 10) || (iteration >= iterationLimit - 10) || ((iteration % 10) == 0) || (test3 <= 1.1 * ctol) || (test2 <= 1.1 * aTolerance) || (test1 <= 1.1 * rtol) || (stop != StopCode.CONTINUE)) {
commit:ac0abc6
/////////////////////////////////////////////////////////////////////////
0:       if (stop != StopCode.CONTINUE && stop.ordinal() != istop) {
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:8b6a26a
/////////////////////////////////////////////////////////////////////////
1: public final class LSMR {
1:   private final double lambda;
commit:229aeff
/////////////////////////////////////////////////////////////////////////
commit:e0ec7c1
/////////////////////////////////////////////////////////////////////////
1: 
1:   private static final Logger log = LoggerFactory.getLogger(LSMR.class);
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     lambda = 0;
1:     aTolerance = 1.0e-6;
1:     bTolerance = 1.0e-6;
1:     conditionLimit = 1.0e8;
1:     iterationLimit = -1;
1:     localSize = 0;
/////////////////////////////////////////////////////////////////////////
1:     Vector v = transposedA.times(u);
1:       iterationLimit = minDim;
1:         m, n, lambda, aTolerance, bTolerance));
/////////////////////////////////////////////////////////////////////////
1:     boolean localOrtho = false;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     double aNorm = alpha * alpha;
/////////////////////////////////////////////////////////////////////////
1:       double test1 = 1;
/////////////////////////////////////////////////////////////////////////
1:     double rho = 1;
1:     double rhobar = 1;
1:     double cbar = 1;
1:     double sbar = 0;
1:     double betad = 0;
1:     double rhodold = 1;
1:     double tautildeold = 0;
1:     double thetatilde = 0;
1:     double zeta = 0;
1:     double d = 0;
1:     double maxrbar = 0;
1:     double minrbar = 1.0e+100;
0:     int istop = 0;
1:     StopCode stop = StopCode.CONTINUE;
1:       iteration++;
/////////////////////////////////////////////////////////////////////////
1:       d += betacheck * betacheck;
1:       aNorm += beta * beta;
1:       aNorm += alpha * alpha;
/////////////////////////////////////////////////////////////////////////
1:   private static Vector zeros(int n) {
/////////////////////////////////////////////////////////////////////////
1:     private final String message;
1:     StopCode(String message) {
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:5fc5b65
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.math.solver;
1: 
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Matrix;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.function.Functions;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: /**
1:  * Solves sparse least-squares using the LSMR algorithm.
1:  * <p/>
1:  * LSMR solves the system of linear equations A * X = B. If the system is inconsistent, it solves
1:  * the least-squares problem min ||b - Ax||_2. A is a rectangular matrix of dimension m-by-n, where
1:  * all cases are allowed: m=n, m>n, or m&lt;n. B is a vector of length m. The matrix A may be dense
1:  * or sparse (usually sparse).
1:  * <p/>
1:  * Some additional configurable properties adjust the behavior of the algorithm.
1:  * <p/>
1:  * If you set lambda to a non-zero value then LSMR solves the regularized least-squares problem min
1:  * ||(B) - (   A    )X|| ||(0)   (lambda*I) ||_2 where LAMBDA is a scalar.  If LAMBDA is not set,
1:  * the system is solved without regularization.
1:  * <p/>
1:  * You can also set aTolerance and bTolerance.  These cause LSMR to iterate until a certain backward
1:  * error estimate is smaller than some quantity depending on ATOL and BTOL.  Let RES = B - A*X be
1:  * the residual vector for the current approximate solution X.  If A*X = B seems to be consistent,
1:  * LSMR terminates when NORM(RES) <= ATOL*NORM(A)*NORM(X) + BTOL*NORM(B). Otherwise, LSMR terminates
1:  * when NORM(A'*RES) <= ATOL*NORM(A)*NORM(RES). If both tolerances are 1.0e-6 (say), the final
1:  * NORM(RES) should be accurate to about 6 digits. (The final X will usually have fewer correct
1:  * digits, depending on cond(A) and the size of LAMBDA.)
1:  * <p/>
1:  * The default value for ATOL and BTOL is 1e-6.
1:  * <p/>
1:  * Ideally, they should be estimates of the relative error in the entries of A and B respectively.
1:  * For example, if the entries of A have 7 correct digits, set ATOL = 1e-7. This prevents the
1:  * algorithm from doing unnecessary work beyond the uncertainty of the input data.
1:  * <p/>
1:  * You can also set conditionLimit.  In that case, LSMR terminates if an estimate of cond(A) exceeds
1:  * conditionLimit. For compatible systems Ax = b, conditionLimit could be as large as 1.0e+12 (say).
1:  * For least-squares problems, conditionLimit should be less than 1.0e+8. If conditionLimit is not
1:  * set, the default value is 1e+8. Maximum precision can be obtained by setting aTolerance =
1:  * bTolerance = conditionLimit = 0, but the number of iterations may then be excessive.
1:  * <p/>
1:  * Setting iterationLimit causes LSMR to terminate if the number of iterations reaches
1:  * iterationLimit.  The default is iterationLimit = min(m,n).   For ill-conditioned systems, a
1:  * larger value of ITNLIM may be needed.
1:  * <p/>
1:  * Setting localSize causes LSMR to run with rerorthogonalization on the last localSize v_k's.
1:  * (v-vectors generated by Golub-Kahan bidiagonalization) If localSize is not set, LSMR runs without
1:  * reorthogonalization. A localSize > max(n,m) performs reorthogonalization on all v_k's.
1:  * Reorthgonalizing only u_k or both u_k and v_k are not an option here. Details are discussed in
1:  * the SIAM paper.
1:  * <p/>
1:  * getTerminationReason() gives the reason for termination. ISTOP  = 0 means X=0 is a solution. = 1
1:  * means X is an approximate solution to A*X = B, according to ATOL and BTOL. = 2 means X
1:  * approximately solves the least-squares problem according to ATOL. = 3 means COND(A) seems to be
1:  * greater than CONLIM. = 4 is the same as 1 with ATOL = BTOL = EPS. = 5 is the same as 2 with ATOL
1:  * = EPS. = 6 is the same as 3 with CONLIM = 1/EPS. = 7 means ITN reached ITNLIM before the other
1:  * stopping conditions were satisfied.
1:  * <p/>
1:  * getIterationCount() gives ITN = the number of LSMR iterations.
1:  * <p/>
1:  * getResidualNorm() gives an estimate of the residual norm: NORMR = norm(B-A*X).
1:  * <p/>
1:  * getNormalEquationResidual() gives an estimate of the residual for the normal equation: NORMAR =
1:  * NORM(A'*(B-A*X)).
1:  * <p/>
1:  * getANorm() gives an estimate of the Frobenius norm of A.
1:  * <p/>
1:  * getCondition() gives an estimate of the condition number of A.
1:  * <p/>
1:  * getXNorm() gives an estimate of NORM(X).
1:  * <p/>
1:  * LSMR uses an iterative method. For further information, see D. C.-L. Fong and M. A. Saunders
1:  * LSMR: An iterative algorithm for least-square problems Draft of 03 Apr 2010, to be submitted to
1:  * SISC.
1:  * <p/>
1:  * David Chin-lung Fong            clfong@stanford.edu Institute for Computational and Mathematical
1:  * Engineering Stanford University
1:  * <p/>
1:  * Michael Saunders                saunders@stanford.edu Systems Optimization Laboratory Dept of
1:  * MS&E, Stanford University. -----------------------------------------------------------------------
1:  */
0: public class LSMR {
0:   private Logger log = LoggerFactory.getLogger(LSMR.class);
0:   private double lambda;
1:   private int localSize;
1:   private int iterationLimit;
1:   private double conditionLimit;
1:   private double bTolerance;
1:   private double aTolerance;
1:   private int localPointer;
0:   private Vector v;
0:   private boolean localVQueueFull;
1:   private Vector[] localV;
1:   private double residualNorm;
1:   private double normalEquationResidual;
0:   private double aNorm;
1:   private double xNorm;
1:   private int iteration;
1:   private double normA;
1:   private double condA;
1: 
1:   public int getIterationCount() {
1:     return iteration;
1:   }
1: 
1:   public double getResidualNorm() {
1:     return residualNorm;
1:   }
1: 
1:   public double getNormalEquationResidual() {
1:     return normalEquationResidual;
1:   }
1: 
1:   public double getANorm() {
1:     return normA;
1:   }
1: 
1:   public double getCondition() {
1:     return condA;
1:   }
1: 
1:   public double getXNorm() {
1:     return xNorm;
1:   }
1: 
1:   /**
1:    * LSMR uses an iterative method to solve a linear system. For further information, see D. C.-L.
1:    * Fong and M. A. Saunders LSMR: An iterative algorithm for least-square problems Draft of 03 Apr
1:    * 2010, to be submitted to SISC.
1:    * <p/>
1:    * 08 Dec 2009: First release version of LSMR. 09 Apr 2010: Updated documentation and default
1:    * parameters. 14 Apr 2010: Updated documentation. 03 Jun 2010: LSMR with local
1:    * reorthogonalization (full reorthogonalization is also implemented)
1:    * <p/>
1:    * David Chin-lung Fong            clfong@stanford.edu Institute for Computational and
1:    * Mathematical Engineering Stanford University
1:    * <p/>
1:    * Michael Saunders                saunders@stanford.edu Systems Optimization Laboratory Dept of
1:    * MS&E, Stanford University. -----------------------------------------------------------------------
1:    */
1: 
1:   public LSMR() {
1:     // Set default parameters.
0:     setLambda(0);
0:     setAtolerance(1e-6);
0:     setBtolerance(1e-6);
0:     setConditionLimit(1e8);
0:     setIterationLimit(-1);
0:     setLocalSize(0);
1:   }
1: 
1:   public Vector solve(Matrix A, Vector b) {
1:     /*
1:         % Initialize.
1: 
1: 
1:         hdg1 = '   itn      x(1)       norm r    norm A''r';
1:         hdg2 = ' compatible   LS      norm A   cond A';
1:         pfreq  = 20;   % print frequency (for repeating the heading)
1:         pcount = 0;    % print counter
1: 
1:         % Determine dimensions m and n, and
1:         % form the first vectors u and v.
1:         % These satisfy  beta*u = b,  alpha*v = A'u.
1:     */
1:     log.debug("   itn         x(1)     norm r   norm A'r");
1:     log.debug("   compatible   LS      norm A   cond A");
1: 
1:     Matrix transposedA = A.transpose();
1:     Vector u = b;
1: 
1:     double beta = u.norm(2);
1:     if (beta > 0) {
1:       u = u.divide(beta);
1:     }
1: 
0:     v = transposedA.times(u);
1:     int m = A.numRows();
1:     int n = A.numCols();
1: 
1:     int minDim = Math.min(m, n);
1:     if (iterationLimit == -1) {
0:       setIterationLimit(minDim);
1:     }
1: 
1:     if (log.isDebugEnabled()) {
0:       log.debug("LSMR - Least-squares solution of  Ax = b, based on Matlab Version 1.02, 14 Apr 2010, Mahout version {}",
0:         this.getClass().getPackage().getImplementationVersion());
1:       log.debug(String.format("The matrix A has %d rows  and %d cols, lambda = %.4g, atol = %g, btol = %g",
0:         m, n, getLambda(), getAtolerance(), getBtolerance()));
1:     }
1: 
1:     double alpha = v.norm(2);
1:     if (alpha > 0) {
1:       v.assign(Functions.div(alpha));
1:     }
1: 
1: 
1:     // Initialization for local reorthogonalization
0:     boolean localOrtho = false;
1:     localPointer = 0;
0:     localVQueueFull = false;
1: 
1:     // Preallocate storage for storing the last few v_k. Since with
1:     // orthogonal v_k's, Krylov subspace method would converge in not
1:     // more iterations than the number of singular values, more
1:     // space is not necessary.
1:     localV = new Vector[Math.min(localSize, minDim)];
1:     if (localSize > 0) {
1:       localOrtho = true;
1:       localV[0] = v;
1:     }
1: 
1: 
1:     // Initialize variables for 1st iteration.
1: 
1:     iteration = 0;
1:     double zetabar = alpha * beta;
1:     double alphabar = alpha;
0:     double rho = 1;
0:     double rhobar = 1;
0:     double cbar = 1;
0:     double sbar = 0;
1: 
1:     Vector h = v;
1:     Vector hbar = zeros(n);
1:     Vector x = zeros(n);
1: 
1:     // Initialize variables for estimation of ||r||.
1: 
1:     double betadd = beta;
0:     double betad = 0;
0:     double rhodold = 1;
0:     double tautildeold = 0;
0:     double thetatilde = 0;
0:     double zeta = 0;
0:     double d = 0;
1: 
1:     // Initialize variables for estimation of ||A|| and cond(A)
1: 
0:     aNorm = alpha * alpha;
0:     double maxrbar = 0;
0:     double minrbar = 1e+100;
1: 
1:     // Items for use in stopping rules.
1:     double normb = beta;
1: 
0:     int istop = 0;
0:     StopCode stop = StopCode.CONTINUE;
1: 
1:     double ctol = 0;
1:     if (conditionLimit > 0) {
1:       ctol = 1 / conditionLimit;
1:     }
1:     residualNorm = beta;
1: 
1:     // Exit if b=0 or A'b = 0.
1: 
1:     normalEquationResidual = alpha * beta;
1:     if (normalEquationResidual == 0) {
1:       return x;
1:     }
1: 
1:     // Heading for iteration log.
1: 
1: 
1:     if (log.isDebugEnabled()) {
0:       double test1 = 1;
1:       double test2 = alpha / beta;
1: //      log.debug('{} {}', hdg1, hdg2);
1:       log.debug("{} {}", iteration, x.get(0));
1:       log.debug("{} {}", residualNorm, normalEquationResidual);
1:       log.debug("{} {}", test1, test2);
1:     }
1: 
1: 
1:     //------------------------------------------------------------------
1:     //     Main iteration loop.
1:     //------------------------------------------------------------------
1:     while (iteration <= iterationLimit && stop == StopCode.CONTINUE) {
1: 
0:       iteration = iteration + 1;
1: 
1:       // Perform the next step of the bidiagonalization to obtain the
1:       // next beta, u, alpha, v.  These satisfy the relations
1:       //      beta*u  =  A*v  - alpha*u,
1:       //      alpha*v  =  A'*u - beta*v.
1: 
1:       u = A.times(v).minus(u.times(alpha));
1:       beta = u.norm(2);
1:       if (beta > 0) {
1:         u.assign(Functions.div(beta));
1: 
1:         // store data for local-reorthogonalization of V
1:         if (localOrtho) {
1:           localVEnqueue(v);
1:         }
1:         v = transposedA.times(u).minus(v.times(beta));
1:         // local-reorthogonalization of V
1:         if (localOrtho) {
1:           v = localVOrtho(v);
1:         }
1:         alpha = v.norm(2);
1:         if (alpha > 0) {
1:           v.assign(Functions.div(alpha));
1:         }
1:       }
1: 
1:       // At this point, beta = beta_{k+1}, alpha = alpha_{k+1}.
1: 
1:       // Construct rotation Qhat_{k,2k+1}.
1: 
1:       double alphahat = Math.hypot(alphabar, lambda);
1:       double chat = alphabar / alphahat;
1:       double shat = lambda / alphahat;
1: 
1:       // Use a plane rotation (Q_i) to turn B_i to R_i
1: 
1:       double rhoold = rho;
1:       rho = Math.hypot(alphahat, beta);
1:       double c = alphahat / rho;
1:       double s = beta / rho;
1:       double thetanew = s * alpha;
1:       alphabar = c * alpha;
1: 
1:       // Use a plane rotation (Qbar_i) to turn R_i^T to R_i^bar
1: 
1:       double rhobarold = rhobar;
1:       double zetaold = zeta;
1:       double thetabar = sbar * rho;
1:       double rhotemp = cbar * rho;
1:       rhobar = Math.hypot(cbar * rho, thetanew);
1:       cbar = cbar * rho / rhobar;
1:       sbar = thetanew / rhobar;
1:       zeta = cbar * zetabar;
1:       zetabar = -sbar * zetabar;
1: 
1: 
1:       // Update h, h_hat, x.
1: 
1:       hbar = h.minus(hbar.times(thetabar * rho / (rhoold * rhobarold)));
1: 
1:       x.assign(hbar.times(zeta / (rho * rhobar)), Functions.PLUS);
1:       h = v.minus(h.times(thetanew / rho));
1: 
1:       // Estimate of ||r||.
1: 
1:       // Apply rotation Qhat_{k,2k+1}.
1:       double betaacute = chat * betadd;
1:       double betacheck = -shat * betadd;
1: 
1:       // Apply rotation Q_{k,k+1}.
1:       double betahat = c * betaacute;
1:       betadd = -s * betaacute;
1: 
1:       // Apply rotation Qtilde_{k-1}.
1:       // betad = betad_{k-1} here.
1: 
1:       double thetatildeold = thetatilde;
1:       double rhotildeold = Math.hypot(rhodold, thetabar);
1:       double ctildeold = rhodold / rhotildeold;
1:       double stildeold = thetabar / rhotildeold;
1:       thetatilde = stildeold * rhobar;
1:       rhodold = ctildeold * rhobar;
1:       betad = -stildeold * betad + ctildeold * betahat;
1: 
1:       // betad   = betad_k here.
1:       // rhodold = rhod_k  here.
1: 
1:       tautildeold = (zetaold - thetatildeold * tautildeold) / rhotildeold;
1:       double taud = (zeta - thetatilde * tautildeold) / rhodold;
0:       d = d + betacheck * betacheck;
1:       residualNorm = Math.sqrt(d + (betad - taud) * (betad - taud) + betadd * betadd);
1: 
1:       // Estimate ||A||.
0:       aNorm = aNorm + beta * beta;
1:       normA = Math.sqrt(aNorm);
0:       aNorm = aNorm + alpha * alpha;
1: 
1:       // Estimate cond(A).
1:       maxrbar = Math.max(maxrbar, rhobarold);
1:       if (iteration > 1) {
1:         minrbar = Math.min(minrbar, rhobarold);
1:       }
1:       condA = Math.max(maxrbar, rhotemp) / Math.min(minrbar, rhotemp);
1: 
1:       // Test for convergence.
1: 
1:       // Compute norms for convergence testing.
1:       normalEquationResidual = Math.abs(zetabar);
1:       xNorm = x.norm(2);
1: 
1:       // Now use these norms to estimate certain other quantities,
1:       // some of which will be small near a solution.
1: 
1:       double test1 = residualNorm / normb;
1:       double test2 = normalEquationResidual / (normA * residualNorm);
1:       double test3 = 1 / condA;
1:       double t1 = test1 / (1 + normA * xNorm / normb);
1:       double rtol = bTolerance + aTolerance * normA * xNorm / normb;
1: 
1:       // The following tests guard against extremely small values of
1:       // atol, btol or ctol.  (The user may have set any or all of
1:       // the parameters atol, btol, conlim  to 0.)
1:       // The effect is equivalent to the normAl tests using
1:       // atol = eps,  btol = eps,  conlim = 1/eps.
1: 
1:       if (iteration > iterationLimit) {
0:         istop = 7;
1:         stop = StopCode.ITERATION_LIMIT;
1:       }
1:       if (1 + test3 <= 1) {
0:         istop = 6;
1:         stop = StopCode.CONDITION_MACHINE_TOLERANCE;
1:       }
1:       if (1 + test2 <= 1) {
0:         istop = 5;
1:         stop = StopCode.LEAST_SQUARE_CONVERGED_MACHINE_TOLERANCE;
1:       }
1:       if (1 + t1 <= 1) {
0:         istop = 4;
1:         stop = StopCode.CONVERGED_MACHINE_TOLERANCE;
1:       }
1: 
1:       // Allow for tolerances set by the user.
1: 
1:       if (test3 <= ctol) {
0:         istop = 3;
1:         stop = StopCode.CONDITION;
1:       }
1:       if (test2 <= aTolerance) {
0:         istop = 2;
1:         stop = StopCode.CONVERGED;
1:       }
1:       if (test1 <= rtol) {
0:         istop = 1;
1:         stop = StopCode.TRIVIAL;
1:       }
1: 
0:       if (stop != StopCode.CONTINUE && stop.ordinal() != istop + 1) {
0:         throw new IllegalStateException(String.format("bad code match %d vs %d", istop, stop.ordinal()));
1:       }
1: 
1:       // See if it is time to print something.
1: 
1:       if (log.isDebugEnabled()) {
0:         if ((n <= 40) || (iteration <= 10) || (iteration >= iterationLimit - 10) || ((iteration % 10) == 0) || (test3 <= 1.1 * ctol) || (test2 <= 1.1 * aTolerance) || (test1 <= 1.1 * rtol) || (istop != 0)) {
1:           statusDump(x, normA, condA, test1, test2);
1:         }
1:       }
1:     } // iteration loop
1: 
1:     // Print the stopping condition.
1:     log.debug("Finished: {}", stop.getMessage());
1: 
1:     return x;
1:     /*
1: 
1: 
1:     if show
1:       fprintf('\n\nLSMR finished')
1:       fprintf('\n%s', msg(istop+1,:))
1:       fprintf('\nistop =%8g    normr =%8.1e'     , istop, normr )
1:       fprintf('    normA =%8.1e    normAr =%8.1e', normA, normAr)
1:       fprintf('\nitn   =%8g    condA =%8.1e'     , itn  , condA )
1:       fprintf('    normx =%8.1e\n', normx)
1:     end
1:     */
1:   }
1: 
1:   private void statusDump(Vector x, double normA, double condA, double test1, double test2) {
1:     log.debug("{} {}", residualNorm, normalEquationResidual);
1:     log.debug("{} {}", iteration, x.get(0));
1:     log.debug("{} {}", test1, test2);
1:     log.debug("{} {}", normA, condA);
1:   }
1: 
0:   private Vector zeros(int n) {
1:     return new DenseVector(n);
1:   }
1: 
1:   //-----------------------------------------------------------------------
1:   // stores v into the circular buffer localV
1:   //-----------------------------------------------------------------------
1: 
1:   private void localVEnqueue(Vector v) {
1:     if (localV.length > 0) {
1:       localV[localPointer] = v;
1:       localPointer = (localPointer + 1) % localV.length;
1:     }
1:   }
1: 
1:   //-----------------------------------------------------------------------
1:   // Perform local reorthogonalization of V
1:   //-----------------------------------------------------------------------
1: 
1:   private Vector localVOrtho(Vector v) {
1:     for (Vector old : localV) {
1:       if (old != null) {
1:         double x = v.dot(old);
1:         v = v.minus(old.times(x));
1:       }
1:     }
1:     return v;
1:   }
1: 
1:   private enum StopCode {
1:     CONTINUE("Not done"),
1:     TRIVIAL("The exact solution is  x = 0"),
0:     CONVERGED("Ax - b is small enough, given atol, btol"), LEAST_SQUARE_CONVERGED("The least-squares solution is good enough, given atol"),
1:     CONDITION("The estimate of cond(Abar) has exceeded condition limit"),
1:     CONVERGED_MACHINE_TOLERANCE("Ax - b is small enough for this machine"),
1:     LEAST_SQUARE_CONVERGED_MACHINE_TOLERANCE("The least-squares solution is good enough for this machine"),
1:     CONDITION_MACHINE_TOLERANCE("Cond(Abar) seems to be too large for this machine"),
1:     ITERATION_LIMIT("The iteration limit has been reached");
1: 
0:     private String message;
1: 
0:     private StopCode(String message) {
1:       this.message = message;
1:     }
1: 
1:     public String getMessage() {
1:       return message;
1:     }
1:   }
1: 
1:   public void setAtolerance(double aTolerance) {
1:     this.aTolerance = aTolerance;
1:   }
1: 
1:   public void setBtolerance(double bTolerance) {
1:     this.bTolerance = bTolerance;
1:   }
1: 
1:   public void setConditionLimit(double conditionLimit) {
1:     this.conditionLimit = conditionLimit;
1:   }
1: 
1:   public void setIterationLimit(int iterationLimit) {
1:     this.iterationLimit = iterationLimit;
1:   }
1: 
1:   public void setLocalSize(int localSize) {
1:     this.localSize = localSize;
1:   }
1: 
0:   private void setLambda(double lambda) {
0:     this.lambda = lambda;
1:   }
1: 
1:   public double getLambda() {
1:     return lambda;
1:   }
1: 
1:   public double getAtolerance() {
1:     return aTolerance;
1:   }
1: 
1:   public double getBtolerance() {
1:     return bTolerance;
1:   }
1: }
============================================================================
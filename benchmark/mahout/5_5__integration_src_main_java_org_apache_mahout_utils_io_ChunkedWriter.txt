1:466f319: /**
1:466f319:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:466f319:  * contributor license agreements.  See the NOTICE file distributed with
1:466f319:  * this work for additional information regarding copyright ownership.
1:466f319:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:466f319:  * (the "License"); you may not use this file except in compliance with
1:466f319:  * the License.  You may obtain a copy of the License at
1:466f319:  *
1:466f319:  *     http://www.apache.org/licenses/LICENSE-2.0
1:466f319:  *
1:466f319:  * Unless required by applicable law or agreed to in writing, software
1:466f319:  * distributed under the License is distributed on an "AS IS" BASIS,
1:466f319:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:466f319:  * See the License for the specific language governing permissions and
1:466f319:  * limitations under the License.
1:466f319:  */
1:29a7f38: package org.apache.mahout.utils.io;
1:466f319: 
1:d608a88: import com.google.common.io.Closeables;
1:466f319: import org.apache.hadoop.conf.Configuration;
1:466f319: import org.apache.hadoop.fs.FileSystem;
1:466f319: import org.apache.hadoop.fs.Path;
1:466f319: import org.apache.hadoop.io.SequenceFile;
1:466f319: import org.apache.hadoop.io.Text;
1:466f319: 
1:466f319: import java.io.Closeable;
1:466f319: import java.io.IOException;
1:466f319: 
1:d54c59b: /**
1:d54c59b:  * Writes data splitted in multiple Hadoop sequence files of approximate equal size. The data must consist
1:d54c59b:  * of key-value pairs, both of them of String type. All sequence files are created in the same
1:d54c59b:  * directory and named "chunk-0", "chunk-1", etc. 
1:d54c59b:  */
1:466f319: public final class ChunkedWriter implements Closeable {
1:466f319: 
1:466f319:   private final int maxChunkSizeInBytes;
1:466f319:   private final Path output;
1:466f319:   private SequenceFile.Writer writer;
1:466f319:   private int currentChunkID;
1:466f319:   private int currentChunkSize;
1:466f319:   private final FileSystem fs;
1:466f319:   private final Configuration conf;
1:466f319: 
1:d54c59b:   /** 
1:d54c59b:    * @param conf    needed by Hadoop to know what filesystem implementation to use.
1:d54c59b:    * @param chunkSizeInMB approximate size of each file, in Megabytes.
1:d54c59b:    * @param output        directory where the sequence files will be created.
1:d54c59b:    * @throws IOException
1:d54c59b:    */
1:466f319:   public ChunkedWriter(Configuration conf, int chunkSizeInMB, Path output) throws IOException {
1:466f319:     this.output = output;
1:466f319:     this.conf = conf;
1:466f319:     if (chunkSizeInMB > 1984) {
1:466f319:       chunkSizeInMB = 1984;
1:466f319:     }
1:466f319:     maxChunkSizeInBytes = chunkSizeInMB * 1024 * 1024;
1:f5e7732:     fs = FileSystem.get(output.toUri(), conf);
1:466f319:     currentChunkID = 0;
1:466f319:     writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID), Text.class, Text.class);
1:466f319:   }
1:466f319: 
1:466f319:   private Path getPath(int chunkID) {
1:466f319:     return new Path(output, "chunk-" + chunkID);
1:466f319:   }
1:466f319: 
1:d54c59b:   /** Writes a new key-value pair, creating a new sequence file if necessary.*/
1:466f319:   public void write(String key, String value) throws IOException {
1:466f319:     if (currentChunkSize > maxChunkSizeInBytes) {
1:31cb292:       Closeables.close(writer, false);
1:434b993:       currentChunkID++;
1:434b993:       writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID), Text.class, Text.class);
1:466f319:       currentChunkSize = 0;
1:466f319:     }
1:466f319: 
1:466f319:     Text keyT = new Text(key);
1:466f319:     Text valueT = new Text(value);
1:466f319:     currentChunkSize += keyT.getBytes().length + valueT.getBytes().length; // Overhead
1:466f319:     writer.append(keyT, valueT);
1:466f319:   }
1:466f319: 
1:466f319:   @Override
1:31cb292:   public void close() throws IOException {
1:31cb292:     Closeables.close(writer, false);
1:466f319:   }
1:466f319: }
1:466f319: 
============================================================================
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
/////////////////////////////////////////////////////////////////////////
1:   public void close() throws IOException {
1:     Closeables.close(writer, false);
commit:29a7f38
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.utils.io;
author:smarthi
-------------------------------------------------------------------------------
commit:d54c59b
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Writes data splitted in multiple Hadoop sequence files of approximate equal size. The data must consist
1:  * of key-value pairs, both of them of String type. All sequence files are created in the same
1:  * directory and named "chunk-0", "chunk-1", etc. 
1:  */
/////////////////////////////////////////////////////////////////////////
1:   /** 
1:    * @param conf    needed by Hadoop to know what filesystem implementation to use.
1:    * @param chunkSizeInMB approximate size of each file, in Megabytes.
1:    * @param output        directory where the sequence files will be created.
1:    * @throws IOException
1:    */
/////////////////////////////////////////////////////////////////////////
1:   /** Writes a new key-value pair, creating a new sequence file if necessary.*/
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:434b993
/////////////////////////////////////////////////////////////////////////
1:       currentChunkID++;
1:       writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID), Text.class, Text.class);
commit:3d44c1e
/////////////////////////////////////////////////////////////////////////
0:   public void close() {
commit:f5e7732
/////////////////////////////////////////////////////////////////////////
1:     fs = FileSystem.get(output.toUri(), conf);
commit:50fd693
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:d608a88
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
0:       Closeables.closeQuietly(writer);
/////////////////////////////////////////////////////////////////////////
0:     Closeables.closeQuietly(writer);
author:Isabel Drost
-------------------------------------------------------------------------------
commit:466f319
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: package org.apache.mahout.text;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.Text;
1: 
1: import java.io.Closeable;
1: import java.io.IOException;
1: 
1: public final class ChunkedWriter implements Closeable {
1: 
1:   private final int maxChunkSizeInBytes;
1:   private final Path output;
1:   private SequenceFile.Writer writer;
1:   private int currentChunkID;
1:   private int currentChunkSize;
1:   private final FileSystem fs;
1:   private final Configuration conf;
1: 
1:   public ChunkedWriter(Configuration conf, int chunkSizeInMB, Path output) throws IOException {
1:     this.output = output;
1:     this.conf = conf;
1:     if (chunkSizeInMB > 1984) {
1:       chunkSizeInMB = 1984;
1:     }
1:     maxChunkSizeInBytes = chunkSizeInMB * 1024 * 1024;
0:     fs = FileSystem.get(conf);
1:     currentChunkID = 0;
1:     writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID), Text.class, Text.class);
1:   }
1: 
1:   private Path getPath(int chunkID) {
1:     return new Path(output, "chunk-" + chunkID);
1:   }
1: 
1:   public void write(String key, String value) throws IOException {
1:     if (currentChunkSize > maxChunkSizeInBytes) {
0:       writer.close();
0:       writer = new SequenceFile.Writer(fs, conf, getPath(currentChunkID++), Text.class, Text.class);
1:       currentChunkSize = 0;
1:     }
1: 
1:     Text keyT = new Text(key);
1:     Text valueT = new Text(value);
1:     currentChunkSize += keyT.getBytes().length + valueT.getBytes().length; // Overhead
1:     writer.append(keyT, valueT);
1:   }
1: 
1:   @Override
0:   public void close() throws IOException {
0:     writer.close();
1:   }
1: }
1: 
============================================================================
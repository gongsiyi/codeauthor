2:e8b1acf: /**
1:e8b1acf:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:e8b1acf:  * contributor license agreements.  See the NOTICE file distributed with
1:e8b1acf:  * this work for additional information regarding copyright ownership.
1:e8b1acf:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:e8b1acf:  * (the "License"); you may not use this file except in compliance with
1:e8b1acf:  * the License.  You may obtain a copy of the License at
1:e8b1acf:  *
1:e8b1acf:  *     http://www.apache.org/licenses/LICENSE-2.0
1:e8b1acf:  *
1:e8b1acf:  * Unless required by applicable law or agreed to in writing, software
1:e8b1acf:  * distributed under the License is distributed on an "AS IS" BASIS,
1:e8b1acf:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:e8b1acf:  * See the License for the specific language governing permissions and
1:e8b1acf:  * limitations under the License.
2:e8b1acf:  */
1:b381afd: 
1:e8b1acf: package org.apache.mahout.text;
1:a13b4b7: 
1:d711ac1: import java.io.File;
1:e8b1acf: import java.io.IOException;
1:e8b1acf: import java.io.OutputStreamWriter;
1:85f9ece: import java.util.HashMap;
1:e8b1acf: import java.util.Map;
1:a13b4b7: 
1:85f9ece: import org.apache.commons.io.Charsets;
1:e8b1acf: import org.apache.hadoop.conf.Configuration;
1:e8b1acf: import org.apache.hadoop.fs.FileStatus;
1:e8b1acf: import org.apache.hadoop.fs.FileSystem;
1:e8b1acf: import org.apache.hadoop.fs.Path;
1:a13b4b7: import org.apache.hadoop.io.Text;
1:22533ae: import org.apache.mahout.common.HadoopUtil;
1:b381afd: import org.apache.mahout.common.MahoutTestCase;
1:a13b4b7: import org.apache.mahout.common.Pair;
1:c87196e: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:a13b4b7: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator;
1:e8b1acf: import org.junit.Test;
1:d711ac1: import org.slf4j.Logger;
1:d711ac1: import org.slf4j.LoggerFactory;
16:e8b1acf: 
1:e8b1acf: public final class TestSequenceFilesFromDirectory extends MahoutTestCase {
1:e8b1acf: 
1:d711ac1:   private static final Logger logger = LoggerFactory.getLogger(TestSequenceFilesFromDirectory.class);
1:d711ac1: 
1:e8b1acf:   private static final String[][] DATA1 = {
1:d711ac1:     {"test1", "This is the first text."},
1:d711ac1:     {"test2", "This is the second text."},
1:d711ac1:     {"test3", "This is the third text."}
1:e8b1acf:   };
1:e8b1acf: 
1:d711ac1:   private static final String[][] DATA2 = {
1:d711ac1:     {"recursive_test1", "This is the first text."},
1:d711ac1:     {"recursive_test2", "This is the second text."},
1:d711ac1:     {"recursive_test3", "This is the third text."}
1:d711ac1:   };
1:d711ac1: 
1:e8b1acf:   @Test
1:466f319:   public void testSequenceFileFromDirectoryBasic() throws Exception {
1:e8b1acf:     // parameters
1:921e201:     Configuration configuration = getConfiguration();
1:d711ac1: 
1:74078b6:     FileSystem fs = FileSystem.get(configuration);
1:d711ac1: 
1:e8b1acf:     // create
1:e8b1acf:     Path tmpDir = this.getTestTempDirPath();
1:e8b1acf:     Path inputDir = new Path(tmpDir, "inputDir");
1:e8b1acf:     fs.mkdirs(inputDir);
1:d711ac1: 
1:e8b1acf:     Path outputDir = new Path(tmpDir, "outputDir");
1:d711ac1:     Path outputDirRecursive = new Path(tmpDir, "outputDirRecursive");
1:d711ac1: 
1:d711ac1:     Path inputDirRecursive = new Path(tmpDir, "inputDirRecur");
1:d711ac1:     fs.mkdirs(inputDirRecursive);
1:d711ac1: 
1:e8b1acf:     // prepare input files
1:74078b6:     createFilesFromArrays(configuration, inputDir, DATA1);
1:e8b1acf: 
1:d711ac1:     SequenceFilesFromDirectory.main(new String[]{
1:d711ac1:       "--input", inputDir.toString(),
1:d711ac1:       "--output", outputDir.toString(),
1:d711ac1:       "--chunkSize", "64",
1:d711ac1:       "--charset", Charsets.UTF_8.name(),
1:d711ac1:       "--keyPrefix", "UID",
1:d711ac1:       "--method", "sequential"});
1:d711ac1: 
1:e8b1acf:     // check output chunk files
1:74078b6:     checkChunkFiles(configuration, outputDir, DATA1, "UID");
1:d711ac1: 
1:74078b6:     createRecursiveDirFilesFromArrays(configuration, inputDirRecursive, DATA2);
1:d711ac1: 
1:d711ac1:     FileStatus fstInputPath = fs.getFileStatus(inputDirRecursive);
1:22533ae:     String dirs = HadoopUtil.buildDirList(fs, fstInputPath);
1:d711ac1: 
1:d711ac1:     System.out.println("\n\n ----- recursive dirs: " + dirs);
1:d711ac1:     SequenceFilesFromDirectory.main(new String[]{
1:d711ac1:       "--input", inputDirRecursive.toString(),
1:d711ac1:       "--output", outputDirRecursive.toString(),
1:d711ac1:       "--chunkSize", "64",
1:d711ac1:       "--charset", Charsets.UTF_8.name(),
1:d711ac1:       "--keyPrefix", "UID",
1:d711ac1:       "--method", "sequential"});
1:d711ac1: 
1:74078b6:     checkRecursiveChunkFiles(configuration, outputDirRecursive, DATA2, "UID");
2:e8b1acf:   }
1:d711ac1: 
1:d711ac1:   @Test
1:d711ac1:   public void testSequenceFileFromDirectoryMapReduce() throws Exception {
1:d711ac1: 
1:921e201:     Configuration conf = getConfiguration();
1:d711ac1: 
1:d711ac1:     FileSystem fs = FileSystem.get(conf);
1:d711ac1: 
1:d711ac1:     // create
1:d711ac1:     Path tmpDir = this.getTestTempDirPath();
1:d711ac1:     Path inputDir = new Path(tmpDir, "inputDir");
1:d711ac1:     fs.mkdirs(inputDir);
1:d711ac1: 
1:d711ac1:     Path inputDirRecur = new Path(tmpDir, "inputDirRecur");
1:d711ac1:     fs.mkdirs(inputDirRecur);
1:d711ac1: 
1:d711ac1:     Path mrOutputDir = new Path(tmpDir, "mrOutputDir");
1:d711ac1:     Path mrOutputDirRecur = new Path(tmpDir, "mrOutputDirRecur");
1:d711ac1: 
1:d711ac1:     createFilesFromArrays(conf, inputDir, DATA1);
1:d711ac1: 
1:d711ac1:     SequenceFilesFromDirectory.main(new String[]{
1:e8cd230:       "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"),
1:d711ac1:       "--input", inputDir.toString(),
1:d711ac1:       "--output", mrOutputDir.toString(),
1:d711ac1:       "--chunkSize", "64",
1:d711ac1:       "--charset", Charsets.UTF_8.name(),
1:d711ac1:       "--method", "mapreduce",
1:c87196e:       "--keyPrefix", "UID",
1:c87196e:       "--fileFilterClass", "org.apache.mahout.text.TestPathFilter"
1:c87196e:     });
1:d711ac1: 
1:d711ac1:     checkMRResultFiles(conf, mrOutputDir, DATA1, "UID");
1:d711ac1: 
1:d711ac1:     createRecursiveDirFilesFromArrays(conf, inputDirRecur, DATA2);
1:d711ac1: 
1:d711ac1:     FileStatus fst_input_path = fs.getFileStatus(inputDirRecur);
1:22533ae:     String dirs = HadoopUtil.buildDirList(fs, fst_input_path);
1:d711ac1: 
1:d711ac1:     logger.info("\n\n ---- recursive dirs: {}", dirs);
1:d711ac1: 
1:d711ac1:     SequenceFilesFromDirectory.main(new String[]{
1:e8cd230:       "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"),
1:d711ac1:       "--input", inputDirRecur.toString(),
1:d711ac1:       "--output", mrOutputDirRecur.toString(),
1:d711ac1:       "--chunkSize", "64",
1:d711ac1:       "--charset", Charsets.UTF_8.name(),
1:d711ac1:       "--method", "mapreduce",
1:2e5449f:       "--keyPrefix", "UID",
1:c87196e:       "--fileFilterClass", "org.apache.mahout.text.TestPathFilter"
1:2e5449f:     });
1:d711ac1: 
1:d711ac1:     checkMRResultFilesRecursive(conf, mrOutputDirRecur, DATA2, "UID");
1:d711ac1:   }
1:d711ac1: 
1:d711ac1: 
1:e8b1acf:   private static void createFilesFromArrays(Configuration conf, Path inputDir, String[][] data) throws IOException {
1:d711ac1:     FileSystem fs = FileSystem.get(conf);
2:e8b1acf:     for (String[] aData : data) {
1:85f9ece:       try (OutputStreamWriter writer =
1:85f9ece:                new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8)){
1:d711ac1:         writer.write(aData[1]);
1:d711ac1:       }
1:d711ac1:     }
1:d711ac1:   }
1:d711ac1: 
1:74078b6:   private static void createRecursiveDirFilesFromArrays(Configuration configuration, Path inputDir,
1:74078b6:                                                         String[][] data) throws IOException {
1:74078b6:     FileSystem fs = FileSystem.get(configuration);
1:d711ac1: 
1:d711ac1:     logger.info("creativeRecursiveDirFilesFromArrays > based on: {}", inputDir.toString());
1:d711ac1:     Path curPath;
1:d711ac1:     String currentRecursiveDir = inputDir.toString();
1:d711ac1: 
1:d711ac1:     for (String[] aData : data) {
1:d711ac1:       currentRecursiveDir += "/" + aData[0];
1:d711ac1:       File subDir = new File(currentRecursiveDir);
1:d711ac1:       subDir.mkdir();
1:d711ac1: 
1:d711ac1:       curPath = new Path(subDir.toString(), "file.txt");
1:d711ac1:       logger.info("Created file: {}", curPath.toString());
1:d711ac1: 
1:85f9ece:       try (OutputStreamWriter writer = new OutputStreamWriter(fs.create(curPath), Charsets.UTF_8)){
1:d608a88:         writer.write(aData[1]);
1:e8b1acf:       }
1:e8b1acf:     }
1:e8b1acf:   }
1:d711ac1: 
1:74078b6:   private static void checkChunkFiles(Configuration configuration,
1:d711ac1:                                       Path outputDir,
1:d711ac1:                                       String[][] data,
1:d711ac1:                                       String prefix) throws IOException {
1:74078b6:     FileSystem fs = FileSystem.get(configuration);
1:d711ac1: 
1:d711ac1:     // output exists?
1:c87196e:     FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());
1:d711ac1:     assertEquals(1, fileStatuses.length); // only one
1:d711ac1:     assertEquals("chunk-0", fileStatuses[0].getPath().getName());
1:d711ac1: 
1:85f9ece:     Map<String, String> fileToData = new HashMap<>();
1:e8b1acf:     for (String[] aData : data) {
1:7c0da90:       fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
1:e8b1acf:     }
1:d711ac1: 
1:d711ac1:     // read a chunk to check content
1:85f9ece:     try (SequenceFileIterator<Text, Text> iterator =
1:85f9ece:              new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)){
1:d711ac1:       while (iterator.hasNext()) {
1:d711ac1:         Pair<Text, Text> record = iterator.next();
1:a13b4b7:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:d711ac1:         assertNotNull(retrievedData);
1:d711ac1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:d711ac1:       }
1:d711ac1:     }
1:e8b1acf:   }
1:d711ac1: 
1:74078b6:   private static void checkRecursiveChunkFiles(Configuration configuration,
1:a13b4b7:                                                Path outputDir,
1:a13b4b7:                                                String[][] data,
1:7c0da90:                                                String prefix) throws IOException {
1:74078b6:     FileSystem fs = FileSystem.get(configuration);
1:e8b1acf: 
1:d711ac1:     System.out.println(" ----------- check_Recursive_ChunkFiles ------------");
1:d711ac1: 
1:d711ac1:     // output exists?
1:c87196e:     FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());
1:d711ac1:     assertEquals(1, fileStatuses.length); // only one
1:d711ac1:     assertEquals("chunk-0", fileStatuses[0].getPath().getName());
1:d711ac1: 
1:d711ac1: 
1:85f9ece:     Map<String, String> fileToData = new HashMap<>();
1:d711ac1:     String currentPath = prefix;
1:d711ac1:     for (String[] aData : data) {
1:d711ac1:       currentPath += Path.SEPARATOR + aData[0];
1:d711ac1:       fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);
1:d711ac1:     }
1:d711ac1: 
1:d711ac1:     // read a chunk to check content
1:85f9ece:     try (SequenceFileIterator<Text, Text> iterator =
1:85f9ece:              new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)) {
1:d711ac1:       while (iterator.hasNext()) {
1:d711ac1:         Pair<Text, Text> record = iterator.next();
1:d711ac1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:d711ac1:         System.out.printf("%s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());
1:d711ac1: 
1:d711ac1:         assertNotNull(retrievedData);
1:d711ac1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:d711ac1:         System.out.printf(">>> k: %s, v: %s\n", record.getFirst().toString(), record.getSecond().toString());
1:d711ac1:       }
1:d711ac1:     }
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   private static void checkMRResultFiles(Configuration conf, Path outputDir,
1:d711ac1:                                          String[][] data, String prefix) throws IOException {
3:d711ac1:     FileSystem fs = FileSystem.get(conf);
1:d711ac1: 
1:d711ac1:     // output exists?
1:c87196e:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());
1:d711ac1:     assertEquals(1, fileStatuses.length); // only one
1:d711ac1:     assertEquals("part-m-00000", fileStatuses[0].getPath().getName());
1:85f9ece:     Map<String, String> fileToData = new HashMap<>();
1:d711ac1:     for (String[] aData : data) {
1:d711ac1:       System.out.printf("map.put: %s %s\n", prefix + Path.SEPARATOR + aData[0], aData[1]);
1:d711ac1:       fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
1:d711ac1:     }
1:d711ac1: 
1:d711ac1:     // read a chunk to check content
1:85f9ece:     try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
1:85f9ece:         fileStatuses[0].getPath(), true, conf)) {
1:d711ac1:       while (iterator.hasNext()) {
1:d711ac1:         Pair<Text, Text> record = iterator.next();
1:d711ac1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:d711ac1: 
1:d711ac1:         System.out.printf("MR> %s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());
1:d711ac1:         assertNotNull(retrievedData);
1:d711ac1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:d711ac1:       }
1:d711ac1:     }
1:d711ac1:   }
1:d711ac1: 
1:74078b6:   private static void checkMRResultFilesRecursive(Configuration configuration, Path outputDir,
1:d711ac1:                                                   String[][] data, String prefix) throws IOException {
1:74078b6:     FileSystem fs = FileSystem.get(configuration);
1:d711ac1: 
1:d711ac1:     // output exists?
1:c87196e:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());
1:d711ac1:     assertEquals(1, fileStatuses.length); // only one
1:d711ac1:     assertEquals("part-m-00000", fileStatuses[0].getPath().getName());
1:85f9ece:     Map<String, String> fileToData = new HashMap<>();
1:d711ac1:     String currentPath = prefix;
1:d711ac1: 
1:d711ac1:     for (String[] aData : data) {
1:d711ac1:       currentPath += Path.SEPARATOR + aData[0];
1:d711ac1:       fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);
1:d711ac1:     }
1:e8b1acf: 
1:a13b4b7:     // read a chunk to check content
1:85f9ece:     try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
1:85f9ece:         fileStatuses[0].getPath(), true, configuration)){
1:d711ac1:       while (iterator.hasNext()) {
1:d711ac1:         Pair<Text, Text> record = iterator.next();
1:d711ac1:         System.out.printf("MR-Recur > Trying to check: %s\n", record.getFirst().toString().trim());
1:d711ac1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:e8b1acf:         assertNotNull(retrievedData);
1:a13b4b7:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:d711ac1:       }
1:e8b1acf:     }
1:e8b1acf:   }
1:e8b1acf: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashMap;
1: import org.apache.commons.io.Charsets;
/////////////////////////////////////////////////////////////////////////
1:       try (OutputStreamWriter writer =
1:                new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8)){
/////////////////////////////////////////////////////////////////////////
1:       try (OutputStreamWriter writer = new OutputStreamWriter(fs.create(curPath), Charsets.UTF_8)){
/////////////////////////////////////////////////////////////////////////
1:     Map<String, String> fileToData = new HashMap<>();
1:     try (SequenceFileIterator<Text, Text> iterator =
1:              new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)){
/////////////////////////////////////////////////////////////////////////
1:     Map<String, String> fileToData = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:     try (SequenceFileIterator<Text, Text> iterator =
1:              new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration)) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     Map<String, String> fileToData = new HashMap<>();
1:     try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
1:         fileStatuses[0].getPath(), true, conf)) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     Map<String, String> fileToData = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:     try (SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
1:         fileStatuses[0].getPath(), true, configuration)){
/////////////////////////////////////////////////////////////////////////
commit:87c15be
/////////////////////////////////////////////////////////////////////////
0:       new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration);
/////////////////////////////////////////////////////////////////////////
0:     SequenceFileIterator<Text, Text> iterator =
0:         new SequenceFileIterator<>(fileStatuses[0].getPath(), true, configuration);
/////////////////////////////////////////////////////////////////////////
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
/////////////////////////////////////////////////////////////////////////
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<>(
author:smarthi
-------------------------------------------------------------------------------
commit:c87196e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
/////////////////////////////////////////////////////////////////////////
1:       "--fileFilterClass", "org.apache.mahout.text.TestPathFilter"
/////////////////////////////////////////////////////////////////////////
1:       "--keyPrefix", "UID",
1:       "--fileFilterClass", "org.apache.mahout.text.TestPathFilter"
1:     });
/////////////////////////////////////////////////////////////////////////
1:     FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     FileStatus[] fileStatuses = fs.listStatus(outputDir, PathFilters.logsCRCFilter());
/////////////////////////////////////////////////////////////////////////
1:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());
/////////////////////////////////////////////////////////////////////////
1:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), PathFilters.logsCRCFilter());
commit:74078b6
/////////////////////////////////////////////////////////////////////////
0:     Configuration configuration = new Configuration();
1:     FileSystem fs = FileSystem.get(configuration);
/////////////////////////////////////////////////////////////////////////
1:     createFilesFromArrays(configuration, inputDir, DATA1);
/////////////////////////////////////////////////////////////////////////
1:     checkChunkFiles(configuration, outputDir, DATA1, "UID");
1:     createRecursiveDirFilesFromArrays(configuration, inputDirRecursive, DATA2);
/////////////////////////////////////////////////////////////////////////
1:     checkRecursiveChunkFiles(configuration, outputDirRecursive, DATA2, "UID");
/////////////////////////////////////////////////////////////////////////
1:   private static void createRecursiveDirFilesFromArrays(Configuration configuration, Path inputDir,
1:                                                         String[][] data) throws IOException {
1:     FileSystem fs = FileSystem.get(configuration);
/////////////////////////////////////////////////////////////////////////
1:   private static void checkChunkFiles(Configuration configuration,
1:     FileSystem fs = FileSystem.get(configuration);
/////////////////////////////////////////////////////////////////////////
0:     SequenceFileIterator<Text, Text> iterator =
0:       new SequenceFileIterator<Text, Text>(fileStatuses[0].getPath(), true, configuration);
/////////////////////////////////////////////////////////////////////////
1:   private static void checkRecursiveChunkFiles(Configuration configuration,
1:     FileSystem fs = FileSystem.get(configuration);
/////////////////////////////////////////////////////////////////////////
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<Text, Text>(fileStatuses[0].getPath(), true, configuration);
/////////////////////////////////////////////////////////////////////////
1:   private static void checkMRResultFilesRecursive(Configuration configuration, Path outputDir,
1:     FileSystem fs = FileSystem.get(configuration);
/////////////////////////////////////////////////////////////////////////
0:       fileStatuses[0].getPath(), true, configuration);
commit:22533ae
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.HadoopUtil;
/////////////////////////////////////////////////////////////////////////
1:     String dirs = HadoopUtil.buildDirList(fs, fstInputPath);
/////////////////////////////////////////////////////////////////////////
1:     String dirs = HadoopUtil.buildDirList(fs, fst_input_path);
commit:d711ac1
/////////////////////////////////////////////////////////////////////////
1: import java.io.File;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.mahout.common.AbstractJob;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1:   private static final Logger logger = LoggerFactory.getLogger(TestSequenceFilesFromDirectory.class);
1: 
1:     {"test1", "This is the first text."},
1:     {"test2", "This is the second text."},
1:     {"test3", "This is the third text."}
1:   private static final String[][] DATA2 = {
1:     {"recursive_test1", "This is the first text."},
1:     {"recursive_test2", "This is the second text."},
1:     {"recursive_test3", "This is the third text."}
1:   };
1: 
1: 
1: 
1: 
1:     Path outputDirRecursive = new Path(tmpDir, "outputDirRecursive");
1: 
1:     Path inputDirRecursive = new Path(tmpDir, "inputDirRecur");
1:     fs.mkdirs(inputDirRecursive);
1: 
1:     SequenceFilesFromDirectory.main(new String[]{
1:       "--input", inputDir.toString(),
1:       "--output", outputDir.toString(),
1:       "--chunkSize", "64",
1:       "--charset", Charsets.UTF_8.name(),
1:       "--keyPrefix", "UID",
1:       "--method", "sequential"});
1: 
1: 
0:     createRecursiveDirFilesFromArrays(conf, inputDirRecursive, DATA2);
1: 
1:     FileStatus fstInputPath = fs.getFileStatus(inputDirRecursive);
0:     String dirs = AbstractJob.buildDirList(fs, fstInputPath);
1: 
1:     System.out.println("\n\n ----- recursive dirs: " + dirs);
1:     SequenceFilesFromDirectory.main(new String[]{
1:       "--input", inputDirRecursive.toString(),
1:       "--output", outputDirRecursive.toString(),
1:       "--chunkSize", "64",
1:       "--charset", Charsets.UTF_8.name(),
1:       "--keyPrefix", "UID",
1:       "--method", "sequential"});
1: 
0:     checkRecursiveChunkFiles(conf, outputDirRecursive, DATA2, "UID");
1:   @Test
1:   public void testSequenceFileFromDirectoryMapReduce() throws Exception {
1: 
0:     Configuration conf = new Configuration();
1: 
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     // create
1:     Path tmpDir = this.getTestTempDirPath();
1:     Path inputDir = new Path(tmpDir, "inputDir");
1:     fs.mkdirs(inputDir);
1: 
1:     Path inputDirRecur = new Path(tmpDir, "inputDirRecur");
1:     fs.mkdirs(inputDirRecur);
1: 
1:     Path mrOutputDir = new Path(tmpDir, "mrOutputDir");
1:     Path mrOutputDirRecur = new Path(tmpDir, "mrOutputDirRecur");
1: 
1:     createFilesFromArrays(conf, inputDir, DATA1);
1: 
1:     SequenceFilesFromDirectory.main(new String[]{
1:       "--input", inputDir.toString(),
1:       "--output", mrOutputDir.toString(),
1:       "--chunkSize", "64",
1:       "--charset", Charsets.UTF_8.name(),
1:       "--method", "mapreduce",
0:       "--keyPrefix", "UID"});
1: 
1:     checkMRResultFiles(conf, mrOutputDir, DATA1, "UID");
1: 
1:     createRecursiveDirFilesFromArrays(conf, inputDirRecur, DATA2);
1: 
1:     FileStatus fst_input_path = fs.getFileStatus(inputDirRecur);
0:     String dirs = AbstractJob.buildDirList(fs, fst_input_path);
1: 
1:     logger.info("\n\n ---- recursive dirs: {}", dirs);
1: 
1:     SequenceFilesFromDirectory.main(new String[]{
1:       "--input", inputDirRecur.toString(),
1:       "--output", mrOutputDirRecur.toString(),
1:       "--chunkSize", "64",
1:       "--charset", Charsets.UTF_8.name(),
1:       "--method", "mapreduce",
0:       "--keyPrefix", "UID"});
1: 
1:     checkMRResultFilesRecursive(conf, mrOutputDirRecur, DATA2, "UID");
1:   }
1: 
1: 
0:     OutputStreamWriter writer;
0:       writer = new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8);
0:       try {
1:         writer.write(aData[1]);
0:       } finally {
0:         Closeables.close(writer, false);
1:       }
1:     }
1:   }
1: 
0:   private static void createRecursiveDirFilesFromArrays(Configuration conf, Path inputDir, String[][] data) throws IOException {
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     logger.info("creativeRecursiveDirFilesFromArrays > based on: {}", inputDir.toString());
1:     Path curPath;
1:     String currentRecursiveDir = inputDir.toString();
1: 
1:     for (String[] aData : data) {
0:       OutputStreamWriter writer;
1: 
1:       currentRecursiveDir += "/" + aData[0];
1:       File subDir = new File(currentRecursiveDir);
1:       subDir.mkdir();
1: 
1:       curPath = new Path(subDir.toString(), "file.txt");
0:       writer = new OutputStreamWriter(fs.create(curPath), Charsets.UTF_8);
1: 
1:       logger.info("Created file: {}", curPath.toString());
1: 
/////////////////////////////////////////////////////////////////////////
1:     // output exists?
0:     FileStatus[] fileStatuses = fs.listStatus(outputDir, new ExcludeDotFiles());
1:     assertEquals(1, fileStatuses.length); // only one
1:     assertEquals("chunk-0", fileStatuses[0].getPath().getName());
1: 
0:     Map<String, String> fileToData = Maps.newHashMap();
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<Text, Text>(fileStatuses[0].getPath(), true, conf);
1:       while (iterator.hasNext()) {
1:         Pair<Text, Text> record = iterator.next();
/////////////////////////////////////////////////////////////////////////
1: 
0:       return !file.getName().startsWith(".") && !file.getName().startsWith("_");
0:   private static void checkRecursiveChunkFiles(Configuration conf,
1:                                                Path outputDir,
1:                                                String[][] data,
1:                                                String prefix) throws IOException {
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     System.out.println(" ----------- check_Recursive_ChunkFiles ------------");
1: 
1:     // output exists?
0:     FileStatus[] fileStatuses = fs.listStatus(outputDir, new ExcludeDotFiles());
1:     assertEquals(1, fileStatuses.length); // only one
1:     assertEquals("chunk-0", fileStatuses[0].getPath().getName());
1: 
1: 
0:     Map<String, String> fileToData = Maps.newHashMap();
1:     String currentPath = prefix;
1:     for (String[] aData : data) {
1:       currentPath += Path.SEPARATOR + aData[0];
1:       fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);
1:     }
1: 
1:     // read a chunk to check content
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<Text, Text>(fileStatuses[0].getPath(), true, conf);
0:     try {
1:       while (iterator.hasNext()) {
1:         Pair<Text, Text> record = iterator.next();
1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:         System.out.printf("%s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());
1: 
1:         assertNotNull(retrievedData);
1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:         System.out.printf(">>> k: %s, v: %s\n", record.getFirst().toString(), record.getSecond().toString());
1:       }
0:     } finally {
0:       Closeables.close(iterator, true);
1:     }
1:   }
1: 
1:   private static void checkMRResultFiles(Configuration conf, Path outputDir,
1:                                          String[][] data, String prefix) throws IOException {
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     // output exists?
0:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), new ExcludeDotFiles());
1:     assertEquals(1, fileStatuses.length); // only one
1:     assertEquals("part-m-00000", fileStatuses[0].getPath().getName());
0:     Map<String, String> fileToData = Maps.newHashMap();
1:     for (String[] aData : data) {
1:       System.out.printf("map.put: %s %s\n", prefix + Path.SEPARATOR + aData[0], aData[1]);
1:       fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
1:     }
1: 
1:     // read a chunk to check content
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<Text, Text>(
0:       fileStatuses[0].getPath(), true, conf);
0:     try {
1:       while (iterator.hasNext()) {
1:         Pair<Text, Text> record = iterator.next();
1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1: 
1:         System.out.printf("MR> %s >> %s\n", record.getFirst().toString().trim(), record.getSecond().toString().trim());
1:         assertNotNull(retrievedData);
1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:       }
0:     } finally {
0:       Closeables.close(iterator, true);
1:     }
1:   }
1: 
0:   private static void checkMRResultFilesRecursive(Configuration conf, Path outputDir,
1:                                                   String[][] data, String prefix) throws IOException {
1:     FileSystem fs = FileSystem.get(conf);
1: 
1:     // output exists?
0:     FileStatus[] fileStatuses = fs.listStatus(outputDir.suffix("/part-m-00000"), new ExcludeDotFiles());
1:     assertEquals(1, fileStatuses.length); // only one
1:     assertEquals("part-m-00000", fileStatuses[0].getPath().getName());
0:     Map<String, String> fileToData = Maps.newHashMap();
1:     String currentPath = prefix;
1: 
1:     for (String[] aData : data) {
1:       currentPath += Path.SEPARATOR + aData[0];
1:       fileToData.put(currentPath + Path.SEPARATOR + "file.txt", aData[1]);
1:     }
1: 
1:     // read a chunk to check content
0:     SequenceFileIterator<Text, Text> iterator = new SequenceFileIterator<Text, Text>(
0:       fileStatuses[0].getPath(), true, conf);
0:     try {
1:       while (iterator.hasNext()) {
1:         Pair<Text, Text> record = iterator.next();
1:         System.out.printf("MR-Recur > Trying to check: %s\n", record.getFirst().toString().trim());
1:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:         assertNotNull(retrievedData);
1:         assertEquals(retrievedData, record.getSecond().toString().trim());
1:       }
0:     } finally {
0:       Closeables.close(iterator, true);
1:     }
1:   }
author:frankscholten
-------------------------------------------------------------------------------
commit:2e5449f
/////////////////////////////////////////////////////////////////////////
1:       "--keyPrefix", "UID",
0:       "--fileFilterClass", ""
1:     });
author:sslavic
-------------------------------------------------------------------------------
commit:e8cd230
/////////////////////////////////////////////////////////////////////////
1:       "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"),
/////////////////////////////////////////////////////////////////////////
1:       "-Dhadoop.tmp.dir=" + conf.get("hadoop.tmp.dir"),
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration configuration = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
commit:b381afd
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.MahoutTestCase;
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(writer, false);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(writer, true);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(iterator, true);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:7c0da90
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     SequenceFilesFromDirectory.main(new String[] {
0:         "--input", inputDir.toString(),
0:         "--output", outputDir.toString(),
0:         "--chunkSize", "64",
0:         "--charset", Charsets.UTF_8.name(),
0:         "--keyPrefix", "UID"});
0:     checkChunkFiles(conf, outputDir, DATA1, "UID");
/////////////////////////////////////////////////////////////////////////
1:                                       String prefix) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:       fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
commit:50fd693
commit:80366ee
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Charsets;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         Charsets.UTF_8.name(), "--keyPrefix", prefix});
/////////////////////////////////////////////////////////////////////////
0:         "--output", outputDir.toString(), "--charset", Charsets.UTF_8.name(),
/////////////////////////////////////////////////////////////////////////
0:       OutputStreamWriter osw = new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8);
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.io.Text;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator;
/////////////////////////////////////////////////////////////////////////
0:   private enum ParserType {
0:     TEXT, CSV
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:     String prefix = "UID";
0:     int chunkSizeInMB = 64;
0:     int keyColumn = 0;
0:     int valueColumn = 1;
/////////////////////////////////////////////////////////////////////////
0:   private static void createTsvFilesFromArrays(Configuration conf, Path inputDir, String[][] data) throws IOException {
0:       osw.write(aData[0] + '\t' + aData[1] + '\n');
0:   private static void checkChunkFiles(Configuration conf,
1:                                       Path outputDir,
1:                                       String[][] data,
0:                                       String prefix,
0:                                       ParserType inputType) throws IOException {
/////////////////////////////////////////////////////////////////////////
1: 
0:       if (inputType == ParserType.CSV) {
0:       } else {
1:     // read a chunk to check content
0:     SequenceFileIterator<Text,Text> iterator = new SequenceFileIterator<Text,Text>(fstats[0].getPath(), true, conf);
0:     for (String[] datum : data) {
0:       assertTrue(iterator.hasNext());
0:       Pair<Text,Text> record = iterator.next();
1:       String retrievedData = fileToData.get(record.getFirst().toString().trim());
1:       assertEquals(retrievedData, record.getSecond().toString().trim());
0:     iterator.close();
commit:e8b1acf
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.text;
1: 
1: import java.io.IOException;
1: import java.io.OutputStreamWriter;
0: import java.nio.charset.Charset;
0: import java.util.HashMap;
0: import java.util.Locale;
1: import java.util.Map;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.fs.PathFilter;
0: import org.apache.hadoop.io.SequenceFile;
0: import org.apache.hadoop.io.Writable;
0: import org.apache.mahout.utils.MahoutTestCase;
0: import org.junit.Before;
1: import org.junit.Test;
1: 
1: public final class TestSequenceFilesFromDirectory extends MahoutTestCase {
1: 
0:   private static final Charset UTF8 = Charset.forName("UTF-8");
1:   private static final String[][] DATA1 = {
0:       {"test1", "This is the first text."},
0:       {"test2", "This is the second text."},
0:       {"test3", "This is the third text."}
1:   };
1: 
0:   @Override
0:   @Before
0:   public void setUp() throws Exception {
0:     super.setUp();
1:   }
1:   
0:   /** Story converting text files to SequenceFile */
1:   @Test
0:   public void testSequnceFileFromTsvBasic() throws Exception {
1:     // parameters
0:     Configuration conf = new Configuration();
1:     
0:     FileSystem fs = FileSystem.get(conf);
1:     
1:     // create
1:     Path tmpDir = this.getTestTempDirPath();
1:     Path inputDir = new Path(tmpDir, "inputDir");
1:     fs.mkdirs(inputDir);
1:     Path outputDir = new Path(tmpDir, "outputDir");
1:     
1:     // prepare input files
0:     createFilesFromArrays(conf, inputDir, DATA1);
1: 
0:     String prefix = "UID";
0:     SequenceFilesFromDirectory.main(new String[] {"--input",
0:         inputDir.toString(), "--output", outputDir.toString(), "--chunkSize",
0:         "64", "--charset",
0:         UTF8.displayName(Locale.ENGLISH), "--keyPrefix", prefix});
1:     
1:     // check output chunk files
0:     checkChunkFiles(conf, outputDir, DATA1, prefix);
1:   }
1: 
1:   private static void createFilesFromArrays(Configuration conf, Path inputDir, String[][] data) throws IOException {
0:     FileSystem fs = FileSystem.get(conf);
1:     for (String[] aData : data) {
0:       OutputStreamWriter osw = new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), UTF8);
0:       osw.write(aData[1]);
0:       osw.close();
1:     }
1:   }
1: 
0:   private static void checkChunkFiles(Configuration conf, Path outputDir, String[][] data, String prefix)
0:     throws IOException, InstantiationException, IllegalAccessException {
0:     FileSystem fs = FileSystem.get(conf);
1:     
0:     // output exists?
0:     FileStatus[] fstats = fs.listStatus(outputDir, new ExcludeDotFiles());
0:     assertEquals(1, fstats.length); // only one
0:     assertEquals("chunk-0", fstats[0].getPath().getName());
1:     
0:     // read a chunk to check content
0:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, fstats[0].getPath(), conf);
0:     assertEquals("org.apache.hadoop.io.Text", reader.getKeyClassName());
0:     assertEquals("org.apache.hadoop.io.Text", reader.getValueClassName());
0:     Writable key = reader.getKeyClass().asSubclass(Writable.class).newInstance();
0:     Writable value = reader.getValueClass().asSubclass(Writable.class).newInstance();
1:     
0:     Map<String,String> fileToData = new HashMap<String,String>();
1:     for (String[] aData : data) {
0:       fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
1:     }
1: 
1:     for (String[] aData : data) {
0:       assertTrue(reader.next(key, value));
0:       String retrievedData = fileToData.get(key.toString().trim());
1:       assertNotNull(retrievedData);
0:       assertEquals(retrievedData, value.toString().trim());
1:     }
0:     reader.close();
1:   }
1:   
1:   /**
0:    * exclude hidden (starting with dot) files
1:    */
0:   private static class ExcludeDotFiles implements PathFilter {
0:     @Override
0:     public boolean accept(Path file) {
0:       return !file.getName().startsWith(".");
1:     }
1:   }
1: 
1: }
1: 
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:74f849b
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.collect.Maps;
/////////////////////////////////////////////////////////////////////////
0:     Map<String,String> fileToData = Maps.newHashMap();
commit:d608a88
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
0:       OutputStreamWriter writer = new OutputStreamWriter(fs.create(new Path(inputDir, aData[0])), Charsets.UTF_8);
0:       try {
1:         writer.write(aData[1]);
0:       } finally {
0:         Closeables.closeQuietly(writer);
0:       }
0:     OutputStreamWriter writer = new OutputStreamWriter(fs.create(new Path(inputDir, "inputTsvFile")));
0:     try {
0:       for (String[] aData : data) {
0:         writer.write(aData[0] + '\t' + aData[1] + '\n');
0:       }
0:     } finally {
0:       Closeables.closeQuietly(writer);
/////////////////////////////////////////////////////////////////////////
0:     try {
0:       for (String[] datum : data) {
0:         assertTrue(iterator.hasNext());
0:         Pair<Text,Text> record = iterator.next();
0:         String retrievedData = fileToData.get(record.getFirst().toString().trim());
0:         assertNotNull(retrievedData);
0:         assertEquals(retrievedData, record.getSecond().toString().trim());
0:       }
0:     } finally {
0:       Closeables.closeQuietly(iterator);
author:Isabel Drost
-------------------------------------------------------------------------------
commit:466f319
/////////////////////////////////////////////////////////////////////////
0:   private enum ParserType {TEXT, CSV};
0: 
0:   /**
0:    * Story converting text files to SequenceFile
0:    */
1:   public void testSequenceFileFromDirectoryBasic() throws Exception {
/////////////////////////////////////////////////////////////////////////
0:     checkChunkFiles(conf, outputDir, DATA1, prefix, ParserType.TEXT);
0:   }
0: 
0:   /**
0:    * Story converting a TSV file to SequenceFile
0:    */
0:   @Test
0:   public void testSequnceFileFromDirectoryTsv() throws Exception {
0:     Configuration conf = new Configuration();
0:     FileSystem fs = FileSystem.get(conf);
0:     
0:     // parameters
0:     final String prefix = "UID";
0:     final int chunkSizeInMB = 64;
0:     final int keyColumn = 0;
0:     final int valueColumn = 1;
0:     
0:     // create
0:     Path tmpDir = this.getTestTempDirPath();
0:     Path inputDir = new Path(tmpDir, "inputDir");
0:     fs.mkdirs(inputDir);
0:     Path outputDir = new Path(tmpDir, "outputDir");
0:     
0:     // prepare input TSV file
0:     createTsvFilesFromArrays(conf, inputDir, DATA1);
0:     
0:     // convert it to SequenceFile
0:     SequenceFilesFromCsvFilter.main(new String[] {"--input", inputDir.toString(),
0:         "--output", outputDir.toString(), "--charset", UTF8.name(),
0:         "--chunkSize", Integer.toString(chunkSizeInMB), "--keyPrefix", prefix,
0:         "--keyColumn", Integer.toString(keyColumn), "--valueColumn",
0:         Integer.toString(valueColumn)});
0:     
0:     // check output chunk files
0:     checkChunkFiles(conf, outputDir, DATA1, prefix, ParserType.CSV);
/////////////////////////////////////////////////////////////////////////
0:   private static void createTsvFilesFromArrays(Configuration conf,
0:       Path inputDir, String[][] data) throws IOException {
0:     FileSystem fs = FileSystem.get(conf);
0:     OutputStreamWriter osw = new OutputStreamWriter(fs.create(new Path(inputDir, "inputTsvFile")));
0:     for (String[] aData : data) {
0:       osw.write(aData[0] + "\t" + aData[1] + "\n");
0:     }
0:     osw.close();
0:   }
0: 
0:   private static void checkChunkFiles(Configuration conf, Path outputDir, String[][] data, String prefix,
0:       ParserType inputType)
/////////////////////////////////////////////////////////////////////////
0:       if (ParserType.CSV == inputType) {
0:         fileToData.put(prefix + aData[0], aData[1]);
0:       }
0:       else {
0:         fileToData.put(prefix + Path.SEPARATOR + aData[0], aData[1]);
0:       }
0:     for (int i=0; i<data.length; ++i) {
============================================================================
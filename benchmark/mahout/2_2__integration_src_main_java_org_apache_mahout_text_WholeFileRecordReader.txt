1:d711ac1: /**
1:d711ac1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:d711ac1:  * contributor license agreements.  See the NOTICE file distributed with
1:d711ac1:  * this work for additional information regarding copyright ownership.
1:d711ac1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:d711ac1:  * (the "License"); you may not use this file except in compliance with
1:d711ac1:  * the License.  You may obtain a copy of the License at
1:85f9ece:  * <p/>
1:85f9ece:  * http://www.apache.org/licenses/LICENSE-2.0
1:85f9ece:  * <p/>
1:d711ac1:  * Unless required by applicable law or agreed to in writing, software
1:d711ac1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:d711ac1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:d711ac1:  * See the License for the specific language governing permissions and
1:d711ac1:  * limitations under the License.
1:d711ac1:  */
2:d711ac1: 
1:d711ac1: package org.apache.mahout.text;
1:d711ac1: 
1:d711ac1: import java.io.IOException;
1:d711ac1: 
1:c87196e: import org.apache.commons.lang3.StringUtils;
1:d711ac1: import org.apache.hadoop.conf.Configuration;
1:d711ac1: import org.apache.hadoop.fs.FSDataInputStream;
1:c87196e: import org.apache.hadoop.fs.FileStatus;
1:d711ac1: import org.apache.hadoop.fs.FileSystem;
1:d711ac1: import org.apache.hadoop.fs.Path;
1:c87196e: import org.apache.hadoop.fs.PathFilter;
1:d711ac1: import org.apache.hadoop.io.BytesWritable;
1:d711ac1: import org.apache.hadoop.io.IOUtils;
1:d711ac1: import org.apache.hadoop.io.IntWritable;
1:d711ac1: import org.apache.hadoop.mapreduce.InputSplit;
1:d711ac1: import org.apache.hadoop.mapreduce.RecordReader;
1:d711ac1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1:d711ac1: import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
1:d711ac1: import org.apache.hadoop.mapreduce.lib.input.FileSplit;
1:d711ac1: 
1:c87196e: import static org.apache.mahout.text.SequenceFilesFromDirectory.FILE_FILTER_CLASS_OPTION;
1:c87196e: 
1:d711ac1: /**
1:d711ac1:  * RecordReader used with the MultipleTextFileInputFormat class to read full files as
1:d711ac1:  * k/v pairs and groups of files as single input splits.
1:d711ac1:  */
1:d711ac1: public class WholeFileRecordReader extends RecordReader<IntWritable, BytesWritable> {
1:d711ac1: 
1:d711ac1:   private FileSplit fileSplit;
1:d711ac1:   private boolean processed = false;
1:d711ac1:   private Configuration configuration;
1:d711ac1:   private BytesWritable value = new BytesWritable();
1:d711ac1:   private IntWritable index;
1:c87196e:   private String fileFilterClassName = null;
1:c87196e:   private PathFilter pathFilter = null;
1:d711ac1: 
1:d711ac1:   public WholeFileRecordReader(CombineFileSplit fileSplit, TaskAttemptContext taskAttemptContext, Integer idx)
1:c87196e:       throws IOException {
1:d711ac1:     this.fileSplit = new FileSplit(fileSplit.getPath(idx), fileSplit.getOffset(idx),
1:85f9ece:         fileSplit.getLength(idx), fileSplit.getLocations());
1:d711ac1:     this.configuration = taskAttemptContext.getConfiguration();
1:d711ac1:     this.index = new IntWritable(idx);
1:c87196e:     this.fileFilterClassName = this.configuration.get(FILE_FILTER_CLASS_OPTION[0]);
2:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public IntWritable getCurrentKey() {
1:d711ac1:     return index;
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public BytesWritable getCurrentValue() {
1:d711ac1:     return value;
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public float getProgress() throws IOException {
1:d711ac1:     return processed ? 1.0f : 0.0f;
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)
1:85f9ece:       throws IOException, InterruptedException {
1:85f9ece:     if (!StringUtils.isBlank(fileFilterClassName) &&
1:85f9ece:         !PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {
1:c87196e:       try {
1:c87196e:         pathFilter = (PathFilter) Class.forName(fileFilterClassName).newInstance();
1:87c15be:       } catch (ClassNotFoundException | InstantiationException | IllegalAccessException e) {
3:c87196e:         throw new IllegalStateException(e);
1:c87196e:       }
1:c87196e:     }
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public boolean nextKeyValue() throws IOException {
1:d711ac1:     if (!processed) {
1:d711ac1:       byte[] contents = new byte[(int) fileSplit.getLength()];
1:d711ac1:       Path file = fileSplit.getPath();
1:d711ac1:       FileSystem fs = file.getFileSystem(this.configuration);
1:c87196e: 
1:c87196e:       if (!fs.isFile(file)) {
1:c87196e:         return false;
1:d711ac1:       }
1:c87196e: 
1:c87196e:       FileStatus[] fileStatuses;
1:c87196e:       if (pathFilter != null) {
1:c87196e:         fileStatuses = fs.listStatus(file, pathFilter);
1:c87196e:       } else {
1:c87196e:         fileStatuses = fs.listStatus(file);
1:c87196e:       }
1:c87196e: 
1:c87196e:       if (fileStatuses.length == 1) {
1:85f9ece:         try (FSDataInputStream in = fs.open(fileStatuses[0].getPath())) {
1:c87196e:           IOUtils.readFully(in, contents, 0, contents.length);
1:c87196e:           value.setCapacity(contents.length);
1:c87196e:           value.set(contents, 0, contents.length);
1:c87196e:         }
1:c87196e:         processed = true;
1:c87196e:         return true;
1:c87196e:       }
1:d711ac1:     }
2:d711ac1:     return false;
1:d711ac1:   }
1:d711ac1: 
1:d711ac1:   @Override
1:d711ac1:   public void close() throws IOException {
1:d711ac1:   }
1:d711ac1: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1:  * <p/>
1:  * http://www.apache.org/licenses/LICENSE-2.0
1:  * <p/>
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         fileSplit.getLength(idx), fileSplit.getLocations());
/////////////////////////////////////////////////////////////////////////
1:       throws IOException, InterruptedException {
1:     if (!StringUtils.isBlank(fileFilterClassName) &&
1:         !PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {
/////////////////////////////////////////////////////////////////////////
1:         try (FSDataInputStream in = fs.open(fileStatuses[0].getPath())) {
commit:87c15be
/////////////////////////////////////////////////////////////////////////
1:       } catch (ClassNotFoundException | InstantiationException | IllegalAccessException e) {
author:smarthi
-------------------------------------------------------------------------------
commit:c87196e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.commons.lang3.StringUtils;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.PathFilter;
/////////////////////////////////////////////////////////////////////////
1: import static org.apache.mahout.text.SequenceFilesFromDirectory.FILE_FILTER_CLASS_OPTION;
1: 
/////////////////////////////////////////////////////////////////////////
1:   private String fileFilterClassName = null;
1:   private PathFilter pathFilter = null;
1:       throws IOException {
0:       fileSplit.getLength(idx), fileSplit.getLocations());
1:     this.fileFilterClassName = this.configuration.get(FILE_FILTER_CLASS_OPTION[0]);
/////////////////////////////////////////////////////////////////////////
0:     if (!StringUtils.isBlank(fileFilterClassName) && !PrefixAdditionFilter.class.getName().equals(fileFilterClassName)) {
1:       try {
1:         pathFilter = (PathFilter) Class.forName(fileFilterClassName).newInstance();
0:       } catch (ClassNotFoundException e) {
1:         throw new IllegalStateException(e);
0:       } catch (InstantiationException e) {
1:         throw new IllegalStateException(e);
0:       } catch (IllegalAccessException e) {
1:         throw new IllegalStateException(e);
1:       }
1:     }
/////////////////////////////////////////////////////////////////////////
1: 
1:       if (!fs.isFile(file)) {
1:         return false;
1: 
1:       FileStatus[] fileStatuses;
1:       if (pathFilter != null) {
1:         fileStatuses = fs.listStatus(file, pathFilter);
1:       } else {
1:         fileStatuses = fs.listStatus(file);
1:       }
1: 
0:       FSDataInputStream in = null;
1:       if (fileStatuses.length == 1) {
0:         try {
0:           in = fs.open(fileStatuses[0].getPath());
1:           IOUtils.readFully(in, contents, 0, contents.length);
1:           value.setCapacity(contents.length);
1:           value.set(contents, 0, contents.length);
0:         } finally {
0:           Closeables.close(in, false);
1:         }
1:         processed = true;
1:         return true;
1:       }
commit:d711ac1
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.text;
1: 
1: import java.io.IOException;
1: 
0: import com.google.common.io.Closeables;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FSDataInputStream;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.BytesWritable;
1: import org.apache.hadoop.io.IOUtils;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.InputSplit;
1: import org.apache.hadoop.mapreduce.RecordReader;
1: import org.apache.hadoop.mapreduce.TaskAttemptContext;
1: import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;
1: import org.apache.hadoop.mapreduce.lib.input.FileSplit;
1: 
1: /**
1:  * RecordReader used with the MultipleTextFileInputFormat class to read full files as
1:  * k/v pairs and groups of files as single input splits.
1:  */
1: public class WholeFileRecordReader extends RecordReader<IntWritable, BytesWritable> {
1: 
1:   private FileSplit fileSplit;
1:   private boolean processed = false;
1:   private Configuration configuration;
1:   private BytesWritable value = new BytesWritable();
1:   private IntWritable index;
1: 
1:   public WholeFileRecordReader(CombineFileSplit fileSplit, TaskAttemptContext taskAttemptContext, Integer idx)
0:     throws IOException {
1:     this.fileSplit = new FileSplit(fileSplit.getPath(idx), fileSplit.getOffset(idx),
0:        fileSplit.getLength(idx), fileSplit.getLocations());
1:     this.configuration = taskAttemptContext.getConfiguration();
1:     this.index = new IntWritable(idx);
1:   }
1: 
1:   @Override
1:   public IntWritable getCurrentKey() {
1:     return index;
1:   }
1: 
1:   @Override
1:   public BytesWritable getCurrentValue() {
1:     return value;
1:   }
1: 
1:   @Override
1:   public float getProgress() throws IOException {
1:     return processed ? 1.0f : 0.0f;
1:   }
1: 
1:   @Override
1:   public void initialize(InputSplit inputSplit, TaskAttemptContext taskAttemptContext)
0:     throws IOException, InterruptedException {
1: 
1:   }
1: 
1:   @Override
1:   public boolean nextKeyValue() throws IOException {
1:     if (!processed) {
1:       byte[] contents = new byte[(int) fileSplit.getLength()];
1:       Path file = fileSplit.getPath();
1:       FileSystem fs = file.getFileSystem(this.configuration);
0:       FSDataInputStream in = null;
0:       try {
0:         if (!fs.isFile(file)) {
1:           return false;
1:         }
0:         in = fs.open(file);
0:         IOUtils.readFully(in, contents, 0, contents.length);
0:         value.setCapacity(contents.length);
0:         value.set(contents, 0, contents.length);
0:       } finally {
0:         Closeables.close(in, false);
1:       }
0:       processed = true;
0:       return true;
1:     }
1:     return false;
1:   }
1: 
1:   @Override
1:   public void close() throws IOException {
1:   }
1: }
============================================================================
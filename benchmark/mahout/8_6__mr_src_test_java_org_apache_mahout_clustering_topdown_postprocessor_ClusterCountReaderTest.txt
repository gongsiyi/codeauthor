1:9d44881: /**
1:9d44881:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:9d44881:  * contributor license agreements.  See the NOTICE file distributed with
1:9d44881:  * this work for additional information regarding copyright ownership.
1:9d44881:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:9d44881:  * (the "License"); you may not use this file except in compliance with
1:9d44881:  * the License.  You may obtain a copy of the License at
1:9d44881:  *
1:9d44881:  *     http://www.apache.org/licenses/LICENSE-2.0
1:9d44881:  *
1:9d44881:  * Unless required by applicable law or agreed to in writing, software
1:9d44881:  * distributed under the License is distributed on an "AS IS" BASIS,
1:9d44881:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:9d44881:  * See the License for the specific language governing permissions and
1:9d44881:  * limitations under the License.
1:9d44881:  */
4:9d44881: 
1:9d44881: package org.apache.mahout.clustering.topdown.postprocessor;
1:9d44881: 
1:9d44881: import java.io.IOException;
1:9d44881: import java.util.List;
1:9d44881: 
1:9d44881: import org.apache.hadoop.conf.Configuration;
1:9d44881: import org.apache.hadoop.fs.FileSystem;
1:9d44881: import org.apache.hadoop.fs.Path;
1:9d44881: import org.apache.hadoop.io.IntWritable;
1:9d44881: import org.apache.mahout.clustering.Cluster;
1:9d44881: import org.apache.mahout.clustering.ClusteringTestUtils;
1:9d44881: import org.apache.mahout.clustering.canopy.CanopyDriver;
1:8d102ea: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
1:9d44881: import org.apache.mahout.clustering.kmeans.KMeansDriver;
1:9d44881: import org.apache.mahout.common.DummyOutputCollector;
1:9d44881: import org.apache.mahout.common.MahoutTestCase;
1:9d44881: import org.apache.mahout.common.Pair;
1:564c3e1: import org.apache.mahout.common.distance.DistanceMeasure;
1:9d44881: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1:9d44881: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1:9d44881: import org.apache.mahout.math.RandomAccessSparseVector;
1:9d44881: import org.apache.mahout.math.Vector;
1:9d44881: import org.apache.mahout.math.VectorWritable;
1:9d44881: import org.junit.Assert;
1:9d44881: import org.junit.Before;
1:9d44881: import org.junit.Test;
1:9d44881: 
1:9d44881: import com.google.common.collect.Lists;
1:9d44881: 
1:564c3e1: public final class ClusterCountReaderTest extends MahoutTestCase {
1:9d44881:   
1:9d44881:   public static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}};
1:9d44881:   
1:9d44881:   private FileSystem fs;
1:9d44881:   private Path outputPathForCanopy;
1:9d44881:   private Path outputPathForKMeans;
1:9d44881:   
1:9d44881:   @Override
1:9d44881:   @Before
1:9d44881:   public void setUp() throws Exception {
1:9d44881:     super.setUp();
1:921e201:     Configuration conf = getConfiguration();
1:9d44881:     fs = FileSystem.get(conf);
1:9d44881:   }
1:9d44881:   
1:9d44881:   public static List<VectorWritable> getPointsWritable(double[][] raw) {
1:9d44881:     List<VectorWritable> points = Lists.newArrayList();
1:9d44881:     for (double[] fr : raw) {
1:9d44881:       Vector vec = new RandomAccessSparseVector(fr.length);
1:9d44881:       vec.assign(fr);
1:9d44881:       points.add(new VectorWritable(vec));
1:9d44881:     }
1:9d44881:     return points;
1:9d44881:   }
1:9d44881:   
1:9d44881:   /**
1:9d44881:    * Story: User wants to use cluster post processor after canopy clustering and then run clustering on the
1:9d44881:    * output clusters
1:9d44881:    */
1:9d44881:   @Test
1:9d44881:   public void testGetNumberOfClusters() throws Exception {
1:9d44881:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:9d44881:     
1:9d44881:     Path pointsPath = getTestTempDirPath("points");
1:921e201:     Configuration conf = getConfiguration();
1:9d44881:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
1:9d44881:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);
1:9d44881:     
1:9d44881:     outputPathForCanopy = getTestTempDirPath("canopy");
1:9d44881:     outputPathForKMeans = getTestTempDirPath("kmeans");
1:9d44881:     
1:9d44881:     topLevelClustering(pointsPath, conf);
1:9d44881:     
1:9d44881:     int numberOfClusters = ClusterCountReader.getNumberOfClusters(outputPathForKMeans, conf);
1:9d44881:     Assert.assertEquals(2, numberOfClusters);
1:9d44881:     verifyThatNumberOfClustersIsCorrect(conf, new Path(outputPathForKMeans, new Path("clusteredPoints")));
1:9d44881:     
1:9d44881:   }
1:9d44881:   
1:9d44881:   private void topLevelClustering(Path pointsPath, Configuration conf) throws IOException,
1:9d44881:                                                                       InterruptedException,
1:9d44881:                                                                       ClassNotFoundException {
1:564c3e1:     DistanceMeasure measure = new ManhattanDistanceMeasure();
1:f99a18f:     CanopyDriver.run(conf, pointsPath, outputPathForCanopy, measure, 4.0, 3.0, true, 0.0, true);
1:564c3e1:     Path clustersIn = new Path(outputPathForCanopy, new Path(Cluster.CLUSTERS_DIR + '0'
1:9d44881:                                                                    + Cluster.FINAL_ITERATION_SUFFIX));
1:8405928:     KMeansDriver.run(conf, pointsPath, clustersIn, outputPathForKMeans, 1, 1, true, 0.0, true);
1:9d44881:   }
1:9d44881:   
1:564c3e1:   private static void verifyThatNumberOfClustersIsCorrect(Configuration conf, Path clusteredPointsPath) {
1:564c3e1:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector =
1:02ff22f:         new DummyOutputCollector<>();
1:9d44881:     
1:9d44881:     // The key is the clusterId, the value is the weighted vector
1:564c3e1:     for (Pair<IntWritable,WeightedVectorWritable> record :
1:564c3e1:          new SequenceFileIterable<IntWritable,WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"),
1:564c3e1:                                                                       conf)) {
1:9d44881:       collector.collect(record.getFirst(), record.getSecond());
1:9d44881:     }
1:564c3e1:     int clusterSize = collector.getKeys().size();
1:564c3e1:     assertEquals(2, clusterSize);
1:9d44881:   }
1:9d44881:   
1:9d44881: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:         new DummyOutputCollector<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:8405928
/////////////////////////////////////////////////////////////////////////
1:     KMeansDriver.run(conf, pointsPath, clustersIn, outputPathForKMeans, 1, 1, true, 0.0, true);
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:pranjan
-------------------------------------------------------------------------------
commit:2cfaf19
/////////////////////////////////////////////////////////////////////////
0:     KMeansDriver.run(conf, pointsPath, clustersIn, outputPathForKMeans, measure, 1, 1, true, 0.0, true);
commit:f99a18f
/////////////////////////////////////////////////////////////////////////
1:     CanopyDriver.run(conf, pointsPath, outputPathForCanopy, measure, 4.0, 3.0, true, 0.0, true);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
commit:9d44881
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.clustering.topdown.postprocessor;
1: 
1: import java.io.IOException;
1: import java.util.List;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.mahout.clustering.Cluster;
1: import org.apache.mahout.clustering.ClusteringTestUtils;
0: import org.apache.mahout.clustering.WeightedVectorWritable;
1: import org.apache.mahout.clustering.canopy.CanopyDriver;
1: import org.apache.mahout.clustering.kmeans.KMeansDriver;
1: import org.apache.mahout.common.DummyOutputCollector;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1: import org.apache.mahout.math.RandomAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Assert;
1: import org.junit.Before;
1: import org.junit.Test;
1: 
1: import com.google.common.collect.Lists;
1: 
0: public class ClusterCountReaderTest extends MahoutTestCase {
1:   
1:   public static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}};
1:   
1:   private FileSystem fs;
1:   
1:   private Path outputPathForCanopy;
1:   
0:   private Configuration conf;
1:   
1:   private Path outputPathForKMeans;
1:   
1:   @Override
1:   @Before
1:   public void setUp() throws Exception {
1:     super.setUp();
0:     Configuration conf = new Configuration();
1:     fs = FileSystem.get(conf);
1:   }
1:   
1:   public static List<VectorWritable> getPointsWritable(double[][] raw) {
1:     List<VectorWritable> points = Lists.newArrayList();
1:     for (double[] fr : raw) {
1:       Vector vec = new RandomAccessSparseVector(fr.length);
1:       vec.assign(fr);
1:       points.add(new VectorWritable(vec));
1:     }
1:     return points;
1:   }
1:   
1:   /**
1:    * Story: User wants to use cluster post processor after canopy clustering and then run clustering on the
1:    * output clusters
1:    */
1:   @Test
1:   public void testGetNumberOfClusters() throws Exception {
1:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:     
1:     Path pointsPath = getTestTempDirPath("points");
0:     conf = new Configuration();
1:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
1:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);
1:     
1:     outputPathForCanopy = getTestTempDirPath("canopy");
1:     outputPathForKMeans = getTestTempDirPath("kmeans");
1:     
1:     topLevelClustering(pointsPath, conf);
1:     
1:     int numberOfClusters = ClusterCountReader.getNumberOfClusters(outputPathForKMeans, conf);
1:     Assert.assertEquals(2, numberOfClusters);
1:     verifyThatNumberOfClustersIsCorrect(conf, new Path(outputPathForKMeans, new Path("clusteredPoints")));
1:     
1:   }
1:   
1:   private void topLevelClustering(Path pointsPath, Configuration conf) throws IOException,
1:                                                                       InterruptedException,
1:                                                                       ClassNotFoundException {
0:     final ManhattanDistanceMeasure measure = new ManhattanDistanceMeasure();
0:     CanopyDriver.run(conf, pointsPath, outputPathForCanopy, measure, 4.0, 3.0, true, true);
0:     final Path clustersIn = new Path(outputPathForCanopy, new Path(Cluster.CLUSTERS_DIR + '0'
1:                                                                    + Cluster.FINAL_ITERATION_SUFFIX));
0:     KMeansDriver.run(conf, pointsPath, clustersIn, outputPathForKMeans, measure, 1, 1, true, true);
1:   }
1:   
0:   private void verifyThatNumberOfClustersIsCorrect(Configuration conf, Path clusteredPointsPath) {
0:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector = new DummyOutputCollector<IntWritable,WeightedVectorWritable>();
1:     
1:     // The key is the clusterId, the value is the weighted vector
0:     for (Pair<IntWritable,WeightedVectorWritable> record : new SequenceFileIterable<IntWritable,WeightedVectorWritable>(
0:         new Path(clusteredPointsPath, "part-m-0"), conf)) {
1:       collector.collect(record.getFirst(), record.getSecond());
1:     }
0:     final int clusterSize = collector.getKeys().size();
0:     Assert.assertTrue(clusterSize == 2);
1:   }
1:   
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.distance.DistanceMeasure;
/////////////////////////////////////////////////////////////////////////
1: public final class ClusterCountReaderTest extends MahoutTestCase {
/////////////////////////////////////////////////////////////////////////
0:     Configuration conf = new Configuration();
/////////////////////////////////////////////////////////////////////////
1:     DistanceMeasure measure = new ManhattanDistanceMeasure();
1:     Path clustersIn = new Path(outputPathForCanopy, new Path(Cluster.CLUSTERS_DIR + '0'
1:   private static void verifyThatNumberOfClustersIsCorrect(Configuration conf, Path clusteredPointsPath) {
1:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector =
0:         new DummyOutputCollector<IntWritable,WeightedVectorWritable>();
1:     for (Pair<IntWritable,WeightedVectorWritable> record :
1:          new SequenceFileIterable<IntWritable,WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"),
1:                                                                       conf)) {
1:     int clusterSize = collector.getKeys().size();
1:     assertEquals(2, clusterSize);
============================================================================
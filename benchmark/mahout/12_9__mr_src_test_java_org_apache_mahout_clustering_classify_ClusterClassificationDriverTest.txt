1:6a3f566: /**
1:6a3f566:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:6a3f566:  * contributor license agreements.  See the NOTICE file distributed with
1:6a3f566:  * this work for additional information regarding copyright ownership.
1:6a3f566:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:6a3f566:  * (the "License"); you may not use this file except in compliance with
1:6a3f566:  * the License.  You may obtain a copy of the License at
1:6a3f566:  *
1:6a3f566:  *     http://www.apache.org/licenses/LICENSE-2.0
1:6a3f566:  *
1:6a3f566:  * Unless required by applicable law or agreed to in writing, software
1:6a3f566:  * distributed under the License is distributed on an "AS IS" BASIS,
1:6a3f566:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:6a3f566:  * See the License for the specific language governing permissions and
1:6a3f566:  * limitations under the License.
1:6a3f566:  */
1:be94533: 
1:6a3f566: package org.apache.mahout.clustering.classify;
1:1371326: 
1:6a3f566: import java.io.IOException;
1:6a3f566: import java.util.List;
1:90987ff: import java.util.Set;
1:1371326: 
1:67a531e: import org.apache.commons.lang3.ArrayUtils;
1:6a3f566: import org.apache.hadoop.conf.Configuration;
1:6a3f566: import org.apache.hadoop.fs.FileStatus;
1:6a3f566: import org.apache.hadoop.fs.FileSystem;
1:6a3f566: import org.apache.hadoop.fs.FileUtil;
1:6a3f566: import org.apache.hadoop.fs.Path;
1:6a3f566: import org.apache.hadoop.io.IntWritable;
1:6a3f566: import org.apache.hadoop.io.SequenceFile;
1:6a3f566: import org.apache.hadoop.io.Writable;
1:6a3f566: import org.apache.mahout.clustering.ClusteringTestUtils;
1:6a3f566: import org.apache.mahout.clustering.canopy.CanopyDriver;
1:8d102ea: import org.apache.mahout.clustering.iterator.CanopyClusteringPolicy;
1:1371326: import org.apache.mahout.common.HadoopUtil;
1:6a3f566: import org.apache.mahout.common.MahoutTestCase;
1:6a3f566: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1:1371326: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:e93f05d: import org.apache.mahout.math.NamedVector;
1:6a3f566: import org.apache.mahout.math.RandomAccessSparseVector;
1:6a3f566: import org.apache.mahout.math.Vector;
1:6a3f566: import org.apache.mahout.math.VectorWritable;
1:229aeff: import org.junit.Assert;
1:6a3f566: import org.junit.Before;
1:6a3f566: import org.junit.Test;
1:1371326: 
1:6a3f566: import com.google.common.collect.Lists;
1:be94533: import com.google.common.collect.Sets;
1:90987ff: 
1:457db94: public class ClusterClassificationDriverTest extends MahoutTestCase {
1:be94533: 
1:98f66f4:   private static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4},
1:98f66f4:       {5, 4}, {4, 5}, {5, 5}, {9, 9}, {8, 8}};
1:be94533: 
1:6a3f566:   private FileSystem fs;
1:6a3f566:   private Path clusteringOutputPath;
1:6a3f566:   private Configuration conf;
1:6a3f566:   private Path pointsPath;
1:6a3f566:   private Path classifiedOutputPath;
1:6a3f566:   private List<Vector> firstCluster;
1:6a3f566:   private List<Vector> secondCluster;
1:6a3f566:   private List<Vector> thirdCluster;
1:be94533: 
1:6a3f566:   @Override
1:6a3f566:   @Before
1:6a3f566:   public void setUp() throws Exception {
1:6a3f566:     super.setUp();
1:e3ec9d8:     Configuration conf = getConfiguration();
1:6a3f566:     fs = FileSystem.get(conf);
1:210b265:     firstCluster = Lists.newArrayList();
1:210b265:     secondCluster = Lists.newArrayList();
1:210b265:     thirdCluster = Lists.newArrayList();
1:be94533: 
10:6a3f566:   }
1:be94533: 
1:6a3f566:   private static List<VectorWritable> getPointsWritable(double[][] raw) {
1:6a3f566:     List<VectorWritable> points = Lists.newArrayList();
1:6a3f566:     for (double[] fr : raw) {
1:6a3f566:       Vector vec = new RandomAccessSparseVector(fr.length);
1:6a3f566:       vec.assign(fr);
1:6a3f566:       points.add(new VectorWritable(vec));
1:6a3f566:     }
1:6a3f566:     return points;
1:6a3f566:   }
1:be94533: 
1:6a3f566:   @Test
1:1371326:   public void testVectorClassificationWithOutlierRemovalMR() throws Exception {
1:1371326:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:be94533: 
1:1371326:     pointsPath = getTestTempDirPath("points");
1:1371326:     clusteringOutputPath = getTestTempDirPath("output");
1:1371326:     classifiedOutputPath = getTestTempDirPath("classifiedClusters");
1:1371326:     HadoopUtil.delete(conf, classifiedOutputPath);
1:be94533: 
1:e3ec9d8:     conf = getConfiguration();
1:be94533: 
1:be94533:     ClusteringTestUtils.writePointsToFile(points, true,
1:1371326:         new Path(pointsPath, "file1"), fs, conf);
1:1371326:     runClustering(pointsPath, conf, false);
1:229aeff:     runClassificationWithOutlierRemoval(false);
1:1371326:     collectVectorsForAssertion();
1:1371326:     assertVectorsWithOutlierRemoval();
1:1371326:   }
1:be94533: 
1:1371326:   @Test
1:6a3f566:   public void testVectorClassificationWithoutOutlierRemoval() throws Exception {
1:6a3f566:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:be94533: 
1:6a3f566:     pointsPath = getTestTempDirPath("points");
1:6a3f566:     clusteringOutputPath = getTestTempDirPath("output");
1:6a3f566:     classifiedOutputPath = getTestTempDirPath("classify");
1:be94533: 
1:921e201:     conf = getConfiguration();
1:be94533: 
1:1371326:     ClusteringTestUtils.writePointsToFile(points,
1:98f66f4:         new Path(pointsPath, "file1"), fs, conf);
1:1371326:     runClustering(pointsPath, conf, true);
1:229aeff:     runClassificationWithoutOutlierRemoval();
1:6a3f566:     collectVectorsForAssertion();
1:6a3f566:     assertVectorsWithoutOutlierRemoval();
1:6a3f566:   }
1:be94533: 
1:6a3f566:   @Test
1:6a3f566:   public void testVectorClassificationWithOutlierRemoval() throws Exception {
1:6a3f566:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:be94533: 
1:6a3f566:     pointsPath = getTestTempDirPath("points");
1:6a3f566:     clusteringOutputPath = getTestTempDirPath("output");
1:6a3f566:     classifiedOutputPath = getTestTempDirPath("classify");
1:be94533: 
1:e3ec9d8:     conf = getConfiguration();
1:be94533: 
1:98f66f4:     ClusteringTestUtils.writePointsToFile(points,
1:98f66f4:         new Path(pointsPath, "file1"), fs, conf);
1:1371326:     runClustering(pointsPath, conf, true);
1:229aeff:     runClassificationWithOutlierRemoval(true);
1:6a3f566:     collectVectorsForAssertion();
1:6a3f566:     assertVectorsWithOutlierRemoval();
1:6a3f566:   }
1:be94533: 
1:1371326:   private void runClustering(Path pointsPath, Configuration conf,
1:1371326:       Boolean runSequential) throws IOException, InterruptedException,
1:1371326:       ClassNotFoundException {
1:98f66f4:     CanopyDriver.run(conf, pointsPath, clusteringOutputPath,
1:f99a18f:         new ManhattanDistanceMeasure(), 3.1, 2.1, false, 0.0, runSequential);
1:457db94:     Path finalClustersPath = new Path(clusteringOutputPath, "clusters-0-final");
1:98f66f4:     ClusterClassifier.writePolicy(new CanopyClusteringPolicy(),
1:98f66f4:         finalClustersPath);
1:6a3f566:   }
1:be94533: 
1:229aeff:   private void runClassificationWithoutOutlierRemoval()
1:229aeff:     throws IOException, InterruptedException, ClassNotFoundException {
1:e3ec9d8:     ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.0, true, true);
1:6a3f566:   }
1:be94533: 
1:229aeff:   private void runClassificationWithOutlierRemoval(boolean runSequential)
1:229aeff:     throws IOException, InterruptedException, ClassNotFoundException {
1:e3ec9d8:     ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.73, true, runSequential);
1:6a3f566:   }
1:be94533: 
1:6a3f566:   private void collectVectorsForAssertion() throws IOException {
1:98f66f4:     Path[] partFilePaths = FileUtil.stat2Paths(fs
1:98f66f4:         .globStatus(classifiedOutputPath));
1:1371326:     FileStatus[] listStatus = fs.listStatus(partFilePaths,
1:1371326:         PathFilters.partFilter());
1:6a3f566:     for (FileStatus partFile : listStatus) {
1:98f66f4:       SequenceFile.Reader classifiedVectors = new SequenceFile.Reader(fs,
1:98f66f4:           partFile.getPath(), conf);
1:6a3f566:       Writable clusterIdAsKey = new IntWritable();
1:8253491:       WeightedPropertyVectorWritable point = new WeightedPropertyVectorWritable();
1:6a3f566:       while (classifiedVectors.next(clusterIdAsKey, point)) {
1:1371326:         collectVector(clusterIdAsKey.toString(), point.getVector());
1:6a3f566:       }
1:6a3f566:     }
1:6a3f566:   }
1:1371326: 
1:6a3f566:   private void collectVector(String clusterId, Vector vector) {
1:229aeff:     if ("0".equals(clusterId)) {
1:6a3f566:       firstCluster.add(vector);
1:229aeff:     } else if ("1".equals(clusterId)) {
1:6a3f566:       secondCluster.add(vector);
1:229aeff:     } else if ("2".equals(clusterId)) {
1:6a3f566:       thirdCluster.add(vector);
1:6a3f566:     }
1:6a3f566:   }
1:be94533: 
1:6a3f566:   private void assertVectorsWithOutlierRemoval() {
1:90987ff:     checkClustersWithOutlierRemoval();
1:6a3f566:   }
1:be94533: 
1:6a3f566:   private void assertVectorsWithoutOutlierRemoval() {
1:6a3f566:     assertFirstClusterWithoutOutlierRemoval();
1:6a3f566:     assertSecondClusterWithoutOutlierRemoval();
1:6a3f566:     assertThirdClusterWithoutOutlierRemoval();
1:6a3f566:   }
1:be94533: 
1:6a3f566:   private void assertThirdClusterWithoutOutlierRemoval() {
1:6a3f566:     Assert.assertEquals(2, thirdCluster.size());
2:6a3f566:     for (Vector vector : thirdCluster) {
1:be94533:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:9.0,1:9.0}",
1:be94533:           "{0:8.0,1:8.0}"}, vector.asFormatString()));
1:6a3f566:     }
1:6a3f566:   }
1:be94533: 
1:6a3f566:   private void assertSecondClusterWithoutOutlierRemoval() {
1:6a3f566:     Assert.assertEquals(4, secondCluster.size());
1:6a3f566:     for (Vector vector : secondCluster) {
1:be94533:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:4.0,1:4.0}",
1:be94533:           "{0:5.0,1:4.0}", "{0:4.0,1:5.0}", "{0:5.0,1:5.0}"},
2:98f66f4:           vector.asFormatString()));
1:6a3f566:     }
1:6a3f566:   }
1:be94533: 
1:457db94:   private void assertFirstClusterWithoutOutlierRemoval() {
1:457db94:     Assert.assertEquals(3, firstCluster.size());
1:457db94:     for (Vector vector : firstCluster) {
1:be94533:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:1.0,1:1.0}",
1:be94533:           "{0:2.0,1:1.0}", "{0:1.0,1:2.0}"}, vector.asFormatString()));
1:457db94:     }
1:457db94:   }
1:90987ff: 
1:90987ff:   private void checkClustersWithOutlierRemoval() {
1:be94533:     Set<String> reference = Sets.newHashSet("{0:9.0,1:9.0}", "{0:1.0,1:1.0}");
1:90987ff: 
1:90987ff:     List<List<Vector>> clusters = Lists.newArrayList();
1:90987ff:     clusters.add(firstCluster);
1:90987ff:     clusters.add(secondCluster);
1:90987ff:     clusters.add(thirdCluster);
1:90987ff: 
1:229aeff:     int singletonCnt = 0;
1:229aeff:     int emptyCnt = 0;
1:90987ff:     for (List<Vector> vList : clusters) {
1:229aeff:       if (vList.isEmpty()) {
1:90987ff:         emptyCnt++;
1:90987ff:       } else {
1:90987ff:         singletonCnt++;
1:229aeff:         assertEquals("expecting only singleton clusters; got size=" + vList.size(), 1, vList.size());
1:ab6216f:         if (vList.get(0).getClass().equals(NamedVector.class)) {
1:e93f05d:           Assert.assertTrue("not expecting cluster:" + ((NamedVector) vList.get(0)).getDelegate().asFormatString(),
1:e93f05d:                   reference.contains(((NamedVector)  vList.get(0)).getDelegate().asFormatString()));
1:e93f05d:           reference.remove(((NamedVector)vList.get(0)).getDelegate().asFormatString());
1:ab6216f:         } else if (vList.get(0).getClass().equals(RandomAccessSparseVector.class)) {
1:e93f05d:           Assert.assertTrue("not expecting cluster:" + vList.get(0).asFormatString(),
1:e93f05d:                   reference.contains(vList.get(0).asFormatString()));
1:e93f05d:           reference.remove(vList.get(0).asFormatString());
1:e93f05d:         }
1:be94533:       }
1:90987ff:     }
1:90987ff:     Assert.assertEquals("Different number of empty clusters than expected!", 1, emptyCnt);
1:90987ff:     Assert.assertEquals("Different number of singletons than expected!", 2, singletonCnt);
1:90987ff:     Assert.assertEquals("Didn't match all reference clusters!", 0, reference.size());
1:90987ff:   }
1:90987ff: 
1:6a3f566: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:ab6216f
/////////////////////////////////////////////////////////////////////////
1:         if (vList.get(0).getClass().equals(NamedVector.class)) {
1:         } else if (vList.get(0).getClass().equals(RandomAccessSparseVector.class)) {
commit:e93f05d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.math.NamedVector;
/////////////////////////////////////////////////////////////////////////
0:         if (vList.get(0) instanceof NamedVector) {
1:           Assert.assertTrue("not expecting cluster:" + ((NamedVector) vList.get(0)).getDelegate().asFormatString(),
1:                   reference.contains(((NamedVector)  vList.get(0)).getDelegate().asFormatString()));
1:           reference.remove(((NamedVector)vList.get(0)).getDelegate().asFormatString());
0:         } else if (vList.get(0) instanceof RandomAccessSparseVector) {
1:           Assert.assertTrue("not expecting cluster:" + vList.get(0).asFormatString(),
1:                   reference.contains(vList.get(0).asFormatString()));
1:           reference.remove(vList.get(0).asFormatString());
1:         }
commit:8253491
/////////////////////////////////////////////////////////////////////////
1:       WeightedPropertyVectorWritable point = new WeightedPropertyVectorWritable();
commit:69178eb
/////////////////////////////////////////////////////////////////////////
commit:67a531e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.commons.lang3.ArrayUtils;
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.util.ToolRunner;
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
commit:229aeff
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import org.junit.Assert;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     runClassificationWithOutlierRemoval(false);
/////////////////////////////////////////////////////////////////////////
1:     runClassificationWithoutOutlierRemoval();
/////////////////////////////////////////////////////////////////////////
1:     runClassificationWithOutlierRemoval(true);
/////////////////////////////////////////////////////////////////////////
1:   private void runClassificationWithoutOutlierRemoval()
1:     throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath, classifiedOutputPath, 0.0, true, true);
1:   private void runClassificationWithOutlierRemoval(boolean runSequential)
1:     throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath, classifiedOutputPath, 0.73, true, runSequential);
/////////////////////////////////////////////////////////////////////////
1:     if ("0".equals(clusterId)) {
1:     } else if ("1".equals(clusterId)) {
1:     } else if ("2".equals(clusterId)) {
/////////////////////////////////////////////////////////////////////////
0:     Set<String> reference = Sets.newHashSet("{1:9.0,0:9.0}", "{1:1.0,0:1.0}");
1:     int singletonCnt = 0;
1:     int emptyCnt = 0;
1:       if (vList.isEmpty()) {
1:         assertEquals("expecting only singleton clusters; got size=" + vList.size(), 1, vList.size());
author:Isabel Drost
-------------------------------------------------------------------------------
commit:e3ec9d8
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.util.ToolRunner;
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.0, true, true);
1:     ClusterClassificationDriver.run(getConfiguration(), pointsPath, clusteringOutputPath, classifiedOutputPath, 0.73, true, runSequential);
author:Robin Anil
-------------------------------------------------------------------------------
commit:be94533
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.collect.Sets;
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1:     ClusteringTestUtils.writePointsToFile(points, true,
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:9.0,1:9.0}",
1:           "{0:8.0,1:8.0}"}, vector.asFormatString()));
1: 
1:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:4.0,1:4.0}",
1:           "{0:5.0,1:4.0}", "{0:4.0,1:5.0}", "{0:5.0,1:5.0}"},
1: 
1:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:1.0,1:1.0}",
1:           "{0:2.0,1:1.0}", "{0:1.0,1:2.0}"}, vector.asFormatString()));
1:     Set<String> reference = Sets.newHashSet("{0:9.0,1:9.0}", "{0:1.0,1:1.0}");
/////////////////////////////////////////////////////////////////////////
1:     }
author:Ted Dunning
-------------------------------------------------------------------------------
commit:402e296
/////////////////////////////////////////////////////////////////////////
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:210b265
/////////////////////////////////////////////////////////////////////////
1:     firstCluster = Lists.newArrayList();
1:     secondCluster = Lists.newArrayList();
1:     thirdCluster = Lists.newArrayList();
author:pranjan
-------------------------------------------------------------------------------
commit:ba81a93
/////////////////////////////////////////////////////////////////////////
0:     ClusteringTestUtils.writePointsToFile(points, true, 
commit:f99a18f
/////////////////////////////////////////////////////////////////////////
1:         new ManhattanDistanceMeasure(), 3.1, 2.1, false, 0.0, runSequential);
commit:1371326
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
/////////////////////////////////////////////////////////////////////////
1:   public void testVectorClassificationWithOutlierRemovalMR() throws Exception {
1:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:     
1:     pointsPath = getTestTempDirPath("points");
1:     clusteringOutputPath = getTestTempDirPath("output");
1:     classifiedOutputPath = getTestTempDirPath("classifiedClusters");
1:     HadoopUtil.delete(conf, classifiedOutputPath);
1:     
0:     conf = new Configuration();
1:     
1:     ClusteringTestUtils.writePointsToFile(points,
1:         new Path(pointsPath, "file1"), fs, conf);
1:     runClustering(pointsPath, conf, false);
0:     runClassificationWithOutlierRemoval(conf, false);
1:     collectVectorsForAssertion();
1:     assertVectorsWithOutlierRemoval();
1:   }
1:   
1:   @Test
/////////////////////////////////////////////////////////////////////////
1:     runClustering(pointsPath, conf, true);
/////////////////////////////////////////////////////////////////////////
1:     runClustering(pointsPath, conf, true);
0:     runClassificationWithOutlierRemoval(conf, true);
1:   private void runClustering(Path pointsPath, Configuration conf,
1:       Boolean runSequential) throws IOException, InterruptedException,
1:       ClassNotFoundException {
0:         new ManhattanDistanceMeasure(), 3.1, 2.1, false, runSequential);
/////////////////////////////////////////////////////////////////////////
0:   private void runClassificationWithOutlierRemoval(Configuration conf2,
0:       boolean runSequential) throws IOException, InterruptedException,
0:       ClassNotFoundException {
0:         classifiedOutputPath, 0.73, true, runSequential);
1:     FileStatus[] listStatus = fs.listStatus(partFilePaths,
1:         PathFilters.partFilter());
0:       WeightedVectorWritable point = new WeightedVectorWritable();
1:         collectVector(clusterIdAsKey.toString(), point.getVector());
commit:98f66f4
/////////////////////////////////////////////////////////////////////////
1:   private static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4},
1:       {5, 4}, {4, 5}, {5, 5}, {9, 9}, {8, 8}};
/////////////////////////////////////////////////////////////////////////
1:     ClusteringTestUtils.writePointsToFile(points,
1:         new Path(pointsPath, "file1"), fs, conf);
/////////////////////////////////////////////////////////////////////////
0:     ClusteringTestUtils.writePointsToFile(points,
1:         new Path(pointsPath, "file1"), fs, conf);
0:   private void runClustering(Path pointsPath, Configuration conf)
0:       throws IOException, InterruptedException, ClassNotFoundException {
1:     CanopyDriver.run(conf, pointsPath, clusteringOutputPath,
0:         new ManhattanDistanceMeasure(), 3.1, 2.1, false, true);
1:     ClusterClassifier.writePolicy(new CanopyClusteringPolicy(),
1:         finalClustersPath);
0:   private void runClassificationWithoutOutlierRemoval(Configuration conf)
0:       throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath,
0:         classifiedOutputPath, 0.0, true, true);
0:   private void runClassificationWithOutlierRemoval(Configuration conf2)
0:       throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath,
0:         classifiedOutputPath, 0.73, true, true);
1:     Path[] partFilePaths = FileUtil.stat2Paths(fs
1:         .globStatus(classifiedOutputPath));
1:       SequenceFile.Reader classifiedVectors = new SequenceFile.Reader(fs,
1:           partFile.getPath(), conf);
/////////////////////////////////////////////////////////////////////////
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:9.0,0:9.0}",
0:           "{1:8.0,0:8.0}"}, vector.asFormatString()));
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:4.0,0:4.0}",
0:           "{1:4.0,0:5.0}", "{1:5.0,0:4.0}", "{1:5.0,0:5.0}"},
1:           vector.asFormatString()));
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}",
0:           "{1:1.0,0:2.0}", "{1:2.0,0:1.0}"}, vector.asFormatString()));
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:9.0,0:9.0}"},
1:           vector.asFormatString()));
/////////////////////////////////////////////////////////////////////////
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}"},
0:           vector.asFormatString()));
author:tcp
-------------------------------------------------------------------------------
commit:90987ff
/////////////////////////////////////////////////////////////////////////
1: import java.util.Set;
1: 
0: import com.google.common.collect.Sets;
/////////////////////////////////////////////////////////////////////////
1:     checkClustersWithOutlierRemoval();
/////////////////////////////////////////////////////////////////////////
1: 
1:   private void checkClustersWithOutlierRemoval() {
0:     Set<String> reference = Sets.newHashSet(new String[] {"{1:9.0,0:9.0}",
0:                                                           "{1:1.0,0:1.0}"});
0:     int singletonCnt = 0;
0:     int emptyCnt = 0;
1: 
1:     List<List<Vector>> clusters = Lists.newArrayList();
1:     clusters.add(firstCluster);
1:     clusters.add(secondCluster);
1:     clusters.add(thirdCluster);
1: 
1:     for (List<Vector> vList : clusters) {
0:       if (vList.size() == 0) {
1:         emptyCnt++;
1:       } else {
1:         singletonCnt++;
0:         Assert.assertTrue("expecting only singleton clusters; got size=" + vList.size(),
0:                           vList.size() == 1);
0:         Assert.assertTrue("not expecting cluster:" + vList.get(0).asFormatString(),
0:                           reference.contains(vList.get(0).asFormatString()));
0:         reference.remove(vList.get(0).asFormatString());
1:       }
1:     } 
1:     Assert.assertEquals("Different number of empty clusters than expected!", 1, emptyCnt);
1:     Assert.assertEquals("Different number of singletons than expected!", 2, singletonCnt);
1:     Assert.assertEquals("Didn't match all reference clusters!", 0, reference.size());
1: 
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.iterator.CanopyClusteringPolicy;
commit:457db94
/////////////////////////////////////////////////////////////////////////
0: import org.apache.mahout.clustering.CanopyClusteringPolicy;
0: import org.apache.mahout.clustering.ClusterClassifier;
/////////////////////////////////////////////////////////////////////////
1: public class ClusterClassificationDriverTest extends MahoutTestCase {
/////////////////////////////////////////////////////////////////////////
0:   
0:   
0:   
/////////////////////////////////////////////////////////////////////////
0:     
/////////////////////////////////////////////////////////////////////////
0:     
/////////////////////////////////////////////////////////////////////////
0:   private void runClustering(Path pointsPath, Configuration conf) throws IOException, InterruptedException,
0:       ClassNotFoundException {
1:     Path finalClustersPath = new Path(clusteringOutputPath, "clusters-0-final");
0:     ClusterClassifier.writePolicy(new CanopyClusteringPolicy(), finalClustersPath);
0:   private void runClassificationWithoutOutlierRemoval(Configuration conf) throws IOException, InterruptedException,
0:       ClassNotFoundException {
0:   private void runClassificationWithOutlierRemoval(Configuration conf2) throws IOException, InterruptedException,
0:       ClassNotFoundException {
0:   
/////////////////////////////////////////////////////////////////////////
0:     if (clusterId.equals("0")) {
0:     } else if (clusterId.equals("1")) {
0:     } else if (clusterId.equals("2")) {
/////////////////////////////////////////////////////////////////////////
0:   
0:   
0:   
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:4.0,0:4.0}", "{1:4.0,0:5.0}", "{1:5.0,0:4.0}",
0:           "{1:5.0,0:5.0}"}, vector.asFormatString()));
1:   private void assertFirstClusterWithoutOutlierRemoval() {
1:     Assert.assertEquals(3, firstCluster.size());
1:     for (Vector vector : firstCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}", "{1:1.0,0:2.0}", "{1:2.0,0:1.0}"},
0:           vector.asFormatString()));
1:     }
1:   }
0:   
0:   
0:   
commit:6a3f566
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: 
1: package org.apache.mahout.clustering.classify;
0: 
1: import java.io.IOException;
0: import java.util.ArrayList;
1: import java.util.List;
0: 
0: import junit.framework.Assert;
0: 
0: import org.apache.commons.lang.ArrayUtils;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.FileUtil;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.Writable;
1: import org.apache.mahout.clustering.ClusteringTestUtils;
1: import org.apache.mahout.clustering.canopy.CanopyDriver;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1: import org.apache.mahout.math.RandomAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Before;
1: import org.junit.Test;
0: 
1: import com.google.common.collect.Lists;
0: 
0: public class ClusterClassificationDriverTest extends MahoutTestCase{
0:   
0:   private static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}, {9, 9}, {8, 8}};
0:   
1:   private FileSystem fs;
0:   
1:   private Path clusteringOutputPath;
0:   
1:   private Configuration conf;
0: 
1:   private Path pointsPath;
0: 
1:   private Path classifiedOutputPath;
0: 
1:   private List<Vector> firstCluster;
0:   
1:   private List<Vector> secondCluster;
0:   
1:   private List<Vector> thirdCluster;
0:   
1:   @Override
1:   @Before
1:   public void setUp() throws Exception {
1:     super.setUp();
0:     Configuration conf = new Configuration();
1:     fs = FileSystem.get(conf);
0:     firstCluster = new ArrayList<Vector>();
0:     secondCluster = new ArrayList<Vector>();
0:     thirdCluster = new ArrayList<Vector>();
0:     
1:   }
0:   
1:   private static List<VectorWritable> getPointsWritable(double[][] raw) {
1:     List<VectorWritable> points = Lists.newArrayList();
1:     for (double[] fr : raw) {
1:       Vector vec = new RandomAccessSparseVector(fr.length);
1:       vec.assign(fr);
1:       points.add(new VectorWritable(vec));
1:     }
1:     return points;
1:   }
0:   
1:   @Test
1:   public void testVectorClassificationWithoutOutlierRemoval() throws Exception {
1:     List<VectorWritable> points = getPointsWritable(REFERENCE);
0:     
1:     pointsPath = getTestTempDirPath("points");
1:     clusteringOutputPath = getTestTempDirPath("output");
1:     classifiedOutputPath = getTestTempDirPath("classify");
0: 
0:     conf = new Configuration();
0:     
0:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
0:     runClustering(pointsPath, conf);
0:     runClassificationWithoutOutlierRemoval(conf);
1:     collectVectorsForAssertion();
1:     assertVectorsWithoutOutlierRemoval();
1:   }
0:   
1:   @Test
1:   public void testVectorClassificationWithOutlierRemoval() throws Exception {
1:     List<VectorWritable> points = getPointsWritable(REFERENCE);
0:     
1:     pointsPath = getTestTempDirPath("points");
1:     clusteringOutputPath = getTestTempDirPath("output");
1:     classifiedOutputPath = getTestTempDirPath("classify");
0: 
0:     conf = new Configuration();
0:     
0:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
0:     runClustering(pointsPath, conf);
0:     runClassificationWithOutlierRemoval(conf);
1:     collectVectorsForAssertion();
1:     assertVectorsWithOutlierRemoval();
1:   }
0:   
0:   private void runClustering(Path pointsPath, Configuration conf) throws IOException,
0:   InterruptedException,
0:   ClassNotFoundException {
0:     CanopyDriver.run(conf, pointsPath, clusteringOutputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, false, true);
1:   }
0:   
0:   private void runClassificationWithoutOutlierRemoval(Configuration conf) throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath, classifiedOutputPath, 0.0, true);
1:   }
0:   
0:   private void runClassificationWithOutlierRemoval(Configuration conf2) throws IOException, InterruptedException, ClassNotFoundException {
0:     ClusterClassificationDriver.run(pointsPath, clusteringOutputPath, classifiedOutputPath, 0.73, true);
1:   }
0: 
1:   private void collectVectorsForAssertion() throws IOException {
0:     Path[] partFilePaths = FileUtil.stat2Paths(fs.globStatus(classifiedOutputPath));
0:     FileStatus[] listStatus = fs.listStatus(partFilePaths);
1:     for (FileStatus partFile : listStatus) {
0:       SequenceFile.Reader classifiedVectors = new SequenceFile.Reader(fs, partFile.getPath(), conf);
1:       Writable clusterIdAsKey = new IntWritable();
0:       VectorWritable point = new VectorWritable();
1:       while (classifiedVectors.next(clusterIdAsKey, point)) {
0:         collectVector(clusterIdAsKey.toString(), point.get());
1:       }
1:     }
1:   }
0:   
1:   private void collectVector(String clusterId, Vector vector) {
0:     if(clusterId.equals("0")) {
1:       firstCluster.add(vector);
1:     }
0:     else if(clusterId.equals("1")) {
1:       secondCluster.add(vector);
1:     }
0:     else if(clusterId.equals("2")) {
1:       thirdCluster.add(vector);
1:     }
1:   }
0:   
1:   private void assertVectorsWithOutlierRemoval() {
0:     assertFirstClusterWithOutlierRemoval();
0:     assertSecondClusterWithOutlierRemoval();
0:     assertThirdClusterWithOutlierRemoval();
1:   }
0: 
1:   private void assertVectorsWithoutOutlierRemoval() {
1:     assertFirstClusterWithoutOutlierRemoval();
1:     assertSecondClusterWithoutOutlierRemoval();
1:     assertThirdClusterWithoutOutlierRemoval();
1:   }
0: 
1:   private void assertThirdClusterWithoutOutlierRemoval() {
1:     Assert.assertEquals(2, thirdCluster.size());
1:     for (Vector vector : thirdCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:9.0,0:9.0}", "{1:8.0,0:8.0}"}, vector.asFormatString()));
1:     }
1:   }
0: 
1:   private void assertSecondClusterWithoutOutlierRemoval() {
1:     Assert.assertEquals(4, secondCluster.size());
1:     for (Vector vector : secondCluster) {
0:     Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:4.0,0:4.0}", "{1:4.0,0:5.0}", "{1:5.0,0:4.0}",
0:     "{1:5.0,0:5.0}"}, vector.asFormatString()));
1:     }
1:   }
0: 
0:   private void assertFirstClusterWithoutOutlierRemoval() {
0:     Assert.assertEquals(3, firstCluster.size());
0:     for (Vector vector : firstCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}","{1:1.0,0:2.0}", "{1:2.0,0:1.0}"}, vector.asFormatString()));
1:     }
1:   }
0:   
0: 
0:   private void assertThirdClusterWithOutlierRemoval() {
0:     Assert.assertEquals(1, thirdCluster.size());
1:     for (Vector vector : thirdCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:9.0,0:9.0}"}, vector.asFormatString()));
1:     }
1:   }
0: 
0:   private void assertSecondClusterWithOutlierRemoval() {
0:     Assert.assertEquals(0, secondCluster.size());
1:   }
0: 
0:   private void assertFirstClusterWithOutlierRemoval() {
0:     Assert.assertEquals(1, firstCluster.size());
0:     for (Vector vector : firstCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}"}, vector.asFormatString()));
1:     }
1:   }
0: 
0:   
1: }
============================================================================
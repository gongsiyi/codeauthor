1:b35e54f: /**
1:b35e54f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:b35e54f:  * contributor license agreements.  See the NOTICE file distributed with
1:b35e54f:  * this work for additional information regarding copyright ownership.
1:b35e54f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:b35e54f:  * (the "License"); you may not use this file except in compliance with
1:b35e54f:  * the License.  You may obtain a copy of the License at
1:b35e54f:  *
1:b35e54f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:b35e54f:  *
1:b35e54f:  * Unless required by applicable law or agreed to in writing, software
1:b35e54f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:b35e54f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:b35e54f:  * See the License for the specific language governing permissions and
1:b35e54f:  * limitations under the License.
1:b35e54f:  */
2:b35e54f: 
1:7120506: package org.apache.mahout.clustering.spectral.kmeans;
1:b35e54f: 
1:b35e54f: import java.io.IOException;
1:85f9ece: import java.util.HashMap;
1:b35e54f: import java.util.Map;
1:b35e54f: 
1:b35e54f: import org.apache.hadoop.conf.Configuration;
1:b35e54f: import org.apache.hadoop.fs.FileStatus;
1:b35e54f: import org.apache.hadoop.fs.FileSystem;
1:b35e54f: import org.apache.hadoop.fs.Path;
1:b35e54f: import org.apache.hadoop.io.SequenceFile;
1:b35e54f: import org.apache.hadoop.io.Text;
1:b35e54f: import org.apache.hadoop.io.Writable;
1:b35e54f: import org.apache.mahout.clustering.iterator.ClusterWritable;
1:7120506: import org.apache.mahout.clustering.kmeans.Kluster;
1:b35e54f: import org.apache.mahout.common.HadoopUtil;
1:b35e54f: import org.apache.mahout.common.Pair;
1:b35e54f: import org.apache.mahout.common.distance.DistanceMeasure;
1:b35e54f: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:b35e54f: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1:b35e54f: import org.apache.mahout.math.Vector;
1:b35e54f: import org.apache.mahout.math.VectorWritable;
1:b35e54f: import org.slf4j.Logger;
1:b35e54f: import org.slf4j.LoggerFactory;
1:b35e54f: 
1:b35e54f: /**
1:b35e54f:  * Given an Input Path containing a {@link org.apache.hadoop.io.SequenceFile}, select k vectors and write them to the
1:b35e54f:  * output file as a {@link org.apache.mahout.clustering.kmeans.Kluster} representing the initial centroid to use. The
1:b35e54f:  * selection criterion is the rows with max value in that respective column
1:b35e54f:  */
1:b35e54f: public final class EigenSeedGenerator {
1:b35e54f: 
1:b35e54f:   private static final Logger log = LoggerFactory.getLogger(EigenSeedGenerator.class);
1:b35e54f: 
1:b35e54f:   public static final String K = "k";
1:b35e54f: 
1:b35e54f:   private EigenSeedGenerator() {}
1:b35e54f: 
1:b35e54f:   public static Path buildFromEigens(Configuration conf, Path input, Path output, int k, DistanceMeasure measure)
1:b35e54f:       throws IOException {
1:b35e54f:     // delete the output directory
1:b35e54f:     FileSystem fs = FileSystem.get(output.toUri(), conf);
1:b35e54f:     HadoopUtil.delete(conf, output);
1:b35e54f:     Path outFile = new Path(output, "part-eigenSeed");
1:b35e54f:     boolean newFile = fs.createNewFile(outFile);
1:b35e54f:     if (newFile) {
1:b35e54f:       Path inputPathPattern;
1:b35e54f: 
1:b988c49:       if (fs.getFileStatus(input).isDir()) {
1:b35e54f:         inputPathPattern = new Path(input, "*");
1:b35e54f:       } else {
1:b35e54f:         inputPathPattern = input;
2:b35e54f:       }
1:b35e54f: 
1:b35e54f:       FileStatus[] inputFiles = fs.globStatus(inputPathPattern, PathFilters.logsCRCFilter());
1:85f9ece:       Map<Integer,Double> maxEigens = new HashMap<>(k); // store
1:b35e54f:                                                                           // max
1:b35e54f:                                                                           // value
1:b35e54f:                                                                           // of
1:b35e54f:                                                                           // each
1:b35e54f:                                                                           // column
1:85f9ece:       Map<Integer,Text> chosenTexts = new HashMap<>(k);
1:85f9ece:       Map<Integer,ClusterWritable> chosenClusters = new HashMap<>(k);
1:b35e54f: 
1:b35e54f:       for (FileStatus fileStatus : inputFiles) {
1:b988c49:         if (!fileStatus.isDir()) {
1:cb9a9ea:           for (Pair<Writable,VectorWritable> record : new SequenceFileIterable<Writable,VectorWritable>(
1:cb9a9ea:               fileStatus.getPath(), true, conf)) {
1:cb9a9ea:             Writable key = record.getFirst();
1:cb9a9ea:             VectorWritable value = record.getSecond();
1:b35e54f: 
1:cb9a9ea:             for (Vector.Element e : value.get().nonZeroes()) {
1:cb9a9ea:               int index = e.index();
1:cb9a9ea:               double v = Math.abs(e.get());
1:b35e54f: 
1:cb9a9ea:               if (!maxEigens.containsKey(index) || v > maxEigens.get(index)) {
1:cb9a9ea:                 maxEigens.put(index, v);
1:cb9a9ea:                 Text newText = new Text(key.toString());
1:cb9a9ea:                 chosenTexts.put(index, newText);
1:cb9a9ea:                 Kluster newCluster = new Kluster(value.get(), index, measure);
1:cb9a9ea:                 newCluster.observe(value.get(), 1);
1:cb9a9ea:                 ClusterWritable clusterWritable = new ClusterWritable();
1:cb9a9ea:                 clusterWritable.setValue(newCluster);
1:cb9a9ea:                 chosenClusters.put(index, clusterWritable);
1:cb9a9ea:               }
1:b35e54f:             }
1:b35e54f:           }
1:b35e54f:         }
1:b35e54f:       }
1:b35e54f: 
1:85f9ece:       try (SequenceFile.Writer writer =
1:85f9ece:                SequenceFile.createWriter(fs, conf, outFile, Text.class, ClusterWritable.class)){
1:99a5ce8:         for (Integer key : maxEigens.keySet()) {
1:b35e54f:           writer.append(chosenTexts.get(key), chosenClusters.get(key));
1:b35e54f:         }
1:b35e54f:         log.info("EigenSeedGenerator:: Wrote {} Klusters to {}", chosenTexts.size(), outFile);
1:b35e54f:       }
1:b35e54f:     }
1:b35e54f: 
1:b35e54f:     return outFile;
1:b35e54f:   }
1:b35e54f: 
1:b35e54f: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.util.HashMap;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       Map<Integer,Double> maxEigens = new HashMap<>(k); // store
1:       Map<Integer,Text> chosenTexts = new HashMap<>(k);
1:       Map<Integer,ClusterWritable> chosenClusters = new HashMap<>(k);
/////////////////////////////////////////////////////////////////////////
1:       try (SequenceFile.Writer writer =
1:                SequenceFile.createWriter(fs, conf, outFile, Text.class, ClusterWritable.class)){
commit:87c15be
/////////////////////////////////////////////////////////////////////////
0:       if (fs.getFileStatus(input).isDirectory()) {
/////////////////////////////////////////////////////////////////////////
0:         if (!fileStatus.isDirectory()) {
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
/////////////////////////////////////////////////////////////////////////
1:       if (fs.getFileStatus(input).isDir()) {
/////////////////////////////////////////////////////////////////////////
1:         if (!fileStatus.isDir()) {
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
commit:7120506
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral.kmeans;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.kmeans.Kluster;
author:smarthi
-------------------------------------------------------------------------------
commit:cb9a9ea
/////////////////////////////////////////////////////////////////////////
0:         if (!fileStatus.isDir()) {
1:           for (Pair<Writable,VectorWritable> record : new SequenceFileIterable<Writable,VectorWritable>(
1:               fileStatus.getPath(), true, conf)) {
1:             Writable key = record.getFirst();
1:             VectorWritable value = record.getSecond();
1:             for (Vector.Element e : value.get().nonZeroes()) {
1:               int index = e.index();
1:               double v = Math.abs(e.get());
1:               if (!maxEigens.containsKey(index) || v > maxEigens.get(index)) {
1:                 maxEigens.put(index, v);
1:                 Text newText = new Text(key.toString());
1:                 chosenTexts.put(index, newText);
1:                 Kluster newCluster = new Kluster(value.get(), index, measure);
1:                 newCluster.observe(value.get(), 1);
1:                 ClusterWritable clusterWritable = new ClusterWritable();
1:                 clusterWritable.setValue(newCluster);
1:                 chosenClusters.put(index, clusterWritable);
1:               }
commit:99a5ce8
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:           for (Vector.Element e : value.get().nonZeroes()) {
/////////////////////////////////////////////////////////////////////////
1:         for (Integer key : maxEigens.keySet()) {
author:Robin Anil
-------------------------------------------------------------------------------
commit:b35e54f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.kmeans;
1: 
1: import java.io.IOException;
0: import java.util.Iterator;
1: import java.util.Map;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.io.Writable;
1: import org.apache.mahout.clustering.iterator.ClusterWritable;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.distance.DistanceMeasure;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
0: import com.google.common.collect.Maps;
0: import com.google.common.io.Closeables;
1: 
1: /**
1:  * Given an Input Path containing a {@link org.apache.hadoop.io.SequenceFile}, select k vectors and write them to the
1:  * output file as a {@link org.apache.mahout.clustering.kmeans.Kluster} representing the initial centroid to use. The
1:  * selection criterion is the rows with max value in that respective column
1:  */
1: public final class EigenSeedGenerator {
1: 
1:   private static final Logger log = LoggerFactory.getLogger(EigenSeedGenerator.class);
1: 
1:   public static final String K = "k";
1: 
1:   private EigenSeedGenerator() {}
1: 
1:   public static Path buildFromEigens(Configuration conf, Path input, Path output, int k, DistanceMeasure measure)
1:       throws IOException {
1:     // delete the output directory
1:     FileSystem fs = FileSystem.get(output.toUri(), conf);
1:     HadoopUtil.delete(conf, output);
1:     Path outFile = new Path(output, "part-eigenSeed");
1:     boolean newFile = fs.createNewFile(outFile);
1:     if (newFile) {
1:       Path inputPathPattern;
1: 
0:       if (fs.getFileStatus(input).isDir()) {
1:         inputPathPattern = new Path(input, "*");
1:       } else {
1:         inputPathPattern = input;
1:       }
1: 
1:       FileStatus[] inputFiles = fs.globStatus(inputPathPattern, PathFilters.logsCRCFilter());
0:       SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, outFile, Text.class, ClusterWritable.class);
0:       Map<Integer,Double> maxEigens = Maps.newHashMapWithExpectedSize(k); // store
1:                                                                           // max
1:                                                                           // value
1:                                                                           // of
1:                                                                           // each
1:                                                                           // column
0:       Map<Integer,Text> chosenTexts = Maps.newHashMapWithExpectedSize(k);
0:       Map<Integer,ClusterWritable> chosenClusters = Maps.newHashMapWithExpectedSize(k);
1: 
1:       for (FileStatus fileStatus : inputFiles) {
0:         if (fileStatus.isDir()) {
0:           continue;
1:         }
0:         for (Pair<Writable,VectorWritable> record : new SequenceFileIterable<Writable,VectorWritable>(
0:             fileStatus.getPath(), true, conf)) {
0:           Writable key = record.getFirst();
0:           VectorWritable value = record.getSecond();
0:           Iterator<Vector.Element> nonZeroElements = value.get().nonZeroes().iterator();
1: 
0:           while (nonZeroElements.hasNext()) {
0:             Vector.Element e = nonZeroElements.next();
0:             int index = e.index();
0:             double v = Math.abs(e.get());
1: 
0:             if (!maxEigens.containsKey(index) || v > maxEigens.get(index)) {
0:               maxEigens.put(index, v);
0:               Text newText = new Text(key.toString());
0:               chosenTexts.put(index, newText);
0:               Kluster newCluster = new Kluster(value.get(), index, measure);
0:               newCluster.observe(value.get(), 1);
0:               ClusterWritable clusterWritable = new ClusterWritable();
0:               clusterWritable.setValue(newCluster);
0:               chosenClusters.put(index, clusterWritable);
1:             }
1:           }
1:         }
1:       }
1: 
0:       try {
0:         Iterator<Integer> iter = maxEigens.keySet().iterator();
0:         while (iter.hasNext()) {
0:           int key = iter.next();
1:           writer.append(chosenTexts.get(key), chosenClusters.get(key));
1:         }
1:         log.info("EigenSeedGenerator:: Wrote {} Klusters to {}", chosenTexts.size(), outFile);
0:       } finally {
0:         Closeables.close(writer, false);
1:       }
1:     }
1: 
1:     return outFile;
1:   }
1: 
1: }
============================================================================
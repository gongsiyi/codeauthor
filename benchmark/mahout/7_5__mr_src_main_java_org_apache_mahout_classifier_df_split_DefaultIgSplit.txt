1:8c37a84: /**
1:8c37a84:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:8c37a84:  * contributor license agreements.  See the NOTICE file distributed with
1:8c37a84:  * this work for additional information regarding copyright ownership.
1:8c37a84:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:8c37a84:  * (the "License"); you may not use this file except in compliance with
1:8c37a84:  * the License.  You may obtain a copy of the License at
4:8c37a84:  *
1:8c37a84:  *     http://www.apache.org/licenses/LICENSE-2.0
1:8c37a84:  *
1:8c37a84:  * Unless required by applicable law or agreed to in writing, software
1:8c37a84:  * distributed under the License is distributed on an "AS IS" BASIS,
1:8c37a84:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:8c37a84:  * See the License for the specific language governing permissions and
1:8c37a84:  * limitations under the License.
1:8c37a84:  */
2:8c37a84: 
1:52ce412: package org.apache.mahout.classifier.df.split;
1:8c37a84: 
1:52ce412: import org.apache.mahout.classifier.df.data.Data;
1:52ce412: import org.apache.mahout.classifier.df.data.conditions.Condition;
1:8c37a84: 
1:d6aba1a: import java.util.Arrays;
1:d6aba1a: 
1:8c37a84: /**
1:8c37a84:  * Default, not optimized, implementation of IgSplit
1:8c37a84:  */
1:1ffa3a4: @Deprecated
1:8c37a84: public class DefaultIgSplit extends IgSplit {
1:8c37a84:   
1:8c37a84:   /** used by entropy() */
1:8547de7:   private int[] counts;
1:8c37a84:   
1:8c37a84:   @Override
1:8c37a84:   public Split computeSplit(Data data, int attr) {
1:acafdc0:     if (data.getDataset().isNumerical(attr)) {
1:8c37a84:       double[] values = data.values(attr);
1:8c37a84:       double bestIg = -1;
1:8c37a84:       double bestSplit = 0.0;
1:8c37a84:       
1:8c37a84:       for (double value : values) {
1:8c37a84:         double ig = numericalIg(data, attr, value);
1:8c37a84:         if (ig > bestIg) {
1:8c37a84:           bestIg = ig;
1:8c37a84:           bestSplit = value;
1:8c37a84:         }
1:8c37a84:       }
1:8c37a84:       
1:8c37a84:       return new Split(attr, bestIg, bestSplit);
1:8c37a84:     } else {
1:8c37a84:       double ig = categoricalIg(data, attr);
1:8c37a84:       
1:8c37a84:       return new Split(attr, ig);
1:8c37a84:     }
1:8c37a84:   }
1:8c37a84:   
1:8c37a84:   /**
1:8c37a84:    * Computes the Information Gain for a CATEGORICAL attribute
1:8c37a84:    */
1:e9cc323:   double categoricalIg(Data data, int attr) {
1:8c37a84:     double[] values = data.values(attr);
1:8c37a84:     double hy = entropy(data); // H(Y)
1:8c37a84:     double hyx = 0.0; // H(Y|X)
1:8c37a84:     double invDataSize = 1.0 / data.size();
1:8c37a84:     
1:8c37a84:     for (double value : values) {
1:8c37a84:       Data subset = data.subset(Condition.equals(attr, value));
1:8c37a84:       hyx += subset.size() * invDataSize * entropy(subset);
1:8c37a84:     }
1:8c37a84:     
1:8c37a84:     return hy - hyx;
1:8c37a84:   }
1:8c37a84:   
1:8c37a84:   /**
1:ad11134:    * Computes the Information Gain for a NUMERICAL attribute given a splitting value
1:8c37a84:    */
1:e9cc323:   double numericalIg(Data data, int attr, double split) {
1:8c37a84:     double hy = entropy(data);
1:8c37a84:     double invDataSize = 1.0 / data.size();
1:8c37a84:     
1:8c37a84:     // LO subset
1:8547de7:     Data subset = data.subset(Condition.lesser(attr, split));
1:8c37a84:     hy -= subset.size() * invDataSize * entropy(subset);
1:8c37a84:     
1:8c37a84:     // HI subset
1:8c37a84:     subset = data.subset(Condition.greaterOrEquals(attr, split));
1:8c37a84:     hy -= subset.size() * invDataSize * entropy(subset);
1:8c37a84:     
1:8c37a84:     return hy;
1:8c37a84:   }
1:8c37a84:   
1:8c37a84:   /**
1:8c37a84:    * Computes the Entropy
1:8c37a84:    */
1:8c37a84:   protected double entropy(Data data) {
1:8c37a84:     double invDataSize = 1.0 / data.size();
1:8c37a84:     
1:ad11134:     if (counts == null) {
1:acafdc0:       counts = new int[data.getDataset().nblabels()];
1:ad11134:     }
1:8c37a84:     
1:8c37a84:     Arrays.fill(counts, 0);
1:8c37a84:     data.countLabels(counts);
1:8c37a84:     
1:8c37a84:     double entropy = 0.0;
1:acafdc0:     for (int label = 0; label < data.getDataset().nblabels(); label++) {
1:8c37a84:       int count = counts[label];
1:ad11134:       if (count == 0) {
1:8c37a84:         continue; // otherwise we get a NaN
1:ad11134:       }
1:8c37a84:       double p = count * invDataSize;
1:8c37a84:       entropy += -p * Math.log(p) / LOG2;
1:8c37a84:     }
1:8c37a84:     
1:8c37a84:     return entropy;
1:8c37a84:   }
1:8c37a84:   
1:8c37a84: }
============================================================================
author:smarthi
-------------------------------------------------------------------------------
commit:1ffa3a4
/////////////////////////////////////////////////////////////////////////
1: @Deprecated
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Abdel Hakim Deneche
-------------------------------------------------------------------------------
commit:d6aba1a
/////////////////////////////////////////////////////////////////////////
1: import java.util.Arrays;
1: 
commit:e9cc323
/////////////////////////////////////////////////////////////////////////
1:   double categoricalIg(Data data, int attr) {
/////////////////////////////////////////////////////////////////////////
1:   double numericalIg(Data data, int attr, double split) {
commit:8c37a84
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.df.split;
1: 
0: import java.util.Arrays;
1: 
0: import org.apache.mahout.df.data.Data;
0: import org.apache.mahout.df.data.conditions.Condition;
1: 
1: /**
1:  * Default, not optimized, implementation of IgSplit
1:  */
1: public class DefaultIgSplit extends IgSplit {
1: 
1:   /** used by entropy() */
0:   protected int[] counts;
1: 
1:   @Override
1:   public Split computeSplit(Data data, int attr) {
0:     if (data.dataset.isNumerical(attr)) {
1:       double[] values = data.values(attr);
1:       double bestIg = -1;
1:       double bestSplit = 0.0;
1: 
1:       for (double value : values) {
1:         double ig = numericalIg(data, attr, value);
1:         if (ig > bestIg) {
1:           bestIg = ig;
1:           bestSplit = value;
1:         }
1:       }
1: 
1:       return new Split(attr, bestIg, bestSplit);
1:     } else {
1:       double ig = categoricalIg(data, attr);
1: 
1:       return new Split(attr, ig);
1:     }
1:   }
1: 
1:   /**
1:    * Computes the Information Gain for a CATEGORICAL attribute
1:    * 
0:    * @param data
0:    * @param attr
0:    * @return
1:    */
0:   protected double categoricalIg(Data data, int attr) {
1:     double[] values = data.values(attr);
1:     double hy = entropy(data); // H(Y)
1:     double hyx = 0.0; // H(Y|X)
1:     double invDataSize = 1.0 / data.size();
1: 
1:     for (double value : values) {
1:       Data subset = data.subset(Condition.equals(attr, value));
1:       hyx += subset.size() * invDataSize * entropy(subset);
1:     }
1: 
1:     return hy - hyx;
1:   }
1: 
1:   /**
0:    * Computes the Information Gain for a NUMERICAL attribute given a splitting
0:    * value
1:    * 
0:    * @param data
0:    * @param attr
0:    * @param split
0:    * @return
1:    */
0:   protected double numericalIg(Data data, int attr, double split) {
1:     double hy = entropy(data);
1:     double invDataSize = 1.0 / data.size();
0:     Data subset;
1: 
1:     // LO subset
0:     subset = data.subset(Condition.lesser(attr, split));
1:     hy -= subset.size() * invDataSize * entropy(subset);
1: 
1:     // HI subset
1:     subset = data.subset(Condition.greaterOrEquals(attr, split));
1:     hy -= subset.size() * invDataSize * entropy(subset);
1: 
1:     return hy;
1:   }
1: 
1:   /**
1:    * Computes the Entropy
1:    * 
0:    * @param data
0:    * @return
1:    */
1:   protected double entropy(Data data) {
1:     double entropy = 0.0;
1:     double invDataSize = 1.0 / data.size();
1: 
0:     if (counts == null)
0:       counts = new int[data.dataset.nblabels()];
1: 
1:     Arrays.fill(counts, 0);
1:     data.countLabels(counts);
1: 
0:     for (int label = 0; label < data.dataset.nblabels(); label++) {
1:       int count = counts[label];
0:       if (count == 0)
1:         continue; // otherwise we get a NaN
1:       double p = count * invDataSize;
1:       entropy += -p * Math.log(p) / LOG2;
1:     }
1: 
1:     return entropy;
1:   }
1: 
1: }
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:52ce412
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.classifier.df.split;
1: import org.apache.mahout.classifier.df.data.Data;
1: import org.apache.mahout.classifier.df.data.conditions.Condition;
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:515bac4
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:210fac3
commit:acafdc0
/////////////////////////////////////////////////////////////////////////
1:     if (data.getDataset().isNumerical(attr)) {
/////////////////////////////////////////////////////////////////////////
1:       counts = new int[data.getDataset().nblabels()];
1:     for (int label = 0; label < data.getDataset().nblabels(); label++) {
commit:8547de7
/////////////////////////////////////////////////////////////////////////
1:   private int[] counts;
/////////////////////////////////////////////////////////////////////////
1:     Data subset = data.subset(Condition.lesser(attr, split));
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     double entropy = 0.0;
author:Robin Anil
-------------------------------------------------------------------------------
commit:ad11134
/////////////////////////////////////////////////////////////////////////
0:   
0:   
0:       
/////////////////////////////////////////////////////////////////////////
0:       
0:       
0:   
/////////////////////////////////////////////////////////////////////////
0:     
0:     
0:   
1:    * Computes the Information Gain for a NUMERICAL attribute given a splitting value
/////////////////////////////////////////////////////////////////////////
0:     
0:     
0:     
0:   
/////////////////////////////////////////////////////////////////////////
0:     
1:     if (counts == null) {
1:     }
0:     
0:     
1:       if (count == 0) {
1:       }
0:       entropy += -p * Math.log(p) / IgSplit.LOG2;
0:     
0:   
============================================================================
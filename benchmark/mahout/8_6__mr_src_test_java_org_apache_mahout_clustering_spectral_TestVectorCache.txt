1:48d069f: /**
1:48d069f:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:48d069f:  * contributor license agreements.  See the NOTICE file distributed with
1:48d069f:  * this work for additional information regarding copyright ownership.
1:48d069f:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:48d069f:  * (the "License"); you may not use this file except in compliance with
1:48d069f:  * the License.  You may obtain a copy of the License at
1:48d069f:  *
1:48d069f:  *     http://www.apache.org/licenses/LICENSE-2.0
1:48d069f:  *
1:48d069f:  * Unless required by applicable law or agreed to in writing, software
1:48d069f:  * distributed under the License is distributed on an "AS IS" BASIS,
1:48d069f:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:48d069f:  * See the License for the specific language governing permissions and
1:48d069f:  * limitations under the License.
1:48d069f:  */
4:48d069f: 
1:b60c909: package org.apache.mahout.clustering.spectral;
1:48d069f: 
1:48d069f: import java.net.URI;
1:48d069f: 
1:d608a88: import com.google.common.io.Closeables;
1:48d069f: import org.apache.hadoop.conf.Configuration;
1:48d069f: import org.apache.hadoop.filecache.DistributedCache;
1:48d069f: import org.apache.hadoop.fs.FileSystem;
1:48d069f: import org.apache.hadoop.fs.Path;
1:48d069f: import org.apache.hadoop.io.IntWritable;
1:48d069f: import org.apache.hadoop.io.SequenceFile;
1:58fd277: import org.apache.hadoop.io.Writable;
1:48d069f: import org.apache.mahout.common.HadoopUtil;
1:48d069f: import org.apache.mahout.common.MahoutTestCase;
1:a13b4b7: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
1:48d069f: import org.apache.mahout.math.DenseVector;
1:48d069f: import org.apache.mahout.math.Vector;
1:48d069f: import org.apache.mahout.math.VectorWritable;
1:48d069f: import org.junit.Test;
1:48d069f: 
1:48d069f: public class TestVectorCache extends MahoutTestCase {
1:48d069f: 
1:049e7dc:   private static final double [] VECTOR = { 1, 2, 3, 4 };
1:48d069f:   
1:48d069f:   @Test
1:48d069f:   public void testSave() throws Exception {
1:921e201:     Configuration conf = getConfiguration();
1:58fd277:     Writable key = new IntWritable(0);
1:049e7dc:     Vector value = new DenseVector(VECTOR);
1:48d069f:     Path path = getTestTempDirPath("output");
1:48d069f:     
1:48d069f:     // write the vector out
1:48d069f:     VectorCache.save(key, value, path, conf, true, true);
1:48d069f:     
1:48d069f:     // can we read it from here?
1:a13b4b7:     SequenceFileValueIterator<VectorWritable> iterator =
1:02ff22f:         new SequenceFileValueIterator<>(path, true, conf);
1:d608a88:     try {
1:d608a88:       VectorWritable old = iterator.next();
1:d608a88:       // test if the values are identical
1:d608a88:       assertEquals("Saved vector is identical to original", old.get(), value);
1:d608a88:     } finally {
1:4a6453c:       Closeables.close(iterator, true);
1:d608a88:     }
1:48d069f:   }
1:48d069f:   
1:48d069f:   @Test
1:48d069f:   public void testLoad() throws Exception {
1:48d069f:     // save a vector manually
1:921e201:     Configuration conf = getConfiguration();
1:58fd277:     Writable key = new IntWritable(0);
1:049e7dc:     Vector value = new DenseVector(VECTOR);
1:48d069f:     Path path = getTestTempDirPath("output");
1:1de8cec: 
1:1de8cec:     FileSystem fs = FileSystem.get(path.toUri(), conf);
1:48d069f:     // write the vector
1:48d069f:     path = fs.makeQualified(path);
1:48d069f:     fs.deleteOnExit(path);
1:a13b4b7:     HadoopUtil.delete(conf, path);
1:a13b4b7:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);
1:d608a88:     try {
1:d608a88:       writer.append(key, new VectorWritable(value));
1:d608a88:     } finally {
1:4a6453c:       Closeables.close(writer, false);
1:d608a88:     }
1:4a6453c:     DistributedCache.setCacheFiles(new URI[] {path.toUri()}, conf);
1:d608a88: 
1:48d069f:     // load it
1:a13b4b7:     Vector result = VectorCache.load(conf);
1:48d069f:     
1:48d069f:     // are they the same?
1:4a6453c:     assertNotNull("Vector is null", result);
1:4a6453c:     assertEquals("Loaded vector is not identical to original", result, value);
1:48d069f:   }
1:48d069f:   
1:48d069f:   @Test
1:48d069f:   public void testAll() throws Exception {
1:921e201:     Configuration conf = getConfiguration();
1:049e7dc:     Vector v = new DenseVector(VECTOR);
1:48d069f:     Path toSave = getTestTempDirPath("output");
1:a13b4b7:     Writable key = new IntWritable(0);
1:48d069f:     
1:48d069f:     // save it
1:48d069f:     VectorCache.save(key, v, toSave, conf);
1:48d069f:     
1:48d069f:     // now, load it back
1:a13b4b7:     Vector v2 = VectorCache.load(conf);
1:48d069f:     
1:48d069f:     // are they the same?
1:4a6453c:     assertNotNull("Vector is null", v2);
1:4a6453c:     assertEquals("Vectors are not identical", v2, v);
1:48d069f:   }
1:48d069f: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:         new SequenceFileValueIterator<>(path, true, conf);
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.clustering.spectral;
commit:d608a88
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       VectorWritable old = iterator.next();
1:       // test if the values are identical
1:       assertEquals("Saved vector is identical to original", old.get(), value);
1:     } finally {
0:       Closeables.closeQuietly(iterator);
1:     }
/////////////////////////////////////////////////////////////////////////
1:     try {
1:       writer.append(key, new VectorWritable(value));
1:     } finally {
0:       Closeables.closeQuietly(writer);
1:     }
1: 
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:4a6453c
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(iterator, true);
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
1:     DistributedCache.setCacheFiles(new URI[] {path.toUri()}, conf);
1:     assertNotNull("Vector is null", result);
1:     assertEquals("Loaded vector is not identical to original", result, value);
/////////////////////////////////////////////////////////////////////////
1:     assertNotNull("Vector is null", v2);
1:     assertEquals("Vectors are not identical", v2, v);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:1de8cec
/////////////////////////////////////////////////////////////////////////
1: 
1:     FileSystem fs = FileSystem.get(path.toUri(), conf);
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileValueIterator;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     SequenceFileValueIterator<VectorWritable> iterator =
0:         new SequenceFileValueIterator<VectorWritable>(path, true, conf);
0:     VectorWritable old = iterator.next();
0:     iterator.close();
/////////////////////////////////////////////////////////////////////////
1:     HadoopUtil.delete(conf, path);
1:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, IntWritable.class, VectorWritable.class);
1:     Vector result = VectorCache.load(conf);
/////////////////////////////////////////////////////////////////////////
1:     Writable key = new IntWritable(0);
1:     Vector v2 = VectorCache.load(conf);
commit:58fd277
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.io.Writable;
/////////////////////////////////////////////////////////////////////////
1:     Writable key = new IntWritable(0);
/////////////////////////////////////////////////////////////////////////
0:     assertEquals("Saved vector is identical to original", old.get(), value);
/////////////////////////////////////////////////////////////////////////
1:     Writable key = new IntWritable(0);
commit:049e7dc
/////////////////////////////////////////////////////////////////////////
1:   private static final double [] VECTOR = { 1, 2, 3, 4 };
1:     Vector value = new DenseVector(VECTOR);
/////////////////////////////////////////////////////////////////////////
1:     Vector value = new DenseVector(VECTOR);
/////////////////////////////////////////////////////////////////////////
0:     assertNotNull("Vector is not null", result);
0:     assertEquals("Loaded vector is identical to original", result, value);
1:     Vector v = new DenseVector(VECTOR);
/////////////////////////////////////////////////////////////////////////
0:     assertNotNull("Vector is not null", v2);
0:     assertEquals("Vectors are identical", v2, v);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:48d069f
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
0: package org.apache.mahout.clustering.spectral.common;
1: 
1: import java.net.URI;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.filecache.DistributedCache;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Test;
1: 
1: public class TestVectorCache extends MahoutTestCase {
1: 
0:   private double [] vector = { 1, 2, 3, 4 };
1:   
1:   @Test
1:   public void testSave() throws Exception {
0:     Configuration conf = new Configuration();
0:     FileSystem fs = FileSystem.get(conf);
0:     IntWritable key = new IntWritable(0);
0:     Vector value = new DenseVector(vector);
1:     Path path = getTestTempDirPath("output");
1:     
1:     // write the vector out
1:     VectorCache.save(key, value, path, conf, true, true);
1:     
1:     // can we read it from here?
0:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, conf);
0:     VectorWritable old = new VectorWritable();
0:     reader.next(key, old);
0:     reader.close();
1:     
0:     // test if the values are identical
0:     assertTrue("Saved vector is identical to original", old.get().equals(value));
1:   }
1:   
1:   @Test
1:   public void testLoad() throws Exception {
1:     // save a vector manually
0:     Configuration conf = new Configuration();
0:     FileSystem fs = FileSystem.get(conf);
0:     IntWritable key = new IntWritable(0);
0:     Vector value = new DenseVector(vector);
1:     Path path = getTestTempDirPath("output");
1:     
1:     // write the vector
1:     path = fs.makeQualified(path);
1:     fs.deleteOnExit(path);
0:     HadoopUtil.overwriteOutput(path);
0:     DistributedCache.setCacheFiles(new URI[] {path.toUri()}, conf);
0:     SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, path, 
0:         IntWritable.class, VectorWritable.class);
0:     writer.append(key, new VectorWritable(value));
0:     writer.close();
1:     
1:     // load it
0:     Vector result = VectorCache.load(key, conf);
1:     
1:     // are they the same?
0:     assertTrue("Vector is not null", result != null);
0:     assertTrue("Loaded vector is identical to original", result.equals(value));
1:   }
1:   
1:   @Test
1:   public void testAll() throws Exception {
0:     Configuration conf = new Configuration();
0:     Vector v = new DenseVector(vector);
1:     Path toSave = getTestTempDirPath("output");
0:     IntWritable key = new IntWritable(0);
1:     
1:     // save it
1:     VectorCache.save(key, v, toSave, conf);
1:     
1:     // now, load it back
0:     key = new IntWritable(0);
0:     Vector v2 = VectorCache.load(key, conf);
1:     
1:     // are they the same?
0:     assertTrue("Vector is not null", v2 != null);
0:     assertTrue("Vectors are identical", v2.equals(v));
1:   }
1: }
============================================================================
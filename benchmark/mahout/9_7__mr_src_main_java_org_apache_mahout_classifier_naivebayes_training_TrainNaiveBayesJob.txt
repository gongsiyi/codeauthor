1:e3fb0c4: /**
1:e3fb0c4:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:e3fb0c4:  * contributor license agreements.  See the NOTICE file distributed with
1:e3fb0c4:  * this work for additional information regarding copyright ownership.
1:e3fb0c4:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:e3fb0c4:  * (the "License"); you may not use this file except in compliance with
1:e3fb0c4:  * the License.  You may obtain a copy of the License at
1:e3fb0c4:  *
1:e3fb0c4:  *     http://www.apache.org/licenses/LICENSE-2.0
1:e3fb0c4:  *
1:e3fb0c4:  * Unless required by applicable law or agreed to in writing, software
1:e3fb0c4:  * distributed under the License is distributed on an "AS IS" BASIS,
1:e3fb0c4:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:e3fb0c4:  * See the License for the specific language governing permissions and
1:e3fb0c4:  * limitations under the License.
1:e3fb0c4:  */
2:e3fb0c4: 
1:e3fb0c4: package org.apache.mahout.classifier.naivebayes.training;
1:e3fb0c4: 
1:3cadef9: import java.io.IOException;
1:3cadef9: import java.util.List;
1:e3fb0c4: import java.util.Map;
1:e3fb0c4: 
1:29a7f38: import org.apache.hadoop.conf.Configuration;
1:d8d721a: import org.apache.hadoop.fs.Path;
1:e3fb0c4: import org.apache.hadoop.io.IntWritable;
1:e3fb0c4: import org.apache.hadoop.io.Text;
1:e3fb0c4: import org.apache.hadoop.mapreduce.Job;
1:e3fb0c4: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:e3fb0c4: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:29a7f38: import org.apache.hadoop.util.ToolRunner;
1:29a7f38: import org.apache.mahout.classifier.naivebayes.BayesUtils;
1:e3fb0c4: import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;
1:e3fb0c4: import org.apache.mahout.common.AbstractJob;
1:29a7f38: import org.apache.mahout.common.HadoopUtil;
1:229aeff: import org.apache.mahout.common.Pair;
1:29a7f38: import org.apache.mahout.common.commandline.DefaultOptionCreator;
1:d8d721a: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:d8d721a: import org.apache.mahout.common.iterator.sequencefile.PathType;
1:d8d721a: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
1:e3fb0c4: import org.apache.mahout.common.mapreduce.VectorSumReducer;
1:e3fb0c4: import org.apache.mahout.math.VectorWritable;
1:e3fb0c4: 
1:e3fb0c4: import com.google.common.base.Splitter;
1:e3fb0c4: 
1:94b08db: /** Trains a Naive Bayes Classifier (parameters for both Naive Bayes and Complementary Naive Bayes) */
1:e3fb0c4: public final class TrainNaiveBayesJob extends AbstractJob {
1:d94eb39:   private static final String TRAIN_COMPLEMENTARY = "trainComplementary";
1:d94eb39:   private static final String ALPHA_I = "alphaI";
1:d94eb39:   private static final String LABEL_INDEX = "labelIndex";
1:e3fb0c4:   public static final String WEIGHTS_PER_FEATURE = "__SPF";
1:e3fb0c4:   public static final String WEIGHTS_PER_LABEL = "__SPL";
1:e3fb0c4:   public static final String LABEL_THETA_NORMALIZER = "_LTN";
1:e3fb0c4:   public static final String SUMMED_OBSERVATIONS = "summedObservations";
1:e3fb0c4:   public static final String WEIGHTS = "weights";
1:e3fb0c4:   public static final String THETAS = "thetas";
1:e3fb0c4: 
1:29a7f38:   public static void main(String[] args) throws Exception {
1:29a7f38:     ToolRunner.run(new Configuration(), new TrainNaiveBayesJob(), args);
1:7c2b664:   }
1:e3fb0c4: 
1:e3fb0c4:   @Override
1:e3fb0c4:   public int run(String[] args) throws Exception {
1:e3fb0c4: 
1:e3fb0c4:     addInputOption();
1:e3fb0c4:     addOutputOption();
1:e3fb0c4: 
1:d94eb39:     addOption(ALPHA_I, "a", "smoothing parameter", String.valueOf(1.0f));
1:d94eb39:     addOption(buildOption(TRAIN_COMPLEMENTARY, "c", "train complementary?", false, false, String.valueOf(false)));
1:d94eb39:     addOption(LABEL_INDEX, "li", "The path to store the label index in", false);
1:29a7f38:     addOption(DefaultOptionCreator.overwriteOption().create());
1:88520fb: 
1:6db7f62:     Map<String, List<String>> parsedArgs = parseArguments(args);
1:e3fb0c4:     if (parsedArgs == null) {
1:e3fb0c4:       return -1;
1:e3fb0c4:     }
1:29a7f38:     if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:29a7f38:       HadoopUtil.delete(getConf(), getOutputPath());
1:29a7f38:       HadoopUtil.delete(getConf(), getTempPath());
1:d8d721a:     }
1:d8d721a:     Path labPath;
1:d94eb39:     String labPathStr = getOption(LABEL_INDEX);
1:d8d721a:     if (labPathStr != null) {
1:d8d721a:       labPath = new Path(labPathStr);
1:d8d721a:     } else {
1:d94eb39:       labPath = getTempPath(LABEL_INDEX);
1:d8d721a:     }
1:d8d721a:     long labelSize = createLabelIndex(labPath);
1:d94eb39:     float alphaI = Float.parseFloat(getOption(ALPHA_I));
1:ede812b:     boolean trainComplementary = hasOption(TRAIN_COMPLEMENTARY);
1:e3fb0c4: 
1:29a7f38:     HadoopUtil.setSerializations(getConf());
1:d8d721a:     HadoopUtil.cacheFiles(labPath, getConf());
1:e3fb0c4: 
1:94b08db:     // Add up all the vectors with the same labels, while mapping the labels into our index
1:229aeff:     Job indexInstances = prepareJob(getInputPath(),
1:229aeff:                                     getTempPath(SUMMED_OBSERVATIONS),
1:229aeff:                                     SequenceFileInputFormat.class,
1:229aeff:                                     IndexInstancesMapper.class,
1:229aeff:                                     IntWritable.class,
1:229aeff:                                     VectorWritable.class,
1:229aeff:                                     VectorSumReducer.class,
1:229aeff:                                     IntWritable.class,
1:229aeff:                                     VectorWritable.class,
1:229aeff:                                     SequenceFileOutputFormat.class);
1:e3fb0c4:     indexInstances.setCombinerClass(VectorSumReducer.class);
1:7c2b664:     boolean succeeded = indexInstances.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       return -1;
1:7c2b664:     }
1:94b08db:     // Sum up all the weights from the previous step, per label and per feature
1:229aeff:     Job weightSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS),
1:229aeff:                                   getTempPath(WEIGHTS),
1:229aeff:                                   SequenceFileInputFormat.class,
1:229aeff:                                   WeightsMapper.class,
1:229aeff:                                   Text.class,
1:229aeff:                                   VectorWritable.class,
1:229aeff:                                   VectorSumReducer.class,
1:229aeff:                                   Text.class,
1:229aeff:                                   VectorWritable.class,
1:229aeff:                                   SequenceFileOutputFormat.class);
1:29a7f38:     weightSummer.getConfiguration().set(WeightsMapper.NUM_LABELS, String.valueOf(labelSize));
1:e3fb0c4:     weightSummer.setCombinerClass(VectorSumReducer.class);
1:7c2b664:     succeeded = weightSummer.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       return -1;
1:7c2b664:     }
1:e3fb0c4: 
1:94b08db:     // Put the per label and per feature vectors into the cache
1:29a7f38:     HadoopUtil.cacheFiles(getTempPath(WEIGHTS), getConf());
1:e3fb0c4: 
1:9a5bab5:     if (trainComplementary){
1:9a5bab5:       // Calculate the per label theta normalizers, write out to LABEL_THETA_NORMALIZER vector
1:9a5bab5:       // see http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf - Section 3.2, Weight Magnitude Errors
1:9a5bab5:       Job thetaSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS),
1:9a5bab5:                                    getTempPath(THETAS),
1:9a5bab5:                                    SequenceFileInputFormat.class,
1:9a5bab5:                                    ThetaMapper.class,
1:9a5bab5:                                    Text.class,
1:9a5bab5:                                    VectorWritable.class,
1:9a5bab5:                                    VectorSumReducer.class,
1:9a5bab5:                                    Text.class,
1:9a5bab5:                                    VectorWritable.class,
1:9a5bab5:                                    SequenceFileOutputFormat.class);
1:9a5bab5:       thetaSummer.setCombinerClass(VectorSumReducer.class);
1:9a5bab5:       thetaSummer.getConfiguration().setFloat(ThetaMapper.ALPHA_I, alphaI);
1:9a5bab5:       thetaSummer.getConfiguration().setBoolean(ThetaMapper.TRAIN_COMPLEMENTARY, trainComplementary);
1:9a5bab5:       succeeded = thetaSummer.waitForCompletion(true);
1:9a5bab5:       if (!succeeded) {
1:9a5bab5:         return -1;
1:9a5bab5:       }
1:fa29726:     }
1:e3fb0c4:     
1:94b08db:     // Put the per label theta normalizers into the cache
1:fa29726:     HadoopUtil.cacheFiles(getTempPath(THETAS), getConf());
1:e3fb0c4:     
1:94b08db:     // Validate our model and then write it out to the official output
1:2b8b2a7:     getConf().setFloat(ThetaMapper.ALPHA_I, alphaI);
1:9a5bab5:     getConf().setBoolean(NaiveBayesModel.COMPLEMENTARY_MODEL, trainComplementary);
1:29a7f38:     NaiveBayesModel naiveBayesModel = BayesUtils.readModelFromDir(getTempPath(), getConf());
1:e3fb0c4:     naiveBayesModel.validate();
1:e3fb0c4:     naiveBayesModel.serialize(getOutputPath(), getConf());
1:e3fb0c4: 
1:e3fb0c4:     return 0;
1:e3fb0c4:   }
1:e3fb0c4: 
1:d8d721a:   private long createLabelIndex(Path labPath) throws IOException {
1:d8d721a:     long labelSize = 0;
1:88520fb:     Iterable<Pair<Text,IntWritable>> iterable =
1:02ff22f:       new SequenceFileDirIterable<>(getInputPath(),
1:88520fb:                                                      PathType.LIST,
1:88520fb:                                                      PathFilters.logsCRCFilter(),
1:88520fb:                                                      getConf());
1:88520fb:     labelSize = BayesUtils.writeLabelIndex(getConf(), labPath, iterable);
1:d8d721a:     return labelSize;
1:e3fb0c4:   }
1:d8d721a: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:       new SequenceFileDirIterable<>(getInputPath(),
author:Andrew Palumbo
-------------------------------------------------------------------------------
commit:88520fb
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     Iterable<Pair<Text,IntWritable>> iterable =
0:       new SequenceFileDirIterable<Text, IntWritable>(getInputPath(),
1:                                                      PathType.LIST,
1:                                                      PathFilters.logsCRCFilter(),
1:                                                      getConf());
1:     labelSize = BayesUtils.writeLabelIndex(getConf(), labPath, iterable);
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:9a5bab5
/////////////////////////////////////////////////////////////////////////
1:     if (trainComplementary){
1:       // Calculate the per label theta normalizers, write out to LABEL_THETA_NORMALIZER vector
1:       // see http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf - Section 3.2, Weight Magnitude Errors
1:       Job thetaSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS),
1:                                    getTempPath(THETAS),
1:                                    SequenceFileInputFormat.class,
1:                                    ThetaMapper.class,
1:                                    Text.class,
1:                                    VectorWritable.class,
1:                                    VectorSumReducer.class,
1:                                    Text.class,
1:                                    VectorWritable.class,
1:                                    SequenceFileOutputFormat.class);
1:       thetaSummer.setCombinerClass(VectorSumReducer.class);
1:       thetaSummer.getConfiguration().setFloat(ThetaMapper.ALPHA_I, alphaI);
1:       thetaSummer.getConfiguration().setBoolean(ThetaMapper.TRAIN_COMPLEMENTARY, trainComplementary);
1:       succeeded = thetaSummer.waitForCompletion(true);
1:       if (!succeeded) {
1:         return -1;
1:       }
/////////////////////////////////////////////////////////////////////////
1:     getConf().setBoolean(NaiveBayesModel.COMPLEMENTARY_MODEL, trainComplementary);
commit:94b08db
/////////////////////////////////////////////////////////////////////////
1: /** Trains a Naive Bayes Classifier (parameters for both Naive Bayes and Complementary Naive Bayes) */
/////////////////////////////////////////////////////////////////////////
1:     // Add up all the vectors with the same labels, while mapping the labels into our index
/////////////////////////////////////////////////////////////////////////
1:     // Sum up all the weights from the previous step, per label and per feature
/////////////////////////////////////////////////////////////////////////
1:     // Put the per label and per feature vectors into the cache
0:     // Calculate the per label theta normalizers, write out to LABEL_THETA_NORMALIZER vector -- Rennie 3.2
/////////////////////////////////////////////////////////////////////////
1:     // Put the per label theta normalizers into the cache
1:     // Validate our model and then write it out to the official output
commit:2b8b2a7
/////////////////////////////////////////////////////////////////////////
1:     getConf().setFloat(ThetaMapper.ALPHA_I, alphaI);
commit:e3fb0c4
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.naivebayes.training;
1: 
1: import java.util.Map;
1: 
1: import com.google.common.base.Splitter;
0: import com.google.common.collect.Iterables;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1: import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;
1: import org.apache.mahout.common.AbstractJob;
1: import org.apache.mahout.common.mapreduce.VectorSumReducer;
1: import org.apache.mahout.math.VectorWritable;
1: 
0: /** This class trains a Naive Bayes Classifier (Parameters for both Naive Bayes and Complementary Naive Bayes) */
1: public final class TrainNaiveBayesJob extends AbstractJob {
1: 
1:   public static final String WEIGHTS_PER_FEATURE = "__SPF";
1:   public static final String WEIGHTS_PER_LABEL = "__SPL";
1:   public static final String LABEL_THETA_NORMALIZER = "_LTN";
1: 
1:   public static final String SUMMED_OBSERVATIONS = "summedObservations";
1:   public static final String WEIGHTS = "weights";
1:   public static final String THETAS = "thetas";
1: 
1:   @Override
1:   public int run(String[] args) throws Exception {
1: 
1:     addInputOption();
1:     addOutputOption();
0:     addOption("labels", "l", "comma-separated list of labels to include in training", true);
0:     addOption("alphaI", "a", "smoothing parameter", String.valueOf(1.0f));
0:     addOption("trainComplementary", "c", "train complementary?", String.valueOf(false));
1: 
0:     Map<String,String> parsedArgs = parseArguments(args);
1:     if (parsedArgs == null) {
1:       return -1;
1:     }
1: 
0:     Iterable<String> labels = Splitter.on(",").split(parsedArgs.get("--labels"));
0:     float alphaI = Float.parseFloat(parsedArgs.get("--alphaI"));
0:     boolean trainComplementary = Boolean.parseBoolean(parsedArgs.get("--trainComplementary"));
1: 
0:     TrainUtils.writeLabelIndex(getConf(), labels, getTempPath("labelIndex"));
0:     TrainUtils.setSerializations(getConf());
0:     TrainUtils.cacheFiles(getTempPath("labelIndex"), getConf());
1: 
0:     Job indexInstances = prepareJob(getInputPath(), getTempPath(SUMMED_OBSERVATIONS), SequenceFileInputFormat.class,
0:         IndexInstancesMapper.class, IntWritable.class, VectorWritable.class, VectorSumReducer.class, IntWritable.class,
0:         VectorWritable.class, SequenceFileOutputFormat.class);
1:     indexInstances.setCombinerClass(VectorSumReducer.class);
0:     indexInstances.waitForCompletion(true);
1: 
0:     Job weightSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS), getTempPath(WEIGHTS),
0:         SequenceFileInputFormat.class, WeightsMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class,
0:         Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
0:     weightSummer.getConfiguration().set(WeightsMapper.NUM_LABELS, String.valueOf(Iterables.size(labels)));
1:     weightSummer.setCombinerClass(VectorSumReducer.class);
0:     weightSummer.waitForCompletion(true);
1: 
0:     TrainUtils.cacheFiles(getTempPath(WEIGHTS), getConf());
1: 
0:     Job thetaSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS), getTempPath(THETAS),
0:         SequenceFileInputFormat.class, ThetaMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class,
0:         Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
0:     thetaSummer.setCombinerClass(VectorSumReducer.class);
0:     thetaSummer.getConfiguration().setFloat(ThetaMapper.ALPHA_I, alphaI);
0:     thetaSummer.getConfiguration().setBoolean(ThetaMapper.TRAIN_COMPLEMENTARY, trainComplementary);
0:     thetaSummer.waitForCompletion(true);
1: 
0:     NaiveBayesModel naiveBayesModel = TrainUtils.readModelFromTempDir(getTempPath(), getConf());
1:     naiveBayesModel.validate();
1:     naiveBayesModel.serialize(getOutputPath(), getConf());
1: 
1:     return 0;
1:   }
1: 
1: }
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:28fe003
/////////////////////////////////////////////////////////////////////////
0:     // Calculate the per label theta normalizers, write out to LABEL_THETA_NORMALIZER vector
0:     // see http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf - Section 3.2, Weight Magnitude Errors
commit:fa29726
/////////////////////////////////////////////////////////////////////////
0:     // calculate the per label theta normalizers, write out to LABEL_THETA_NORMALIZER vector --
0:     // Rennie 3.2      
/////////////////////////////////////////////////////////////////////////
1:     }
0:     
0:     //put the per label theta normalizers into the cache 
1:     HadoopUtil.cacheFiles(getTempPath(THETAS), getConf());
0:     
commit:ede812b
/////////////////////////////////////////////////////////////////////////
0:     //boolean trainComplementary = Boolean.parseBoolean(getOption(TRAIN_COMPLEMENTARY)); //always result to false
1:     boolean trainComplementary = hasOption(TRAIN_COMPLEMENTARY);
author:Robin Anil
-------------------------------------------------------------------------------
commit:3cadef9
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import java.util.List;
0: import java.util.Map;
0: 
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Splitter;
/////////////////////////////////////////////////////////////////////////
0: 
0: 
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
commit:d94eb39
/////////////////////////////////////////////////////////////////////////
1:   private static final String TRAIN_COMPLEMENTARY = "trainComplementary";
1:   private static final String ALPHA_I = "alphaI";
1:   private static final String LABEL_INDEX = "labelIndex";
0:   private static final String EXTRACT_LABELS = "extractLabels";
0:   private static final String LABELS = "labels";
/////////////////////////////////////////////////////////////////////////
0:     addOption(LABELS, "l", "comma-separated list of labels to include in training", false);
0:     addOption(buildOption(EXTRACT_LABELS, "el", "Extract the labels from the input", false, false, ""));
1:     addOption(ALPHA_I, "a", "smoothing parameter", String.valueOf(1.0f));
1:     addOption(buildOption(TRAIN_COMPLEMENTARY, "c", "train complementary?", false, false, String.valueOf(false)));
1:     addOption(LABEL_INDEX, "li", "The path to store the label index in", false);
/////////////////////////////////////////////////////////////////////////
1:     String labPathStr = getOption(LABEL_INDEX);
1:       labPath = getTempPath(LABEL_INDEX);
1:     float alphaI = Float.parseFloat(getOption(ALPHA_I));
0:     boolean trainComplementary = Boolean.parseBoolean(getOption(TRAIN_COMPLEMENTARY));
/////////////////////////////////////////////////////////////////////////
0:     /* TODO(robinanil): Enable this when thetanormalization works.
0:     }*/
/////////////////////////////////////////////////////////////////////////
0:     if (hasOption(LABELS)) {
0:       Iterable<String> labels = Splitter.on(",").split(getOption(LABELS));
0:     } else if (hasOption(EXTRACT_LABELS)) {
commit:a344c6b
/////////////////////////////////////////////////////////////////////////
0:     
0:     
/////////////////////////////////////////////////////////////////////////
0:     
commit:d8d721a
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.base.Splitter;
1: import org.apache.hadoop.fs.Path;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1: import org.apache.mahout.common.iterator.sequencefile.PathType;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
0: import java.io.IOException;
0: import java.util.List;
0: import java.util.Map;
0: 
/////////////////////////////////////////////////////////////////////////
0: 
0:     addOption("labels", "l", "comma-separated list of labels to include in training", false);
0: 
0:     addOption(buildOption("extractLabels", "el", "Extract the labels from the input", false, false, ""));
0:     addOption("labelIndex", "li", "The path to store the label index in", false);
/////////////////////////////////////////////////////////////////////////
1:     Path labPath;
0:     String labPathStr = getOption("labelIndex");
1:     if (labPathStr != null) {
1:       labPath = new Path(labPathStr);
1:     } else {
0:       labPath = getTempPath("labelIndex");
1:     }
1:     long labelSize = createLabelIndex(labPath);
0: 
1:     HadoopUtil.cacheFiles(labPath, getConf());
0: 
/////////////////////////////////////////////////////////////////////////
0: 
1:   private long createLabelIndex(Path labPath) throws IOException {
1:     long labelSize = 0;
0:     if (hasOption("labels")) {
0:       Iterable<String> labels = Splitter.on(",").split(getOption("labels"));
0:       labelSize = BayesUtils.writeLabelIndex(getConf(), labels, labPath);
0:     } else if (hasOption("extractLabels")) {
0:       SequenceFileDirIterable<Text, IntWritable> iterable =
0:               new SequenceFileDirIterable<Text, IntWritable>(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), getConf());
0:       labelSize = BayesUtils.writeLabelIndex(getConf(), labPath, iterable);
1:     }
1:     return labelSize;
1:   }
0: 
commit:1526c5b
/////////////////////////////////////////////////////////////////////////
0: import java.util.List;
0: import java.util.Map;
0: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     addOption("labelSize", "ls", "Number of labels in the input data", String.valueOf(2));
/////////////////////////////////////////////////////////////////////////
0:     int labelSize = Integer.parseInt(getOption("labelSize"));
0:     
/////////////////////////////////////////////////////////////////////////
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.Pair;
/////////////////////////////////////////////////////////////////////////
1:     Job indexInstances = prepareJob(getInputPath(),
1:                                     getTempPath(SUMMED_OBSERVATIONS),
1:                                     SequenceFileInputFormat.class,
1:                                     IndexInstancesMapper.class,
1:                                     IntWritable.class,
1:                                     VectorWritable.class,
1:                                     VectorSumReducer.class,
1:                                     IntWritable.class,
1:                                     VectorWritable.class,
1:                                     SequenceFileOutputFormat.class);
1:     Job weightSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS),
1:                                   getTempPath(WEIGHTS),
1:                                   SequenceFileInputFormat.class,
1:                                   WeightsMapper.class,
1:                                   Text.class,
1:                                   VectorWritable.class,
1:                                   VectorSumReducer.class,
1:                                   Text.class,
1:                                   VectorWritable.class,
1:                                   SequenceFileOutputFormat.class);
/////////////////////////////////////////////////////////////////////////
0:     //calculate the Thetas, write out to LABEL_THETA_NORMALIZER vectors --
0:     // TODO: add reference here to the part of the Rennie paper that discusses this
0:     Job thetaSummer = prepareJob(getTempPath(SUMMED_OBSERVATIONS),
0:                                  getTempPath(THETAS),
0:                                  SequenceFileInputFormat.class,
0:                                  ThetaMapper.class,
0:                                  Text.class,
0:                                  VectorWritable.class,
0:                                  VectorSumReducer.class,
0:                                  Text.class,
0:                                  VectorWritable.class,
0:                                  SequenceFileOutputFormat.class);
/////////////////////////////////////////////////////////////////////////
0:       Iterable<Pair<Text,IntWritable>> iterable =
0:           new SequenceFileDirIterable<Text, IntWritable>(getInputPath(),
0:                                                          PathType.LIST,
0:                                                          PathFilters.logsCRCFilter(),
0:                                                          getConf());
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = indexInstances.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
1:     }
1:     succeeded = weightSummer.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
1:     }
/////////////////////////////////////////////////////////////////////////
0:     succeeded = thetaSummer.waitForCompletion(true);
0:     if (!succeeded) {
0:       return -1;
1:     }
commit:4194a28
/////////////////////////////////////////////////////////////////////////
0:       Iterable<String> labels = Splitter.on(",").split(parsedArgs.get("--labels"));
0:       SequenceFileDirIterable<Text, IntWritable> iterable =
0:           new SequenceFileDirIterable<Text, IntWritable>(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), getConf());
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6db7f62
/////////////////////////////////////////////////////////////////////////
0: import java.util.List;
/////////////////////////////////////////////////////////////////////////
1:     Map<String, List<String>> parsedArgs = parseArguments(args);
/////////////////////////////////////////////////////////////////////////
0:     String labPathStr = getOption("labelIndex");
0:     long labelSize = createLabelIndex(labPath);
0:     float alphaI = Float.parseFloat(getOption("alphaI"));
0:     boolean trainComplementary = Boolean.parseBoolean(getOption("trainComplementary"));
/////////////////////////////////////////////////////////////////////////
0:   private long createLabelIndex(Path labPath) throws IOException {
0:     if (hasOption("labels")) {
0:       Iterable<String> labels = Splitter.on(",").split(getOption("labels"));
0:     } else if (hasOption("extractLabels")) {
commit:3ba87c8
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.mahout.classifier.naivebayes.NaiveBayesModel;
/////////////////////////////////////////////////////////////////////////
0: import java.io.IOException;
0: import java.util.Map;
0: 
0: /**
0:  * This class trains a Naive Bayes Classifier (Parameters for both Naive Bayes and Complementary Naive Bayes)
0:  */
/////////////////////////////////////////////////////////////////////////
0:     Map<String, String> parsedArgs = parseArguments(args);
/////////////////////////////////////////////////////////////////////////
0:     if (labPathStr != null) {
/////////////////////////////////////////////////////////////////////////
0:     //add up all the vectors with the same labels, while mapping the labels into our index
0:             IndexInstancesMapper.class, IntWritable.class, VectorWritable.class, VectorSumReducer.class, IntWritable.class,
0:             VectorWritable.class, SequenceFileOutputFormat.class);
0:     //sum up all the weights from the previous step, per label and per feature
0:             SequenceFileInputFormat.class, WeightsMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class,
0:             Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
0:     //put the per label and per feature vectors into the cache
0:     //calculate the Thetas, write out to LABEL_THETA_NORMALIZER vectors -- TODO: add reference here to the part of the Rennie paper that discusses this
0:             SequenceFileInputFormat.class, ThetaMapper.class, Text.class, VectorWritable.class, VectorSumReducer.class,
0:             Text.class, VectorWritable.class, SequenceFileOutputFormat.class);
0:     //validate our model and then write it out to the official output
/////////////////////////////////////////////////////////////////////////
0:     if (parsedArgs.containsKey("--labels")) {
0:     } else if (parsedArgs.containsKey("--extractLabels")) {
0:               new SequenceFileDirIterable<Text, IntWritable>(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), getConf());
commit:29a7f38
/////////////////////////////////////////////////////////////////////////
0: import java.io.IOException;
1: import org.apache.hadoop.conf.Configuration;
0: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.util.ToolRunner;
1: import org.apache.mahout.classifier.naivebayes.BayesUtils;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.commandline.DefaultOptionCreator;
0: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
0: import org.apache.mahout.common.iterator.sequencefile.PathType;
0: import org.apache.mahout.common.iterator.sequencefile.SequenceFileDirIterable;
/////////////////////////////////////////////////////////////////////////
1:   public static void main(String[] args) throws Exception {
1:     ToolRunner.run(new Configuration(), new TrainNaiveBayesJob(), args);
0:   }
0: 
0:     addOption("labels", "l", "comma-separated list of labels to include in training", false);
0:     addOption(buildOption("extractLabels", "el", "Extract the labels from the input", false, false, ""));
0:     addOption("alphaI", "a", "smoothing parameter", String.valueOf(1.0f));
0:     addOption(buildOption("trainComplementary", "c", "train complementary?", false, false, String.valueOf(false)));
0:     addOption("labelIndex", "li", "The path to store the label index in", false);
1:     addOption(DefaultOptionCreator.overwriteOption().create());
1:     if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:       HadoopUtil.delete(getConf(), getOutputPath());
1:       HadoopUtil.delete(getConf(), getTempPath());
0:     }
0:     Path labPath;
0:     String labPathStr = parsedArgs.get("--labelIndex");
0:     if (labPathStr != null){
0:       labPath = new Path(labPathStr);
0:     } else {
0:       labPath = getTempPath("labelIndex");
0:     }
0:     long labelSize = createLabelIndex(parsedArgs, labPath);
0: 
1:     HadoopUtil.setSerializations(getConf());
0:     HadoopUtil.cacheFiles(labPath, getConf());
/////////////////////////////////////////////////////////////////////////
1:     weightSummer.getConfiguration().set(WeightsMapper.NUM_LABELS, String.valueOf(labelSize));
1:     HadoopUtil.cacheFiles(getTempPath(WEIGHTS), getConf());
/////////////////////////////////////////////////////////////////////////
1:     NaiveBayesModel naiveBayesModel = BayesUtils.readModelFromDir(getTempPath(), getConf());
0:   private long createLabelIndex(Map<String, String> parsedArgs, Path labPath) throws IOException {
0:     long labelSize = 0;
0:     if (parsedArgs.containsKey("--labels")){
0:       Iterable<String> labels;
0:       labels = Splitter.on(",").split(parsedArgs.get("--labels"));
0:       labelSize = BayesUtils.writeLabelIndex(getConf(), labels, labPath);
0:     } else if (parsedArgs.containsKey("--extractLabels")){
0:       SequenceFileDirIterable iterable = new SequenceFileDirIterable(getInputPath(), PathType.LIST, PathFilters.logsCRCFilter(), getConf());
0:       labelSize = BayesUtils.writeLabelIndex(getConf(), labPath, iterable);
0:     }
0:     return labelSize;
0:   }
0: 
============================================================================
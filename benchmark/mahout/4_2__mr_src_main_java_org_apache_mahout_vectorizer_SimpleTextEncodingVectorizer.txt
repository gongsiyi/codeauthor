1:4fbfbc6: /*
1:faa82ce:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:faa82ce:  * contributor license agreements.  See the NOTICE file distributed with
1:faa82ce:  * this work for additional information regarding copyright ownership.
1:faa82ce:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:faa82ce:  * (the "License"); you may not use this file except in compliance with
1:faa82ce:  * the License.  You may obtain a copy of the License at
1:faa82ce:  *
1:faa82ce:  *     http://www.apache.org/licenses/LICENSE-2.0
1:faa82ce:  *
1:faa82ce:  * Unless required by applicable law or agreed to in writing, software
1:faa82ce:  * distributed under the License is distributed on an "AS IS" BASIS,
1:faa82ce:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:faa82ce:  * See the License for the specific language governing permissions and
1:faa82ce:  * limitations under the License.
1:faa82ce:  */
3:faa82ce: 
1:4fbfbc6: package org.apache.mahout.vectorizer;
1:faa82ce: 
1:faa82ce: import org.apache.hadoop.conf.Configuration;
1:faa82ce: import org.apache.hadoop.fs.Path;
1:faa82ce: import org.apache.hadoop.io.Text;
1:faa82ce: import org.apache.hadoop.mapreduce.Job;
1:faa82ce: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1:faa82ce: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:faa82ce: import org.apache.mahout.common.HadoopUtil;
1:faa82ce: import org.apache.mahout.math.VectorWritable;
1:faa82ce: import org.slf4j.Logger;
1:faa82ce: import org.slf4j.LoggerFactory;
1:faa82ce: 
1:4fbfbc6: import java.io.IOException;
1:4fbfbc6: 
2:faa82ce: /**
1:4fbfbc6:  * <p>Runs a Map/Reduce job that encodes {@link org.apache.mahout.vectorizer.encoders.FeatureVectorEncoder} the
1:4fbfbc6:  * input and writes it to the output as a sequence file.</p>
1:4fbfbc6:  *
1:4fbfbc6:  * <p>Only works on basic text, where the value in the SequenceFile is a blob of text.</p>
1:faa82ce:  */
1:faa82ce: //TODO: find commonalities w/ DictionaryVectorizer and abstract them out
1:faa82ce: public class SimpleTextEncodingVectorizer implements Vectorizer {
1:faa82ce: 
1:4fbfbc6:   private static final Logger log = LoggerFactory.getLogger(SimpleTextEncodingVectorizer.class);
1:faa82ce: 
1:faa82ce:   @Override
1:4fbfbc6:   public void createVectors(Path input, Path output, VectorizerConfig config)
1:4fbfbc6:     throws IOException, ClassNotFoundException, InterruptedException {
1:faa82ce:     //do this for convenience of using prepareJob
1:4fbfbc6:     Job job = HadoopUtil.prepareJob(input, output,
1:4fbfbc6:                                     SequenceFileInputFormat.class,
1:4fbfbc6:                                     EncodingMapper.class,
1:4fbfbc6:                                     Text.class,
1:4fbfbc6:                                     VectorWritable.class,
1:4fbfbc6:                                     SequenceFileOutputFormat.class,
1:4fbfbc6:                                     config.getConf());
1:faa82ce:     Configuration conf = job.getConfiguration();
1:4fbfbc6:     conf.set(EncodingMapper.USE_SEQUENTIAL, String.valueOf(config.isSequentialAccess()));
1:4fbfbc6:     conf.set(EncodingMapper.USE_NAMED_VECTORS, String.valueOf(config.isNamedVectors()));
1:4fbfbc6:     conf.set(EncodingMapper.ANALYZER_NAME, config.getAnalyzerClassName());
1:4fbfbc6:     conf.set(EncodingMapper.ENCODER_FIELD_NAME, config.getEncoderName());
1:4fbfbc6:     conf.set(EncodingMapper.ENCODER_CLASS, config.getEncoderClass());
1:4fbfbc6:     conf.set(EncodingMapper.CARDINALITY, String.valueOf(config.getCardinality()));
1:faa82ce:     job.setNumReduceTasks(0);
1:faa82ce:     boolean finished = job.waitForCompletion(true);
1:faa82ce: 
1:4fbfbc6:     log.info("result of run: {}", finished);
1:229aeff:     if (!finished) {
1:7c2b664:       throw new IllegalStateException("Job failed!");
1:229aeff:     }
2:faa82ce:   }
1:faa82ce: 
1:faa82ce: }
1:faa82ce: 
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     if (!finished) {
1:     }
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
0:     if (!finished) 
1:       throw new IllegalStateException("Job failed!");
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
1: /*
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.vectorizer;
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: 
1:  * <p>Runs a Map/Reduce job that encodes {@link org.apache.mahout.vectorizer.encoders.FeatureVectorEncoder} the
1:  * input and writes it to the output as a sequence file.</p>
1:  *
1:  * <p>Only works on basic text, where the value in the SequenceFile is a blob of text.</p>
1:   private static final Logger log = LoggerFactory.getLogger(SimpleTextEncodingVectorizer.class);
1:   public void createVectors(Path input, Path output, VectorizerConfig config)
1:     throws IOException, ClassNotFoundException, InterruptedException {
1:     Job job = HadoopUtil.prepareJob(input, output,
1:                                     SequenceFileInputFormat.class,
1:                                     EncodingMapper.class,
1:                                     Text.class,
1:                                     VectorWritable.class,
1:                                     SequenceFileOutputFormat.class,
1:                                     config.getConf());
1:     conf.set(EncodingMapper.USE_SEQUENTIAL, String.valueOf(config.isSequentialAccess()));
1:     conf.set(EncodingMapper.USE_NAMED_VECTORS, String.valueOf(config.isNamedVectors()));
1:     conf.set(EncodingMapper.ANALYZER_NAME, config.getAnalyzerClassName());
1:     conf.set(EncodingMapper.ENCODER_FIELD_NAME, config.getEncoderName());
1:     conf.set(EncodingMapper.ENCODER_CLASS, config.getEncoderClass());
1:     conf.set(EncodingMapper.CARDINALITY, String.valueOf(config.getCardinality()));
1:     log.info("result of run: {}", finished);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:faa82ce
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.vectorizer;
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.math.VectorWritable;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
1: /**
0:  * Runs a Map/Reduce job that encodes {@link org.apache.mahout.vectorizer.encoders.FeatureVectorEncoder} the
0:  * input and writes it to the output as a sequence file.
0:  *<p/>
0:  * Only works on basic text, where the value in the SequenceFile is a blob of text.
1:  */
1: //TODO: find commonalities w/ DictionaryVectorizer and abstract them out
1: public class SimpleTextEncodingVectorizer implements Vectorizer {
0:   private transient static Logger log = LoggerFactory.getLogger(SimpleTextEncodingVectorizer.class);
1: 
0:   public SimpleTextEncodingVectorizer() {
1:   }
1: 
1: 
1:   @Override
0:   public void createVectors(final Path input, final Path output, final VectorizerConfig config) throws Exception {
1:     //do this for convenience of using prepareJob
0:     Job job = HadoopUtil.prepareJob(input, output, SequenceFileInputFormat.class, EncodingMapper.class, Text.class, VectorWritable.class,
0:             SequenceFileOutputFormat.class, config.conf);
1:     Configuration conf = job.getConfiguration();
0:     conf.set(EncodingMapper.USE_SEQUENTIAL, String.valueOf(config.sequentialAccess));
0:     conf.set(EncodingMapper.USE_NAMED_VECTORS, String.valueOf(config.namedVectors));
0:     conf.set(EncodingMapper.ANALYZER_NAME, config.analyzerClassName);
0:     conf.set(EncodingMapper.ENCODER_FIELD_NAME, config.encoderName);
0:     conf.set(EncodingMapper.ENCODER_CLASS, config.encoderClass);
0:     conf.set(EncodingMapper.CARDINALITY, String.valueOf(config.cardinality));
1:     job.setNumReduceTasks(0);
1:     boolean finished = job.waitForCompletion(true);
1: 
0:     log.info("result of run: " + finished);
0:     //TODO: something useful w/ this result should it be meaningful.
1:   }
1: 
1: 
1: }
1: 
============================================================================
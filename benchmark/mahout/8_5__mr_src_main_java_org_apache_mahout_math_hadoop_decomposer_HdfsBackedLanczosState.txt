1:96117d3: /*
1:96117d3:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:96117d3:  * contributor license agreements.  See the NOTICE file distributed with
1:96117d3:  * this work for additional information regarding copyright ownership.
1:96117d3:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:96117d3:  * (the "License"); you may not use this file except in compliance with
1:96117d3:  * the License.  You may obtain a copy of the License at
1:96117d3:  *
1:96117d3:  *     http://www.apache.org/licenses/LICENSE-2.0
1:96117d3:  *
1:96117d3:  * Unless required by applicable law or agreed to in writing, software
1:96117d3:  * distributed under the License is distributed on an "AS IS" BASIS,
1:96117d3:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:96117d3:  * See the License for the specific language governing permissions and
1:96117d3:  * limitations under the License.
1:96117d3:  */
1:96117d3: 
1:522ee0b: package org.apache.mahout.math.hadoop.decomposer;
3:522ee0b: 
1:87d4b2e: import java.io.IOException;
1:87d4b2e: import java.util.Map;
1:87d4b2e: 
1:d608a88: import com.google.common.io.Closeables;
1:522ee0b: import org.apache.hadoop.conf.Configurable;
1:522ee0b: import org.apache.hadoop.conf.Configuration;
1:522ee0b: import org.apache.hadoop.fs.FileSystem;
1:522ee0b: import org.apache.hadoop.fs.Path;
1:522ee0b: import org.apache.hadoop.io.IntWritable;
1:522ee0b: import org.apache.hadoop.io.SequenceFile;
1:522ee0b: import org.apache.mahout.math.DenseMatrix;
1:522ee0b: import org.apache.mahout.math.DenseVector;
1:522ee0b: import org.apache.mahout.math.Matrix;
1:522ee0b: import org.apache.mahout.math.Vector;
1:522ee0b: import org.apache.mahout.math.VectorIterable;
1:522ee0b: import org.apache.mahout.math.VectorWritable;
1:522ee0b: import org.apache.mahout.math.decomposer.lanczos.LanczosState;
1:522ee0b: import org.slf4j.Logger;
1:522ee0b: import org.slf4j.LoggerFactory;
1:522ee0b: 
1:522ee0b: public class HdfsBackedLanczosState extends LanczosState implements Configurable {
1:96117d3: 
1:522ee0b:   private static final Logger log = LoggerFactory.getLogger(HdfsBackedLanczosState.class);
1:96117d3: 
1:522ee0b:   public static final String BASIS_PREFIX = "basis";
1:522ee0b:   public static final String SINGULAR_PREFIX = "singular";
1:f88d7dc:  //public static final String METADATA_FILE = "metadata";
1:96117d3: 
1:522ee0b:   private Configuration conf;
1:96117d3:   private final Path baseDir;
1:96117d3:   private final Path basisPath;
1:96117d3:   private final Path singularVectorPath;
1:522ee0b:   private FileSystem fs;
1:522ee0b:   
1:4fbfbc6:   public HdfsBackedLanczosState(VectorIterable corpus, int desiredRank, Vector initialVector, Path dir) {
1:4fbfbc6:     super(corpus, desiredRank, initialVector);
1:522ee0b:     baseDir = dir;
1:96117d3:     //Path metadataPath = new Path(dir, METADATA_FILE);
1:522ee0b:     basisPath = new Path(dir, BASIS_PREFIX);
1:522ee0b:     singularVectorPath = new Path(dir, SINGULAR_PREFIX);
1:e64dd36:     if (corpus instanceof Configurable) {
1:522ee0b:       setConf(((Configurable)corpus).getConf());
5:522ee0b:     }
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override public void setConf(Configuration configuration) {
1:522ee0b:     conf = configuration;
1:522ee0b:     try {
1:522ee0b:       setupDirs();
1:522ee0b:       updateHdfsState();
1:522ee0b:     } catch (IOException e) {
1:4ca6b86:       log.error("Could not retrieve filesystem: {}", conf, e);
1:522ee0b:     }
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override public Configuration getConf() {
1:522ee0b:     return conf;
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   private void setupDirs() throws IOException {
1:522ee0b:     fs = baseDir.getFileSystem(conf);
1:522ee0b:     createDirIfNotExist(baseDir);
1:522ee0b:     createDirIfNotExist(basisPath);
1:522ee0b:     createDirIfNotExist(singularVectorPath);
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   private void createDirIfNotExist(Path path) throws IOException {
1:229aeff:     if (!fs.exists(path) && !fs.mkdirs(path)) {
1:229aeff:       throw new IOException("Unable to create: " + path);
1:522ee0b:     }
1:522ee0b:   }
1:522ee0b: 
3:522ee0b:   @Override
1:522ee0b:   public void setIterationNumber(int i) {
1:522ee0b:     super.setIterationNumber(i);
1:522ee0b:     try {
1:522ee0b:       updateHdfsState();
1:522ee0b:     } catch (IOException e) {
1:522ee0b:       log.error("Could not update HDFS state: ", e);
1:522ee0b:     }
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   protected void updateHdfsState() throws IOException {
1:e64dd36:     if (conf == null) {
1:522ee0b:       return;
1:522ee0b:     }
1:522ee0b:     int numBasisVectorsOnDisk = 0;
1:96117d3:     Path nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + numBasisVectorsOnDisk);
1:e64dd36:     while (fs.exists(nextBasisVectorPath)) {
1:96117d3:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);
1:522ee0b:     }
1:96117d3:     Vector nextVector;
1:6d16230:     while (numBasisVectorsOnDisk < iterationNumber
1:6d16230:         && (nextVector = getBasisVector(numBasisVectorsOnDisk)) != null) {
1:522ee0b:       persistVector(nextBasisVectorPath, numBasisVectorsOnDisk, nextVector);
1:96117d3:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);
1:522ee0b:     }
1:e64dd36:     if (scaleFactor <= 0) {
1:522ee0b:       scaleFactor = getScaleFactor(); // load from disk if possible
1:522ee0b:     }
1:522ee0b:     diagonalMatrix = getDiagonalMatrix(); // load from disk if possible
1:522ee0b:     Vector norms = new DenseVector(diagonalMatrix.numCols() - 1);
1:522ee0b:     Vector projections = new DenseVector(diagonalMatrix.numCols());
1:522ee0b:     int i = 0;
1:e64dd36:     while (i < diagonalMatrix.numCols() - 1) {
1:522ee0b:       norms.set(i, diagonalMatrix.get(i, i + 1));
1:522ee0b:       projections.set(i, diagonalMatrix.get(i, i));
1:522ee0b:       i++;
1:522ee0b:     }
1:522ee0b:     projections.set(i, diagonalMatrix.get(i, i));
1:522ee0b:     persistVector(new Path(baseDir, "projections"), 0, projections);
1:522ee0b:     persistVector(new Path(baseDir, "norms"), 0, norms);
1:522ee0b:     persistVector(new Path(baseDir, "scaleFactor"), 0, new DenseVector(new double[] {scaleFactor}));
1:e64dd36:     for (Map.Entry<Integer, Vector> entry : singularVectors.entrySet()) {
1:96117d3:       persistVector(new Path(singularVectorPath, SINGULAR_PREFIX + '_' + entry.getKey()),
1:522ee0b:           entry.getKey(), entry.getValue());
1:522ee0b:     }
1:522ee0b:     super.setIterationNumber(numBasisVectorsOnDisk);
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   protected void persistVector(Path p, int key, Vector vector) throws IOException {
1:522ee0b:     SequenceFile.Writer writer = null;
1:522ee0b:     try {
1:e64dd36:       if (fs.exists(p)) {
1:4194a28:         log.warn("{} exists, will overwrite", p);
1:522ee0b:         fs.delete(p, true);
1:522ee0b:       }
1:522ee0b:       writer = new SequenceFile.Writer(fs, conf, p,
1:522ee0b:           IntWritable.class, VectorWritable.class);
1:522ee0b:       writer.append(new IntWritable(key), new VectorWritable(vector));
1:522ee0b:     } finally {
1:87d4b2e:       Closeables.close(writer, false);
1:522ee0b:     }
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   protected Vector fetchVector(Path p, int keyIndex) throws IOException {
1:e64dd36:     if (!fs.exists(p)) {
1:522ee0b:       return null;
1:522ee0b:     }
1:522ee0b:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, p, conf);
1:522ee0b:     IntWritable key = new IntWritable();
1:522ee0b:     VectorWritable vw = new VectorWritable();
1:e64dd36:     while (reader.next(key, vw)) {
1:e64dd36:       if (key.get() == keyIndex) {
1:522ee0b:         return vw.get();
1:522ee0b:       }
1:522ee0b:     }
1:522ee0b:     return null;
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override
1:522ee0b:   public Vector getBasisVector(int i) {
1:e64dd36:     if (!basis.containsKey(i)) {
1:522ee0b:       try {
1:96117d3:         Vector v = fetchVector(new Path(basisPath, BASIS_PREFIX + '_' + i), i);
1:522ee0b:         basis.put(i, v);
1:522ee0b:       } catch (IOException e) {
1:4ca6b86:         log.error("Could not load basis vector: {}", i, e);
1:522ee0b:       }
1:522ee0b:     }
1:522ee0b:     return super.getBasisVector(i);
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override
1:522ee0b:   public Vector getRightSingularVector(int i) {
1:e64dd36:     if (!singularVectors.containsKey(i)) {
1:522ee0b:       try {
1:96117d3:         Vector v = fetchVector(new Path(singularVectorPath, BASIS_PREFIX + '_' + i), i);
1:522ee0b:         singularVectors.put(i, v);
1:522ee0b:       } catch (IOException e) {
1:4ca6b86:         log.error("Could not load singular vector: {}", i, e);
1:522ee0b:       }
1:522ee0b:     }
1:522ee0b:     return super.getRightSingularVector(i);
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override
1:522ee0b:   public double getScaleFactor() {
1:e64dd36:     if (scaleFactor <= 0) {
1:522ee0b:       try {
1:522ee0b:         Vector v = fetchVector(new Path(baseDir, "scaleFactor"), 0);
1:e64dd36:         if (v != null && v.size() > 0) {
1:522ee0b:           scaleFactor = v.get(0);
1:522ee0b:         }
1:522ee0b:       } catch (IOException e) {
1:522ee0b:         log.error("could not load scaleFactor:", e);
1:522ee0b:       }
1:522ee0b:     }
1:522ee0b:     return scaleFactor;
1:522ee0b:   }
1:522ee0b: 
1:522ee0b:   @Override
1:522ee0b:   public Matrix getDiagonalMatrix() {
1:e64dd36:     if (diagonalMatrix == null) {
1:522ee0b:       diagonalMatrix = new DenseMatrix(desiredRank, desiredRank);
1:522ee0b:     }
1:e64dd36:     if (diagonalMatrix.get(0, 1) <= 0) {
1:522ee0b:       try {
1:522ee0b:         Vector norms = fetchVector(new Path(baseDir, "norms"), 0);
1:522ee0b:         Vector projections = fetchVector(new Path(baseDir, "projections"), 0);
1:e64dd36:         if (norms != null && projections != null) {
1:4841efb:           int i = 0;
1:4841efb:           while (i < projections.size() - 1) {
1:522ee0b:             diagonalMatrix.set(i, i, projections.get(i));
1:4841efb:             diagonalMatrix.set(i, i + 1, norms.get(i));
1:4841efb:             diagonalMatrix.set(i + 1, i, norms.get(i));
1:522ee0b:             i++;
1:522ee0b:           }
1:522ee0b:           diagonalMatrix.set(i, i, projections.get(i));
1:522ee0b:         }
1:522ee0b:       } catch (IOException e) {
1:522ee0b:         log.error("Could not load diagonal matrix of norms and projections: ", e);
1:522ee0b:       }
1:522ee0b:     }
1:522ee0b:     return diagonalMatrix;
1:522ee0b:   }
1:522ee0b: 
1:522ee0b: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:f88d7dc
/////////////////////////////////////////////////////////////////////////
1:  //public static final String METADATA_FILE = "metadata";
commit:17f6362
/////////////////////////////////////////////////////////////////////////
0: @Deprecated
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:     while (numBasisVectorsOnDisk < iterationNumber
1:         && (nextVector = getBasisVector(numBasisVectorsOnDisk)) != null) {
commit:4841efb
/////////////////////////////////////////////////////////////////////////
1:           int i = 0;
1:           while (i < projections.size() - 1) {
1:             diagonalMatrix.set(i, i + 1, norms.get(i));
1:             diagonalMatrix.set(i + 1, i, norms.get(i));
commit:d608a88
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
0:       Closeables.closeQuietly(writer);
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
1: import java.io.IOException;
1: import java.util.Map;
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       Closeables.close(writer, false);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(writer, true);
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:4ca6b86
/////////////////////////////////////////////////////////////////////////
1:       log.error("Could not retrieve filesystem: {}", conf, e);
/////////////////////////////////////////////////////////////////////////
1:         log.error("Could not load basis vector: {}", i, e);
/////////////////////////////////////////////////////////////////////////
1:         log.error("Could not load singular vector: {}", i, e);
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     if (!fs.exists(path) && !fs.mkdirs(path)) {
1:       throw new IOException("Unable to create: " + path);
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
1:   public HdfsBackedLanczosState(VectorIterable corpus, int desiredRank, Vector initialVector, Path dir) {
1:     super(corpus, desiredRank, initialVector);
commit:4194a28
/////////////////////////////////////////////////////////////////////////
1:         log.warn("{} exists, will overwrite", p);
commit:3d44c1e
/////////////////////////////////////////////////////////////////////////
commit:96117d3
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1:   private final Path baseDir;
1:   private final Path basisPath;
1:   private final Path singularVectorPath;
1:     //Path metadataPath = new Path(dir, METADATA_FILE);
/////////////////////////////////////////////////////////////////////////
1:     Path nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + numBasisVectorsOnDisk);
1:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);
1:     Vector nextVector;
1:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + '_' + ++numBasisVectorsOnDisk);
/////////////////////////////////////////////////////////////////////////
1:       persistVector(new Path(singularVectorPath, SINGULAR_PREFIX + '_' + entry.getKey()),
/////////////////////////////////////////////////////////////////////////
1:         Vector v = fetchVector(new Path(basisPath, BASIS_PREFIX + '_' + i), i);
/////////////////////////////////////////////////////////////////////////
1:         Vector v = fetchVector(new Path(singularVectorPath, BASIS_PREFIX + '_' + i), i);
author:tcp
-------------------------------------------------------------------------------
commit:e64dd36
/////////////////////////////////////////////////////////////////////////
1:     if (corpus instanceof Configurable) {
/////////////////////////////////////////////////////////////////////////
0:     if (!fs.exists(path)) {
0:       if (!fs.mkdirs(path)) {
/////////////////////////////////////////////////////////////////////////
1:     if (conf == null) {
1:     while (fs.exists(nextBasisVectorPath)) {
0:     while (numBasisVectorsOnDisk < iterationNumber &&
1:     if (scaleFactor <= 0) {
1:     while (i < diagonalMatrix.numCols() - 1) {
/////////////////////////////////////////////////////////////////////////
1:     for (Map.Entry<Integer, Vector> entry : singularVectors.entrySet()) {
/////////////////////////////////////////////////////////////////////////
1:       if (fs.exists(p)) {
/////////////////////////////////////////////////////////////////////////
1:     if (!fs.exists(p)) {
1:     while (reader.next(key, vw)) {
1:       if (key.get() == keyIndex) {
/////////////////////////////////////////////////////////////////////////
1:     if (!basis.containsKey(i)) {
/////////////////////////////////////////////////////////////////////////
1:     if (!singularVectors.containsKey(i)) {
/////////////////////////////////////////////////////////////////////////
1:     if (scaleFactor <= 0) {
1:         if (v != null && v.size() > 0) {
/////////////////////////////////////////////////////////////////////////
1:     if (diagonalMatrix == null) {
1:     if (diagonalMatrix.get(0, 1) <= 0) {
1:         if (norms != null && projections != null) {
0:           while (i<projections.size()-1) {
author:Jacob Alexander Mannix
-------------------------------------------------------------------------------
commit:522ee0b
/////////////////////////////////////////////////////////////////////////
1: package org.apache.mahout.math.hadoop.decomposer;
1: 
1: import org.apache.hadoop.conf.Configurable;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.mahout.math.DenseMatrix;
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.Matrix;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorIterable;
1: import org.apache.mahout.math.VectorWritable;
1: import org.apache.mahout.math.decomposer.lanczos.LanczosState;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
0: import java.io.IOException;
0: import java.util.Map;
1: 
1: public class HdfsBackedLanczosState extends LanczosState implements Configurable {
1:   private static final Logger log = LoggerFactory.getLogger(HdfsBackedLanczosState.class);
1:   public static final String BASIS_PREFIX = "basis";
1:   public static final String SINGULAR_PREFIX = "singular";
0:   public static final String METADATA_FILE = "metadata";
1:   private Configuration conf;
0:   private Path baseDir;
0:   private Path metadataPath;
0:   private Path basisPath;
0:   private Path singularVectorPath;
1:   private FileSystem fs;
1:   
0:   public HdfsBackedLanczosState(VectorIterable corpus, int numCols, int desiredRank,
0:       Vector initialVector, Path dir) {
0:     super(corpus, numCols, desiredRank, initialVector);
1:     baseDir = dir;
0:     metadataPath = new Path(dir, METADATA_FILE);
1:     basisPath = new Path(dir, BASIS_PREFIX);
1:     singularVectorPath = new Path(dir, SINGULAR_PREFIX);
0:     if(corpus instanceof Configurable) {
1:       setConf(((Configurable)corpus).getConf());
1:     }
1:   }
1: 
1:   @Override public void setConf(Configuration configuration) {
1:     conf = configuration;
1:     try {
1:       setupDirs();
1:       updateHdfsState();
1:     } catch (IOException e) {
0:       log.error("Could not retrieve filesystem: ", conf, e);
1:     }
1:   }
1: 
1:   @Override public Configuration getConf() {
1:     return conf;
1:   }
1: 
1:   private void setupDirs() throws IOException {
1:     fs = baseDir.getFileSystem(conf);
1:     createDirIfNotExist(baseDir);
1:     createDirIfNotExist(basisPath);
1:     createDirIfNotExist(singularVectorPath);
1:   }
1: 
1:   private void createDirIfNotExist(Path path) throws IOException {
0:     if(!fs.exists(path)) {
0:       if(!fs.mkdirs(path)) {
0:         throw new IOException("Unable to create: " + path);
1:       }
1:     }
1:   }
1: 
1:   @Override
1:   public void setIterationNumber(int i) {
1:     super.setIterationNumber(i);
1:     try {
1:       updateHdfsState();
1:     } catch (IOException e) {
1:       log.error("Could not update HDFS state: ", e);
1:     }
1:   }
1: 
1:   protected void updateHdfsState() throws IOException {
0:     if(conf == null) {
1:       return;
1:     }
1:     int numBasisVectorsOnDisk = 0;
0:     Path nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + "_" + numBasisVectorsOnDisk);
0:     while(fs.exists(nextBasisVectorPath)) {
0:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + "_" + ++numBasisVectorsOnDisk);
1:     }
0:     Vector nextVector = null;
0:     while(numBasisVectorsOnDisk < iterationNumber &&
0:           (nextVector = getBasisVector(numBasisVectorsOnDisk)) != null) {
1:       persistVector(nextBasisVectorPath, numBasisVectorsOnDisk, nextVector);
0:       nextBasisVectorPath = new Path(basisPath, BASIS_PREFIX + "_" + ++numBasisVectorsOnDisk);
1:     }
0:     if(scaleFactor <= 0) {
1:       scaleFactor = getScaleFactor(); // load from disk if possible
1:     }
1:     diagonalMatrix = getDiagonalMatrix(); // load from disk if possible
1:     Vector norms = new DenseVector(diagonalMatrix.numCols() - 1);
1:     Vector projections = new DenseVector(diagonalMatrix.numCols());
1:     int i = 0;
0:     while(i < diagonalMatrix.numCols() - 1) {
1:       norms.set(i, diagonalMatrix.get(i, i + 1));
1:       projections.set(i, diagonalMatrix.get(i, i));
1:       i++;
1:     }
1:     projections.set(i, diagonalMatrix.get(i, i));
1:     persistVector(new Path(baseDir, "projections"), 0, projections);
1:     persistVector(new Path(baseDir, "norms"), 0, norms);
1:     persistVector(new Path(baseDir, "scaleFactor"), 0, new DenseVector(new double[] {scaleFactor}));
0:     for(Map.Entry<Integer, Vector> entry : singularVectors.entrySet()) {
0:       persistVector(new Path(singularVectorPath, SINGULAR_PREFIX + "_" + entry.getKey()),
1:           entry.getKey(), entry.getValue());
1:     }
1:     super.setIterationNumber(numBasisVectorsOnDisk);
1:   }
1: 
1:   protected void persistVector(Path p, int key, Vector vector) throws IOException {
1:     SequenceFile.Writer writer = null;
1:     try {
0:       if(fs.exists(p)) {
0:         log.warn(p + " exists, will overwrite");
1:         fs.delete(p, true);
1:       }
1:       writer = new SequenceFile.Writer(fs, conf, p,
1:           IntWritable.class, VectorWritable.class);
1:       writer.append(new IntWritable(key), new VectorWritable(vector));
1:     } finally {
0:       if(writer != null) {
0:         writer.close();
1:       }
1:     }
1:   }
1: 
1:   protected Vector fetchVector(Path p, int keyIndex) throws IOException {
0:     if(!fs.exists(p)) {
1:       return null;
1:     }
1:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, p, conf);
1:     IntWritable key = new IntWritable();
1:     VectorWritable vw = new VectorWritable();
0:     while(reader.next(key, vw)) {
0:       if(key.get() == keyIndex) {
1:         return vw.get();
1:       }
1:     }
1:     return null;
1:   }
1: 
1:   @Override
1:   public Vector getBasisVector(int i) {
0:     if(!basis.containsKey(i)) {
1:       try {
0:         Vector v = fetchVector(new Path(basisPath, BASIS_PREFIX + "_" + i), i);
1:         basis.put(i, v);
1:       } catch (IOException e) {
0:         log.error("Could not load basis vector: ", i, e);
1:       }
1:     }
1:     return super.getBasisVector(i);
1:   }
1: 
1:   @Override
1:   public Vector getRightSingularVector(int i) {
0:     if(!singularVectors.containsKey(i)) {
1:       try {
0:         Vector v = fetchVector(new Path(singularVectorPath, BASIS_PREFIX + "_" + i), i);
1:         singularVectors.put(i, v);
1:       } catch (IOException e) {
0:         log.error("Could not load singular vector: ", i, e);
1:       }
1:     }
1:     return super.getRightSingularVector(i);
1:   }
1: 
1:   @Override
1:   public double getScaleFactor() {
0:     if(scaleFactor <= 0) {
1:       try {
1:         Vector v = fetchVector(new Path(baseDir, "scaleFactor"), 0);
0:         if(v != null && v.size() > 0) {
1:           scaleFactor = v.get(0);
1:         }
1:       } catch (IOException e) {
1:         log.error("could not load scaleFactor:", e);
1:       }
1:     }
1:     return scaleFactor;
1:   }
1: 
1:   @Override
1:   public Matrix getDiagonalMatrix() {
0:     if(diagonalMatrix == null) {
1:       diagonalMatrix = new DenseMatrix(desiredRank, desiredRank);
1:     }
0:     if(diagonalMatrix.get(0, 1) <= 0) {
1:       try {
1:         Vector norms = fetchVector(new Path(baseDir, "norms"), 0);
1:         Vector projections = fetchVector(new Path(baseDir, "projections"), 0);
0:         if(norms != null && projections != null) {
0:           int i=0;
0:           while(i<projections.size()-1) {
1:             diagonalMatrix.set(i, i, projections.get(i));
0:             diagonalMatrix.set(i, i+1, norms.get(i));
0:             diagonalMatrix.set(i+1, i, norms.get(i));
1:             i++;
1:           }
1:           diagonalMatrix.set(i, i, projections.get(i));
1:         }
1:       } catch (IOException e) {
1:         log.error("Could not load diagonal matrix of norms and projections: ", e);
1:       }
1:     }
1:     return diagonalMatrix;
1:   }
1: 
1:   @Override
0:   public void setBasisVector(int i, Vector vector) {
0:     super.setBasisVector(i, vector);
1:   }
1: 
1:   @Override
0:   public void setRightSingularVector(int i, Vector vector) {
0:     super.setRightSingularVector(i, vector);
1:   }
1: }
============================================================================
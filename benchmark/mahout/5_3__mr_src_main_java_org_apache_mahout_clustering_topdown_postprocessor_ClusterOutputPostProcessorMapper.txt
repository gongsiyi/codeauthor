2:9d44881: /**
1:9d44881:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:9d44881:  * contributor license agreements.  See the NOTICE file distributed with
1:9d44881:  * this work for additional information regarding copyright ownership.
1:9d44881:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:9d44881:  * (the "License"); you may not use this file except in compliance with
1:9d44881:  * the License.  You may obtain a copy of the License at
1:9d44881:  *
1:9d44881:  *     http://www.apache.org/licenses/LICENSE-2.0
1:9d44881:  *
1:9d44881:  * Unless required by applicable law or agreed to in writing, software
1:9d44881:  * distributed under the License is distributed on an "AS IS" BASIS,
1:9d44881:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:9d44881:  * See the License for the specific language governing permissions and
1:9d44881:  * limitations under the License.
2:9d44881:  */
3:9d44881: 
1:9d44881: package org.apache.mahout.clustering.topdown.postprocessor;
1:9d44881: 
1:bbf5369: import org.apache.hadoop.conf.Configuration;
1:bbf5369: import org.apache.hadoop.fs.Path;
1:9d44881: import org.apache.hadoop.io.IntWritable;
1:9d44881: import org.apache.hadoop.mapreduce.Mapper;
1:8953d93: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
1:9d44881: import org.apache.mahout.math.VectorWritable;
1:9d44881: 
1:bbf5369: import java.io.IOException;
1:bbf5369: import java.util.Map;
1:bbf5369: 
1:9d44881: /**
1:9d44881:  * Mapper for post processing cluster output.
1:9d44881:  */
1:9d44881: public class ClusterOutputPostProcessorMapper extends
1:bbf5369:         Mapper<IntWritable, WeightedVectorWritable, IntWritable, VectorWritable> {
1:bbf5369: 
1:bbf5369:   private Map<Integer, Integer> newClusterMappings;
1:bbf5369:   private VectorWritable outputVector;
1:bbf5369: 
1:bbf5369:   //read the current cluster ids, and populate the cluster mapping hash table
1:9d44881:   @Override
1:bbf5369:   public void setup(Context context) throws IOException {
1:bbf5369:     Configuration conf = context.getConfiguration();
1:bbf5369:     //this give the clusters-x-final directory where the cluster ids can be read
1:bbf5369:     Path clusterOutputPath = new Path(conf.get("clusterOutputPath"));
1:bbf5369:     //we want the key to be the cluster id, the value to be the index
1:bbf5369:     newClusterMappings = ClusterCountReader.getClusterIDs(clusterOutputPath, conf, true);
1:bbf5369:     outputVector = new VectorWritable();
1:bbf5369:   }
1:bbf5369: 
1:bbf5369:   @Override
1:58cc1ae:   public void map(IntWritable key, WeightedVectorWritable val, Context context)
1:58cc1ae:     throws IOException, InterruptedException {
1:58cc1ae:     // by pivoting on the cluster mapping value, we can make sure that each unique cluster goes to it's own reducer,
1:58cc1ae:     // since they are numbered from 0 to k-1, where k is the number of clusters
1:bbf5369:     outputVector.set(val.getVector());
1:bbf5369:     context.write(new IntWritable(newClusterMappings.get(key.get())), outputVector);
1:9d44881:   }
1:9d44881: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1:   public void map(IntWritable key, WeightedVectorWritable val, Context context)
1:     throws IOException, InterruptedException {
1:     // by pivoting on the cluster mapping value, we can make sure that each unique cluster goes to it's own reducer,
1:     // since they are numbered from 0 to k-1, where k is the number of clusters
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:bbf5369
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import java.io.IOException;
1: import java.util.Map;
1: 
1:         Mapper<IntWritable, WeightedVectorWritable, IntWritable, VectorWritable> {
1: 
1:   private Map<Integer, Integer> newClusterMappings;
1:   private VectorWritable outputVector;
1: 
1:   //read the current cluster ids, and populate the cluster mapping hash table
1:   public void setup(Context context) throws IOException {
1:     Configuration conf = context.getConfiguration();
1:     //this give the clusters-x-final directory where the cluster ids can be read
1:     Path clusterOutputPath = new Path(conf.get("clusterOutputPath"));
1:     //we want the key to be the cluster id, the value to be the index
1:     newClusterMappings = ClusterCountReader.getClusterIDs(clusterOutputPath, conf, true);
1:     outputVector = new VectorWritable();
1:   }
1: 
1:   @Override
0:   public void map(IntWritable key, WeightedVectorWritable val, Context context) throws IOException, InterruptedException {
0:     //by pivoting on the cluster mapping value, we can make sure that each unique cluster goes to it's own reducer, since they
0:     //are numbered from 0 to k-1, where k is the number of clusters
1:     outputVector.set(val.getVector());
1:     context.write(new IntWritable(newClusterMappings.get(key.get())), outputVector);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:8953d93
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
commit:9d44881
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.clustering.topdown.postprocessor;
1: 
0: import java.io.IOException;
1: 
1: import org.apache.hadoop.io.IntWritable;
0: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Mapper;
0: import org.apache.mahout.clustering.WeightedVectorWritable;
1: import org.apache.mahout.math.VectorWritable;
1: 
1: /**
1:  * Mapper for post processing cluster output.
1:  */
1: public class ClusterOutputPostProcessorMapper extends
0:     Mapper<IntWritable,WeightedVectorWritable,Text,VectorWritable> {
1:   
1:   /**
0:    * The key is the cluster id and the value is the vector.
1:    */
1:   @Override
0:   protected void map(IntWritable key, WeightedVectorWritable vector, Context context) throws IOException,
0:                                                                                      InterruptedException {
0:     context.write(new Text(key.toString().trim()), new VectorWritable(vector.getVector()));
1:   }
1: }
============================================================================
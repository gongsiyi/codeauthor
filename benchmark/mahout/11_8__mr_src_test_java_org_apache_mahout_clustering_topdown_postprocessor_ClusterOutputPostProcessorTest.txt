1:9d44881: /**
1:9d44881:  * Licensed to the Apache Software Foundation (ASF) under one
1:9d44881:  * or more contributor license agreements. See the NOTICE file
1:9d44881:  * distributed with this work for additional information
1:9d44881:  * regarding copyright ownership. The ASF licenses this file
1:9d44881:  * to you under the Apache License, Version 2.0 (the
1:9d44881:  * "License"); you may not use this file except in compliance
1:9d44881:  * with the License. You may obtain a copy of the License at
1:9d44881:  *
1:9d44881:  * http://www.apache.org/licenses/LICENSE-2.0
1:9d44881:  *
1:9d44881:  * Unless required by applicable law or agreed to in writing,
1:9d44881:  * software distributed under the License is distributed on an
1:9d44881:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:9d44881:  * KIND, either express or implied. See the License for the
1:9d44881:  * specific language governing permissions and limitations
1:9d44881:  * under the License.
1:9d44881:  */
30:9d44881: 
1:9d44881: package org.apache.mahout.clustering.topdown.postprocessor;
1:9d44881: 
1:9d44881: import java.io.IOException;
1:9d44881: import java.util.List;
1:9d44881: import java.util.Map;
1:9d44881: import java.util.Map.Entry;
1:9d44881: 
1:67a531e: import org.apache.commons.lang3.ArrayUtils;
1:9d44881: import org.apache.hadoop.conf.Configuration;
1:9d44881: import org.apache.hadoop.fs.FileStatus;
1:9d44881: import org.apache.hadoop.fs.FileSystem;
1:9d44881: import org.apache.hadoop.fs.FileUtil;
1:9d44881: import org.apache.hadoop.fs.Path;
1:9d44881: import org.apache.hadoop.io.IntWritable;
1:9d44881: import org.apache.hadoop.io.LongWritable;
1:9d44881: import org.apache.hadoop.io.SequenceFile;
1:564c3e1: import org.apache.hadoop.io.Writable;
1:9d44881: import org.apache.mahout.clustering.ClusteringTestUtils;
1:9d44881: import org.apache.mahout.clustering.canopy.CanopyDriver;
1:8d102ea: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
1:9d44881: import org.apache.mahout.clustering.topdown.PathDirectory;
1:9d44881: import org.apache.mahout.common.DummyOutputCollector;
1:9d44881: import org.apache.mahout.common.MahoutTestCase;
1:9d44881: import org.apache.mahout.common.Pair;
1:9d44881: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1:9d44881: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1:9d44881: import org.apache.mahout.math.RandomAccessSparseVector;
1:9d44881: import org.apache.mahout.math.Vector;
1:9d44881: import org.apache.mahout.math.VectorWritable;
1:9d44881: import org.junit.Assert;
1:9d44881: import org.junit.Before;
1:9d44881: import org.junit.Test;
1:9d44881: 
1:9d44881: import com.google.common.collect.Lists;
1:9d44881: 
1:051cbcf: public final class ClusterOutputPostProcessorTest extends MahoutTestCase {
1:be94533: 
1:051cbcf:   private static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}};
1:be94533: 
1:9d44881:   private FileSystem fs;
1:be94533: 
1:9d44881:   private Path outputPath;
1:be94533: 
1:9d44881:   private Configuration conf;
1:be94533: 
1:9d44881:   @Override
1:9d44881:   @Before
1:9d44881:   public void setUp() throws Exception {
1:9d44881:     super.setUp();
1:921e201:     Configuration conf = getConfiguration();
1:9d44881:     fs = FileSystem.get(conf);
2:9d44881:   }
1:be94533: 
1:051cbcf:   private static List<VectorWritable> getPointsWritable(double[][] raw) {
1:9d44881:     List<VectorWritable> points = Lists.newArrayList();
1:9d44881:     for (double[] fr : raw) {
1:9d44881:       Vector vec = new RandomAccessSparseVector(fr.length);
1:9d44881:       vec.assign(fr);
1:9d44881:       points.add(new VectorWritable(vec));
1:9d44881:     }
1:9d44881:     return points;
1:9d44881:   }
1:be94533: 
1:9d44881:   /**
1:9d44881:    * Story: User wants to use cluster post processor after canopy clustering and then run clustering on the
1:9d44881:    * output clusters
1:9d44881:    */
1:9d44881:   @Test
1:9d44881:   public void testTopDownClustering() throws Exception {
1:9d44881:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:be94533: 
1:9d44881:     Path pointsPath = getTestTempDirPath("points");
1:921e201:     conf = getConfiguration();
1:9d44881:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
1:9d44881:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);
1:be94533: 
1:9d44881:     outputPath = getTestTempDirPath("output");
1:be94533: 
1:9d44881:     topLevelClustering(pointsPath, conf);
1:be94533: 
1:9d44881:     Map<String,Path> postProcessedClusterDirectories = ouputPostProcessing(conf);
1:be94533: 
1:9d44881:     assertPostProcessedOutput(postProcessedClusterDirectories);
1:be94533: 
1:9d44881:     bottomLevelClustering(postProcessedClusterDirectories);
1:9d44881:   }
1:be94533: 
1:9d44881:   private void assertTopLevelCluster(Entry<String,Path> cluster) {
1:9d44881:     String clusterId = cluster.getKey();
1:9d44881:     Path clusterPath = cluster.getValue();
1:be94533: 
1:9d44881:     try {
1:564c3e1:       if ("0".equals(clusterId)) {
1:9d44881:         assertPointsInFirstTopLevelCluster(clusterPath);
1:564c3e1:       } else if ("1".equals(clusterId)) {
1:9d44881:         assertPointsInSecondTopLevelCluster(clusterPath);
1:9d44881:       }
1:9d44881:     } catch (IOException e) {
1:9d44881:       Assert.fail("Exception occurred while asserting top level cluster.");
1:9d44881:     }
1:be94533: 
1:9d44881:   }
1:be94533: 
1:9d44881:   private void assertPointsInFirstTopLevelCluster(Path clusterPath) throws IOException {
1:9d44881:     List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);
1:9d44881:     for (Vector vector : vectorsInCluster) {
1:be94533:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:1.0,1:1.0}", "{0:2.0,1:1.0}", "{0:1.0,1:2.0}"},
1:9d44881:         vector.asFormatString()));
1:9d44881:     }
1:9d44881:   }
1:be94533: 
1:9d44881:   private void assertPointsInSecondTopLevelCluster(Path clusterPath) throws IOException {
1:9d44881:     List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);
1:9d44881:     for (Vector vector : vectorsInCluster) {
1:be94533:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:4.0,1:4.0}", "{0:5.0,1:4.0}", "{0:4.0,1:5.0}",
1:be94533:                                                           "{0:5.0,1:5.0}"}, vector.asFormatString()));
1:9d44881:     }
1:9d44881:   }
1:be94533: 
1:9d44881:   private List<Vector> getVectorsInCluster(Path clusterPath) throws IOException {
1:9d44881:     Path[] partFilePaths = FileUtil.stat2Paths(fs.globStatus(clusterPath));
1:9d44881:     FileStatus[] listStatus = fs.listStatus(partFilePaths);
1:210b265:     List<Vector> vectors = Lists.newArrayList();
1:9d44881:     for (FileStatus partFile : listStatus) {
1:9d44881:       SequenceFile.Reader topLevelClusterReader = new SequenceFile.Reader(fs, partFile.getPath(), conf);
1:564c3e1:       Writable clusterIdAsKey = new LongWritable();
1:9d44881:       VectorWritable point = new VectorWritable();
1:9d44881:       while (topLevelClusterReader.next(clusterIdAsKey, point)) {
1:9d44881:         vectors.add(point.get());
1:9d44881:       }
1:9d44881:     }
1:9d44881:     return vectors;
1:9d44881:   }
1:be94533: 
1:9d44881:   private void bottomLevelClustering(Map<String,Path> postProcessedClusterDirectories) throws IOException,
1:9d44881:                                                                                       InterruptedException,
1:9d44881:                                                                                       ClassNotFoundException {
1:9d44881:     for (Entry<String,Path> topLevelCluster : postProcessedClusterDirectories.entrySet()) {
1:9d44881:       String clusterId = topLevelCluster.getKey();
1:9d44881:       Path topLevelclusterPath = topLevelCluster.getValue();
1:be94533: 
1:9d44881:       Path bottomLevelCluster = PathDirectory.getBottomLevelClusterPath(outputPath, clusterId);
1:9d44881:       CanopyDriver.run(conf, topLevelclusterPath, bottomLevelCluster, new ManhattanDistanceMeasure(), 2.1,
1:f99a18f:         2.0, true, 0.0, true);
1:9d44881:       assertBottomLevelCluster(bottomLevelCluster);
1:9d44881:     }
1:9d44881:   }
1:be94533: 
1:9d44881:   private void assertBottomLevelCluster(Path bottomLevelCluster) {
1:9d44881:     Path clusteredPointsPath = new Path(bottomLevelCluster, "clusteredPoints");
1:be94533: 
1:564c3e1:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector =
1:02ff22f:         new DummyOutputCollector<>();
1:be94533: 
1:9d44881:     // The key is the clusterId, the value is the weighted vector
1:564c3e1:     for (Pair<IntWritable,WeightedVectorWritable> record :
1:564c3e1:          new SequenceFileIterable<IntWritable,WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"),
1:564c3e1:                                                                       conf)) {
1:9d44881:       collector.collect(record.getFirst(), record.getSecond());
1:9d44881:     }
1:564c3e1:     int clusterSize = collector.getKeys().size();
1:9d44881:     // First top level cluster produces two more clusters, second top level cluster is not broken again
1:564c3e1:     assertTrue(clusterSize == 1 || clusterSize == 2);
1:be94533: 
1:9d44881:   }
1:be94533: 
1:9d44881:   private void assertPostProcessedOutput(Map<String,Path> postProcessedClusterDirectories) {
1:9d44881:     for (Entry<String,Path> cluster : postProcessedClusterDirectories.entrySet()) {
1:9d44881:       assertTopLevelCluster(cluster);
1:9d44881:     }
1:9d44881:   }
1:be94533: 
1:564c3e1:   private Map<String,Path> ouputPostProcessing(Configuration conf) throws IOException {
1:9d44881:     ClusterOutputPostProcessor clusterOutputPostProcessor = new ClusterOutputPostProcessor(outputPath,
1:9d44881:         outputPath, conf);
1:9d44881:     clusterOutputPostProcessor.process();
1:9d44881:     return clusterOutputPostProcessor.getPostProcessedClusterDirectories();
1:9d44881:   }
1:be94533: 
1:9d44881:   private void topLevelClustering(Path pointsPath, Configuration conf) throws IOException,
1:9d44881:                                                                       InterruptedException,
1:9d44881:                                                                       ClassNotFoundException {
1:f99a18f:     CanopyDriver.run(conf, pointsPath, outputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, true, 0.0, true);
1:921e201:   }
1:be94533: 
1:9d44881: }
============================================================================
author:Karl Richter
-------------------------------------------------------------------------------
commit:02ff22f
/////////////////////////////////////////////////////////////////////////
1:         new DummyOutputCollector<>();
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:sslavic
-------------------------------------------------------------------------------
commit:921e201
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1:     conf = getConfiguration();
/////////////////////////////////////////////////////////////////////////
1: }
author:Robin Anil
-------------------------------------------------------------------------------
commit:be94533
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:1.0,1:1.0}", "{0:2.0,1:1.0}", "{0:1.0,1:2.0}"},
1: 
1:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{0:4.0,1:4.0}", "{0:5.0,1:4.0}", "{0:4.0,1:5.0}",
1:                                                           "{0:5.0,1:5.0}"}, vector.asFormatString()));
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
author:smarthi
-------------------------------------------------------------------------------
commit:67a531e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.commons.lang3.ArrayUtils;
author:Ted Dunning
-------------------------------------------------------------------------------
commit:402e296
/////////////////////////////////////////////////////////////////////////
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:210b265
/////////////////////////////////////////////////////////////////////////
1:     List<Vector> vectors = Lists.newArrayList();
author:pranjan
-------------------------------------------------------------------------------
commit:f99a18f
/////////////////////////////////////////////////////////////////////////
1:         2.0, true, 0.0, true);
/////////////////////////////////////////////////////////////////////////
1:     CanopyDriver.run(conf, pointsPath, outputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, true, 0.0, true);
author:Jeff Eastman
-------------------------------------------------------------------------------
commit:8d102ea
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.clustering.classify.WeightedVectorWritable;
commit:9d44881
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one
1:  * or more contributor license agreements. See the NOTICE file
1:  * distributed with this work for additional information
1:  * regarding copyright ownership. The ASF licenses this file
1:  * to you under the Apache License, Version 2.0 (the
1:  * "License"); you may not use this file except in compliance
1:  * with the License. You may obtain a copy of the License at
1:  *
1:  * http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing,
1:  * software distributed under the License is distributed on an
1:  * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:  * KIND, either express or implied. See the License for the
1:  * specific language governing permissions and limitations
1:  * under the License.
1:  */
1: 
1: package org.apache.mahout.clustering.topdown.postprocessor;
1: 
1: import java.io.IOException;
0: import java.util.ArrayList;
1: import java.util.List;
1: import java.util.Map;
1: import java.util.Map.Entry;
1: 
0: import org.apache.commons.lang.ArrayUtils;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.FileUtil;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.io.LongWritable;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.mahout.clustering.ClusteringTestUtils;
0: import org.apache.mahout.clustering.WeightedVectorWritable;
1: import org.apache.mahout.clustering.canopy.CanopyDriver;
1: import org.apache.mahout.clustering.topdown.PathDirectory;
1: import org.apache.mahout.common.DummyOutputCollector;
1: import org.apache.mahout.common.MahoutTestCase;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.distance.ManhattanDistanceMeasure;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1: import org.apache.mahout.math.RandomAccessSparseVector;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: import org.junit.Assert;
1: import org.junit.Before;
1: import org.junit.Test;
1: 
1: import com.google.common.collect.Lists;
1: 
0: public class ClusterOutputPostProcessorTest extends MahoutTestCase {
1:   
0:   public static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}};
1:   
1:   private FileSystem fs;
1:   
1:   private Path outputPath;
1:   
1:   private Configuration conf;
1:   
1:   @Override
1:   @Before
1:   public void setUp() throws Exception {
1:     super.setUp();
0:     Configuration conf = new Configuration();
1:     fs = FileSystem.get(conf);
1:   }
1:   
0:   public static List<VectorWritable> getPointsWritable(double[][] raw) {
1:     List<VectorWritable> points = Lists.newArrayList();
1:     for (double[] fr : raw) {
1:       Vector vec = new RandomAccessSparseVector(fr.length);
1:       vec.assign(fr);
1:       points.add(new VectorWritable(vec));
1:     }
1:     return points;
1:   }
1:   
1:   /**
1:    * Story: User wants to use cluster post processor after canopy clustering and then run clustering on the
1:    * output clusters
1:    */
1:   @Test
1:   public void testTopDownClustering() throws Exception {
1:     List<VectorWritable> points = getPointsWritable(REFERENCE);
1:     
1:     Path pointsPath = getTestTempDirPath("points");
0:     conf = new Configuration();
1:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file1"), fs, conf);
1:     ClusteringTestUtils.writePointsToFile(points, new Path(pointsPath, "file2"), fs, conf);
1:     
1:     outputPath = getTestTempDirPath("output");
1:     
1:     topLevelClustering(pointsPath, conf);
1:     
1:     Map<String,Path> postProcessedClusterDirectories = ouputPostProcessing(conf);
1:     
1:     assertPostProcessedOutput(postProcessedClusterDirectories);
1:     
1:     bottomLevelClustering(postProcessedClusterDirectories);
1:   }
1:   
1:   private void assertTopLevelCluster(Entry<String,Path> cluster) {
1:     String clusterId = cluster.getKey();
1:     Path clusterPath = cluster.getValue();
1:     
1:     try {
0:       if (clusterId.equals("0")) {
1:         assertPointsInFirstTopLevelCluster(clusterPath);
0:       } else if (clusterId.equals("1")) {
1:         assertPointsInSecondTopLevelCluster(clusterPath);
1:       }
1:     } catch (IOException e) {
1:       Assert.fail("Exception occurred while asserting top level cluster.");
1:     }
1:     
1:   }
1:   
1:   private void assertPointsInFirstTopLevelCluster(Path clusterPath) throws IOException {
1:     List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);
1:     for (Vector vector : vectorsInCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:1.0,0:1.0}", "{1:1.0,0:2.0}", "{1:2.0,0:1.0}"},
1:         vector.asFormatString()));
1:     }
1:   }
1:   
1:   private void assertPointsInSecondTopLevelCluster(Path clusterPath) throws IOException {
1:     List<Vector> vectorsInCluster = getVectorsInCluster(clusterPath);
1:     for (Vector vector : vectorsInCluster) {
0:       Assert.assertTrue(ArrayUtils.contains(new String[] {"{1:4.0,0:4.0}", "{1:4.0,0:5.0}", "{1:5.0,0:4.0}",
0:                                                           "{1:5.0,0:5.0}"}, vector.asFormatString()));
1:     }
1:   }
1:   
1:   private List<Vector> getVectorsInCluster(Path clusterPath) throws IOException {
1:     Path[] partFilePaths = FileUtil.stat2Paths(fs.globStatus(clusterPath));
1:     FileStatus[] listStatus = fs.listStatus(partFilePaths);
0:     List<Vector> vectors = new ArrayList<Vector>();
1:     for (FileStatus partFile : listStatus) {
1:       SequenceFile.Reader topLevelClusterReader = new SequenceFile.Reader(fs, partFile.getPath(), conf);
0:       LongWritable clusterIdAsKey = new LongWritable();
1:       VectorWritable point = new VectorWritable();
1:       while (topLevelClusterReader.next(clusterIdAsKey, point)) {
1:         vectors.add(point.get());
1:       }
1:     }
1:     return vectors;
1:   }
1:   
1:   private void bottomLevelClustering(Map<String,Path> postProcessedClusterDirectories) throws IOException,
1:                                                                                       InterruptedException,
1:                                                                                       ClassNotFoundException {
1:     for (Entry<String,Path> topLevelCluster : postProcessedClusterDirectories.entrySet()) {
1:       String clusterId = topLevelCluster.getKey();
1:       Path topLevelclusterPath = topLevelCluster.getValue();
1:       
1:       Path bottomLevelCluster = PathDirectory.getBottomLevelClusterPath(outputPath, clusterId);
1:       CanopyDriver.run(conf, topLevelclusterPath, bottomLevelCluster, new ManhattanDistanceMeasure(), 2.1,
0:         2.0, true, true);
1:       assertBottomLevelCluster(bottomLevelCluster);
1:     }
1:   }
1:   
1:   private void assertBottomLevelCluster(Path bottomLevelCluster) {
1:     Path clusteredPointsPath = new Path(bottomLevelCluster, "clusteredPoints");
1:     
0:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector = new DummyOutputCollector<IntWritable,WeightedVectorWritable>();
1:     
1:     // The key is the clusterId, the value is the weighted vector
0:     for (Pair<IntWritable,WeightedVectorWritable> record : new SequenceFileIterable<IntWritable,WeightedVectorWritable>(
0:         new Path(clusteredPointsPath, "part-m-0"), conf)) {
1:       collector.collect(record.getFirst(), record.getSecond());
1:     }
0:     final int clusterSize = collector.getKeys().size();
1:     // First top level cluster produces two more clusters, second top level cluster is not broken again
0:     Assert.assertTrue(clusterSize == 1 || clusterSize == 2);
1:     
1:   }
1:   
1:   private void assertPostProcessedOutput(Map<String,Path> postProcessedClusterDirectories) {
1:     for (Entry<String,Path> cluster : postProcessedClusterDirectories.entrySet()) {
1:       assertTopLevelCluster(cluster);
1:     }
1:   }
1:   
0:   private Map<String,Path> ouputPostProcessing(Configuration conf) throws IOException,
0:                                                                   InstantiationException, IllegalAccessException {
1:     ClusterOutputPostProcessor clusterOutputPostProcessor = new ClusterOutputPostProcessor(outputPath,
1:         outputPath, conf);
1:     clusterOutputPostProcessor.process();
1:     return clusterOutputPostProcessor.getPostProcessedClusterDirectories();
1:   }
1:   
1:   private void topLevelClustering(Path pointsPath, Configuration conf) throws IOException,
1:                                                                       InterruptedException,
1:                                                                       ClassNotFoundException {
0:     CanopyDriver.run(conf, pointsPath, outputPath, new ManhattanDistanceMeasure(), 3.1, 2.1, true, true);
1:   }
1:   
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:051cbcf
/////////////////////////////////////////////////////////////////////////
1: public final class ClusterOutputPostProcessorTest extends MahoutTestCase {
1:   private static final double[][] REFERENCE = { {1, 1}, {2, 1}, {1, 2}, {4, 4}, {5, 4}, {4, 5}, {5, 5}};
/////////////////////////////////////////////////////////////////////////
1:   private static List<VectorWritable> getPointsWritable(double[][] raw) {
commit:564c3e1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.io.Writable;
/////////////////////////////////////////////////////////////////////////
1:       if ("0".equals(clusterId)) {
1:       } else if ("1".equals(clusterId)) {
/////////////////////////////////////////////////////////////////////////
1:       Writable clusterIdAsKey = new LongWritable();
/////////////////////////////////////////////////////////////////////////
1:     DummyOutputCollector<IntWritable,WeightedVectorWritable> collector =
0:         new DummyOutputCollector<IntWritable,WeightedVectorWritable>();
1:     for (Pair<IntWritable,WeightedVectorWritable> record :
1:          new SequenceFileIterable<IntWritable,WeightedVectorWritable>(new Path(clusteredPointsPath, "part-m-0"),
1:                                                                       conf)) {
1:     int clusterSize = collector.getKeys().size();
1:     assertTrue(clusterSize == 1 || clusterSize == 2);
/////////////////////////////////////////////////////////////////////////
1:   private Map<String,Path> ouputPostProcessing(Configuration conf) throws IOException {
============================================================================
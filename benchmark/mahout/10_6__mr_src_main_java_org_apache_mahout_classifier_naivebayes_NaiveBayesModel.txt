4:515a414: /**
1:515a414:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:515a414:  * contributor license agreements.  See the NOTICE file distributed with
1:515a414:  * this work for additional information regarding copyright ownership.
1:515a414:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:515a414:  * (the "License"); you may not use this file except in compliance with
1:515a414:  * the License.  You may obtain a copy of the License at
5:515a414:  *
1:515a414:  *     http://www.apache.org/licenses/LICENSE-2.0
1:515a414:  *
1:515a414:  * Unless required by applicable law or agreed to in writing, software
1:515a414:  * distributed under the License is distributed on an "AS IS" BASIS,
1:515a414:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:515a414:  * See the License for the specific language governing permissions and
1:515a414:  * limitations under the License.
4:515a414:  */
41:515a414: 
1:515a414: package org.apache.mahout.classifier.naivebayes;
1:515a414: 
1:e3fb0c4: import java.io.IOException;
1:d8d721a: 
1:515a414: import org.apache.hadoop.conf.Configuration;
1:e3fb0c4: import org.apache.hadoop.fs.FSDataInputStream;
1:e3fb0c4: import org.apache.hadoop.fs.FSDataOutputStream;
1:e3fb0c4: import org.apache.hadoop.fs.FileSystem;
1:515a414: import org.apache.hadoop.fs.Path;
1:d8d721a: import org.apache.mahout.math.DenseVector;
1:515a414: import org.apache.mahout.math.Matrix;
1:d8d721a: import org.apache.mahout.math.SparseRowMatrix;
1:515a414: import org.apache.mahout.math.Vector;
1:515a414: import org.apache.mahout.math.VectorWritable;
1:515a414: 
1:96024a7: import com.google.common.base.Preconditions;
1:e3fb0c4: 
1:94b08db: /** NaiveBayesModel holds the weight matrix, the feature and label sums and the weight normalizer vectors.*/
1:35032b8: public class NaiveBayesModel {
1:e3fb0c4: 
1:b59e468:   private final Vector weightsPerLabel;
1:b59e468:   private final Vector perlabelThetaNormalizer;
1:b59e468:   private final Vector weightsPerFeature;
1:b59e468:   private final Matrix weightsPerLabelAndFeature;
1:b59e468:   private final float alphaI;
1:b59e468:   private final double numFeatures;
1:b59e468:   private final double totalWeightSum;
1:9a5bab5:   private final boolean isComplementary;  
1:9a5bab5:    
1:9a5bab5:   public final static String COMPLEMENTARY_MODEL = "COMPLEMENTARY_MODEL";
1:515a414: 
1:9a5bab5:   public NaiveBayesModel(Matrix weightMatrix, Vector weightsPerFeature, Vector weightsPerLabel, Vector thetaNormalizer,
1:9a5bab5:                          float alphaI, boolean isComplementary) {
1:e3fb0c4:     this.weightsPerLabelAndFeature = weightMatrix;
1:e3fb0c4:     this.weightsPerFeature = weightsPerFeature;
1:e3fb0c4:     this.weightsPerLabel = weightsPerLabel;
1:515a414:     this.perlabelThetaNormalizer = thetaNormalizer;
1:e3fb0c4:     this.numFeatures = weightsPerFeature.getNumNondefaultElements();
1:e3fb0c4:     this.totalWeightSum = weightsPerLabel.zSum();
2:515a414:     this.alphaI = alphaI;
1:9a5bab5:     this.isComplementary=isComplementary;
25:515a414:   }
1:515a414: 
1:e3fb0c4:   public double labelWeight(int label) {
1:e3fb0c4:     return weightsPerLabel.getQuick(label);
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public double thetaNormalizer(int label) {
1:e3fb0c4:     return perlabelThetaNormalizer.get(label); 
1:fa29726:   }
1:515a414: 
1:e3fb0c4:   public double featureWeight(int feature) {
1:e3fb0c4:     return weightsPerFeature.getQuick(feature);
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public double weight(int label, int feature) {
1:e3fb0c4:     return weightsPerLabelAndFeature.getQuick(label, feature);
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public float alphaI() {
1:515a414:     return alphaI;
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public double numFeatures() {
1:e3fb0c4:     return numFeatures;
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public double totalWeightSum() {
1:e3fb0c4:     return totalWeightSum;
1:515a414:   }
1:515a414:   
1:e3fb0c4:   public int numLabels() {
1:e3fb0c4:     return weightsPerLabel.size();
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public Vector createScoringVector() {
1:e3fb0c4:     return weightsPerLabel.like();
1:515a414:   }
1:9a5bab5:   
1:9a5bab5:   public boolean isComplemtary(){
1:9a5bab5:       return isComplementary;
1:9a5bab5:   }
1:9a5bab5:   
1:e3fb0c4:   public static NaiveBayesModel materialize(Path output, Configuration conf) throws IOException {
1:e3fb0c4:     FileSystem fs = output.getFileSystem(conf);
1:e3fb0c4: 
1:85f9ece:     Vector weightsPerLabel;
1:e3fb0c4:     Vector perLabelThetaNormalizer = null;
1:85f9ece:     Vector weightsPerFeature;
1:e3fb0c4:     Matrix weightsPerLabelAndFeature;
1:e3fb0c4:     float alphaI;
1:9a5bab5:     boolean isComplementary;
1:e3fb0c4: 
1:85f9ece:     try (FSDataInputStream in = fs.open(new Path(output, "naiveBayesModel.bin"))) {
1:e3fb0c4:       alphaI = in.readFloat();
1:9a5bab5:       isComplementary = in.readBoolean();
1:e3fb0c4:       weightsPerFeature = VectorWritable.readVector(in);
1:d8d721a:       weightsPerLabel = new DenseVector(VectorWritable.readVector(in));
1:9a5bab5:       if (isComplementary){
1:9a5bab5:         perLabelThetaNormalizer = new DenseVector(VectorWritable.readVector(in));
1:9a5bab5:       }
1:6d16230:       weightsPerLabelAndFeature = new SparseRowMatrix(weightsPerLabel.size(), weightsPerFeature.size());
1:e3fb0c4:       for (int label = 0; label < weightsPerLabelAndFeature.numRows(); label++) {
1:e3fb0c4:         weightsPerLabelAndFeature.assignRow(label, VectorWritable.readVector(in));
1:515a414:       }
1:515a414:     }
1:85f9ece: 
1:e3fb0c4:     NaiveBayesModel model = new NaiveBayesModel(weightsPerLabelAndFeature, weightsPerFeature, weightsPerLabel,
1:9a5bab5:         perLabelThetaNormalizer, alphaI, isComplementary);
1:e3fb0c4:     model.validate();
2:515a414:     return model;
1:515a414:   }
1:515a414: 
1:e3fb0c4:   public void serialize(Path output, Configuration conf) throws IOException {
1:e3fb0c4:     FileSystem fs = output.getFileSystem(conf);
1:85f9ece:     try (FSDataOutputStream out = fs.create(new Path(output, "naiveBayesModel.bin"))) {
1:e3fb0c4:       out.writeFloat(alphaI);
1:9a5bab5:       out.writeBoolean(isComplementary);
1:e3fb0c4:       VectorWritable.writeVector(out, weightsPerFeature);
1:9a5bab5:       VectorWritable.writeVector(out, weightsPerLabel); 
1:9a5bab5:       if (isComplementary){
1:9a5bab5:         VectorWritable.writeVector(out, perlabelThetaNormalizer);
1:9a5bab5:       }
1:e3fb0c4:       for (int row = 0; row < weightsPerLabelAndFeature.numRows(); row++) {
1:528ffcd:         VectorWritable.writeVector(out, weightsPerLabelAndFeature.viewRow(row));
1:e3fb0c4:       }
1:e3fb0c4:     }
1:e3fb0c4:   }
1:e3fb0c4:   
1:e3fb0c4:   public void validate() {
1:e3fb0c4:     Preconditions.checkState(alphaI > 0, "alphaI has to be greater than 0!");
1:e3fb0c4:     Preconditions.checkArgument(numFeatures > 0, "the vocab count has to be greater than 0!");
1:e3fb0c4:     Preconditions.checkArgument(totalWeightSum > 0, "the totalWeightSum has to be greater than 0!");
1:210b265:     Preconditions.checkNotNull(weightsPerLabel, "the number of labels has to be defined!");
1:e3fb0c4:     Preconditions.checkArgument(weightsPerLabel.getNumNondefaultElements() > 0,
1:e3fb0c4:         "the number of labels has to be greater than 0!");
1:210b265:     Preconditions.checkNotNull(weightsPerFeature, "the feature sums have to be defined");
1:e3fb0c4:     Preconditions.checkArgument(weightsPerFeature.getNumNondefaultElements() > 0,
1:e3fb0c4:         "the feature sums have to be greater than 0!");
1:9a5bab5:     if (isComplementary){
1:9a5bab5:         Preconditions.checkArgument(perlabelThetaNormalizer != null, "the theta normalizers have to be defined");
1:9a5bab5:         Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0,
1:9a5bab5:             "the number of theta normalizers has to be greater than 0!");    
1:9a5bab5:         Preconditions.checkArgument(Math.signum(perlabelThetaNormalizer.minValue()) 
1:9a5bab5:                 == Math.signum(perlabelThetaNormalizer.maxValue()), 
1:9a5bab5:            "Theta normalizers do not all have the same sign");            
1:9a5bab5:         Preconditions.checkArgument(perlabelThetaNormalizer.getNumNonZeroElements() 
1:9a5bab5:                 == perlabelThetaNormalizer.size(), 
1:9a5bab5:            "Theta normalizers can not have zero value.");
1:9a5bab5:     }
1:fa29726:     
1:515a414:   }
1:515a414: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     Vector weightsPerLabel;
1:     Vector weightsPerFeature;
1:     try (FSDataInputStream in = fs.open(new Path(output, "naiveBayesModel.bin"))) {
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     try (FSDataOutputStream out = fs.create(new Path(output, "naiveBayesModel.bin"))) {
/////////////////////////////////////////////////////////////////////////
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:9a5bab5
/////////////////////////////////////////////////////////////////////////
1:   private final boolean isComplementary;  
1:    
1:   public final static String COMPLEMENTARY_MODEL = "COMPLEMENTARY_MODEL";
1:   public NaiveBayesModel(Matrix weightMatrix, Vector weightsPerFeature, Vector weightsPerLabel, Vector thetaNormalizer,
1:                          float alphaI, boolean isComplementary) {
/////////////////////////////////////////////////////////////////////////
1:     this.isComplementary=isComplementary;
/////////////////////////////////////////////////////////////////////////
1:   
1:   public boolean isComplemtary(){
1:       return isComplementary;
1:   }
1:   
/////////////////////////////////////////////////////////////////////////
1:     boolean isComplementary;
1:       isComplementary = in.readBoolean();
1:       if (isComplementary){
1:         perLabelThetaNormalizer = new DenseVector(VectorWritable.readVector(in));
1:       }
/////////////////////////////////////////////////////////////////////////
1:         perLabelThetaNormalizer, alphaI, isComplementary);
/////////////////////////////////////////////////////////////////////////
1:       out.writeBoolean(isComplementary);
1:       VectorWritable.writeVector(out, weightsPerLabel); 
1:       if (isComplementary){
1:         VectorWritable.writeVector(out, perlabelThetaNormalizer);
1:       }
/////////////////////////////////////////////////////////////////////////
1:     if (isComplementary){
1:         Preconditions.checkArgument(perlabelThetaNormalizer != null, "the theta normalizers have to be defined");
1:         Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0,
1:             "the number of theta normalizers has to be greater than 0!");    
1:         Preconditions.checkArgument(Math.signum(perlabelThetaNormalizer.minValue()) 
1:                 == Math.signum(perlabelThetaNormalizer.maxValue()), 
1:            "Theta normalizers do not all have the same sign");            
1:         Preconditions.checkArgument(perlabelThetaNormalizer.getNumNonZeroElements() 
1:                 == perlabelThetaNormalizer.size(), 
1:            "Theta normalizers can not have zero value.");
1:     }
commit:94b08db
/////////////////////////////////////////////////////////////////////////
1: /** NaiveBayesModel holds the weight matrix, the feature and label sums and the weight normalizer vectors.*/
/////////////////////////////////////////////////////////////////////////
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:       weightsPerLabelAndFeature = new SparseRowMatrix(weightsPerLabel.size(), weightsPerFeature.size());
commit:210b265
/////////////////////////////////////////////////////////////////////////
0:   //  private final double minThetaNormalizer;
/////////////////////////////////////////////////////////////////////////
0: //    this.minThetaNormalizer = thetaNormalizer.maxValue();
0: //  public double thetaNormalizer(int label) {
0: //    return perlabelThetaNormalizer.get(label) / minThetaNormalizer;
0: //  }
/////////////////////////////////////////////////////////////////////////
1:     Preconditions.checkNotNull(weightsPerLabel, "the number of labels has to be defined!");
1:     Preconditions.checkNotNull(weightsPerFeature, "the feature sums have to be defined");
commit:e3fb0c4
/////////////////////////////////////////////////////////////////////////
0: import com.google.common.io.Closeables;
1: import org.apache.hadoop.fs.FSDataInputStream;
1: import org.apache.hadoop.fs.FSDataOutputStream;
1: import org.apache.hadoop.fs.FileSystem;
1: import java.io.IOException;
1: 
0: /** NaiveBayesModel holds the weight Matrix, the feature and label sums and the weight normalizer vectors.*/
0:   private Vector weightsPerLabel;
0:   private Vector weightsPerFeature;
0:   private Matrix weightsPerLabelAndFeature;
0:   private double numFeatures;
0:   private double totalWeightSum;
1: 
0:   public NaiveBayesModel(Matrix weightMatrix, Vector weightsPerFeature, Vector weightsPerLabel, Vector thetaNormalizer,
0:       float alphaI) {
1:     this.weightsPerLabelAndFeature = weightMatrix;
1:     this.weightsPerFeature = weightsPerFeature;
1:     this.weightsPerLabel = weightsPerLabel;
1:     this.numFeatures = weightsPerFeature.getNumNondefaultElements();
1:     this.totalWeightSum = weightsPerLabel.zSum();
1:   public double labelWeight(int label) {
1:     return weightsPerLabel.getQuick(label);
1:   public double thetaNormalizer(int label) {
1:     return perlabelThetaNormalizer.get(label);
1:   public double featureWeight(int feature) {
1:     return weightsPerFeature.getQuick(feature);
1:   public double weight(int label, int feature) {
1:     return weightsPerLabelAndFeature.getQuick(label, feature);
1:   public float alphaI() {
1:   public double numFeatures() {
1:     return numFeatures;
1:   public double totalWeightSum() {
1:     return totalWeightSum;
1:   public int numLabels() {
1:     return weightsPerLabel.size();
1:   public Vector createScoringVector() {
1:     return weightsPerLabel.like();
1:   public static NaiveBayesModel materialize(Path output, Configuration conf) throws IOException {
1:     FileSystem fs = output.getFileSystem(conf);
0:     Vector weightsPerLabel = null;
1:     Vector perLabelThetaNormalizer = null;
0:     Vector weightsPerFeature = null;
1:     Matrix weightsPerLabelAndFeature;
1:     float alphaI;
1: 
0:     FSDataInputStream in = fs.open(new Path(output, "naiveBayesModel.bin"));
0:     try {
1:       alphaI = in.readFloat();
1:       weightsPerFeature = VectorWritable.readVector(in);
0:       weightsPerLabel = VectorWritable.readVector(in);
0:       perLabelThetaNormalizer = VectorWritable.readVector(in);
1: 
0:       weightsPerLabelAndFeature = new SparseMatrix(new int[] { weightsPerLabel.size(), weightsPerFeature.size() });
1:       for (int label = 0; label < weightsPerLabelAndFeature.numRows(); label++) {
1:         weightsPerLabelAndFeature.assignRow(label, VectorWritable.readVector(in));
0:     } finally {
0:       Closeables.closeQuietly(in);
1:     NaiveBayesModel model = new NaiveBayesModel(weightsPerLabelAndFeature, weightsPerFeature, weightsPerLabel,
0:         perLabelThetaNormalizer, alphaI);
1:     model.validate();
1:   public void serialize(Path output, Configuration conf) throws IOException {
1:     FileSystem fs = output.getFileSystem(conf);
0:     FSDataOutputStream out = fs.create(new Path(output, "naiveBayesModel.bin"));
0:     try {
1:       out.writeFloat(alphaI);
1:       VectorWritable.writeVector(out, weightsPerFeature);
0:       VectorWritable.writeVector(out, weightsPerLabel);
0:       VectorWritable.writeVector(out, perlabelThetaNormalizer);
1:       for (int row = 0; row < weightsPerLabelAndFeature.numRows(); row++) {
0:         VectorWritable.writeVector(out, weightsPerLabelAndFeature.getRow(row));
1:       }
0:     } finally {
0:       Closeables.closeQuietly(out);
1:     }
1:   }
1:   
1:   public void validate() {
1:     Preconditions.checkState(alphaI > 0, "alphaI has to be greater than 0!");
1:     Preconditions.checkArgument(numFeatures > 0, "the vocab count has to be greater than 0!");
1:     Preconditions.checkArgument(totalWeightSum > 0, "the totalWeightSum has to be greater than 0!");
0:     Preconditions.checkArgument(weightsPerLabel != null, "the number of labels has to be defined!");
1:     Preconditions.checkArgument(weightsPerLabel.getNumNondefaultElements() > 0,
1:         "the number of labels has to be greater than 0!");
0:     Preconditions.checkArgument(perlabelThetaNormalizer != null, "the theta normalizers have to be defined");
0:     Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0,
0:         "the number of theta normalizers has to be greater than 0!");
0:     Preconditions.checkArgument(weightsPerFeature != null, "the feature sums have to be defined");
1:     Preconditions.checkArgument(weightsPerFeature.getNumNondefaultElements() > 0,
1:         "the feature sums have to be greater than 0!");
commit:96024a7
/////////////////////////////////////////////////////////////////////////
1: import com.google.common.base.Preconditions;
/////////////////////////////////////////////////////////////////////////
0:     Preconditions.checkArgument(model.getAlphaI() > 0, "Error: AlphaI has to be greater than 0!");
0:     Preconditions.checkArgument(model.getVocabCount() > 0, "Error: The vocab count has to be greater than 0!");
0:     Preconditions.checkArgument(model.getTotalSum() > 0, "Error: The vocab count has to be greater than 0!");
0:     Preconditions.checkArgument(model.getLabelSum() != null && model.getLabelSum().getNumNondefaultElements() > 0,
0:         "Error: The number of labels has to be greater than 0 and defined!");
0:     Preconditions.checkArgument(model.getPerlabelThetaNormalizer() != null &&
0:         model.getPerlabelThetaNormalizer().getNumNondefaultElements() > 0,
0:         "Error: The number of theta normalizers has to be greater than 0 or defined!");
0:     Preconditions.checkArgument(model.getFeatureSum() != null && model.getFeatureSum().getNumNondefaultElements() > 0,
0:         "Error: The number of features has to be greater than 0 or defined!");
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:smarthi
-------------------------------------------------------------------------------
commit:fa29726
/////////////////////////////////////////////////////////////////////////
0:   public double thetaNormalizer(int label) {
0:     return perlabelThetaNormalizer.get(label); 
1:   }
/////////////////////////////////////////////////////////////////////////
0:     Preconditions.checkArgument(perlabelThetaNormalizer != null, "the theta normalizers have to be defined");
0:     Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0,
0:         "the number of theta normalizers has to be greater than 0!");    
0:     Preconditions.checkArgument(Math.signum(perlabelThetaNormalizer.minValue()) 
0:             == Math.signum(perlabelThetaNormalizer.maxValue()), 
0:        "Theta normalizers do not all have the same sign");            
0:     Preconditions.checkArgument(perlabelThetaNormalizer.getNumNonZeroElements() 
0:             == perlabelThetaNormalizer.size(), 
0:        "Theta normalizers can not have zero value.");
1:     
author:dfilimon
-------------------------------------------------------------------------------
commit:87d4b2e
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(out, false);
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(in, true);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(out, true);
author:Robin Anil
-------------------------------------------------------------------------------
commit:d94eb39
/////////////////////////////////////////////////////////////////////////
0:   private final double minThetaNormalizer;
/////////////////////////////////////////////////////////////////////////
0:     this.minThetaNormalizer = thetaNormalizer.maxValue();
/////////////////////////////////////////////////////////////////////////
0:     return perlabelThetaNormalizer.get(label) / minThetaNormalizer;
/////////////////////////////////////////////////////////////////////////
0:     // Preconditions.checkArgument(perlabelThetaNormalizer.getNumNondefaultElements() > 0,
0:     //    "the number of theta normalizers has to be greater than 0!");
0:     // Check if all thetas have same sign.
0:     /*Iterator<Element> it = perlabelThetaNormalizer.iterateNonZero();
0:     while (it.hasNext()) {
0:       Element e = it.next();
0:       Preconditions.checkArgument(Math.signum(e.get()) == Math.signum(minThetaNormalizer), e.get()
0:           + "  " + minThetaNormalizer);
0:     }*/
commit:d8d721a
/////////////////////////////////////////////////////////////////////////
0: import java.io.IOException;
1: 
1: import org.apache.mahout.math.DenseVector;
1: import org.apache.mahout.math.SparseRowMatrix;
0: import com.google.common.base.Preconditions;
0: import com.google.common.io.Closeables;
/////////////////////////////////////////////////////////////////////////
1:       weightsPerLabel = new DenseVector(VectorWritable.readVector(in));
0:       perLabelThetaNormalizer = new DenseVector(VectorWritable.readVector(in));
0:       weightsPerLabelAndFeature = new SparseRowMatrix(weightsPerLabel.size(), weightsPerFeature.size() );
commit:515a414
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.classifier.naivebayes;
1: 
0: import java.io.IOException;
0: import java.lang.reflect.Type;
1: 
1: import org.apache.hadoop.conf.Configuration;
0: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.io.IntWritable;
0: import org.apache.hadoop.io.SequenceFile;
0: import org.apache.hadoop.io.Text;
0: import org.apache.mahout.classifier.naivebayes.trainer.NaiveBayesTrainer;
0: import org.apache.mahout.math.JsonMatrixAdapter;
0: import org.apache.mahout.math.JsonVectorAdapter;
1: import org.apache.mahout.math.Matrix;
0: import org.apache.mahout.math.SparseMatrix;
1: import org.apache.mahout.math.Vector;
1: import org.apache.mahout.math.VectorWritable;
1: 
0: import com.google.gson.Gson;
0: import com.google.gson.GsonBuilder;
0: import com.google.gson.JsonDeserializationContext;
0: import com.google.gson.JsonDeserializer;
0: import com.google.gson.JsonElement;
0: import com.google.gson.JsonObject;
0: import com.google.gson.JsonParseException;
0: import com.google.gson.JsonPrimitive;
0: import com.google.gson.JsonSerializationContext;
0: import com.google.gson.JsonSerializer;
1: 
1: /**
1:  * 
0:  * NaiveBayesModel holds the weight Matrix, the feature and label sums and the weight normalizer vectors.
1:  *
1:  */
0: public class NaiveBayesModel implements JsonDeserializer<NaiveBayesModel>, JsonSerializer<NaiveBayesModel>, Cloneable {
1:  
0:   private Vector labelSum;
0:   private Vector perlabelThetaNormalizer;
0:   private Vector featureSum;
0:   private Matrix weightMatrix;
0:   private float alphaI;
0:   private double vocabCount;
0:   private double totalSum;
1:   
0:   private NaiveBayesModel() { 
0:     // do nothing
1:   }
1:   
0:   public NaiveBayesModel(Matrix matrix, Vector featureSum, Vector labelSum, Vector thetaNormalizer, float alphaI) {
0:     this.weightMatrix = matrix;
0:     this.featureSum = featureSum;
0:     this.labelSum = labelSum;
1:     this.perlabelThetaNormalizer = thetaNormalizer;
0:     this.vocabCount = featureSum.getNumNondefaultElements();
0:     this.totalSum = labelSum.zSum();
1:     this.alphaI = alphaI;
1:   }
1: 
0:   private void setLabelSum(Vector labelSum) {
0:     this.labelSum = labelSum;
1:   }
1: 
1: 
0:   public void setPerlabelThetaNormalizer(Vector perlabelThetaNormalizer) {
0:     this.perlabelThetaNormalizer = perlabelThetaNormalizer;
1:   }
1: 
1: 
0:   public void setFeatureSum(Vector featureSum) {
0:     this.featureSum = featureSum;
1:   }
1: 
1: 
0:   public void setWeightMatrix(Matrix weightMatrix) {
0:     this.weightMatrix = weightMatrix;
1:   }
1: 
1: 
0:   public void setAlphaI(float alphaI) {
1:     this.alphaI = alphaI;
1:   }
1: 
1: 
0:   public void setVocabCount(double vocabCount) {
0:     this.vocabCount = vocabCount;
1:   }
1: 
1: 
0:   public void setTotalSum(double totalSum) {
0:     this.totalSum = totalSum;
1:   }
1:   
0:   public Vector getLabelSum() {
0:     return labelSum;
1:   }
1: 
0:   public Vector getPerlabelThetaNormalizer() {
0:     return perlabelThetaNormalizer;
1:   }
1: 
0:   public Vector getFeatureSum() {
0:     return featureSum;
1:   }
1: 
0:   public Matrix getWeightMatrix() {
0:     return weightMatrix;
1:   }
1: 
0:   public float getAlphaI() {
1:     return alphaI;
1:   }
1: 
0:   public double getVocabCount() {
0:     return vocabCount;
1:   }
1: 
0:   public double getTotalSum() {
0:     return totalSum;
1:   }
1:   
0:   public int getNumLabels() {
0:     return labelSum.size();
1:   }
1: 
0:   public static String getModelName() {
0:     return MODEL;
1:   }
1:   
0:   // CODE USED FOR SERIALIZATION
0:   public static NaiveBayesModel fromMRTrainerOutput(Path output, Configuration conf) throws IOException {
0:     Path classVectorPath = new Path(output, NaiveBayesTrainer.CLASS_VECTORS);
0:     Path sumVectorPath = new Path(output, NaiveBayesTrainer.SUM_VECTORS);
0:     Path thetaSumPath = new Path(output, NaiveBayesTrainer.THETA_SUM);
1: 
0:     NaiveBayesModel model = new NaiveBayesModel();
0:     model.setAlphaI(conf.getFloat(NaiveBayesTrainer.ALPHA_I, 1.0f));
1:     
0:     FileSystem fs = sumVectorPath.getFileSystem(conf);
0:     SequenceFile.Reader reader = new SequenceFile.Reader(fs, sumVectorPath, conf);
0:     Text key = new Text();
0:     VectorWritable value = new VectorWritable();
1: 
0:     int featureCount = 0;
0:     int labelCount = 0;
0:     // read feature sums and label sums
0:     while (reader.next(key, value)) {
0:       if (key.toString().equals(BayesConstants.FEATURE_SUM)) {
0:         model.setFeatureSum(value.get());
0:         featureCount = value.get().getNumNondefaultElements();
0:         model.setVocabCount(featureCount);       
0:       } else  if (key.toString().equals(BayesConstants.LABEL_SUM)) {
0:         model.setLabelSum(value.get());
0:         model.setTotalSum(value.get().zSum());
0:         labelCount = value.get().size();
1:       }
1:     }
0:     reader.close();
1:     
0:     // read the class matrix
0:     reader = new SequenceFile.Reader(fs, classVectorPath, conf);
0:     IntWritable label = new IntWritable();
0:     Matrix matrix = new SparseMatrix(new int[] {labelCount, featureCount});
0:     while (reader.next(label, value)) {
0:       matrix.assignRow(label.get(), value.get());
1:     }
0:     reader.close();
1:     
0:     model.setWeightMatrix(matrix);
1:    
1:     
1:     
0:     reader = new SequenceFile.Reader(fs, thetaSumPath, conf);
0:     // read theta normalizer
0:     while (reader.next(key, value)) {
0:       if (key.toString().equals(BayesConstants.LABEL_THETA_NORMALIZER)) {
0:         model.setPerlabelThetaNormalizer(value.get());
1:       }
1:     }
0:     reader.close();
1:     
1:     return model;
1:   }
1:   
1:   /**
0:    * Encode this NaiveBayesModel as a JSON string
1:    *
0:    * @return String containing the JSON of this model
1:    */
0:   public String toJson() {
0:     GsonBuilder builder = new GsonBuilder();
0:     builder.registerTypeAdapter(NaiveBayesModel.class, this);
0:     Gson gson = builder.create();
0:     return gson.toJson(this);
1:   }
1: 
1:   /**
0:    * Decode this NaiveBayesModel from a JSON string
1:    *
0:    * @param json String containing JSON representation of this model
0:    * @return Initialized model
1:    */
0:   public static NaiveBayesModel fromJson(String json) {
0:     GsonBuilder builder = new GsonBuilder();
0:     builder.registerTypeAdapter(NaiveBayesModel.class, new NaiveBayesModel());
0:     Gson gson = builder.create();
0:     return gson.fromJson(json, NaiveBayesModel.class);
1:   }
1:    
0:   private static final String MODEL = "NaiveBayesModel";
1: 
0:   @Override
0:   public JsonElement serialize(NaiveBayesModel model,
0:                                Type type,
0:                                JsonSerializationContext context) {
0:     // now register the builders for matrix / vector
0:     GsonBuilder builder = new GsonBuilder();
0:     builder.registerTypeAdapter(Matrix.class, new JsonMatrixAdapter());
0:     builder.registerTypeAdapter(Vector.class, new JsonVectorAdapter());
0:     Gson gson = builder.create();
0:     // create a model
0:     JsonObject json = new JsonObject();
0:     // first, we add the model
0:     json.add(MODEL, new JsonPrimitive(gson.toJson(model)));
0:     return json;
1:   }
1: 
0:   @Override
0:   public NaiveBayesModel deserialize(JsonElement json,
0:                                      Type type,
0:                                      JsonDeserializationContext context) throws JsonParseException {
0:     // register the builders for matrix / vector
0:     GsonBuilder builder = new GsonBuilder();
0:     builder.registerTypeAdapter(Matrix.class, new JsonMatrixAdapter());
0:     builder.registerTypeAdapter(Vector.class, new JsonVectorAdapter());
0:     Gson gson = builder.create();
0:     // now decode the original model
0:     JsonObject obj = json.getAsJsonObject();
0:     String modelString = obj.get(MODEL).getAsString();
0:     NaiveBayesModel model = gson.fromJson(modelString, NaiveBayesModel.class);
1:    
0:     // return the model
1:     return model;
1:   }
1:   
0:   public static void validate(NaiveBayesModel model) {
0:     if (model == null) {
0:       return; // empty models are valid
1:     }
1: 
0:     if (model.getAlphaI() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: AlphaI has to be greater than 0!");
1:     }
1: 
0:     if (model.getVocabCount() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The vocab count has to be greater than 0!");
1:     }
1: 
0:     if (model.getVocabCount() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The vocab count has to be greater than 0!");
1:     }
1:     
0:     if (model.getTotalSum() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The vocab count has to be greater than 0!");
1:     }    
1: 
0:     if (model.getLabelSum() == null || model.getLabelSum().getNumNondefaultElements() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The number of labels has to be greater than 0 or defined!");
1:     }  
1:     
0:     if (model.getPerlabelThetaNormalizer() == null ||
0:         model.getPerlabelThetaNormalizer().getNumNondefaultElements() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The number of theta normalizers has to be greater than 0 or defined!");
1:     }
1:     
0:     if (model.getFeatureSum() == null ||model.getFeatureSum().getNumNondefaultElements() <= 0) {
0:       throw new IllegalArgumentException(
0:           "Error: The number of features has to be greater than 0 or defined!");
1:     }
1:   }
1: }
author:Ted Dunning
-------------------------------------------------------------------------------
commit:95f836b
/////////////////////////////////////////////////////////////////////////
0:       weightsPerLabelAndFeature = new SparseMatrix(weightsPerLabel.size(), weightsPerFeature.size() );
commit:528ffcd
/////////////////////////////////////////////////////////////////////////
1:         VectorWritable.writeVector(out, weightsPerLabelAndFeature.viewRow(row));
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:b59e468
/////////////////////////////////////////////////////////////////////////
1:   private final Vector weightsPerLabel;
1:   private final Vector perlabelThetaNormalizer;
1:   private final Vector weightsPerFeature;
1:   private final Matrix weightsPerLabelAndFeature;
1:   private final float alphaI;
1:   private final double numFeatures;
1:   private final double totalWeightSum;
0:   public NaiveBayesModel(Matrix weightMatrix,
0:                          Vector weightsPerFeature,
0:                          Vector weightsPerLabel,
0:                          Vector thetaNormalizer,
0:                          float alphaI) {
commit:3218e95
/////////////////////////////////////////////////////////////////////////
0:     for (Pair<Text,VectorWritable> record
0:          : new SequenceFileIterable<Text, VectorWritable>(sumVectorPath, true, conf)) {
/////////////////////////////////////////////////////////////////////////
0:     for (Pair<IntWritable,VectorWritable> record
0:          : new SequenceFileIterable<IntWritable,VectorWritable>(classVectorPath, true, conf)) {
/////////////////////////////////////////////////////////////////////////
0:     for (Pair<Text,VectorWritable> record
0:          : new SequenceFileIterable<Text,VectorWritable>(thetaSumPath, true, conf)) {
commit:35032b8
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: public class NaiveBayesModel {
0: 
0:   private static final String MODEL = "NaiveBayesModel";
0: 
/////////////////////////////////////////////////////////////////////////
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
0: import org.apache.mahout.common.Pair;
0: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
/////////////////////////////////////////////////////////////////////////
0:   public static NaiveBayesModel fromMRTrainerOutput(Path output, Configuration conf) {
0:     for (Pair<Text,VectorWritable> record :
0:          new SequenceFileIterable<Text, VectorWritable>(sumVectorPath, true, conf)) {
0:       Text key = record.getFirst();
0:       VectorWritable value = record.getSecond();
/////////////////////////////////////////////////////////////////////////
0: 
0:     for (Pair<IntWritable,VectorWritable> record :
0:          new SequenceFileIterable<IntWritable,VectorWritable>(classVectorPath, true, conf)) {
0:       IntWritable label = record.getFirst();
0:       VectorWritable value = record.getSecond();
0: 
0:     for (Pair<Text,VectorWritable> record :
0:          new SequenceFileIterable<Text,VectorWritable>(thetaSumPath, true, conf)) {
0:       Text key = record.getFirst();
0:       VectorWritable value = record.getSecond();
0: 
commit:d61a0ee
/////////////////////////////////////////////////////////////////////////
0: public class NaiveBayesModel implements JsonDeserializer<NaiveBayesModel>, JsonSerializer<NaiveBayesModel> {
/////////////////////////////////////////////////////////////////////////
0:                                      JsonDeserializationContext context) {
/////////////////////////////////////////////////////////////////////////
0:     if (model.getPerlabelThetaNormalizer() == null
0:         || model.getPerlabelThetaNormalizer().getNumNondefaultElements() <= 0) {
0:     if (model.getFeatureSum() == null || model.getFeatureSum().getNumNondefaultElements() <= 0) {
commit:58fd277
/////////////////////////////////////////////////////////////////////////
0: 
0:     return gson.fromJson(modelString, NaiveBayesModel.class);
commit:939ac30
/////////////////////////////////////////////////////////////////////////
0: import org.apache.hadoop.io.Writable;
/////////////////////////////////////////////////////////////////////////
0:     Writable key = new Text();
============================================================================
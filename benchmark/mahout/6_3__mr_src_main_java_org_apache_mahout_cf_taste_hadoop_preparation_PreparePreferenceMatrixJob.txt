1:845cbcd: /**
1:845cbcd:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:845cbcd:  * contributor license agreements.  See the NOTICE file distributed with
1:845cbcd:  * this work for additional information regarding copyright ownership.
1:845cbcd:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:845cbcd:  * (the "License"); you may not use this file except in compliance with
1:845cbcd:  * the License.  You may obtain a copy of the License at
1:845cbcd:  *
1:845cbcd:  *     http://www.apache.org/licenses/LICENSE-2.0
1:845cbcd:  *
1:845cbcd:  * Unless required by applicable law or agreed to in writing, software
1:845cbcd:  * distributed under the License is distributed on an "AS IS" BASIS,
1:845cbcd:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:845cbcd:  * See the License for the specific language governing permissions and
1:845cbcd:  * limitations under the License.
1:845cbcd:  */
6:845cbcd: 
1:845cbcd: package org.apache.mahout.cf.taste.hadoop.preparation;
1:845cbcd: 
1:845cbcd: import org.apache.hadoop.io.IntWritable;
1:845cbcd: import org.apache.hadoop.mapreduce.Job;
1:845cbcd: import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
1:845cbcd: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1:845cbcd: import org.apache.hadoop.util.ToolRunner;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.EntityPrefWritable;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.ToEntityPrefsMapper;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.ToItemPrefsMapper;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.item.ItemIDIndexMapper;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.item.ItemIDIndexReducer;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.item.RecommenderJob;
1:845cbcd: import org.apache.mahout.cf.taste.hadoop.item.ToUserVectorsReducer;
1:845cbcd: import org.apache.mahout.common.AbstractJob;
1:08e65f6: import org.apache.mahout.common.HadoopUtil;
1:845cbcd: import org.apache.mahout.math.VarIntWritable;
1:845cbcd: import org.apache.mahout.math.VarLongWritable;
1:845cbcd: import org.apache.mahout.math.VectorWritable;
1:845cbcd: 
1:6db7f62: import java.util.List;
1:845cbcd: import java.util.Map;
1:845cbcd: 
1:845cbcd: public class PreparePreferenceMatrixJob extends AbstractJob {
1:845cbcd: 
1:845cbcd:   public static final String NUM_USERS = "numUsers.bin";
1:845cbcd:   public static final String ITEMID_INDEX = "itemIDIndex";
1:845cbcd:   public static final String USER_VECTORS = "userVectors";
1:845cbcd:   public static final String RATING_MATRIX = "ratingMatrix";
1:845cbcd: 
1:845cbcd:   private static final int DEFAULT_MIN_PREFS_PER_USER = 1;
1:845cbcd: 
1:845cbcd:   public static void main(String[] args) throws Exception {
1:845cbcd:     ToolRunner.run(new PreparePreferenceMatrixJob(), args);
1:845cbcd:   }
1:845cbcd: 
1:845cbcd:   @Override
1:845cbcd:   public int run(String[] args) throws Exception {
1:845cbcd: 
1:845cbcd:     addInputOption();
1:845cbcd:     addOutputOption();
1:845cbcd:     addOption("minPrefsPerUser", "mp", "ignore users with less preferences than this "
1:845cbcd:             + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));
1:845cbcd:     addOption("booleanData", "b", "Treat input as without pref values", Boolean.FALSE.toString());
1:1499411:     addOption("ratingShift", "rs", "shift ratings by this value", "0.0");
1:845cbcd: 
1:6db7f62:     Map<String, List<String>> parsedArgs = parseArguments(args);
1:845cbcd:     if (parsedArgs == null) {
1:845cbcd:       return -1;
1:845cbcd:     }
1:845cbcd: 
1:6db7f62:     int minPrefsPerUser = Integer.parseInt(getOption("minPrefsPerUser"));
1:6db7f62:     boolean booleanData = Boolean.valueOf(getOption("booleanData"));
1:6db7f62:     float ratingShift = Float.parseFloat(getOption("ratingShift"));
1:e410e34:     //convert items to an internal index
1:845cbcd:     Job itemIDIndex = prepareJob(getInputPath(), getOutputPath(ITEMID_INDEX), TextInputFormat.class,
1:845cbcd:             ItemIDIndexMapper.class, VarIntWritable.class, VarLongWritable.class, ItemIDIndexReducer.class,
1:845cbcd:             VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);
1:845cbcd:     itemIDIndex.setCombinerClass(ItemIDIndexReducer.class);
1:7c2b664:     boolean succeeded = itemIDIndex.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       return -1;
1:7c2b664:     }
1:e410e34:     //convert user preferences into a vector per user
1:229aeff:     Job toUserVectors = prepareJob(getInputPath(),
1:229aeff:                                    getOutputPath(USER_VECTORS),
1:229aeff:                                    TextInputFormat.class,
1:229aeff:                                    ToItemPrefsMapper.class,
1:229aeff:                                    VarLongWritable.class,
1:229aeff:                                    booleanData ? VarLongWritable.class : EntityPrefWritable.class,
1:229aeff:                                    ToUserVectorsReducer.class,
1:229aeff:                                    VarLongWritable.class,
1:229aeff:                                    VectorWritable.class,
1:229aeff:                                    SequenceFileOutputFormat.class);
1:845cbcd:     toUserVectors.getConfiguration().setBoolean(RecommenderJob.BOOLEAN_DATA, booleanData);
1:845cbcd:     toUserVectors.getConfiguration().setInt(ToUserVectorsReducer.MIN_PREFERENCES_PER_USER, minPrefsPerUser);
1:845cbcd:     toUserVectors.getConfiguration().set(ToEntityPrefsMapper.RATING_SHIFT, String.valueOf(ratingShift));
1:7c2b664:     succeeded = toUserVectors.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       return -1;
1:7c2b664:     }
1:e410e34:     //we need the number of users later
1:845cbcd:     int numberOfUsers = (int) toUserVectors.getCounters().findCounter(ToUserVectorsReducer.Counters.USERS).getValue();
1:08e65f6:     HadoopUtil.writeInt(numberOfUsers, getOutputPath(NUM_USERS), getConf());
1:e410e34:     //build the rating matrix
1:845cbcd:     Job toItemVectors = prepareJob(getOutputPath(USER_VECTORS), getOutputPath(RATING_MATRIX),
1:845cbcd:             ToItemVectorsMapper.class, IntWritable.class, VectorWritable.class, ToItemVectorsReducer.class,
1:845cbcd:             IntWritable.class, VectorWritable.class);
1:845cbcd:     toItemVectors.setCombinerClass(ToItemVectorsReducer.class);
1:845cbcd: 
1:7c2b664:     succeeded = toItemVectors.waitForCompletion(true);
1:7c2b664:     if (!succeeded) {
1:7c2b664:       return -1;
1:845cbcd:     }
1:845cbcd: 
1:845cbcd:     return 0;
1:845cbcd:   }
1:845cbcd: }
============================================================================
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
author:frankscholten
-------------------------------------------------------------------------------
commit:1a42d85
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:e90d901
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:08e65f6
/////////////////////////////////////////////////////////////////////////
1: import org.apache.mahout.common.HadoopUtil;
/////////////////////////////////////////////////////////////////////////
1:     HadoopUtil.writeInt(numberOfUsers, getOutputPath(NUM_USERS), getConf());
commit:845cbcd
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.cf.taste.hadoop.preparation;
1: 
1: import org.apache.hadoop.io.IntWritable;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
1: import org.apache.hadoop.util.ToolRunner;
1: import org.apache.mahout.cf.taste.hadoop.EntityPrefWritable;
0: import org.apache.mahout.cf.taste.hadoop.TasteHadoopUtils;
1: import org.apache.mahout.cf.taste.hadoop.ToEntityPrefsMapper;
1: import org.apache.mahout.cf.taste.hadoop.ToItemPrefsMapper;
1: import org.apache.mahout.cf.taste.hadoop.item.ItemIDIndexMapper;
1: import org.apache.mahout.cf.taste.hadoop.item.ItemIDIndexReducer;
1: import org.apache.mahout.cf.taste.hadoop.item.RecommenderJob;
1: import org.apache.mahout.cf.taste.hadoop.item.ToUserVectorsReducer;
1: import org.apache.mahout.common.AbstractJob;
1: import org.apache.mahout.math.VarIntWritable;
1: import org.apache.mahout.math.VarLongWritable;
1: import org.apache.mahout.math.VectorWritable;
1: 
1: import java.util.Map;
1: 
1: public class PreparePreferenceMatrixJob extends AbstractJob {
1: 
1:   public static final String NUM_USERS = "numUsers.bin";
1:   public static final String ITEMID_INDEX = "itemIDIndex";
1:   public static final String USER_VECTORS = "userVectors";
1:   public static final String RATING_MATRIX = "ratingMatrix";
1: 
1:   private static final int DEFAULT_MIN_PREFS_PER_USER = 1;
1: 
1:   public static void main(String[] args) throws Exception {
1:     ToolRunner.run(new PreparePreferenceMatrixJob(), args);
1:   }
1: 
1:   @Override
1:   public int run(String[] args) throws Exception {
1: 
1:     addInputOption();
1:     addOutputOption();
0:     addOption("maxPrefsPerUser", "mppu", "max number of preferences to consider per user, " +
0:         "users with more preferences will be sampled down");
1:     addOption("minPrefsPerUser", "mp", "ignore users with less preferences than this "
1:         + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));
1:     addOption("booleanData", "b", "Treat input as without pref values", Boolean.FALSE.toString());
0:     addOption("ratingShift", "rs", "shift ratings by this value", String.valueOf(0f));
1: 
0:     Map<String,String> parsedArgs = parseArguments(args);
1:     if (parsedArgs == null) {
1:       return -1;
1:     }
1: 
0:     int minPrefsPerUser = Integer.parseInt(parsedArgs.get("--minPrefsPerUser"));
0:     boolean booleanData = Boolean.valueOf(parsedArgs.get("--booleanData"));
0:     float ratingShift = Float.parseFloat(parsedArgs.get("--ratingShift"));
1: 
1:     Job itemIDIndex = prepareJob(getInputPath(), getOutputPath(ITEMID_INDEX), TextInputFormat.class,
1:         ItemIDIndexMapper.class, VarIntWritable.class, VarLongWritable.class, ItemIDIndexReducer.class,
1:         VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);
1:     itemIDIndex.setCombinerClass(ItemIDIndexReducer.class);
0:     itemIDIndex.waitForCompletion(true);
1: 
0:     Job toUserVectors = prepareJob(getInputPath(), getOutputPath(USER_VECTORS), TextInputFormat.class,
0:         ToItemPrefsMapper.class, VarLongWritable.class, booleanData ? VarLongWritable.class : EntityPrefWritable.class,
0:         ToUserVectorsReducer.class, VarLongWritable.class, VectorWritable.class, SequenceFileOutputFormat.class);
1:     toUserVectors.getConfiguration().setBoolean(RecommenderJob.BOOLEAN_DATA, booleanData);
1:     toUserVectors.getConfiguration().setInt(ToUserVectorsReducer.MIN_PREFERENCES_PER_USER, minPrefsPerUser);
1:     toUserVectors.getConfiguration().set(ToEntityPrefsMapper.RATING_SHIFT, String.valueOf(ratingShift));
0:     toUserVectors.waitForCompletion(true);
1: 
1:     int numberOfUsers = (int) toUserVectors.getCounters().findCounter(ToUserVectorsReducer.Counters.USERS).getValue();
0:     TasteHadoopUtils.writeInt(numberOfUsers, getOutputPath(NUM_USERS), getConf());
1: 
1:     Job toItemVectors = prepareJob(getOutputPath(USER_VECTORS), getOutputPath(RATING_MATRIX),
1:         ToItemVectorsMapper.class, IntWritable.class, VectorWritable.class, ToItemVectorsReducer.class,
1:         IntWritable.class, VectorWritable.class);
1:     toItemVectors.setCombinerClass(ToItemVectorsReducer.class);
1: 
0:     /* configure sampling regarding the uservectors */
0:     if (parsedArgs.containsKey("--maxPrefsPerUser")) {
0:       int samplingSize = Integer.parseInt(parsedArgs.get("--maxPrefsPerUser"));
0:       toItemVectors.getConfiguration().setInt(ToItemVectorsMapper.SAMPLE_SIZE, samplingSize);
1:     }
1: 
0:     toItemVectors.waitForCompletion(true);
1: 
1:     return 0;
1:   }
1: }
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:229aeff
/////////////////////////////////////////////////////////////////////////
1:     Job toUserVectors = prepareJob(getInputPath(),
1:                                    getOutputPath(USER_VECTORS),
1:                                    TextInputFormat.class,
1:                                    ToItemPrefsMapper.class,
1:                                    VarLongWritable.class,
1:                                    booleanData ? VarLongWritable.class : EntityPrefWritable.class,
1:                                    ToUserVectorsReducer.class,
1:                                    VarLongWritable.class,
1:                                    VectorWritable.class,
1:                                    SequenceFileOutputFormat.class);
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
1:     boolean succeeded = itemIDIndex.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
1:     }
/////////////////////////////////////////////////////////////////////////
1:     succeeded = toUserVectors.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
1:     }
/////////////////////////////////////////////////////////////////////////
1:     succeeded = toItemVectors.waitForCompletion(true);
1:     if (!succeeded) {
1:       return -1;
0:     }
commit:4fbfbc6
/////////////////////////////////////////////////////////////////////////
commit:1499411
/////////////////////////////////////////////////////////////////////////
1:     addOption("ratingShift", "rs", "shift ratings by this value", "0.0");
author:tcp
-------------------------------------------------------------------------------
commit:44459bd
/////////////////////////////////////////////////////////////////////////
0:     addOption("maxPrefsPerUser", "mppu", "max number of preferences to consider per user, " 
0:             + "users with more preferences will be sampled down");
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:6db7f62
/////////////////////////////////////////////////////////////////////////
1: import java.util.List;
/////////////////////////////////////////////////////////////////////////
1:     Map<String, List<String>> parsedArgs = parseArguments(args);
1:     int minPrefsPerUser = Integer.parseInt(getOption("minPrefsPerUser"));
1:     boolean booleanData = Boolean.valueOf(getOption("booleanData"));
1:     float ratingShift = Float.parseFloat(getOption("ratingShift"));
/////////////////////////////////////////////////////////////////////////
0:     if (hasOption("maxPrefsPerUser")) {
0:       int samplingSize = Integer.parseInt(getOption("maxPrefsPerUser"));
commit:e410e34
/////////////////////////////////////////////////////////////////////////
0:             "users with more preferences will be sampled down");
0:             + "(default: " + DEFAULT_MIN_PREFS_PER_USER + ')', String.valueOf(DEFAULT_MIN_PREFS_PER_USER));
0:     Map<String, String> parsedArgs = parseArguments(args);
/////////////////////////////////////////////////////////////////////////
1:     //convert items to an internal index
0:             ItemIDIndexMapper.class, VarIntWritable.class, VarLongWritable.class, ItemIDIndexReducer.class,
0:             VarIntWritable.class, VarLongWritable.class, SequenceFileOutputFormat.class);
1:     //convert user preferences into a vector per user
0:             ToItemPrefsMapper.class, VarLongWritable.class, booleanData ? VarLongWritable.class : EntityPrefWritable.class,
0:             ToUserVectorsReducer.class, VarLongWritable.class, VectorWritable.class, SequenceFileOutputFormat.class);
1:     //we need the number of users later
1:     //build the rating matrix
0:             ToItemVectorsMapper.class, IntWritable.class, VectorWritable.class, ToItemVectorsReducer.class,
0:             IntWritable.class, VectorWritable.class);
============================================================================
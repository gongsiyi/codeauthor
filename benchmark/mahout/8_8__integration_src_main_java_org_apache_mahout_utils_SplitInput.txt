1:29a7f38: /*
1:29a7f38:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:29a7f38:  * contributor license agreements.  See the NOTICE file distributed with
1:29a7f38:  * this work for additional information regarding copyright ownership.
1:29a7f38:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:29a7f38:  * (the "License"); you may not use this file except in compliance with
1:29a7f38:  * the License.  You may obtain a copy of the License at
1:29a7f38:  *
1:29a7f38:  *     http://www.apache.org/licenses/LICENSE-2.0
1:29a7f38:  *
1:29a7f38:  * Unless required by applicable law or agreed to in writing, software
1:29a7f38:  * distributed under the License is distributed on an "AS IS" BASIS,
1:29a7f38:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:29a7f38:  * See the License for the specific language governing permissions and
1:29a7f38:  * limitations under the License.
1:29a7f38:  */
16:29a7f38: 
1:29a7f38: package org.apache.mahout.utils;
1:29a7f38: 
1:85f9ece: import java.io.BufferedReader;
1:85f9ece: import java.io.IOException;
1:85f9ece: import java.io.InputStreamReader;
1:85f9ece: import java.io.OutputStreamWriter;
1:85f9ece: import java.io.Writer;
1:85f9ece: import java.nio.charset.Charset;
1:85f9ece: import java.util.BitSet;
1:85f9ece: 
1:29a7f38: import com.google.common.base.Preconditions;
1:29a7f38: import org.apache.commons.cli2.OptionException;
1:85f9ece: import org.apache.commons.io.Charsets;
1:29a7f38: import org.apache.hadoop.conf.Configuration;
1:29a7f38: import org.apache.hadoop.fs.FileStatus;
1:29a7f38: import org.apache.hadoop.fs.FileSystem;
1:29a7f38: import org.apache.hadoop.fs.Path;
1:29a7f38: import org.apache.hadoop.io.SequenceFile;
1:e0ec7c1: import org.apache.hadoop.io.Writable;
1:e6a308b: import org.apache.hadoop.util.ToolRunner;
1:e6a308b: import org.apache.mahout.common.AbstractJob;
1:29a7f38: import org.apache.mahout.common.CommandLineUtil;
1:29a7f38: import org.apache.mahout.common.HadoopUtil;
1:29a7f38: import org.apache.mahout.common.Pair;
1:29a7f38: import org.apache.mahout.common.RandomUtils;
1:29a7f38: import org.apache.mahout.common.commandline.DefaultOptionCreator;
1:29a7f38: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
1:29a7f38: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator;
1:29a7f38: import org.apache.mahout.math.jet.random.sampling.RandomSampler;
1:29a7f38: import org.slf4j.Logger;
1:29a7f38: import org.slf4j.LoggerFactory;
1:29a7f38: 
1:29a7f38: /**
1:29a7f38:  * A utility for splitting files in the input format used by the Bayes
1:29a7f38:  * classifiers or anything else that has one item per line or SequenceFiles (key/value)
1:29a7f38:  * into training and test sets in order to perform cross-validation.
1:29a7f38:  * <p/>
1:29a7f38:  * <p/>
1:29a7f38:  * This class can be used to split directories of files or individual files into
1:29a7f38:  * training and test sets using a number of different methods.
1:29a7f38:  * <p/>
1:29a7f38:  * When executed via {@link #splitDirectory(Path)} or {@link #splitFile(Path)},
1:29a7f38:  * the lines read from one or more, input files are written to files of the same
1:29a7f38:  * name into the directories specified by the
1:29a7f38:  * {@link #setTestOutputDirectory(Path)} and
1:29a7f38:  * {@link #setTrainingOutputDirectory(Path)} methods.
1:29a7f38:  * <p/>
1:29a7f38:  * The composition of the test set is determined using one of the following
1:29a7f38:  * approaches:
1:29a7f38:  * <ul>
1:29a7f38:  * <li>A contiguous set of items can be chosen from the input file(s) using the
1:29a7f38:  * {@link #setTestSplitSize(int)} or {@link #setTestSplitPct(int)} methods.
1:29a7f38:  * {@link #setTestSplitSize(int)} allocates a fixed number of items, while
1:29a7f38:  * {@link #setTestSplitPct(int)} allocates a percentage of the original input,
1:29a7f38:  * rounded up to the nearest integer. {@link #setSplitLocation(int)} is used to
1:29a7f38:  * control the position in the input from which the test data is extracted and
1:29a7f38:  * is described further below.</li>
1:29a7f38:  * <li>A random sampling of items can be chosen from the input files(s) using
1:29a7f38:  * the {@link #setTestRandomSelectionSize(int)} or
1:29a7f38:  * {@link #setTestRandomSelectionPct(int)} methods, each choosing a fixed test
1:29a7f38:  * set size or percentage of the input set size as described above. The
1:29a7f38:  * {@link RandomSampler} class from {@code mahout-math} is used to create a sample
1:29a7f38:  * of the appropriate size.</li>
1:29a7f38:  * </ul>
1:29a7f38:  * <p/>
1:29a7f38:  * Any one of the methods above can be used to control the size of the test set.
1:29a7f38:  * If multiple methods are called, a runtime exception will be thrown at
1:29a7f38:  * execution time.
1:29a7f38:  * <p/>
1:29a7f38:  * The {@link #setSplitLocation(int)} method is passed an integer from 0 to 100
1:29a7f38:  * (inclusive) which is translated into the position of the start of the test
1:29a7f38:  * data within the input file.
1:29a7f38:  * <p/>
1:29a7f38:  * Given:
1:29a7f38:  * <ul>
1:29a7f38:  * <li>an input file of 1500 lines</li>
1:29a7f38:  * <li>a desired test data size of 10 percent</li>
1:29a7f38:  * </ul>
1:29a7f38:  * <p/>
1:29a7f38:  * <ul>
1:29a7f38:  * <li>A split location of 0 will cause the first 150 items appearing in the
1:29a7f38:  * input set to be written to the test set.</li>
1:29a7f38:  * <li>A split location of 25 will cause items 375-525 to be written to the test
1:29a7f38:  * set.</li>
1:29a7f38:  * <li>A split location of 100 will cause the last 150 items in the input to be
1:29a7f38:  * written to the test set</li>
1:29a7f38:  * </ul>
1:29a7f38:  * The start of the split will always be adjusted forwards in order to ensure
1:29a7f38:  * that the desired test set size is allocated. Split location has no effect is
1:29a7f38:  * random sampling is employed.
1:29a7f38:  */
1:e6a308b: public class SplitInput extends AbstractJob {
1:29a7f38: 
1:29a7f38:   private static final Logger log = LoggerFactory.getLogger(SplitInput.class);
1:29a7f38: 
1:29a7f38:   private int testSplitSize = -1;
1:29a7f38:   private int testSplitPct = -1;
1:29a7f38:   private int splitLocation = 100;
1:29a7f38:   private int testRandomSelectionSize = -1;
1:29a7f38:   private int testRandomSelectionPct = -1;
1:e6a308b:   private int keepPct = 100;
1:29a7f38:   private Charset charset = Charsets.UTF_8;
1:29a7f38:   private boolean useSequence;
1:e6a308b:   private boolean useMapRed;
1:29a7f38: 
1:29a7f38:   private Path inputDirectory;
1:29a7f38:   private Path trainingOutputDirectory;
1:29a7f38:   private Path testOutputDirectory;
1:e6a308b:   private Path mapRedOutputDirectory;
1:29a7f38: 
1:29a7f38:   private SplitCallback callback;
1:29a7f38: 
1:e6a308b:   @Override
1:e6a308b:   public int run(String[] args) throws Exception {
1:e6a308b: 
1:e6a308b:     if (parseArgs(args)) {
1:e6a308b:       splitDirectory();
3:29a7f38:     }
1:e6a308b:     return 0;
1:e6a308b:   }
1:e6a308b: 
1:e6a308b:   public static void main(String[] args) throws Exception {
1:e6a308b:     ToolRunner.run(new Configuration(), new SplitInput(), args);
1:29a7f38:   }
1:e6a308b: 
1:29a7f38:   /**
1:29a7f38:    * Configure this instance based on the command-line arguments contained within provided array.
1:29a7f38:    * Calls {@link #validate()} to ensure consistency of configuration.
1:29a7f38:    *
1:29a7f38:    * @return true if the arguments were parsed successfully and execution should proceed.
1:29a7f38:    * @throws Exception if there is a problem parsing the command-line arguments or the particular
1:29a7f38:    *                   combination would violate class invariants.
1:29a7f38:    */
1:e6a308b:   private boolean parseArgs(String[] args) throws Exception {
1:29a7f38: 
1:e6a308b:     addInputOption();
1:e6a308b:     addOption("trainingOutput", "tr", "The training data output directory", false);
1:e6a308b:     addOption("testOutput", "te", "The test data output directory", false);
1:e6a308b:     addOption("testSplitSize", "ss", "The number of documents held back as test data for each category", false);
1:e6a308b:     addOption("testSplitPct", "sp", "The % of documents held back as test data for each category", false);
1:6d16230:     addOption("splitLocation", "sl", "Location for start of test data expressed as a percentage of the input file "
1:6d16230:         + "size (0=start, 50=middle, 100=end", false);
1:e6a308b:     addOption("randomSelectionSize", "rs", "The number of items to be randomly selected as test data ", false);
1:6d16230:     addOption("randomSelectionPct", "rp", "Percentage of items to be randomly selected as test data when using "
1:6d16230:         + "mapreduce mode", false);
1:6d16230:     addOption("charset", "c", "The name of the character encoding of the input files (not needed if using "
1:6d16230:         + "SequenceFiles)", false);
1:3c22856:     addOption(buildOption("sequenceFiles", "seq", "Set if the input files are sequence files.  Default is false",
1:3c22856:         false, false, "false"));
1:e6a308b:     addOption(DefaultOptionCreator.methodOption().create());
1:e6a308b:     addOption(DefaultOptionCreator.overwriteOption().create());
1:e6a308b:     //TODO: extend this to sequential mode
1:6d16230:     addOption("keepPct", "k", "The percentage of total data to keep in map-reduce mode, the rest will be ignored.  "
1:6d16230:         + "Default is 100%", false);
1:e6a308b:     addOption("mapRedOutputDir", "mro", "Output directory for map reduce jobs", false);
1:29a7f38: 
1:e6a308b:     if (parseArguments(args) == null) {
1:e6a308b:       return false;
1:e6a308b:     }
1:29a7f38: 
4:29a7f38:     try {
1:e6a308b:       inputDirectory = getInputPath();
1:29a7f38: 
1:e6a308b:       useMapRed = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.MAPREDUCE_METHOD);
1:29a7f38: 
1:e6a308b:       if (useMapRed) {
1:e6a308b:         if (!hasOption("randomSelectionPct")) {
1:e6a308b:           throw new OptionException(getCLIOption("randomSelectionPct"),
1:e6a308b:                   "must set randomSelectionPct when mapRed option is used");
1:e6a308b:         }
1:e6a308b:         if (!hasOption("mapRedOutputDir")) {
1:e6a308b:           throw new OptionException(getCLIOption("mapRedOutputDir"),
1:e6a308b:                                     "mapRedOutputDir must be set when mapRed option is used");
1:e6a308b:         }
1:822a5e1:         mapRedOutputDirectory = new Path(getOption("mapRedOutputDir"));
1:e6a308b:         if (hasOption("keepPct")) {
1:822a5e1:           keepPct = Integer.parseInt(getOption("keepPct"));
1:e6a308b:         }
1:e6a308b:         if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:e6a308b:           HadoopUtil.delete(getConf(), mapRedOutputDirectory);
1:e6a308b:         }
1:e6a308b:       } else {
1:e6a308b:         if (!hasOption("trainingOutput")
1:e6a308b:                 || !hasOption("testOutput")) {
1:e6a308b:           throw new OptionException(getCLIOption("trainingOutput"),
1:e6a308b:                   "trainingOutput and testOutput must be set if mapRed option is not used");
1:e6a308b:         }
1:e6a308b:         if (!hasOption("testSplitSize")
1:e6a308b:                 && !hasOption("testSplitPct")
1:e6a308b:                 && !hasOption("randomSelectionPct")
1:e6a308b:                 && !hasOption("randomSelectionSize")) {
1:e6a308b:           throw new OptionException(getCLIOption("testSplitSize"),
1:e6a308b:                   "must set one of test split size/percentage or randomSelectionSize/percentage");
1:e6a308b:         }
1:e6a308b: 
1:822a5e1:         trainingOutputDirectory = new Path(getOption("trainingOutput"));
1:822a5e1:         testOutputDirectory = new Path(getOption("testOutput"));
1:e6a308b:         FileSystem fs = trainingOutputDirectory.getFileSystem(getConf());
1:e6a308b:         if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:e6a308b:           HadoopUtil.delete(fs.getConf(), trainingOutputDirectory);
1:e6a308b:           HadoopUtil.delete(fs.getConf(), testOutputDirectory);
1:e6a308b:         }
1:e6a308b:         fs.mkdirs(trainingOutputDirectory);
1:e6a308b:         fs.mkdirs(testOutputDirectory);
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("charset")) {
1:822a5e1:         charset = Charset.forName(getOption("charset"));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("testSplitSize") && hasOption("testSplitPct")) {
1:6d16230:         throw new OptionException(getCLIOption("testSplitPct"), "must have either split size or split percentage "
1:6d16230:             + "option, not BOTH");
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("testSplitSize")) {
1:e6a308b:         setTestSplitSize(Integer.parseInt(getOption("testSplitSize")));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("testSplitPct")) {
1:e6a308b:         setTestSplitPct(Integer.parseInt(getOption("testSplitPct")));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("splitLocation")) {
1:e6a308b:         setSplitLocation(Integer.parseInt(getOption("splitLocation")));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("randomSelectionSize")) {
1:e6a308b:         setTestRandomSelectionSize(Integer.parseInt(getOption("randomSelectionSize")));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       if (hasOption("randomSelectionPct")) {
1:e6a308b:         setTestRandomSelectionPct(Integer.parseInt(getOption("randomSelectionPct")));
1:29a7f38:       }
1:29a7f38: 
1:e6a308b:       useSequence = hasOption("sequenceFiles");
1:29a7f38: 
1:29a7f38:     } catch (OptionException e) {
1:29a7f38:       log.error("Command-line option Exception", e);
1:051cbcf:       CommandLineUtil.printHelp(getGroup());
2:29a7f38:       return false;
1:29a7f38:     }
1:29a7f38: 
1:29a7f38:     validate();
1:29a7f38:     return true;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Perform a split on directory specified by {@link #setInputDirectory(Path)} by calling {@link #splitFile(Path)}
1:29a7f38:    * on each file found within that directory.
1:29a7f38:    */
1:822a5e1:   public void splitDirectory() throws IOException, ClassNotFoundException, InterruptedException {
1:29a7f38:     this.splitDirectory(inputDirectory);
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Perform a split on the specified directory by calling {@link #splitFile(Path)} on each file found within that
1:29a7f38:    * directory.
1:29a7f38:    */
1:822a5e1:   public void splitDirectory(Path inputDir) throws IOException, ClassNotFoundException, InterruptedException {
1:e6a308b:     Configuration conf = getConf();
1:e3ec9d8:     splitDirectory(conf, inputDir);
1:e6a308b:   }
1:29a7f38: 
1:e3ec9d8:   /*
1:e3ec9d8:    * See also splitDirectory(Path inputDir)
1:e3ec9d8:    * */
1:58cc1ae:   public void splitDirectory(Configuration conf, Path inputDir)
1:58cc1ae:     throws IOException, ClassNotFoundException, InterruptedException {
1:e6a308b:     FileSystem fs = inputDir.getFileSystem(conf);
1:29a7f38:     if (fs.getFileStatus(inputDir) == null) {
1:29a7f38:       throw new IOException(inputDir + " does not exist");
1:e6a308b:     }
1:b988c49:     if (!fs.getFileStatus(inputDir).isDir()) {
1:29a7f38:       throw new IOException(inputDir + " is not a directory");
1:e6a308b:     }
1:29a7f38: 
1:e6a308b:     if (useMapRed) {
1:e3ec9d8:       SplitInputJob.run(conf, inputDir, mapRedOutputDirectory,
1:e6a308b:             keepPct, testRandomSelectionPct);
1:e6a308b:     } else {
1:e6a308b:       // input dir contains one file per category.
1:e6a308b:       FileStatus[] fileStats = fs.listStatus(inputDir, PathFilters.logsCRCFilter());
1:e6a308b:       for (FileStatus inputFile : fileStats) {
1:a4f24dd:         if (!inputFile.isDir()) {
1:e6a308b:           splitFile(inputFile.getPath());
1:e6a308b:         }
1:29a7f38:       }
1:29a7f38:     }
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Perform a split on the specified input file. Results will be written to files of the same name in the specified
1:29a7f38:    * training and test output directories. The {@link #validate()} method is called prior to executing the split.
1:29a7f38:    */
1:29a7f38:   public void splitFile(Path inputFile) throws IOException {
1:e6a308b:     Configuration conf = getConf();
1:e6a308b:     FileSystem fs = inputFile.getFileSystem(conf);
1:29a7f38:     if (fs.getFileStatus(inputFile) == null) {
1:29a7f38:       throw new IOException(inputFile + " does not exist");
1:29a7f38:     }
1:b988c49:     if (fs.getFileStatus(inputFile).isDir()) {
1:29a7f38:       throw new IOException(inputFile + " is a directory");
1:29a7f38:     }
1:29a7f38: 
1:29a7f38:     validate();
1:29a7f38: 
1:29a7f38:     Path testOutputFile = new Path(testOutputDirectory, inputFile.getName());
1:29a7f38:     Path trainingOutputFile = new Path(trainingOutputDirectory, inputFile.getName());
1:29a7f38: 
1:29a7f38:     int lineCount = countLines(fs, inputFile, charset);
1:29a7f38: 
1:29a7f38:     log.info("{} has {} lines", inputFile.getName(), lineCount);
1:29a7f38: 
1:29a7f38:     int testSplitStart = 0;
1:29a7f38:     int testSplitSize = this.testSplitSize; // don't modify state
1:29a7f38:     BitSet randomSel = null;
1:29a7f38: 
1:29a7f38:     if (testRandomSelectionPct > 0 || testRandomSelectionSize > 0) {
1:29a7f38:       testSplitSize = this.testRandomSelectionSize;
1:29a7f38: 
1:29a7f38:       if (testRandomSelectionPct > 0) {
1:29a7f38:         testSplitSize = Math.round(lineCount * testRandomSelectionPct / 100.0f);
1:29a7f38:       }
1:29a7f38:       log.info("{} test split size is {} based on random selection percentage {}",
1:8396a27:                inputFile.getName(), testSplitSize, testRandomSelectionPct);
1:29a7f38:       long[] ridx = new long[testSplitSize];
1:29a7f38:       RandomSampler.sample(testSplitSize, lineCount - 1, testSplitSize, 0, ridx, 0, RandomUtils.getRandom());
1:29a7f38:       randomSel = new BitSet(lineCount);
1:29a7f38:       for (long idx : ridx) {
1:29a7f38:         randomSel.set((int) idx + 1);
1:29a7f38:       }
1:e6a308b:     } else {
1:29a7f38:       if (testSplitPct > 0) { // calculate split size based on percentage
1:29a7f38:         testSplitSize = Math.round(lineCount * testSplitPct / 100.0f);
1:29a7f38:         log.info("{} test split size is {} based on percentage {}",
1:8396a27:                  inputFile.getName(), testSplitSize, testSplitPct);
2:29a7f38:       } else {
1:29a7f38:         log.info("{} test split size is {}", inputFile.getName(), testSplitSize);
1:29a7f38:       }
1:29a7f38: 
1:29a7f38:       if (splitLocation > 0) { // calculate start of split based on percentage
1:29a7f38:         testSplitStart = Math.round(lineCount * splitLocation / 100.0f);
1:29a7f38:         if (lineCount - testSplitStart < testSplitSize) {
1:29a7f38:           // adjust split start downwards based on split size.
1:29a7f38:           testSplitStart = lineCount - testSplitSize;
1:29a7f38:         }
1:29a7f38:         log.info("{} test split start is {} based on split location {}",
1:8396a27:                  inputFile.getName(), testSplitStart, splitLocation);
1:29a7f38:       }
1:29a7f38: 
1:29a7f38:       if (testSplitStart < 0) {
1:29a7f38:         throw new IllegalArgumentException("test split size for " + inputFile + " is too large, it would produce an "
1:29a7f38:                 + "empty training set from the initial set of " + lineCount + " examples");
1:29a7f38:       } else if (lineCount - testSplitSize < testSplitSize) {
1:29a7f38:         log.warn("Test set size for {} may be too large, {} is larger than the number of "
1:29a7f38:                 + "lines remaining in the training set: {}",
1:8396a27:                  inputFile, testSplitSize, lineCount - testSplitSize);
1:29a7f38:       }
1:29a7f38:     }
1:29a7f38:     int trainCount = 0;
1:29a7f38:     int testCount = 0;
1:e0ec7c1:     if (!useSequence) {
1:85f9ece:       try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset));
1:85f9ece:            Writer trainingWriter = new OutputStreamWriter(fs.create(trainingOutputFile), charset);
1:85f9ece:            Writer testWriter = new OutputStreamWriter(fs.create(testOutputFile), charset)){
1:29a7f38: 
2:29a7f38:         String line;
1:29a7f38:         int pos = 0;
1:29a7f38:         while ((line = reader.readLine()) != null) {
1:29a7f38:           pos++;
1:29a7f38: 
1:29a7f38:           Writer writer;
1:29a7f38:           if (testRandomSelectionPct > 0) { // Randomly choose
1:29a7f38:             writer = randomSel.get(pos) ? testWriter : trainingWriter;
1:29a7f38:           } else { // Choose based on location
1:29a7f38:             writer = pos > testSplitStart ? testWriter : trainingWriter;
1:29a7f38:           }
1:29a7f38: 
1:29a7f38:           if (writer == testWriter) {
1:29a7f38:             if (testCount >= testSplitSize) {
1:29a7f38:               writer = trainingWriter;
1:29a7f38:             } else {
1:29a7f38:               testCount++;
1:29a7f38:             }
1:29a7f38:           }
1:29a7f38:           if (writer == trainingWriter) {
1:29a7f38:             trainCount++;
1:29a7f38:           }
1:29a7f38:           writer.write(line);
1:29a7f38:           writer.write('\n');
1:29a7f38:         }
1:29a7f38: 
1:29a7f38:       }
1:29a7f38:     } else {
1:85f9ece:       try (SequenceFileIterator<Writable, Writable> iterator =
1:85f9ece:                new SequenceFileIterator<>(inputFile, false, fs.getConf());
1:85f9ece:            SequenceFile.Writer trainingWriter = SequenceFile.createWriter(fs, fs.getConf(), trainingOutputFile,
1:85f9ece:                iterator.getKeyClass(), iterator.getValueClass());
1:85f9ece:            SequenceFile.Writer testWriter = SequenceFile.createWriter(fs, fs.getConf(), testOutputFile,
1:85f9ece:                iterator.getKeyClass(), iterator.getValueClass())) {
1:29a7f38: 
1:29a7f38:         int pos = 0;
1:29a7f38:         while (iterator.hasNext()) {
1:29a7f38:           pos++;
1:29a7f38:           SequenceFile.Writer writer;
1:29a7f38:           if (testRandomSelectionPct > 0) { // Randomly choose
1:29a7f38:             writer = randomSel.get(pos) ? testWriter : trainingWriter;
1:29a7f38:           } else { // Choose based on location
1:29a7f38:             writer = pos > testSplitStart ? testWriter : trainingWriter;
1:29a7f38:           }
1:29a7f38: 
1:29a7f38:           if (writer == testWriter) {
1:29a7f38:             if (testCount >= testSplitSize) {
1:29a7f38:               writer = trainingWriter;
1:29a7f38:             } else {
1:29a7f38:               testCount++;
1:29a7f38:             }
1:29a7f38:           }
1:29a7f38:           if (writer == trainingWriter) {
1:29a7f38:             trainCount++;
1:29a7f38:           }
1:e6a308b:           Pair<Writable, Writable> pair = iterator.next();
1:29a7f38:           writer.append(pair.getFirst(), pair.getSecond());
1:29a7f38:         }
1:29a7f38: 
1:29a7f38:       }
1:29a7f38:     }
1:29a7f38:     log.info("file: {}, input: {} train: {}, test: {} starting at {}",
1:8396a27:              inputFile.getName(), lineCount, trainCount, testCount, testSplitStart);
1:29a7f38: 
1:29a7f38:     // testing;
1:29a7f38:     if (callback != null) {
1:29a7f38:       callback.splitComplete(inputFile, lineCount, trainCount, testCount, testSplitStart);
1:29a7f38:     }
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public int getTestSplitSize() {
1:29a7f38:     return testSplitSize;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public void setTestSplitSize(int testSplitSize) {
1:29a7f38:     this.testSplitSize = testSplitSize;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public int getTestSplitPct() {
1:29a7f38:     return testSplitPct;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Sets the percentage of the input data to allocate to the test split
1:29a7f38:    *
1:29a7f38:    * @param testSplitPct a value between 0 and 100 inclusive.
1:29a7f38:    */
1:29a7f38:   public void setTestSplitPct(int testSplitPct) {
1:29a7f38:     this.testSplitPct = testSplitPct;
1:29a7f38:   }
1:29a7f38: 
1:e6a308b:   /**
1:e6a308b:    * Sets the percentage of the input data to keep in a map reduce split input job
1:e6a308b:    *
1:e6a308b:    * @param keepPct a value between 0 and 100 inclusive.
1:e6a308b:    */
1:e6a308b:   public void setKeepPct(int keepPct) {
1:e6a308b:     this.keepPct = keepPct;
1:e6a308b:   }
1:e6a308b: 
1:e6a308b:   /**
1:e6a308b:    * Set to true to use map reduce to split the input
1:e6a308b:    *
1:e6a308b:    * @param useMapRed a boolean to indicate whether map reduce should be used
1:e6a308b:    */
1:e6a308b:   public void setUseMapRed(boolean useMapRed) {
1:e6a308b:     this.useMapRed = useMapRed;
1:e6a308b:   }
1:e6a308b: 
1:e6a308b:   public void setMapRedOutputDirectory(Path mapRedOutputDirectory) {
1:e6a308b:     this.mapRedOutputDirectory = mapRedOutputDirectory;
1:e6a308b:   }
1:e6a308b: 
1:29a7f38:   public int getSplitLocation() {
1:29a7f38:     return splitLocation;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Set the location of the start of the test/training data split. Expressed as percentage of lines, for example
1:29a7f38:    * 0 indicates that the test data should be taken from the start of the file, 100 indicates that the test data
1:29a7f38:    * should be taken from the end of the input file, while 25 indicates that the test data should be taken from the
1:29a7f38:    * first quarter of the file.
1:29a7f38:    * <p/>
1:29a7f38:    * This option is only relevant in cases where random selection is not employed
1:29a7f38:    *
1:29a7f38:    * @param splitLocation a value between 0 and 100 inclusive.
1:29a7f38:    */
1:29a7f38:   public void setSplitLocation(int splitLocation) {
1:29a7f38:     this.splitLocation = splitLocation;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public Charset getCharset() {
1:29a7f38:     return charset;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Set the charset used to read and write files
1:29a7f38:    */
1:29a7f38:   public void setCharset(Charset charset) {
1:29a7f38:     this.charset = charset;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public Path getInputDirectory() {
1:29a7f38:     return inputDirectory;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Set the directory from which input data will be read when the the {@link #splitDirectory()} method is invoked
1:29a7f38:    */
1:29a7f38:   public void setInputDirectory(Path inputDir) {
1:29a7f38:     this.inputDirectory = inputDir;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public Path getTrainingOutputDirectory() {
1:29a7f38:     return trainingOutputDirectory;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Set the directory to which training data will be written.
1:29a7f38:    */
1:29a7f38:   public void setTrainingOutputDirectory(Path trainingOutputDir) {
1:29a7f38:     this.trainingOutputDirectory = trainingOutputDir;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public Path getTestOutputDirectory() {
1:29a7f38:     return testOutputDirectory;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Set the directory to which test data will be written.
1:29a7f38:    */
1:29a7f38:   public void setTestOutputDirectory(Path testOutputDir) {
1:29a7f38:     this.testOutputDirectory = testOutputDir;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public SplitCallback getCallback() {
1:29a7f38:     return callback;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Sets the callback used to inform the caller that an input file has been successfully split
1:29a7f38:    */
1:29a7f38:   public void setCallback(SplitCallback callback) {
1:29a7f38:     this.callback = callback;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public int getTestRandomSelectionSize() {
1:29a7f38:     return testRandomSelectionSize;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Sets number of random input samples that will be saved to the test set.
1:29a7f38:    */
1:29a7f38:   public void setTestRandomSelectionSize(int testRandomSelectionSize) {
1:29a7f38:     this.testRandomSelectionSize = testRandomSelectionSize;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   public int getTestRandomSelectionPct() {
1:29a7f38: 
1:29a7f38:     return testRandomSelectionPct;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Sets number of random input samples that will be saved to the test set as a percentage of the size of the
1:29a7f38:    * input set.
1:29a7f38:    *
1:29a7f38:    * @param randomSelectionPct a value between 0 and 100 inclusive.
1:29a7f38:    */
1:29a7f38:   public void setTestRandomSelectionPct(int randomSelectionPct) {
1:29a7f38:     this.testRandomSelectionPct = randomSelectionPct;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Validates that the current instance is in a consistent state
1:29a7f38:    *
1:29a7f38:    * @throws IllegalArgumentException if settings violate class invariants.
1:29a7f38:    * @throws IOException              if output directories do not exist or are not directories.
1:29a7f38:    */
1:29a7f38:   public void validate() throws IOException {
1:29a7f38:     Preconditions.checkArgument(testSplitSize >= 1 || testSplitSize == -1,
1:cd167f9:         "Invalid testSplitSize: " + testSplitSize + ". Must be: testSplitSize >= 1 or testSplitSize = -1");
2:29a7f38:     Preconditions.checkArgument(splitLocation >= 0 && splitLocation <= 100 || splitLocation == -1,
1:cd167f9:         "Invalid splitLocation percentage: " + splitLocation + ". Must be: 0 <= splitLocation <= 100 or splitLocation = -1");
1:29a7f38:     Preconditions.checkArgument(testSplitPct >= 0 && testSplitPct <= 100 || testSplitPct == -1,
1:cd167f9:         "Invalid testSplitPct percentage: " + testSplitPct + ". Must be: 0 <= testSplitPct <= 100 or testSplitPct = -1");
1:29a7f38:     Preconditions.checkArgument(testRandomSelectionPct >= 0 && testRandomSelectionPct <= 100
1:cd167f9:             || testRandomSelectionPct == -1,"Invalid testRandomSelectionPct percentage: " + testRandomSelectionPct +
1:cd167f9:         ". Must be: 0 <= testRandomSelectionPct <= 100 or testRandomSelectionPct = -1");
1:29a7f38: 
1:3c22856:     Preconditions.checkArgument(trainingOutputDirectory != null || useMapRed,
1:3c22856:         "No training output directory was specified");
1:e6a308b:     Preconditions.checkArgument(testOutputDirectory != null || useMapRed, "No test output directory was specified");
1:29a7f38: 
1:29a7f38:     // only one of the following may be set, one must be set.
1:29a7f38:     int count = 0;
1:29a7f38:     if (testSplitSize > 0) {
1:29a7f38:       count++;
1:29a7f38:     }
1:29a7f38:     if (testSplitPct > 0) {
1:29a7f38:       count++;
1:29a7f38:     }
1:29a7f38:     if (testRandomSelectionSize > 0) {
1:29a7f38:       count++;
1:29a7f38:     }
1:29a7f38:     if (testRandomSelectionPct > 0) {
1:29a7f38:       count++;
1:29a7f38:     }
1:29a7f38: 
1:6d16230:     Preconditions.checkArgument(count == 1, "Exactly one of testSplitSize, testSplitPct, testRandomSelectionSize, "
1:6d16230:         + "testRandomSelectionPct should be set");
1:29a7f38: 
1:e6a308b:     if (!useMapRed) {
1:e6a308b:       Configuration conf = getConf();
1:e6a308b:       FileSystem fs = trainingOutputDirectory.getFileSystem(conf);
1:e6a308b:       FileStatus trainingOutputDirStatus = fs.getFileStatus(trainingOutputDirectory);
1:b988c49:       Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDir(),
1:cd167f9:           "%s is not a directory", trainingOutputDirectory);
1:e6a308b:       FileStatus testOutputDirStatus = fs.getFileStatus(testOutputDirectory);
1:b988c49:       Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDir(),
1:cd167f9:           "%s is not a directory", testOutputDirectory);
1:e6a308b:     }
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Count the lines in the file specified as returned by {@code BufferedReader.readLine()}
1:29a7f38:    *
1:29a7f38:    * @param inputFile the file whose lines will be counted
1:29a7f38:    * @param charset   the charset of the file to read
1:29a7f38:    * @return the number of lines in the input file.
1:29a7f38:    * @throws IOException if there is a problem opening or reading the file.
1:29a7f38:    */
1:29a7f38:   public static int countLines(FileSystem fs, Path inputFile, Charset charset) throws IOException {
1:29a7f38:     int lineCount = 0;
1:85f9ece:     try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset))){
1:29a7f38:       while (reader.readLine() != null) {
1:29a7f38:         lineCount++;
1:29a7f38:       }
1:29a7f38:     }
1:29a7f38:     return lineCount;
1:29a7f38:   }
1:29a7f38: 
1:29a7f38:   /**
1:29a7f38:    * Used to pass information back to a caller once a file has been split without the need for a data object
1:29a7f38:    */
1:29a7f38:   public interface SplitCallback {
1:29a7f38:     void splitComplete(Path inputFile, int lineCount, int trainCount, int testCount, int testSplitStart);
1:29a7f38:   }
1:29a7f38: 
1:29a7f38: }
============================================================================
author:Suneel Marthi
-------------------------------------------------------------------------------
commit:85f9ece
/////////////////////////////////////////////////////////////////////////
1: import java.io.BufferedReader;
1: import java.io.IOException;
1: import java.io.InputStreamReader;
1: import java.io.OutputStreamWriter;
1: import java.io.Writer;
1: import java.nio.charset.Charset;
1: import java.util.BitSet;
1: 
1: import org.apache.commons.io.Charsets;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset));
1:            Writer trainingWriter = new OutputStreamWriter(fs.create(trainingOutputFile), charset);
1:            Writer testWriter = new OutputStreamWriter(fs.create(testOutputFile), charset)){
/////////////////////////////////////////////////////////////////////////
1:       try (SequenceFileIterator<Writable, Writable> iterator =
1:                new SequenceFileIterator<>(inputFile, false, fs.getConf());
1:            SequenceFile.Writer trainingWriter = SequenceFile.createWriter(fs, fs.getConf(), trainingOutputFile,
1:                iterator.getKeyClass(), iterator.getValueClass());
1:            SequenceFile.Writer testWriter = SequenceFile.createWriter(fs, fs.getConf(), testOutputFile,
1:                iterator.getKeyClass(), iterator.getValueClass())) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset))){
commit:87c15be
/////////////////////////////////////////////////////////////////////////
0:     if (!fs.getFileStatus(inputDir).isDirectory()) {
/////////////////////////////////////////////////////////////////////////
0:         if (!inputFile.isDirectory()) {
/////////////////////////////////////////////////////////////////////////
0:     if (fs.getFileStatus(inputFile).isDirectory()) {
/////////////////////////////////////////////////////////////////////////
0:               new SequenceFileIterator<>(inputFile, false, fs.getConf());
/////////////////////////////////////////////////////////////////////////
0:       Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDirectory(),
0:       Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDirectory(),
author:Stevo Slavic
-------------------------------------------------------------------------------
commit:a4f24dd
/////////////////////////////////////////////////////////////////////////
1:         if (!inputFile.isDir()) {
author:pferrel
-------------------------------------------------------------------------------
commit:b988c49
/////////////////////////////////////////////////////////////////////////
1:     if (!fs.getFileStatus(inputDir).isDir()) {
/////////////////////////////////////////////////////////////////////////
1:     if (fs.getFileStatus(inputFile).isDir()) {
/////////////////////////////////////////////////////////////////////////
1:       Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDir(),
1:       Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDir(),
author:smarthi
-------------------------------------------------------------------------------
commit:cd167f9
/////////////////////////////////////////////////////////////////////////
1:         "Invalid testSplitSize: " + testSplitSize + ". Must be: testSplitSize >= 1 or testSplitSize = -1");
1:         "Invalid splitLocation percentage: " + splitLocation + ". Must be: 0 <= splitLocation <= 100 or splitLocation = -1");
1:         "Invalid testSplitPct percentage: " + testSplitPct + ". Must be: 0 <= testSplitPct <= 100 or testSplitPct = -1");
1:             || testRandomSelectionPct == -1,"Invalid testRandomSelectionPct percentage: " + testRandomSelectionPct +
1:         ". Must be: 0 <= testRandomSelectionPct <= 100 or testRandomSelectionPct = -1");
/////////////////////////////////////////////////////////////////////////
1:           "%s is not a directory", trainingOutputDirectory);
1:           "%s is not a directory", testOutputDirectory);
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:58cc1ae
/////////////////////////////////////////////////////////////////////////
1:   public void splitDirectory(Configuration conf, Path inputDir)
1:     throws IOException, ClassNotFoundException, InterruptedException {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:6d16230
/////////////////////////////////////////////////////////////////////////
1:     addOption("splitLocation", "sl", "Location for start of test data expressed as a percentage of the input file "
1:         + "size (0=start, 50=middle, 100=end", false);
1:     addOption("randomSelectionPct", "rp", "Percentage of items to be randomly selected as test data when using "
1:         + "mapreduce mode", false);
1:     addOption("charset", "c", "The name of the character encoding of the input files (not needed if using "
1:         + "SequenceFiles)", false);
1:     addOption("keepPct", "k", "The percentage of total data to keep in map-reduce mode, the rest will be ignored.  "
1:         + "Default is 100%", false);
/////////////////////////////////////////////////////////////////////////
1:         throw new OptionException(getCLIOption("testSplitPct"), "must have either split size or split percentage "
1:             + "option, not BOTH");
/////////////////////////////////////////////////////////////////////////
1:     Preconditions.checkArgument(count == 1, "Exactly one of testSplitSize, testSplitPct, testRandomSelectionSize, "
1:         + "testRandomSelectionPct should be set");
commit:3c22856
/////////////////////////////////////////////////////////////////////////
0:     addOption("splitLocation", "sl", "Location for start of test data expressed as a percentage of the input file " +
0:         "size (0=start, 50=middle, 100=end", false);
0:     addOption("randomSelectionPct", "rp", "Percentage of items to be randomly selected as test data when using " +
0:         "mapreduce mode", false);
0:     addOption("charset", "c", "The name of the character encoding of the input files (not needed if using " +
0:         "SequenceFiles)", false);
1:     addOption(buildOption("sequenceFiles", "seq", "Set if the input files are sequence files.  Default is false",
1:         false, false, "false"));
0:     addOption("keepPct", "k", "The percentage of total data to keep in map-reduce mode, the rest will be ignored.  " +
0:         "Default is 100%", false);
/////////////////////////////////////////////////////////////////////////
0:         throw new OptionException(getCLIOption("testSplitPct"), "must have either split size or split percentage " +
0:             "option, not BOTH");
/////////////////////////////////////////////////////////////////////////
0:       SequenceFile.Writer trainingWriter = SequenceFile.createWriter(fs, fs.getConf(), trainingOutputFile,
0:           iterator.getKeyClass(), iterator.getValueClass());
0:       SequenceFile.Writer testWriter = SequenceFile.createWriter(fs, fs.getConf(), testOutputFile,
0:           iterator.getKeyClass(), iterator.getValueClass());
/////////////////////////////////////////////////////////////////////////
1:     Preconditions.checkArgument(trainingOutputDirectory != null || useMapRed,
1:         "No training output directory was specified");
/////////////////////////////////////////////////////////////////////////
0:     Preconditions.checkArgument(count == 1, "Exactly one of testSplitSize, testSplitPct, testRandomSelectionSize, " +
0:         "testRandomSelectionPct should be set");
author:Grant Ingersoll
-------------------------------------------------------------------------------
commit:31cb292
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(reader, true);
0:         Closeables.close(trainingWriter, false);
0:         Closeables.close(testWriter, false);
/////////////////////////////////////////////////////////////////////////
0:         Closeables.close(iterator, true);
0:         Closeables.close(trainingWriter, false);
0:         Closeables.close(testWriter, false);
/////////////////////////////////////////////////////////////////////////
0:       Closeables.close(reader, true);
commit:e6a308b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.util.ToolRunner;
1: import org.apache.mahout.common.AbstractJob;
/////////////////////////////////////////////////////////////////////////
1: public class SplitInput extends AbstractJob {
/////////////////////////////////////////////////////////////////////////
1:   private int keepPct = 100;
1:   private boolean useMapRed;
1:   private Path mapRedOutputDirectory;
1:   @Override
1:   public int run(String[] args) throws Exception {
1: 
1:     if (parseArgs(args)) {
1:       splitDirectory();
1:     return 0;
1:   }
1: 
1:   public static void main(String[] args) throws Exception {
1:     ToolRunner.run(new Configuration(), new SplitInput(), args);
1: 
/////////////////////////////////////////////////////////////////////////
1:   private boolean parseArgs(String[] args) throws Exception {
1:     addInputOption();
1:     addOption("trainingOutput", "tr", "The training data output directory", false);
1:     addOption("testOutput", "te", "The test data output directory", false);
1:     addOption("testSplitSize", "ss", "The number of documents held back as test data for each category", false);
1:     addOption("testSplitPct", "sp", "The % of documents held back as test data for each category", false);
0:     addOption("splitLocation", "sl", "Location for start of test data expressed as a percentage of the input file size (0=start, 50=middle, 100=end", false);
1:     addOption("randomSelectionSize", "rs", "The number of items to be randomly selected as test data ", false);
0:     addOption("randomSelectionPct", "rp", "Percentage of items to be randomly selected as test data when using mapreduce mode", false);
0:     addOption("charset", "c", "The name of the character encoding of the input files (not needed if using SequenceFiles)", false);
0:     addOption(buildOption("sequenceFiles", "seq", "Set if the input files are sequence files.  Default is false", false, false, "false"));
1:     addOption(DefaultOptionCreator.methodOption().create());
1:     addOption(DefaultOptionCreator.overwriteOption().create());
1:     //TODO: extend this to sequential mode
0:     addOption("keepPct", "k", "The percentage of total data to keep in map-reduce mode, the rest will be ignored.  Default is 100%", false);
1:     addOption("mapRedOutputDir", "mro", "Output directory for map reduce jobs", false);
1:     if (parseArguments(args) == null) {
1:       return false;
1:     }
1:       inputDirectory = getInputPath();
1:       useMapRed = getOption(DefaultOptionCreator.METHOD_OPTION).equalsIgnoreCase(DefaultOptionCreator.MAPREDUCE_METHOD);
1:       if (useMapRed) {
1:         if (!hasOption("randomSelectionPct")) {
1:           throw new OptionException(getCLIOption("randomSelectionPct"),
1:                   "must set randomSelectionPct when mapRed option is used");
1:         }
1:         if (!hasOption("mapRedOutputDir")) {
1:           throw new OptionException(getCLIOption("mapRedOutputDir"),
1:                   "mapRedOutputDir must be set when mapRed option is used");
1:         } else {
0:           mapRedOutputDirectory =
0:                   new Path((String) getOption("mapRedOutputDir"));
1:         }
1:         if (hasOption("keepPct")) {
0:           keepPct =
0:                   Integer.parseInt((String) getOption("keepPct"));
1:         }
1:         if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:           HadoopUtil.delete(getConf(), mapRedOutputDirectory);
1:         }
1:       } else {
1:         if (!hasOption("trainingOutput")
1:                 || !hasOption("testOutput")) {
1:           throw new OptionException(getCLIOption("trainingOutput"),
1:                   "trainingOutput and testOutput must be set if mapRed option is not used");
1:         }
1:         if (!hasOption("testSplitSize")
1:                 && !hasOption("testSplitPct")
1:                 && !hasOption("randomSelectionPct")
1:                 && !hasOption("randomSelectionSize")) {
1:           throw new OptionException(getCLIOption("testSplitSize"),
1:                   "must set one of test split size/percentage or randomSelectionSize/percentage");
1:         }
1: 
0:         trainingOutputDirectory =
0:                 new Path((String) getOption("trainingOutput"));
0:         testOutputDirectory =
0:                 new Path((String) getOption("testOutput"));
1:         FileSystem fs = trainingOutputDirectory.getFileSystem(getConf());
1:         if (hasOption(DefaultOptionCreator.OVERWRITE_OPTION)) {
1:           HadoopUtil.delete(fs.getConf(), trainingOutputDirectory);
1:           HadoopUtil.delete(fs.getConf(), testOutputDirectory);
1:         }
1:         fs.mkdirs(trainingOutputDirectory);
1:         fs.mkdirs(testOutputDirectory);
1:       if (hasOption("charset")) {
0:         charset = Charset.forName((String) getOption("charset"));
1:       if (hasOption("testSplitSize") && hasOption("testSplitPct")) {
0:         throw new OptionException(getCLIOption("testSplitPct"), "must have either split size or split percentage option, not BOTH");
1:       if (hasOption("testSplitSize")) {
1:         setTestSplitSize(Integer.parseInt(getOption("testSplitSize")));
1:       if (hasOption("testSplitPct")) {
1:         setTestSplitPct(Integer.parseInt(getOption("testSplitPct")));
1:       if (hasOption("splitLocation")) {
1:         setSplitLocation(Integer.parseInt(getOption("splitLocation")));
1:       if (hasOption("randomSelectionSize")) {
1:         setTestRandomSelectionSize(Integer.parseInt(getOption("randomSelectionSize")));
1:       if (hasOption("randomSelectionPct")) {
1:         setTestRandomSelectionPct(Integer.parseInt(getOption("randomSelectionPct")));
1:       useSequence = hasOption("sequenceFiles");
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConf();
0:     if (conf == null) {
0:       conf = new Configuration();
1:     }
1:     FileSystem fs = inputDir.getFileSystem(conf);
/////////////////////////////////////////////////////////////////////////
1:     if (useMapRed) {
0:       SplitInputJob.run(new Configuration(), inputDir, mapRedOutputDirectory,
1:               keepPct, testRandomSelectionPct);
1:     } else {
1:       // input dir contains one file per category.
1:       FileStatus[] fileStats = fs.listStatus(inputDir, PathFilters.logsCRCFilter());
1:       for (FileStatus inputFile : fileStats) {
0:         if (!inputFile.isDir()) {
1:           splitFile(inputFile.getPath());
1:         }
/////////////////////////////////////////////////////////////////////////
1:     Configuration conf = getConf();
0:     if (conf == null) {
0:       conf = new Configuration();
1:     }
1:     FileSystem fs = inputFile.getFileSystem(conf);
/////////////////////////////////////////////////////////////////////////
0:       SequenceFileIterator<Writable, Writable> iterator =
0:               new SequenceFileIterator<Writable, Writable>(inputFile, false, fs.getConf());
/////////////////////////////////////////////////////////////////////////
1:           Pair<Writable, Writable> pair = iterator.next();
/////////////////////////////////////////////////////////////////////////
1:   /**
1:    * Sets the percentage of the input data to keep in a map reduce split input job
1:    *
1:    * @param keepPct a value between 0 and 100 inclusive.
1:    */
1:   public void setKeepPct(int keepPct) {
1:     this.keepPct = keepPct;
1:   }
1: 
1:   /**
1:    * Set to true to use map reduce to split the input
1:    *
1:    * @param useMapRed a boolean to indicate whether map reduce should be used
1:    */
1:   public void setUseMapRed(boolean useMapRed) {
1:     this.useMapRed = useMapRed;
1:   }
1: 
1:   public void setMapRedOutputDirectory(Path mapRedOutputDirectory) {
1:     this.mapRedOutputDirectory = mapRedOutputDirectory;
1:   }
1: 
/////////////////////////////////////////////////////////////////////////
0:     Preconditions.checkArgument(trainingOutputDirectory != null || useMapRed, "No training output directory was specified");
1:     Preconditions.checkArgument(testOutputDirectory != null || useMapRed, "No test output directory was specified");
/////////////////////////////////////////////////////////////////////////
1:     if (!useMapRed) {
1:       Configuration conf = getConf();
0:       if (conf == null) {
0:         conf = new Configuration();
1:       }
1:       FileSystem fs = trainingOutputDirectory.getFileSystem(conf);
1:       FileStatus trainingOutputDirStatus = fs.getFileStatus(trainingOutputDirectory);
0:       Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDir(),
0:               "%s is not a directory", trainingOutputDirectory);
1:       FileStatus testOutputDirStatus = fs.getFileStatus(testOutputDirectory);
0:       Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDir(),
0:               "%s is not a directory", testOutputDirectory);
1:     }
commit:29a7f38
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.utils;
1: 
0: import com.google.common.base.Charsets;
1: import com.google.common.base.Preconditions;
0: import com.google.common.io.Closeables;
0: import org.apache.commons.cli2.CommandLine;
0: import org.apache.commons.cli2.Group;
0: import org.apache.commons.cli2.Option;
1: import org.apache.commons.cli2.OptionException;
0: import org.apache.commons.cli2.builder.ArgumentBuilder;
0: import org.apache.commons.cli2.builder.DefaultOptionBuilder;
0: import org.apache.commons.cli2.builder.GroupBuilder;
0: import org.apache.commons.cli2.commandline.Parser;
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.FileStatus;
1: import org.apache.hadoop.fs.FileSystem;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.SequenceFile;
1: import org.apache.mahout.common.CommandLineUtil;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.Pair;
1: import org.apache.mahout.common.RandomUtils;
1: import org.apache.mahout.common.commandline.DefaultOptionCreator;
1: import org.apache.mahout.common.iterator.sequencefile.PathFilters;
0: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterable;
1: import org.apache.mahout.common.iterator.sequencefile.SequenceFileIterator;
1: import org.apache.mahout.math.jet.random.sampling.RandomSampler;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1: 
0: import java.io.BufferedReader;
0: import java.io.IOException;
0: import java.io.InputStreamReader;
0: import java.io.OutputStreamWriter;
0: import java.io.Writer;
0: import java.nio.charset.Charset;
0: import java.util.BitSet;
1: 
1: /**
1:  * A utility for splitting files in the input format used by the Bayes
1:  * classifiers or anything else that has one item per line or SequenceFiles (key/value)
1:  * into training and test sets in order to perform cross-validation.
1:  * <p/>
1:  * <p/>
1:  * This class can be used to split directories of files or individual files into
1:  * training and test sets using a number of different methods.
1:  * <p/>
1:  * When executed via {@link #splitDirectory(Path)} or {@link #splitFile(Path)},
1:  * the lines read from one or more, input files are written to files of the same
1:  * name into the directories specified by the
1:  * {@link #setTestOutputDirectory(Path)} and
1:  * {@link #setTrainingOutputDirectory(Path)} methods.
1:  * <p/>
1:  * The composition of the test set is determined using one of the following
1:  * approaches:
1:  * <ul>
1:  * <li>A contiguous set of items can be chosen from the input file(s) using the
1:  * {@link #setTestSplitSize(int)} or {@link #setTestSplitPct(int)} methods.
1:  * {@link #setTestSplitSize(int)} allocates a fixed number of items, while
1:  * {@link #setTestSplitPct(int)} allocates a percentage of the original input,
1:  * rounded up to the nearest integer. {@link #setSplitLocation(int)} is used to
1:  * control the position in the input from which the test data is extracted and
1:  * is described further below.</li>
1:  * <li>A random sampling of items can be chosen from the input files(s) using
1:  * the {@link #setTestRandomSelectionSize(int)} or
1:  * {@link #setTestRandomSelectionPct(int)} methods, each choosing a fixed test
1:  * set size or percentage of the input set size as described above. The
1:  * {@link RandomSampler} class from {@code mahout-math} is used to create a sample
1:  * of the appropriate size.</li>
1:  * </ul>
1:  * <p/>
1:  * Any one of the methods above can be used to control the size of the test set.
1:  * If multiple methods are called, a runtime exception will be thrown at
1:  * execution time.
1:  * <p/>
1:  * The {@link #setSplitLocation(int)} method is passed an integer from 0 to 100
1:  * (inclusive) which is translated into the position of the start of the test
1:  * data within the input file.
1:  * <p/>
1:  * Given:
1:  * <ul>
1:  * <li>an input file of 1500 lines</li>
1:  * <li>a desired test data size of 10 percent</li>
1:  * </ul>
1:  * <p/>
1:  * <ul>
1:  * <li>A split location of 0 will cause the first 150 items appearing in the
1:  * input set to be written to the test set.</li>
1:  * <li>A split location of 25 will cause items 375-525 to be written to the test
1:  * set.</li>
1:  * <li>A split location of 100 will cause the last 150 items in the input to be
1:  * written to the test set</li>
1:  * </ul>
1:  * The start of the split will always be adjusted forwards in order to ensure
1:  * that the desired test set size is allocated. Split location has no effect is
1:  * random sampling is employed.
1:  */
0: public class SplitInput {
1: 
1:   private static final Logger log = LoggerFactory.getLogger(SplitInput.class);
1: 
1:   private int testSplitSize = -1;
1:   private int testSplitPct = -1;
1:   private int splitLocation = 100;
1:   private int testRandomSelectionSize = -1;
1:   private int testRandomSelectionPct = -1;
1:   private Charset charset = Charsets.UTF_8;
1:   private boolean useSequence;
1: 
0:   private final FileSystem fs;
1:   private Path inputDirectory;
1:   private Path trainingOutputDirectory;
1:   private Path testOutputDirectory;
1: 
1:   private SplitCallback callback;
1: 
0:   public static void main(String[] args) throws Exception {
0:     SplitInput si = new SplitInput();
0:     if (si.parseArgs(args)) {
0:       si.splitDirectory();
1:     }
1:   }
1: 
0:   public SplitInput() throws IOException {
0:     Configuration conf = new Configuration();
0:     fs = FileSystem.get(conf);
1:   }
1: 
1:   /**
1:    * Configure this instance based on the command-line arguments contained within provided array.
1:    * Calls {@link #validate()} to ensure consistency of configuration.
1:    *
1:    * @return true if the arguments were parsed successfully and execution should proceed.
1:    * @throws Exception if there is a problem parsing the command-line arguments or the particular
1:    *                   combination would violate class invariants.
1:    */
0:   public boolean parseArgs(String[] args) throws Exception {
1: 
0:     DefaultOptionBuilder obuilder = new DefaultOptionBuilder();
0:     ArgumentBuilder abuilder = new ArgumentBuilder();
0:     GroupBuilder gbuilder = new GroupBuilder();
0:     Option helpOpt = DefaultOptionCreator.helpOption();
1: 
0:     Option inputDirOpt = obuilder.withLongName("input").withRequired(true).withArgument(
0:             abuilder.withName("input").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The input directory").withShortName("i").create();
1: 
0:     Option trainingOutputDirOpt = obuilder.withLongName("trainingOutput").withRequired(true).withArgument(
0:             abuilder.withName("outputDir").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The training data output directory").withShortName("tr").create();
1: 
0:     Option testOutputDirOpt = obuilder.withLongName("testOutput").withRequired(true).withArgument(
0:             abuilder.withName("outputDir").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The test data output directory").withShortName("te").create();
1: 
0:     Option testSplitSizeOpt = obuilder.withLongName("testSplitSize").withRequired(false).withArgument(
0:             abuilder.withName("splitSize").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The number of documents held back as test data for each category").withShortName("ss").create();
1: 
0:     Option testSplitPctOpt = obuilder.withLongName("testSplitPct").withRequired(false).withArgument(
0:             abuilder.withName("splitPct").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The percentage of documents held back as test data for each category").withShortName("sp").create();
1: 
0:     Option splitLocationOpt = obuilder.withLongName("splitLocation").withRequired(false).withArgument(
0:             abuilder.withName("splitLoc").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "Location for start of test data expressed as a percentage of the input file size (0=start, 50=middle, 100=end")
0:             .withShortName("sl").create();
1: 
0:     Option randomSelectionSizeOpt = obuilder.withLongName("randomSelectionSize").withRequired(false).withArgument(
0:             abuilder.withName("randomSize").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The number of items to be randomly selected as test data ").withShortName("rs").create();
1: 
0:     Option randomSelectionPctOpt = obuilder.withLongName("randomSelectionPct").withRequired(false).withArgument(
0:             abuilder.withName("randomPct").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "Percentage of items to be randomly selected as test data ").withShortName("rp").create();
1: 
0:     Option charsetOpt = obuilder.withLongName("charset").withRequired(false).withArgument(
0:             abuilder.withName("charset").withMinimum(1).withMaximum(1).create()).withDescription(
0:             "The name of the character encoding of the input files (not needed if using SequenceFiles)").withShortName("c").create();
0:     Option sequenceFileOpt = obuilder.withLongName("sequenceFiles").withRequired(false).
0:             withDescription("Set if the input files are sequence files.  Default is false").withShortName("seq").create();
1: 
0:     Option overOpt = DefaultOptionCreator.overwriteOption().create();
0:     Group group = gbuilder.withName("Options").withOption(inputDirOpt).withOption(trainingOutputDirOpt)
0:             .withOption(testOutputDirOpt).withOption(testSplitSizeOpt).withOption(testSplitPctOpt)
0:             .withOption(splitLocationOpt).withOption(randomSelectionSizeOpt).withOption(randomSelectionPctOpt)
0:             .withOption(charsetOpt).withOption(sequenceFileOpt).withOption(overOpt).create();
1: 
1:     try {
1: 
0:       Parser parser = new Parser();
0:       parser.setGroup(group);
0:       CommandLine cmdLine = parser.parse(args);
1: 
0:       if (cmdLine.hasOption(helpOpt)) {
0:         CommandLineUtil.printHelp(group);
1:         return false;
1:       }
1: 
0:       inputDirectory = new Path((String) cmdLine.getValue(inputDirOpt));
0:       trainingOutputDirectory = new Path((String) cmdLine.getValue(trainingOutputDirOpt));
0:       testOutputDirectory = new Path((String) cmdLine.getValue(testOutputDirOpt));
0:       if (cmdLine.hasOption(overOpt)) {
0:         HadoopUtil.delete(fs.getConf(), trainingOutputDirectory);
0:         HadoopUtil.delete(fs.getConf(), testOutputDirectory);
1:       }
1: 
0:       if (cmdLine.hasOption(charsetOpt)) {
0:         charset = Charset.forName((String) cmdLine.getValue(charsetOpt));
1:       }
1: 
0:       if (cmdLine.hasOption(testSplitSizeOpt) && cmdLine.hasOption(testSplitPctOpt)) {
0:         throw new OptionException(testSplitSizeOpt, "must have either split size or split percentage option, not BOTH");
0:       } else if (!cmdLine.hasOption(testSplitSizeOpt) && !cmdLine.hasOption(testSplitPctOpt) && !cmdLine.hasOption(randomSelectionPctOpt) && !cmdLine.hasOption(randomSelectionSizeOpt)) {
0:         throw new OptionException(testSplitSizeOpt, "must set one of test split size/percentage or randomSelectionSize/percentage");
1:       }
1: 
0:       if (cmdLine.hasOption(testSplitSizeOpt)) {
0:         setTestSplitSize(Integer.parseInt((String) cmdLine.getValue(testSplitSizeOpt)));
1:       }
1: 
0:       if (cmdLine.hasOption(testSplitPctOpt)) {
0:         setTestSplitPct(Integer.parseInt((String) cmdLine.getValue(testSplitPctOpt)));
1:       }
1: 
0:       if (cmdLine.hasOption(splitLocationOpt)) {
0:         setSplitLocation(Integer.parseInt((String) cmdLine.getValue(splitLocationOpt)));
1:       }
1: 
0:       if (cmdLine.hasOption(randomSelectionSizeOpt)) {
0:         setTestRandomSelectionSize(Integer.parseInt((String) cmdLine.getValue(randomSelectionSizeOpt)));
1:       }
1: 
0:       if (cmdLine.hasOption(randomSelectionPctOpt)) {
0:         setTestRandomSelectionPct(Integer.parseInt((String) cmdLine.getValue(randomSelectionPctOpt)));
1:       }
0:       useSequence = cmdLine.hasOption(sequenceFileOpt);
0:       fs.mkdirs(trainingOutputDirectory);
0:       fs.mkdirs(testOutputDirectory);
1: 
1:     } catch (OptionException e) {
1:       log.error("Command-line option Exception", e);
0:       CommandLineUtil.printHelp(group);
1:       return false;
1:     }
1: 
1:     validate();
1:     return true;
1:   }
1: 
1:   /**
1:    * Perform a split on directory specified by {@link #setInputDirectory(Path)} by calling {@link #splitFile(Path)}
1:    * on each file found within that directory.
1:    */
0:   public void splitDirectory() throws IOException {
1:     this.splitDirectory(inputDirectory);
1:   }
1: 
1:   /**
1:    * Perform a split on the specified directory by calling {@link #splitFile(Path)} on each file found within that
1:    * directory.
1:    */
0:   public void splitDirectory(Path inputDir) throws IOException {
1:     if (fs.getFileStatus(inputDir) == null) {
1:       throw new IOException(inputDir + " does not exist");
0:     } else if (!fs.getFileStatus(inputDir).isDir()) {
1:       throw new IOException(inputDir + " is not a directory");
1:     }
1: 
0:     // input dir contains one file per category.
0:     FileStatus[] fileStats = fs.listStatus(inputDir, PathFilters.logsCRCFilter());
0:     for (FileStatus inputFile : fileStats) {
0:       if (!inputFile.isDir()) {
0:         splitFile(inputFile.getPath());
1:       }
1:     }
1:   }
1: 
1: 
1:   /**
1:    * Perform a split on the specified input file. Results will be written to files of the same name in the specified
1:    * training and test output directories. The {@link #validate()} method is called prior to executing the split.
1:    */
1:   public void splitFile(Path inputFile) throws IOException {
1:     if (fs.getFileStatus(inputFile) == null) {
1:       throw new IOException(inputFile + " does not exist");
0:     } else if (fs.getFileStatus(inputFile).isDir()) {
1:       throw new IOException(inputFile + " is a directory");
1:     }
1: 
1:     validate();
1: 
1:     Path testOutputFile = new Path(testOutputDirectory, inputFile.getName());
1:     Path trainingOutputFile = new Path(trainingOutputDirectory, inputFile.getName());
1: 
1:     int lineCount = countLines(fs, inputFile, charset);
1: 
1:     log.info("{} has {} lines", inputFile.getName(), lineCount);
1: 
1:     int testSplitStart = 0;
1:     int testSplitSize = this.testSplitSize; // don't modify state
1:     BitSet randomSel = null;
1: 
1:     if (testRandomSelectionPct > 0 || testRandomSelectionSize > 0) {
1:       testSplitSize = this.testRandomSelectionSize;
1: 
1:       if (testRandomSelectionPct > 0) {
1:         testSplitSize = Math.round(lineCount * testRandomSelectionPct / 100.0f);
1:       }
1:       log.info("{} test split size is {} based on random selection percentage {}",
0:               new Object[]{inputFile.getName(), testSplitSize, testRandomSelectionPct});
1:       long[] ridx = new long[testSplitSize];
1:       RandomSampler.sample(testSplitSize, lineCount - 1, testSplitSize, 0, ridx, 0, RandomUtils.getRandom());
1:       randomSel = new BitSet(lineCount);
1:       for (long idx : ridx) {
1:         randomSel.set((int) idx + 1);
1:       }
1:     } else {
1:       if (testSplitPct > 0) { // calculate split size based on percentage
1:         testSplitSize = Math.round(lineCount * testSplitPct / 100.0f);
1:         log.info("{} test split size is {} based on percentage {}",
0:                 new Object[]{inputFile.getName(), testSplitSize, testSplitPct});
1:       } else {
1:         log.info("{} test split size is {}", inputFile.getName(), testSplitSize);
1:       }
1: 
1:       if (splitLocation > 0) { // calculate start of split based on percentage
1:         testSplitStart = Math.round(lineCount * splitLocation / 100.0f);
1:         if (lineCount - testSplitStart < testSplitSize) {
1:           // adjust split start downwards based on split size.
1:           testSplitStart = lineCount - testSplitSize;
1:         }
1:         log.info("{} test split start is {} based on split location {}",
0:                 new Object[]{inputFile.getName(), testSplitStart, splitLocation});
1:       }
1: 
1:       if (testSplitStart < 0) {
1:         throw new IllegalArgumentException("test split size for " + inputFile + " is too large, it would produce an "
1:                 + "empty training set from the initial set of " + lineCount + " examples");
1:       } else if (lineCount - testSplitSize < testSplitSize) {
1:         log.warn("Test set size for {} may be too large, {} is larger than the number of "
1:                 + "lines remaining in the training set: {}",
0:                 new Object[]{inputFile, testSplitSize, lineCount - testSplitSize});
1:       }
1:     }
1:     int trainCount = 0;
1:     int testCount = 0;
0:     if (useSequence == false) {
0:       BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset));
0:       Writer trainingWriter = new OutputStreamWriter(fs.create(trainingOutputFile), charset);
0:       Writer testWriter = new OutputStreamWriter(fs.create(testOutputFile), charset);
1: 
1: 
1:       try {
1: 
1:         String line;
1:         int pos = 0;
1:         while ((line = reader.readLine()) != null) {
1:           pos++;
1: 
1:           Writer writer;
1:           if (testRandomSelectionPct > 0) { // Randomly choose
1:             writer = randomSel.get(pos) ? testWriter : trainingWriter;
1:           } else { // Choose based on location
1:             writer = pos > testSplitStart ? testWriter : trainingWriter;
1:           }
1: 
1:           if (writer == testWriter) {
1:             if (testCount >= testSplitSize) {
1:               writer = trainingWriter;
1:             } else {
1:               testCount++;
1:             }
1:           }
1:           if (writer == trainingWriter) {
1:             trainCount++;
1:           }
1:           writer.write(line);
1:           writer.write('\n');
1:         }
1: 
0:       } finally {
0:         Closeables.closeQuietly(reader);
0:         Closeables.closeQuietly(trainingWriter);
0:         Closeables.closeQuietly(testWriter);
1:       }
1:     } else {
0:       SequenceFileIterable iter = new SequenceFileIterable(inputFile, fs.getConf());
0:       SequenceFileIterator iterator = (SequenceFileIterator) iter.iterator();
0:       SequenceFile.Writer trainingWriter = SequenceFile.createWriter(fs, fs.getConf(), trainingOutputFile, iterator.getKeyClass(), iterator.getValueClass());
0:       SequenceFile.Writer testWriter = SequenceFile.createWriter(fs, fs.getConf(), testOutputFile, iterator.getKeyClass(), iterator.getValueClass());
1:       try {
1: 
1:         String line;
1:         int pos = 0;
1:         SequenceFile.Writer writer;
1:         while (iterator.hasNext()) {
1:           pos++;
1:           if (testRandomSelectionPct > 0) { // Randomly choose
1:             writer = randomSel.get(pos) ? testWriter : trainingWriter;
1:           } else { // Choose based on location
1:             writer = pos > testSplitStart ? testWriter : trainingWriter;
1:           }
1: 
1:           if (writer == testWriter) {
1:             if (testCount >= testSplitSize) {
1:               writer = trainingWriter;
1:             } else {
1:               testCount++;
1:             }
1:           }
1:           if (writer == trainingWriter) {
1:             trainCount++;
1:           }
0:           Pair pair = (Pair) iterator.next();
1:           writer.append(pair.getFirst(), pair.getSecond());
1:         }
1: 
0:       } finally {
0:         Closeables.closeQuietly(iterator);
0:         Closeables.closeQuietly(trainingWriter);
0:         Closeables.closeQuietly(testWriter);
1:       }
1:     }
1:     log.info("file: {}, input: {} train: {}, test: {} starting at {}",
0:             new Object[]{inputFile.getName(), lineCount, trainCount, testCount, testSplitStart});
1: 
1:     // testing;
1:     if (callback != null) {
1:       callback.splitComplete(inputFile, lineCount, trainCount, testCount, testSplitStart);
1:     }
1:   }
1: 
1:   public int getTestSplitSize() {
1:     return testSplitSize;
1:   }
1: 
1:   public void setTestSplitSize(int testSplitSize) {
1:     this.testSplitSize = testSplitSize;
1:   }
1: 
1:   public int getTestSplitPct() {
1:     return testSplitPct;
1:   }
1: 
1:   /**
1:    * Sets the percentage of the input data to allocate to the test split
1:    *
1:    * @param testSplitPct a value between 0 and 100 inclusive.
1:    */
1:   public void setTestSplitPct(int testSplitPct) {
1:     this.testSplitPct = testSplitPct;
1:   }
1: 
1:   public int getSplitLocation() {
1:     return splitLocation;
1:   }
1: 
1:   /**
1:    * Set the location of the start of the test/training data split. Expressed as percentage of lines, for example
1:    * 0 indicates that the test data should be taken from the start of the file, 100 indicates that the test data
1:    * should be taken from the end of the input file, while 25 indicates that the test data should be taken from the
1:    * first quarter of the file.
1:    * <p/>
1:    * This option is only relevant in cases where random selection is not employed
1:    *
1:    * @param splitLocation a value between 0 and 100 inclusive.
1:    */
1:   public void setSplitLocation(int splitLocation) {
1:     this.splitLocation = splitLocation;
1:   }
1: 
1:   public Charset getCharset() {
1:     return charset;
1:   }
1: 
1:   /**
1:    * Set the charset used to read and write files
1:    */
1:   public void setCharset(Charset charset) {
1:     this.charset = charset;
1:   }
1: 
1:   public Path getInputDirectory() {
1:     return inputDirectory;
1:   }
1: 
1:   /**
1:    * Set the directory from which input data will be read when the the {@link #splitDirectory()} method is invoked
1:    */
1:   public void setInputDirectory(Path inputDir) {
1:     this.inputDirectory = inputDir;
1:   }
1: 
1:   public Path getTrainingOutputDirectory() {
1:     return trainingOutputDirectory;
1:   }
1: 
1:   /**
1:    * Set the directory to which training data will be written.
1:    */
1:   public void setTrainingOutputDirectory(Path trainingOutputDir) {
1:     this.trainingOutputDirectory = trainingOutputDir;
1:   }
1: 
1:   public Path getTestOutputDirectory() {
1:     return testOutputDirectory;
1:   }
1: 
1:   /**
1:    * Set the directory to which test data will be written.
1:    */
1:   public void setTestOutputDirectory(Path testOutputDir) {
1:     this.testOutputDirectory = testOutputDir;
1:   }
1: 
1:   public SplitCallback getCallback() {
1:     return callback;
1:   }
1: 
1:   /**
1:    * Sets the callback used to inform the caller that an input file has been successfully split
1:    */
1:   public void setCallback(SplitCallback callback) {
1:     this.callback = callback;
1:   }
1: 
1:   public int getTestRandomSelectionSize() {
1:     return testRandomSelectionSize;
1:   }
1: 
1:   /**
1:    * Sets number of random input samples that will be saved to the test set.
1:    */
1:   public void setTestRandomSelectionSize(int testRandomSelectionSize) {
1:     this.testRandomSelectionSize = testRandomSelectionSize;
1:   }
1: 
1:   public int getTestRandomSelectionPct() {
1: 
1:     return testRandomSelectionPct;
1:   }
1: 
1:   /**
1:    * Sets number of random input samples that will be saved to the test set as a percentage of the size of the
1:    * input set.
1:    *
1:    * @param randomSelectionPct a value between 0 and 100 inclusive.
1:    */
1:   public void setTestRandomSelectionPct(int randomSelectionPct) {
1:     this.testRandomSelectionPct = randomSelectionPct;
1:   }
1: 
1:   /**
1:    * Validates that the current instance is in a consistent state
1:    *
1:    * @throws IllegalArgumentException if settings violate class invariants.
1:    * @throws IOException              if output directories do not exist or are not directories.
1:    */
1:   public void validate() throws IOException {
1:     Preconditions.checkArgument(testSplitSize >= 1 || testSplitSize == -1,
0:             "Invalid testSplitSize", testSplitSize);
1:     Preconditions.checkArgument(splitLocation >= 0 && splitLocation <= 100 || splitLocation == -1,
0:             "Invalid splitLocation percentage", splitLocation);
1:     Preconditions.checkArgument(testSplitPct >= 0 && testSplitPct <= 100 || testSplitPct == -1,
0:             "Invalid testSplitPct percentage", testSplitPct);
1:     Preconditions.checkArgument(splitLocation >= 0 && splitLocation <= 100 || splitLocation == -1,
0:             "Invalid splitLocation percentage", splitLocation);
1:     Preconditions.checkArgument(testRandomSelectionPct >= 0 && testRandomSelectionPct <= 100
0:             || testRandomSelectionPct == -1,
0:             "Invalid testRandomSelectionPct percentage", testRandomSelectionPct);
1: 
0:     Preconditions.checkArgument(trainingOutputDirectory != null, "No training output directory was specified");
0:     Preconditions.checkArgument(testOutputDirectory != null, "No test output directory was specified");
1: 
1:     // only one of the following may be set, one must be set.
1:     int count = 0;
1:     if (testSplitSize > 0) {
1:       count++;
1:     }
1:     if (testSplitPct > 0) {
1:       count++;
1:     }
1:     if (testRandomSelectionSize > 0) {
1:       count++;
1:     }
1:     if (testRandomSelectionPct > 0) {
1:       count++;
1:     }
1: 
0:     Preconditions.checkArgument(count == 1,
0:             "Exactly one of testSplitSize, testSplitPct, testRandomSelectionSize, testRandomSelectionPct should be set");
1: 
0:     FileStatus trainingOutputDirStatus = fs.getFileStatus(trainingOutputDirectory);
0:     Preconditions.checkArgument(trainingOutputDirStatus != null && trainingOutputDirStatus.isDir(),
0:             "%s is not a directory", trainingOutputDirectory);
0:     FileStatus testOutputDirStatus = fs.getFileStatus(testOutputDirectory);
0:     Preconditions.checkArgument(testOutputDirStatus != null && testOutputDirStatus.isDir(),
0:             "%s is not a directory", testOutputDirectory);
1:   }
1: 
1:   /**
1:    * Count the lines in the file specified as returned by {@code BufferedReader.readLine()}
1:    *
1:    * @param inputFile the file whose lines will be counted
1:    * @param charset   the charset of the file to read
1:    * @return the number of lines in the input file.
1:    * @throws IOException if there is a problem opening or reading the file.
1:    */
1:   public static int countLines(FileSystem fs, Path inputFile, Charset charset) throws IOException {
1:     int lineCount = 0;
0:     BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(inputFile), charset));
1:     try {
1:       while (reader.readLine() != null) {
1:         lineCount++;
1:       }
0:     } finally {
0:       Closeables.closeQuietly(reader);
1:     }
1: 
1:     return lineCount;
1:   }
1: 
1:   /**
1:    * Used to pass information back to a caller once a file has been split without the need for a data object
1:    */
1:   public interface SplitCallback {
1:     void splitComplete(Path inputFile, int lineCount, int trainCount, int testCount, int testSplitStart);
1:   }
1: 
1: }
author:Isabel Drost
-------------------------------------------------------------------------------
commit:e3ec9d8
/////////////////////////////////////////////////////////////////////////
1:     splitDirectory(conf, inputDir);
0:   }
0: 
1:   /*
1:    * See also splitDirectory(Path inputDir)
1:    * */
0:   public void splitDirectory(Configuration conf, Path inputDir) throws IOException, ClassNotFoundException, InterruptedException {
/////////////////////////////////////////////////////////////////////////
1:       SplitInputJob.run(conf, inputDir, mapRedOutputDirectory,
0:             keepPct, testRandomSelectionPct);
/////////////////////////////////////////////////////////////////////////
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:8396a27
/////////////////////////////////////////////////////////////////////////
1:                inputFile.getName(), testSplitSize, testRandomSelectionPct);
/////////////////////////////////////////////////////////////////////////
1:                  inputFile.getName(), testSplitSize, testSplitPct);
/////////////////////////////////////////////////////////////////////////
1:                  inputFile.getName(), testSplitStart, splitLocation);
/////////////////////////////////////////////////////////////////////////
1:                  inputFile, testSplitSize, lineCount - testSplitSize);
/////////////////////////////////////////////////////////////////////////
1:              inputFile.getName(), lineCount, trainCount, testCount, testSplitStart);
commit:051cbcf
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:       CommandLineUtil.printHelp(getGroup());
commit:822a5e1
/////////////////////////////////////////////////////////////////////////
0:   public SplitInput() {
/////////////////////////////////////////////////////////////////////////
0:                                     "mapRedOutputDir must be set when mapRed option is used");
1:         mapRedOutputDirectory = new Path(getOption("mapRedOutputDir"));
1:           keepPct = Integer.parseInt(getOption("keepPct"));
/////////////////////////////////////////////////////////////////////////
1:         trainingOutputDirectory = new Path(getOption("trainingOutput"));
1:         testOutputDirectory = new Path(getOption("testOutput"));
/////////////////////////////////////////////////////////////////////////
1:         charset = Charset.forName(getOption("charset"));
/////////////////////////////////////////////////////////////////////////
1:   public void splitDirectory() throws IOException, ClassNotFoundException, InterruptedException {
/////////////////////////////////////////////////////////////////////////
1:   public void splitDirectory(Path inputDir) throws IOException, ClassNotFoundException, InterruptedException {
commit:e0ec7c1
/////////////////////////////////////////////////////////////////////////
1: import org.apache.hadoop.io.Writable;
/////////////////////////////////////////////////////////////////////////
1:     if (!useSequence) {
/////////////////////////////////////////////////////////////////////////
0:       SequenceFileIterator<Writable,Writable> iterator =
0:           new SequenceFileIterator<Writable,Writable>(inputFile, false, fs.getConf());
0:           SequenceFile.Writer writer;
/////////////////////////////////////////////////////////////////////////
0:           Pair<Writable,Writable> pair = iterator.next();
commit:4194a28
/////////////////////////////////////////////////////////////////////////
0:       }
0:       if (!cmdLine.hasOption(testSplitSizeOpt) && !cmdLine.hasOption(testSplitPctOpt) && !cmdLine.hasOption(randomSelectionPctOpt) && !cmdLine.hasOption(randomSelectionSizeOpt)) {
/////////////////////////////////////////////////////////////////////////
0:     }
0:     if (!fs.getFileStatus(inputDir).isDir()) {
/////////////////////////////////////////////////////////////////////////
0:     }
0:     if (fs.getFileStatus(inputFile).isDir()) {
============================================================================
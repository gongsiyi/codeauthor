1:7002241: /*
1:7002241:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:7002241:  * contributor license agreements.  See the NOTICE file distributed with
1:7002241:  * this work for additional information regarding copyright ownership.
1:7002241:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:7002241:  * (the "License"); you may not use this file except in compliance with
1:7002241:  * the License.  You may obtain a copy of the License at
1:7002241:  *
1:7002241:  *     http://www.apache.org/licenses/LICENSE-2.0
1:7002241:  *
1:7002241:  * Unless required by applicable law or agreed to in writing, software
1:7002241:  * distributed under the License is distributed on an "AS IS" BASIS,
1:7002241:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:7002241:  * See the License for the specific language governing permissions and
1:7002241:  * limitations under the License.
1:7002241:  */
1:7002241: 
1:7002241: package org.apache.mahout.fpm.pfpgrowth.dataset;
1:7002241: 
1:7002241: import java.io.IOException;
1:7002241: 
1:7002241: import org.apache.hadoop.conf.Configuration;
1:7002241: import org.apache.hadoop.fs.Path;
1:7002241: import org.apache.hadoop.io.Text;
1:7002241: import org.apache.hadoop.mapreduce.Job;
1:7002241: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1:7002241: import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
1:7002241: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1:7002241: import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
1:7002241: import org.apache.mahout.common.HadoopUtil;
1:7002241: import org.apache.mahout.common.Parameters;
1:7002241: import org.apache.mahout.common.StringTuple;
1:7002241: 
1:7002241: public final class KeyBasedStringTupleGrouper {
1:7002241:   
1:7002241:   private KeyBasedStringTupleGrouper() { }
1:7002241:   
1:7002241:   public static void startJob(Parameters params) throws IOException,
1:7002241:                                                 InterruptedException,
1:7002241:                                                 ClassNotFoundException {
1:7002241:     Configuration conf = new Configuration();
1:7002241:     
1:7002241:     conf.set("job.parameters", params.toString());
1:7002241:     conf.set("mapred.compress.map.output", "true");
1:7002241:     conf.set("mapred.output.compression.type", "BLOCK");
1:7002241:     conf.set("mapred.map.output.compression.codec", "org.apache.hadoop.io.compress.GzipCodec");
1:7002241:     conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization,"
1:7002241:                                   + "org.apache.hadoop.io.serializer.WritableSerialization");
1:7002241:     
1:7002241:     String input = params.get("input");
1:7002241:     Job job = new Job(conf, "Generating dataset based from input" + input);
1:7002241:     job.setJarByClass(KeyBasedStringTupleGrouper.class);
1:7002241:     
1:7002241:     job.setMapOutputKeyClass(Text.class);
1:7002241:     job.setMapOutputValueClass(StringTuple.class);
1:7002241:     
1:7002241:     job.setOutputKeyClass(Text.class);
1:7002241:     job.setOutputValueClass(Text.class);
1:7002241:     
1:7002241:     FileInputFormat.addInputPath(job, new Path(input));
1:7002241:     Path outPath = new Path(params.get("output"));
1:7002241:     FileOutputFormat.setOutputPath(job, outPath);
1:7002241:     
1:7002241:     HadoopUtil.delete(conf, outPath);
1:7002241: 
1:7002241:     job.setInputFormatClass(TextInputFormat.class);
1:7002241:     job.setMapperClass(KeyBasedStringTupleMapper.class);
1:7002241:     job.setCombinerClass(KeyBasedStringTupleCombiner.class);
1:7002241:     job.setReducerClass(KeyBasedStringTupleReducer.class);
1:7002241:     job.setOutputFormatClass(TextOutputFormat.class);
1:7002241:     
1:7002241:     boolean succeeded = job.waitForCompletion(true);
1:7002241:     if (!succeeded) {
1:7002241:       throw new IllegalStateException("Job failed!");
1:7002241:     }
1:7002241:   }
1:7002241: }
============================================================================
author:smarthi
-------------------------------------------------------------------------------
commit:7002241
/////////////////////////////////////////////////////////////////////////
1: /*
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *     http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: 
1: package org.apache.mahout.fpm.pfpgrowth.dataset;
1: 
1: import java.io.IOException;
1: 
1: import org.apache.hadoop.conf.Configuration;
1: import org.apache.hadoop.fs.Path;
1: import org.apache.hadoop.io.Text;
1: import org.apache.hadoop.mapreduce.Job;
1: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
1: import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
1: import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
1: import org.apache.mahout.common.HadoopUtil;
1: import org.apache.mahout.common.Parameters;
1: import org.apache.mahout.common.StringTuple;
1: 
1: public final class KeyBasedStringTupleGrouper {
1:   
1:   private KeyBasedStringTupleGrouper() { }
1:   
1:   public static void startJob(Parameters params) throws IOException,
1:                                                 InterruptedException,
1:                                                 ClassNotFoundException {
1:     Configuration conf = new Configuration();
1:     
1:     conf.set("job.parameters", params.toString());
1:     conf.set("mapred.compress.map.output", "true");
1:     conf.set("mapred.output.compression.type", "BLOCK");
1:     conf.set("mapred.map.output.compression.codec", "org.apache.hadoop.io.compress.GzipCodec");
1:     conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization,"
1:                                   + "org.apache.hadoop.io.serializer.WritableSerialization");
1:     
1:     String input = params.get("input");
1:     Job job = new Job(conf, "Generating dataset based from input" + input);
1:     job.setJarByClass(KeyBasedStringTupleGrouper.class);
1:     
1:     job.setMapOutputKeyClass(Text.class);
1:     job.setMapOutputValueClass(StringTuple.class);
1:     
1:     job.setOutputKeyClass(Text.class);
1:     job.setOutputValueClass(Text.class);
1:     
1:     FileInputFormat.addInputPath(job, new Path(input));
1:     Path outPath = new Path(params.get("output"));
1:     FileOutputFormat.setOutputPath(job, outPath);
1:     
1:     HadoopUtil.delete(conf, outPath);
1: 
1:     job.setInputFormatClass(TextInputFormat.class);
1:     job.setMapperClass(KeyBasedStringTupleMapper.class);
1:     job.setCombinerClass(KeyBasedStringTupleCombiner.class);
1:     job.setReducerClass(KeyBasedStringTupleReducer.class);
1:     job.setOutputFormatClass(TextOutputFormat.class);
1:     
1:     boolean succeeded = job.waitForCompletion(true);
1:     if (!succeeded) {
1:       throw new IllegalStateException("Job failed!");
1:     }
1:   }
1: }
author:Sebastian Schelter
-------------------------------------------------------------------------------
commit:b60c909
/////////////////////////////////////////////////////////////////////////
author:Sean R. Owen
-------------------------------------------------------------------------------
commit:7c2b664
/////////////////////////////////////////////////////////////////////////
0:     boolean succeeded = job.waitForCompletion(true);
0:     if (!succeeded) {
0:       throw new IllegalStateException("Job failed!");
0:     }
commit:a13b4b7
/////////////////////////////////////////////////////////////////////////
0:     HadoopUtil.delete(conf, outPath);
commit:f824f90
commit:16937e1
commit:2e77bf8
/////////////////////////////////////////////////////////////////////////
0:   private KeyBasedStringTupleGrouper() {
0:   }
0: 
commit:5a677d4
/////////////////////////////////////////////////////////////////////////
0:   public static void startJob(Parameters params) throws IOException,
author:Robin Anil
-------------------------------------------------------------------------------
commit:42ae840
/////////////////////////////////////////////////////////////////////////
0:   
0:   private KeyBasedStringTupleGrouper() { }
0:   
0:                                                 InterruptedException,
0:                                                 ClassNotFoundException {
0:     conf.set("mapred.map.output.compression.codec", "org.apache.hadoop.io.compress.GzipCodec");
0:     conf.set("io.serializations", "org.apache.hadoop.io.serializer.JavaSerialization,"
0:                                   + "org.apache.hadoop.io.serializer.WritableSerialization");
0:     
0:     
0:     
/////////////////////////////////////////////////////////////////////////
0:     
0:     
commit:6980b95
/////////////////////////////////////////////////////////////////////////
0: package org.apache.mahout.fpm.pfpgrowth.dataset;
commit:b35b030
/////////////////////////////////////////////////////////////////////////
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one or more
0:  * contributor license agreements.  See the NOTICE file distributed with
0:  * this work for additional information regarding copyright ownership.
0:  * The ASF licenses this file to You under the Apache License, Version 2.0
0:  * (the "License"); you may not use this file except in compliance with
0:  * the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: /**
0:  * Licensed to the Apache Software Foundation (ASF) under one or more
0:  * contributor license agreements.  See the NOTICE file distributed with
0:  * this work for additional information regarding copyright ownership.
0:  * The ASF licenses this file to You under the Apache License, Version 2.0
0:  * (the "License"); you may not use this file except in compliance with
0:  * the License.  You may obtain a copy of the License at
0:  *
0:  *     http://www.apache.org/licenses/LICENSE-2.0
0:  *
0:  * Unless required by applicable law or agreed to in writing, software
0:  * distributed under the License is distributed on an "AS IS" BASIS,
0:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:  * See the License for the specific language governing permissions and
0:  * limitations under the License.
0:  */
0: 
0: package org.apache.mahout.fpm.pfpgrowth.example.dataset;
0: 
0: import java.io.IOException;
0: 
0: import org.apache.hadoop.conf.Configuration;
0: import org.apache.hadoop.fs.FileSystem;
0: import org.apache.hadoop.fs.Path;
0: import org.apache.hadoop.io.Text;
0: import org.apache.hadoop.mapreduce.Job;
0: import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
0: import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
0: import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
0: import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
0: import org.apache.mahout.common.Parameters;
0: import org.apache.mahout.common.StringTuple;
0: 
0: public class KeyBasedStringTupleGrouper {
0: 
0: 
0:   public void startJob(Parameters params) throws IOException,
0:       InterruptedException, ClassNotFoundException {
0:     Configuration conf = new Configuration();
0:     
0:     conf.set("job.parameters", params.toString());
0:     conf.set("mapred.compress.map.output", "true");
0:     conf.set("mapred.output.compression.type", "BLOCK");
0:     conf.set("mapred.map.output.compression.codec",
0:         "org.apache.hadoop.io.compress.GzipCodec");
0:     conf.set("io.serializations",
0:         "org.apache.hadoop.io.serializer.JavaSerialization,"
0:             + "org.apache.hadoop.io.serializer.WritableSerialization");
0:    
0:     String input = params.get("input");
0:     Job job = new Job(conf, "Generating dataset based from input" + input);
0:     job.setJarByClass(KeyBasedStringTupleGrouper.class);
0: 
0:     job.setMapOutputKeyClass(Text.class);
0:     job.setMapOutputValueClass(StringTuple.class);
0:     
0:     job.setOutputKeyClass(Text.class);
0:     job.setOutputValueClass(Text.class);
0: 
0:     FileInputFormat.addInputPath(job, new Path(input));
0:     Path outPath = new Path(params.get("output"));
0:     FileOutputFormat.setOutputPath(job, outPath);
0:     
0:     FileSystem dfs = FileSystem.get(outPath.toUri(), conf);
0:     if (dfs.exists(outPath)) {
0:       dfs.delete(outPath, true);
0:     }
0: 
0:     job.setInputFormatClass(TextInputFormat.class);
0:     job.setMapperClass(KeyBasedStringTupleMapper.class);
0:     job.setCombinerClass(KeyBasedStringTupleCombiner.class);
0:     job.setReducerClass(KeyBasedStringTupleReducer.class);
0:     job.setOutputFormatClass(TextOutputFormat.class);
0: 
0:     job.waitForCompletion(true);
0:   }
0: }
============================================================================
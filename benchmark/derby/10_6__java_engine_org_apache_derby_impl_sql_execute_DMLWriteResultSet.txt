1:eac0369: /*
1:345de35: 
1:345de35:    Derby - Class org.apache.derby.impl.sql.execute.DMLWriteResultSet
1:345de35: 
1:f6123ee:    Licensed to the Apache Software Foundation (ASF) under one or more
1:f6123ee:    contributor license agreements.  See the NOTICE file distributed with
1:f6123ee:    this work for additional information regarding copyright ownership.
1:f6123ee:    The ASF licenses this file to you under the Apache License, Version 2.0
1:f6123ee:    (the "License"); you may not use this file except in compliance with
1:f6123ee:    the License.  You may obtain a copy of the License at
1:345de35: 
1:345de35:       http://www.apache.org/licenses/LICENSE-2.0
1:345de35: 
1:345de35:    Unless required by applicable law or agreed to in writing, software
1:345de35:    distributed under the License is distributed on an "AS IS" BASIS,
1:345de35:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:345de35:    See the License for the specific language governing permissions and
1:345de35:    limitations under the License.
1:eac0369: 
1:eac0369:  */
1:eac0369: 
1:eac0369: package org.apache.derby.impl.sql.execute;
1:d2d2e68: 
1:d2d2e68: import java.io.InputStream;
1:af1c18c: import org.apache.derby.catalog.UUID;
1:eac0369: import org.apache.derby.iapi.error.StandardException;
1:801cf0d: import org.apache.derby.iapi.services.io.FormatableBitSet;
1:801cf0d: import org.apache.derby.iapi.services.io.StreamStorable;
1:eac0369: import org.apache.derby.iapi.sql.Activation;
1:6ab1083: import org.apache.derby.iapi.sql.ResultColumnDescriptor;
1:6ab1083: import org.apache.derby.iapi.sql.ResultDescription;
1:eac0369: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1:801cf0d: import org.apache.derby.iapi.sql.execute.ConstantAction;
1:801cf0d: import org.apache.derby.iapi.sql.execute.ExecRow;
1:801cf0d: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
1:eac0369: import org.apache.derby.iapi.store.access.DynamicCompiledOpenConglomInfo;
1:eac0369: import org.apache.derby.iapi.store.access.TransactionController;
1:38f02ec: import org.apache.derby.iapi.transaction.TransactionControl;
1:6ab1083: import org.apache.derby.iapi.types.DataTypeDescriptor;
1:801cf0d: import org.apache.derby.iapi.types.DataValueDescriptor;
1:af1c18c: import org.apache.derby.shared.common.sanity.SanityManager;
1:eac0369: 
1:eac0369: /**
1:eac0369:  * For INSERT/UPDATE/DELETE impls.  Used to tag them.
1:eac0369:  */
1:af1c18c: abstract public class DMLWriteResultSet extends NoRowsResultSetImpl
2:eac0369: {
1:eac0369: 	protected WriteCursorConstantAction constantAction;
1:eac0369: 	protected int[] baseRowReadMap;
1:eac0369: 	protected int[] streamStorableHeapColIds;
1:eac0369: 	protected DynamicCompiledOpenConglomInfo heapDCOCI;
1:eac0369: 	protected DynamicCompiledOpenConglomInfo[] indexDCOCIs;
1:eac0369: 	private boolean needToObjectifyStream;
1:eac0369: 
1:eac0369: 
1:7fb9956: 	public long rowCount;
1:eac0369: 
1:6ab1083: 	// divined at run time
1:6ab1083:     protected   ResultDescription 		resultDescription;
1:6ab1083: 
1:6ab1083:     /**
1:6ab1083:      * This array contains data value descriptors that can be used (and reused)
1:6ab1083:      * to hold the normalized column values.
1:6ab1083:      */
1:6ab1083:     protected DataValueDescriptor[] cachedDestinations;
1:6ab1083: 
1:eac0369: 	/**
1:eac0369: 	 * Constructor
1:eac0369: 	 *
1:eac0369:  	 * @param activation		an activation
1:eac0369: 	 *
1:eac0369:  	 * @exception StandardException on error
1:eac0369: 	 */
1:6bc9897: 	DMLWriteResultSet(Activation activation)
1:eac0369: 		throws StandardException
1:eac0369: 	{
1:eac0369: 		this(activation, activation.getConstantAction());
1:eac0369: 	}
1:6bc9897: 	DMLWriteResultSet(Activation activation, ConstantAction constantAction)
1:eac0369: 		throws StandardException
1:eac0369: 	{
1:eac0369: 		super(activation);
1:eac0369: 
1:eac0369: 		this.constantAction = (WriteCursorConstantAction) constantAction;
1:eac0369: 		baseRowReadMap = this.constantAction.getBaseRowReadMap();
1:eac0369: 		streamStorableHeapColIds = this.constantAction.getStreamStorableHeapColIds();
1:eac0369: 
1:eac0369: 		TransactionController tc = activation.getTransactionController();
1:eac0369: 
1:eac0369: 		// Special handling for updatable VTIs
1:eac0369: 		if (! (constantAction instanceof UpdatableVTIConstantAction))
1:eac0369: 		{
1:eac0369: 			heapDCOCI = tc.getDynamicCompiledConglomInfo(this.constantAction.conglomId);
1:eac0369: 			if (this.constantAction.indexCIDS.length != 0)
1:eac0369: 			{
1:eac0369: 				indexDCOCIs = new DynamicCompiledOpenConglomInfo[this.constantAction.indexCIDS.length];
1:eac0369: 				for (int index = 0; index < this.constantAction.indexCIDS.length; index++)
1:eac0369: 				{
1:eac0369: 					indexDCOCIs[index] = tc.getDynamicCompiledConglomInfo(
1:eac0369: 												this.constantAction.indexCIDS[index]);
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		/* We only need to objectify the streams here if they are exposed to the users through the
1:eac0369: 		 * trigger context.  For "before" trigger, we could just return the stream wrapped in
1:eac0369: 		 * RememberBytesInputStream to the user and reset it after usage, but this wouldn't work
1:eac0369: 		 * because the user may get the stream in trigger action and do something with it in parallel
1:eac0369: 		 * with the store doing insert.  We could also delay the materializing until the stream is
1:eac0369: 		 * fetched in before trigger but that would complicate the code.  For "after" trigger, we have
1:eac0369: 		 * to materialize it here because store only keeps a page's amount for each round.  For other
1:eac0369: 		 * reasons of "deferred" operations we don't need to objectify here.  Simply going through a
1:eac0369: 		 * temp table (either in memory part or spilled to disk) is fine for the stream, unless a
1:eac0369: 		 * same stream appears in two rows in the temp table, which could happen for an "update", in
1:eac0369: 		 * which case we do the objectifying in UpdateResultSet.  Beetle 4896.  Related bug entries:
1:eac0369: 		 * 2432, 3383.
1:eac0369: 		 */
1:508a010:         needToObjectifyStream = (this.constantAction.getTriggerInfo() != null);
1:eac0369: 	}
1:eac0369: 
1:801cf0d:     @Override
1:2e87a4c: 	public final long	modifiedRowCount() { return rowCount + RowUtil.getRowCountBase(); }
1:eac0369: 
1:6ab1083: 	/**
1:6ab1083:      * Returns the description of the inserted rows.
1:6ab1083:      * REVISIT: Do we want this to return NULL instead?
1:45da2f5:      *
1:45da2f5:      * @return the description of the inserted rows
1:6ab1083: 	 */
1:45da2f5:     @Override
1:6ab1083: 	public ResultDescription getResultDescription()
1:6ab1083: 	{
1:6ab1083: 	    return resultDescription;
1:6ab1083: 	}
1:eac0369: 
1:eac0369: 	/**
1:eac0369: 	 * Get next row from the source result set.
1:eac0369: 	 * 
1:eac0369: 	 * @param source		SourceResultSet
1:eac0369: 	 * Also look at Track#2432/change 12433
1:45da2f5:      * @return             The next row in the result set
1:45da2f5:      * @throws StandardException
1:45da2f5:      *                     Standard error policy
1:eac0369: 	 */
1:eac0369: 	protected ExecRow getNextRowCore(NoPutResultSet source)
1:eac0369: 		throws StandardException
1:eac0369: 	{
1:eac0369: 		ExecRow row = source.getNextRowCore();
1:eac0369: 		if (needToObjectifyStream)
1:eac0369: 		{
1:eac0369: 			/* 
1:eac0369: 			   See comments in the constructor. We also need to load the column
1:eac0369: 			   if it is part of an index on an insert but that is done in
1:eac0369: 			   insertResultSet#normalInsertCore or IRS#changedRow
1:eac0369: 			*/
1:eac0369: 			objectifyStreams(row);
1:eac0369: 		}
1:eac0369: 		return row;
1:eac0369: 	}
1:af1c18c: 
1:eac0369: 	private void objectifyStreams(ExecRow row) throws StandardException 
1:eac0369: 	{
1:eac0369: 		// if the column is a streamStorable, we need to materialize the object
1:eac0369: 		// therefore, the object can be used to multiple rows.
1:eac0369: 		if ((row != null) && (streamStorableHeapColIds != null))
1:eac0369: 		{
1:eac0369: 			for (int ix=0; ix < streamStorableHeapColIds.length; ix++)
1:eac0369: 			{
1:eac0369: 				int heapIx = streamStorableHeapColIds[ix];
1:eac0369: 				int readIx = (baseRowReadMap == null) ?
1:eac0369: 					heapIx :
1:eac0369: 					baseRowReadMap[heapIx];
1:d2d2e68: 
1:eac0369: 				DataValueDescriptor col = row.getColumn(readIx+1);
1:eac0369: 				
1:d9a720b: 				// Derby-4779
1:d9a720b: 				if ( col != null ) {
1:d9a720b: 					InputStream stream = ((StreamStorable)col).returnStream();
1:d9a720b: 					((StreamStorable)col).loadStream();
1:d9a720b: 
1:d9a720b: 					// DERBY-3238
1:d9a720b: 					// fix up any duplicate streams, for instance in the case of an update with a trigger,
1:d9a720b: 					// all the columns are read as update columns even if they are not updated, so 
1:d9a720b: 					// the update column will still have a reference to the original stream.
1:d9a720b: 					// If we knew from this context that this was an update and we knew the number
1:d9a720b: 					// of columns in the base table we would be able to calculate exactly the offset to 
1:d9a720b: 					// check, but we don't have that information from this context.
1:d9a720b: 					// If DERBY-1482 is fixed, perhaps this code can be removed.
1:d9a720b: 
1:d9a720b: 					if (stream != null)
1:d9a720b: 						for (int i = 1; i <= row.nColumns(); i++)
1:d9a720b: 						{
1:d9a720b: 							DataValueDescriptor c = row.getColumn(i);
1:d9a720b: 							if (c instanceof StreamStorable)
1:d9a720b: 								if (((StreamStorable)c).returnStream() == stream)
1:d9a720b: 									row.setColumn(i, col.cloneValue(false));
1:d9a720b: 						}
1:d2d2e68: 					}
1:d2d2e68: 				}
1:eac0369: 			}
1:eac0369: 	}
1:d2d2e68: 
1:eac0369: 	/**
1:eac0369: 	 * For deferred update, get a deferred sparse row based on the
1:eac0369: 	 * deferred non-sparse row. Share the underlying columns. If there
1:eac0369: 	 * is no column bit map, make them the same row.
1:eac0369: 	 *
1:45da2f5:      * @param deferredBaseRow  the deferred non-sparse row
1:45da2f5:      * @param baseRowReadList  the columns to include (1-based bit map)
1:45da2f5:      * @param lcc              the language connection context
1:45da2f5:      * @return                 the deferred sparse row
1:eac0369: 	 * @exception StandardException		Thrown on error
1:eac0369: 	 */
1:eac0369: 	protected ExecRow makeDeferredSparseRow(
1:eac0369: 							ExecRow deferredBaseRow,
1:eac0369: 							FormatableBitSet baseRowReadList,
1:eac0369: 							LanguageConnectionContext lcc)
1:eac0369: 				throws StandardException
1:d2d2e68: 	{
1:eac0369: 		ExecRow deferredSparseRow;
1:eac0369: 
1:eac0369: 		if (baseRowReadList == null)
1:eac0369: 		{
1:eac0369: 			/* No sparse row */
1:eac0369: 			deferredSparseRow = deferredBaseRow;
1:eac0369: 		}
1:eac0369: 		else
1:eac0369: 		{
1:eac0369: 			/*
1:eac0369: 			** We need to do a fetch doing a partial row
1:eac0369: 			** read.  We need to shift our 1-based bit
1:eac0369: 			** set to a zero based bit set like the store
1:eac0369: 			** expects.
1:eac0369: 			*/
1:eac0369: 			deferredSparseRow =
1:eac0369: 				RowUtil.getEmptyValueRow(
1:eac0369: 								baseRowReadList.getLength() - 1,
1:eac0369: 								lcc);
1:eac0369: 			/*
1:eac0369: 			** getColumn(), setColumn(), and baseRowReadList are
1:eac0369: 			** one-based.
1:eac0369: 			*/
1:eac0369: 			int fromPosition = 1;
1:eac0369: 			for (int i = 1; i <= deferredSparseRow.nColumns(); i++)
1:eac0369: 			{
1:eac0369: 				if (baseRowReadList.isSet(i))
1:eac0369: 				{
1:eac0369: 					deferredSparseRow.setColumn(
1:eac0369: 						i,
1:eac0369: 						deferredBaseRow.getColumn(fromPosition++)
1:eac0369: 						);
1:eac0369: 				}
1:eac0369: 			}
1:eac0369: 		}
1:eac0369: 
1:eac0369: 		return deferredSparseRow;
1:eac0369: 	}
1:eac0369: 
1:eac0369:     /**
1:6369b54:      * Decode the update lock mode.
1:6369b54:      * <p>
1:6369b54:      * The value for update lock mode is in the second most significant byte for
1:38f02ec:      * TransactionControl.SERIALIZABLE_ISOLATION_LEVEL isolation level. Otherwise
1:6369b54:      * (REPEATABLE READ, READ COMMITTED, and READ UNCOMMITTED) the lock mode is
1:6369b54:      * located in the least significant byte.
1:6369b54:      * <p>
1:6369b54:      * This is done to override the optimizer choice to provide maximum 
1:6369b54:      * concurrency of record level locking except in SERIALIZABLE where table
1:6369b54:      * level locking is required in heap scans for correctness.
1:6369b54:      *
1:6369b54:      * @param lockMode the compiled encoded lock mode for this query
1:6369b54:      * @return the lock mode (record or table) to use to open the result set
1:6369b54:      * @see org.apache.derby.impl.sql.compile.FromBaseTable#updateTargetLockMode
1:eac0369:      */
1:6369b54:     int decodeLockMode(int lockMode) {
1:eac0369: 
1:6369b54:         if (SanityManager.DEBUG) {
1:6369b54:             // we want to decode lock mode when the result set is opened, not
1:6369b54:             // in the constructor
1:6369b54:             SanityManager.ASSERT(!isClosed());
1:eac0369:         }
1:eac0369: 
1:6369b54:         if ((lockMode >>> 16) == 0) {
1:6369b54:             return lockMode;
2:6369b54:         }
1:eac0369: 
1:6369b54:         // Note that isolation level encoding from getCurrentIsolationLevel()
1:38f02ec:         // returns TransactionControl.*ISOLATION_LEVEL constants, not
1:6369b54:         // TransactionController.ISOLATION* constants.
1:eac0369: 
1:6369b54:         int isolationLevel = lcc.getCurrentIsolationLevel();
1:eac0369: 
1:38f02ec:         if (isolationLevel == TransactionControl.SERIALIZABLE_ISOLATION_LEVEL) {
1:6369b54:             return lockMode >>> 16;
1:6369b54:         }
1:eac0369: 
1:6369b54:         return lockMode & 0xff;
1:6369b54:     }
1:eac0369: 
1:eac0369: 	/**
1:eac0369: 	 * get the index name given the conglomerate id of the index.
1:eac0369: 	 * 
1:eac0369: 	 * @param indexCID		conglomerate ID of the index.
1:eac0369: 	 * 
1:eac0369: 	 * @return index name of given index.
1:eac0369: 	 */
1:eac0369: 	String getIndexNameFromCID(long indexCID)
1:eac0369: 	{
1:eac0369: 		return this.constantAction.getIndexNameFromCID(indexCID);
1:eac0369: 	}
1:6ab1083: 
1:6ab1083:     /**
1:6ab1083:      * <p>
1:6ab1083:      * Normalize a row as part of the INSERT/UPDATE action of a MERGE statement.
1:6ab1083:      * This applies logic usually found in a NormalizeResultSet, which is missing for
1:6ab1083:      * the MERGE statement.
1:6ab1083:      * </p>
1:45da2f5:      * @param sourceResultSet        the result set for which this action is
1:45da2f5:      *                               to be performed
1:45da2f5:      * @param row                    the row to be normalized
1:45da2f5:      * @return                       the normalized row
1:45da2f5:      * @throws StandardException     Standard error policy
1:6ab1083:      */
1:6ab1083:     protected   ExecRow normalizeRow( NoPutResultSet sourceResultSet, ExecRow row )
1:6ab1083:         throws StandardException
1:6ab1083:     {
1:6ab1083:         //
1:6ab1083:         // Make sure that the evaluated expressions fit in the base table row.
1:6ab1083:         //
1:6ab1083:         int count = resultDescription.getColumnCount();
1:6ab1083:         if ( cachedDestinations == null )
1:6ab1083:         {
1:6ab1083:             cachedDestinations = new DataValueDescriptor[ count ];
1:6ab1083:             for ( int i = 0; i < count; i++)
1:6ab1083:             {
1:6ab1083:                 int         position = i + 1;
1:6ab1083:                 ResultColumnDescriptor  colDesc = resultDescription.getColumnDescriptor( position );
1:6ab1083:                 cachedDestinations[ i ] = colDesc.getType().getNull();
1:6ab1083:             }
1:6ab1083:         }
1:6ab1083: 
1:6ab1083:         for ( int i = 0; i < count; i++ )
1:6ab1083:         {
1:6ab1083:             int         position = i + 1;
1:6ab1083:             DataTypeDescriptor  dtd = resultDescription.getColumnDescriptor( position ).getType();
1:6ab1083: 
1:6ab1083:             if ( row.getColumn( position ) == null )
1:6ab1083:             {
1:6ab1083:                 row.setColumn( position, dtd.getNull() );
1:6ab1083:             }
1:6ab1083: 
1:6ab1083:             row.setColumn
1:6ab1083:                 (
1:6ab1083:                  position,
1:6ab1083:                  NormalizeResultSet.normalizeColumn
1:6ab1083:                  (
1:6ab1083:                   dtd,
1:6ab1083:                   row,
1:6ab1083:                   position,
1:6ab1083:                   cachedDestinations[ i ],
1:6ab1083:                   resultDescription
1:6ab1083:                   )
1:6ab1083:                  );
1:6ab1083:         }
1:6ab1083: 
1:6ab1083:         // put the row where expressions in constraints can access it
1:6ab1083:         activation.setCurrentRow( row, sourceResultSet.resultSetNumber() );
1:6ab1083: 
1:6ab1083:         return row;
1:6ab1083:     }
1:6ab1083: 
1:af1c18c:     public void rememberConstraint(UUID cid) throws StandardException {
1:af1c18c:         if (SanityManager.DEBUG) {
1:af1c18c:             // This method should be overriden by InsertResultSet and
1:af1c18c:             // UpdateResultSet, other shouldn't need it.
1:af1c18c:             SanityManager.NOTREACHED();
1:af1c18c:         }
1:af1c18c:     }
1:eac0369: }
============================================================================
author:Dag H. Wanvik
-------------------------------------------------------------------------------
commit:45da2f5
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:      *
1:      * @return the description of the inserted rows
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:      * @return             The next row in the result set
1:      * @throws StandardException
1:      *                     Standard error policy
/////////////////////////////////////////////////////////////////////////
1:      * @param deferredBaseRow  the deferred non-sparse row
1:      * @param baseRowReadList  the columns to include (1-based bit map)
1:      * @param lcc              the language connection context
1:      * @return                 the deferred sparse row
/////////////////////////////////////////////////////////////////////////
1:      * @param sourceResultSet        the result set for which this action is
1:      *                               to be performed
1:      * @param row                    the row to be normalized
1:      * @return                       the normalized row
1:      * @throws StandardException     Standard error policy
commit:af1c18c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.catalog.UUID;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.shared.common.sanity.SanityManager;
1: abstract public class DMLWriteResultSet extends NoRowsResultSetImpl
/////////////////////////////////////////////////////////////////////////
1: 
1:     public void rememberConstraint(UUID cid) throws StandardException {
1:         if (SanityManager.DEBUG) {
1:             // This method should be overriden by InsertResultSet and
1:             // UpdateResultSet, other shouldn't need it.
1:             SanityManager.NOTREACHED();
1:         }
1:     }
commit:801cf0d
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: import org.apache.derby.iapi.services.io.StreamStorable;
0: import org.apache.derby.iapi.services.sanity.SanityManager;
1: import org.apache.derby.iapi.sql.execute.ConstantAction;
1: import org.apache.derby.iapi.sql.execute.ExecRow;
1: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
1: import org.apache.derby.iapi.types.DataValueDescriptor;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     @Override
author:Richard N. Hillegas
-------------------------------------------------------------------------------
commit:6ab1083
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.sql.ResultColumnDescriptor;
1: import org.apache.derby.iapi.sql.ResultDescription;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.types.DataTypeDescriptor;
/////////////////////////////////////////////////////////////////////////
1: 	// divined at run time
1:     protected   ResultDescription 		resultDescription;
1: 
1:     /**
1:      * This array contains data value descriptors that can be used (and reused)
1:      * to hold the normalized column values.
1:      */
1:     protected DataValueDescriptor[] cachedDestinations;
1: 
/////////////////////////////////////////////////////////////////////////
1: 	/**
1:      * Returns the description of the inserted rows.
1:      * REVISIT: Do we want this to return NULL instead?
1: 	 */
1: 	public ResultDescription getResultDescription()
1: 	{
1: 	    return resultDescription;
1: 	}
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * <p>
1:      * Normalize a row as part of the INSERT/UPDATE action of a MERGE statement.
1:      * This applies logic usually found in a NormalizeResultSet, which is missing for
1:      * the MERGE statement.
1:      * </p>
1:      */
1:     protected   ExecRow normalizeRow( NoPutResultSet sourceResultSet, ExecRow row )
1:         throws StandardException
1:     {
1:         //
1:         // Make sure that the evaluated expressions fit in the base table row.
1:         //
1:         int count = resultDescription.getColumnCount();
1:         if ( cachedDestinations == null )
1:         {
1:             cachedDestinations = new DataValueDescriptor[ count ];
1:             for ( int i = 0; i < count; i++)
1:             {
1:                 int         position = i + 1;
1:                 ResultColumnDescriptor  colDesc = resultDescription.getColumnDescriptor( position );
1:                 cachedDestinations[ i ] = colDesc.getType().getNull();
1:             }
1:         }
1: 
1:         for ( int i = 0; i < count; i++ )
1:         {
1:             int         position = i + 1;
1:             DataTypeDescriptor  dtd = resultDescription.getColumnDescriptor( position ).getType();
1: 
1:             if ( row.getColumn( position ) == null )
1:             {
1:                 row.setColumn( position, dtd.getNull() );
1:             }
1: 
1:             row.setColumn
1:                 (
1:                  position,
1:                  NormalizeResultSet.normalizeColumn
1:                  (
1:                   dtd,
1:                   row,
1:                   position,
1:                   cachedDestinations[ i ],
1:                   resultDescription
1:                   )
1:                  );
1:         }
1: 
1:         // put the row where expressions in constraints can access it
1:         activation.setCurrentRow( row, sourceResultSet.resultSetNumber() );
1: 
1:         return row;
1:     }
1:     
commit:508a010
/////////////////////////////////////////////////////////////////////////
1:         needToObjectifyStream = (this.constantAction.getTriggerInfo() != null);
commit:2e87a4c
/////////////////////////////////////////////////////////////////////////
1: 	public final long	modifiedRowCount() { return rowCount + RowUtil.getRowCountBase(); }
commit:38f02ec
/////////////////////////////////////////////////////////////////////////
1: import org.apache.derby.iapi.transaction.TransactionControl;
/////////////////////////////////////////////////////////////////////////
1:      * TransactionControl.SERIALIZABLE_ISOLATION_LEVEL isolation level. Otherwise
/////////////////////////////////////////////////////////////////////////
1:         // returns TransactionControl.*ISOLATION_LEVEL constants, not
1:         if (isolationLevel == TransactionControl.SERIALIZABLE_ISOLATION_LEVEL) {
commit:f26c60c
/////////////////////////////////////////////////////////////////////////
0: 	public final long	modifiedRowCount() { return rowCount + RowUtil.rowCountBase; }
commit:7fb9956
/////////////////////////////////////////////////////////////////////////
1: 	public long rowCount;
/////////////////////////////////////////////////////////////////////////
0: 	public final long	modifiedRowCount() { return rowCount; }
commit:d9a720b
/////////////////////////////////////////////////////////////////////////
1: 				// Derby-4779
1: 				if ( col != null ) {
1: 					InputStream stream = ((StreamStorable)col).returnStream();
1: 					((StreamStorable)col).loadStream();
1: 
1: 					// DERBY-3238
1: 					// fix up any duplicate streams, for instance in the case of an update with a trigger,
1: 					// all the columns are read as update columns even if they are not updated, so 
1: 					// the update column will still have a reference to the original stream.
1: 					// If we knew from this context that this was an update and we knew the number
1: 					// of columns in the base table we would be able to calculate exactly the offset to 
1: 					// check, but we don't have that information from this context.
1: 					// If DERBY-1482 is fixed, perhaps this code can be removed.
1: 
1: 					if (stream != null)
1: 						for (int i = 1; i <= row.nColumns(); i++)
1: 						{
1: 							DataValueDescriptor c = row.getColumn(i);
1: 							if (c instanceof StreamStorable)
1: 								if (((StreamStorable)c).returnStream() == stream)
1: 									row.setColumn(i, col.cloneValue(false));
1: 						}
author:Bryan Pendleton
-------------------------------------------------------------------------------
commit:7e51e9d
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.shared.common.sanity.SanityManager;
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:854dd10
/////////////////////////////////////////////////////////////////////////
0: 								row.setColumn(i, col.cloneValue(false));
author:Katherine Marsden
-------------------------------------------------------------------------------
commit:d2d2e68
/////////////////////////////////////////////////////////////////////////
1: import java.io.InputStream;
1: 
/////////////////////////////////////////////////////////////////////////
1:                 
0: 				InputStream stream = ((StreamStorable)col).returnStream();
0: 				// DERBY-3238 
0: 				// fix up any duplicate streams, for instance in the case of an update with a trigger,
0: 				// all the columns are read as update columns even if they are not updated, so 
0: 				// the update column will still have a reference to the original stream.
0: 				// If we knew from this context that this was an update and we knew the number
0: 				// of columns in the base table we would be able to calculate exactly the offset to 
0: 				// check, but we don't have that information from this context.
0: 				// If DERBY-1482 is fixed, perhaps this code can be removed.
1: 				
0: 				if (stream != null)
0: 					for (int i = 1; i <= row.nColumns(); i++)
1: 					{
0: 						DataValueDescriptor c = row.getColumn(i);
0: 						if (c instanceof StreamStorable)
0: 							if (((StreamStorable)c).returnStream() == stream)
0: 								row.setColumn(i, col.getClone());
1: 					}
1: 				}
author:Daniel John Debrunner
-------------------------------------------------------------------------------
commit:4119c42
/////////////////////////////////////////////////////////////////////////
0: 		needToObjectifyStream = (this.constantAction.getTriggerInfo() != null);
commit:6bc9897
/////////////////////////////////////////////////////////////////////////
1: 	DMLWriteResultSet(Activation activation)
1: 	DMLWriteResultSet(Activation activation, ConstantAction constantAction)
commit:345de35
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derby.impl.sql.execute.DMLWriteResultSet
1: 
0:    Copyright 1999, 2004 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
1:       http://www.apache.org/licenses/LICENSE-2.0
1: 
1:    Unless required by applicable law or agreed to in writing, software
1:    distributed under the License is distributed on an "AS IS" BASIS,
1:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:    See the License for the specific language governing permissions and
1:    limitations under the License.
commit:9e5097f
/////////////////////////////////////////////////////////////////////////
commit:eac0369
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 1999, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
1: 
1:  */
1: 
1: package org.apache.derby.impl.sql.execute;
1: 
0: import org.apache.derby.iapi.types.DataValueDescriptor;
0: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
0: import org.apache.derby.iapi.services.io.StreamStorable;
0: import org.apache.derby.iapi.sql.execute.ExecRow;
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
1: import org.apache.derby.iapi.error.StandardException;
1: import org.apache.derby.iapi.sql.Activation;
1: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
1: 
1: import org.apache.derby.iapi.store.access.DynamicCompiledOpenConglomInfo;
0: import org.apache.derby.iapi.store.access.StaticCompiledOpenConglomInfo;
1: import org.apache.derby.iapi.store.access.TransactionController;
1: 
0: import org.apache.derby.catalog.UUID;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
1: 
1: /**
1:  * For INSERT/UPDATE/DELETE impls.  Used to tag them.
1:  */
0: abstract class DMLWriteResultSet extends NoRowsResultSetImpl 
1: {
1: 	/**
0: 		IBM Copyright &copy notice.
1: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1999_2004;
1: 	protected WriteCursorConstantAction constantAction;
1: 	protected int[] baseRowReadMap;
1: 	protected int[] streamStorableHeapColIds;
0: 	protected ExecRow	deferredSparseRow;
1: 	protected DynamicCompiledOpenConglomInfo heapDCOCI;
1: 	protected DynamicCompiledOpenConglomInfo[] indexDCOCIs;
1: 	private boolean needToObjectifyStream;
1: 
1: 
0: 	public int rowCount;
1: 
1: 
1: 	/**
1: 	 * Constructor
1: 	 *
1:  	 * @param activation		an activation
0: 	 * @param constantAction	a write constant action
1: 	 *
1:  	 * @exception StandardException on error
1: 	 */
0: 	protected DMLWriteResultSet(Activation activation)
1: 		throws StandardException
1: 	{
1: 		this(activation, activation.getConstantAction());
1: 	}
0: 	protected DMLWriteResultSet(Activation activation, ConstantAction constantAction)
1: 		throws StandardException
1: 	{
1: 		super(activation);
1: 
1: 		this.constantAction = (WriteCursorConstantAction) constantAction;
1: 		baseRowReadMap = this.constantAction.getBaseRowReadMap();
1: 		streamStorableHeapColIds = this.constantAction.getStreamStorableHeapColIds();
1: 
1: 		TransactionController tc = activation.getTransactionController();
1: 
1: 		// Special handling for updatable VTIs
1: 		if (! (constantAction instanceof UpdatableVTIConstantAction))
1: 		{
1: 			heapDCOCI = tc.getDynamicCompiledConglomInfo(this.constantAction.conglomId);
1: 			if (this.constantAction.indexCIDS.length != 0)
1: 			{
1: 				indexDCOCIs = new DynamicCompiledOpenConglomInfo[this.constantAction.indexCIDS.length];
1: 				for (int index = 0; index < this.constantAction.indexCIDS.length; index++)
1: 				{
1: 					indexDCOCIs[index] = tc.getDynamicCompiledConglomInfo(
1: 												this.constantAction.indexCIDS[index]);
1: 				}
1: 			}
1: 		}
1: 
1: 		/* We only need to objectify the streams here if they are exposed to the users through the
1: 		 * trigger context.  For "before" trigger, we could just return the stream wrapped in
1: 		 * RememberBytesInputStream to the user and reset it after usage, but this wouldn't work
1: 		 * because the user may get the stream in trigger action and do something with it in parallel
1: 		 * with the store doing insert.  We could also delay the materializing until the stream is
1: 		 * fetched in before trigger but that would complicate the code.  For "after" trigger, we have
1: 		 * to materialize it here because store only keeps a page's amount for each round.  For other
1: 		 * reasons of "deferred" operations we don't need to objectify here.  Simply going through a
1: 		 * temp table (either in memory part or spilled to disk) is fine for the stream, unless a
1: 		 * same stream appears in two rows in the temp table, which could happen for an "update", in
1: 		 * which case we do the objectifying in UpdateResultSet.  Beetle 4896.  Related bug entries:
1: 		 * 2432, 3383.
1: 		 */
0: 		needToObjectifyStream = (this.constantAction.getTriggerInfo(
0: 						activation.getLanguageConnectionContext().getExecutionContext()) != null);
1: 	}
1: 
0: 	public final int	modifiedRowCount() { return rowCount; }
1: 
1: 
1: 	/**
1: 	 * Get next row from the source result set.
1: 	 * 
1: 	 * @param source		SourceResultSet
1: 	 * Also look at Track#2432/change 12433
1: 	 */
1: 	protected ExecRow getNextRowCore(NoPutResultSet source)
1: 		throws StandardException
1: 	{
1: 		ExecRow row = source.getNextRowCore();
1: 		if (needToObjectifyStream)
1: 		{
1: 			/* 
1: 			   See comments in the constructor. We also need to load the column
1: 			   if it is part of an index on an insert but that is done in
1: 			   insertResultSet#normalInsertCore or IRS#changedRow
1: 			*/
1: 			objectifyStreams(row);
1: 		}
1: 		return row;
1: 	}
1: 
1: 	private void objectifyStreams(ExecRow row) throws StandardException 
1: 	{
1: 		// if the column is a streamStorable, we need to materialize the object
1: 		// therefore, the object can be used to multiple rows.
1: 		if ((row != null) && (streamStorableHeapColIds != null))
1: 		{
1: 			for (int ix=0; ix < streamStorableHeapColIds.length; ix++)
1: 			{
1: 				int heapIx = streamStorableHeapColIds[ix];
1: 				int readIx = (baseRowReadMap == null) ?
1: 					heapIx :
1: 					baseRowReadMap[heapIx];
1: 
1: 				DataValueDescriptor col = row.getColumn(readIx+1);
0: 				((StreamStorable)col).loadStream();
1: 			}
1: 		}
1: 	}
1: 
1: 	/**
1: 	 * For deferred update, get a deferred sparse row based on the
1: 	 * deferred non-sparse row. Share the underlying columns. If there
1: 	 * is no column bit map, make them the same row.
1: 	 *
1: 	 * @exception StandardException		Thrown on error
1: 	 */
1: 	protected ExecRow makeDeferredSparseRow(
1: 							ExecRow deferredBaseRow,
1: 							FormatableBitSet baseRowReadList,
1: 							LanguageConnectionContext lcc)
1: 				throws StandardException
1: 	{
1: 		ExecRow deferredSparseRow;
1: 
1: 		if (baseRowReadList == null)
1: 		{
1: 			/* No sparse row */
1: 			deferredSparseRow = deferredBaseRow;
1: 		}
1: 		else
1: 		{
1: 			/*
1: 			** We need to do a fetch doing a partial row
1: 			** read.  We need to shift our 1-based bit
1: 			** set to a zero based bit set like the store
1: 			** expects.
1: 			*/
1: 			deferredSparseRow =
1: 				RowUtil.getEmptyValueRow(
1: 								baseRowReadList.getLength() - 1,
1: 								lcc);
1: 			/*
1: 			** getColumn(), setColumn(), and baseRowReadList are
1: 			** one-based.
1: 			*/
1: 			int fromPosition = 1;
1: 			for (int i = 1; i <= deferredSparseRow.nColumns(); i++)
1: 			{
1: 				if (baseRowReadList.isSet(i))
1: 				{
1: 					deferredSparseRow.setColumn(
1: 						i,
1: 						deferredBaseRow.getColumn(fromPosition++)
1: 						);
1: 				}
1: 			}
1: 		}
1: 
1: 		return deferredSparseRow;
1: 	}
1: 	
1: 	/**
1: 	 * get the index name given the conglomerate id of the index.
1: 	 * 
1: 	 * @param indexCID		conglomerate ID of the index.
1: 	 * 
1: 	 * @return index name of given index.
1: 	 */
1: 	String getIndexNameFromCID(long indexCID)
1: 	{
1: 		return this.constantAction.getIndexNameFromCID(indexCID);
1: 	}
1: }
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:6369b54
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.sql.execute.ExecutionContext;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.derby.iapi.services.sanity.SanityManager;
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
1:      * Decode the update lock mode.
1:      * <p>
1:      * The value for update lock mode is in the second most significant byte for
0:      * ExecutionContext.SERIALIZABLE_ISOLATION_LEVEL isolation level. Otherwise
1:      * (REPEATABLE READ, READ COMMITTED, and READ UNCOMMITTED) the lock mode is
1:      * located in the least significant byte.
1:      * <p>
1:      * This is done to override the optimizer choice to provide maximum 
1:      * concurrency of record level locking except in SERIALIZABLE where table
1:      * level locking is required in heap scans for correctness.
1:      *
1:      * @param lockMode the compiled encoded lock mode for this query
1:      * @return the lock mode (record or table) to use to open the result set
1:      * @see org.apache.derby.impl.sql.compile.FromBaseTable#updateTargetLockMode
0:      */
1:     int decodeLockMode(int lockMode) {
0: 
1:         if (SanityManager.DEBUG) {
1:             // we want to decode lock mode when the result set is opened, not
1:             // in the constructor
1:             SanityManager.ASSERT(!isClosed());
1:         }
0: 
1:         if ((lockMode >>> 16) == 0) {
1:             return lockMode;
1:         }
0: 
1:         // Note that isolation level encoding from getCurrentIsolationLevel()
0:         // returns ExecutionContext.*ISOLATION_LEVEL constants, not
1:         // TransactionController.ISOLATION* constants.
0: 
1:         int isolationLevel = lcc.getCurrentIsolationLevel();
0: 
0:         if (isolationLevel == ExecutionContext.SERIALIZABLE_ISOLATION_LEVEL) {
1:             return lockMode >>> 16;
1:         }
0: 
1:         return lockMode & 0xff;
1:     }
0: 
author:David Van Couvering
-------------------------------------------------------------------------------
commit:f6123ee
/////////////////////////////////////////////////////////////////////////
1:    Licensed to the Apache Software Foundation (ASF) under one or more
1:    contributor license agreements.  See the NOTICE file distributed with
1:    this work for additional information regarding copyright ownership.
1:    The ASF licenses this file to you under the Apache License, Version 2.0
1:    (the "License"); you may not use this file except in compliance with
1:    the License.  You may obtain a copy of the License at
commit:6b50965
/////////////////////////////////////////////////////////////////////////
author:Oyvind Bakksjo
-------------------------------------------------------------------------------
commit:aaea357
author:Ken Coar
-------------------------------------------------------------------------------
commit:95e7b46
/////////////////////////////////////////////////////////////////////////
0: /*
0: 
0:    Licensed Materials - Property of IBM
0:    Cloudscape - Package org.apache.derby.impl.sql.execute
0:    (C) Copyright IBM Corp. 1999, 2004. All Rights Reserved.
0:    US Government Users Restricted Rights - Use, duplication or
0:    disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
0: 
0:  */
0: 
0: package org.apache.derby.impl.sql.execute;
0: 
0: import org.apache.derby.iapi.types.DataValueDescriptor;
0: import org.apache.derby.iapi.sql.execute.NoPutResultSet;
0: import org.apache.derby.iapi.services.io.StreamStorable;
0: import org.apache.derby.iapi.sql.execute.ExecRow;
0: import org.apache.derby.iapi.sql.execute.ConstantAction;
0: import org.apache.derby.iapi.error.StandardException;
0: import org.apache.derby.iapi.sql.Activation;
0: import org.apache.derby.iapi.sql.conn.LanguageConnectionContext;
0: 
0: import org.apache.derby.iapi.store.access.DynamicCompiledOpenConglomInfo;
0: import org.apache.derby.iapi.store.access.StaticCompiledOpenConglomInfo;
0: import org.apache.derby.iapi.store.access.TransactionController;
0: 
0: import org.apache.derby.catalog.UUID;
0: import org.apache.derby.iapi.services.io.FormatableBitSet;
0: 
0: /**
0:  * For INSERT/UPDATE/DELETE impls.  Used to tag them.
0:  */
0: abstract class DMLWriteResultSet extends NoRowsResultSetImpl 
0: {
0: 	/**
0: 		IBM Copyright &copy notice.
0: 	*/
0: 	public static final String copyrightNotice = org.apache.derby.iapi.reference.Copyright.SHORT_1999_2004;
0: 	protected WriteCursorConstantAction constantAction;
0: 	protected int[] baseRowReadMap;
0: 	protected int[] streamStorableHeapColIds;
0: 	protected ExecRow	deferredSparseRow;
0: 	protected DynamicCompiledOpenConglomInfo heapDCOCI;
0: 	protected DynamicCompiledOpenConglomInfo[] indexDCOCIs;
0: 	private boolean needToObjectifyStream;
0: 
0: 
0: 	public int rowCount;
0: 
0: 
0: 	/**
0: 	 * Constructor
0: 	 *
0:  	 * @param activation		an activation
0: 	 * @param constantAction	a write constant action
0: 	 *
0:  	 * @exception StandardException on error
0: 	 */
0: 	protected DMLWriteResultSet(Activation activation)
0: 		throws StandardException
0: 	{
0: 		this(activation, activation.getConstantAction());
0: 	}
0: 	protected DMLWriteResultSet(Activation activation, ConstantAction constantAction)
0: 		throws StandardException
0: 	{
0: 		super(activation);
0: 
0: 		this.constantAction = (WriteCursorConstantAction) constantAction;
0: 		baseRowReadMap = this.constantAction.getBaseRowReadMap();
0: 		streamStorableHeapColIds = this.constantAction.getStreamStorableHeapColIds();
0: 
0: 		TransactionController tc = activation.getTransactionController();
0: 
0: 		// Special handling for updatable VTIs
0: 		if (! (constantAction instanceof UpdatableVTIConstantAction))
0: 		{
0: 			heapDCOCI = tc.getDynamicCompiledConglomInfo(this.constantAction.conglomId);
0: 			if (this.constantAction.indexCIDS.length != 0)
0: 			{
0: 				indexDCOCIs = new DynamicCompiledOpenConglomInfo[this.constantAction.indexCIDS.length];
0: 				for (int index = 0; index < this.constantAction.indexCIDS.length; index++)
0: 				{
0: 					indexDCOCIs[index] = tc.getDynamicCompiledConglomInfo(
0: 												this.constantAction.indexCIDS[index]);
0: 				}
0: 			}
0: 		}
0: 
0: 		/* We only need to objectify the streams here if they are exposed to the users through the
0: 		 * trigger context.  For "before" trigger, we could just return the stream wrapped in
0: 		 * RememberBytesInputStream to the user and reset it after usage, but this wouldn't work
0: 		 * because the user may get the stream in trigger action and do something with it in parallel
0: 		 * with the store doing insert.  We could also delay the materializing until the stream is
0: 		 * fetched in before trigger but that would complicate the code.  For "after" trigger, we have
0: 		 * to materialize it here because store only keeps a page's amount for each round.  For other
0: 		 * reasons of "deferred" operations we don't need to objectify here.  Simply going through a
0: 		 * temp table (either in memory part or spilled to disk) is fine for the stream, unless a
0: 		 * same stream appears in two rows in the temp table, which could happen for an "update", in
0: 		 * which case we do the objectifying in UpdateResultSet.  Beetle 4896.  Related bug entries:
0: 		 * 2432, 3383.
0: 		 */
0: 		needToObjectifyStream = (this.constantAction.getTriggerInfo(
0: 						activation.getLanguageConnectionContext().getExecutionContext()) != null);
0: 	}
0: 
0: 	public final int	modifiedRowCount() { return rowCount; }
0: 
0: 
0: 	/**
0: 	 * Get next row from the source result set.
0: 	 * 
0: 	 * @param source		SourceResultSet
0: 	 * Also look at Track#2432/change 12433
0: 	 */
0: 	protected ExecRow getNextRowCore(NoPutResultSet source)
0: 		throws StandardException
0: 	{
0: 		ExecRow row = source.getNextRowCore();
0: 		if (needToObjectifyStream)
0: 		{
0: 			/* 
0: 			   See comments in the constructor. We also need to load the column
0: 			   if it is part of an index on an insert but that is done in
0: 			   insertResultSet#normalInsertCore or IRS#changedRow
0: 			*/
0: 			objectifyStreams(row);
0: 		}
0: 		return row;
0: 	}
0: 
0: 	private void objectifyStreams(ExecRow row) throws StandardException 
0: 	{
0: 		// if the column is a streamStorable, we need to materialize the object
0: 		// therefore, the object can be used to multiple rows.
0: 		if ((row != null) && (streamStorableHeapColIds != null))
0: 		{
0: 			for (int ix=0; ix < streamStorableHeapColIds.length; ix++)
0: 			{
0: 				int heapIx = streamStorableHeapColIds[ix];
0: 				int readIx = (baseRowReadMap == null) ?
0: 					heapIx :
0: 					baseRowReadMap[heapIx];
0: 
0: 				DataValueDescriptor col = row.getColumn(readIx+1);
0: 				((StreamStorable)col).loadStream();
0: 			}
0: 		}
0: 	}
0: 
0: 	/**
0: 	 * For deferred update, get a deferred sparse row based on the
0: 	 * deferred non-sparse row. Share the underlying columns. If there
0: 	 * is no column bit map, make them the same row.
0: 	 *
0: 	 * @exception StandardException		Thrown on error
0: 	 */
0: 	protected ExecRow makeDeferredSparseRow(
0: 							ExecRow deferredBaseRow,
0: 							FormatableBitSet baseRowReadList,
0: 							LanguageConnectionContext lcc)
0: 				throws StandardException
0: 	{
0: 		ExecRow deferredSparseRow;
0: 
0: 		if (baseRowReadList == null)
0: 		{
0: 			/* No sparse row */
0: 			deferredSparseRow = deferredBaseRow;
0: 		}
0: 		else
0: 		{
0: 			/*
0: 			** We need to do a fetch doing a partial row
0: 			** read.  We need to shift our 1-based bit
0: 			** set to a zero based bit set like the store
0: 			** expects.
0: 			*/
0: 			deferredSparseRow =
0: 				RowUtil.getEmptyValueRow(
0: 								baseRowReadList.getLength() - 1,
0: 								lcc);
0: 			/*
0: 			** getColumn(), setColumn(), and baseRowReadList are
0: 			** one-based.
0: 			*/
0: 			int fromPosition = 1;
0: 			for (int i = 1; i <= deferredSparseRow.nColumns(); i++)
0: 			{
0: 				if (baseRowReadList.isSet(i))
0: 				{
0: 					deferredSparseRow.setColumn(
0: 						i,
0: 						deferredBaseRow.getColumn(fromPosition++)
0: 						);
0: 				}
0: 			}
0: 		}
0: 
0: 		return deferredSparseRow;
0: 	}
0: 	
0: 	/**
0: 	 * get the index name given the conglomerate id of the index.
0: 	 * 
0: 	 * @param indexCID		conglomerate ID of the index.
0: 	 * 
0: 	 * @return index name of given index.
0: 	 */
0: 	String getIndexNameFromCID(long indexCID)
0: 	{
0: 		return this.constantAction.getIndexNameFromCID(indexCID);
0: 	}
0: }
============================================================================
1:801c515: /*
10:801c515: 
1:bb0c274:    Derby - Class org.apache.derbyTesting.functionTests.tests.storetests.st_derby1939
1:801c515: 
1:bb0c274:    Licensed to the Apache Software Foundation (ASF) under one
1:bb0c274:    or more contributor license agreements.  See the NOTICE file
1:bb0c274:    distributed with this work for additional information
1:bb0c274:    regarding copyright ownership.  The ASF licenses this file
1:bb0c274:    to you under the Apache License, Version 2.0 (the
1:bb0c274:    "License"); you may not use this file except in compliance
1:bb0c274:    with the License.  You may obtain a copy of the License at
1:801c515: 
1:bb0c274:      http://www.apache.org/licenses/LICENSE-2.0
1:801c515: 
1:bb0c274:    Unless required by applicable law or agreed to in writing,
1:bb0c274:    software distributed under the License is distributed on an
1:bb0c274:    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:bb0c274:    KIND, either express or implied.  See the License for the
1:bb0c274:    specific language governing permissions and limitations
1:bb0c274:    under the License.
1:801c515: 
1:801c515:  */
1:801c515: package org.apache.derbyTesting.functionTests.tests.storetests;
1:801c515: 
1:801c515: 
1:801c515: import java.sql.*;
1:43bb9d4: import java.util.Properties;
1:43bb9d4: import junit.framework.Test;
1:43bb9d4: import org.apache.derbyTesting.junit.BaseJDBCTestCase;
1:43bb9d4: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1:43bb9d4: import org.apache.derbyTesting.junit.SystemPropertyTestSetup;
1:43bb9d4: import org.apache.derbyTesting.junit.TestConfiguration;
1:801c515: 
1:801c515: /**
1:801c515:  * Repro for DERBY-1939.  In effect what we have to do is execute
1:801c515:  * a query (using a PreparedStatement) for which the optimizer
1:801c515:  * will choose to do a Hash Join using an IndexToBaseRow result
1:801c515:  * result.  But that's not enough--at execution time, we then
1:801c515:  * have to force a situation where the Hash Table "spills" to
1:801c515:  * disk, and only then will the error occur.
1:801c515:  *
1:801c515:  * In order to get the optimizer to choose the necessary plan
1:801c515:  * we have a moderately complex query that has a predicate
1:801c515:  * which can be pushed to table T1.  T1 in turn has an index
1:801c515:  * declared on the appropriate column.  The optimizer will
1:801c515:  * then choose to do a Hash Join between T2 and T1 and
1:801c515:  * will use the index on T1, as desired.
1:801c515:  *
1:801c515:  * Then, in order to force the "spill" to disk, we use the
1:801c515:  * Derby property "maxMemoryPerTable" and set it to a
1:801c515:  * "magic" value that a) is large enough to allow the optimizer
1:801c515:  * to choose a Hash Join, but b) is small enough to cause
1:801c515:  * hash-table-spill-over at execution time.  It took a while
1:801c515:  * find out what value this property should have given the
1:801c515:  * data in the tables, but having found it we can now reliably
1:801c515:  * reproduce the failure.
1:801c515:  */
1:43bb9d4: public class st_derby1939 extends BaseJDBCTestCase {
1:801c515: 
1:801c515: 	// We have a VARCHAR column in the table to help with the
1:801c515: 	// hash table "spill-over".
1:801c515: 	private final int VC_SIZE = 1024;
1:801c515: 
1:43bb9d4:     public st_derby1939(String name) {
1:43bb9d4:         super(name);
1:43bb9d4:     }
1:43bb9d4: 
1:43bb9d4:     public static Test suite() {
1:43bb9d4:         Properties sysprops = new Properties();
1:43bb9d4:         sysprops.setProperty("derby.language.maxMemoryPerTable", "140");
1:43bb9d4:         sysprops.setProperty("derby.optimizer.noTimeout", "true");
1:43bb9d4:         return new SystemPropertyTestSetup(
1:43bb9d4:                 new CleanDatabaseTestSetup(
1:43bb9d4:                         TestConfiguration.embeddedSuite(st_derby1939.class)),
1:43bb9d4:                 sysprops, true);
1:43bb9d4:     }
1:43bb9d4: 
1:43bb9d4:     public void testDerby1939() throws SQLException {
1:43bb9d4:         setAutoCommit(false);
1:43bb9d4:         doLoad();
1:43bb9d4:         doQuery();
1:43bb9d4:     }
1:43bb9d4: 
1:43bb9d4:     private void doLoad() throws SQLException
2:801c515: 	{
1:43bb9d4:         Statement st = createStatement();
1:801c515: 
1:43bb9d4:         println("Creating tables and index...");
1:801c515: 		st.execute("create table d1939_t1 (i smallint, vc varchar(" + VC_SIZE + "))");
1:801c515: 		st.execute("create table d1939_t2 (j smallint, val double, vc varchar(" + VC_SIZE + "))");
1:801c515: 		st.execute("create index ix_d1939_t1 on d1939_t1 (i)");
1:801c515: 
1:43bb9d4:         PreparedStatement pSt = prepareStatement(
1:801c515: 			"insert into d1939_t1(i, vc) values (?, ?)");
1:801c515: 
1:43bb9d4:         PreparedStatement pSt2 = prepareStatement(
1:801c515: 			"insert into d1939_t2 values (?, ?, ?)");
1:801c515: 
1:43bb9d4:         println("Doing inserts...");
1:801c515: 	
1:801c515: 		// Number of rows and columns here is pretty much just "magic";
1:801c515: 		// changing any of them can make it so that the problem doesn't
1:801c515: 		// reproduce...
1:801c515: 		for (int i = 0; i < 69; i++)
1:801c515: 		{
1:801c515: 			/* In order for the repro to work, the data in the tables
1:801c515: 			 * has to be sequential w.r.t the smallint column.  I.e.
1:801c515: 			 * instead of inserting "1, 2, 3, 1, 2, 3, ..." we have to
1:801c515: 			 * insert "1, 1, 1, 2, 2, 2, ...".  So that's what the
1:801c515: 			 * "i % 10" achieves in this code.
1:801c515: 			 */
1:801c515: 			for (int j = 0; j < 10; j++)
1:801c515: 			{
1:43bb9d4:                 String str = buildString(i + ":" + j);
1:801c515: 				pSt.setInt(1, i % 10);
1:801c515: 				pSt.setString(2, str);
1:801c515: 				pSt.execute();
1:801c515: 				pSt2.setInt(1, i % 10);
1:801c515: 				pSt2.setDouble(2, j*2.0d);
1:801c515: 				if (j % 2 == 1)
1:801c515: 					pSt2.setString(3, "shorty-string");
1:801c515: 				else
1:801c515: 					pSt2.setString(3, str);
1:801c515: 				pSt2.execute();
3:801c515: 			}
1:801c515: 
1:801c515: 			// Add some extra rows T2, just because.
1:801c515: 			pSt2.setInt(1, i);
1:801c515: 			pSt2.setDouble(2, i*2.0d);
1:801c515: 			pSt2.setNull(3, Types.VARCHAR);
1:801c515: 			pSt2.execute();
1:801c515: 		}
1:801c515: 
1:801c515: 		pSt2.setNull(1, Types.INTEGER);
1:801c515: 		pSt2.setDouble(2, 48.0d);
1:801c515: 		pSt.close();
1:43bb9d4:         commit();
1:801c515: 	}
1:801c515: 
1:43bb9d4:     private void doQuery() throws SQLException
1:801c515: 	{
1:801c515: 		/* Set Derby properties to allow the optimizer to find the
1:801c515: 		 * best plan (Hash Join with Index) and also to set a max
1:801c515: 		 * memory size on the hash table, which makes it possible
1:801c515: 		 * to "spill" to disk.
1:801c515: 		 */
1:801c515: 
1:43bb9d4:         PreparedStatement pSt = prepareStatement(
1:801c515: 			"select * from d1939_t2 " +
1:801c515: 			"  left outer join " +
1:801c515: 			"    (select distinct d1939_t1.i, d1939_t2.j, d1939_t1.vc from d1939_t2 " + 
1:801c515: 			"      left outer join d1939_t1 " +
1:801c515: 			"        on d1939_t2.j = d1939_t1.i " +
1:801c515: 			"        and d1939_t1.i = ? " + 
1:801c515: 			"    ) x1 " + 
1:801c515: 			"  on d1939_t2.j = x1.i");
1:801c515: 
1:43bb9d4:         println("Done preparing, about to execute...");
1:801c515: 		pSt.setShort(1, (short)8);
1:801c515: 		int count = 0;
4:801c515: 		try {
1:801c515: 
1:801c515: 			// Will fail on next line without fix for DERBY-1939.
1:801c515: 			ResultSet rs = pSt.executeQuery();
1:801c515: 
1:801c515: 			// To iterate through the rows actually takes quite a long time,
1:801c515: 			// so just get the first 10 rows as a sanity check.
1:801c515: 			for (count = 0; rs.next() && count < 10; count++);
1:801c515: 			rs.close();
1:43bb9d4:             println("Ran without error, retrieved first " + count + " rows.");
1:801c515: 
1:801c515: 		} catch (SQLException se) {
1:801c515: 
1:801c515: 			if (se.getSQLState().equals("XSDA7"))
1:801c515: 			{
1:43bb9d4:                 fail("Reproduced DERBY-1939", se);
1:801c515: 			}
1:801c515: 			else
1:801c515: 				throw se;
1:801c515: 
1:801c515: 		}
1:801c515: 
1:801c515: 		pSt.close();
1:43bb9d4:         rollback();
1:801c515: 	}
1:801c515: 
1:801c515: 	private String buildString(String s) {
1:43bb9d4:         StringBuilder sb = new StringBuilder(VC_SIZE);
1:43bb9d4:         for (int i = 0; i < VC_SIZE; i++) {
1:43bb9d4:             sb.append(s.charAt(i % s.length()));
1:43bb9d4:         }
1:43bb9d4:         return sb.toString();
1:801c515: 	}
1:801c515: }
============================================================================
author:Knut Anders Hatlen
-------------------------------------------------------------------------------
commit:43bb9d4
/////////////////////////////////////////////////////////////////////////
1: import java.util.Properties;
1: import junit.framework.Test;
1: import org.apache.derbyTesting.junit.BaseJDBCTestCase;
1: import org.apache.derbyTesting.junit.CleanDatabaseTestSetup;
1: import org.apache.derbyTesting.junit.SystemPropertyTestSetup;
1: import org.apache.derbyTesting.junit.TestConfiguration;
/////////////////////////////////////////////////////////////////////////
1: public class st_derby1939 extends BaseJDBCTestCase {
1:     public st_derby1939(String name) {
1:         super(name);
1:     }
1: 
1:     public static Test suite() {
1:         Properties sysprops = new Properties();
1:         sysprops.setProperty("derby.language.maxMemoryPerTable", "140");
1:         sysprops.setProperty("derby.optimizer.noTimeout", "true");
1:         return new SystemPropertyTestSetup(
1:                 new CleanDatabaseTestSetup(
1:                         TestConfiguration.embeddedSuite(st_derby1939.class)),
1:                 sysprops, true);
1:     }
1: 
1:     public void testDerby1939() throws SQLException {
1:         setAutoCommit(false);
1:         doLoad();
1:         doQuery();
1:     }
1: 
1:     private void doLoad() throws SQLException
1:         Statement st = createStatement();
1:         println("Creating tables and index...");
1:         PreparedStatement pSt = prepareStatement(
1:         PreparedStatement pSt2 = prepareStatement(
1:         println("Doing inserts...");
/////////////////////////////////////////////////////////////////////////
1:                 String str = buildString(i + ":" + j);
/////////////////////////////////////////////////////////////////////////
1:         commit();
1:     private void doQuery() throws SQLException
/////////////////////////////////////////////////////////////////////////
1:         PreparedStatement pSt = prepareStatement(
/////////////////////////////////////////////////////////////////////////
1:         println("Done preparing, about to execute...");
/////////////////////////////////////////////////////////////////////////
1:             println("Ran without error, retrieved first " + count + " rows.");
1:                 fail("Reproduced DERBY-1939", se);
/////////////////////////////////////////////////////////////////////////
1:         rollback();
1:         StringBuilder sb = new StringBuilder(VC_SIZE);
1:         for (int i = 0; i < VC_SIZE; i++) {
1:             sb.append(s.charAt(i % s.length()));
1:         }
1:         return sb.toString();
author:Kristian Waagan
-------------------------------------------------------------------------------
commit:bb0c274
/////////////////////////////////////////////////////////////////////////
1:    Derby - Class org.apache.derbyTesting.functionTests.tests.storetests.st_derby1939
1:    Licensed to the Apache Software Foundation (ASF) under one
1:    or more contributor license agreements.  See the NOTICE file
1:    distributed with this work for additional information
1:    regarding copyright ownership.  The ASF licenses this file
1:    to you under the Apache License, Version 2.0 (the
1:    "License"); you may not use this file except in compliance
1:    with the License.  You may obtain a copy of the License at
1:      http://www.apache.org/licenses/LICENSE-2.0
1:    Unless required by applicable law or agreed to in writing,
1:    software distributed under the License is distributed on an
1:    "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
1:    KIND, either express or implied.  See the License for the
1:    specific language governing permissions and limitations
1:    under the License.
commit:ffb9317
/////////////////////////////////////////////////////////////////////////
author:Mike Matrigali
-------------------------------------------------------------------------------
commit:801c515
/////////////////////////////////////////////////////////////////////////
1: /*
1: 
0:    Derby - Class org.apache.derbyTesting.functionTests.harness.procedure
1: 
0:    Copyright 2006 The Apache Software Foundation or its licensors, as applicable.
1: 
0:    Licensed under the Apache License, Version 2.0 (the "License");
0:    you may not use this file except in compliance with the License.
0:    You may obtain a copy of the License at
1: 
0:       http://www.apache.org/licenses/LICENSE-2.0
1: 
0:    Unless required by applicable law or agreed to in writing, software
0:    distributed under the License is distributed on an "AS IS" BASIS,
0:    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
0:    See the License for the specific language governing permissions and
0:    limitations under the License.
1: 
1:  */
1: 
1: package org.apache.derbyTesting.functionTests.tests.storetests;
1: 
0: import org.apache.derby.tools.ij;
1: 
1: import java.sql.*;
1: 
1: /**
1:  * Repro for DERBY-1939.  In effect what we have to do is execute
1:  * a query (using a PreparedStatement) for which the optimizer
1:  * will choose to do a Hash Join using an IndexToBaseRow result
1:  * result.  But that's not enough--at execution time, we then
1:  * have to force a situation where the Hash Table "spills" to
1:  * disk, and only then will the error occur.
1:  *
1:  * In order to get the optimizer to choose the necessary plan
1:  * we have a moderately complex query that has a predicate
1:  * which can be pushed to table T1.  T1 in turn has an index
1:  * declared on the appropriate column.  The optimizer will
1:  * then choose to do a Hash Join between T2 and T1 and
1:  * will use the index on T1, as desired.
1:  *
1:  * Then, in order to force the "spill" to disk, we use the
1:  * Derby property "maxMemoryPerTable" and set it to a
1:  * "magic" value that a) is large enough to allow the optimizer
1:  * to choose a Hash Join, but b) is small enough to cause
1:  * hash-table-spill-over at execution time.  It took a while
1:  * find out what value this property should have given the
1:  * data in the tables, but having found it we can now reliably
1:  * reproduce the failure.
1:  */
0: public class st_derby1939 {
1: 
1: 	// We have a VARCHAR column in the table to help with the
1: 	// hash table "spill-over".
1: 	private final int VC_SIZE = 1024;
0: 	private char[] cArr = new char[VC_SIZE];
1: 
0: 	public static void main(String [] args)
1: 	{
1: 
1: 		try {
0:             System.setProperty("derby.language.maxMemoryPerTable", "140");
0:             System.setProperty("derby.optimizer.noTimeout", "true");
1: 
0:             ij.getPropertyArg(args);
0:             Connection conn = ij.startJBMS();
1: 
0:             st_derby1939 test = new st_derby1939();
0:             test.doLoad(conn);
0:             test.doQuery(conn);
0:             conn.close();
0: 		} catch (Throwable t) {
0: 			System.out.println("OOPS, unexpected error:");
0: 			t.printStackTrace();
1: 		}
1: 	}
1: 
0: 	private void doLoad(Connection conn) throws Exception
1: 	{
0: 		conn.setAutoCommit(false);
0: 		Statement st = conn.createStatement();
1: 		try {
0: 			st.execute("drop table d1939_t1");
0: 		} catch (SQLException se) {}
1: 		try {
0: 			st.execute("drop table d1939_t2");
0: 		} catch (SQLException se) {}
1: 
0: 		System.out.println("Creating tables and index...");
1: 		st.execute("create table d1939_t1 (i smallint, vc varchar(" + VC_SIZE + "))");
1: 		st.execute("create table d1939_t2 (j smallint, val double, vc varchar(" + VC_SIZE + "))");
1: 		st.execute("create index ix_d1939_t1 on d1939_t1 (i)");
1: 
0: 		PreparedStatement pSt = conn.prepareStatement(
1: 			"insert into d1939_t1(i, vc) values (?, ?)");
1: 
0: 		PreparedStatement pSt2 = conn.prepareStatement(
1: 			"insert into d1939_t2 values (?, ?, ?)");
1: 
0: 		String str = null;
0: 		System.out.println("Doing inserts...");
1: 	
1: 		// Number of rows and columns here is pretty much just "magic";
1: 		// changing any of them can make it so that the problem doesn't
1: 		// reproduce...
1: 		for (int i = 0; i < 69; i++)
1: 		{
1: 			/* In order for the repro to work, the data in the tables
1: 			 * has to be sequential w.r.t the smallint column.  I.e.
1: 			 * instead of inserting "1, 2, 3, 1, 2, 3, ..." we have to
1: 			 * insert "1, 1, 1, 2, 2, 2, ...".  So that's what the
1: 			 * "i % 10" achieves in this code.
1: 			 */
1: 			for (int j = 0; j < 10; j++)
1: 			{
0: 				str = buildString(i + ":" + j);
1: 				pSt.setInt(1, i % 10);
1: 				pSt.setString(2, str);
1: 				pSt.execute();
1: 				pSt2.setInt(1, i % 10);
1: 				pSt2.setDouble(2, j*2.0d);
1: 				if (j % 2 == 1)
1: 					pSt2.setString(3, "shorty-string");
1: 				else
1: 					pSt2.setString(3, str);
1: 				pSt2.execute();
1: 			}
1: 
1: 			// Add some extra rows T2, just because.
1: 			pSt2.setInt(1, i);
1: 			pSt2.setDouble(2, i*2.0d);
1: 			pSt2.setNull(3, Types.VARCHAR);
1: 			pSt2.execute();
1: 		}
1: 
1: 		pSt2.setNull(1, Types.INTEGER);
1: 		pSt2.setDouble(2, 48.0d);
1: 		pSt.close();
0: 		conn.commit();
1: 	}
1: 
0: 	private void doQuery(Connection conn) throws Exception
1: 	{
1: 		/* Set Derby properties to allow the optimizer to find the
1: 		 * best plan (Hash Join with Index) and also to set a max
1: 		 * memory size on the hash table, which makes it possible
1: 		 * to "spill" to disk.
1: 		 */
1: 
1: 
0: 		conn.setAutoCommit(false);
0: 		PreparedStatement pSt = conn.prepareStatement(
1: 			"select * from d1939_t2 " +
1: 			"  left outer join " +
1: 			"    (select distinct d1939_t1.i, d1939_t2.j, d1939_t1.vc from d1939_t2 " + 
1: 			"      left outer join d1939_t1 " +
1: 			"        on d1939_t2.j = d1939_t1.i " +
1: 			"        and d1939_t1.i = ? " + 
1: 			"    ) x1 " + 
1: 			"  on d1939_t2.j = x1.i");
1: 
0: 		System.out.println("Done preparing, about to execute...");
1: 		pSt.setShort(1, (short)8);
1: 		int count = 0;
1: 		try {
1: 
1: 			// Will fail on next line without fix for DERBY-1939.
1: 			ResultSet rs = pSt.executeQuery();
1: 
1: 			// To iterate through the rows actually takes quite a long time,
1: 			// so just get the first 10 rows as a sanity check.
1: 			for (count = 0; rs.next() && count < 10; count++);
1: 			rs.close();
0: 			System.out.println("-=-> Ran without error, retrieved first "
0: 				 + count + " rows.");
1: 
1: 		} catch (SQLException se) {
1: 
1: 			if (se.getSQLState().equals("XSDA7"))
1: 			{
0: 				System.out.println("-=-> Reproduced DERBY-1939:\n" +
0: 					" -- " + se.getMessage());
1: 			}
1: 			else
1: 				throw se;
1: 
1: 		}
1: 
1: 		pSt.close();
0: 		conn.rollback();
1: 	}
1: 
1: 	private String buildString(String s) {
1: 
0: 		char [] sArr = new char [] { s.charAt(0), s.charAt(1), s.charAt(2) };
0: 		for (int i = 0; i < cArr.length; i++)
0: 			cArr[i] = sArr[i % 3];
1: 
0: 		return new String(cArr);
1: 	}
1: }
============================================================================
1:456a2ba: /**
1:456a2ba:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:456a2ba:  * contributor license agreements.  See the NOTICE file distributed with
1:456a2ba:  * this work for additional information regarding copyright ownership.
1:456a2ba:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:456a2ba:  * (the "License"); you may not use this file except in compliance with
1:456a2ba:  * the License.  You may obtain a copy of the License at
1:40f9146:  *
1:456a2ba:  *      http://www.apache.org/licenses/LICENSE-2.0
1:40f9146:  *
1:456a2ba:  * Unless required by applicable law or agreed to in writing, software
1:456a2ba:  * distributed under the License is distributed on an "AS IS" BASIS,
1:456a2ba:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:456a2ba:  * See the License for the specific language governing permissions and
1:456a2ba:  * limitations under the License.
1:456a2ba:  */
1:f62737b: package org.apache.activemq.store.kahadb;
1:a6a6a70: 
1:1c41085: import static org.apache.activemq.store.kahadb.disk.journal.Location.NOT_SET;
1:15405af: 
1:3f0cf98: import java.io.ByteArrayInputStream;
1:a6a6a70: import java.io.ByteArrayOutputStream;
1:1595378: import java.io.DataInput;
1:1595378: import java.io.DataOutput;
1:1595378: import java.io.EOFException;
1:1595378: import java.io.File;
1:1595378: import java.io.IOException;
1:1595378: import java.io.InputStream;
1:0af0021: import java.io.InterruptedIOException;
1:1595378: import java.io.ObjectInputStream;
1:1595378: import java.io.ObjectOutputStream;
1:1595378: import java.io.OutputStream;
1:0af0021: import java.util.ArrayList;
1:0dcdab7: import java.util.Arrays;
1:0af0021: import java.util.Collection;
1:0af0021: import java.util.Collections;
1:0af0021: import java.util.Date;
1:0af0021: import java.util.HashMap;
1:0af0021: import java.util.HashSet;
1:0af0021: import java.util.Iterator;
1:0af0021: import java.util.LinkedHashMap;
1:0af0021: import java.util.LinkedHashSet;
1:54e2e3b: import java.util.LinkedList;
1:0af0021: import java.util.List;
1:0af0021: import java.util.Map;
1:456a2ba: import java.util.Map.Entry;
1:0af0021: import java.util.Set;
1:0af0021: import java.util.SortedSet;
1:0af0021: import java.util.TreeMap;
1:0af0021: import java.util.TreeSet;
1:785b16b: import java.util.concurrent.ConcurrentHashMap;
1:b52796f: import java.util.concurrent.ConcurrentMap;
1:946e62d: import java.util.concurrent.Executors;
1:946e62d: import java.util.concurrent.ScheduledExecutorService;
1:946e62d: import java.util.concurrent.ThreadFactory;
1:946e62d: import java.util.concurrent.TimeUnit;
1:456a2ba: import java.util.concurrent.atomic.AtomicBoolean;
1:5763561: import java.util.concurrent.atomic.AtomicLong;
1:1a59827: import java.util.concurrent.atomic.AtomicReference;
1:5f7fc14: import java.util.concurrent.locks.ReentrantReadWriteLock;
1:6b643dc: 
1:a6a6a70: import org.apache.activemq.ActiveMQMessageAuditNoSync;
1:b1a9130: import org.apache.activemq.broker.BrokerService;
1:b1a9130: import org.apache.activemq.broker.BrokerServiceAware;
1:785b16b: import org.apache.activemq.broker.region.Destination;
1:785b16b: import org.apache.activemq.broker.region.Queue;
1:785b16b: import org.apache.activemq.broker.region.Topic;
1:101e711: import org.apache.activemq.command.MessageAck;
1:456a2ba: import org.apache.activemq.command.TransactionId;
1:bc4392b: import org.apache.activemq.openwire.OpenWireFormat;
1:a6a6a70: import org.apache.activemq.protobuf.Buffer;
1:785b16b: import org.apache.activemq.store.MessageStore;
1:785b16b: import org.apache.activemq.store.MessageStoreStatistics;
1:cf3d419: import org.apache.activemq.store.MessageStoreSubscriptionStatistics;
1:cf3d419: import org.apache.activemq.store.TopicMessageStore;
1:3bf9d0c: import org.apache.activemq.store.kahadb.data.KahaAckMessageFileMapCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaAddMessageCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaCommitCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaDestination;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaEntryType;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaPrepareCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaProducerAuditCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaRemoveDestinationCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaRemoveMessageCommand;
1:946e62d: import org.apache.activemq.store.kahadb.data.KahaRewrittenDataFileCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaRollbackCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaSubscriptionCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
1:1595378: import org.apache.activemq.store.kahadb.data.KahaTransactionInfo;
1:266d23e: import org.apache.activemq.store.kahadb.data.KahaUpdateMessageCommand;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.index.BTreeIndex;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.index.BTreeVisitor;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.index.ListIndex;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.journal.DataFile;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1:dd0ed17: import org.apache.activemq.store.kahadb.disk.journal.Journal.JournalDiskSyncStrategy;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.journal.Location;
1:946e62d: import org.apache.activemq.store.kahadb.disk.journal.TargetedDataFileAppender;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.page.Page;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.page.PageFile;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.page.Transaction;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.LocationMarshaller;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.LongMarshaller;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.Marshaller;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.Sequence;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.SequenceSet;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.StringMarshaller;
1:1aab71b: import org.apache.activemq.store.kahadb.disk.util.VariableMarshaller;
1:3bf9d0c: import org.apache.activemq.util.ByteSequence;
1:3bf9d0c: import org.apache.activemq.util.DataByteArrayInputStream;
1:3bf9d0c: import org.apache.activemq.util.DataByteArrayOutputStream;
1:946e62d: import org.apache.activemq.util.IOExceptionSupport;
1:3bf9d0c: import org.apache.activemq.util.IOHelper;
1:3bf9d0c: import org.apache.activemq.util.ServiceStopper;
1:3bf9d0c: import org.apache.activemq.util.ServiceSupport;
1:946e62d: import org.apache.activemq.util.ThreadPoolUtils;
1:1595378: import org.slf4j.Logger;
1:1595378: import org.slf4j.LoggerFactory;
1:4386750: import org.slf4j.MDC;
1:1c41085: 
1:2030097: public abstract class MessageDatabase extends ServiceSupport implements BrokerServiceAware {
1:db3f8b3: 
1:40f9146:     protected BrokerService brokerService;
1:6b643dc: 
1:35658c7:     public static final String PROPERTY_LOG_SLOW_ACCESS_TIME = "org.apache.activemq.store.kahadb.LOG_SLOW_ACCESS_TIME";
1:cdba931:     public static final int LOG_SLOW_ACCESS_TIME = Integer.getInteger(PROPERTY_LOG_SLOW_ACCESS_TIME, 0);
1:85edfb3:     public static final File DEFAULT_DIRECTORY = new File("KahaDB");
1:5477bc0:     protected static final Buffer UNMATCHED;
1:5477bc0:     static {
1:5477bc0:         UNMATCHED = new Buffer(new byte[]{});
1:6dea944:     }
1:8bf987b:     private static final Logger LOG = LoggerFactory.getLogger(MessageDatabase.class);
1:785b16b: 
1:a6a6a70:     static final int CLOSED_STATE = 1;
1:a6a6a70:     static final int OPEN_STATE = 2;
1:a6a6a70:     static final long NOT_ACKED = -1;
1:45e59e6: 
1:785b16b:     static final int VERSION = 6;
1:45e59e6: 
1:946e62d:     static final byte COMPACTED_JOURNAL_FILE = DataFile.STANDARD_LOG_FILE + 1;
1:946e62d: 
1:456a2ba:     protected class Metadata {
1:456a2ba:         protected Page<Metadata> page;
1:456a2ba:         protected int state;
1:456a2ba:         protected BTreeIndex<String, StoredDestination> destinations;
1:456a2ba:         protected Location lastUpdate;
1:456a2ba:         protected Location firstInProgressTransactionLocation;
1:a6a6a70:         protected Location producerSequenceIdTrackerLocation = null;
1:3bf9d0c:         protected Location ackMessageFileMapLocation = null;
1:a6a6a70:         protected transient ActiveMQMessageAuditNoSync producerSequenceIdTracker = new ActiveMQMessageAuditNoSync();
1:281d600:         protected transient Map<Integer, Set<Integer>> ackMessageFileMap = new HashMap<>();
1:cba0468:         protected int version = VERSION;
1:13044de:         protected int openwireVersion = OpenWireFormat.DEFAULT_STORE_VERSION;
1:232b8c5: 
1:456a2ba:         public void read(DataInput is) throws IOException {
1:456a2ba:             state = is.readInt();
1:281d600:             destinations = new BTreeIndex<>(pageFile, is.readLong());
1:456a2ba:             if (is.readBoolean()) {
1:456a2ba:                 lastUpdate = LocationMarshaller.INSTANCE.readPayload(is);
1:946e62d:             } else {
1:456a2ba:                 lastUpdate = null;
1:45e59e6:             }
1:456a2ba:             if (is.readBoolean()) {
1:456a2ba:                 firstInProgressTransactionLocation = LocationMarshaller.INSTANCE.readPayload(is);
1:38b840a:             } else {
1:456a2ba:                 firstInProgressTransactionLocation = null;
1:2030097:             }
1:54e2e3b:             try {
1:a6a6a70:                 if (is.readBoolean()) {
1:a6a6a70:                     producerSequenceIdTrackerLocation = LocationMarshaller.INSTANCE.readPayload(is);
1:a6a6a70:                 } else {
1:a6a6a70:                     producerSequenceIdTrackerLocation = null;
1:1c41085:                 }
1:a6a6a70:             } catch (EOFException expectedOnUpgrade) {
1:2030097:             }
1:62c6c8f:             try {
1:1595378:                 version = is.readInt();
1:5325cdb:             } catch (EOFException expectedOnUpgrade) {
1:bc4392b:                 version = 1;
1:a6c51a4:             }
1:3bf9d0c:             if (version >= 5 && is.readBoolean()) {
1:3bf9d0c:                 ackMessageFileMapLocation = LocationMarshaller.INSTANCE.readPayload(is);
1:3bf9d0c:             } else {
1:3bf9d0c:                 ackMessageFileMapLocation = null;
1:62c6c8f:             }
1:a6a6a70:             try {
1:bc4392b:                 openwireVersion = is.readInt();
1:bc4392b:             } catch (EOFException expectedOnUpgrade) {
1:13044de:                 openwireVersion = OpenWireFormat.DEFAULT_LEGACY_VERSION;
1:3f0cf98:             }
1:cba0468:             LOG.info("KahaDB is version " + version);
1:6dea944:         }
1:946e62d: 
1:456a2ba:         public void write(DataOutput os) throws IOException {
1:456a2ba:             os.writeInt(state);
1:456a2ba:             os.writeLong(destinations.getPageId());
1:2030097: 
1:456a2ba:             if (lastUpdate != null) {
1:456a2ba:                 os.writeBoolean(true);
1:456a2ba:                 LocationMarshaller.INSTANCE.writePayload(lastUpdate, os);
1:40f9146:             } else {
1:456a2ba:                 os.writeBoolean(false);
1:5477bc0:             }
1:2030097: 
1:456a2ba:             if (firstInProgressTransactionLocation != null) {
1:456a2ba:                 os.writeBoolean(true);
1:456a2ba:                 LocationMarshaller.INSTANCE.writePayload(firstInProgressTransactionLocation, os);
1:40f9146:             } else {
1:456a2ba:                 os.writeBoolean(false);
1:a6a6a70:             }
1:a6c51a4: 
1:a6a6a70:             if (producerSequenceIdTrackerLocation != null) {
1:a6a6a70:                 os.writeBoolean(true);
1:a6a6a70:                 LocationMarshaller.INSTANCE.writePayload(producerSequenceIdTrackerLocation, os);
1:a6a6a70:             } else {
1:a6a6a70:                 os.writeBoolean(false);
1:a6a6a70:             }
1:3f0cf98:             os.writeInt(VERSION);
1:3bf9d0c:             if (ackMessageFileMapLocation != null) {
1:3bf9d0c:                 os.writeBoolean(true);
1:3bf9d0c:                 LocationMarshaller.INSTANCE.writePayload(ackMessageFileMapLocation, os);
1:3bf9d0c:             } else {
1:3bf9d0c:                 os.writeBoolean(false);
1:a6a6a70:             }
1:bc4392b:             os.writeInt(this.openwireVersion);
1:a6a6a70:         }
1:76f842d:     }
1:a6c51a4: 
1:e22a37a:     class MetadataMarshaller extends VariableMarshaller<Metadata> {
1:54e2e3b:         @Override
1:456a2ba:         public Metadata readPayload(DataInput dataIn) throws IOException {
1:bfb1778:             Metadata rc = createMetadata();
1:456a2ba:             rc.read(dataIn);
5:456a2ba:             return rc;
1:54e2e3b:         }
1:8871c67: 
1:8871b0e:         @Override
1:456a2ba:         public void writePayload(Metadata object, DataOutput dataOut) throws IOException {
1:456a2ba:             object.write(dataOut);
1:785b16b:         }
1:785b16b:     }
1:8871c67: 
1:28819ae:     public enum PurgeRecoveredXATransactionStrategy {
1:28819ae:         NEVER,
1:28819ae:         COMMIT,
1:28819ae:         ROLLBACK;
1:28819ae:     }
1:28819ae: 
1:456a2ba:     protected PageFile pageFile;
1:1595378:     protected Journal journal;
1:a6a6a70:     protected Metadata metadata = new Metadata();
1:8871c67: 
1:456a2ba:     protected MetadataMarshaller metadataMarshaller = new MetadataMarshaller();
1:3f0cf98: 
1:456a2ba:     protected boolean failIfDatabaseIsLocked;
1:6fd292d: 
1:456a2ba:     protected boolean deleteAllMessages;
1:85edfb3:     protected File directory = DEFAULT_DIRECTORY;
1:232b8c5:     protected File indexDirectory = null;
1:946e62d:     protected ScheduledExecutorService scheduler;
1:946e62d:     private final Object schedulerLock = new Object();
1:946e62d: 
1:0d824a8:     protected JournalDiskSyncStrategy journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS;
1:f8cb847:     protected boolean archiveDataLogs;
1:98bb7bf:     protected File directoryArchive;
1:a604424:     protected AtomicLong journalSize = new AtomicLong(0);
1:dd0ed17:     long journalDiskSyncInterval = 1000;
1:1595378:     long checkpointInterval = 5*1000;
1:1595378:     long cleanupInterval = 30*1000;
1:c42d980:     int journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
1:356c39d:     int journalMaxWriteBatchSize = Journal.DEFAULT_MAX_WRITE_BATCH_SIZE;
1:deea2d1:     boolean enableIndexWriteAsync = false;
1:a6a6a70:     int setIndexWriteBatchSize = PageFile.DEFAULT_WRITE_BATCH_SIZE;
1:65cef69:     private String preallocationScope = Journal.PreallocationScope.ENTIRE_JOURNAL.name();
1:45e59e6:     private String preallocationStrategy = Journal.PreallocationStrategy.SPARSE_FILE.name();
1:514ef7d: 
1:456a2ba:     protected AtomicBoolean opened = new AtomicBoolean();
1:fbc5eb5:     private boolean ignoreMissingJournalfiles = false;
1:ea84378:     private int indexCacheSize = 10000;
1:c9500f4:     private boolean checkForCorruptJournalFiles = false;
1:28819ae:     protected PurgeRecoveredXATransactionStrategy purgeRecoveredXATransactionStrategy = PurgeRecoveredXATransactionStrategy.NEVER;
1:5cadb04:     private boolean checksumJournalFiles = true;
1:f2517c0:     protected boolean forceRecoverIndex = false;
1:5f7fc14:     private boolean archiveCorruptedIndex = false;
1:7da61d9:     private boolean useIndexLFRUEviction = false;
1:7da61d9:     private float indexLFUEvictionFactor = 0.2f;
1:bb4a2f7:     private boolean enableIndexDiskSyncs = true;
1:bb4a2f7:     private boolean enableIndexRecoveryFile = true;
1:bb4a2f7:     private boolean enableIndexPageCaching = true;
1:4c51977:     ReentrantReadWriteLock checkpointLock = new ReentrantReadWriteLock();
1:6f7e3fc: 
1:cbad8ba:     private boolean enableAckCompaction = true;
1:946e62d:     private int compactAcksAfterNoGC = 10;
1:946e62d:     private boolean compactAcksIgnoresStoreGrowth = false;
1:946e62d:     private int checkPointCyclesWithNoGC;
1:946e62d:     private int journalLogOnLastCompactionCheck;
1:cf3d419:     private boolean enableSubscriptionStatistics = false;
1:946e62d: 
1:1a59827:     //only set when using JournalDiskSyncStrategy.PERIODIC
1:1a59827:     protected final AtomicReference<Location> lastAsyncJournalUpdate = new AtomicReference<>();
1:1a59827: 
1:8871b0e:     @Override
1:ea84378:     public void doStart() throws Exception {
1:456a2ba:         load();
1:bc4392b:     }
1:b1d7a78: 
1:62c6c8f:     @Override
1:ea84378:     public void doStop(ServiceStopper stopper) throws Exception {
1:456a2ba:         unload();
1:3bf9d0c:     }
1:a6a6a70: 
1:c5a8b2c:     public void allowIOResumption() {
1:c5a8b2c:         if (pageFile != null) {
1:c5a8b2c:             pageFile.allowIOResumption();
1:c5a8b2c:         }
1:c5a8b2c:         if (journal != null) {
1:c5a8b2c:             journal.allowIOResumption();
1:c5a8b2c:         }
1:c5a8b2c:     }
1:c5a8b2c: 
1:40f9146:     private void loadPageFile() throws IOException {
1:2030097:         this.indexLock.writeLock().lock();
1:c6ed5ff:         try {
1:40f9146:             final PageFile pageFile = getPageFile();
1:456a2ba:             pageFile.load();
1:dcf1f5e:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                 @Override
1:dcf1f5e:                 public void execute(Transaction tx) throws IOException {
1:456a2ba:                     if (pageFile.getPageCount() == 0) {
1:456a2ba:                         // First time this is created.. Initialize the metadata
1:456a2ba:                         Page<Metadata> page = tx.allocate();
1:456a2ba:                         assert page.getPageId() == 0;
1:456a2ba:                         page.set(metadata);
1:456a2ba:                         metadata.page = page;
1:456a2ba:                         metadata.state = CLOSED_STATE;
1:281d600:                         metadata.destinations = new BTreeIndex<>(pageFile, tx.allocate().getPageId());
1:1595378: 
2:456a2ba:                         tx.store(metadata.page, metadataMarshaller, true);
1:fbc5eb5:                     } else {
1:456a2ba:                         Page<Metadata> page = tx.load(0, metadataMarshaller);
1:456a2ba:                         metadata = page.get();
1:456a2ba:                         metadata.page = page;
1:cfe099d:                     }
1:456a2ba:                     metadata.destinations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:456a2ba:                     metadata.destinations.setValueMarshaller(new StoredDestinationMarshaller());
1:456a2ba:                     metadata.destinations.load(tx);
1:69c0d39:                 }
1:54e2e3b:             });
1:456a2ba:             // Load up all the destinations since we need to scan all the indexes to figure out which journal files can be deleted.
1:456a2ba:             // Perhaps we should just keep an index of file
1:456a2ba:             storedDestinations.clear();
1:2030097:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                 @Override
1:2030097:                 public void execute(Transaction tx) throws IOException {
1:1595378:                     for (Iterator<Entry<String, StoredDestination>> iterator = metadata.destinations.iterator(tx); iterator.hasNext();) {
1:456a2ba:                         Entry<String, StoredDestination> entry = iterator.next();
1:1595378:                         StoredDestination sd = loadStoredDestination(tx, entry.getKey(), entry.getValue().subscriptions!=null);
1:456a2ba:                         storedDestinations.put(entry.getKey(), sd);
1:06f24e2: 
1:06f24e2:                         if (checkForCorruptJournalFiles) {
1:06f24e2:                             // sanity check the index also
1:06f24e2:                             if (!entry.getValue().locationIndex.isEmpty(tx)) {
1:06f24e2:                                 if (entry.getValue().orderIndex.nextMessageId <= 0) {
1:06f24e2:                                     throw new IOException("Detected uninitialized orderIndex nextMessageId with pending messages for " + entry.getKey());
1:06f24e2:                                 }
1:06f24e2:                             }
1:06f24e2:                         }
1:dcf1f5e:                     }
1:2030097:                 }
1:dcf1f5e:             });
1:3f0cf98:             pageFile.flush();
1:5325cdb:         } finally {
1:b47da80:             this.indexLock.writeLock().unlock();
1:c6ed5ff:         }
1:3bf9d0c:     }
1:1595378: 
1:40f9146:     private void startCheckpoint() {
1:946e62d:         if (checkpointInterval == 0 && cleanupInterval == 0) {
1:89f22da:             LOG.info("periodic checkpoint/cleanup disabled, will ocurr on clean shutdown/restart");
1:0061f6f:             return;
1:89f22da:         }
1:946e62d:         synchronized (schedulerLock) {
1:9121301:             if (scheduler == null || scheduler.isShutdown()) {
1:946e62d:                 scheduler = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() {
1:c6ed5ff: 
1:946e62d:                     @Override
1:946e62d:                     public Thread newThread(Runnable r) {
1:946e62d:                         Thread schedulerThread = new Thread(r);
1:946e62d: 
1:946e62d:                         schedulerThread.setName("ActiveMQ Journal Checkpoint Worker");
1:946e62d:                         schedulerThread.setDaemon(true);
1:946e62d: 
1:946e62d:                         return schedulerThread;
1:946e62d:                     }
1:946e62d:                 });
1:946e62d: 
1:946e62d:                 // Short intervals for check-point and cleanups
1:dd0ed17:                 long delay;
1:dd0ed17:                 if (journal.isJournalDiskSyncPeriodic()) {
1:dd0ed17:                     delay = Math.min(journalDiskSyncInterval > 0 ? journalDiskSyncInterval : checkpointInterval, 500);
1:dd0ed17:                 } else {
1:dd0ed17:                     delay = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
1:dd0ed17:                 }
1:946e62d: 
1:946e62d:                 scheduler.scheduleWithFixedDelay(new CheckpointRunner(), 0, delay, TimeUnit.MILLISECONDS);
1:946e62d:             }
1:946e62d:         }
1:946e62d:     }
1:946e62d: 
1:946e62d:     private final class CheckpointRunner implements Runnable {
1:946e62d: 
1:946e62d:         private long lastCheckpoint = System.currentTimeMillis();
1:946e62d:         private long lastCleanup = System.currentTimeMillis();
1:dd0ed17:         private long lastSync = System.currentTimeMillis();
1:1a59827:         private Location lastAsyncUpdate = null;
1:946e62d: 
1:946e62d:         @Override
1:946e62d:         public void run() {
1:946e62d:             try {
1:946e62d:                 // Decide on cleanup vs full checkpoint here.
1:946e62d:                 if (opened.get()) {
1:946e62d:                     long now = System.currentTimeMillis();
1:dd0ed17:                     if (journal.isJournalDiskSyncPeriodic() &&
1:dd0ed17:                             journalDiskSyncInterval > 0 && (now - lastSync >= journalDiskSyncInterval)) {
1:1a59827:                         Location currentUpdate = lastAsyncJournalUpdate.get();
1:1a59827:                         if (currentUpdate != null && !currentUpdate.equals(lastAsyncUpdate)) {
1:1a59827:                             lastAsyncUpdate = currentUpdate;
1:1a59827:                             if (LOG.isTraceEnabled()) {
1:1a59827:                                 LOG.trace("Writing trace command to trigger journal sync");
1:1a59827:                             }
1:1a59827:                             store(new KahaTraceCommand(), true, null, null);
1:1a59827:                         }
1:dd0ed17:                         lastSync = now;
1:dd0ed17:                     }
1:946e62d:                     if (cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval)) {
1:946e62d:                         checkpointCleanup(true);
1:946e62d:                         lastCleanup = now;
1:946e62d:                         lastCheckpoint = now;
1:946e62d:                     } else if (checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval)) {
1:946e62d:                         checkpointCleanup(false);
1:946e62d:                         lastCheckpoint = now;
1:946e62d:                     }
1:946e62d:                 }
1:946e62d:             } catch (IOException ioe) {
1:e53e340:                 LOG.error("Checkpoint failed", ioe);
1:946e62d:                 brokerService.handleIOException(ioe);
1:946e62d:             } catch (Throwable e) {
1:e53e340:                 LOG.error("Checkpoint failed", e);
1:946e62d:                 brokerService.handleIOException(IOExceptionSupport.create(e));
1:89f22da:             }
1:62c6c8f:         }
1:62c6c8f:     }
1:62bdbb0: 
1:40f9146:     public void open() throws IOException {
1:1595378:         if( opened.compareAndSet(false, true) ) {
1:1595378:             getJournal().start();
1:38b840a:             try {
1:40f9146:                 loadPageFile();
1:dcf1f5e:             } catch (Throwable t) {
1:dcf1f5e:                 LOG.warn("Index corrupted. Recovering the index through journal replay. Cause:" + t);
1:dcf1f5e:                 if (LOG.isDebugEnabled()) {
1:dcf1f5e:                     LOG.debug("Index load failure", t);
1:dcf1f5e:                 }
1:5f7fc14:                 // try to recover index
1:bc4392b:                 try {
1:40f9146:                     pageFile.unload();
1:5f7fc14:                 } catch (Exception ignore) {}
1:5f7fc14:                 if (archiveCorruptedIndex) {
1:5f7fc14:                     pageFile.archive();
1:40f9146:                 } else {
1:456a2ba:                     pageFile.delete();
1:2030097:                 }
1:bfb1778:                 metadata = createMetadata();
1:7a7c70a:                 //The metadata was recreated after a detect corruption so we need to
1:7a7c70a:                 //reconfigure anything that was configured on the old metadata on startup
1:7a7c70a:                 configureMetadata();
1:dcf1f5e:                 pageFile = null;
2:456a2ba:                 loadPageFile();
1:3bf9d0c:             }
1:456a2ba:             recover();
1:8cc5c56:             startCheckpoint();
1:e1389a6:         }
1:5325cdb:     }
1:db3f8b3: 
1:456a2ba:     public void load() throws IOException {
1:c6ed5ff:         this.indexLock.writeLock().lock();
1:3bf9d0c:         try {
1:281d600:             IOHelper.mkdirs(directory);
1:fbc5eb5:             if (deleteAllMessages) {
1:8c218ee:                 getJournal().setCheckForCorruptionOnStartup(false);
1:1595378:                 getJournal().start();
1:1595378:                 getJournal().delete();
1:1595378:                 getJournal().close();
1:1595378:                 journal = null;
1:fbc5eb5:                 getPageFile().delete();
1:fbc5eb5:                 LOG.info("Persistence store purged.");
1:fbc5eb5:                 deleteAllMessages = false;
1:40f9146:             }
1:db3f8b3: 
1:40f9146:             open();
1:1595378:             store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
1:5325cdb:         } finally {
1:2030097:             this.indexLock.writeLock().unlock();
1:40f9146:         }
1:40f9146:     }
1:a6c51a4: 
1:40f9146:     public void close() throws IOException, InterruptedException {
1:281d600:         if (opened.compareAndSet(true, false)) {
1:e53e340:             checkpointLock.writeLock().lock();
1:2030097:             try {
1:dcf1f5e:                 if (metadata.page != null) {
1:4c51977:                     checkpointUpdate(true);
1:dcf1f5e:                 }
1:2030097:                 pageFile.unload();
1:bfb1778:                 metadata = createMetadata();
1:2030097:             } finally {
1:4c51977:                 checkpointLock.writeLock().unlock();
1:dcf1f5e:             }
1:2030097:             journal.close();
1:7bdcca1:             synchronized(schedulerLock) {
1:7bdcca1:                 if (scheduler != null) {
1:7bdcca1:                     ThreadPoolUtils.shutdownGraceful(scheduler, -1);
1:7bdcca1:                     scheduler = null;
1:7bdcca1:                 }
1:7bdcca1:             }
1:946e62d:             // clear the cache and journalSize on shutdown of the store
1:c6542a9:             storeCache.clear();
1:e07809d:             journalSize.set(0);
1:60b0c4f:         }
1:60b0c4f:     }
1:62609f0: 
1:456a2ba:     public void unload() throws IOException, InterruptedException {
1:40f9146:         this.indexLock.writeLock().lock();
1:3bf9d0c:         try {
1:1595378:             if( pageFile != null && pageFile.isLoaded() ) {
1:456a2ba:                 metadata.state = CLOSED_STATE;
1:0dcdab7:                 metadata.firstInProgressTransactionLocation = getInProgressTxLocationRange()[0];
1:a6a6a70: 
1:dcf1f5e:                 if (metadata.page != null) {
1:54e2e3b:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                         @Override
1:54e2e3b:                         public void execute(Transaction tx) throws IOException {
1:dcf1f5e:                             tx.store(metadata.page, metadataMarshaller, true);
1:dcf1f5e:                         }
1:dcf1f5e:                     });
1:89f22da:                 }
1:2030097:             }
1:5325cdb:         } finally {
1:40f9146:             this.indexLock.writeLock().unlock();
1:62c6c8f:         }
1:a91f59a:         close();
1:40f9146:     }
1:a6a6a70: 
1:a6c51a4:     // public for testing
1:3bf9d0c:     @SuppressWarnings("rawtypes")
1:0dcdab7:     public Location[] getInProgressTxLocationRange() {
1:0dcdab7:         Location[] range = new Location[]{null, null};
1:a6c51a4:         synchronized (inflightTransactions) {
1:a6a6a70:             if (!inflightTransactions.isEmpty()) {
1:1595378:                 for (List<Operation> ops : inflightTransactions.values()) {
1:1595378:                     if (!ops.isEmpty()) {
1:0dcdab7:                         trackMaxAndMin(range, ops);
1:1595378:                     }
1:1595378:                 }
1:40f9146:             }
1:a6a6a70:             if (!preparedTransactions.isEmpty()) {
1:1595378:                 for (List<Operation> ops : preparedTransactions.values()) {
1:1595378:                     if (!ops.isEmpty()) {
1:0dcdab7:                         trackMaxAndMin(range, ops);
1:a6a6a70:                     }
1:a6a6a70:                 }
1:40f9146:             }
1:40f9146:         }
1:0dcdab7:         return range;
1:0dcdab7:     }
1:0dcdab7: 
1:3bf9d0c:     @SuppressWarnings("rawtypes")
1:0dcdab7:     private void trackMaxAndMin(Location[] range, List<Operation> ops) {
1:0dcdab7:         Location t = ops.get(0).getLocation();
1:946e62d:         if (range[0] == null || t.compareTo(range[0]) <= 0) {
1:0dcdab7:             range[0] = t;
1:0dcdab7:         }
1:0dcdab7:         t = ops.get(ops.size() -1).getLocation();
1:946e62d:         if (range[1] == null || t.compareTo(range[1]) >= 0) {
1:0dcdab7:             range[1] = t;
1:0dcdab7:         }
1:40f9146:     }
1:a6a6a70: 
1:3bffaf7:     class TranInfo {
1:3bffaf7:         TransactionId id;
1:3bffaf7:         Location location;
1:3bffaf7: 
1:3bffaf7:         class opCount {
1:3bffaf7:             int add;
1:3bffaf7:             int remove;
1:3bffaf7:         }
1:281d600:         HashMap<KahaDestination, opCount> destinationOpCount = new HashMap<>();
1:3bffaf7: 
1:c273cab:         @SuppressWarnings("rawtypes")
1:3bffaf7:         public void track(Operation operation) {
1:3bffaf7:             if (location == null ) {
1:3bffaf7:                 location = operation.getLocation();
1:3bffaf7:             }
1:3bffaf7:             KahaDestination destination;
1:3bffaf7:             boolean isAdd = false;
1:54e2e3b:             if (operation instanceof AddOperation) {
1:54e2e3b:                 AddOperation add = (AddOperation) operation;
1:3bffaf7:                 destination = add.getCommand().getDestination();
1:3bffaf7:                 isAdd = true;
1:3bffaf7:             } else {
1:54e2e3b:                 RemoveOperation removeOpperation = (RemoveOperation) operation;
1:3bffaf7:                 destination = removeOpperation.getCommand().getDestination();
1:3bffaf7:             }
1:3bffaf7:             opCount opCount = destinationOpCount.get(destination);
1:3bffaf7:             if (opCount == null) {
1:3bffaf7:                 opCount = new opCount();
1:3bffaf7:                 destinationOpCount.put(destination, opCount);
1:3bffaf7:             }
1:3bffaf7:             if (isAdd) {
1:3bffaf7:                 opCount.add++;
1:3bffaf7:             } else {
1:3bffaf7:                 opCount.remove++;
1:3bffaf7:             }
1:3bffaf7:         }
1:3bffaf7: 
1:3bffaf7:         @Override
1:3bffaf7:         public String toString() {
1:3bffaf7:            StringBuffer buffer = new StringBuffer();
1:3bffaf7:            buffer.append(location).append(";").append(id).append(";\n");
1:3bffaf7:            for (Entry<KahaDestination, opCount> op : destinationOpCount.entrySet()) {
1:3bffaf7:                buffer.append(op.getKey()).append('+').append(op.getValue().add).append(',').append('-').append(op.getValue().remove).append(';');
1:3bffaf7:            }
1:3bffaf7:            return buffer.toString();
1:3bffaf7:         }
1:3bffaf7:     }
1:3bffaf7: 
1:3bffaf7:     @SuppressWarnings("rawtypes")
1:3bffaf7:     public String getTransactions() {
1:3bffaf7: 
1:281d600:         ArrayList<TranInfo> infos = new ArrayList<>();
1:3bffaf7:         synchronized (inflightTransactions) {
1:3bffaf7:             if (!inflightTransactions.isEmpty()) {
1:3bffaf7:                 for (Entry<TransactionId, List<Operation>> entry : inflightTransactions.entrySet()) {
1:3bffaf7:                     TranInfo info = new TranInfo();
1:3bffaf7:                     info.id = entry.getKey();
1:3bffaf7:                     for (Operation operation : entry.getValue()) {
1:3bffaf7:                         info.track(operation);
1:3bffaf7:                     }
1:3bffaf7:                     infos.add(info);
1:3bffaf7:                 }
1:3bffaf7:             }
1:3bffaf7:         }
1:69c0d39:         synchronized (preparedTransactions) {
1:69c0d39:             if (!preparedTransactions.isEmpty()) {
1:69c0d39:                 for (Entry<TransactionId, List<Operation>> entry : preparedTransactions.entrySet()) {
1:69c0d39:                     TranInfo info = new TranInfo();
1:69c0d39:                     info.id = entry.getKey();
1:69c0d39:                     for (Operation operation : entry.getValue()) {
1:69c0d39:                         info.track(operation);
1:69c0d39:                     }
1:69c0d39:                     infos.add(info);
1:69c0d39:                 }
1:69c0d39:             }
1:69c0d39:         }
1:3bffaf7:         return infos.toString();
1:3bffaf7:     }
1:3bffaf7: 
1:8871b0e:     /**
1:456a2ba:      * Move all the messages that were in the journal into long term storage. We
1:456a2ba:      * just replay and do a checkpoint.
1:1595378:      *
1:1595378:      * @throws IOException
1:1595378:      * @throws IOException
1:1595378:      * @throws IllegalStateException
1:785b16b:      */
1:456a2ba:     private void recover() throws IllegalStateException, IOException {
1:40f9146:         this.indexLock.writeLock().lock();
1:54d56df:         try {
1:1595378: 
1:1595378:             long start = System.currentTimeMillis();
1:a359d81:             boolean requiresJournalReplay = recoverProducerAudit();
1:a359d81:             requiresJournalReplay |= recoverAckMessageFileMap();
1:1595378:             Location lastIndoubtPosition = getRecoveryPosition();
1:a359d81:             Location recoveryPosition = requiresJournalReplay ? journal.getNextLocation(null) : lastIndoubtPosition;
1:1595378:             if (recoveryPosition != null) {
1:1595378:                 int redoCounter = 0;
1:d427952:                 int dataFileRotationTracker = recoveryPosition.getDataFileId();
1:a7178a4:                 LOG.info("Recovering from the journal @" + recoveryPosition);
1:1595378:                 while (recoveryPosition != null) {
1:73db4d2:                     try {
1:73db4d2:                         JournalCommand<?> message = load(recoveryPosition);
1:73db4d2:                         metadata.lastUpdate = recoveryPosition;
1:73db4d2:                         process(message, recoveryPosition, lastIndoubtPosition);
1:73db4d2:                         redoCounter++;
1:73db4d2:                     } catch (IOException failedRecovery) {
1:73db4d2:                         if (isIgnoreMissingJournalfiles()) {
1:4a82118:                             LOG.debug("Failed to recover data at position:" + recoveryPosition, failedRecovery);
1:73db4d2:                             // track this dud location
1:73db4d2:                             journal.corruptRecoveryLocation(recoveryPosition);
1:73db4d2:                         } else {
1:0a21c5f:                             throw new IOException("Failed to recover data at position:" + recoveryPosition, failedRecovery);
1:73db4d2:                         }
1:73db4d2:                     }
1:1595378:                     recoveryPosition = journal.getNextLocation(recoveryPosition);
1:d427952:                     // hold on to the minimum number of open files during recovery
1:d427952:                     if (recoveryPosition != null && dataFileRotationTracker != recoveryPosition.getDataFileId()) {
1:d427952:                         dataFileRotationTracker = recoveryPosition.getDataFileId();
1:d427952:                         journal.cleanup();
1:d427952:                     }
1:d427952:                     if (LOG.isInfoEnabled() && redoCounter % 100000 == 0) {
1:d427952:                         LOG.info("@" + recoveryPosition + ", " + redoCounter + " entries recovered ..");
1:d427952:                     }
1:db3f8b3:                 }
1:5325cdb:                 if (LOG.isInfoEnabled()) {
1:1595378:                     long end = System.currentTimeMillis();
1:1595378:                     LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1:41cdadb:                 }
1:1595378:             }
1:1595378: 
1:1595378:             // We may have to undo some index updates.
1:dcf1f5e:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                 @Override
1:dcf1f5e:                 public void execute(Transaction tx) throws IOException {
1:1595378:                     recoverIndex(tx);
1:1595378:                 }
1:2030097:             });
1:1595378: 
1:d9b54d6:             // rollback any recovered inflight local transactions, and discard any inflight XA transactions.
1:281d600:             Set<TransactionId> toRollback = new HashSet<>();
1:281d600:             Set<TransactionId> toDiscard = new HashSet<>();
1:1595378:             synchronized (inflightTransactions) {
1:1595378:                 for (Iterator<TransactionId> it = inflightTransactions.keySet().iterator(); it.hasNext(); ) {
1:1595378:                     TransactionId id = it.next();
1:1595378:                     if (id.isLocalTransaction()) {
1:1595378:                         toRollback.add(id);
1:d9b54d6:                     } else {
1:d9b54d6:                         toDiscard.add(id);
1:1595378:                     }
1:1595378:                 }
1:1595378:                 for (TransactionId tx: toRollback) {
1:5325cdb:                     if (LOG.isDebugEnabled()) {
1:1595378:                         LOG.debug("rolling back recovered indoubt local transaction " + tx);
1:a6c51a4:                     }
1:1595378:                     store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convertToLocal(tx)), false, null, null);
1:1595378:                 }
1:d9b54d6:                 for (TransactionId tx: toDiscard) {
1:d9b54d6:                     if (LOG.isDebugEnabled()) {
1:d9b54d6:                         LOG.debug("discarding recovered in-flight XA transaction " + tx);
1:1595378:                     }
1:d9b54d6:                     inflightTransactions.remove(tx);
1:a6c51a4:                 }
1:a6c51a4:             }
1:a6a6a70: 
1:7057e81:             synchronized (preparedTransactions) {
1:28819ae:                 Set<TransactionId> txIds = new LinkedHashSet<TransactionId>(preparedTransactions.keySet());
1:28819ae:                 for (TransactionId txId : txIds) {
1:28819ae:                     switch (purgeRecoveredXATransactionStrategy){
1:28819ae:                         case NEVER:
1:28819ae:                             LOG.warn("Recovered prepared XA TX: [{}]", txId);
1:28819ae:                             break;
1:28819ae:                         case COMMIT:
1:28819ae:                             store(new KahaCommitCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
1:28819ae:                             LOG.warn("Recovered and Committing prepared XA TX: [{}]", txId);
1:28819ae:                             break;
1:28819ae:                         case ROLLBACK:
1:28819ae:                             store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
1:28819ae:                             LOG.warn("Recovered and Rolling Back prepared XA TX: [{}]", txId);
1:28819ae:                             break;
1:24b9ae2:                     }
1:24b9ae2:                 }
1:1595378:             }
1:24b9ae2: 
1:5325cdb:         } finally {
1:6ce702d:             this.indexLock.writeLock().unlock();
1:1595378:         }
1:a6c51a4:     }
1:a6a6a70: 
1:943db3c:     @SuppressWarnings("unused")
1:1595378:     private KahaTransactionInfo createLocalTransactionInfo(TransactionId tx) {
1:1595378:         return TransactionIdConversion.convertToLocal(tx);
1:a6a6a70:     }
1:a6a6a70: 
1:1c41085:     private Location minimum(Location x,
1:1c41085:                              Location y) {
1:a6a6a70:         Location min = null;
1:ba77b9f:         if (x != null) {
1:ba77b9f:             min = x;
1:ba77b9f:             if (y != null) {
1:ba77b9f:                 int compare = y.compareTo(x);
1:ba77b9f:                 if (compare < 0) {
1:ba77b9f:                     min = y;
1:ba77b9f:                 }
1:db3f8b3:             }
1:a6a6a70:         } else {
1:ba77b9f:             min = y;
1:a6a6a70:         }
1:a6a6a70:         return min;
1:a6a6a70:     }
1:a6a6a70: 
1:a359d81:     private boolean recoverProducerAudit() throws IOException {
1:a359d81:         boolean requiresReplay = true;
1:a6a6a70:         if (metadata.producerSequenceIdTrackerLocation != null) {
1:a6a6a70:             try {
1:822e2be:                 KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(metadata.producerSequenceIdTrackerLocation);
1:a6a6a70:                 ObjectInputStream objectIn = new ObjectInputStream(audit.getAudit().newInput());
1:bfb1778:                 int maxNumProducers = getMaxFailoverProducersToTrack();
1:bfb1778:                 int maxAuditDepth = getFailoverProducersAuditDepth();
1:a6a6a70:                 metadata.producerSequenceIdTracker = (ActiveMQMessageAuditNoSync) objectIn.readObject();
1:bfb1778:                 metadata.producerSequenceIdTracker.setAuditDepth(maxAuditDepth);
1:bfb1778:                 metadata.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(maxNumProducers);
1:a359d81:                 requiresReplay = false;
1:54e2e3b:             } catch (Exception e) {
1:14755a1:                 LOG.warn("Cannot recover message audit", e);
1:a6a6a70:             }
1:d9b54d6:         }
1:a359d81:         // got no audit stored so got to recreate via replay from start of the journal
1:a359d81:         return requiresReplay;
1:a6a6a70:     }
1:a6a6a70: 
1:3bf9d0c:     @SuppressWarnings("unchecked")
1:a359d81:     private boolean recoverAckMessageFileMap() throws IOException {
1:a359d81:         boolean requiresReplay = true;
1:3bf9d0c:         if (metadata.ackMessageFileMapLocation != null) {
1:3bf9d0c:             try {
1:822e2be:                 KahaAckMessageFileMapCommand audit = (KahaAckMessageFileMapCommand) load(metadata.ackMessageFileMapLocation);
1:3bf9d0c:                 ObjectInputStream objectIn = new ObjectInputStream(audit.getAckMessageFileMap().newInput());
1:3bf9d0c:                 metadata.ackMessageFileMap = (Map<Integer, Set<Integer>>) objectIn.readObject();
1:a359d81:                 requiresReplay = false;
1:54e2e3b:             } catch (Exception e) {
1:3bf9d0c:                 LOG.warn("Cannot recover ackMessageFileMap", e);
1:a6a6a70:             }
1:d9b54d6:         }
1:a359d81:         // got no ackMessageFileMap stored so got to recreate via replay from start of the journal
1:a359d81:         return requiresReplay;
1:7057e81:     }
1:3271401: 
1:1595378:     protected void recoverIndex(Transaction tx) throws IOException {
1:40f9146:         long start = System.currentTimeMillis();
1:40f9146:         // It is possible index updates got applied before the journal updates..
1:d761e80:         // in that case we need to removed references to messages that are not in the journal
1:d761e80:         final Location lastAppendLocation = journal.getLastAppendLocation();
1:1595378:         long undoCounter=0;
1:bc4392b: 
1:d761e80:         // Go through all the destinations to see if they have messages past the lastAppendLocation
1:785b16b:         for (String key : storedDestinations.keySet()) {
1:785b16b:             StoredDestination sd = storedDestinations.get(key);
1:7057e81: 
1:281d600:             final ArrayList<Long> matches = new ArrayList<>();
1:d761e80:             // Find all the Locations that are >= than the last Append Location.
1:d761e80:             sd.locationIndex.visit(tx, new BTreeVisitor.GTEVisitor<Location, Long>(lastAppendLocation) {
1:54d56df:                 @Override
1:40f9146:                 protected void matched(Location key, Long value) {
1:40f9146:                     matches.add(value);
1:7057e81:                 }
1:1595378:             });
1:7057e81: 
1:c9500f4:             for (Long sequenceId : matches) {
1:d761e80:                 MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
1:8f30866:                 if (keys != null) {
1:8f30866:                     sd.locationIndex.remove(tx, keys.location);
1:8f30866:                     sd.messageIdIndex.remove(tx, keys.messageId);
1:8f30866:                     metadata.producerSequenceIdTracker.rollback(keys.messageId);
1:8f30866:                     undoCounter++;
1:8f30866:                     decrementAndSubSizeToStoreStat(key, keys.location.getSize());
1:8f30866:                     // TODO: do we need to modify the ack positions for the pub sub case?
1:8f30866:                 }
1:3bf9d0c:             }
1:5325cdb:         }
1:3bf9d0c: 
1:946e62d:         if (undoCounter > 0) {
1:5325cdb:             // The rolledback operations are basically in flight journal writes.  To avoid getting
1:5325cdb:             // these the end user should do sync writes to the journal.
1:5325cdb:             if (LOG.isInfoEnabled()) {
1:a6a6a70:                 long end = System.currentTimeMillis();
1:5325cdb:                 LOG.info("Rolled back " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:5325cdb:             }
1:5325cdb:         }
1:3bf9d0c: 
1:c9500f4:         undoCounter = 0;
1:c9500f4:         start = System.currentTimeMillis();
1:3bf9d0c: 
1:fbc5eb5:         // Lets be extra paranoid here and verify that all the datafiles being referenced
1:fbc5eb5:         // by the indexes still exists.
1:3bf9d0c: 
1:fbc5eb5:         final SequenceSet ss = new SequenceSet();
1:c9500f4:         for (StoredDestination sd : storedDestinations.values()) {
1:fbc5eb5:             // Use a visitor to cut down the number of pages that we load
1:fbc5eb5:             sd.locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
1:1595378:                 int last=-1;
1:0af0021: 
1:54d56df:                 @Override
1:fbc5eb5:                 public boolean isInterestedInKeysBetween(Location first, Location second) {
1:1595378:                     if( first==null ) {
1:fbc5eb5:                         return !ss.contains(0, second.getDataFileId());
1:1595378:                     } else if( second==null ) {
1:fbc5eb5:                         return true;
1:a6a6a70:                     } else {
1:fbc5eb5:                         return !ss.contains(first.getDataFileId(), second.getDataFileId());
1:5325cdb:                     }
1:40f9146:                 }
1:5325cdb: 
1:54d56df:                 @Override
1:fbc5eb5:                 public void visit(List<Location> keys, List<Long> values) {
1:fbc5eb5:                     for (Location l : keys) {
1:fbc5eb5:                         int fileId = l.getDataFileId();
1:1595378:                         if( last != fileId ) {
1:fbc5eb5:                             ss.add(fileId);
1:fbc5eb5:                             last = fileId;
1:40f9146:                         }
1:40f9146:                     }
1:40f9146:                 }
1:40f9146: 
1:3bf9d0c:             });
1:40f9146:         }
1:281d600:         HashSet<Integer> missingJournalFiles = new HashSet<>();
1:5325cdb:         while (!ss.isEmpty()) {
1:5325cdb:             missingJournalFiles.add((int) ss.removeFirst());
1:5325cdb:         }
1:40f9146: 
1:5db5f3e:         for (Entry<Integer, Set<Integer>> entry : metadata.ackMessageFileMap.entrySet()) {
1:5db5f3e:             missingJournalFiles.add(entry.getKey());
1:5db5f3e:             for (Integer i : entry.getValue()) {
1:5db5f3e:                 missingJournalFiles.add(i);
1:40f9146:             }
1:40f9146:         }
1:40f9146: 
1:5db5f3e:         missingJournalFiles.removeAll(journal.getFileMap().keySet());
1:5db5f3e: 
1:5db5f3e:         if (!missingJournalFiles.isEmpty()) {
1:5db5f3e:             LOG.warn("Some journal files are missing: " + missingJournalFiles);
1:5db5f3e:         }
1:5db5f3e: 
1:281d600:         ArrayList<BTreeVisitor.Predicate<Location>> knownCorruption = new ArrayList<>();
1:281d600:         ArrayList<BTreeVisitor.Predicate<Location>> missingPredicates = new ArrayList<>();
1:c9500f4:         for (Integer missing : missingJournalFiles) {
1:5325cdb:             missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing, 0), new Location(missing + 1, 0)));
1:40f9146:         }
1:40f9146: 
1:5325cdb:         if (checkForCorruptJournalFiles) {
1:c9500f4:             Collection<DataFile> dataFiles = journal.getFileMap().values();
1:c9500f4:             for (DataFile dataFile : dataFiles) {
1:c9500f4:                 int id = dataFile.getDataFileId();
1:5db5f3e:                 // eof to next file id
1:5325cdb:                 missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, dataFile.getLength()), new Location(id + 1, 0)));
1:c9500f4:                 Sequence seq = dataFile.getCorruptedBlocks().getHead();
1:5325cdb:                 while (seq != null) {
1:193f6be:                     BTreeVisitor.BetweenVisitor<Location, Long> visitor =
1:281d600:                         new BTreeVisitor.BetweenVisitor<>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
1:5db5f3e:                     missingPredicates.add(visitor);
1:5db5f3e:                     knownCorruption.add(visitor);
1:c9500f4:                     seq = seq.getNext();
1:40f9146:                 }
1:40f9146:             }
1:40f9146:         }
1:40f9146: 
1:5325cdb:         if (!missingPredicates.isEmpty()) {
1:73db4d2:             for (Entry<String, StoredDestination> sdEntry : storedDestinations.entrySet()) {
1:73db4d2:                 final StoredDestination sd = sdEntry.getValue();
1:281d600:                 final LinkedHashMap<Long, Location> matches = new LinkedHashMap<>();
1:c9500f4:                 sd.locationIndex.visit(tx, new BTreeVisitor.OrVisitor<Location, Long>(missingPredicates) {
1:54d56df:                     @Override
1:c9500f4:                     protected void matched(Location key, Long value) {
1:dad629e:                         matches.put(value, key);
1:40f9146:                     }
1:3bf9d0c:                 });
1:40f9146: 
1:5db5f3e:                 // If some message references are affected by the missing data files...
1:5325cdb:                 if (!matches.isEmpty()) {
1:40f9146: 
1:c9500f4:                     // We either 'gracefully' recover dropping the missing messages or
1:c9500f4:                     // we error out.
1:1595378:                     if( ignoreMissingJournalfiles ) {
1:c9500f4:                         // Update the index to remove the references to the missing data
1:dad629e:                         for (Long sequenceId : matches.keySet()) {
1:c9500f4:                             MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
1:c9500f4:                             sd.locationIndex.remove(tx, keys.location);
1:c9500f4:                             sd.messageIdIndex.remove(tx, keys.messageId);
1:73db4d2:                             LOG.info("[" + sdEntry.getKey() + "] dropped: " + keys.messageId + " at corrupt location: " + keys.location);
1:c9500f4:                             undoCounter++;
1:785b16b:                             decrementAndSubSizeToStoreStat(sdEntry.getKey(), keys.location.getSize());
1:c9500f4:                             // TODO: do we need to modify the ack positions for the pub sub case?
1:4c51977:                         }
1:3bf9d0c:                     } else {
1:dad629e:                         LOG.error("[" + sdEntry.getKey() + "] references corrupt locations: " + matches);
1:5db5f3e:                         throw new IOException("Detected missing/corrupt journal files referenced by:[" + sdEntry.getKey() + "] " +matches.size()+" messages affected.");
1:4c51977:                     }
1:bdd9e2a:                 }
1:c9500f4:             }
1:c9500f4:         }
1:40f9146: 
1:5db5f3e:         if (!ignoreMissingJournalfiles) {
1:5db5f3e:             if (!knownCorruption.isEmpty()) {
1:5db5f3e:                 LOG.error("Detected corrupt journal files. " + knownCorruption);
1:5db5f3e:                 throw new IOException("Detected corrupt journal files. " + knownCorruption);
1:5db5f3e:             }
1:5db5f3e: 
1:5db5f3e:             if (!missingJournalFiles.isEmpty()) {
1:5db5f3e:                 LOG.error("Detected missing journal files. " + missingJournalFiles);
1:5db5f3e:                 throw new IOException("Detected missing journal files. " + missingJournalFiles);
1:5db5f3e:             }
1:5db5f3e:         }
1:5db5f3e: 
1:946e62d:         if (undoCounter > 0) {
1:40f9146:             // The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
1:40f9146:             // should do sync writes to the journal.
1:5325cdb:             if (LOG.isInfoEnabled()) {
1:5325cdb:                 long end = System.currentTimeMillis();
1:5325cdb:                 LOG.info("Detected missing/corrupt journal files.  Dropped " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:5325cdb:             }
1:40f9146:         }
1:c9500f4:     }
1:40f9146: 
1:40f9146:     private Location nextRecoveryPosition;
1:40f9146:     private Location lastRecoveryPosition;
1:40f9146: 
1:1595378:     public void incrementalRecover() throws IOException {
1:40f9146:         this.indexLock.writeLock().lock();
1:40f9146:         try {
1:1595378:             if( nextRecoveryPosition == null ) {
1:1595378:                 if( lastRecoveryPosition==null ) {
1:1595378:                     nextRecoveryPosition = getRecoveryPosition();
1:40f9146:                 } else {
1:40f9146:                     nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:40f9146:                 }
1:40f9146:             }
1:40f9146:             while (nextRecoveryPosition != null) {
1:40f9146:                 lastRecoveryPosition = nextRecoveryPosition;
1:40f9146:                 metadata.lastUpdate = lastRecoveryPosition;
1:1595378:                 JournalCommand<?> message = load(lastRecoveryPosition);
1:54e2e3b:                 process(message, lastRecoveryPosition, (IndexAware) null);
1:40f9146:                 nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:40f9146:             }
1:5325cdb:         } finally {
1:b47da80:             this.indexLock.writeLock().unlock();
1:40f9146:         }
1:c9500f4:     }
1:40f9146: 
1:456a2ba:     public Location getLastUpdatePosition() throws IOException {
1:456a2ba:         return metadata.lastUpdate;
1:c9500f4:     }
1:a6a6a70: 
1:1595378:     private Location getRecoveryPosition() throws IOException {
1:f2517c0: 
1:f2517c0:         if (!this.forceRecoverIndex) {
1:f2517c0: 
1:f2517c0:             // If we need to recover the transactions..
1:f2517c0:             if (metadata.firstInProgressTransactionLocation != null) {
1:f2517c0:                 return metadata.firstInProgressTransactionLocation;
1:f2517c0:             }
1:40f9146: 
1:f2517c0:             // Perhaps there were no transactions...
1:1595378:             if( metadata.lastUpdate!=null) {
1:f2517c0:                 // Start replay at the record after the last one recorded in the index file.
1:1c41085:                 return getNextInitializedLocation(metadata.lastUpdate);
1:f2517c0:             }
1:c9500f4:         }
1:456a2ba:         // This loads the first position.
1:a6a6a70:         return journal.getNextLocation(null);
1:3bf9d0c:     }
1:3bf9d0c: 
1:1c41085:     private Location getNextInitializedLocation(Location location) throws IOException {
1:1c41085:         Location mayNotBeInitialized = journal.getNextLocation(location);
1:8c218ee:         if (location.getSize() == NOT_SET && mayNotBeInitialized != null && mayNotBeInitialized.getSize() != NOT_SET) {
1:1c41085:             // need to init size and type to skip
1:1c41085:             return journal.getNextLocation(mayNotBeInitialized);
1:1c41085:         } else {
1:1c41085:             return mayNotBeInitialized;
1:1c41085:         }
1:1c41085:     }
1:1c41085: 
1:b1a9130:     protected void checkpointCleanup(final boolean cleanup) throws IOException {
1:8f8f9ac:         long start;
1:40f9146:         this.indexLock.writeLock().lock();
1:40f9146:         try {
1:8f8f9ac:             start = System.currentTimeMillis();
1:1595378:             if( !opened.get() ) {
1:60b0c4f:                 return;
1:db3f8b3:             }
1:5325cdb:         } finally {
1:b47da80:             this.indexLock.writeLock().unlock();
1:db3f8b3:         }
1:4c51977:         checkpointUpdate(cleanup);
1:5325cdb:         long end = System.currentTimeMillis();
1:5325cdb:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:5325cdb:             if (LOG.isInfoEnabled()) {
1:5325cdb:                 LOG.info("Slow KahaDB access: cleanup took " + (end - start));
1:c6ed5ff:             }
1:3bf9d0c:         }
1:5325cdb:     }
1:db3f8b3: 
1:2030097:     public ByteSequence toByteSequence(JournalCommand<?> data) throws IOException {
1:2030097:         int size = data.serializedSizeFramed();
1:2030097:         DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
1:2030097:         os.writeByte(data.type().getNumber());
1:2030097:         data.writeFramed(os);
1:2030097:         return os.toByteSequence();
1:89f22da:     }
1:89f22da: 
1:89f22da:     // /////////////////////////////////////////////////////////////////
1:89f22da:     // Methods call by the broker to update and query the store.
1:89f22da:     // /////////////////////////////////////////////////////////////////
1:89f22da:     public Location store(JournalCommand<?> data) throws IOException {
1:89f22da:         return store(data, false, null,null);
1:89f22da:     }
1:89f22da: 
1:89f22da:     public Location store(JournalCommand<?> data, Runnable onJournalStoreComplete) throws IOException {
1:54e2e3b:         return store(data, false, null, null, onJournalStoreComplete);
1:54e2e3b:     }
1:89f22da: 
1:54e2e3b:     public Location store(JournalCommand<?> data, boolean sync, IndexAware before,Runnable after) throws IOException {
1:54e2e3b:         return store(data, sync, before, after, null);
1:54e2e3b:     }
1:54e2e3b: 
1:785b16b:     /**
1:a19e27a:      * All updated are are funneled through this method. The updates are converted
1:456a2ba:      * to a JournalMessage which is logged to the journal and then the data from
1:456a2ba:      * the JournalMessage is used to update the index just like it would be done
1:a19e27a:      * during a recovery process.
1:456a2ba:      */
1:54e2e3b:     public Location store(JournalCommand<?> data, boolean sync, IndexAware before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
1:101e711:         try {
1:2030097:             ByteSequence sequence = toByteSequence(data);
1:4c51977:             Location location;
1:946e62d: 
1:4c51977:             checkpointLock.readLock().lock();
1:101e711:             try {
1:2030097: 
1:4c51977:                 long start = System.currentTimeMillis();
1:946e62d:                 location = onJournalStoreComplete == null ? journal.write(sequence, sync) : journal.write(sequence, onJournalStoreComplete) ;
1:4c51977:                 long start2 = System.currentTimeMillis();
1:1a59827:                 //Track the last async update so we know if we need to sync at the next checkpoint
1:1a59827:                 if (!sync && journal.isJournalDiskSyncPeriodic()) {
1:1a59827:                     lastAsyncJournalUpdate.set(location);
1:1a59827:                 }
1:54e2e3b:                 process(data, location, before);
1:101e711: 
1:5325cdb:                 long end = System.currentTimeMillis();
1:946e62d:                 if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:5325cdb:                     if (LOG.isInfoEnabled()) {
1:1595378:                         LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
1:89f22da:                     }
1:2030097:                 }
1:946e62d:             } finally {
1:4c51977:                 checkpointLock.readLock().unlock();
1:c6ed5ff:             }
1:946e62d: 
1:395bf82:             if (after != null) {
1:66e8011:                 after.run();
1:c6ed5ff:             }
1:c6ed5ff: 
1:946e62d:             if (scheduler == null && opened.get()) {
1:40f9146:                 startCheckpoint();
1:101e711:             }
2:456a2ba:             return location;
1:946e62d:         } catch (IOException ioe) {
1:d53b8f8:             LOG.error("KahaDB failed to store to Journal, command of type: " + data.type(), ioe);
1:946e62d:             brokerService.handleIOException(ioe);
1:a6a6a70:             throw ioe;
1:101e711:         }
1:101e711:     }
1:101e711: 
1:456a2ba:     /**
1:456a2ba:      * Loads a previously stored JournalMessage
1:1595378:      *
1:1595378:      * @param location
1:8871b0e:      * @return
1:1595378:      * @throws IOException
1:456a2ba:      */
1:1595378:     public JournalCommand<?> load(Location location) throws IOException {
1:2b10259:         long start = System.currentTimeMillis();
1:456a2ba:         ByteSequence data = journal.read(location);
1:2b10259:         long end = System.currentTimeMillis();
1:1595378:         if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
1:5325cdb:             if (LOG.isInfoEnabled()) {
1:1595378:                 LOG.info("Slow KahaDB access: Journal read took: "+(end-start)+" ms");
1:2b10259:             }
1:101e711:         }
1:456a2ba:         DataByteArrayInputStream is = new DataByteArrayInputStream(data);
1:456a2ba:         byte readByte = is.readByte();
1:456a2ba:         KahaEntryType type = KahaEntryType.valueOf(readByte);
1:1595378:         if( type == null ) {
1:785b16b:             try {
1:3bf9d0c:                 is.close();
1:3bf9d0c:             } catch (IOException e) {}
1:2518bde:             throw new IOException("Could not load journal record, null type information from: " + readByte + " at location: "+location);
1:101e711:         }
1:1595378:         JournalCommand<?> message = (JournalCommand<?>)type.createMessage();
1:456a2ba:         message.mergeFramed(is);
1:456a2ba:         return message;
1:101e711:     }
1:101e711: 
1:a6a6a70:     /**
1:a6a6a70:      * do minimal recovery till we reach the last inDoubtLocation
1:1595378:      * @param data
1:1595378:      * @param location
1:1595378:      * @param inDoubtlocation
1:1595378:      * @throws IOException
1:a6a6a70:      */
1:a6a6a70:     void process(JournalCommand<?> data, final Location location, final Location inDoubtlocation) throws IOException {
1:a6a6a70:         if (inDoubtlocation != null && location.compareTo(inDoubtlocation) >= 0) {
1:54e2e3b:             process(data, location, (IndexAware) null);
1:db3f8b3:         } else {
1:a6a6a70:             // just recover producer audit
1:a6a6a70:             data.visit(new Visitor() {
1:54d56df:                 @Override
1:a6a6a70:                 public void visit(KahaAddMessageCommand command) throws IOException {
1:a6a6a70:                     metadata.producerSequenceIdTracker.isDuplicate(command.getMessageId());
1:0061f6f:                 }
1:a6a6a70:             });
1:0061f6f:         }
1:101e711:     }
1:a6c51a4: 
1:a6c51a4:     // /////////////////////////////////////////////////////////////////
1:456a2ba:     // Journaled record processing methods. Once the record is journaled,
1:456a2ba:     // these methods handle applying the index updates. These may be called
1:456a2ba:     // from the recovery method too so they need to be idempotent
1:a6c51a4:     // /////////////////////////////////////////////////////////////////
1:a6c51a4: 
1:54e2e3b:     void process(JournalCommand<?> data, final Location location, final IndexAware onSequenceAssignedCallback) throws IOException {
1:456a2ba:         data.visit(new Visitor() {
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaAddMessageCommand command) throws IOException {
1:54e2e3b:                 process(command, location, onSequenceAssignedCallback);
1:a6c51a4:             }
1:6fd292d: 
1:54d56df:             @Override
1:2030097:             public void visit(KahaRemoveMessageCommand command) throws IOException {
3:456a2ba:                 process(command, location);
1:a6c51a4:             }
1:deea2d1: 
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaPrepareCommand command) throws IOException {
1:456a2ba:                 process(command, location);
1:a6c51a4:             }
1:40f9146: 
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaCommitCommand command) throws IOException {
1:54e2e3b:                 process(command, location, onSequenceAssignedCallback);
1:6fd292d:             }
1:40f9146: 
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaRollbackCommand command) throws IOException {
1:456a2ba:                 process(command, location);
1:6fd292d:             }
1:40f9146: 
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaRemoveDestinationCommand command) throws IOException {
1:456a2ba:                 process(command, location);
1:a6a6a70:             }
1:40f9146: 
1:54d56df:             @Override
1:456a2ba:             public void visit(KahaSubscriptionCommand command) throws IOException {
1:456a2ba:                 process(command, location);
1:a6a6a70:             }
1:c6ed5ff: 
1:c6ed5ff:             @Override
1:c6ed5ff:             public void visit(KahaProducerAuditCommand command) throws IOException {
1:c6ed5ff:                 processLocation(location);
1:c6ed5ff:             }
1:c6ed5ff: 
1:c6ed5ff:             @Override
1:3bf9d0c:             public void visit(KahaAckMessageFileMapCommand command) throws IOException {
1:3bf9d0c:                 processLocation(location);
1:a6a6a70:             }
1:3bf9d0c: 
1:3bf9d0c:             @Override
1:c6ed5ff:             public void visit(KahaTraceCommand command) {
1:c6ed5ff:                 processLocation(location);
1:c6ed5ff:             }
1:266d23e: 
1:266d23e:             @Override
1:266d23e:             public void visit(KahaUpdateMessageCommand command) throws IOException {
1:266d23e:                 process(command, location);
1:266d23e:             }
1:946e62d: 
1:946e62d:             @Override
1:946e62d:             public void visit(KahaRewrittenDataFileCommand command) throws IOException {
1:946e62d:                 process(command, location);
1:946e62d:             }
1:40f9146:         });
1:5325cdb:     }
1:40f9146: 
1:c273cab:     @SuppressWarnings("rawtypes")
1:54e2e3b:     protected void process(final KahaAddMessageCommand command, final Location location, final IndexAware runWithIndexLock) throws IOException {
1:456a2ba:         if (command.hasTransactionInfo()) {
1:54e2e3b:             List<Operation> inflightTx = getInflightTx(command.getTransactionInfo());
1:54e2e3b:             inflightTx.add(new AddOperation(command, location, runWithIndexLock));
1:c6ed5ff:         } else {
1:101e711:             this.indexLock.writeLock().lock();
1:3bf9d0c:             try {
1:1595378:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                     @Override
1:1595378:                     public void execute(Transaction tx) throws IOException {
1:54e2e3b:                         long assignedIndex = updateIndex(tx, command, location);
1:54e2e3b:                         if (runWithIndexLock != null) {
1:54e2e3b:                             runWithIndexLock.sequenceAssignedWithIndexLocked(assignedIndex);
1:54e2e3b:                         }
1:5325cdb:                     }
1:4c51977:                 });
1:54e2e3b: 
1:101e711:             } finally {
1:101e711:                 this.indexLock.writeLock().unlock();
1:40f9146:             }
1:40f9146:         }
1:40f9146:     }
1:40f9146: 
1:266d23e:     protected void process(final KahaUpdateMessageCommand command, final Location location) throws IOException {
1:266d23e:         this.indexLock.writeLock().lock();
1:266d23e:         try {
1:266d23e:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:266d23e:                 @Override
1:266d23e:                 public void execute(Transaction tx) throws IOException {
1:266d23e:                     updateIndex(tx, command, location);
1:266d23e:                 }
1:266d23e:             });
1:266d23e:         } finally {
1:266d23e:             this.indexLock.writeLock().unlock();
1:266d23e:         }
1:266d23e:     }
1:266d23e: 
1:266d23e:     @SuppressWarnings("rawtypes")
1:456a2ba:     protected void process(final KahaRemoveMessageCommand command, final Location location) throws IOException {
1:456a2ba:         if (command.hasTransactionInfo()) {
1:54e2e3b:            List<Operation> inflightTx = getInflightTx(command.getTransactionInfo());
1:54e2e3b:            inflightTx.add(new RemoveOperation(command, location));
1:a6c51a4:         } else {
1:101e711:             this.indexLock.writeLock().lock();
1:40f9146:             try {
1:3bf9d0c:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                     @Override
1:3bf9d0c:                     public void execute(Transaction tx) throws IOException {
1:266d23e:                         updateIndex(tx, command, location);
1:40f9146:                     }
1:c9500f4:                 });
1:101e711:             } finally {
1:101e711:                 this.indexLock.writeLock().unlock();
1:40f9146:             }
1:4c51977:         }
1:4c51977:     }
1:40f9146: 
1:456a2ba:     protected void process(final KahaRemoveDestinationCommand command, final Location location) throws IOException {
1:40f9146:         this.indexLock.writeLock().lock();
1:4c51977:         try {
1:3bf9d0c:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                 @Override
1:40f9146:                 public void execute(Transaction tx) throws IOException {
1:266d23e:                     updateIndex(tx, command, location);
1:4c51977:                 }
1:fbc5eb5:             });
1:5325cdb:         } finally {
1:b47da80:             this.indexLock.writeLock().unlock();
1:c9500f4:         }
1:c9500f4:     }
1:40f9146: 
1:456a2ba:     protected void process(final KahaSubscriptionCommand command, final Location location) throws IOException {
1:40f9146:         this.indexLock.writeLock().lock();
1:4c51977:         try {
1:40f9146:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                 @Override
1:4c51977:                 public void execute(Transaction tx) throws IOException {
3:456a2ba:                     updateIndex(tx, command, location);
1:c9500f4:                 }
1:fbc5eb5:             });
1:5325cdb:         } finally {
1:b47da80:             this.indexLock.writeLock().unlock();
1:fbc5eb5:         }
1:fbc5eb5:     }
1:40f9146: 
1:c6ed5ff:     protected void processLocation(final Location location) {
1:6ce702d:         this.indexLock.writeLock().lock();
2:fbc5eb5:         try {
1:54e2e3b:             metadata.lastUpdate = location;
1:c6ed5ff:         } finally {
1:c6ed5ff:             this.indexLock.writeLock().unlock();
1:4ab55f1:         }
1:c6ed5ff:     }
1:2c53dbc: 
1:c273cab:     @SuppressWarnings("rawtypes")
1:54e2e3b:     protected void process(KahaCommitCommand command, final Location location, final IndexAware before) throws IOException {
1:1595378:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
1:b1d7a78:         List<Operation> inflightTx;
1:76f842d:         synchronized (inflightTransactions) {
1:76f842d:             inflightTx = inflightTransactions.remove(key);
2:456a2ba:             if (inflightTx == null) {
1:456a2ba:                 inflightTx = preparedTransactions.remove(key);
1:395bf82:             }
1:c6ed5ff:         }
1:76f842d:         if (inflightTx == null) {
1:66e8011:             // only non persistent messages in this tx
1:66e8011:             if (before != null) {
1:54e2e3b:                 before.sequenceAssignedWithIndexLocked(-1);
1:c6ed5ff:             }
1:946e62d:             return;
1:c6ed5ff:         }
1:4ab55f1: 
1:b1d7a78:         final List<Operation> messagingTx = inflightTx;
1:140ce1b:         indexLock.writeLock().lock();
1:54e2e3b:         try {
1:140ce1b:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:140ce1b:                 @Override
1:140ce1b:                 public void execute(Transaction tx) throws IOException {
1:140ce1b:                     for (Operation op : messagingTx) {
1:140ce1b:                         op.execute(tx);
1:140ce1b:                     }
1:54e2e3b:                 }
1:140ce1b:             });
1:140ce1b:             metadata.lastUpdate = location;
1:140ce1b:         } finally {
1:140ce1b:             indexLock.writeLock().unlock();
1:54e2e3b:         }
1:946e62d:     }
1:946e62d: 
1:c273cab:     @SuppressWarnings("rawtypes")
1:456a2ba:     protected void process(KahaPrepareCommand command, Location location) {
1:1595378:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
1:76f842d:         synchronized (inflightTransactions) {
1:b1d7a78:             List<Operation> tx = inflightTransactions.remove(key);
1:456a2ba:             if (tx != null) {
1:456a2ba:                 preparedTransactions.put(key, tx);
1:66e8011:             }
1:76f842d:         }
1:76f842d:     }
1:946e62d: 
1:c273cab:     @SuppressWarnings("rawtypes")
1:2030097:     protected void process(KahaRollbackCommand command, Location location)  throws IOException {
1:1595378:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
1:2030097:         List<Operation> updates = null;
1:76f842d:         synchronized (inflightTransactions) {
1:2030097:             updates = inflightTransactions.remove(key);
1:2030097:             if (updates == null) {
1:2030097:                 updates = preparedTransactions.remove(key);
1:2030097:             }
1:2030097:         }
1:2030097:     }
1:946e62d: 
1:946e62d:     protected void process(KahaRewrittenDataFileCommand command, Location location)  throws IOException {
1:281d600:         final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
1:946e62d: 
1:4d6cc4b:         // Mark the current journal file as a compacted file so that gc checks can skip
1:4d6cc4b:         // over logs that are smaller compaction type logs.
1:4d6cc4b:         DataFile current = journal.getDataFileById(location.getDataFileId());
1:4d6cc4b:         current.setTypeCode(command.getRewriteType());
1:4d6cc4b: 
1:4d6cc4b:         if (completeFileSet.contains(command.getSourceDataFileId()) && command.getSkipIfSourceExists()) {
1:946e62d:             // Move offset so that next location read jumps to next file.
1:946e62d:             location.setOffset(journalMaxFileLength);
1:946e62d:         }
1:946e62d:     }
1:946e62d: 
3:456a2ba:     // /////////////////////////////////////////////////////////////////
1:456a2ba:     // These methods do the actual index updates.
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:946e62d: 
1:b47da80:     protected final ReentrantReadWriteLock indexLock = new ReentrantReadWriteLock();
1:281d600:     private final HashSet<Integer> journalFilesBeingReplicated = new HashSet<>();
1:fb0b63e: 
1:54e2e3b:     long updateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
1:456a2ba:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:2030097: 
1:456a2ba:         // Skip adding the message to the index if this is a topic and there are
1:456a2ba:         // no subscriptions.
1:8871c67:         if (sd.subscriptions != null && sd.subscriptions.isEmpty(tx)) {
1:54e2e3b:             return -1;
1:2030097:         }
1:2030097: 
1:456a2ba:         // Add the message.
1:cba0468:         int priority = command.getPrioritySupported() ? command.getPriority() : javax.jms.Message.DEFAULT_PRIORITY;
1:fcabcd2:         long id = sd.orderIndex.getNextMessageId();
1:456a2ba:         Long previous = sd.locationIndex.put(tx, location, id);
1:cba0468:         if (previous == null) {
1:bdd9e2a:             previous = sd.messageIdIndex.put(tx, command.getMessageId(), id);
1:cba0468:             if (previous == null) {
1:785b16b:                 incrementAndAddSizeToStoreStat(command.getDestination(), location.getSize());
1:cba0468:                 sd.orderIndex.put(tx, priority, id, new MessageKeys(command.getMessageId(), location));
1:f4a2543:                 if (sd.subscriptions != null && !sd.subscriptions.isEmpty(tx)) {
1:cf3d419:                     addAckLocationForNewMessage(tx, command.getDestination(), sd, id);
1:2030097:                 }
1:1352265:                 metadata.lastUpdate = location;
1:a6a6a70:             } else {
1:a5050a8: 
1:2c53dbc:                 MessageKeys messageKeys = sd.orderIndex.get(tx, previous);
1:2c53dbc:                 if (messageKeys != null && messageKeys.location.compareTo(location) < 0) {
1:2c53dbc:                     // If the message ID is indexed, then the broker asked us to store a duplicate before the message was dispatched and acked, we ignore this add attempt
1:2c53dbc:                     LOG.warn("Duplicate message add attempt rejected. Destination: {}://{}, Message id: {}", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId());
1:2c53dbc:                 }
1:bdd9e2a:                 sd.messageIdIndex.put(tx, command.getMessageId(), previous);
1:815c2f3:                 sd.locationIndex.remove(tx, location);
1:54e2e3b:                 id = -1;
1:8871c67:             }
1:bdd9e2a:         } else {
1:3bf9d0c:             // restore the previous value.. Looks like this was a redo of a previously
1:3bf9d0c:             // added message. We don't want to assign it a new id as the other indexes would
1:456a2ba:             // be wrong..
1:456a2ba:             sd.locationIndex.put(tx, location, previous);
1:fcabcd2:             // ensure sequence is not broken
1:fcabcd2:             sd.orderIndex.revertNextMessageId();
1:1352265:             metadata.lastUpdate = location;
1:f4a2543:         }
1:a6a6a70:         // record this id in any event, initial send or recovery
1:a6a6a70:         metadata.producerSequenceIdTracker.isDuplicate(command.getMessageId());
1:785b16b: 
1:54e2e3b:        return id;
1:54e2e3b:     }
1:54e2e3b: 
1:54e2e3b:     void trackPendingAdd(KahaDestination destination, Long seq) {
1:54e2e3b:         StoredDestination sd = storedDestinations.get(key(destination));
1:54e2e3b:         if (sd != null) {
1:54e2e3b:             sd.trackPendingAdd(seq);
1:54e2e3b:         }
1:54e2e3b:     }
1:54e2e3b: 
1:54e2e3b:     void trackPendingAddComplete(KahaDestination destination, Long seq) {
1:54e2e3b:         StoredDestination sd = storedDestinations.get(key(destination));
1:54e2e3b:         if (sd != null) {
1:54e2e3b:             sd.trackPendingAddComplete(seq);
1:54e2e3b:         }
1:40f9146:     }
1:c6ed5ff: 
1:266d23e:     void updateIndex(Transaction tx, KahaUpdateMessageCommand updateMessageCommand, Location location) throws IOException {
1:266d23e:         KahaAddMessageCommand command = updateMessageCommand.getMessage();
1:266d23e:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:266d23e: 
1:266d23e:         Long id = sd.messageIdIndex.get(tx, command.getMessageId());
1:266d23e:         if (id != null) {
1:a0c42a6:             MessageKeys previousKeys = sd.orderIndex.put(
1:266d23e:                     tx,
1:266d23e:                     command.getPrioritySupported() ? command.getPriority() : javax.jms.Message.DEFAULT_PRIORITY,
1:266d23e:                     id,
1:266d23e:                     new MessageKeys(command.getMessageId(), location)
1:266d23e:             );
1:266d23e:             sd.locationIndex.put(tx, location, id);
1:785b16b:             incrementAndAddSizeToStoreStat(command.getDestination(), location.getSize());
1:266d23e: 
1:a5050a8:             if (previousKeys != null) {
1:a5050a8:                 //Remove the existing from the size
1:785b16b:                 decrementAndSubSizeToStoreStat(command.getDestination(), previousKeys.location.getSize());
1:a5050a8: 
1:cf3d419:                 //update all the subscription metrics
1:2731f04:                 if (enableSubscriptionStatistics && sd.ackPositions != null && location.getSize() != previousKeys.location.getSize()) {
1:cf3d419:                     Iterator<Entry<String, SequenceSet>> iter = sd.ackPositions.iterator(tx);
1:cf3d419:                     while (iter.hasNext()) {
1:cf3d419:                         Entry<String, SequenceSet> e = iter.next();
1:cf3d419:                         if (e.getValue().contains(id)) {
1:cf3d419:                             incrementAndAddSizeToStoreStat(key(command.getDestination()), e.getKey(), location.getSize());
1:cf3d419:                             decrementAndSubSizeToStoreStat(key(command.getDestination()), e.getKey(), previousKeys.location.getSize());
1:266d23e:                         }
1:266d23e:                     }
1:cf3d419:                 }
1:cf3d419: 
1:2c53dbc:                 // on first update previous is original location, on recovery/replay it may be the updated location
1:a5050a8:                 if(!previousKeys.location.equals(location)) {
1:a0c42a6:                     sd.locationIndex.remove(tx, previousKeys.location);
1:a0c42a6:                 }
1:cf3d419:             }
1:1352265:             metadata.lastUpdate = location;
1:266d23e:         } else {
1:b4aa53d:             //Add the message if it can't be found
1:b4aa53d:             this.updateIndex(tx, command, location);
1:cf3d419:         }
1:a5050a8:     }
1:40f9146: 
1:1a5ad28:     void updateIndex(Transaction tx, KahaRemoveMessageCommand command, Location ackLocation) throws IOException {
1:456a2ba:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:456a2ba:         if (!command.hasSubscriptionKey()) {
1:40f9146: 
1:456a2ba:             // In the queue case we just remove the message from the index..
1:456a2ba:             Long sequenceId = sd.messageIdIndex.remove(tx, command.getMessageId());
2:456a2ba:             if (sequenceId != null) {
1:fbc5eb5:                 MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
1:722258e:                 if (keys != null) {
1:722258e:                     sd.locationIndex.remove(tx, keys.location);
1:785b16b:                     decrementAndSubSizeToStoreStat(command.getDestination(), keys.location.getSize());
1:f2517c0:                     recordAckMessageReferenceLocation(ackLocation, keys.location);
1:1352265:                     metadata.lastUpdate = ackLocation;
1:2398a3a:                 }  else if (LOG.isDebugEnabled()) {
1:2398a3a:                     LOG.debug("message not found in order index: " + sequenceId  + " for: " + command.getMessageId());
1:722258e:                 }
1:2398a3a:             } else if (LOG.isDebugEnabled()) {
1:2398a3a:                 LOG.debug("message not found in sequence id index: " + command.getMessageId());
1:40f9146:             }
1:943db3c:         } else {
1:456a2ba:             // In the topic case we need remove the message once it's been acked
1:456a2ba:             // by all the subs
1:456a2ba:             Long sequence = sd.messageIdIndex.get(tx, command.getMessageId());
1:40f9146: 
1:456a2ba:             // Make sure it's a valid message id...
1:456a2ba:             if (sequence != null) {
3:456a2ba:                 String subscriptionKey = command.getSubscriptionKey();
1:8871c67:                 if (command.getAck() != UNMATCHED) {
1:8871c67:                     sd.orderIndex.get(tx, sequence);
1:8871c67:                     byte priority = sd.orderIndex.lastGetPriority();
1:8871c67:                     sd.subscriptionAcks.put(tx, subscriptionKey, new LastAck(sequence, priority));
1:6ddbba4:                 }
1:6fd292d: 
1:3bf9d0c:                 MessageKeys keys = sd.orderIndex.get(tx, sequence);
1:3bf9d0c:                 if (keys != null) {
1:3bf9d0c:                     recordAckMessageReferenceLocation(ackLocation, keys.location);
1:3bf9d0c:                 }
1:8871c67:                 // The following method handles deleting un-referenced messages.
1:785b16b:                 removeAckLocation(command, tx, sd, subscriptionKey, sequence);
1:1352265:                 metadata.lastUpdate = ackLocation;
1:9c9b856:             } else if (LOG.isDebugEnabled()) {
1:fcabcd2:                 LOG.debug("on ack, no message sequence exists for id: " + command.getMessageId() + " and sub: " + command.getSubscriptionKey());
1:fbc5eb5:             }
1:6fd292d: 
1:fbc5eb5:         }
1:fbc5eb5:     }
1:6ddbba4: 
1:f2517c0:     private void recordAckMessageReferenceLocation(Location ackLocation, Location messageLocation) {
1:3bf9d0c:         Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(Integer.valueOf(ackLocation.getDataFileId()));
1:f2517c0:         if (referenceFileIds == null) {
1:281d600:             referenceFileIds = new HashSet<>();
1:f2517c0:             referenceFileIds.add(messageLocation.getDataFileId());
1:3bf9d0c:             metadata.ackMessageFileMap.put(ackLocation.getDataFileId(), referenceFileIds);
1:f2517c0:         } else {
1:f2517c0:             Integer id = Integer.valueOf(messageLocation.getDataFileId());
1:f2517c0:             if (!referenceFileIds.contains(id)) {
1:f2517c0:                 referenceFileIds.add(id);
1:f2517c0:             }
1:f2517c0:         }
1:f2517c0:     }
1:f2517c0: 
1:1a5ad28:     void updateIndex(Transaction tx, KahaRemoveDestinationCommand command, Location location) throws IOException {
1:456a2ba:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:cba0468:         sd.orderIndex.remove(tx);
1:40f9146: 
1:0af0021:         sd.locationIndex.clear(tx);
1:456a2ba:         sd.locationIndex.unload(tx);
1:456a2ba:         tx.free(sd.locationIndex.getPageId());
1:40f9146: 
1:0af0021:         sd.messageIdIndex.clear(tx);
1:456a2ba:         sd.messageIdIndex.unload(tx);
1:456a2ba:         tx.free(sd.messageIdIndex.getPageId());
1:34af42f: 
1:456a2ba:         if (sd.subscriptions != null) {
1:456a2ba:             sd.subscriptions.clear(tx);
1:456a2ba:             sd.subscriptions.unload(tx);
1:456a2ba:             tx.free(sd.subscriptions.getPageId());
1:34af42f: 
1:456a2ba:             sd.subscriptionAcks.clear(tx);
1:456a2ba:             sd.subscriptionAcks.unload(tx);
1:456a2ba:             tx.free(sd.subscriptionAcks.getPageId());
1:3f0cf98: 
1:3f0cf98:             sd.ackPositions.clear(tx);
1:3f0cf98:             sd.ackPositions.unload(tx);
1:943db3c:             tx.free(sd.ackPositions.getHeadPageId());
1:3bf9d0c: 
1:3bf9d0c:             sd.subLocations.clear(tx);
1:3bf9d0c:             sd.subLocations.unload(tx);
1:3bf9d0c:             tx.free(sd.subLocations.getHeadPageId());
1:34af42f:         }
1:34af42f: 
1:456a2ba:         String key = key(command.getDestination());
1:456a2ba:         storedDestinations.remove(key);
1:456a2ba:         metadata.destinations.remove(tx, key);
1:785b16b:         clearStoreStats(command.getDestination());
1:785b16b:         storeCache.remove(key(command.getDestination()));
1:34af42f:     }
1:34af42f: 
1:1a5ad28:     void updateIndex(Transaction tx, KahaSubscriptionCommand command, Location location) throws IOException {
1:456a2ba:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:1c1aa17:         final String subscriptionKey = command.getSubscriptionKey();
1:34af42f: 
1:456a2ba:         // If set then we are creating it.. otherwise we are destroying the sub
1:456a2ba:         if (command.hasSubscriptionInfo()) {
1:dc06c8d:             Location existing = sd.subLocations.get(tx, subscriptionKey);
1:dc06c8d:             if (existing != null && existing.compareTo(location) == 0) {
1:dc06c8d:                 // replay on recovery, ignore
1:dc06c8d:                 LOG.trace("ignoring journal replay of replay of sub from: " + location);
1:dc06c8d:                 return;
1:dc06c8d:             }
1:dc06c8d: 
1:456a2ba:             sd.subscriptions.put(tx, subscriptionKey, command);
1:3bf9d0c:             sd.subLocations.put(tx, subscriptionKey, location);
1:1595378:             long ackLocation=NOT_ACKED;
1:456a2ba:             if (!command.getRetroactive()) {
1:1595378:                 ackLocation = sd.orderIndex.nextMessageId-1;
1:8871c67:             } else {
1:eaac0d2:                 addAckLocationForRetroactiveSub(tx, sd, subscriptionKey);
1:34af42f:             }
1:8871c67:             sd.subscriptionAcks.put(tx, subscriptionKey, new LastAck(ackLocation));
1:943db3c:             sd.subscriptionCache.add(subscriptionKey);
1:34af42f:         } else {
1:456a2ba:             // delete the sub...
1:456a2ba:             sd.subscriptions.remove(tx, subscriptionKey);
1:3bf9d0c:             sd.subLocations.remove(tx, subscriptionKey);
1:8871c67:             sd.subscriptionAcks.remove(tx, subscriptionKey);
1:943db3c:             sd.subscriptionCache.remove(subscriptionKey);
1:785b16b:             removeAckLocationsForSub(command, tx, sd, subscriptionKey);
1:cf3d419:             MessageStoreSubscriptionStatistics subStats = getSubStats(key(command.getDestination()));
1:cf3d419:             if (subStats != null) {
1:cf3d419:                 subStats.removeSubscription(subscriptionKey);
1:cf3d419:             }
1:34af42f: 
1:0af0021:             if (sd.subscriptions.isEmpty(tx)) {
1:3fdf986:                 // remove the stored destination
1:3fdf986:                 KahaRemoveDestinationCommand removeDestinationCommand = new KahaRemoveDestinationCommand();
1:3fdf986:                 removeDestinationCommand.setDestination(command.getDestination());
1:3fdf986:                 updateIndex(tx, removeDestinationCommand, null);
1:785b16b:                 clearStoreStats(command.getDestination());
1:34af42f:             }
1:34af42f:         }
1:34af42f:     }
1:34af42f: 
1:4c51977:     private void checkpointUpdate(final boolean cleanup) throws IOException {
1:4c51977:         checkpointLock.writeLock().lock();
1:db3f8b3:         try {
1:4c51977:             this.indexLock.writeLock().lock();
1:4c51977:             try {
1:2052239:                 Set<Integer> filesToGc = pageFile.tx().execute(new Transaction.CallableClosure<Set<Integer>, IOException>() {
1:54e2e3b:                     @Override
1:2052239:                     public Set<Integer> execute(Transaction tx) throws IOException {
1:2052239:                         return checkpointUpdate(tx, cleanup);
1:34af42f:                     }
1:54e2e3b:                 });
1:ca5e41b:                 pageFile.flush();
1:2052239:                 // after the index update such that partial removal does not leave dangling references in the index.
1:2052239:                 journal.removeDataFiles(filesToGc);
1:54e2e3b:             } finally {
1:4c51977:                 this.indexLock.writeLock().unlock();
1:0af0021:             }
1:34af42f: 
1:db3f8b3:         } finally {
1:e53e340:             checkpointLock.writeLock().unlock();
1:4c51977:         }
1:4c51977:     }
1:40f9146: 
1:456a2ba:     /**
1:456a2ba:      * @param tx
1:a6a6a70:      * @throws IOException
1:456a2ba:      */
1:2052239:     Set<Integer> checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
1:4386750:         MDC.put("activemq.persistenceDir", getDirectory().getName());
1:456a2ba:         LOG.debug("Checkpoint started.");
1:6b643dc: 
1:6b643dc:         // reflect last update exclusive of current checkpoint
1:0dcdab7:         Location lastUpdate = metadata.lastUpdate;
1:6b643dc: 
1:456a2ba:         metadata.state = OPEN_STATE;
1:1595378:         metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
1:3bf9d0c:         metadata.ackMessageFileMapLocation = checkpointAckMessageFileMap();
1:0dcdab7:         Location[] inProgressTxRange = getInProgressTxLocationRange();
1:0dcdab7:         metadata.firstInProgressTransactionLocation = inProgressTxRange[0];
1:456a2ba:         tx.store(metadata.page, metadataMarshaller, true);
1:40f9146: 
1:2052239:         final TreeSet<Integer> gcCandidateSet = new TreeSet<>();
1:946e62d:         if (cleanup) {
1:40f9146: 
1:281d600:             final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
1:2052239:             gcCandidateSet.addAll(completeFileSet);
1:40f9146: 
1:5325cdb:             if (LOG.isTraceEnabled()) {
1:0dcdab7:                 LOG.trace("Last update: " + lastUpdate + ", full gc candidates set: " + gcCandidateSet);
1:0dcdab7:             }
1:0dcdab7: 
1:0dcdab7:             if (lastUpdate != null) {
1:c1cbf50:                 // we won't delete past the last update, ackCompaction journal can be a candidate in error
1:c1cbf50:                 gcCandidateSet.removeAll(new TreeSet<Integer>(gcCandidateSet.tailSet(lastUpdate.getDataFileId())));
1:fbc5eb5:             }
1:40f9146: 
1:40f9146:             // Don't GC files under replication
1:1595378:             if( journalFilesBeingReplicated!=null ) {
1:40f9146:                 gcCandidateSet.removeAll(journalFilesBeingReplicated);
1:40f9146:             }
1:6b643dc: 
1:40f9146:             if (metadata.producerSequenceIdTrackerLocation != null) {
1:65bc9f3:                 int dataFileId = metadata.producerSequenceIdTrackerLocation.getDataFileId();
1:65bc9f3:                 if (gcCandidateSet.contains(dataFileId) && gcCandidateSet.first() == dataFileId) {
1:65bc9f3:                     // rewrite so we don't prevent gc
1:65bc9f3:                     metadata.producerSequenceIdTracker.setModified(true);
1:65bc9f3:                     if (LOG.isTraceEnabled()) {
1:65bc9f3:                         LOG.trace("rewriting producerSequenceIdTracker:" + metadata.producerSequenceIdTrackerLocation);
1:65bc9f3:                     }
1:65bc9f3:                 }
1:65bc9f3:                 gcCandidateSet.remove(dataFileId);
1:65bc9f3:                 if (LOG.isTraceEnabled()) {
1:9b64e18:                     LOG.trace("gc candidates after producerSequenceIdTrackerLocation:" + metadata.producerSequenceIdTrackerLocation + ", " + gcCandidateSet);
1:65bc9f3:                 }
1:fbc5eb5:             }
1:40f9146: 
1:3bf9d0c:             if (metadata.ackMessageFileMapLocation != null) {
1:3bf9d0c:                 int dataFileId = metadata.ackMessageFileMapLocation.getDataFileId();
1:3bf9d0c:                 gcCandidateSet.remove(dataFileId);
1:3bf9d0c:                 if (LOG.isTraceEnabled()) {
1:9b64e18:                     LOG.trace("gc candidates after ackMessageFileMapLocation:" + metadata.ackMessageFileMapLocation + ", " + gcCandidateSet);
1:3bf9d0c:                 }
1:3bf9d0c:             }
1:3bf9d0c: 
1:0dcdab7:             // Don't GC files referenced by in-progress tx
1:0dcdab7:             if (inProgressTxRange[0] != null) {
1:0dcdab7:                 for (int pendingTx=inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
1:0dcdab7:                     gcCandidateSet.remove(pendingTx);
1:fbc5eb5:                 }
1:fbc5eb5:             }
1:0dcdab7:             if (LOG.isTraceEnabled()) {
1:9b64e18:                 LOG.trace("gc candidates after in progress tx range:" + Arrays.asList(inProgressTxRange) + ", " + gcCandidateSet);
1:fbc5eb5:             }
1:40f9146: 
1:8262ef7:             // Go through all the destinations to see if any of them can remove GC candidates.
1:514ef7d:             for (Entry<String, StoredDestination> entry : storedDestinations.entrySet()) {
1:1595378:                 if( gcCandidateSet.isEmpty() ) {
1:734fb7d:                     break;
1:40f9146:                 }
1:1c1aa17: 
1:456a2ba:                 // Use a visitor to cut down the number of pages that we load
1:514ef7d:                 entry.getValue().locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
1:1595378:                     int last=-1;
1:2030097:                     @Override
1:456a2ba:                     public boolean isInterestedInKeysBetween(Location first, Location second) {
1:1595378:                         if( first==null ) {
1:1595378:                             SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
1:1595378:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
1:40f9146:                                 subset.remove(second.getDataFileId());
1:40f9146:                             }
1:40f9146:                             return !subset.isEmpty();
1:1595378:                         } else if( second==null ) {
1:40f9146:                             SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
1:1595378:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:40f9146:                                 subset.remove(first.getDataFileId());
1:40f9146:                             }
1:40f9146:                             return !subset.isEmpty();
1:40f9146:                         } else {
1:1595378:                             SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
1:1595378:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:40f9146:                                 subset.remove(first.getDataFileId());
1:40f9146:                             }
1:1595378:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
1:40f9146:                                 subset.remove(second.getDataFileId());
1:40f9146:                             }
1:40f9146:                             return !subset.isEmpty();
1:fbc5eb5:                         }
1:fbc5eb5:                     }
1:1c1aa17: 
1:54d56df:                     @Override
1:456a2ba:                     public void visit(List<Location> keys, List<Long> values) {
1:40f9146:                         for (Location l : keys) {
1:8262ef7:                             int fileId = l.getDataFileId();
1:1595378:                             if( last != fileId ) {
1:40f9146:                                 gcCandidateSet.remove(fileId);
1:8262ef7:                                 last = fileId;
1:1c1aa17:                             }
1:fbc5eb5:                         }
1:e22a37a:                     }
1:2030097:                 });
1:40f9146: 
1:3bf9d0c:                 // Durable Subscription
1:3bf9d0c:                 if (entry.getValue().subLocations != null) {
1:3bf9d0c:                     Iterator<Entry<String, Location>> iter = entry.getValue().subLocations.iterator(tx);
1:3bf9d0c:                     while (iter.hasNext()) {
1:3bf9d0c:                         Entry<String, Location> subscription = iter.next();
1:3bf9d0c:                         int dataFileId = subscription.getValue().getDataFileId();
1:3bf9d0c: 
1:3bf9d0c:                         // Move subscription along if it has no outstanding messages that need ack'd
1:3bf9d0c:                         // and its in the last log file in the journal.
1:3bf9d0c:                         if (!gcCandidateSet.isEmpty() && gcCandidateSet.first() == dataFileId) {
1:3bf9d0c:                             final StoredDestination destination = entry.getValue();
1:3bf9d0c:                             final String subscriptionKey = subscription.getKey();
1:3bf9d0c:                             SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);
1:3bf9d0c: 
1:3bf9d0c:                             // When pending is size one that is the next message Id meaning there
1:3bf9d0c:                             // are no pending messages currently.
1:193f6be:                             if (pendingAcks == null || pendingAcks.isEmpty() ||
1:193f6be:                                 (pendingAcks.size() == 1 && pendingAcks.getTail().range() == 1)) {
1:193f6be: 
1:3bf9d0c:                                 if (LOG.isTraceEnabled()) {
1:3bf9d0c:                                     LOG.trace("Found candidate for rewrite: {} from file {}", entry.getKey(), dataFileId);
1:3bf9d0c:                                 }
1:3bf9d0c: 
1:3bf9d0c:                                 final KahaSubscriptionCommand kahaSub =
1:3bf9d0c:                                     destination.subscriptions.get(tx, subscriptionKey);
1:3bf9d0c:                                 destination.subLocations.put(
1:3bf9d0c:                                     tx, subscriptionKey, checkpointSubscriptionCommand(kahaSub));
1:3bf9d0c: 
1:3bf9d0c:                                 // Skips the remove from candidates if we rewrote the subscription
1:3bf9d0c:                                 // in order to prevent duplicate subscription commands on recover.
1:3bf9d0c:                                 // If another subscription is on the same file and isn't rewritten
1:3bf9d0c:                                 // than it will remove the file from the set.
1:3bf9d0c:                                 continue;
1:3bf9d0c:                             }
1:3bf9d0c:                         }
1:3bf9d0c: 
1:3bf9d0c:                         gcCandidateSet.remove(dataFileId);
1:3bf9d0c:                     }
1:3bf9d0c:                 }
1:3bf9d0c: 
1:5325cdb:                 if (LOG.isTraceEnabled()) {
1:514ef7d:                     LOG.trace("gc candidates after dest:" + entry.getKey() + ", " + gcCandidateSet);
1:5325cdb:                 }
1:e22a37a:             }
1:40f9146: 
1:f2517c0:             // check we are not deleting file with ack for in-use journal files
1:5325cdb:             if (LOG.isTraceEnabled()) {
1:514ef7d:                 LOG.trace("gc candidates: " + gcCandidateSet);
1:5db5f3e:                 LOG.trace("ackMessageFileMap: " +  metadata.ackMessageFileMap);
1:5325cdb:             }
1:946e62d: 
1:31d99b6:             boolean ackMessageFileMapMod = false;
1:f2517c0:             Iterator<Integer> candidates = gcCandidateSet.iterator();
1:f2517c0:             while (candidates.hasNext()) {
1:f2517c0:                 Integer candidate = candidates.next();
1:3bf9d0c:                 Set<Integer> referencedFileIds = metadata.ackMessageFileMap.get(candidate);
1:f2517c0:                 if (referencedFileIds != null) {
1:f2517c0:                     for (Integer referencedFileId : referencedFileIds) {
1:b0a1bd8:                         if (completeFileSet.contains(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
1:f2517c0:                             // active file that is not targeted for deletion is referenced so don't delete
1:f2517c0:                             candidates.remove();
1:734fb7d:                             break;
1:f2517c0:                         }
1:f2517c0:                     }
1:f2517c0:                     if (gcCandidateSet.contains(candidate)) {
1:31d99b6:                         ackMessageFileMapMod |= (metadata.ackMessageFileMap.remove(candidate) != null);
1:f2517c0:                     } else {
1:5325cdb:                         if (LOG.isTraceEnabled()) {
1:514ef7d:                             LOG.trace("not removing data file: " + candidate
1:f2517c0:                                     + " as contained ack(s) refer to referenced file: " + referencedFileIds);
1:f2517c0:                         }
1:f2517c0:                     }
1:f2517c0:                 }
1:5325cdb:             }
1:f2517c0: 
1:5325cdb:             if (!gcCandidateSet.isEmpty()) {
1:946e62d:                 LOG.debug("Cleanup removing the data files: {}", gcCandidateSet);
1:5db5f3e:                 for (Integer candidate : gcCandidateSet) {
1:5db5f3e:                     for (Set<Integer> ackFiles : metadata.ackMessageFileMap.values()) {
1:5db5f3e:                         ackMessageFileMapMod |= ackFiles.remove(candidate);
1:5db5f3e:                     }
1:5db5f3e:                 }
1:5db5f3e:                 if (ackMessageFileMapMod) {
1:5db5f3e:                     checkpointUpdate(tx, false);
1:5db5f3e:                 }
1:cbad8ba:             } else if (isEnableAckCompaction()) {
1:946e62d:                 if (++checkPointCyclesWithNoGC >= getCompactAcksAfterNoGC()) {
1:946e62d:                     // First check length of journal to make sure it makes sense to even try.
1:946e62d:                     //
1:946e62d:                     // If there is only one journal file with Acks in it we don't need to move
1:946e62d:                     // it since it won't be chained to any later logs.
1:946e62d:                     //
1:946e62d:                     // If the logs haven't grown since the last time then we need to compact
1:946e62d:                     // otherwise there seems to still be room for growth and we don't need to incur
1:946e62d:                     // the overhead.  Depending on configuration this check can be avoided and
1:946e62d:                     // Ack compaction will run any time the store has not GC'd a journal file in
1:946e62d:                     // the configured amount of cycles.
1:946e62d:                     if (metadata.ackMessageFileMap.size() > 1 &&
1:946e62d:                         (journalLogOnLastCompactionCheck == journal.getCurrentDataFileId() || isCompactAcksIgnoresStoreGrowth())) {
1:e53e340: 
1:946e62d:                         LOG.trace("No files GC'd checking if threshold to ACK compaction has been met.");
1:946e62d:                         try {
1:946e62d:                             scheduler.execute(new AckCompactionRunner());
1:946e62d:                         } catch (Exception ex) {
1:946e62d:                             LOG.warn("Error on queueing the Ack Compactor", ex);
1:946e62d:                         }
1:946e62d:                     } else {
1:946e62d:                         LOG.trace("Journal activity detected, no Ack compaction scheduled.");
1:946e62d:                     }
1:e53e340: 
1:946e62d:                     checkPointCyclesWithNoGC = 0;
1:946e62d:                 } else {
1:946e62d:                     LOG.trace("Not yet time to check for compaction: {} of {} cycles",
1:946e62d:                               checkPointCyclesWithNoGC, getCompactAcksAfterNoGC());
1:946e62d:                 }
1:946e62d: 
1:946e62d:                 journalLogOnLastCompactionCheck = journal.getCurrentDataFileId();
1:946e62d:             }
1:946e62d:         }
1:4386750:         MDC.remove("activemq.persistenceDir");
1:946e62d: 
1:456a2ba:         LOG.debug("Checkpoint done.");
1:2052239:         return gcCandidateSet;
1:946e62d:     }
1:946e62d: 
1:946e62d:     private final class AckCompactionRunner implements Runnable {
1:946e62d: 
1:946e62d:         @Override
1:946e62d:         public void run() {
1:946e62d: 
1:62bdbb0:             int journalToAdvance = -1;
1:281d600:             Set<Integer> journalLogsReferenced = new HashSet<>();
1:62bdbb0: 
1:c8a6171:             //flag to know whether the ack forwarding completed without an exception
1:c8a6171:             boolean forwarded = false;
1:c8a6171: 
1:62bdbb0:             try {
1:e53e340:                 //acquire the checkpoint lock to prevent other threads from
1:e53e340:                 //running a checkpoint while this is running
1:e53e340:                 //
1:e53e340:                 //Normally this task runs on the same executor as the checkpoint task
1:e53e340:                 //so this ack compaction runner wouldn't run at the same time as the checkpoint task.
1:e53e340:                 //
1:e53e340:                 //However, there are two cases where this isn't always true.
1:e53e340:                 //First, the checkpoint() method is public and can be called through the
1:e53e340:                 //PersistenceAdapter interface by someone at the same time this is running.
1:e53e340:                 //Second, a checkpoint is called during shutdown without using the executor.
1:e53e340:                 //
1:e53e340:                 //In the future it might be better to just remove the checkpointLock entirely
1:e53e340:                 //and only use the executor but this would need to be examined for any unintended
1:e53e340:                 //consequences
1:c8a6171:                 checkpointLock.readLock().lock();
1:e53e340: 
1:e53e340:                 try {
1:e53e340: 
1:e53e340:                     // Lock index to capture the ackMessageFileMap data
1:54e2e3b:                     indexLock.writeLock().lock();
1:e53e340: 
1:62bdbb0:                     // Map keys might not be sorted, find the earliest log file to forward acks
1:62bdbb0:                     // from and move only those, future cycles can chip away at more as needed.
1:62bdbb0:                     // We won't move files that are themselves rewritten on a previous compaction.
1:281d600:                     List<Integer> journalFileIds = new ArrayList<>(metadata.ackMessageFileMap.keySet());
1:62bdbb0:                     Collections.sort(journalFileIds);
1:62bdbb0:                     for (Integer journalFileId : journalFileIds) {
1:62bdbb0:                         DataFile current = journal.getDataFileById(journalFileId);
1:62bdbb0:                         if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
1:62bdbb0:                             journalToAdvance = journalFileId;
1:62bdbb0:                             break;
1:62bdbb0:                         }
1:e53e340:                     }
1:62bdbb0: 
1:62bdbb0:                     // Check if we found one, or if we only found the current file being written to.
1:62bdbb0:                     if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:62bdbb0:                         return;
1:62bdbb0:                     }
1:62bdbb0: 
1:62bdbb0:                     journalLogsReferenced.addAll(metadata.ackMessageFileMap.get(journalToAdvance));
1:62bdbb0: 
1:62bdbb0:                 } finally {
1:62bdbb0:                     indexLock.writeLock().unlock();
1:e53e340:                 }
1:e53e340: 
1:e53e340:                 try {
1:e53e340:                     // Background rewrite of the old acks
1:e53e340:                     forwardAllAcks(journalToAdvance, journalLogsReferenced);
1:c8a6171:                     forwarded = true;
1:e53e340:                 } catch (IOException ioe) {
1:c8a6171:                     LOG.error("Forwarding of acks failed", ioe);
1:e53e340:                     brokerService.handleIOException(ioe);
1:e53e340:                 } catch (Throwable e) {
1:c8a6171:                     LOG.error("Forwarding of acks failed", e);
1:e53e340:                     brokerService.handleIOException(IOExceptionSupport.create(e));
1:c8a6171:                 }
1:e53e340:             } finally {
1:c8a6171:                 checkpointLock.readLock().unlock();
1:db3f8b3:             }
1:c8a6171: 
1:c8a6171:             try {
1:c8a6171:                 if (forwarded) {
1:c8a6171:                     // Checkpoint with changes from the ackMessageFileMap
1:c8a6171:                     checkpointUpdate(false);
1:c8a6171:                 }
1:c8a6171:             } catch (IOException ioe) {
1:c8a6171:                 LOG.error("Checkpoint failed", ioe);
1:c8a6171:                 brokerService.handleIOException(ioe);
1:c8a6171:             } catch (Throwable e) {
1:c8a6171:                 LOG.error("Checkpoint failed", e);
1:c8a6171:                 brokerService.handleIOException(IOExceptionSupport.create(e));
1:db3f8b3:             }
1:60b0c4f:         }
1:946e62d:     }
1:e53e340: 
1:946e62d:     private void forwardAllAcks(Integer journalToRead, Set<Integer> journalLogsReferenced) throws IllegalStateException, IOException {
1:946e62d:         LOG.trace("Attempting to move all acks in journal:{} to the front.", journalToRead);
1:db3f8b3: 
1:946e62d:         DataFile forwardsFile = journal.reserveDataFile();
1:4d6cc4b:         forwardsFile.setTypeCode(COMPACTED_JOURNAL_FILE);
1:9b64e18:         LOG.trace("Reserved file for forwarded acks: {}", forwardsFile);
1:db3f8b3: 
1:281d600:         Map<Integer, Set<Integer>> updatedAckLocations = new HashMap<>();
1:db3f8b3: 
1:946e62d:         try (TargetedDataFileAppender appender = new TargetedDataFileAppender(journal, forwardsFile);) {
1:946e62d:             KahaRewrittenDataFileCommand compactionMarker = new KahaRewrittenDataFileCommand();
1:946e62d:             compactionMarker.setSourceDataFileId(journalToRead);
1:4d6cc4b:             compactionMarker.setRewriteType(forwardsFile.getTypeCode());
1:60b0c4f: 
1:946e62d:             ByteSequence payload = toByteSequence(compactionMarker);
1:15405af:             appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
1:946e62d:             LOG.trace("Marked ack rewrites file as replacing file: {}", journalToRead);
1:60b0c4f: 
1:9b64e18:             final Location limit = new Location(journalToRead + 1, 0);
1:9b64e18:             Location nextLocation = getNextLocationForAckForward(new Location(journalToRead, 0), limit);
1:9b64e18:             while (nextLocation != null) {
1:946e62d:                 JournalCommand<?> command = null;
1:946e62d:                 try {
1:946e62d:                     command = load(nextLocation);
1:946e62d:                 } catch (IOException ex) {
1:946e62d:                     LOG.trace("Error loading command during ack forward: {}", nextLocation);
1:946e62d:                 }
1:60b0c4f: 
1:946e62d:                 if (command != null && command instanceof KahaRemoveMessageCommand) {
1:946e62d:                     payload = toByteSequence(command);
1:15405af:                     Location location = appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
1:946e62d:                     updatedAckLocations.put(location.getDataFileId(), journalLogsReferenced);
1:946e62d:                 }
1:946e62d: 
1:9b64e18:                 nextLocation = getNextLocationForAckForward(nextLocation, limit);
1:946e62d:             }
1:946e62d:         }
1:946e62d: 
1:946e62d:         LOG.trace("ACKS forwarded, updates for ack locations: {}", updatedAckLocations);
1:946e62d: 
1:946e62d:         // Lock index while we update the ackMessageFileMap.
1:e53e340:         indexLock.writeLock().lock();
1:946e62d: 
1:946e62d:         // Update the ack map with the new locations of the acks
1:946e62d:         for (Entry<Integer, Set<Integer>> entry : updatedAckLocations.entrySet()) {
1:946e62d:             Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(entry.getKey());
1:946e62d:             if (referenceFileIds == null) {
1:281d600:                 referenceFileIds = new HashSet<>();
1:946e62d:                 referenceFileIds.addAll(entry.getValue());
1:946e62d:                 metadata.ackMessageFileMap.put(entry.getKey(), referenceFileIds);
1:946e62d:             } else {
1:946e62d:                 referenceFileIds.addAll(entry.getValue());
1:946e62d:             }
1:946e62d:         }
1:946e62d: 
1:946e62d:         // remove the old location data from the ack map so that the old journal log file can
1:946e62d:         // be removed on next GC.
1:946e62d:         metadata.ackMessageFileMap.remove(journalToRead);
1:946e62d: 
1:54e2e3b:         indexLock.writeLock().unlock();
1:946e62d: 
1:946e62d:         LOG.trace("ACK File Map following updates: {}", metadata.ackMessageFileMap);
1:946e62d:     }
1:946e62d: 
1:9b64e18:     private Location getNextLocationForAckForward(final Location nextLocation, final Location limit) {
1:e53e340:         //getNextLocation() can throw an IOException, we should handle it and set
1:e53e340:         //nextLocation to null and abort gracefully
1:e53e340:         //Should not happen in the normal case
1:e53e340:         Location location = null;
1:e53e340:         try {
1:9b64e18:             location = journal.getNextLocation(nextLocation, limit);
1:e53e340:         } catch (IOException e) {
1:e3b5291:             LOG.warn("Failed to load next journal location after: {}, reason: {}", nextLocation, e);
1:e53e340:             if (LOG.isDebugEnabled()) {
1:e3b5291:                 LOG.debug("Failed to load next journal location after: {}", nextLocation, e);
1:e53e340:             }
1:e53e340:         }
1:e53e340:         return location;
1:e53e340:     }
1:e53e340: 
1:89f22da:     final Runnable nullCompletionCallback = new Runnable() {
1:89f22da:         @Override
1:89f22da:         public void run() {
1:946e62d:         }
1:89f22da:     };
1:946e62d: 
1:1595378:     private Location checkpointProducerAudit() throws IOException {
1:54d56df:         if (metadata.producerSequenceIdTracker == null || metadata.producerSequenceIdTracker.modified()) {
1:a6a6a70:             ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:a6a6a70:             ObjectOutputStream oout = new ObjectOutputStream(baos);
1:a6a6a70:             oout.writeObject(metadata.producerSequenceIdTracker);
1:a6a6a70:             oout.flush();
1:a6a6a70:             oout.close();
1:89f22da:             // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false
1:89f22da:             Location location = store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), nullCompletionCallback);
1:946e62d:             try {
1:89f22da:                 location.getLatch().await();
1:ec6fa19:                 if (location.getException().get() != null) {
1:ec6fa19:                     throw location.getException().get();
1:8c3ef6c:                 }
1:89f22da:             } catch (InterruptedException e) {
1:89f22da:                 throw new InterruptedIOException(e.toString());
1:89f22da:             }
1:89f22da:             return location;
1:62c6c8f:         }
1:54d56df:         return metadata.producerSequenceIdTrackerLocation;
1:a6a6a70:     }
1:946e62d: 
1:3bf9d0c:     private Location checkpointAckMessageFileMap() throws IOException {
1:3bf9d0c:         ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:3bf9d0c:         ObjectOutputStream oout = new ObjectOutputStream(baos);
1:3bf9d0c:         oout.writeObject(metadata.ackMessageFileMap);
1:3bf9d0c:         oout.flush();
1:3bf9d0c:         oout.close();
1:3bf9d0c:         // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false
1:3bf9d0c:         Location location = store(new KahaAckMessageFileMapCommand().setAckMessageFileMap(new Buffer(baos.toByteArray())), nullCompletionCallback);
1:89f22da:         try {
1:3bf9d0c:             location.getLatch().await();
1:62c6c8f:         } catch (InterruptedException e) {
1:3bf9d0c:             throw new InterruptedIOException(e.toString());
1:38b840a:         }
1:3bf9d0c:         return location;
1:38b840a:     }
1:946e62d: 
1:3bf9d0c:     private Location checkpointSubscriptionCommand(KahaSubscriptionCommand subscription) throws IOException {
1:946e62d: 
1:3bf9d0c:         ByteSequence sequence = toByteSequence(subscription);
1:3bf9d0c:         Location location = journal.write(sequence, nullCompletionCallback) ;
1:946e62d: 
1:38b840a:         try {
1:3bf9d0c:             location.getLatch().await();
2:3bf9d0c:         } catch (InterruptedException e) {
1:3bf9d0c:             throw new InterruptedIOException(e.toString());
1:38b840a:         }
1:3bf9d0c:         return location;
1:38b840a:     }
1:946e62d: 
1:456a2ba:     public HashSet<Integer> getJournalFilesBeingReplicated() {
1:40f9146:         return journalFilesBeingReplicated;
1:3bf9d0c:     }
1:946e62d: 
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:456a2ba:     // StoredDestination related implementation methods.
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:62c6c8f: 
1:281d600:     protected final HashMap<String, StoredDestination> storedDestinations = new HashMap<>();
1:a6a6a70: 
1:456a2ba:     static class MessageKeys {
1:456a2ba:         final String messageId;
1:456a2ba:         final Location location;
1:3bf9d0c: 
1:456a2ba:         public MessageKeys(String messageId, Location location) {
1:1595378:             this.messageId=messageId;
1:1595378:             this.location=location;
1:3bf9d0c:         }
1:3bf9d0c: 
1:54d56df:         @Override
1:456a2ba:         public String toString() {
1:1595378:             return "["+messageId+","+location+"]";
1:3bf9d0c:         }
1:3bf9d0c:     }
1:3bf9d0c: 
1:246ccb8:     protected class MessageKeysMarshaller extends VariableMarshaller<MessageKeys> {
1:246ccb8:         final LocationSizeMarshaller locationSizeMarshaller = new LocationSizeMarshaller();
1:3bf9d0c: 
1:54d56df:         @Override
1:456a2ba:         public MessageKeys readPayload(DataInput dataIn) throws IOException {
1:246ccb8:             return new MessageKeys(dataIn.readUTF(), locationSizeMarshaller.readPayload(dataIn));
1:54d56df:         }
1:40f9146: 
1:54d56df:         @Override
1:456a2ba:         public void writePayload(MessageKeys object, DataOutput dataOut) throws IOException {
1:456a2ba:             dataOut.writeUTF(object.messageId);
1:246ccb8:             locationSizeMarshaller.writePayload(object.location, dataOut);
1:5325cdb:         }
1:40f9146:     }
1:40f9146: 
1:8871c67:     class LastAck {
1:8871c67:         long lastAckedSequence;
1:8871c67:         byte priority;
1:8871c67: 
1:8871c67:         public LastAck(LastAck source) {
1:8871c67:             this.lastAckedSequence = source.lastAckedSequence;
1:8871c67:             this.priority = source.priority;
1:8871c67:         }
1:8871c67: 
1:8871c67:         public LastAck() {
2:8871c67:             this.priority = MessageOrderIndex.HI;
1:8871c67:         }
1:8871c67: 
1:8871c67:         public LastAck(long ackLocation) {
1:8871c67:             this.lastAckedSequence = ackLocation;
1:aec047d:             this.priority = MessageOrderIndex.LO;
1:8871c67:         }
1:8871c67: 
1:8871c67:         public LastAck(long ackLocation, byte priority) {
1:8871c67:             this.lastAckedSequence = ackLocation;
1:8871c67:             this.priority = priority;
1:8871c67:         }
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public String toString() {
1:8871c67:             return "[" + lastAckedSequence + ":" + priority + "]";
1:8871c67:         }
1:8871c67:     }
1:8871c67: 
1:8871c67:     protected class LastAckMarshaller implements Marshaller<LastAck> {
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public void writePayload(LastAck object, DataOutput dataOut) throws IOException {
1:8871c67:             dataOut.writeLong(object.lastAckedSequence);
1:8871c67:             dataOut.writeByte(object.priority);
1:8871c67:         }
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public LastAck readPayload(DataInput dataIn) throws IOException {
1:8871c67:             LastAck lastAcked = new LastAck();
1:8871c67:             lastAcked.lastAckedSequence = dataIn.readLong();
1:90d6c20:             if (metadata.version >= 3) {
1:8871c67:                 lastAcked.priority = dataIn.readByte();
1:8871c67:             }
1:8871c67:             return lastAcked;
1:8871c67:         }
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public int getFixedSize() {
1:8871c67:             return 9;
1:8871c67:         }
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public LastAck deepCopy(LastAck source) {
1:8871c67:             return new LastAck(source);
1:8871c67:         }
1:8871c67: 
1:54d56df:         @Override
1:8871c67:         public boolean isDeepCopySupported() {
1:8871c67:             return true;
1:8871c67:         }
1:8871c67:     }
1:8871c67: 
1:cba0468:     class StoredDestination {
1:943db3c: 
1:cba0468:         MessageOrderIndex orderIndex = new MessageOrderIndex();
1:456a2ba:         BTreeIndex<Location, Long> locationIndex;
1:456a2ba:         BTreeIndex<String, Long> messageIdIndex;
1:40f9146: 
1:456a2ba:         // These bits are only set for Topics
1:456a2ba:         BTreeIndex<String, KahaSubscriptionCommand> subscriptions;
1:8871c67:         BTreeIndex<String, LastAck> subscriptionAcks;
1:cba0468:         HashMap<String, MessageOrderCursor> subscriptionCursors;
1:943db3c:         ListIndex<String, SequenceSet> ackPositions;
1:3bf9d0c:         ListIndex<String, Location> subLocations;
1:943db3c: 
1:943db3c:         // Transient data used to track which Messages are no longer needed.
1:281d600:         final TreeMap<Long, Long> messageReferences = new TreeMap<>();
1:281d600:         final HashSet<String> subscriptionCache = new LinkedHashSet<>();
1:54e2e3b: 
1:54e2e3b:         public void trackPendingAdd(Long seq) {
1:54e2e3b:             orderIndex.trackPendingAdd(seq);
1:54e2e3b:         }
1:54e2e3b: 
1:54e2e3b:         public void trackPendingAddComplete(Long seq) {
1:54e2e3b:             orderIndex.trackPendingAddComplete(seq);
1:54e2e3b:         }
1:9c2b1d2: 
1:9c2b1d2:         @Override
1:9c2b1d2:         public String toString() {
1:9c2b1d2:             return "nextSeq:" + orderIndex.nextMessageId + ",lastRet:" + orderIndex.cursor + ",pending:" + orderIndex.pendingAdditions.size();
1:9c2b1d2:         }
1:40f9146:     }
1:40f9146: 
1:e22a37a:     protected class StoredDestinationMarshaller extends VariableMarshaller<StoredDestination> {
1:40f9146: 
1:8871b0e:         final MessageKeysMarshaller messageKeysMarshaller = new MessageKeysMarshaller();
1:785b16b: 
1:54d56df:         @Override
1:d1357b4:         public StoredDestination readPayload(final DataInput dataIn) throws IOException {
1:3f0cf98:             final StoredDestination value = new StoredDestination();
1:281d600:             value.orderIndex.defaultPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:281d600:             value.locationIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:281d600:             value.messageIdIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:40f9146: 
1:456a2ba:             if (dataIn.readBoolean()) {
1:281d600:                 value.subscriptions = new BTreeIndex<>(pageFile, dataIn.readLong());
1:281d600:                 value.subscriptionAcks = new BTreeIndex<>(pageFile, dataIn.readLong());
1:d1357b4:                 if (metadata.version >= 4) {
1:281d600:                     value.ackPositions = new ListIndex<>(pageFile, dataIn.readLong());
1:3f0cf98:                 } else {
1:1595378:                     // upgrade
1:1595378:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:54d56df:                         @Override
1:1595378:                         public void execute(Transaction tx) throws IOException {
1:281d600:                             LinkedHashMap<String, SequenceSet> temp = new LinkedHashMap<>();
1:943db3c: 
1:8871c67:                             if (metadata.version >= 3) {
1:90d6c20:                                 // migrate
1:90d6c20:                                 BTreeIndex<Long, HashSet<String>> oldAckPositions =
1:281d600:                                         new BTreeIndex<>(pageFile, dataIn.readLong());
1:90d6c20:                                 oldAckPositions.setKeyMarshaller(LongMarshaller.INSTANCE);
1:90d6c20:                                 oldAckPositions.setValueMarshaller(HashSetStringMarshaller.INSTANCE);
1:90d6c20:                                 oldAckPositions.load(tx);
1:90d6c20: 
1:943db3c: 
1:90d6c20:                                 // Do the initial build of the data in memory before writing into the store
1:90d6c20:                                 // based Ack Positions List to avoid a lot of disk thrashing.
1:90d6c20:                                 Iterator<Entry<Long, HashSet<String>>> iterator = oldAckPositions.iterator(tx);
1:734fb7d:                                 while (iterator.hasNext()) {
1:90d6c20:                                     Entry<Long, HashSet<String>> entry = iterator.next();
1:90d6c20: 
1:90d6c20:                                     for(String subKey : entry.getValue()) {
1:90d6c20:                                         SequenceSet pendingAcks = temp.get(subKey);
1:90d6c20:                                         if (pendingAcks == null) {
1:90d6c20:                                             pendingAcks = new SequenceSet();
1:90d6c20:                                             temp.put(subKey, pendingAcks);
1:90d6c20:                                         }
1:90d6c20: 
1:90d6c20:                                         pendingAcks.add(entry.getKey());
1:8871c67:                                     }
1:8871c67:                                 }
1:943db3c:                             }
1:943db3c:                             // Now move the pending messages to ack data into the store backed
1:943db3c:                             // structure.
1:281d600:                             value.ackPositions = new ListIndex<>(pageFile, tx.allocate());
1:3bf9d0c:                             value.ackPositions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:3bf9d0c:                             value.ackPositions.setValueMarshaller(SequenceSet.Marshaller.INSTANCE);
1:3f0cf98:                             value.ackPositions.load(tx);
1:943db3c:                             for(String subscriptionKey : temp.keySet()) {
1:943db3c:                                 value.ackPositions.put(tx, subscriptionKey, temp.get(subscriptionKey));
1:3f0cf98:                             }
1:8871c67: 
1:3f0cf98:                         }
1:3f0cf98:                     });
1:943db3c:                 }
1:943db3c: 
1:3bf9d0c:                 if (metadata.version >= 5) {
1:281d600:                     value.subLocations = new ListIndex<>(pageFile, dataIn.readLong());
1:3bf9d0c:                 } else {
1:3f0cf98:                     // upgrade
1:3f0cf98:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:3bf9d0c:                         @Override
1:3f0cf98:                         public void execute(Transaction tx) throws IOException {
1:281d600:                             value.subLocations = new ListIndex<>(pageFile, tx.allocate());
1:3bf9d0c:                             value.subLocations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:3bf9d0c:                             value.subLocations.setValueMarshaller(LocationMarshaller.INSTANCE);
1:3bf9d0c:                             value.subLocations.load(tx);
1:3bf9d0c:                         }
1:3f0cf98:                     });
1:3bf9d0c:                 }
1:943db3c:             }
1:cba0468:             if (metadata.version >= 2) {
1:281d600:                 value.orderIndex.lowPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:281d600:                 value.orderIndex.highPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:3f0cf98:             } else {
1:3f0cf98:                 // upgrade
1:3f0cf98:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:3bf9d0c:                     @Override
1:3f0cf98:                     public void execute(Transaction tx) throws IOException {
1:281d600:                         value.orderIndex.lowPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:1595378:                         value.orderIndex.lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
1:785b16b:                         value.orderIndex.lowPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:1595378:                         value.orderIndex.lowPriorityIndex.load(tx);
1:3f0cf98: 
1:281d600:                         value.orderIndex.highPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:1595378:                         value.orderIndex.highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
1:785b16b:                         value.orderIndex.highPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:1595378:                         value.orderIndex.highPriorityIndex.load(tx);
1:1595378:                     }
1:1595378:                 });
1:3f0cf98:             }
1:3f0cf98: 
1:456a2ba:             return value;
1:3bf9d0c:         }
1:943db3c: 
1:54d56df:         @Override
1:456a2ba:         public void writePayload(StoredDestination value, DataOutput dataOut) throws IOException {
1:cba0468:             dataOut.writeLong(value.orderIndex.defaultPriorityIndex.getPageId());
1:456a2ba:             dataOut.writeLong(value.locationIndex.getPageId());
1:456a2ba:             dataOut.writeLong(value.messageIdIndex.getPageId());
1:456a2ba:             if (value.subscriptions != null) {
1:456a2ba:                 dataOut.writeBoolean(true);
1:456a2ba:                 dataOut.writeLong(value.subscriptions.getPageId());
1:456a2ba:                 dataOut.writeLong(value.subscriptionAcks.getPageId());
1:943db3c:                 dataOut.writeLong(value.ackPositions.getHeadPageId());
1:3bf9d0c:                 dataOut.writeLong(value.subLocations.getHeadPageId());
1:c9500f4:             } else {
1:456a2ba:                 dataOut.writeBoolean(false);
1:943db3c:             }
1:3f0cf98:             dataOut.writeLong(value.orderIndex.lowPriorityIndex.getPageId());
1:3f0cf98:             dataOut.writeLong(value.orderIndex.highPriorityIndex.getPageId());
1:fbc5eb5:         }
1:fbc5eb5:     }
1:943db3c: 
1:e22a37a:     static class KahaSubscriptionCommandMarshaller extends VariableMarshaller<KahaSubscriptionCommand> {
1:456a2ba:         final static KahaSubscriptionCommandMarshaller INSTANCE = new KahaSubscriptionCommandMarshaller();
1:40f9146: 
1:54d56df:         @Override
1:456a2ba:         public KahaSubscriptionCommand readPayload(DataInput dataIn) throws IOException {
1:456a2ba:             KahaSubscriptionCommand rc = new KahaSubscriptionCommand();
1:1595378:             rc.mergeFramed((InputStream)dataIn);
1:a6c51a4:             return rc;
1:fbc5eb5:         }
1:40f9146: 
1:54d56df:         @Override
1:456a2ba:         public void writePayload(KahaSubscriptionCommand object, DataOutput dataOut) throws IOException {
1:1595378:             object.writeFramed((OutputStream)dataOut);
1:fbc5eb5:         }
1:fbc5eb5:     }
1:40f9146: 
1:456a2ba:     protected StoredDestination getStoredDestination(KahaDestination destination, Transaction tx) throws IOException {
1:456a2ba:         String key = key(destination);
1:456a2ba:         StoredDestination rc = storedDestinations.get(key);
1:456a2ba:         if (rc == null) {
1:456a2ba:             boolean topic = destination.getType() == KahaDestination.DestinationType.TOPIC || destination.getType() == KahaDestination.DestinationType.TEMP_TOPIC;
1:456a2ba:             rc = loadStoredDestination(tx, key, topic);
1:456a2ba:             // Cache it. We may want to remove/unload destinations from the
1:456a2ba:             // cache that are not used for a while
1:456a2ba:             // to reduce memory usage.
1:456a2ba:             storedDestinations.put(key, rc);
1:fbc5eb5:         }
1:456a2ba:         return rc;
1:fbc5eb5:     }
1:40f9146: 
1:6f7e3fc:     protected StoredDestination getExistingStoredDestination(KahaDestination destination, Transaction tx) throws IOException {
1:6f7e3fc:         String key = key(destination);
1:6f7e3fc:         StoredDestination rc = storedDestinations.get(key);
1:6f7e3fc:         if (rc == null && metadata.destinations.containsKey(tx, key)) {
1:6f7e3fc:             rc = getStoredDestination(destination, tx);
1:6f7e3fc:         }
1:6f7e3fc:         return rc;
1:6f7e3fc:     }
1:6f7e3fc: 
1:456a2ba:     /**
1:456a2ba:      * @param tx
1:456a2ba:      * @param key
1:456a2ba:      * @param topic
1:785b16b:      * @return
6:456a2ba:      * @throws IOException
1:456a2ba:      */
1:456a2ba:     private StoredDestination loadStoredDestination(Transaction tx, String key, boolean topic) throws IOException {
1:456a2ba:         // Try to load the existing indexes..
1:456a2ba:         StoredDestination rc = metadata.destinations.get(tx, key);
1:456a2ba:         if (rc == null) {
1:456a2ba:             // Brand new destination.. allocate indexes for it.
1:456a2ba:             rc = new StoredDestination();
1:cba0468:             rc.orderIndex.allocate(tx);
1:281d600:             rc.locationIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:281d600:             rc.messageIdIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:40f9146: 
1:456a2ba:             if (topic) {
1:281d600:                 rc.subscriptions = new BTreeIndex<>(pageFile, tx.allocate());
1:281d600:                 rc.subscriptionAcks = new BTreeIndex<>(pageFile, tx.allocate());
1:281d600:                 rc.ackPositions = new ListIndex<>(pageFile, tx.allocate());
1:281d600:                 rc.subLocations = new ListIndex<>(pageFile, tx.allocate());
1:d761e80:             }
1:456a2ba:             metadata.destinations.put(tx, key, rc);
1:d761e80:         }
1:40f9146: 
1:456a2ba:         // Configure the marshalers and load.
1:456a2ba:         rc.orderIndex.load(tx);
1:40f9146: 
1:456a2ba:         // Figure out the next key using the last entry in the destination.
1:cba0468:         rc.orderIndex.configureLast(tx);
1:40f9146: 
1:785b16b:         rc.locationIndex.setKeyMarshaller(new LocationSizeMarshaller());
1:456a2ba:         rc.locationIndex.setValueMarshaller(LongMarshaller.INSTANCE);
1:456a2ba:         rc.locationIndex.load(tx);
1:40f9146: 
1:456a2ba:         rc.messageIdIndex.setKeyMarshaller(StringMarshaller.INSTANCE);
1:456a2ba:         rc.messageIdIndex.setValueMarshaller(LongMarshaller.INSTANCE);
1:456a2ba:         rc.messageIdIndex.load(tx);
1:40f9146: 
1:8871b0e:         //go through an upgrade old index if older than version 6
1:8871b0e:         if (metadata.version < 6) {
1:8871b0e:             for (Iterator<Entry<Location, Long>> iterator = rc.locationIndex.iterator(tx); iterator.hasNext(); ) {
1:734fb7d:                 Entry<Location, Long> entry = iterator.next();
1:8871b0e:                 // modify so it is upgraded
1:8871b0e:                 rc.locationIndex.put(tx, entry.getKey(), entry.getValue());
1:8871b0e:             }
1:246ccb8:             //upgrade the order index
1:246ccb8:             for (Iterator<Entry<Long, MessageKeys>> iterator = rc.orderIndex.iterator(tx); iterator.hasNext(); ) {
1:25ff569:                 Entry<Long, MessageKeys> entry = iterator.next();
1:246ccb8:                 //call get so that the last priority is updated
1:246ccb8:                 rc.orderIndex.get(tx, entry.getKey());
1:246ccb8:                 rc.orderIndex.put(tx, rc.orderIndex.lastGetPriority(), entry.getKey(), entry.getValue());
1:246ccb8:             }
1:8871b0e:         }
1:8871b0e: 
1:456a2ba:         // If it was a topic...
1:456a2ba:         if (topic) {
1:40f9146: 
1:456a2ba:             rc.subscriptions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:456a2ba:             rc.subscriptions.setValueMarshaller(KahaSubscriptionCommandMarshaller.INSTANCE);
1:456a2ba:             rc.subscriptions.load(tx);
1:40f9146: 
1:456a2ba:             rc.subscriptionAcks.setKeyMarshaller(StringMarshaller.INSTANCE);
1:8871c67:             rc.subscriptionAcks.setValueMarshaller(new LastAckMarshaller());
1:456a2ba:             rc.subscriptionAcks.load(tx);
1:40f9146: 
1:943db3c:             rc.ackPositions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:943db3c:             rc.ackPositions.setValueMarshaller(SequenceSet.Marshaller.INSTANCE);
1:3f0cf98:             rc.ackPositions.load(tx);
1:3f0cf98: 
1:3bf9d0c:             rc.subLocations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:3bf9d0c:             rc.subLocations.setValueMarshaller(LocationMarshaller.INSTANCE);
1:3bf9d0c:             rc.subLocations.load(tx);
1:3bf9d0c: 
1:281d600:             rc.subscriptionCursors = new HashMap<>();
1:40f9146: 
1:3f0cf98:             if (metadata.version < 3) {
1:8871c67: 
1:8871c67:                 // on upgrade need to fill ackLocation with available messages past last ack
1:8871c67:                 for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
1:8871c67:                     Entry<String, LastAck> entry = iterator.next();
1:8871c67:                     for (Iterator<Entry<Long, MessageKeys>> orderIterator =
1:1595378:                             rc.orderIndex.iterator(tx, new MessageOrderCursor(entry.getValue().lastAckedSequence)); orderIterator.hasNext(); ) {
1:8871c67:                         Long sequence = orderIterator.next().getKey();
1:8871c67:                         addAckLocation(tx, rc, sequence, entry.getKey());
1:8871c67:                     }
1:8871c67:                     // modify so it is upgraded
1:8871c67:                     rc.subscriptionAcks.put(tx, entry.getKey(), entry.getValue());
1:3f0cf98:                 }
1:d761e80:             }
1:40f9146: 
1:943db3c:             // Configure the message references index
1:943db3c:             Iterator<Entry<String, SequenceSet>> subscriptions = rc.ackPositions.iterator(tx);
1:943db3c:             while (subscriptions.hasNext()) {
1:943db3c:                 Entry<String, SequenceSet> subscription = subscriptions.next();
1:34af42f:                 SequenceSet pendingAcks = subscription.getValue();
1:34af42f:                 if (pendingAcks != null && !pendingAcks.isEmpty()) {
1:34af42f:                     Long lastPendingAck = pendingAcks.getTail().getLast();
1:455f1ca:                     for (Long sequenceId : pendingAcks) {
1:943db3c:                         Long current = rc.messageReferences.get(sequenceId);
1:943db3c:                         if (current == null) {
1:943db3c:                             current = new Long(0);
1:943db3c:                         }
1:34af42f: 
1:34af42f:                         // We always add a trailing empty entry for the next position to start from
1:34af42f:                         // so we need to ensure we don't count that as a message reference on reload.
1:34af42f:                         if (!sequenceId.equals(lastPendingAck)) {
1:34af42f:                             current = current.longValue() + 1;
1:455f1ca:                         } else {
1:455f1ca:                             current = Long.valueOf(0L);
1:34af42f:                         }
1:34af42f: 
1:34af42f:                         rc.messageReferences.put(sequenceId, current);
1:943db3c:                     }
1:943db3c:                 }
1:943db3c:             }
1:943db3c: 
1:943db3c:             // Configure the subscription cache
1:943db3c:             for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
1:8871c67:                 Entry<String, LastAck> entry = iterator.next();
1:943db3c:                 rc.subscriptionCache.add(entry.getKey());
1:943db3c:             }
1:943db3c: 
1:cba0468:             if (rc.orderIndex.nextMessageId == 0) {
1:3271401:                 // check for existing durable sub all acked out - pull next seq from acks as messages are gone
1:8871c67:                 if (!rc.subscriptionAcks.isEmpty(tx)) {
1:1595378:                     for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext();) {
1:8871c67:                         Entry<String, LastAck> entry = iterator.next();
1:8871c67:                         rc.orderIndex.nextMessageId =
1:1595378:                                 Math.max(rc.orderIndex.nextMessageId, entry.getValue().lastAckedSequence +1);
1:3271401:                     }
1:3271401:                 }
1:2d121f4:             } else {
1:2d121f4:                 // update based on ackPositions for unmatched, last entry is always the next
1:943db3c:                 if (!rc.messageReferences.isEmpty()) {
1:943db3c:                     Long nextMessageId = (Long) rc.messageReferences.keySet().toArray()[rc.messageReferences.size() - 1];
1:2d121f4:                     rc.orderIndex.nextMessageId =
1:943db3c:                             Math.max(rc.orderIndex.nextMessageId, nextMessageId);
1:2d121f4:                 }
1:3271401:             }
1:d761e80:         }
1:4c51977: 
1:943db3c:         if (metadata.version < VERSION) {
1:3f0cf98:             // store again after upgrade
1:3f0cf98:             metadata.destinations.put(tx, key, rc);
1:3f0cf98:         }
1:456a2ba:         return rc;
1:40f9146:     }
1:4c51977: 
1:456a2ba:     /**
1:785b16b:      * Clear the counter for the destination, if one exists.
1:785b16b:      *
1:8871b0e:      * @param kahaDestination
1:785b16b:      */
1:785b16b:     protected void clearStoreStats(KahaDestination kahaDestination) {
1:cf3d419:         String key = key(kahaDestination);
1:cf3d419:         MessageStoreStatistics storeStats = getStoreStats(key);
1:cf3d419:         MessageStoreSubscriptionStatistics subStats = getSubStats(key);
1:785b16b:         if (storeStats != null) {
1:785b16b:             storeStats.reset();
1:785b16b:         }
1:cf3d419:         if (subStats != null) {
1:cf3d419:             subStats.reset();
1:cf3d419:         }
1:785b16b:     }
1:785b16b: 
1:785b16b:     /**
1:785b16b:      * Update MessageStoreStatistics
1:785b16b:      *
3:785b16b:      * @param kahaDestination
1:785b16b:      * @param size
1:785b16b:      */
1:785b16b:     protected void incrementAndAddSizeToStoreStat(KahaDestination kahaDestination, long size) {
1:785b16b:         incrementAndAddSizeToStoreStat(key(kahaDestination), size);
1:785b16b:     }
1:785b16b: 
1:785b16b:     protected void incrementAndAddSizeToStoreStat(String kahaDestKey, long size) {
1:785b16b:         MessageStoreStatistics storeStats = getStoreStats(kahaDestKey);
1:785b16b:         if (storeStats != null) {
1:785b16b:             storeStats.getMessageCount().increment();
1:785b16b:             if (size > 0) {
1:785b16b:                 storeStats.getMessageSize().addSize(size);
1:785b16b:             }
1:785b16b:         }
1:785b16b:     }
1:785b16b: 
1:785b16b:     protected void decrementAndSubSizeToStoreStat(KahaDestination kahaDestination, long size) {
1:785b16b:         decrementAndSubSizeToStoreStat(key(kahaDestination), size);
1:785b16b:     }
1:785b16b: 
1:785b16b:     protected void decrementAndSubSizeToStoreStat(String kahaDestKey, long size) {
1:785b16b:         MessageStoreStatistics storeStats = getStoreStats(kahaDestKey);
1:785b16b:         if (storeStats != null) {
1:785b16b:             storeStats.getMessageCount().decrement();
1:785b16b:             if (size > 0) {
1:785b16b:                 storeStats.getMessageSize().addSize(-size);
1:785b16b:             }
1:785b16b:         }
1:785b16b:     }
1:785b16b: 
1:cf3d419:     protected void incrementAndAddSizeToStoreStat(KahaDestination kahaDestination, String subKey, long size) {
1:cf3d419:         incrementAndAddSizeToStoreStat(key(kahaDestination), subKey, size);
1:cf3d419:     }
1:cf3d419: 
1:cf3d419:     protected void incrementAndAddSizeToStoreStat(String kahaDestKey, String subKey, long size) {
1:cf3d419:         if (enableSubscriptionStatistics) {
1:cf3d419:             MessageStoreSubscriptionStatistics subStats = getSubStats(kahaDestKey);
1:cf3d419:             if (subStats != null && subKey != null) {
1:cf3d419:                 subStats.getMessageCount(subKey).increment();
1:cf3d419:                 if (size > 0) {
1:cf3d419:                     subStats.getMessageSize(subKey).addSize(size);
1:cf3d419:                 }
1:cf3d419:             }
1:cf3d419:         }
1:cf3d419:     }
1:cf3d419: 
1:cf3d419: 
1:cf3d419:     protected void decrementAndSubSizeToStoreStat(String kahaDestKey, String subKey, long size) {
1:cf3d419:         if (enableSubscriptionStatistics) {
1:cf3d419:             MessageStoreSubscriptionStatistics subStats = getSubStats(kahaDestKey);
1:cf3d419:             if (subStats != null && subKey != null) {
1:cf3d419:                 subStats.getMessageCount(subKey).decrement();
1:cf3d419:                 if (size > 0) {
1:cf3d419:                     subStats.getMessageSize(subKey).addSize(-size);
1:cf3d419:                 }
1:cf3d419:             }
1:cf3d419:         }
1:cf3d419:     }
1:cf3d419: 
1:cf3d419:     protected void decrementAndSubSizeToStoreStat(KahaDestination kahaDestination, String subKey, long size) {
1:cf3d419:         decrementAndSubSizeToStoreStat(key(kahaDestination), subKey, size);
1:cf3d419:     }
1:cf3d419: 
1:785b16b:     /**
1:cf3d419:      * This is a map to cache MessageStores for a specific
1:785b16b:      * KahaDestination key
1:785b16b:      */
1:b52796f:     protected final ConcurrentMap<String, MessageStore> storeCache =
1:281d600:             new ConcurrentHashMap<>();
1:785b16b: 
1:785b16b:     /**
1:8871b0e:      * Locate the storeMessageSize counter for this KahaDestination
1:8871b0e:      */
1:8871b0e:     protected MessageStoreStatistics getStoreStats(String kahaDestKey) {
1:8871b0e:         MessageStoreStatistics storeStats = null;
1:8871b0e:         try {
1:8871b0e:             MessageStore messageStore = storeCache.get(kahaDestKey);
1:8871b0e:             if (messageStore != null) {
1:8871b0e:                 storeStats = messageStore.getMessageStoreStatistics();
1:8871b0e:             }
1:8871b0e:         } catch (Exception e1) {
1:8871b0e:              LOG.error("Getting size counter of destination failed", e1);
1:8871b0e:         }
1:785b16b: 
1:8871b0e:         return storeStats;
1:8871b0e:     }
1:785b16b: 
1:cf3d419:     protected MessageStoreSubscriptionStatistics getSubStats(String kahaDestKey) {
1:cf3d419:         MessageStoreSubscriptionStatistics subStats = null;
1:cf3d419:         try {
1:cf3d419:             MessageStore messageStore = storeCache.get(kahaDestKey);
1:cf3d419:             if (messageStore instanceof TopicMessageStore) {
1:cf3d419:                 subStats = ((TopicMessageStore)messageStore).getMessageStoreSubStatistics();
1:cf3d419:             }
1:cf3d419:         } catch (Exception e1) {
1:cf3d419:              LOG.error("Getting size counter of destination failed", e1);
1:cf3d419:         }
1:cf3d419: 
1:cf3d419:         return subStats;
1:cf3d419:     }
1:cf3d419: 
1:785b16b:     /**
1:785b16b:      * Determine whether this Destination matches the DestinationType
1:785b16b:      *
1:785b16b:      * @param destination
1:785b16b:      * @param type
1:785b16b:      * @return
1:785b16b:      */
1:785b16b:     protected boolean matchType(Destination destination,
1:785b16b:             KahaDestination.DestinationType type) {
1:785b16b:         if (destination instanceof Topic
1:785b16b:                 && type.equals(KahaDestination.DestinationType.TOPIC)) {
1:785b16b:             return true;
1:785b16b:         } else if (destination instanceof Queue
1:785b16b:                 && type.equals(KahaDestination.DestinationType.QUEUE)) {
1:785b16b:             return true;
1:785b16b:         }
1:785b16b:         return false;
1:785b16b:     }
1:785b16b: 
1:785b16b:     class LocationSizeMarshaller implements Marshaller<Location> {
1:785b16b: 
1:785b16b:         public LocationSizeMarshaller() {
1:785b16b: 
1:785b16b:         }
1:785b16b: 
1:40f9146:         @Override
1:785b16b:         public Location readPayload(DataInput dataIn) throws IOException {
1:785b16b:             Location rc = new Location();
1:785b16b:             rc.setDataFileId(dataIn.readInt());
1:785b16b:             rc.setOffset(dataIn.readInt());
1:785b16b:             if (metadata.version >= 6) {
1:785b16b:                 rc.setSize(dataIn.readInt());
1:785b16b:             }
1:785b16b:             return rc;
1:785b16b:         }
1:785b16b: 
1:4c51977:         @Override
1:785b16b:         public void writePayload(Location object, DataOutput dataOut)
1:785b16b:                 throws IOException {
1:785b16b:             dataOut.writeInt(object.getDataFileId());
1:785b16b:             dataOut.writeInt(object.getOffset());
1:785b16b:             dataOut.writeInt(object.getSize());
1:785b16b:         }
1:785b16b: 
1:8871b0e:         @Override
1:785b16b:         public int getFixedSize() {
1:785b16b:             return 12;
1:785b16b:         }
1:785b16b: 
1:8871b0e:         @Override
1:785b16b:         public Location deepCopy(Location source) {
1:785b16b:             return new Location(source);
1:785b16b:         }
1:785b16b: 
1:8871b0e:         @Override
1:785b16b:         public boolean isDeepCopySupported() {
1:785b16b:             return true;
1:785b16b:         }
1:785b16b:     }
1:785b16b: 
1:3f0cf98:     private void addAckLocation(Transaction tx, StoredDestination sd, Long messageSequence, String subscriptionKey) throws IOException {
2:943db3c:         SequenceSet sequences = sd.ackPositions.get(tx, subscriptionKey);
2:943db3c:         if (sequences == null) {
2:943db3c:             sequences = new SequenceSet();
3:943db3c:             sequences.add(messageSequence);
1:e23afb3:             sd.ackPositions.add(tx, subscriptionKey, sequences);
1:943db3c:         } else {
1:943db3c:             sequences.add(messageSequence);
1:e23afb3:             sd.ackPositions.put(tx, subscriptionKey, sequences);
1:785b16b:         }
1:5325cdb: 
2:943db3c:         Long count = sd.messageReferences.get(messageSequence);
2:943db3c:         if (count == null) {
2:943db3c:             count = Long.valueOf(0L);
1:943db3c:         }
3:943db3c:         count = count.longValue() + 1;
2:943db3c:         sd.messageReferences.put(messageSequence, count);
1:e22a37a:     }
1:943db3c: 
1:8871c67:     // new sub is interested in potentially all existing messages
1:eaac0d2:     private void addAckLocationForRetroactiveSub(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:eaac0d2:         SequenceSet allOutstanding = new SequenceSet();
1:eaac0d2:         Iterator<Map.Entry<String, SequenceSet>> iterator = sd.ackPositions.iterator(tx);
1:90d6c20:         while (iterator.hasNext()) {
1:eaac0d2:             SequenceSet set = iterator.next().getValue();
1:eaac0d2:             for (Long entry : set) {
1:eaac0d2:                 allOutstanding.add(entry);
1:eaac0d2:             }
1:943db3c:         }
1:eaac0d2:         sd.ackPositions.put(tx, subscriptionKey, allOutstanding);
1:943db3c: 
1:eaac0d2:         for (Long ackPosition : allOutstanding) {
1:eaac0d2:             Long count = sd.messageReferences.get(ackPosition);
1:455f1ca: 
1:455f1ca:             // There might not be a reference if the ackLocation was the last
1:455f1ca:             // one which is a placeholder for the next incoming message and
1:455f1ca:             // no value was added to the message references table.
1:455f1ca:             if (count != null) {
1:455f1ca:                 count = count.longValue() + 1;
1:455f1ca:                 sd.messageReferences.put(ackPosition, count);
1:455f1ca:             }
1:943db3c:         }
1:d761e80:     }
1:943db3c: 
1:8871c67:     // on a new message add, all existing subs are interested in this message
1:cf3d419:     private void addAckLocationForNewMessage(Transaction tx, KahaDestination kahaDest,
1:cf3d419:             StoredDestination sd, Long messageSequence) throws IOException {
1:943db3c:         for(String subscriptionKey : sd.subscriptionCache) {
1:c6ec76e:             SequenceSet sequences = sd.ackPositions.get(tx, subscriptionKey);
1:943db3c:             if (sequences == null) {
1:943db3c:                 sequences = new SequenceSet();
1:943db3c:                 sequences.add(new Sequence(messageSequence, messageSequence + 1));
1:e23afb3:                 sd.ackPositions.add(tx, subscriptionKey, sequences);
1:943db3c:             } else {
1:943db3c:                 sequences.add(new Sequence(messageSequence, messageSequence + 1));
1:e23afb3:                 sd.ackPositions.put(tx, subscriptionKey, sequences);
1:8871c67:             }
1:8871c67: 
1:cf3d419:             MessageKeys key = sd.orderIndex.get(tx, messageSequence);
1:cf3d419:             incrementAndAddSizeToStoreStat(kahaDest, subscriptionKey,
1:cf3d419:                     key.location.getSize());
1:cf3d419: 
1:943db3c:             Long count = sd.messageReferences.get(messageSequence);
1:943db3c:             if (count == null) {
1:943db3c:                 count = Long.valueOf(0L);
1:8871c67:             }
1:eaac0d2:             count = count.longValue() + 1;
1:943db3c:             sd.messageReferences.put(messageSequence, count);
1:455f1ca:             sd.messageReferences.put(messageSequence + 1, Long.valueOf(0L));
1:943db3c:         }
1:943db3c:     }
1:943db3c: 
1:785b16b:     private void removeAckLocationsForSub(KahaSubscriptionCommand command,
1:785b16b:             Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:1c1aa17:         if (!sd.ackPositions.isEmpty(tx)) {
1:943db3c:             SequenceSet sequences = sd.ackPositions.remove(tx, subscriptionKey);
1:943db3c:             if (sequences == null || sequences.isEmpty()) {
1:e53e340:                 return;
1:8871c67:             }
1:8871c67: 
1:281d600:             ArrayList<Long> unreferenced = new ArrayList<>();
1:943db3c: 
1:943db3c:             for(Long sequenceId : sequences) {
1:c6ec76e:                 Long references = sd.messageReferences.get(sequenceId);
1:c6ec76e:                 if (references != null) {
1:c6ec76e:                     references = references.longValue() - 1;
1:943db3c: 
1:c6ec76e:                     if (references.longValue() > 0) {
1:c6ec76e:                         sd.messageReferences.put(sequenceId, references);
1:c6ec76e:                     } else {
1:c6ec76e:                         sd.messageReferences.remove(sequenceId);
1:c6ec76e:                         unreferenced.add(sequenceId);
1:8871c67:                     }
1:8871c67:                 }
1:c6ec76e:             }
1:943db3c: 
1:943db3c:             for(Long sequenceId : unreferenced) {
1:8871c67:                 // Find all the entries that need to get deleted.
1:281d600:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<>();
1:8871c67:                 sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
1:6ddbba4: 
1:8871c67:                 // Do the actual deletes.
1:8871c67:                 for (Entry<Long, MessageKeys> entry : deletes) {
1:8871c67:                     sd.locationIndex.remove(tx, entry.getValue().location);
1:8871c67:                     sd.messageIdIndex.remove(tx, entry.getValue().messageId);
1:8871c67:                     sd.orderIndex.remove(tx, entry.getKey());
1:785b16b:                     decrementAndSubSizeToStoreStat(command.getDestination(), entry.getValue().location.getSize());
1:6ddbba4:                 }
1:943db3c:             }
1:943db3c:         }
1:d761e80:     }
1:4c51977: 
1:456a2ba:     /**
1:456a2ba:      * @param tx
2:456a2ba:      * @param sd
2:456a2ba:      * @param subscriptionKey
1:9c9b856:      * @param messageSequence
1:456a2ba:      * @throws IOException
1:456a2ba:      */
1:785b16b:     private void removeAckLocation(KahaRemoveMessageCommand command,
1:785b16b:             Transaction tx, StoredDestination sd, String subscriptionKey,
1:785b16b:             Long messageSequence) throws IOException {
1:456a2ba:         // Remove the sub from the previous location set..
1:e23afb3:         if (messageSequence != null) {
1:943db3c:             SequenceSet range = sd.ackPositions.get(tx, subscriptionKey);
1:943db3c:             if (range != null && !range.isEmpty()) {
1:e23afb3:                 range.remove(messageSequence);
1:943db3c:                 if (!range.isEmpty()) {
1:943db3c:                     sd.ackPositions.put(tx, subscriptionKey, range);
1:1c1aa17:                 } else {
1:943db3c:                     sd.ackPositions.remove(tx, subscriptionKey);
1:943db3c:                 }
1:943db3c: 
1:cf3d419:                 MessageKeys key = sd.orderIndex.get(tx, messageSequence);
1:cf3d419:                 decrementAndSubSizeToStoreStat(command.getDestination(), subscriptionKey,
1:cf3d419:                         key.location.getSize());
1:cf3d419: 
1:943db3c:                 // Check if the message is reference by any other subscription.
1:e23afb3:                 Long count = sd.messageReferences.get(messageSequence);
1:455f1ca:                 if (count != null) {
1:455f1ca:                     long references = count.longValue() - 1;
1:943db3c:                     if (references > 0) {
1:e23afb3:                         sd.messageReferences.put(messageSequence, Long.valueOf(references));
1:db3f8b3:                         return;
1:943db3c:                     } else {
1:e23afb3:                         sd.messageReferences.remove(messageSequence);
1:943db3c:                     }
1:943db3c:                 }
1:943db3c: 
1:6ddbba4:                 // Find all the entries that need to get deleted.
1:281d600:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<>();
1:e23afb3:                 sd.orderIndex.getDeleteList(tx, deletes, messageSequence);
1:943db3c: 
1:6ddbba4:                 // Do the actual deletes.
1:6ddbba4:                 for (Entry<Long, MessageKeys> entry : deletes) {
1:6ddbba4:                     sd.locationIndex.remove(tx, entry.getValue().location);
1:514ef7d:                     sd.messageIdIndex.remove(tx, entry.getValue().messageId);
1:514ef7d:                     sd.orderIndex.remove(tx, entry.getKey());
1:785b16b:                     decrementAndSubSizeToStoreStat(command.getDestination(), entry.getValue().location.getSize());
1:943db3c:                 }
1:d761e80:             }
1:51e82d5:         }
1:51e82d5:     }
1:943db3c: 
1:943db3c:     public LastAck getLastAck(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:943db3c:         return sd.subscriptionAcks.get(tx, subscriptionKey);
1:943db3c:     }
1:943db3c: 
1:2731f04:     protected long getStoredMessageCount(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:2731f04:         if (sd.ackPositions != null) {
1:2731f04:             SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
1:2731f04:             if (messageSequences != null) {
1:2731f04:                 long result = messageSequences.rangeSize();
1:2731f04:                 // if there's anything in the range the last value is always the nextMessage marker, so remove 1.
1:2731f04:                 return result > 0 ? result - 1 : 0;
1:2731f04:             }
1:734fb7d:         }
1:25ff569: 
1:943db3c:         return 0;
1:734fb7d:     }
1:734fb7d: 
1:2731f04:     protected long getStoredMessageSize(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:734fb7d:         long locationSize = 0;
1:734fb7d: 
1:2731f04:         if (sd.ackPositions != null) {
1:2731f04:             //grab the messages attached to this subscription
1:2731f04:             SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
1:2731f04: 
1:2731f04:             if (messageSequences != null) {
1:2731f04:                 Sequence head = messageSequences.getHead();
1:2731f04:                 if (head != null) {
1:2731f04:                     //get an iterator over the order index starting at the first unacked message
1:2731f04:                     //and go over each message to add up the size
1:2731f04:                     Iterator<Entry<Long, MessageKeys>> iterator = sd.orderIndex.iterator(tx,
1:2731f04:                             new MessageOrderCursor(head.getFirst()));
1:2731f04: 
1:2731f04:                     while (iterator.hasNext()) {
1:2731f04:                         Entry<Long, MessageKeys> entry = iterator.next();
1:2731f04:                         locationSize += entry.getValue().location.getSize();
1:2731f04:                     }
1:734fb7d:                 }
1:734fb7d:             }
1:734fb7d:         }
1:734fb7d: 
1:734fb7d:         return locationSize;
1:734fb7d:     }
1:25ff569: 
1:9c2b1d2:     protected String key(KahaDestination destination) {
1:456a2ba:         return destination.getType().getNumber() + ":" + destination.getName();
1:943db3c:     }
1:943db3c: 
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:456a2ba:     // Transaction related implementation methods.
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:c273cab:     @SuppressWarnings("rawtypes")
1:281d600:     private final LinkedHashMap<TransactionId, List<Operation>> inflightTransactions = new LinkedHashMap<>();
1:c273cab:     @SuppressWarnings("rawtypes")
1:281d600:     protected final LinkedHashMap<TransactionId, List<Operation>> preparedTransactions = new LinkedHashMap<>();
1:943db3c: 
2:c273cab:     @SuppressWarnings("rawtypes")
1:54e2e3b:     private List<Operation> getInflightTx(KahaTransactionInfo info) {
1:1595378:         TransactionId key = TransactionIdConversion.convert(info);
1:b1d7a78:         List<Operation> tx;
1:b1d7a78:         synchronized (inflightTransactions) {
1:b1d7a78:             tx = inflightTransactions.get(key);
1:b1d7a78:             if (tx == null) {
1:b1d7a78:                 tx = Collections.synchronizedList(new ArrayList<Operation>());
1:b1d7a78:                 inflightTransactions.put(key, tx);
1:b1d7a78:             }
1:943db3c:         }
1:456a2ba:         return tx;
1:51e82d5:     }
1:4c51977: 
1:943db3c:     @SuppressWarnings("unused")
1:456a2ba:     private TransactionId key(KahaTransactionInfo transactionInfo) {
1:1595378:         return TransactionIdConversion.convert(transactionInfo);
1:51e82d5:     }
1:4c51977: 
1:2030097:     abstract class Operation <T extends JournalCommand<T>> {
1:2030097:         final T command;
1:456a2ba:         final Location location;
1:bdd9e2a: 
1:2030097:         public Operation(T command, Location location) {
1:2030097:             this.command = command;
1:456a2ba:             this.location = location;
1:51e82d5:         }
1:bdd9e2a: 
1:456a2ba:         public Location getLocation() {
1:54d56df:             return location;
1:51e82d5:         }
1:35658c7: 
1:2030097:         public T getCommand() {
1:2030097:             return command;
1:2030097:         }
1:2030097: 
1:456a2ba:         abstract public void execute(Transaction tx) throws IOException;
1:8262ef7:     }
1:35658c7: 
1:54e2e3b:     class AddOperation extends Operation<KahaAddMessageCommand> {
1:54e2e3b:         final IndexAware runWithIndexLock;
1:54e2e3b:         public AddOperation(KahaAddMessageCommand command, Location location, IndexAware runWithIndexLock) {
1:2030097:             super(command, location);
1:54e2e3b:             this.runWithIndexLock = runWithIndexLock;
1:8262ef7:         }
1:c9500f4: 
1:fbc5eb5:         @Override
1:3bf9d0c:         public void execute(Transaction tx) throws IOException {
1:54e2e3b:             long seq = updateIndex(tx, command, location);
1:54e2e3b:             if (runWithIndexLock != null) {
1:54e2e3b:                 runWithIndexLock.sequenceAssignedWithIndexLocked(seq);
1:54e2e3b:             }
1:8262ef7:         }
1:8262ef7:     }
1:c9500f4: 
1:54e2e3b:     class RemoveOperation extends Operation<KahaRemoveMessageCommand> {
1:c9500f4: 
1:54e2e3b:         public RemoveOperation(KahaRemoveMessageCommand command, Location location) {
1:2030097:             super(command, location);
1:8262ef7:         }
1:c9500f4: 
1:d761e80:         @Override
1:d761e80:         public void execute(Transaction tx) throws IOException {
1:456a2ba:             updateIndex(tx, command, location);
1:8262ef7:         }
1:8262ef7:     }
1:c9500f4: 
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:456a2ba:     // Initialization related implementation methods.
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:c9500f4: 
1:232b8c5:     private PageFile createPageFile() throws IOException {
1:946e62d:         if (indexDirectory == null) {
1:232b8c5:             indexDirectory = directory;
1:232b8c5:         }
1:232b8c5:         IOHelper.mkdirs(indexDirectory);
1:232b8c5:         PageFile index = new PageFile(indexDirectory, "db");
1:deea2d1:         index.setEnableWriteThread(isEnableIndexWriteAsync());
1:deea2d1:         index.setWriteBatchSize(getIndexWriteBatchSize());
1:fbc5eb5:         index.setPageCacheSize(indexCacheSize);
1:7da61d9:         index.setUseLFRUEviction(isUseIndexLFRUEviction());
1:7da61d9:         index.setLFUEvictionFactor(getIndexLFUEvictionFactor());
1:bb4a2f7:         index.setEnableDiskSyncs(isEnableIndexDiskSyncs());
1:bb4a2f7:         index.setEnableRecoveryFile(isEnableIndexRecoveryFile());
1:bb4a2f7:         index.setEnablePageCaching(isEnableIndexPageCaching());
1:deea2d1:         return index;
1:8262ef7:     }
1:fbc5eb5: 
1:8c3ef6c:     protected Journal createJournal() throws IOException {
1:1595378:         Journal manager = new Journal();
1:456a2ba:         manager.setDirectory(directory);
1:deea2d1:         manager.setMaxFileLength(getJournalMaxFileLength());
1:c9500f4:         manager.setCheckForCorruptionOnStartup(checkForCorruptJournalFiles);
1:c9500f4:         manager.setChecksum(checksumJournalFiles || checkForCorruptJournalFiles);
1:356c39d:         manager.setWriteBatchSize(getJournalMaxWriteBatchSize());
1:f8cb847:         manager.setArchiveDataLogs(isArchiveDataLogs());
1:a604424:         manager.setSizeAccumulator(journalSize);
1:89f22da:         manager.setEnableAsyncDiskSync(isEnableJournalDiskSyncs());
1:45e59e6:         manager.setPreallocationScope(Journal.PreallocationScope.valueOf(preallocationScope.trim().toUpperCase()));
1:45e59e6:         manager.setPreallocationStrategy(
1:45e59e6:                 Journal.PreallocationStrategy.valueOf(preallocationStrategy.trim().toUpperCase()));
1:0d824a8:         manager.setJournalDiskSyncStrategy(journalDiskSyncStrategy);
1:98bb7bf:         if (getDirectoryArchive() != null) {
1:98bb7bf:             IOHelper.mkdirs(getDirectoryArchive());
1:98bb7bf:             manager.setDirectoryArchive(getDirectoryArchive());
1:8262ef7:         }
1:456a2ba:         return manager;
1:8262ef7:     }
1:fbc5eb5: 
1:bfb1778:     private Metadata createMetadata() {
1:bfb1778:         Metadata md = new Metadata();
1:bfb1778:         md.producerSequenceIdTracker.setAuditDepth(getFailoverProducersAuditDepth());
1:bfb1778:         md.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(getMaxFailoverProducersToTrack());
1:bfb1778:         return md;
1:bfb1778:     }
1:bfb1778: 
1:7a7c70a:     protected abstract void configureMetadata();
1:7a7c70a: 
1:356c39d:     public int getJournalMaxWriteBatchSize() {
1:356c39d:         return journalMaxWriteBatchSize;
1:356c39d:     }
1:356c39d: 
1:356c39d:     public void setJournalMaxWriteBatchSize(int journalMaxWriteBatchSize) {
1:356c39d:         this.journalMaxWriteBatchSize = journalMaxWriteBatchSize;
1:356c39d:     }
1:356c39d: 
1:456a2ba:     public File getDirectory() {
1:456a2ba:         return directory;
1:8262ef7:     }
1:fbc5eb5: 
1:456a2ba:     public void setDirectory(File directory) {
1:456a2ba:         this.directory = directory;
1:8262ef7:     }
1:fbc5eb5: 
1:456a2ba:     public boolean isDeleteAllMessages() {
1:456a2ba:         return deleteAllMessages;
1:19c4316:     }
1:fbc5eb5: 
1:456a2ba:     public void setDeleteAllMessages(boolean deleteAllMessages) {
1:456a2ba:         this.deleteAllMessages = deleteAllMessages;
1:19c4316:     }
1:deea2d1: 
1:deea2d1:     public void setIndexWriteBatchSize(int setIndexWriteBatchSize) {
1:deea2d1:         this.setIndexWriteBatchSize = setIndexWriteBatchSize;
1:deea2d1:     }
1:fbc5eb5: 
1:deea2d1:     public int getIndexWriteBatchSize() {
1:deea2d1:         return setIndexWriteBatchSize;
1:deea2d1:     }
1:deea2d1: 
1:deea2d1:     public void setEnableIndexWriteAsync(boolean enableIndexWriteAsync) {
1:deea2d1:         this.enableIndexWriteAsync = enableIndexWriteAsync;
1:deea2d1:     }
1:deea2d1: 
1:deea2d1:     boolean isEnableIndexWriteAsync() {
1:deea2d1:         return enableIndexWriteAsync;
1:deea2d1:     }
1:deea2d1: 
1:dd0ed17:     /**
1:0d824a8:      * @deprecated use {@link #getJournalDiskSyncStrategyEnum} or {@link #getJournalDiskSyncStrategy} instead
1:dd0ed17:      * @return
1:dd0ed17:      */
1:281d600:     @Deprecated
1:c059425:     public boolean isEnableJournalDiskSyncs() {
1:0d824a8:         return journalDiskSyncStrategy == JournalDiskSyncStrategy.ALWAYS;
126:456a2ba:     }
1:40f9146: 
1:dd0ed17:     /**
1:dd0ed17:      * @deprecated use {@link #setEnableJournalDiskSyncs} instead
1:dd0ed17:      * @param syncWrites
1:dd0ed17:      */
1:281d600:     @Deprecated
1:c059425:     public void setEnableJournalDiskSyncs(boolean syncWrites) {
1:dd0ed17:         if (syncWrites) {
1:0d824a8:             journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS;
1:dd0ed17:         } else {
1:0d824a8:             journalDiskSyncStrategy = JournalDiskSyncStrategy.NEVER;
1:dd0ed17:         }
1:dd0ed17:     }
1:dd0ed17: 
1:0d824a8:     public JournalDiskSyncStrategy getJournalDiskSyncStrategyEnum() {
1:dd0ed17:         return journalDiskSyncStrategy;
1:dd0ed17:     }
1:dd0ed17: 
1:0d824a8:     public String getJournalDiskSyncStrategy() {
1:0d824a8:         return journalDiskSyncStrategy.name();
1:0d824a8:     }
1:0d824a8: 
1:dd0ed17:     public void setJournalDiskSyncStrategy(String journalDiskSyncStrategy) {
1:0d824a8:         this.journalDiskSyncStrategy = JournalDiskSyncStrategy.valueOf(journalDiskSyncStrategy.trim().toUpperCase());
1:dd0ed17:     }
1:dd0ed17: 
1:dd0ed17:     public long getJournalDiskSyncInterval() {
1:dd0ed17:         return journalDiskSyncInterval;
1:dd0ed17:     }
1:dd0ed17: 
1:dd0ed17:     public void setJournalDiskSyncInterval(long journalDiskSyncInterval) {
1:dd0ed17:         this.journalDiskSyncInterval = journalDiskSyncInterval;
1:456a2ba:     }
1:40f9146: 
1:c059425:     public long getCheckpointInterval() {
1:456a2ba:         return checkpointInterval;
1:456a2ba:     }
1:fbc5eb5: 
1:c059425:     public void setCheckpointInterval(long checkpointInterval) {
1:456a2ba:         this.checkpointInterval = checkpointInterval;
1:456a2ba:     }
1:fbc5eb5: 
1:c059425:     public long getCleanupInterval() {
1:456a2ba:         return cleanupInterval;
1:456a2ba:     }
1:fbc5eb5: 
1:c059425:     public void setCleanupInterval(long cleanupInterval) {
1:456a2ba:         this.cleanupInterval = cleanupInterval;
1:456a2ba:     }
1:fbc5eb5: 
1:c42d980:     public void setJournalMaxFileLength(int journalMaxFileLength) {
1:deea2d1:         this.journalMaxFileLength = journalMaxFileLength;
1:deea2d1:     }
1:deea2d1: 
1:c42d980:     public int getJournalMaxFileLength() {
1:deea2d1:         return journalMaxFileLength;
1:deea2d1:     }
1:deea2d1: 
1:a6a6a70:     public void setMaxFailoverProducersToTrack(int maxFailoverProducersToTrack) {
1:a6a6a70:         this.metadata.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(maxFailoverProducersToTrack);
1:a6a6a70:     }
1:a6a6a70: 
1:a6a6a70:     public int getMaxFailoverProducersToTrack() {
1:a6a6a70:         return this.metadata.producerSequenceIdTracker.getMaximumNumberOfProducersToTrack();
1:a6a6a70:     }
1:a6a6a70: 
1:a6a6a70:     public void setFailoverProducersAuditDepth(int failoverProducersAuditDepth) {
1:a6a6a70:         this.metadata.producerSequenceIdTracker.setAuditDepth(failoverProducersAuditDepth);
1:a6a6a70:     }
1:a6a6a70: 
1:a6a6a70:     public int getFailoverProducersAuditDepth() {
1:a6a6a70:         return this.metadata.producerSequenceIdTracker.getAuditDepth();
1:a6a6a70:     }
1:a6a6a70: 
1:232b8c5:     public PageFile getPageFile() throws IOException {
1:456a2ba:         if (pageFile == null) {
1:456a2ba:             pageFile = createPageFile();
1:456a2ba:         }
1:40f9146:         return pageFile;
1:40f9146:     }
1:40f9146: 
1:1595378:     public Journal getJournal() throws IOException {
1:1595378:         if (journal == null) {
1:1595378:             journal = createJournal();
1:456a2ba:         }
1:1595378:         return journal;
1:40f9146:     }
1:40f9146: 
1:822e2be:     protected Metadata getMetadata() {
1:822e2be:         return metadata;
1:822e2be:     }
1:822e2be: 
1:456a2ba:     public boolean isFailIfDatabaseIsLocked() {
1:456a2ba:         return failIfDatabaseIsLocked;
1:456a2ba:     }
1:fbc5eb5: 
1:456a2ba:     public void setFailIfDatabaseIsLocked(boolean failIfDatabaseIsLocked) {
1:456a2ba:         this.failIfDatabaseIsLocked = failIfDatabaseIsLocked;
1:456a2ba:     }
1:fbc5eb5: 
1:fbc5eb5:     public boolean isIgnoreMissingJournalfiles() {
1:fbc5eb5:         return ignoreMissingJournalfiles;
1:fbc5eb5:     }
1:40f9146: 
1:fbc5eb5:     public void setIgnoreMissingJournalfiles(boolean ignoreMissingJournalfiles) {
1:fbc5eb5:         this.ignoreMissingJournalfiles = ignoreMissingJournalfiles;
1:fbc5eb5:     }
1:fbc5eb5: 
1:fbc5eb5:     public int getIndexCacheSize() {
1:fbc5eb5:         return indexCacheSize;
1:fbc5eb5:     }
1:fbc5eb5: 
1:fbc5eb5:     public void setIndexCacheSize(int indexCacheSize) {
1:fbc5eb5:         this.indexCacheSize = indexCacheSize;
1:fbc5eb5:     }
1:c9500f4: 
1:c9500f4:     public boolean isCheckForCorruptJournalFiles() {
1:c9500f4:         return checkForCorruptJournalFiles;
1:c9500f4:     }
1:c9500f4: 
1:c9500f4:     public void setCheckForCorruptJournalFiles(boolean checkForCorruptJournalFiles) {
1:c9500f4:         this.checkForCorruptJournalFiles = checkForCorruptJournalFiles;
1:24b9ae2:     }
1:24b9ae2: 
1:28819ae:     public PurgeRecoveredXATransactionStrategy getPurgeRecoveredXATransactionStrategyEnum() {
1:28819ae:         return purgeRecoveredXATransactionStrategy;
1:24b9ae2:     }
1:24b9ae2: 
1:28819ae:     public String getPurgeRecoveredXATransactionStrategy() {
1:28819ae:         return purgeRecoveredXATransactionStrategy.name();
1:28819ae:     }
1:28819ae: 
1:28819ae:     public void setPurgeRecoveredXATransactionStrategy(String purgeRecoveredXATransactionStrategy) {
1:28819ae:         this.purgeRecoveredXATransactionStrategy = PurgeRecoveredXATransactionStrategy.valueOf(
1:28819ae:                 purgeRecoveredXATransactionStrategy.trim().toUpperCase());
1:c9500f4:     }
1:c9500f4: 
1:c9500f4:     public boolean isChecksumJournalFiles() {
1:c9500f4:         return checksumJournalFiles;
1:c9500f4:     }
1:c9500f4: 
1:c9500f4:     public void setChecksumJournalFiles(boolean checksumJournalFiles) {
1:c9500f4:         this.checksumJournalFiles = checksumJournalFiles;
1:c9500f4:     }
1:fbc5eb5: 
1:54d56df:     @Override
1:40f9146:     public void setBrokerService(BrokerService brokerService) {
1:40f9146:         this.brokerService = brokerService;
1:40f9146:     }
1:fbc5eb5: 
1:456a2ba:     /**
1:f8cb847:      * @return the archiveDataLogs
1:456a2ba:      */
1:f8cb847:     public boolean isArchiveDataLogs() {
1:f8cb847:         return this.archiveDataLogs;
1:456a2ba:     }
1:fbc5eb5: 
1:456a2ba:     /**
1:f8cb847:      * @param archiveDataLogs the archiveDataLogs to set
1:456a2ba:      */
1:f8cb847:     public void setArchiveDataLogs(boolean archiveDataLogs) {
1:f8cb847:         this.archiveDataLogs = archiveDataLogs;
1:456a2ba:     }
1:fbc5eb5: 
1:456a2ba:     /**
1:98bb7bf:      * @return the directoryArchive
1:456a2ba:      */
1:98bb7bf:     public File getDirectoryArchive() {
1:98bb7bf:         return this.directoryArchive;
1:456a2ba:     }
1:fbc5eb5: 
1:456a2ba:     /**
1:98bb7bf:      * @param directoryArchive the directoryArchive to set
1:456a2ba:      */
1:98bb7bf:     public void setDirectoryArchive(File directoryArchive) {
1:98bb7bf:         this.directoryArchive = directoryArchive;
1:456a2ba:     }
1:fbc5eb5: 
1:5f7fc14:     public boolean isArchiveCorruptedIndex() {
1:5f7fc14:         return archiveCorruptedIndex;
1:456a2ba:     }
1:e22a37a: 
1:5f7fc14:     public void setArchiveCorruptedIndex(boolean archiveCorruptedIndex) {
1:5f7fc14:         this.archiveCorruptedIndex = archiveCorruptedIndex;
1:456a2ba:     }
1:e22a37a: 
1:7da61d9:     public float getIndexLFUEvictionFactor() {
1:7da61d9:         return indexLFUEvictionFactor;
1:456a2ba:     }
1:e22a37a: 
1:7da61d9:     public void setIndexLFUEvictionFactor(float indexLFUEvictionFactor) {
1:7da61d9:         this.indexLFUEvictionFactor = indexLFUEvictionFactor;
1:456a2ba:     }
1:d761e80: 
1:7da61d9:     public boolean isUseIndexLFRUEviction() {
1:7da61d9:         return useIndexLFRUEviction;
1:456a2ba:     }
1:d761e80: 
1:7da61d9:     public void setUseIndexLFRUEviction(boolean useIndexLFRUEviction) {
1:7da61d9:         this.useIndexLFRUEviction = useIndexLFRUEviction;
1:456a2ba:     }
1:d761e80: 
1:bb4a2f7:     public void setEnableIndexDiskSyncs(boolean enableIndexDiskSyncs) {
1:bb4a2f7:         this.enableIndexDiskSyncs = enableIndexDiskSyncs;
1:bb4a2f7:     }
1:bb4a2f7: 
1:bb4a2f7:     public void setEnableIndexRecoveryFile(boolean enableIndexRecoveryFile) {
1:bb4a2f7:         this.enableIndexRecoveryFile = enableIndexRecoveryFile;
1:bb4a2f7:     }
1:bb4a2f7: 
1:bb4a2f7:     public void setEnableIndexPageCaching(boolean enableIndexPageCaching) {
1:bb4a2f7:         this.enableIndexPageCaching = enableIndexPageCaching;
1:bb4a2f7:     }
1:bb4a2f7: 
1:bb4a2f7:     public boolean isEnableIndexDiskSyncs() {
1:bb4a2f7:         return enableIndexDiskSyncs;
1:bb4a2f7:     }
1:bb4a2f7: 
1:bb4a2f7:     public boolean isEnableIndexRecoveryFile() {
1:bb4a2f7:         return enableIndexRecoveryFile;
1:bb4a2f7:     }
1:bb4a2f7: 
1:bb4a2f7:     public boolean isEnableIndexPageCaching() {
1:bb4a2f7:         return enableIndexPageCaching;
1:bb4a2f7:     }
1:bb4a2f7: 
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:a6c51a4:     // Internal conversion methods.
1:456a2ba:     // /////////////////////////////////////////////////////////////////
1:d761e80: 
1:1595378:     class MessageOrderCursor{
1:cba0468:         long defaultCursorPosition;
1:cba0468:         long lowPriorityCursorPosition;
1:cba0468:         long highPriorityCursorPosition;
1:1595378:         MessageOrderCursor(){
1:456a2ba:         }
1:40f9146: 
1:1595378:         MessageOrderCursor(long position){
1:1595378:             this.defaultCursorPosition=position;
1:1595378:             this.lowPriorityCursorPosition=position;
1:1595378:             this.highPriorityCursorPosition=position;
1:456a2ba:         }
1:40f9146: 
1:1595378:         MessageOrderCursor(MessageOrderCursor other){
1:1595378:             this.defaultCursorPosition=other.defaultCursorPosition;
1:1595378:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
1:1595378:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
1:456a2ba:         }
1:40f9146: 
1:cba0468:         MessageOrderCursor copy() {
1:cba0468:             return new MessageOrderCursor(this);
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void reset() {
1:1595378:             this.defaultCursorPosition=0;
1:1595378:             this.highPriorityCursorPosition=0;
1:1595378:             this.lowPriorityCursorPosition=0;
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void increment() {
1:1595378:             if (defaultCursorPosition!=0) {
1:cba0468:                 defaultCursorPosition++;
1:456a2ba:             }
1:1595378:             if (highPriorityCursorPosition!=0) {
1:cba0468:                 highPriorityCursorPosition++;
1:456a2ba:             }
1:1595378:             if (lowPriorityCursorPosition!=0) {
1:cba0468:                 lowPriorityCursorPosition++;
1:456a2ba:             }
1:456a2ba:         }
1:9705671: 
7:456a2ba:         @Override
1:9705671:         public String toString() {
1:1595378:            return "MessageOrderCursor:[def:" + defaultCursorPosition
1:1595378:                    + ", low:" + lowPriorityCursorPosition
1:1595378:                    + ", high:" +  highPriorityCursorPosition + "]";
1:9705671:         }
1:9705671: 
1:9705671:         public void sync(MessageOrderCursor other) {
1:1595378:             this.defaultCursorPosition=other.defaultCursorPosition;
1:1595378:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
1:1595378:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
1:9705671:         }
1:456a2ba:     }
1:40f9146: 
1:8871c67:     class MessageOrderIndex {
1:8871c67:         static final byte HI = 9;
1:8871c67:         static final byte LO = 0;
1:8871c67:         static final byte DEF = 4;
1:8871c67: 
1:456a2ba:         long nextMessageId;
1:cba0468:         BTreeIndex<Long, MessageKeys> defaultPriorityIndex;
1:cba0468:         BTreeIndex<Long, MessageKeys> lowPriorityIndex;
1:cba0468:         BTreeIndex<Long, MessageKeys> highPriorityIndex;
1:67ead20:         final MessageOrderCursor cursor = new MessageOrderCursor();
1:cba0468:         Long lastDefaultKey;
1:cba0468:         Long lastHighKey;
1:cba0468:         Long lastLowKey;
1:8871c67:         byte lastGetPriority;
1:281d600:         final List<Long> pendingAdditions = new LinkedList<>();
1:246ccb8:         final MessageKeysMarshaller messageKeysMarshaller = new MessageKeysMarshaller();
1:8871c67: 
1:cba0468:         MessageKeys remove(Transaction tx, Long key) throws IOException {
1:cba0468:             MessageKeys result = defaultPriorityIndex.remove(tx, key);
1:1595378:             if (result == null && highPriorityIndex!=null) {
1:cba0468:                 result = highPriorityIndex.remove(tx, key);
1:1595378:                 if (result ==null && lowPriorityIndex!=null) {
1:cba0468:                     result = lowPriorityIndex.remove(tx, key);
1:456a2ba:                 }
1:456a2ba:             }
1:cba0468:             return result;
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void load(Transaction tx) throws IOException {
1:cba0468:             defaultPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
1:246ccb8:             defaultPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:cba0468:             defaultPriorityIndex.load(tx);
1:3f0cf98:             lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
1:246ccb8:             lowPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:3f0cf98:             lowPriorityIndex.load(tx);
1:3f0cf98:             highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
1:246ccb8:             highPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:3f0cf98:             highPriorityIndex.load(tx);
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void allocate(Transaction tx) throws IOException {
1:281d600:             defaultPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:cba0468:             if (metadata.version >= 2) {
1:281d600:                 lowPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:281d600:                 highPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:456a2ba:             }
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void configureLast(Transaction tx) throws IOException {
1:cba0468:             // Figure out the next key using the last entry in the destination.
1:281d600:             TreeSet<Long> orderedSet = new TreeSet<>();
1:ecebd24: 
1:ecebd24:             addLast(orderedSet, highPriorityIndex, tx);
1:ecebd24:             addLast(orderedSet, defaultPriorityIndex, tx);
1:ecebd24:             addLast(orderedSet, lowPriorityIndex, tx);
1:ecebd24: 
1:ecebd24:             if (!orderedSet.isEmpty()) {
1:ecebd24:                 nextMessageId = orderedSet.last() + 1;
1:ecebd24:             }
1:ecebd24:         }
1:ecebd24: 
1:ecebd24:         private void addLast(TreeSet<Long> orderedSet, BTreeIndex<Long, MessageKeys> index, Transaction tx) throws IOException {
1:ecebd24:             if (index != null) {
1:ecebd24:                 Entry<Long, MessageKeys> lastEntry = index.getLast(tx);
4:cba0468:                 if (lastEntry != null) {
1:ecebd24:                     orderedSet.add(lastEntry.getKey());
1:456a2ba:                 }
1:456a2ba:             }
1:456a2ba:         }
1:d761e80: 
1:3cea40d:         void clear(Transaction tx) throws IOException {
1:3cea40d:             this.remove(tx);
1:3cea40d:             this.resetCursorPosition();
1:3cea40d:             this.allocate(tx);
1:3cea40d:             this.load(tx);
1:3cea40d:             this.configureLast(tx);
1:3cea40d:         }
1:3cea40d: 
1:cba0468:         void remove(Transaction tx) throws IOException {
1:cba0468:             defaultPriorityIndex.clear(tx);
1:cba0468:             defaultPriorityIndex.unload(tx);
1:cba0468:             tx.free(defaultPriorityIndex.getPageId());
2:cba0468:             if (lowPriorityIndex != null) {
1:cba0468:                 lowPriorityIndex.clear(tx);
1:cba0468:                 lowPriorityIndex.unload(tx);
1:d761e80: 
1:cba0468:                 tx.free(lowPriorityIndex.getPageId());
1:456a2ba:             }
3:cba0468:             if (highPriorityIndex != null) {
1:cba0468:                 highPriorityIndex.clear(tx);
1:cba0468:                 highPriorityIndex.unload(tx);
1:cba0468:                 tx.free(highPriorityIndex.getPageId());
1:456a2ba:             }
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void resetCursorPosition() {
1:cba0468:             this.cursor.reset();
1:cba0468:             lastDefaultKey = null;
1:cba0468:             lastHighKey = null;
1:cba0468:             lastLowKey = null;
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void setBatch(Transaction tx, Long sequence) throws IOException {
1:cba0468:             if (sequence != null) {
1:cba0468:                 Long nextPosition = new Long(sequence.longValue() + 1);
1:3985e72:                 lastDefaultKey = sequence;
1:3985e72:                 cursor.defaultCursorPosition = nextPosition.longValue();
1:3985e72:                 lastHighKey = sequence;
1:3985e72:                 cursor.highPriorityCursorPosition = nextPosition.longValue();
1:3985e72:                 lastLowKey = sequence;
1:3985e72:                 cursor.lowPriorityCursorPosition = nextPosition.longValue();
1:456a2ba:             }
1:456a2ba:         }
1:40f9146: 
1:8871c67:         void setBatch(Transaction tx, LastAck last) throws IOException {
1:8871c67:             setBatch(tx, last.lastAckedSequence);
1:8871c67:             if (cursor.defaultCursorPosition == 0
1:8871c67:                     && cursor.highPriorityCursorPosition == 0
1:8871c67:                     && cursor.lowPriorityCursorPosition == 0) {
1:8871c67:                 long next = last.lastAckedSequence + 1;
1:8871c67:                 switch (last.priority) {
1:8871c67:                     case DEF:
1:8871c67:                         cursor.defaultCursorPosition = next;
1:8871c67:                         cursor.highPriorityCursorPosition = next;
1:e53e340:                         break;
1:8871c67:                     case HI:
1:8871c67:                         cursor.highPriorityCursorPosition = next;
1:db3f8b3:                         break;
1:8871c67:                     case LO:
1:8871c67:                         cursor.lowPriorityCursorPosition = next;
1:8871c67:                         cursor.defaultCursorPosition = next;
1:8871c67:                         cursor.highPriorityCursorPosition = next;
1:60b0c4f:                         break;
1:8871c67:                 }
1:8871c67:             }
1:8871c67:         }
1:51e82d5: 
1:cba0468:         void stoppedIterating() {
1:1595378:             if (lastDefaultKey!=null) {
1:1595378:                 cursor.defaultCursorPosition=lastDefaultKey.longValue()+1;
1:456a2ba:             }
1:1595378:             if (lastHighKey!=null) {
1:1595378:                 cursor.highPriorityCursorPosition=lastHighKey.longValue()+1;
1:456a2ba:             }
1:1595378:             if (lastLowKey!=null) {
1:1595378:                 cursor.lowPriorityCursorPosition=lastLowKey.longValue()+1;
1:456a2ba:             }
1:cba0468:             lastDefaultKey = null;
1:cba0468:             lastHighKey = null;
1:cba0468:             lastLowKey = null;
1:456a2ba:         }
1:51e82d5: 
1:cba0468:         void getDeleteList(Transaction tx, ArrayList<Entry<Long, MessageKeys>> deletes, Long sequenceId)
1:cba0468:                 throws IOException {
1:9705671:             if (defaultPriorityIndex.containsKey(tx, sequenceId)) {
1:9705671:                 getDeleteList(tx, deletes, defaultPriorityIndex, sequenceId);
1:9705671:             } else if (highPriorityIndex != null && highPriorityIndex.containsKey(tx, sequenceId)) {
1:cba0468:                 getDeleteList(tx, deletes, highPriorityIndex, sequenceId);
1:9705671:             } else if (lowPriorityIndex != null && lowPriorityIndex.containsKey(tx, sequenceId)) {
1:cba0468:                 getDeleteList(tx, deletes, lowPriorityIndex, sequenceId);
1:456a2ba:             }
1:456a2ba:         }
1:40f9146: 
1:cba0468:         void getDeleteList(Transaction tx, ArrayList<Entry<Long, MessageKeys>> deletes,
1:1595378:                 BTreeIndex<Long, MessageKeys> index, Long sequenceId) throws IOException {
1:514ef7d: 
1:54e2e3b:             Iterator<Entry<Long, MessageKeys>> iterator = index.iterator(tx, sequenceId, null);
1:514ef7d:             deletes.add(iterator.next());
1:514ef7d:         }
1:40f9146: 
1:fcabcd2:         long getNextMessageId() {
1:cba0468:             return nextMessageId++;
1:456a2ba:         }
1:40f9146: 
1:fcabcd2:         void revertNextMessageId() {
1:fcabcd2:             nextMessageId--;
1:fcabcd2:         }
1:fcabcd2: 
1:cba0468:         MessageKeys get(Transaction tx, Long key) throws IOException {
1:cba0468:             MessageKeys result = defaultPriorityIndex.get(tx, key);
1:cba0468:             if (result == null) {
1:cba0468:                 result = highPriorityIndex.get(tx, key);
1:cba0468:                 if (result == null) {
1:cba0468:                     result = lowPriorityIndex.get(tx, key);
1:8871c67:                     lastGetPriority = LO;
1:8871c67:                 } else {
1:aec047d:                     lastGetPriority = HI;
1:456a2ba:                 }
1:8871c67:             } else {
1:8871c67:                 lastGetPriority = DEF;
1:456a2ba:             }
1:cba0468:             return result;
1:456a2ba:         }
1:51e82d5: 
1:cba0468:         MessageKeys put(Transaction tx, int priority, Long key, MessageKeys value) throws IOException {
1:cba0468:             if (priority == javax.jms.Message.DEFAULT_PRIORITY) {
1:cba0468:                 return defaultPriorityIndex.put(tx, key, value);
1:cba0468:             } else if (priority > javax.jms.Message.DEFAULT_PRIORITY) {
1:cba0468:                 return highPriorityIndex.put(tx, key, value);
1:943db3c:             } else {
1:cba0468:                 return lowPriorityIndex.put(tx, key, value);
1:456a2ba:             }
1:456a2ba:         }
1:40f9146: 
1:1595378:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx) throws IOException{
1:54e2e3b:             return new MessageOrderIterator(tx,cursor,this);
1:456a2ba:         }
1:40f9146: 
1:1595378:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx, MessageOrderCursor m) throws IOException{
1:54e2e3b:             return new MessageOrderIterator(tx,m,this);
1:456a2ba:         }
1:8871c67: 
1:8871c67:         public byte lastGetPriority() {
1:8871c67:             return lastGetPriority;
1:8871c67:         }
1:8871c67: 
1:cfe099d:         public boolean alreadyDispatched(Long sequence) {
1:cfe099d:             return (cursor.highPriorityCursorPosition > 0 && cursor.highPriorityCursorPosition >= sequence) ||
1:cfe099d:                     (cursor.defaultCursorPosition > 0 && cursor.defaultCursorPosition >= sequence) ||
1:cfe099d:                     (cursor.lowPriorityCursorPosition > 0 && cursor.lowPriorityCursorPosition >= sequence);
1:cfe099d:         }
1:cfe099d: 
1:54e2e3b:         public void trackPendingAdd(Long seq) {
1:54e2e3b:             synchronized (pendingAdditions) {
1:54e2e3b:                 pendingAdditions.add(seq);
1:54e2e3b:             }
1:54e2e3b:         }
1:54e2e3b: 
1:54e2e3b:         public void trackPendingAddComplete(Long seq) {
1:54e2e3b:             synchronized (pendingAdditions) {
1:54e2e3b:                 pendingAdditions.remove(seq);
1:54e2e3b:             }
1:54e2e3b:         }
1:54e2e3b: 
1:54e2e3b:         public Long minPendingAdd() {
1:54e2e3b:             synchronized (pendingAdditions) {
1:54e2e3b:                 if (!pendingAdditions.isEmpty()) {
1:54e2e3b:                     return pendingAdditions.get(0);
1:54e2e3b:                 } else {
1:54e2e3b:                     return null;
1:54e2e3b:                 }
1:54e2e3b:             }
1:54e2e3b:         }
1:54e2e3b: 
1:1595378:         class MessageOrderIterator implements Iterator<Entry<Long, MessageKeys>>{
1:1595378:             Iterator<Entry<Long, MessageKeys>>currentIterator;
1:1595378:             final Iterator<Entry<Long, MessageKeys>>highIterator;
1:1595378:             final Iterator<Entry<Long, MessageKeys>>defaultIterator;
1:1595378:             final Iterator<Entry<Long, MessageKeys>>lowIterator;
1:54e2e3b: 
1:54e2e3b:             MessageOrderIterator(Transaction tx, MessageOrderCursor m, MessageOrderIndex messageOrderIndex) throws IOException {
1:54e2e3b:                 Long pendingAddLimiter = messageOrderIndex.minPendingAdd();
1:54e2e3b:                 this.defaultIterator = defaultPriorityIndex.iterator(tx, m.defaultCursorPosition, pendingAddLimiter);
1:cba0468:                 if (highPriorityIndex != null) {
1:54e2e3b:                     this.highIterator = highPriorityIndex.iterator(tx, m.highPriorityCursorPosition, pendingAddLimiter);
1:943db3c:                 } else {
1:cba0468:                     this.highIterator = null;
1:69c0d39:                 }
1:cba0468:                 if (lowPriorityIndex != null) {
1:54e2e3b:                     this.lowIterator = lowPriorityIndex.iterator(tx, m.lowPriorityCursorPosition, pendingAddLimiter);
1:fbc5eb5:                 } else {
1:cba0468:                     this.lowIterator = null;
1:456a2ba:                 }
1:456a2ba:             }
1:69c0d39: 
1:54d56df:             @Override
1:cba0468:             public boolean hasNext() {
1:cba0468:                 if (currentIterator == null) {
1:cba0468:                     if (highIterator != null) {
1:cba0468:                         if (highIterator.hasNext()) {
1:cba0468:                             currentIterator = highIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
1:cba0468:                         if (defaultIterator.hasNext()) {
1:cba0468:                             currentIterator = defaultIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
1:cba0468:                         if (lowIterator.hasNext()) {
1:cba0468:                             currentIterator = lowIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
1:456a2ba:                         return false;
1:fbc5eb5:                     } else {
1:cba0468:                         currentIterator = defaultIterator;
1:cba0468:                         return currentIterator.hasNext();
1:456a2ba:                     }
1:456a2ba:                 }
1:cba0468:                 if (highIterator != null) {
1:cba0468:                     if (currentIterator.hasNext()) {
1:e22a37a:                         return true;
1:456a2ba:                     }
1:cba0468:                     if (currentIterator == highIterator) {
1:cba0468:                         if (defaultIterator.hasNext()) {
1:cba0468:                             currentIterator = defaultIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
1:cba0468:                         if (lowIterator.hasNext()) {
1:cba0468:                             currentIterator = lowIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
2:cba0468:                         return false;
1:456a2ba:                     }
1:1595378: 
1:cba0468:                     if (currentIterator == defaultIterator) {
1:cba0468:                         if (lowIterator.hasNext()) {
1:cba0468:                             currentIterator = lowIterator;
1:cba0468:                             return currentIterator.hasNext();
1:456a2ba:                         }
1:cba0468:                         return false;
1:456a2ba:                     }
1:456a2ba:                 }
1:cba0468:                 return currentIterator.hasNext();
1:456a2ba:             }
1:40f9146: 
1:54d56df:             @Override
1:cba0468:             public Entry<Long, MessageKeys> next() {
1:cba0468:                 Entry<Long, MessageKeys> result = currentIterator.next();
1:cba0468:                 if (result != null) {
1:cba0468:                     Long key = result.getKey();
1:cba0468:                     if (highIterator != null) {
1:cba0468:                         if (currentIterator == defaultIterator) {
1:cba0468:                             lastDefaultKey = key;
1:cba0468:                         } else if (currentIterator == highIterator) {
1:cba0468:                             lastHighKey = key;
1:51e82d5:                         } else {
1:cba0468:                             lastLowKey = key;
1:456a2ba:                         }
2:8262ef7:                     } else {
1:cba0468:                         lastDefaultKey = key;
1:456a2ba:                     }
1:456a2ba:                 }
1:cba0468:                 return result;
1:456a2ba:             }
1:40f9146: 
1:456a2ba:             @Override
1:cba0468:             public void remove() {
1:cba0468:                 throw new UnsupportedOperationException();
1:456a2ba:             }
1:456a2ba:         }
1:456a2ba:     }
1:40f9146: 
1:3f0cf98:     private static class HashSetStringMarshaller extends VariableMarshaller<HashSet<String>> {
1:3f0cf98:         final static HashSetStringMarshaller INSTANCE = new HashSetStringMarshaller();
1:3f0cf98: 
1:54d56df:         @Override
1:3f0cf98:         public void writePayload(HashSet<String> object, DataOutput dataOut) throws IOException {
1:3f0cf98:             ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:3f0cf98:             ObjectOutputStream oout = new ObjectOutputStream(baos);
1:3f0cf98:             oout.writeObject(object);
1:3f0cf98:             oout.flush();
1:3f0cf98:             oout.close();
1:3f0cf98:             byte[] data = baos.toByteArray();
1:3f0cf98:             dataOut.writeInt(data.length);
1:3f0cf98:             dataOut.write(data);
1:3f0cf98:         }
1:3f0cf98: 
1:54d56df:         @Override
1:943db3c:         @SuppressWarnings("unchecked")
1:3f0cf98:         public HashSet<String> readPayload(DataInput dataIn) throws IOException {
1:3f0cf98:             int dataLen = dataIn.readInt();
1:3f0cf98:             byte[] data = new byte[dataLen];
1:3f0cf98:             dataIn.readFully(data);
1:3f0cf98:             ByteArrayInputStream bais = new ByteArrayInputStream(data);
1:3f0cf98:             ObjectInputStream oin = new ObjectInputStream(bais);
1:3f0cf98:             try {
1:3f0cf98:                 return (HashSet<String>) oin.readObject();
1:3f0cf98:             } catch (ClassNotFoundException cfe) {
1:3f0cf98:                 IOException ioe = new IOException("Failed to read HashSet<String>: " + cfe);
1:3f0cf98:                 ioe.initCause(cfe);
1:3f0cf98:                 throw ioe;
1:3f0cf98:             }
1:3f0cf98:         }
1:3f0cf98:     }
6:8262ef7: 
1:232b8c5:     public File getIndexDirectory() {
1:232b8c5:         return indexDirectory;
1:232b8c5:     }
1:232b8c5: 
1:232b8c5:     public void setIndexDirectory(File indexDirectory) {
1:232b8c5:         this.indexDirectory = indexDirectory;
1:232b8c5:     }
1:54e2e3b: 
1:54e2e3b:     interface IndexAware {
1:54e2e3b:         public void sequenceAssignedWithIndexLocked(long index);
1:54e2e3b:     }
1:45e59e6: 
1:45e59e6:     public String getPreallocationScope() {
1:45e59e6:         return preallocationScope;
1:45e59e6:     }
1:45e59e6: 
1:45e59e6:     public void setPreallocationScope(String preallocationScope) {
1:45e59e6:         this.preallocationScope = preallocationScope;
1:45e59e6:     }
1:45e59e6: 
1:45e59e6:     public String getPreallocationStrategy() {
1:45e59e6:         return preallocationStrategy;
1:45e59e6:     }
1:45e59e6: 
1:45e59e6:     public void setPreallocationStrategy(String preallocationStrategy) {
1:45e59e6:         this.preallocationStrategy = preallocationStrategy;
1:45e59e6:     }
1:946e62d: 
1:946e62d:     public int getCompactAcksAfterNoGC() {
1:946e62d:         return compactAcksAfterNoGC;
1:946e62d:     }
1:946e62d: 
1:946e62d:     /**
1:946e62d:      * Sets the number of GC cycles where no journal logs were removed before an attempt to
1:946e62d:      * move forward all the acks in the last log that contains them and is otherwise unreferenced.
1:946e62d:      * <p>
1:946e62d:      * A value of -1 will disable this feature.
1:946e62d:      *
1:946e62d:      * @param compactAcksAfterNoGC
1:946e62d:      *      Number of empty GC cycles before we rewrite old ACKS.
1:946e62d:      */
1:946e62d:     public void setCompactAcksAfterNoGC(int compactAcksAfterNoGC) {
1:946e62d:         this.compactAcksAfterNoGC = compactAcksAfterNoGC;
1:946e62d:     }
1:946e62d: 
1:946e62d:     /**
1:946e62d:      * Returns whether Ack compaction will ignore that the store is still growing
1:946e62d:      * and run more often.
1:946e62d:      *
1:946e62d:      * @return the compactAcksIgnoresStoreGrowth current value.
1:946e62d:      */
1:946e62d:     public boolean isCompactAcksIgnoresStoreGrowth() {
1:946e62d:         return compactAcksIgnoresStoreGrowth;
1:946e62d:     }
1:946e62d: 
1:946e62d:     /**
1:946e62d:      * Configure if Ack compaction will occur regardless of continued growth of the
1:946e62d:      * journal logs meaning that the store has not run out of space yet.  Because the
1:946e62d:      * compaction operation can be costly this value is defaulted to off and the Ack
1:946e62d:      * compaction is only done when it seems that the store cannot grow and larger.
1:946e62d:      *
1:946e62d:      * @param compactAcksIgnoresStoreGrowth the compactAcksIgnoresStoreGrowth to set
1:946e62d:      */
1:946e62d:     public void setCompactAcksIgnoresStoreGrowth(boolean compactAcksIgnoresStoreGrowth) {
1:946e62d:         this.compactAcksIgnoresStoreGrowth = compactAcksIgnoresStoreGrowth;
1:946e62d:     }
1:cbad8ba: 
1:cbad8ba:     /**
1:cbad8ba:      * Returns whether Ack compaction is enabled
1:cbad8ba:      *
1:cbad8ba:      * @return enableAckCompaction
1:cbad8ba:      */
1:cbad8ba:     public boolean isEnableAckCompaction() {
1:cbad8ba:         return enableAckCompaction;
1:cbad8ba:     }
1:cbad8ba: 
1:cbad8ba:     /**
1:cbad8ba:      * Configure if the Ack compaction task should be enabled to run
1:cbad8ba:      *
1:cbad8ba:      * @param enableAckCompaction
1:cbad8ba:      */
1:cbad8ba:     public void setEnableAckCompaction(boolean enableAckCompaction) {
1:cbad8ba:         this.enableAckCompaction = enableAckCompaction;
1:cbad8ba:     }
1:cf3d419: 
1:cf3d419:     /**
1:cf3d419:      * @return
1:cf3d419:      */
1:cf3d419:     public boolean isEnableSubscriptionStatistics() {
1:cf3d419:         return enableSubscriptionStatistics;
1:cf3d419:     }
1:cf3d419: 
1:cf3d419:     /**
1:cf3d419:      * Enable caching statistics for each subscription to allow non-blocking
1:cf3d419:      * retrieval of metrics.  This could incur some overhead to compute if there are a lot
1:cf3d419:      * of subscriptions.
1:cf3d419:      *
1:cf3d419:      * @param enableSubscriptionStatistics
1:cf3d419:      */
1:cf3d419:     public void setEnableSubscriptionStatistics(boolean enableSubscriptionStatistics) {
1:cf3d419:         this.enableSubscriptionStatistics = enableSubscriptionStatistics;
1:cf3d419:     }
1:45e59e6: }
============================================================================
author:Jeff Genender
-------------------------------------------------------------------------------
commit:28819ae
/////////////////////////////////////////////////////////////////////////
1:     public enum PurgeRecoveredXATransactionStrategy {
1:         NEVER,
1:         COMMIT,
1:         ROLLBACK;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     protected PurgeRecoveredXATransactionStrategy purgeRecoveredXATransactionStrategy = PurgeRecoveredXATransactionStrategy.NEVER;
/////////////////////////////////////////////////////////////////////////
1:                 Set<TransactionId> txIds = new LinkedHashSet<TransactionId>(preparedTransactions.keySet());
1:                 for (TransactionId txId : txIds) {
1:                     switch (purgeRecoveredXATransactionStrategy){
1:                         case NEVER:
1:                             LOG.warn("Recovered prepared XA TX: [{}]", txId);
1:                             break;
1:                         case COMMIT:
1:                             store(new KahaCommitCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
1:                             LOG.warn("Recovered and Committing prepared XA TX: [{}]", txId);
1:                             break;
1:                         case ROLLBACK:
1:                             store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convert(txId)), false, null, null);
1:                             LOG.warn("Recovered and Rolling Back prepared XA TX: [{}]", txId);
1:                             break;
/////////////////////////////////////////////////////////////////////////
1:     public PurgeRecoveredXATransactionStrategy getPurgeRecoveredXATransactionStrategyEnum() {
1:         return purgeRecoveredXATransactionStrategy;
1:     public String getPurgeRecoveredXATransactionStrategy() {
1:         return purgeRecoveredXATransactionStrategy.name();
1:     }
1: 
1:     public void setPurgeRecoveredXATransactionStrategy(String purgeRecoveredXATransactionStrategy) {
1:         this.purgeRecoveredXATransactionStrategy = PurgeRecoveredXATransactionStrategy.valueOf(
1:                 purgeRecoveredXATransactionStrategy.trim().toUpperCase());
author:hkesler
-------------------------------------------------------------------------------
commit:24b9ae2
/////////////////////////////////////////////////////////////////////////
0:     private boolean purgeRecoveredXATransactions = false;
/////////////////////////////////////////////////////////////////////////
1: 
0:                 if (purgeRecoveredXATransactions){
0:                     if (!preparedTransactions.isEmpty()){
0:                         LOG.warn("Purging " +  preparedTransactions.size() + " recovered prepared XA TXs" );
0:                         preparedTransactions.clear();
1:                     }
1:                 }
/////////////////////////////////////////////////////////////////////////
0:     public boolean isPurgeRecoveredXATransactions() {
0:         return purgeRecoveredXATransactions;
1:     }
1: 
0:     public void setPurgeRecoveredXATransactions(boolean purgeRecoveredXATransactions) {
0:         this.purgeRecoveredXATransactions = purgeRecoveredXATransactions;
1:     }
1: 
author:gtully
-------------------------------------------------------------------------------
commit:ea70e82
/////////////////////////////////////////////////////////////////////////
commit:ec6fa19
/////////////////////////////////////////////////////////////////////////
1:                 if (location.getException().get() != null) {
1:                     throw location.getException().get();
commit:8c3ef6c
/////////////////////////////////////////////////////////////////////////
0:                 if (location.getBatch().exception.get() != null) {
0:                     throw location.getBatch().exception.get();
1:                 }
/////////////////////////////////////////////////////////////////////////
1:     protected Journal createJournal() throws IOException {
commit:a359d81
/////////////////////////////////////////////////////////////////////////
1:             boolean requiresJournalReplay = recoverProducerAudit();
1:             requiresJournalReplay |= recoverAckMessageFileMap();
1:             Location recoveryPosition = requiresJournalReplay ? journal.getNextLocation(null) : lastIndoubtPosition;
/////////////////////////////////////////////////////////////////////////
1:     private boolean recoverProducerAudit() throws IOException {
1:         boolean requiresReplay = true;
/////////////////////////////////////////////////////////////////////////
1:                 requiresReplay = false;
1:         // got no audit stored so got to recreate via replay from start of the journal
1:         return requiresReplay;
1:     private boolean recoverAckMessageFileMap() throws IOException {
1:         boolean requiresReplay = true;
1:                 requiresReplay = false;
1:         // got no ackMessageFileMap stored so got to recreate via replay from start of the journal
1:         return requiresReplay;
commit:8c218ee
/////////////////////////////////////////////////////////////////////////
1:                 getJournal().setCheckForCorruptionOnStartup(false);
/////////////////////////////////////////////////////////////////////////
1:         if (location.getSize() == NOT_SET && mayNotBeInitialized != null && mayNotBeInitialized.getSize() != NOT_SET) {
commit:2518bde
/////////////////////////////////////////////////////////////////////////
1:             throw new IOException("Could not load journal record, null type information from: " + readByte + " at location: "+location);
commit:ca5e41b
/////////////////////////////////////////////////////////////////////////
1:                 pageFile.flush();
/////////////////////////////////////////////////////////////////////////
commit:c1cbf50
/////////////////////////////////////////////////////////////////////////
1:                 // we won't delete past the last update, ackCompaction journal can be a candidate in error
1:                 gcCandidateSet.removeAll(new TreeSet<Integer>(gcCandidateSet.tailSet(lastUpdate.getDataFileId())));
commit:c5a8b2c
/////////////////////////////////////////////////////////////////////////
1:     public void allowIOResumption() {
1:         if (pageFile != null) {
1:             pageFile.allowIOResumption();
1:         }
1:         if (journal != null) {
1:             journal.allowIOResumption();
1:         }
1:     }
1: 
commit:d53b8f8
/////////////////////////////////////////////////////////////////////////
1:             LOG.error("KahaDB failed to store to Journal, command of type: " + data.type(), ioe);
commit:9b64e18
/////////////////////////////////////////////////////////////////////////
1:                     LOG.trace("gc candidates after producerSequenceIdTrackerLocation:" + metadata.producerSequenceIdTrackerLocation + ", " + gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:                     LOG.trace("gc candidates after ackMessageFileMapLocation:" + metadata.ackMessageFileMapLocation + ", " + gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:                 LOG.trace("gc candidates after in progress tx range:" + Arrays.asList(inProgressTxRange) + ", " + gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:         LOG.trace("Reserved file for forwarded acks: {}", forwardsFile);
/////////////////////////////////////////////////////////////////////////
1:             final Location limit = new Location(journalToRead + 1, 0);
1:             Location nextLocation = getNextLocationForAckForward(new Location(journalToRead, 0), limit);
1:             while (nextLocation != null) {
/////////////////////////////////////////////////////////////////////////
1:                 nextLocation = getNextLocationForAckForward(nextLocation, limit);
/////////////////////////////////////////////////////////////////////////
1:     private Location getNextLocationForAckForward(final Location nextLocation, final Location limit) {
1:             location = journal.getNextLocation(nextLocation, limit);
commit:e3b5291
/////////////////////////////////////////////////////////////////////////
1:             LOG.warn("Failed to load next journal location after: {}, reason: {}", nextLocation, e);
1:                 LOG.debug("Failed to load next journal location after: {}", nextLocation, e);
commit:2052239
/////////////////////////////////////////////////////////////////////////
1:                 Set<Integer> filesToGc = pageFile.tx().execute(new Transaction.CallableClosure<Set<Integer>, IOException>() {
1:                     public Set<Integer> execute(Transaction tx) throws IOException {
1:                         return checkpointUpdate(tx, cleanup);
1:                 // after the index update such that partial removal does not leave dangling references in the index.
1:                 journal.removeDataFiles(filesToGc);
/////////////////////////////////////////////////////////////////////////
1:     Set<Integer> checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:         final TreeSet<Integer> gcCandidateSet = new TreeSet<>();
1:             gcCandidateSet.addAll(completeFileSet);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         return gcCandidateSet;
/////////////////////////////////////////////////////////////////////////
commit:dad629e
/////////////////////////////////////////////////////////////////////////
0:                 final LinkedHashMap<Long, Location> matches = new LinkedHashMap<Long, Location>();
1:                         matches.put(value, key);
/////////////////////////////////////////////////////////////////////////
1:                         for (Long sequenceId : matches.keySet()) {
/////////////////////////////////////////////////////////////////////////
1:                         LOG.error("[" + sdEntry.getKey() + "] references corrupt locations: " + matches);
commit:822e2be
/////////////////////////////////////////////////////////////////////////
1:                 KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
1:                 KahaAckMessageFileMapCommand audit = (KahaAckMessageFileMapCommand) load(metadata.ackMessageFileMapLocation);
/////////////////////////////////////////////////////////////////////////
1:     protected Metadata getMetadata() {
1:         return metadata;
1:     }
1: 
commit:d427952
/////////////////////////////////////////////////////////////////////////
1:                 int dataFileRotationTracker = recoveryPosition.getDataFileId();
/////////////////////////////////////////////////////////////////////////
1:                     // hold on to the minimum number of open files during recovery
1:                     if (recoveryPosition != null && dataFileRotationTracker != recoveryPosition.getDataFileId()) {
1:                         dataFileRotationTracker = recoveryPosition.getDataFileId();
1:                         journal.cleanup();
1:                     }
1:                     if (LOG.isInfoEnabled() && redoCounter % 100000 == 0) {
1:                         LOG.info("@" + recoveryPosition + ", " + redoCounter + " entries recovered ..");
1:                     }
commit:4386750
/////////////////////////////////////////////////////////////////////////
1: import org.slf4j.MDC;
/////////////////////////////////////////////////////////////////////////
1:         MDC.put("activemq.persistenceDir", getDirectory().getName());
/////////////////////////////////////////////////////////////////////////
1:         MDC.remove("activemq.persistenceDir");
commit:65cef69
/////////////////////////////////////////////////////////////////////////
1:     private String preallocationScope = Journal.PreallocationScope.ENTIRE_JOURNAL.name();
commit:1c41085
/////////////////////////////////////////////////////////////////////////
1: import static org.apache.activemq.store.kahadb.disk.journal.Location.NOT_SET;
1: 
/////////////////////////////////////////////////////////////////////////
0:             Location afterProducerAudit = recoverProducerAudit();
0:             Location afterAckMessageFile = recoverAckMessageFileMap();
0:             if (afterProducerAudit != null && afterProducerAudit.equals(metadata.ackMessageFileMapLocation)) {
0:                 // valid checkpoint, possible recover from afterAckMessageFile
0:                 afterProducerAudit = null;
1:             }
0:             Location recoveryPosition = minimum(afterProducerAudit, afterAckMessageFile);
0:             recoveryPosition = minimum(recoveryPosition, lastIndoubtPosition);
/////////////////////////////////////////////////////////////////////////
1:     private Location minimum(Location x,
1:                              Location y) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 return getNextInitializedLocation(metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
0:                 return getNextInitializedLocation(metadata.ackMessageFileMapLocation);
/////////////////////////////////////////////////////////////////////////
1:                 return getNextInitializedLocation(metadata.lastUpdate);
1:     private Location getNextInitializedLocation(Location location) throws IOException {
1:         Location mayNotBeInitialized = journal.getNextLocation(location);
0:         if (location.getSize() == NOT_SET && mayNotBeInitialized.getSize() != NOT_SET) {
1:             // need to init size and type to skip
1:             return journal.getNextLocation(mayNotBeInitialized);
1:         } else {
1:             return mayNotBeInitialized;
1:         }
1:     }
1: 
commit:ba77b9f
/////////////////////////////////////////////////////////////////////////
0:             Location recoveryPosition = startOfRecovery(producerAuditPosition, ackMessageFileLocation);
0:             recoveryPosition = startOfRecovery(recoveryPosition, lastIndoubtPosition);
/////////////////////////////////////////////////////////////////////////
0:     private Location startOfRecovery(Location x,
0:             Location y) {
1:         if (x != null) {
1:             min = x;
1:             if (y != null) {
1:                 int compare = y.compareTo(x);
1:                 if (compare < 0) {
1:                     min = y;
0:                 } else if (compare == 0) {
0:                     min = null; // no recovery needed on a matched location
1:                 }
1:             min = y;
commit:62bdbb0
/////////////////////////////////////////////////////////////////////////
0:     private String preallocationScope = Journal.PreallocationScope.ENTIRE_JOURNAL_ASYNC.name();
/////////////////////////////////////////////////////////////////////////
1: 
1:             int journalToAdvance = -1;
0:             Set<Integer> journalLogsReferenced = new HashSet<Integer>();
1: 
1:             try {
1:                 // Map keys might not be sorted, find the earliest log file to forward acks
1:                 // from and move only those, future cycles can chip away at more as needed.
1:                 // We won't move files that are themselves rewritten on a previous compaction.
0:                 List<Integer> journalFileIds = new ArrayList<Integer>(metadata.ackMessageFileMap.keySet());
1:                 Collections.sort(journalFileIds);
1:                 for (Integer journalFileId : journalFileIds) {
1:                     DataFile current = journal.getDataFileById(journalFileId);
1:                     if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
1:                         journalToAdvance = journalFileId;
1:                         break;
1:                     }
1: 
1:                 // Check if we found one, or if we only found the current file being written to.
1:                 if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:                     return;
1:                 }
1: 
1:                 journalLogsReferenced.addAll(metadata.ackMessageFileMap.get(journalToAdvance));
1: 
1:             } finally {
1:                 indexLock.writeLock().unlock();
commit:31d99b6
/////////////////////////////////////////////////////////////////////////
1:             boolean ackMessageFileMapMod = false;
/////////////////////////////////////////////////////////////////////////
1:                         ackMessageFileMapMod |= (metadata.ackMessageFileMap.remove(candidate) != null);
/////////////////////////////////////////////////////////////////////////
commit:5db5f3e
/////////////////////////////////////////////////////////////////////////
1:         for (Entry<Integer, Set<Integer>> entry : metadata.ackMessageFileMap.entrySet()) {
1:             missingJournalFiles.add(entry.getKey());
1:             for (Integer i : entry.getValue()) {
1:                 missingJournalFiles.add(i);
1:         missingJournalFiles.removeAll(journal.getFileMap().keySet());
1: 
1:         if (!missingJournalFiles.isEmpty()) {
1:             LOG.warn("Some journal files are missing: " + missingJournalFiles);
1:         }
1: 
0:         ArrayList<BTreeVisitor.Predicate<Location>> knownCorruption = new ArrayList<BTreeVisitor.Predicate<Location>>();
/////////////////////////////////////////////////////////////////////////
1:                 // eof to next file id
0:                     BTreeVisitor.BetweenVisitor visitor = new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
1:                     missingPredicates.add(visitor);
1:                     knownCorruption.add(visitor);
/////////////////////////////////////////////////////////////////////////
1:                 // If some message references are affected by the missing data files...
/////////////////////////////////////////////////////////////////////////
0:                         LOG.error("[" + sdEntry.getKey() + "] references corrupt locations. " + matches.size() + " messages affected.");
1:                         throw new IOException("Detected missing/corrupt journal files referenced by:[" + sdEntry.getKey() + "] " +matches.size()+" messages affected.");
1:         if (!ignoreMissingJournalfiles) {
1:             if (!knownCorruption.isEmpty()) {
1:                 LOG.error("Detected corrupt journal files. " + knownCorruption);
1:                 throw new IOException("Detected corrupt journal files. " + knownCorruption);
1:             }
1: 
1:             if (!missingJournalFiles.isEmpty()) {
1:                 LOG.error("Detected missing journal files. " + missingJournalFiles);
1:                 throw new IOException("Detected missing journal files. " + missingJournalFiles);
1:             }
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 LOG.trace("ackMessageFileMap: " +  metadata.ackMessageFileMap);
/////////////////////////////////////////////////////////////////////////
0:                 boolean ackMessageFileMapMod = false;
1:                 for (Integer candidate : gcCandidateSet) {
1:                     for (Set<Integer> ackFiles : metadata.ackMessageFileMap.values()) {
1:                         ackMessageFileMapMod |= ackFiles.remove(candidate);
1:                     }
1:                 }
1:                 if (ackMessageFileMapMod) {
1:                     checkpointUpdate(tx, false);
1:                 }
commit:dc06c8d
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             Location existing = sd.subLocations.get(tx, subscriptionKey);
1:             if (existing != null && existing.compareTo(location) == 0) {
1:                 // replay on recovery, ignore
1:                 LOG.trace("ignoring journal replay of replay of sub from: " + location);
1:                 return;
1:             }
1: 
commit:fcabcd2
/////////////////////////////////////////////////////////////////////////
1:         long id = sd.orderIndex.getNextMessageId();
/////////////////////////////////////////////////////////////////////////
1:             // ensure sequence is not broken
1:             sd.orderIndex.revertNextMessageId();
/////////////////////////////////////////////////////////////////////////
1:                 LOG.debug("on ack, no message sequence exists for id: " + command.getMessageId() + " and sub: " + command.getSubscriptionKey());
/////////////////////////////////////////////////////////////////////////
1:         long getNextMessageId() {
1:         void revertNextMessageId() {
1:             nextMessageId--;
1:         }
1: 
commit:3985e72
/////////////////////////////////////////////////////////////////////////
1:                 lastDefaultKey = sequence;
1:                 cursor.defaultCursorPosition = nextPosition.longValue();
1:                 lastHighKey = sequence;
1:                 cursor.highPriorityCursorPosition = nextPosition.longValue();
1:                 lastLowKey = sequence;
1:                 cursor.lowPriorityCursorPosition = nextPosition.longValue();
commit:2c53dbc
/////////////////////////////////////////////////////////////////////////
1: 
1:                 MessageKeys messageKeys = sd.orderIndex.get(tx, previous);
1:                 if (messageKeys != null && messageKeys.location.compareTo(location) < 0) {
1:                     // If the message ID is indexed, then the broker asked us to store a duplicate before the message was dispatched and acked, we ignore this add attempt
1:                     LOG.warn("Duplicate message add attempt rejected. Destination: {}://{}, Message id: {}", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId());
1:                 }
/////////////////////////////////////////////////////////////////////////
1:             // on first update previous is original location, on recovery/replay it may be the updated location
0:             if(previousKeys != null && !previousKeys.location.equals(location)) {
commit:0a21c5f
/////////////////////////////////////////////////////////////////////////
1:                             throw new IOException("Failed to recover data at position:" + recoveryPosition, failedRecovery);
commit:3fdf986
/////////////////////////////////////////////////////////////////////////
1:                 // remove the stored destination
1:                 KahaRemoveDestinationCommand removeDestinationCommand = new KahaRemoveDestinationCommand();
1:                 removeDestinationCommand.setDestination(command.getDestination());
1:                 updateIndex(tx, removeDestinationCommand, null);
commit:4a82118
/////////////////////////////////////////////////////////////////////////
1:                             LOG.debug("Failed to recover data at position:" + recoveryPosition, failedRecovery);
commit:73db4d2
/////////////////////////////////////////////////////////////////////////
1:                     try {
1:                         JournalCommand<?> message = load(recoveryPosition);
1:                         metadata.lastUpdate = recoveryPosition;
1:                         process(message, recoveryPosition, lastIndoubtPosition);
1:                         redoCounter++;
1:                     } catch (IOException failedRecovery) {
1:                         if (isIgnoreMissingJournalfiles()) {
1:                             // track this dud location
1:                             journal.corruptRecoveryLocation(recoveryPosition);
1:                         } else {
0:                             throw failedRecovery;
1:                         }
1:                     }
/////////////////////////////////////////////////////////////////////////
1:             for (Entry<String, StoredDestination> sdEntry : storedDestinations.entrySet()) {
1:                 final StoredDestination sd = sdEntry.getValue();
/////////////////////////////////////////////////////////////////////////
1:                             LOG.info("[" + sdEntry.getKey() + "] dropped: " + keys.messageId + " at corrupt location: " + keys.location);
commit:a7178a4
/////////////////////////////////////////////////////////////////////////
1:                 LOG.info("Recovering from the journal @" + recoveryPosition);
commit:ecebd24
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             TreeSet<Long> orderedSet = new TreeSet<Long>();
1: 
1:             addLast(orderedSet, highPriorityIndex, tx);
1:             addLast(orderedSet, defaultPriorityIndex, tx);
1:             addLast(orderedSet, lowPriorityIndex, tx);
1: 
1:             if (!orderedSet.isEmpty()) {
1:                 nextMessageId = orderedSet.last() + 1;
1:             }
1:         }
1: 
1:         private void addLast(TreeSet<Long> orderedSet, BTreeIndex<Long, MessageKeys> index, Transaction tx) throws IOException {
1:             if (index != null) {
1:                 Entry<Long, MessageKeys> lastEntry = index.getLast(tx);
1:                     orderedSet.add(lastEntry.getKey());
commit:b0a1bd8
/////////////////////////////////////////////////////////////////////////
1:                         if (completeFileSet.contains(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
commit:02d974c
/////////////////////////////////////////////////////////////////////////
0:             if (checkpointThread != null && !checkpointThread.isAlive() && opened.get()) {
commit:1352265
/////////////////////////////////////////////////////////////////////////
1:                 metadata.lastUpdate = location;
/////////////////////////////////////////////////////////////////////////
1:             metadata.lastUpdate = location;
/////////////////////////////////////////////////////////////////////////
1:             metadata.lastUpdate = location;
/////////////////////////////////////////////////////////////////////////
1:                     metadata.lastUpdate = ackLocation;
/////////////////////////////////////////////////////////////////////////
1:                 metadata.lastUpdate = ackLocation;
commit:67ead20
/////////////////////////////////////////////////////////////////////////
1:         final MessageOrderCursor cursor = new MessageOrderCursor();
/////////////////////////////////////////////////////////////////////////
0:                 } else if (highPriorityIndex != null && highPriorityIndex.containsKey(tx, sequence)) {
0:                     lastHighKey = sequence;
0:                     cursor.highPriorityCursorPosition = nextPosition.longValue();
0:                 } else if (lowPriorityIndex.containsKey(tx, sequence)) {
0:                     lastLowKey = sequence;
0:                     cursor.lowPriorityCursorPosition = nextPosition.longValue();
commit:9c2b1d2
/////////////////////////////////////////////////////////////////////////
0:     protected final HashMap<String, StoredDestination> storedDestinations = new HashMap<String, StoredDestination>();
/////////////////////////////////////////////////////////////////////////
1: 
1:         @Override
1:         public String toString() {
1:             return "nextSeq:" + orderIndex.nextMessageId + ",lastRet:" + orderIndex.cursor + ",pending:" + orderIndex.pendingAdditions.size();
1:         }
/////////////////////////////////////////////////////////////////////////
1:     protected String key(KahaDestination destination) {
commit:140ce1b
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         indexLock.writeLock().lock();
1:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                 @Override
1:                 public void execute(Transaction tx) throws IOException {
1:                     for (Operation op : messagingTx) {
1:                         op.execute(tx);
1:                 }
1:             });
1:             metadata.lastUpdate = location;
1:         } finally {
1:             indexLock.writeLock().unlock();
commit:a0c42a6
/////////////////////////////////////////////////////////////////////////
1:             MessageKeys previousKeys = sd.orderIndex.put(
0:             if(previousKeys != null) {
1:                 sd.locationIndex.remove(tx, previousKeys.location);
1:             }
commit:54e2e3b
/////////////////////////////////////////////////////////////////////////
1: import java.util.LinkedList;
/////////////////////////////////////////////////////////////////////////
0: import java.util.concurrent.Callable;
/////////////////////////////////////////////////////////////////////////
0:     interface SerialExecution<V> {
0:         public V execute(Callable<V> c) throws Exception;
0:     SerialExecution<Location> serialExecutor;
/////////////////////////////////////////////////////////////////////////
1:             if (operation instanceof AddOperation) {
1:                 AddOperation add = (AddOperation) operation;
1:                 RemoveOperation removeOpperation = (RemoveOperation) operation;
/////////////////////////////////////////////////////////////////////////
1:                 process(message, lastRecoveryPosition, (IndexAware) null);
/////////////////////////////////////////////////////////////////////////
1:         return store(data, false, null, null, onJournalStoreComplete);
1:     public Location store(JournalCommand<?> data, boolean sync, IndexAware before,Runnable after) throws IOException {
0:     public Location store(final KahaCommitCommand data, final boolean sync, final IndexAware before, final Runnable after) throws IOException {
1:         try {
0:             return serialExecutor.execute(new Callable<Location>() {
1:                 @Override
0:                 public Location call() throws Exception {
1:                     return store(data, sync, before, after, null);
1:                 }
1:             });
1:         } catch (Exception e) {
0:             LOG.error("Failed to execute commit", e);
0:             throw new IOException(e);
1:         }
1:     }
1: 
1:     public Location store(JournalCommand<?> data, boolean sync, IndexAware before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:                 process(data, location, before);
/////////////////////////////////////////////////////////////////////////
1:             process(data, location, (IndexAware) null);
/////////////////////////////////////////////////////////////////////////
1:     void process(JournalCommand<?> data, final Location location, final IndexAware onSequenceAssignedCallback) throws IOException {
1:                 process(command, location, onSequenceAssignedCallback);
/////////////////////////////////////////////////////////////////////////
1:                 process(command, location, onSequenceAssignedCallback);
/////////////////////////////////////////////////////////////////////////
1:     protected void process(final KahaAddMessageCommand command, final Location location, final IndexAware runWithIndexLock) throws IOException {
1:             List<Operation> inflightTx = getInflightTx(command.getTransactionInfo());
1:             inflightTx.add(new AddOperation(command, location, runWithIndexLock));
1:                         long assignedIndex = updateIndex(tx, command, location);
1:                         if (runWithIndexLock != null) {
1:                             runWithIndexLock.sequenceAssignedWithIndexLocked(assignedIndex);
1:                         }
1: 
/////////////////////////////////////////////////////////////////////////
1:            List<Operation> inflightTx = getInflightTx(command.getTransactionInfo());
1:            inflightTx.add(new RemoveOperation(command, location));
/////////////////////////////////////////////////////////////////////////
1:     protected void process(KahaCommitCommand command, final Location location, final IndexAware before) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:                 before.sequenceAssignedWithIndexLocked(-1);
1:             indexLock.writeLock().lock();
1:             try {
1:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                     @Override
1:                     public void execute(Transaction tx) throws IOException {
0:                         for (Operation op : messagingTx) {
0:                             op.execute(tx);
1:                         }
1:                 });
1:                 metadata.lastUpdate = location;
1:             } finally {
1:                 indexLock.writeLock().unlock();
1:             }
1:         } catch (Exception e) {
0:             LOG.error("serial execution of commit failed", e);
0:             throw new IOException(e);
/////////////////////////////////////////////////////////////////////////
1:     long updateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
1:             return -1;
/////////////////////////////////////////////////////////////////////////
0:                 // If the message ID is indexed, then the broker asked us to store a duplicate before the message was dispatched and acked, we ignore this add attempt
1:                 id = -1;
/////////////////////////////////////////////////////////////////////////
1:         return id;
1:     }
1: 
1:     void trackPendingAdd(KahaDestination destination, Long seq) {
1:         StoredDestination sd = storedDestinations.get(key(destination));
1:         if (sd != null) {
1:             sd.trackPendingAdd(seq);
1:         }
1:     }
1: 
1:     void trackPendingAddComplete(KahaDestination destination, Long seq) {
1:         StoredDestination sd = storedDestinations.get(key(destination));
1:         if (sd != null) {
1:             sd.trackPendingAddComplete(seq);
1:         }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
1:         public void trackPendingAdd(Long seq) {
1:             orderIndex.trackPendingAdd(seq);
1:         }
1: 
1:         public void trackPendingAddComplete(Long seq) {
1:             orderIndex.trackPendingAddComplete(seq);
1:         }
/////////////////////////////////////////////////////////////////////////
1:     private List<Operation> getInflightTx(KahaTransactionInfo info) {
/////////////////////////////////////////////////////////////////////////
1:     class AddOperation extends Operation<KahaAddMessageCommand> {
1:         final IndexAware runWithIndexLock;
1:         public AddOperation(KahaAddMessageCommand command, Location location, IndexAware runWithIndexLock) {
1:             this.runWithIndexLock = runWithIndexLock;
1:             long seq = updateIndex(tx, command, location);
1:             if (runWithIndexLock != null) {
1:                 runWithIndexLock.sequenceAssignedWithIndexLocked(seq);
1:             }
1:     class RemoveOperation extends Operation<KahaRemoveMessageCommand> {
1:         public RemoveOperation(KahaRemoveMessageCommand command, Location location) {
/////////////////////////////////////////////////////////////////////////
0:         final List<Long> pendingAdditions = new LinkedList<Long>();
/////////////////////////////////////////////////////////////////////////
1:             Iterator<Entry<Long, MessageKeys>> iterator = index.iterator(tx, sequenceId, null);
/////////////////////////////////////////////////////////////////////////
1:             return new MessageOrderIterator(tx,cursor,this);
1:             return new MessageOrderIterator(tx,m,this);
/////////////////////////////////////////////////////////////////////////
1:         public void trackPendingAdd(Long seq) {
1:             synchronized (pendingAdditions) {
1:                 pendingAdditions.add(seq);
1:             }
1:         }
1: 
1:         public void trackPendingAddComplete(Long seq) {
1:             synchronized (pendingAdditions) {
1:                 pendingAdditions.remove(seq);
1:             }
1:         }
1: 
1:         public Long minPendingAdd() {
1:             synchronized (pendingAdditions) {
1:                 if (!pendingAdditions.isEmpty()) {
1:                     return pendingAdditions.get(0);
1:                 } else {
1:                     return null;
1:                 }
1:             }
1:         }
1: 
1: 
1:             MessageOrderIterator(Transaction tx, MessageOrderCursor m, MessageOrderIndex messageOrderIndex) throws IOException {
1:                 Long pendingAddLimiter = messageOrderIndex.minPendingAdd();
1:                 this.defaultIterator = defaultPriorityIndex.iterator(tx, m.defaultCursorPosition, pendingAddLimiter);
1:                     this.highIterator = highPriorityIndex.iterator(tx, m.highPriorityCursorPosition, pendingAddLimiter);
1:                     this.lowIterator = lowPriorityIndex.iterator(tx, m.lowPriorityCursorPosition, pendingAddLimiter);
/////////////////////////////////////////////////////////////////////////
1: 
1:     interface IndexAware {
1:         public void sequenceAssignedWithIndexLocked(long index);
1:     }
commit:266d23e
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.data.KahaUpdateMessageCommand;
/////////////////////////////////////////////////////////////////////////
1: 
1:             @Override
1:             public void visit(KahaUpdateMessageCommand command) throws IOException {
1:                 process(command, location);
1:             }
/////////////////////////////////////////////////////////////////////////
1:                         updateIndex(tx, command, location);
/////////////////////////////////////////////////////////////////////////
1:     protected void process(final KahaUpdateMessageCommand command, final Location location) throws IOException {
1:         this.indexLock.writeLock().lock();
1:         try {
1:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                 @Override
1:                 public void execute(Transaction tx) throws IOException {
1:                     updateIndex(tx, command, location);
1:                 }
1:             });
1:         } finally {
1:             this.indexLock.writeLock().unlock();
1:         }
1:     }
1: 
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     void updateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     void updateIndex(Transaction tx, KahaUpdateMessageCommand updateMessageCommand, Location location) throws IOException {
1:         KahaAddMessageCommand command = updateMessageCommand.getMessage();
1:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1: 
1:         Long id = sd.messageIdIndex.get(tx, command.getMessageId());
1:         if (id != null) {
0:             sd.orderIndex.put(
1:                     tx,
1:                     command.getPrioritySupported() ? command.getPriority() : javax.jms.Message.DEFAULT_PRIORITY,
1:                     id,
1:                     new MessageKeys(command.getMessageId(), location)
1:             );
1:             sd.locationIndex.put(tx, location, id);
1:         } else {
0:             LOG.warn("Non existent message update attempt rejected. Destination: {}://{}, Message id: {}", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId());
1:         }
0:         metadata.lastUpdate = location;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:             updateIndex(tx, command, location);
/////////////////////////////////////////////////////////////////////////
commit:cfe099d
/////////////////////////////////////////////////////////////////////////
0:     protected final Set<String> rolledBackAcks = new HashSet<String>();
/////////////////////////////////////////////////////////////////////////
0:     public void forgetRecoveredAcks(ArrayList<MessageAck> acks, boolean rollback) throws IOException {
0:                     final String id = ack.getLastMessageId().toProducerKey();
0:                     ackedAndPrepared.remove(id);
0:                     if (rollback) {
0:                         rolledBackAcks.add(id);
1:                     }
/////////////////////////////////////////////////////////////////////////
1:         public boolean alreadyDispatched(Long sequence) {
1:             return (cursor.highPriorityCursorPosition > 0 && cursor.highPriorityCursorPosition >= sequence) ||
1:                     (cursor.defaultCursorPosition > 0 && cursor.defaultCursorPosition >= sequence) ||
1:                     (cursor.lowPriorityCursorPosition > 0 && cursor.lowPriorityCursorPosition >= sequence);
1:         }
1: 
commit:ab01ae3
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:     public void forgetRecoveredAcks(ArrayList<MessageAck> acks) throws IOException {
0:                     ackedAndPrepared.remove(ack.getLastMessageId().toProducerKey());
/////////////////////////////////////////////////////////////////////////
commit:69c0d39
/////////////////////////////////////////////////////////////////////////
1:         synchronized (preparedTransactions) {
1:             if (!preparedTransactions.isEmpty()) {
1:                 for (Entry<TransactionId, List<Operation>> entry : preparedTransactions.entrySet()) {
1:                     TranInfo info = new TranInfo();
1:                     info.id = entry.getKey();
1:                     for (Operation operation : entry.getValue()) {
1:                         info.track(operation);
1:                     }
1:                     infos.add(info);
1:                 }
1:             }
1:         }
/////////////////////////////////////////////////////////////////////////
0:     protected final Set<String> rolledBackAcks = new HashSet<String>();
/////////////////////////////////////////////////////////////////////////
0:     public void forgetRecoveredAcks(ArrayList<MessageAck> acks, boolean rollback) throws IOException {
0:                     final String id = ack.getLastMessageId().toProducerKey();
0:                     ackedAndPrepared.remove(id);
0:                     if (rollback) {
0:                         rolledBackAcks.add(id);
1:                     }
/////////////////////////////////////////////////////////////////////////
0:         public boolean alreadyDispatched(Long sequence) {
0:             return (cursor.highPriorityCursorPosition > 0 && cursor.highPriorityCursorPosition >= sequence) ||
0:                     (cursor.defaultCursorPosition > 0 && cursor.defaultCursorPosition >= sequence) ||
0:                     (cursor.lowPriorityCursorPosition > 0 && cursor.lowPriorityCursorPosition >= sequence);
1:         }
1: 
commit:f92d45b
/////////////////////////////////////////////////////////////////////////
0:                 LOG.warn("Duplicate message add attempt rejected. Destination: {}://{}, Message id: {}", command.getDestination().getType(), command.getDestination().getName(), command.getMessageId());
commit:06f24e2
/////////////////////////////////////////////////////////////////////////
1: 
1:                         if (checkForCorruptJournalFiles) {
1:                             // sanity check the index also
1:                             if (!entry.getValue().locationIndex.isEmpty(tx)) {
1:                                 if (entry.getValue().orderIndex.nextMessageId <= 0) {
1:                                     throw new IOException("Detected uninitialized orderIndex nextMessageId with pending messages for " + entry.getKey());
1:                                 }
1:                             }
1:                         }
author:Christopher L. Shannon (cshannon)
-------------------------------------------------------------------------------
commit:2731f04
/////////////////////////////////////////////////////////////////////////
1:                 if (enableSubscriptionStatistics && sd.ackPositions != null && location.getSize() != previousKeys.location.getSize()) {
/////////////////////////////////////////////////////////////////////////
1:     protected long getStoredMessageCount(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:         if (sd.ackPositions != null) {
1:             SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
1:             if (messageSequences != null) {
1:                 long result = messageSequences.rangeSize();
1:                 // if there's anything in the range the last value is always the nextMessage marker, so remove 1.
1:                 return result > 0 ? result - 1 : 0;
1:             }
1:     protected long getStoredMessageSize(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:         if (sd.ackPositions != null) {
1:             //grab the messages attached to this subscription
1:             SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
1: 
1:             if (messageSequences != null) {
1:                 Sequence head = messageSequences.getHead();
1:                 if (head != null) {
1:                     //get an iterator over the order index starting at the first unacked message
1:                     //and go over each message to add up the size
1:                     Iterator<Entry<Long, MessageKeys>> iterator = sd.orderIndex.iterator(tx,
1:                             new MessageOrderCursor(head.getFirst()));
1: 
1:                     while (iterator.hasNext()) {
1:                         Entry<Long, MessageKeys> entry = iterator.next();
1:                         locationSize += entry.getValue().location.getSize();
1:                     }
commit:0d824a8
/////////////////////////////////////////////////////////////////////////
1:     protected JournalDiskSyncStrategy journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS;
/////////////////////////////////////////////////////////////////////////
1:         manager.setJournalDiskSyncStrategy(journalDiskSyncStrategy);
/////////////////////////////////////////////////////////////////////////
1:      * @deprecated use {@link #getJournalDiskSyncStrategyEnum} or {@link #getJournalDiskSyncStrategy} instead
1:         return journalDiskSyncStrategy == JournalDiskSyncStrategy.ALWAYS;
/////////////////////////////////////////////////////////////////////////
1:             journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS;
1:             journalDiskSyncStrategy = JournalDiskSyncStrategy.NEVER;
1:     public JournalDiskSyncStrategy getJournalDiskSyncStrategyEnum() {
1:     public String getJournalDiskSyncStrategy() {
1:         return journalDiskSyncStrategy.name();
1:     }
1: 
1:         this.journalDiskSyncStrategy = JournalDiskSyncStrategy.valueOf(journalDiskSyncStrategy.trim().toUpperCase());
commit:1a59827
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.atomic.AtomicReference;
/////////////////////////////////////////////////////////////////////////
1:     //only set when using JournalDiskSyncStrategy.PERIODIC
1:     protected final AtomicReference<Location> lastAsyncJournalUpdate = new AtomicReference<>();
1: 
/////////////////////////////////////////////////////////////////////////
1:         private Location lastAsyncUpdate = null;
/////////////////////////////////////////////////////////////////////////
1:                         Location currentUpdate = lastAsyncJournalUpdate.get();
1:                         if (currentUpdate != null && !currentUpdate.equals(lastAsyncUpdate)) {
1:                             lastAsyncUpdate = currentUpdate;
1:                             if (LOG.isTraceEnabled()) {
1:                                 LOG.trace("Writing trace command to trigger journal sync");
1:                             }
1:                             store(new KahaTraceCommand(), true, null, null);
1:                         }
/////////////////////////////////////////////////////////////////////////
1:                 //Track the last async update so we know if we need to sync at the next checkpoint
1:                 if (!sync && journal.isJournalDiskSyncPeriodic()) {
1:                     lastAsyncJournalUpdate.set(location);
1:                 }
commit:dd0ed17
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.disk.journal.Journal.JournalDiskSyncStrategy;
/////////////////////////////////////////////////////////////////////////
0:     protected String journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS.name();
1:     long journalDiskSyncInterval = 1000;
/////////////////////////////////////////////////////////////////////////
1:                 long delay;
1:                 if (journal.isJournalDiskSyncPeriodic()) {
1:                     delay = Math.min(journalDiskSyncInterval > 0 ? journalDiskSyncInterval : checkpointInterval, 500);
1:                 } else {
1:                     delay = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
1:                 }
/////////////////////////////////////////////////////////////////////////
1:         private long lastSync = System.currentTimeMillis();
/////////////////////////////////////////////////////////////////////////
1:                     if (journal.isJournalDiskSyncPeriodic() &&
1:                             journalDiskSyncInterval > 0 && (now - lastSync >= journalDiskSyncInterval)) {
0:                         journal.syncCurrentDataFile();
1:                         lastSync = now;
1:                     }
/////////////////////////////////////////////////////////////////////////
0:         manager.setJournalDiskSyncStrategy(
0:                 Journal.JournalDiskSyncStrategy.valueOf(journalDiskSyncStrategy.trim().toUpperCase()));
/////////////////////////////////////////////////////////////////////////
1:     /**
0:      * @deprecated use {@link #getJournalDiskSyncStrategy} instead
1:      * @return
1:      */
0:         return journalDiskSyncStrategy != null && JournalDiskSyncStrategy.ALWAYS.name().equals(
0:                 journalDiskSyncStrategy.trim().toUpperCase());
1:     /**
1:      * @deprecated use {@link #setEnableJournalDiskSyncs} instead
1:      * @param syncWrites
1:      */
1:         if (syncWrites) {
0:             journalDiskSyncStrategy = JournalDiskSyncStrategy.ALWAYS.name();
1:         } else {
0:             journalDiskSyncStrategy = JournalDiskSyncStrategy.NEVER.name();
1:         }
1:     }
1: 
0:     public String getJournalDiskSyncStrategy() {
1:         return journalDiskSyncStrategy;
1:     }
1: 
1:     public void setJournalDiskSyncStrategy(String journalDiskSyncStrategy) {
0:         this.journalDiskSyncStrategy = journalDiskSyncStrategy;
1:     }
1: 
1:     public long getJournalDiskSyncInterval() {
1:         return journalDiskSyncInterval;
1:     }
1: 
1:     public void setJournalDiskSyncInterval(long journalDiskSyncInterval) {
1:         this.journalDiskSyncInterval = journalDiskSyncInterval;
commit:cf3d419
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.MessageStoreSubscriptionStatistics;
1: import org.apache.activemq.store.TopicMessageStore;
/////////////////////////////////////////////////////////////////////////
1:     private boolean enableSubscriptionStatistics = false;
/////////////////////////////////////////////////////////////////////////
1:                     addAckLocationForNewMessage(tx, command.getDestination(), sd, id);
/////////////////////////////////////////////////////////////////////////
1:                 //update all the subscription metrics
0:                 if (enableSubscriptionStatistics && location.getSize() != previousKeys.location.getSize()) {
1:                     Iterator<Entry<String, SequenceSet>> iter = sd.ackPositions.iterator(tx);
1:                     while (iter.hasNext()) {
1:                         Entry<String, SequenceSet> e = iter.next();
1:                         if (e.getValue().contains(id)) {
1:                             incrementAndAddSizeToStoreStat(key(command.getDestination()), e.getKey(), location.getSize());
1:                             decrementAndSubSizeToStoreStat(key(command.getDestination()), e.getKey(), previousKeys.location.getSize());
1:                         }
1:                     }
1:                 }
1: 
/////////////////////////////////////////////////////////////////////////
1:             MessageStoreSubscriptionStatistics subStats = getSubStats(key(command.getDestination()));
1:             if (subStats != null) {
1:                 subStats.removeSubscription(subscriptionKey);
1:             }
/////////////////////////////////////////////////////////////////////////
1:         String key = key(kahaDestination);
1:         MessageStoreStatistics storeStats = getStoreStats(key);
1:         MessageStoreSubscriptionStatistics subStats = getSubStats(key);
1:         if (subStats != null) {
1:             subStats.reset();
1:         }
/////////////////////////////////////////////////////////////////////////
1:     protected void incrementAndAddSizeToStoreStat(KahaDestination kahaDestination, String subKey, long size) {
1:         incrementAndAddSizeToStoreStat(key(kahaDestination), subKey, size);
1:     }
1: 
1:     protected void incrementAndAddSizeToStoreStat(String kahaDestKey, String subKey, long size) {
1:         if (enableSubscriptionStatistics) {
1:             MessageStoreSubscriptionStatistics subStats = getSubStats(kahaDestKey);
1:             if (subStats != null && subKey != null) {
1:                 subStats.getMessageCount(subKey).increment();
1:                 if (size > 0) {
1:                     subStats.getMessageSize(subKey).addSize(size);
1:                 }
1:             }
1:         }
1:     }
1: 
1: 
1:     protected void decrementAndSubSizeToStoreStat(String kahaDestKey, String subKey, long size) {
1:         if (enableSubscriptionStatistics) {
1:             MessageStoreSubscriptionStatistics subStats = getSubStats(kahaDestKey);
1:             if (subStats != null && subKey != null) {
1:                 subStats.getMessageCount(subKey).decrement();
1:                 if (size > 0) {
1:                     subStats.getMessageSize(subKey).addSize(-size);
1:                 }
1:             }
1:         }
1:     }
1: 
1:     protected void decrementAndSubSizeToStoreStat(KahaDestination kahaDestination, String subKey, long size) {
1:         decrementAndSubSizeToStoreStat(key(kahaDestination), subKey, size);
1:     }
1: 
1:      * This is a map to cache MessageStores for a specific
/////////////////////////////////////////////////////////////////////////
1:     protected MessageStoreSubscriptionStatistics getSubStats(String kahaDestKey) {
1:         MessageStoreSubscriptionStatistics subStats = null;
1:         try {
1:             MessageStore messageStore = storeCache.get(kahaDestKey);
1:             if (messageStore instanceof TopicMessageStore) {
1:                 subStats = ((TopicMessageStore)messageStore).getMessageStoreSubStatistics();
1:             }
1:         } catch (Exception e1) {
1:              LOG.error("Getting size counter of destination failed", e1);
1:         }
1: 
1:         return subStats;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     private void addAckLocationForNewMessage(Transaction tx, KahaDestination kahaDest,
1:             StoredDestination sd, Long messageSequence) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:             MessageKeys key = sd.orderIndex.get(tx, messageSequence);
1:             incrementAndAddSizeToStoreStat(kahaDest, subscriptionKey,
1:                     key.location.getSize());
1: 
/////////////////////////////////////////////////////////////////////////
1:                 MessageKeys key = sd.orderIndex.get(tx, messageSequence);
1:                 decrementAndSubSizeToStoreStat(command.getDestination(), subscriptionKey,
1:                         key.location.getSize());
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * @return
1:      */
1:     public boolean isEnableSubscriptionStatistics() {
1:         return enableSubscriptionStatistics;
1:     }
1: 
1:     /**
1:      * Enable caching statistics for each subscription to allow non-blocking
1:      * retrieval of metrics.  This could incur some overhead to compute if there are a lot
1:      * of subscriptions.
1:      *
1:      * @param enableSubscriptionStatistics
1:      */
1:     public void setEnableSubscriptionStatistics(boolean enableSubscriptionStatistics) {
1:         this.enableSubscriptionStatistics = enableSubscriptionStatistics;
1:     }
commit:a5050a8
/////////////////////////////////////////////////////////////////////////
1: 
1:             if (previousKeys != null) {
1:                 //Remove the existing from the size
1: 
0:                 // on first update previous is original location, on recovery/replay it may be the updated location
1:                 if(!previousKeys.location.equals(location)) {
0:                     sd.locationIndex.remove(tx, previousKeys.location);
1:                 }
commit:4d6cc4b
/////////////////////////////////////////////////////////////////////////
1:         // Mark the current journal file as a compacted file so that gc checks can skip
1:         // over logs that are smaller compaction type logs.
1:         DataFile current = journal.getDataFileById(location.getDataFileId());
1:         current.setTypeCode(command.getRewriteType());
1: 
1:         if (completeFileSet.contains(command.getSourceDataFileId()) && command.getSkipIfSourceExists()) {
/////////////////////////////////////////////////////////////////////////
1:         forwardsFile.setTypeCode(COMPACTED_JOURNAL_FILE);
/////////////////////////////////////////////////////////////////////////
1:             compactionMarker.setRewriteType(forwardsFile.getTypeCode());
commit:c8a6171
/////////////////////////////////////////////////////////////////////////
1:             //flag to know whether the ack forwarding completed without an exception
1:             boolean forwarded = false;
1: 
/////////////////////////////////////////////////////////////////////////
1:                 checkpointLock.readLock().lock();
/////////////////////////////////////////////////////////////////////////
1:                     forwarded = true;
1:                     LOG.error("Forwarding of acks failed", ioe);
1:                     LOG.error("Forwarding of acks failed", e);
1:                 checkpointLock.readLock().unlock();
1:             }
1: 
1:             try {
1:                 if (forwarded) {
1:                     // Checkpoint with changes from the ackMessageFileMap
1:                     checkpointUpdate(false);
1:                 }
1:             } catch (IOException ioe) {
1:                 LOG.error("Checkpoint failed", ioe);
1:                 brokerService.handleIOException(ioe);
1:             } catch (Throwable e) {
1:                 LOG.error("Checkpoint failed", e);
1:                 brokerService.handleIOException(IOExceptionSupport.create(e));
commit:e53e340
/////////////////////////////////////////////////////////////////////////
1:                 //acquire the checkpoint lock to prevent other threads from
1:                 //running a checkpoint while this is running
1:                 //
1:                 //Normally this task runs on the same executor as the checkpoint task
1:                 //so this ack compaction runner wouldn't run at the same time as the checkpoint task.
1:                 //
1:                 //However, there are two cases where this isn't always true.
1:                 //First, the checkpoint() method is public and can be called through the
1:                 //PersistenceAdapter interface by someone at the same time this is running.
1:                 //Second, a checkpoint is called during shutdown without using the executor.
1:                 //
1:                 //In the future it might be better to just remove the checkpointLock entirely
1:                 //and only use the executor but this would need to be examined for any unintended
1:                 //consequences
1:                 checkpointLock.writeLock().lock();
1: 
1:                 try {
1: 
1:                     // Lock index to capture the ackMessageFileMap data
1:                     indexLock.writeLock().lock();
1: 
0:                     // Map keys might not be sorted, find the earliest log file to forward acks
0:                     // from and move only those, future cycles can chip away at more as needed.
0:                     // We won't move files that are themselves rewritten on a previous compaction.
0:                     List<Integer> journalFileIds = new ArrayList<Integer>(metadata.ackMessageFileMap.keySet());
0:                     Collections.sort(journalFileIds);
0:                     for (Integer journalFileId : journalFileIds) {
0:                         DataFile current = journal.getDataFileById(journalFileId);
0:                         if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
0:                             journalToAdvance = journalFileId;
1:                             break;
1:                         }
1: 
0:                     // Check if we found one, or if we only found the current file being written to.
0:                     if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:                         return;
1:                     }
1: 
0:                     journalLogsReferenced.addAll(metadata.ackMessageFileMap.get(journalToAdvance));
1: 
1:                 } finally {
0:                     indexLock.writeLock().unlock();
1:                 try {
1:                     // Background rewrite of the old acks
1:                     forwardAllAcks(journalToAdvance, journalLogsReferenced);
1: 
0:                     // Checkpoint with changes from the ackMessageFileMap
0:                     checkpointUpdate(false);
1:                 } catch (IOException ioe) {
1:                     LOG.error("Checkpoint failed", ioe);
1:                     brokerService.handleIOException(ioe);
1:                 } catch (Throwable e) {
1:                     LOG.error("Checkpoint failed", e);
1:                     brokerService.handleIOException(IOExceptionSupport.create(e));
1:                 checkpointLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:             Location nextLocation = getNextLocationForAckForward(new Location(journalToRead, 0));
/////////////////////////////////////////////////////////////////////////
0:                 nextLocation = getNextLocationForAckForward(nextLocation);
/////////////////////////////////////////////////////////////////////////
0:     private Location getNextLocationForAckForward(final Location nextLocation) {
1:         //getNextLocation() can throw an IOException, we should handle it and set
1:         //nextLocation to null and abort gracefully
1:         //Should not happen in the normal case
1:         Location location = null;
1:         try {
0:             location = journal.getNextLocation(nextLocation);
1:         } catch (IOException e) {
0:             LOG.warn("Failed to load next journal location: {}", e.getMessage());
1:             if (LOG.isDebugEnabled()) {
0:                 LOG.debug("Failed to load next journal location", e);
1:             }
1:         }
1:         return location;
1:     }
1: 
commit:9121301
/////////////////////////////////////////////////////////////////////////
1:             if (scheduler == null || scheduler.isShutdown()) {
commit:7bdcca1
/////////////////////////////////////////////////////////////////////////
1:             synchronized(schedulerLock) {
1:                 if (scheduler != null) {
1:                     ThreadPoolUtils.shutdownGraceful(scheduler, -1);
1:                     scheduler = null;
1:                 }
1:             }
commit:db3f8b3
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.activemq.store.kahadb.disk.journal.Location.NOT_SET;
1: 
/////////////////////////////////////////////////////////////////////////
0:             ThreadPoolUtils.shutdownGraceful(scheduler, -1);
/////////////////////////////////////////////////////////////////////////
0:             Location afterProducerAudit = recoverProducerAudit();
0:             Location afterAckMessageFile = recoverAckMessageFileMap();
0:             if (afterProducerAudit != null && afterProducerAudit.equals(metadata.ackMessageFileMapLocation)) {
0:                 // valid checkpoint, possible recover from afterAckMessageFile
0:                 afterProducerAudit = null;
1:             }
0:             Location recoveryPosition = minimum(afterProducerAudit, afterAckMessageFile);
/////////////////////////////////////////////////////////////////////////
0:     private Location minimum(Location x,
0:                              Location y) {
0:         if (x != null) {
0:             min = x;
0:             if (y != null) {
0:                 int compare = y.compareTo(x);
0:                 if (compare < 0) {
0:                     min = y;
1:                 }
0:             min = y;
/////////////////////////////////////////////////////////////////////////
0:                 return getNextInitializedLocation(metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
0:                 return getNextInitializedLocation(metadata.ackMessageFileMapLocation);
/////////////////////////////////////////////////////////////////////////
0:                 return getNextInitializedLocation(metadata.lastUpdate);
0:     private Location getNextInitializedLocation(Location location) throws IOException {
0:         Location mayNotBeInitialized = journal.getNextLocation(location);
0:         if (location.getSize() == NOT_SET && mayNotBeInitialized.getSize() != NOT_SET) {
0:             // need to init size and type to skip
0:             return journal.getNextLocation(mayNotBeInitialized);
1:         } else {
0:             return mayNotBeInitialized;
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1: 
0:             int journalToAdvance = -1;
0:             Set<Integer> journalLogsReferenced = new HashSet<Integer>();
1: 
1:             try {
0:                 // Map keys might not be sorted, find the earliest log file to forward acks
0:                 // from and move only those, future cycles can chip away at more as needed.
0:                 // We won't move files that are themselves rewritten on a previous compaction.
0:                 List<Integer> journalFileIds = new ArrayList<Integer>(metadata.ackMessageFileMap.keySet());
0:                 Collections.sort(journalFileIds);
0:                 for (Integer journalFileId : journalFileIds) {
0:                     DataFile current = journal.getDataFileById(journalFileId);
0:                     if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
0:                         journalToAdvance = journalFileId;
1:                         break;
1:                     }
1: 
0:                 // Check if we found one, or if we only found the current file being written to.
0:                 if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:                     return;
1:                 }
1: 
0:                 journalLogsReferenced.addAll(metadata.ackMessageFileMap.get(journalToAdvance));
1: 
1:             } finally {
0:                 indexLock.writeLock().unlock();
commit:60b0c4f
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             synchronized(schedulerLock) {
0:                 if (scheduler != null) {
0:                     ThreadPoolUtils.shutdownGraceful(scheduler, -1);
0:                     scheduler = null;
1:                 }
1:             }
/////////////////////////////////////////////////////////////////////////
0:             Location producerAuditPosition = recoverProducerAudit();
0:             Location ackMessageFileLocation = recoverAckMessageFileMap();
0:             Location recoveryPosition = minimum(producerAuditPosition, ackMessageFileLocation);
/////////////////////////////////////////////////////////////////////////
0:     private Location minimum(Location producerAuditPosition,
0:             Location lastIndoubtPosition) {
0:         if (producerAuditPosition != null) {
0:             min = producerAuditPosition;
0:             if (lastIndoubtPosition != null && lastIndoubtPosition.compareTo(producerAuditPosition) < 0) {
0:                 min = lastIndoubtPosition;
0:             min = lastIndoubtPosition;
/////////////////////////////////////////////////////////////////////////
0:                 return journal.getNextLocation(metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
0:                 return journal.getNextLocation(metadata.ackMessageFileMapLocation);
/////////////////////////////////////////////////////////////////////////
0:                 return journal.getNextLocation(metadata.lastUpdate);
/////////////////////////////////////////////////////////////////////////
0:             // Map keys might not be sorted, find the earliest log file to forward acks
0:             // from and move only those, future cycles can chip away at more as needed.
0:             // We won't move files that are themselves rewritten on a previous compaction.
0:             List<Integer> journalFileIds = new ArrayList<Integer>(metadata.ackMessageFileMap.keySet());
0:             Collections.sort(journalFileIds);
0:             int journalToAdvance = -1;
0:             for (Integer journalFileId : journalFileIds) {
0:                 DataFile current = journal.getDataFileById(journalFileId);
0:                 if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
0:                     journalToAdvance = journalFileId;
1:                     break;
0:             // Check if we found one, or if we only found the current file being written to.
0:             if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:                 return;
1:             }
1: 
0:             Set<Integer> journalLogsReferenced =
0:                 new HashSet<Integer>(metadata.ackMessageFileMap.get(journalToAdvance));
1: 
0:             indexLock.writeLock().unlock();
1: 
commit:cbad8ba
/////////////////////////////////////////////////////////////////////////
1:     private boolean enableAckCompaction = true;
/////////////////////////////////////////////////////////////////////////
1:             } else if (isEnableAckCompaction()) {
/////////////////////////////////////////////////////////////////////////
1: 
1:     /**
1:      * Returns whether Ack compaction is enabled
1:      *
1:      * @return enableAckCompaction
1:      */
1:     public boolean isEnableAckCompaction() {
1:         return enableAckCompaction;
1:     }
1: 
1:     /**
1:      * Configure if the Ack compaction task should be enabled to run
1:      *
1:      * @param enableAckCompaction
1:      */
1:     public void setEnableAckCompaction(boolean enableAckCompaction) {
1:         this.enableAckCompaction = enableAckCompaction;
1:     }
commit:25ff569
/////////////////////////////////////////////////////////////////////////
0:         //grab the messages attached to this subscription
1: 
0:             Sequence head = messageSequences.getHead();
0:             if (head != null) {
0:                 //get an iterator over the order index starting at the first unacked message
0:                 //and go over each message to add up the size
0:                 Iterator<Entry<Long, MessageKeys>> iterator = sd.orderIndex.iterator(tx,
0:                         new MessageOrderCursor(head.getFirst()));
1:                     Entry<Long, MessageKeys> entry = iterator.next();
0:                     locationSize += entry.getValue().location.getSize();
1: 
commit:b4aa53d
/////////////////////////////////////////////////////////////////////////
1:             //Add the message if it can't be found
1:             this.updateIndex(tx, command, location);
commit:246ccb8
/////////////////////////////////////////////////////////////////////////
1:     protected class MessageKeysMarshaller extends VariableMarshaller<MessageKeys> {
1:         final LocationSizeMarshaller locationSizeMarshaller = new LocationSizeMarshaller();
1:             return new MessageKeys(dataIn.readUTF(), locationSizeMarshaller.readPayload(dataIn));
1:             locationSizeMarshaller.writePayload(object.location, dataOut);
/////////////////////////////////////////////////////////////////////////
1:             //upgrade the order index
1:             for (Iterator<Entry<Long, MessageKeys>> iterator = rc.orderIndex.iterator(tx); iterator.hasNext(); ) {
0:                 Entry<Long, MessageKeys> entry = iterator.next();
1:                 //call get so that the last priority is updated
1:                 rc.orderIndex.get(tx, entry.getKey());
1:                 rc.orderIndex.put(tx, rc.orderIndex.lastGetPriority(), entry.getKey(), entry.getValue());
1:             }
/////////////////////////////////////////////////////////////////////////
1:         final MessageKeysMarshaller messageKeysMarshaller = new MessageKeysMarshaller();
/////////////////////////////////////////////////////////////////////////
1:             defaultPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:             lowPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:             highPriorityIndex.setValueMarshaller(messageKeysMarshaller);
commit:7a7c70a
/////////////////////////////////////////////////////////////////////////
1:                 //The metadata was recreated after a detect corruption so we need to
1:                 //reconfigure anything that was configured on the old metadata on startup
1:                 configureMetadata();
/////////////////////////////////////////////////////////////////////////
1:     protected abstract void configureMetadata();
1: 
commit:8f30866
/////////////////////////////////////////////////////////////////////////
1:                 if (keys != null) {
1:                     sd.locationIndex.remove(tx, keys.location);
1:                     sd.messageIdIndex.remove(tx, keys.messageId);
1:                     metadata.producerSequenceIdTracker.rollback(keys.messageId);
1:                     undoCounter++;
1:                     decrementAndSubSizeToStoreStat(key, keys.location.getSize());
1:                     // TODO: do we need to modify the ack positions for the pub sub case?
1:                 }
commit:e07809d
/////////////////////////////////////////////////////////////////////////
0:             //clear the cache and journalSize on shutdown of the store
1:             journalSize.set(0);
commit:734fb7d
/////////////////////////////////////////////////////////////////////////
0:     public long getStoredMessageSize(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
0:         SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
1:         long locationSize = 0;
0:         if (messageSequences != null) {
0:             Iterator<Long> sequences = messageSequences.iterator();
1: 
0:             while (sequences.hasNext()) {
0:                 Long sequenceId = sequences.next();
0:                 //the last item is the next marker
0:                 if (!sequences.hasNext()) {
1:                     break;
1:                 }
0:                 Iterator<Entry<Location, Long>> iterator = sd.locationIndex.iterator(tx);
1:                 while (iterator.hasNext()) {
1:                     Entry<Location, Long> entry = iterator.next();
0:                     if (entry.getValue() == sequenceId - 1) {
0:                         locationSize += entry.getKey().getSize();
1:                         break;
1:                     }
1: 
1:                 }
1:             }
1:         }
1: 
1:         return locationSize;
1:     }
commit:b52796f
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.ConcurrentMap;
/////////////////////////////////////////////////////////////////////////
1:     protected final ConcurrentMap<String, MessageStore> storeCache =
commit:8871b0e
/////////////////////////////////////////////////////////////////////////
1:         final MessageKeysMarshaller messageKeysMarshaller = new MessageKeysMarshaller();
/////////////////////////////////////////////////////////////////////////
1:         //go through an upgrade old index if older than version 6
1:         if (metadata.version < 6) {
1:             for (Iterator<Entry<Location, Long>> iterator = rc.locationIndex.iterator(tx); iterator.hasNext(); ) {
0:                 Entry<Location, Long> entry = iterator.next();
1:                 // modify so it is upgraded
1:                 rc.locationIndex.put(tx, entry.getKey(), entry.getValue());
1:             }
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Locate the storeMessageSize counter for this KahaDestination
1:      * @param kahaDestination
1:      * @return
1:      */
1:     protected MessageStoreStatistics getStoreStats(String kahaDestKey) {
1:         MessageStoreStatistics storeStats = null;
1:         try {
1:             MessageStore messageStore = storeCache.get(kahaDestKey);
1:             if (messageStore != null) {
1:                 storeStats = messageStore.getMessageStoreStatistics();
1:             }
1:         } catch (Exception e1) {
1:              LOG.error("Getting size counter of destination failed", e1);
1:         }
1:         return storeStats;
1:     }
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
1:         @Override
commit:785b16b
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.ConcurrentHashMap;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.broker.region.Destination;
1: import org.apache.activemq.broker.region.Queue;
1: import org.apache.activemq.broker.region.Topic;
1: import org.apache.activemq.store.MessageStore;
1: import org.apache.activemq.store.MessageStoreStatistics;
/////////////////////////////////////////////////////////////////////////
1:     static final int VERSION = 6;
/////////////////////////////////////////////////////////////////////////
1:         for (String key : storedDestinations.keySet()) {
1:             StoredDestination sd = storedDestinations.get(key);
/////////////////////////////////////////////////////////////////////////
0:                 decrementAndSubSizeToStoreStat(key, keys.location.getSize());
/////////////////////////////////////////////////////////////////////////
1:                             decrementAndSubSizeToStoreStat(sdEntry.getKey(), keys.location.getSize());
/////////////////////////////////////////////////////////////////////////
1:                 incrementAndAddSizeToStoreStat(command.getDestination(), location.getSize());
/////////////////////////////////////////////////////////////////////////
1: 
0:        return id;
/////////////////////////////////////////////////////////////////////////
1:             incrementAndAddSizeToStoreStat(command.getDestination(), location.getSize());
1:                 decrementAndSubSizeToStoreStat(command.getDestination(), previousKeys.location.getSize());
/////////////////////////////////////////////////////////////////////////
1:                     decrementAndSubSizeToStoreStat(command.getDestination(), keys.location.getSize());
/////////////////////////////////////////////////////////////////////////
1:                 removeAckLocation(command, tx, sd, subscriptionKey, sequence);
/////////////////////////////////////////////////////////////////////////
1:         clearStoreStats(command.getDestination());
1:         storeCache.remove(key(command.getDestination()));
/////////////////////////////////////////////////////////////////////////
1:             removeAckLocationsForSub(command, tx, sd, subscriptionKey);
1:                 clearStoreStats(command.getDestination());
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:     	final MessageKeysMarshaller messageKeysMarshaller = new MessageKeysMarshaller();
1: 
/////////////////////////////////////////////////////////////////////////
1:                         value.orderIndex.lowPriorityIndex.setValueMarshaller(messageKeysMarshaller);
1:                         value.orderIndex.highPriorityIndex.setValueMarshaller(messageKeysMarshaller);
/////////////////////////////////////////////////////////////////////////
1:         rc.locationIndex.setKeyMarshaller(new LocationSizeMarshaller());
/////////////////////////////////////////////////////////////////////////
1:     /**
1:      * Clear the counter for the destination, if one exists.
1:      *
1:      * @param kahaDestination
1:      */
1:     protected void clearStoreStats(KahaDestination kahaDestination) {
0:         MessageStoreStatistics storeStats = getStoreStats(key(kahaDestination));
1:         if (storeStats != null) {
1:             storeStats.reset();
1:         }
1:     }
1: 
1:     /**
1:      * Update MessageStoreStatistics
1:      *
1:      * @param kahaDestination
1:      * @param size
1:      */
1:     protected void incrementAndAddSizeToStoreStat(KahaDestination kahaDestination, long size) {
1:         incrementAndAddSizeToStoreStat(key(kahaDestination), size);
1:     }
1: 
1:     protected void incrementAndAddSizeToStoreStat(String kahaDestKey, long size) {
1:         MessageStoreStatistics storeStats = getStoreStats(kahaDestKey);
1:         if (storeStats != null) {
1:             storeStats.getMessageCount().increment();
1:             if (size > 0) {
1:                 storeStats.getMessageSize().addSize(size);
1:             }
1:         }
1:     }
1: 
1:     protected void decrementAndSubSizeToStoreStat(KahaDestination kahaDestination, long size) {
1:         decrementAndSubSizeToStoreStat(key(kahaDestination), size);
1:     }
1: 
1:     protected void decrementAndSubSizeToStoreStat(String kahaDestKey, long size) {
1:         MessageStoreStatistics storeStats = getStoreStats(kahaDestKey);
1:         if (storeStats != null) {
1:             storeStats.getMessageCount().decrement();
1:             if (size > 0) {
1:                 storeStats.getMessageSize().addSize(-size);
1:             }
1:         }
1:     }
1: 
1:     /**
0:      * This is a map to cache DestinationStatistics for a specific
1:      * KahaDestination key
1:      */
0:     protected final Map<String, MessageStore> storeCache =
0:             new ConcurrentHashMap<String, MessageStore>();
1: 
1: 	/**
0: 	 * Locate the storeMessageSize counter for this KahaDestination
1: 	 * @param kahaDestination
1: 	 * @return
1: 	 */
0: 	protected MessageStoreStatistics getStoreStats(String kahaDestKey) {
0: 	    MessageStoreStatistics storeStats = null;
1: 		try {
0: 		    MessageStore messageStore = storeCache.get(kahaDestKey);
0: 		    if (messageStore != null) {
0: 		        storeStats = messageStore.getMessageStoreStatistics();
1: 		    }
0: 		} catch (Exception e1) {
0: 			 LOG.error("Getting size counter of destination failed", e1);
1: 		}
1: 
0: 		return storeStats;
1: 	}
1: 
1:     /**
1:      * Determine whether this Destination matches the DestinationType
1:      *
1:      * @param destination
1:      * @param type
1:      * @return
1:      */
1:     protected boolean matchType(Destination destination,
1:             KahaDestination.DestinationType type) {
1:         if (destination instanceof Topic
1:                 && type.equals(KahaDestination.DestinationType.TOPIC)) {
1:             return true;
1:         } else if (destination instanceof Queue
1:                 && type.equals(KahaDestination.DestinationType.QUEUE)) {
1:             return true;
1:         }
1:         return false;
1:     }
1: 
1:     class LocationSizeMarshaller implements Marshaller<Location> {
1: 
1:         public LocationSizeMarshaller() {
1: 
1:         }
1: 
1:         public Location readPayload(DataInput dataIn) throws IOException {
1:             Location rc = new Location();
1:             rc.setDataFileId(dataIn.readInt());
1:             rc.setOffset(dataIn.readInt());
1:             if (metadata.version >= 6) {
1:                 rc.setSize(dataIn.readInt());
1:             }
1:             return rc;
1:         }
1: 
1:         public void writePayload(Location object, DataOutput dataOut)
1:                 throws IOException {
1:             dataOut.writeInt(object.getDataFileId());
1:             dataOut.writeInt(object.getOffset());
1:             dataOut.writeInt(object.getSize());
1:         }
1: 
1:         public int getFixedSize() {
1:             return 12;
1:         }
1: 
1:         public Location deepCopy(Location source) {
1:             return new Location(source);
1:         }
1: 
1:         public boolean isDeepCopySupported() {
1:             return true;
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     private void removeAckLocationsForSub(KahaSubscriptionCommand command,
1:             Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:                     decrementAndSubSizeToStoreStat(command.getDestination(), entry.getValue().location.getSize());
/////////////////////////////////////////////////////////////////////////
1:     private void removeAckLocation(KahaRemoveMessageCommand command,
1:             Transaction tx, StoredDestination sd, String subscriptionKey,
1:             Long messageSequence) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:                     decrementAndSubSizeToStoreStat(command.getDestination(), entry.getValue().location.getSize());
author:Timothy Bish
-------------------------------------------------------------------------------
commit:281d600
/////////////////////////////////////////////////////////////////////////
1:         protected transient Map<Integer, Set<Integer>> ackMessageFileMap = new HashMap<>();
1:             destinations = new BTreeIndex<>(pageFile, is.readLong());
/////////////////////////////////////////////////////////////////////////
1:                         metadata.destinations = new BTreeIndex<>(pageFile, tx.allocate().getPageId());
/////////////////////////////////////////////////////////////////////////
1:             IOHelper.mkdirs(directory);
/////////////////////////////////////////////////////////////////////////
1:         if (opened.compareAndSet(true, false)) {
/////////////////////////////////////////////////////////////////////////
1:         HashMap<KahaDestination, opCount> destinationOpCount = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:         ArrayList<TranInfo> infos = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:             Set<TransactionId> toRollback = new HashSet<>();
1:             Set<TransactionId> toDiscard = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:             final ArrayList<Long> matches = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:         HashSet<Integer> missingJournalFiles = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:         ArrayList<BTreeVisitor.Predicate<Location>> knownCorruption = new ArrayList<>();
1:         ArrayList<BTreeVisitor.Predicate<Location>> missingPredicates = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:                         new BTreeVisitor.BetweenVisitor<>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
/////////////////////////////////////////////////////////////////////////
1:                 final LinkedHashMap<Long, Location> matches = new LinkedHashMap<>();
/////////////////////////////////////////////////////////////////////////
1:         final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
/////////////////////////////////////////////////////////////////////////
1:     private final HashSet<Integer> journalFilesBeingReplicated = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:             referenceFileIds = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:             final TreeSet<Integer> completeFileSet = new TreeSet<>(journal.getFileMap().keySet());
0:             final TreeSet<Integer> gcCandidateSet = new TreeSet<>(completeFileSet);
/////////////////////////////////////////////////////////////////////////
1:             Set<Integer> journalLogsReferenced = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:                     List<Integer> journalFileIds = new ArrayList<>(metadata.ackMessageFileMap.keySet());
/////////////////////////////////////////////////////////////////////////
1:         Map<Integer, Set<Integer>> updatedAckLocations = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:                 referenceFileIds = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:     protected final HashMap<String, StoredDestination> storedDestinations = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:         final TreeMap<Long, Long> messageReferences = new TreeMap<>();
1:         final HashSet<String> subscriptionCache = new LinkedHashSet<>();
/////////////////////////////////////////////////////////////////////////
1:             value.orderIndex.defaultPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:             value.locationIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:             value.messageIdIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:                 value.subscriptions = new BTreeIndex<>(pageFile, dataIn.readLong());
1:                 value.subscriptionAcks = new BTreeIndex<>(pageFile, dataIn.readLong());
1:                     value.ackPositions = new ListIndex<>(pageFile, dataIn.readLong());
1:                             LinkedHashMap<String, SequenceSet> temp = new LinkedHashMap<>();
1:                                         new BTreeIndex<>(pageFile, dataIn.readLong());
/////////////////////////////////////////////////////////////////////////
1:                             value.ackPositions = new ListIndex<>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:                     value.subLocations = new ListIndex<>(pageFile, dataIn.readLong());
1:                             value.subLocations = new ListIndex<>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:                 value.orderIndex.lowPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:                 value.orderIndex.highPriorityIndex = new BTreeIndex<>(pageFile, dataIn.readLong());
1:                         value.orderIndex.lowPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:                         value.orderIndex.highPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:             rc.locationIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:             rc.messageIdIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:                 rc.subscriptions = new BTreeIndex<>(pageFile, tx.allocate());
1:                 rc.subscriptionAcks = new BTreeIndex<>(pageFile, tx.allocate());
1:                 rc.ackPositions = new ListIndex<>(pageFile, tx.allocate());
1:                 rc.subLocations = new ListIndex<>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:             rc.subscriptionCursors = new HashMap<>();
/////////////////////////////////////////////////////////////////////////
1:             new ConcurrentHashMap<>();
/////////////////////////////////////////////////////////////////////////
1:             ArrayList<Long> unreferenced = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<>();
/////////////////////////////////////////////////////////////////////////
1:     private final LinkedHashMap<TransactionId, List<Operation>> inflightTransactions = new LinkedHashMap<>();
1:     protected final LinkedHashMap<TransactionId, List<Operation>> preparedTransactions = new LinkedHashMap<>();
0:     protected final Set<String> ackedAndPrepared = new HashSet<>();
0:     protected final Set<String> rolledBackAcks = new HashSet<>();
/////////////////////////////////////////////////////////////////////////
1:     @Deprecated
/////////////////////////////////////////////////////////////////////////
1:     @Deprecated
/////////////////////////////////////////////////////////////////////////
1:         final List<Long> pendingAdditions = new LinkedList<>();
/////////////////////////////////////////////////////////////////////////
1:             defaultPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:                 lowPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:                 highPriorityIndex = new BTreeIndex<>(pageFile, tx.allocate());
1:             TreeSet<Long> orderedSet = new TreeSet<>();
commit:8cc5c56
/////////////////////////////////////////////////////////////////////////
1:             startCheckpoint();
commit:15405af
/////////////////////////////////////////////////////////////////////////
0: import static org.apache.activemq.store.kahadb.disk.journal.Location.NOT_SET;
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
/////////////////////////////////////////////////////////////////////////
1:                     Location location = appender.storeItem(payload, Journal.USER_RECORD_TYPE, false);
commit:946e62d
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.Executors;
1: import java.util.concurrent.ScheduledExecutorService;
1: import java.util.concurrent.ThreadFactory;
1: import java.util.concurrent.TimeUnit;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.data.KahaRewrittenDataFileCommand;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.disk.journal.TargetedDataFileAppender;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.util.IOExceptionSupport;
1: import org.apache.activemq.util.ThreadPoolUtils;
/////////////////////////////////////////////////////////////////////////
1:     static final byte COMPACTED_JOURNAL_FILE = DataFile.STANDARD_LOG_FILE + 1;
1: 
/////////////////////////////////////////////////////////////////////////
1:     protected ScheduledExecutorService scheduler;
1:     private final Object schedulerLock = new Object();
1: 
0:     protected boolean enableJournalDiskSyncs = true;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     private int compactAcksAfterNoGC = 10;
1:     private boolean compactAcksIgnoresStoreGrowth = false;
1:     private int checkPointCyclesWithNoGC;
1:     private int journalLogOnLastCompactionCheck;
1: 
/////////////////////////////////////////////////////////////////////////
1:         if (checkpointInterval == 0 && cleanupInterval == 0) {
1:         synchronized (schedulerLock) {
0:             if (scheduler == null) {
1:                 scheduler = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() {
1:                     @Override
1:                     public Thread newThread(Runnable r) {
1:                         Thread schedulerThread = new Thread(r);
1: 
1:                         schedulerThread.setName("ActiveMQ Journal Checkpoint Worker");
1:                         schedulerThread.setDaemon(true);
1: 
1:                         return schedulerThread;
1:                     }
1:                 });
1: 
1:                 // Short intervals for check-point and cleanups
0:                 long delay = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
1: 
1:                 scheduler.scheduleWithFixedDelay(new CheckpointRunner(), 0, delay, TimeUnit.MILLISECONDS);
1:             }
1:         }
1:     }
1: 
1:     private final class CheckpointRunner implements Runnable {
1: 
1:         private long lastCheckpoint = System.currentTimeMillis();
1:         private long lastCleanup = System.currentTimeMillis();
1: 
1:         @Override
1:         public void run() {
1:             try {
1:                 // Decide on cleanup vs full checkpoint here.
1:                 if (opened.get()) {
1:                     long now = System.currentTimeMillis();
1:                     if (cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval)) {
1:                         checkpointCleanup(true);
1:                         lastCleanup = now;
1:                         lastCheckpoint = now;
1:                     } else if (checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval)) {
1:                         checkpointCleanup(false);
1:                         lastCheckpoint = now;
1:                     }
1:                 }
1:             } catch (IOException ioe) {
0:                 LOG.error("Checkpoint failed", ioe);
1:                 brokerService.handleIOException(ioe);
1:             } catch (Throwable e) {
0:                 LOG.error("Checkpoint failed", e);
1:                 brokerService.handleIOException(IOExceptionSupport.create(e));
/////////////////////////////////////////////////////////////////////////
0:             ThreadPoolUtils.shutdownGraceful(scheduler, -1);
1:             // clear the cache and journalSize on shutdown of the store
/////////////////////////////////////////////////////////////////////////
1:         if (range[0] == null || t.compareTo(range[0]) <= 0) {
1:         if (range[1] == null || t.compareTo(range[1]) >= 0) {
/////////////////////////////////////////////////////////////////////////
1:         if (undoCounter > 0) {
/////////////////////////////////////////////////////////////////////////
1:         if (undoCounter > 0) {
/////////////////////////////////////////////////////////////////////////
1: 
1:                 location = onJournalStoreComplete == null ? journal.write(sequence, sync) : journal.write(sequence, onJournalStoreComplete) ;
1:                 if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:             } finally {
1: 
1:             if (scheduler == null && opened.get()) {
/////////////////////////////////////////////////////////////////////////
1: 
1:             @Override
1:             public void visit(KahaRewrittenDataFileCommand command) throws IOException {
1:                 process(command, location);
1:             }
/////////////////////////////////////////////////////////////////////////
1:     protected void process(KahaRewrittenDataFileCommand command, Location location)  throws IOException {
0:         final TreeSet<Integer> completeFileSet = new TreeSet<Integer>(journal.getFileMap().keySet());
0:         if (completeFileSet.contains(command.getSourceDataFileId()) && command.getSkipIfSourceExists()) {
0:             // Mark the current journal file as a compacted file so that gc checks can skip
0:             // over logs that are smaller compaction type logs.
0:             DataFile current = journal.getDataFileById(location.getDataFileId());
0:             current.setTypeCode(command.getRewriteType());
1: 
1:             // Move offset so that next location read jumps to next file.
1:             location.setOffset(journalMaxFileLength);
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:         if (cleanup) {
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:                 LOG.debug("Cleanup removing the data files: {}", gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:             } else {
1:                 if (++checkPointCyclesWithNoGC >= getCompactAcksAfterNoGC()) {
1:                     // First check length of journal to make sure it makes sense to even try.
1:                     //
1:                     // If there is only one journal file with Acks in it we don't need to move
1:                     // it since it won't be chained to any later logs.
1:                     //
1:                     // If the logs haven't grown since the last time then we need to compact
1:                     // otherwise there seems to still be room for growth and we don't need to incur
1:                     // the overhead.  Depending on configuration this check can be avoided and
1:                     // Ack compaction will run any time the store has not GC'd a journal file in
1:                     // the configured amount of cycles.
1:                     if (metadata.ackMessageFileMap.size() > 1 &&
1:                         (journalLogOnLastCompactionCheck == journal.getCurrentDataFileId() || isCompactAcksIgnoresStoreGrowth())) {
1: 
1:                         LOG.trace("No files GC'd checking if threshold to ACK compaction has been met.");
1:                         try {
1:                             scheduler.execute(new AckCompactionRunner());
1:                         } catch (Exception ex) {
1:                             LOG.warn("Error on queueing the Ack Compactor", ex);
1:                         }
1:                     } else {
1:                         LOG.trace("Journal activity detected, no Ack compaction scheduled.");
1:                     }
1: 
1:                     checkPointCyclesWithNoGC = 0;
1:                 } else {
1:                     LOG.trace("Not yet time to check for compaction: {} of {} cycles",
1:                               checkPointCyclesWithNoGC, getCompactAcksAfterNoGC());
1:                 }
1: 
1:                 journalLogOnLastCompactionCheck = journal.getCurrentDataFileId();
1:     private final class AckCompactionRunner implements Runnable {
1: 
1:         @Override
1:         public void run() {
0:             // Lock index to capture the ackMessageFileMap data
0:             indexLock.writeLock().lock();
1: 
0:             // Map keys might not be sorted, find the earliest log file to forward acks
0:             // from and move only those, future cycles can chip away at more as needed.
0:             // We won't move files that are themselves rewritten on a previous compaction.
0:             List<Integer> journalFileIds = new ArrayList<Integer>(metadata.ackMessageFileMap.keySet());
0:             Collections.sort(journalFileIds);
0:             int journalToAdvance = -1;
0:             for (Integer journalFileId : journalFileIds) {
0:                 DataFile current = journal.getDataFileById(journalFileId);
0:                 if (current != null && current.getTypeCode() != COMPACTED_JOURNAL_FILE) {
0:                     journalToAdvance = journalFileId;
0:                     break;
1:                 }
1:             }
1: 
0:             // Check if we found one, or if we only found the current file being written to.
0:             if (journalToAdvance == -1 || journalToAdvance == journal.getCurrentDataFileId()) {
1:                 return;
1:             }
1: 
0:             Set<Integer> journalLogsReferenced =
0:                 new HashSet<Integer>(metadata.ackMessageFileMap.get(journalToAdvance));
1: 
0:             indexLock.writeLock().unlock();
1: 
1:             try {
0:                 // Background rewrite of the old acks
0:                 forwardAllAcks(journalToAdvance, journalLogsReferenced);
1: 
0:                 // Checkpoint with changes from the ackMessageFileMap
0:                 checkpointUpdate(false);
1:             } catch (IOException ioe) {
0:                 LOG.error("Checkpoint failed", ioe);
1:                 brokerService.handleIOException(ioe);
0:             } catch (Throwable e) {
0:                 LOG.error("Checkpoint failed", e);
0:                 brokerService.handleIOException(IOExceptionSupport.create(e));
1:             }
1:         }
1:     }
1: 
1:     private void forwardAllAcks(Integer journalToRead, Set<Integer> journalLogsReferenced) throws IllegalStateException, IOException {
1:         LOG.trace("Attempting to move all acks in journal:{} to the front.", journalToRead);
1: 
1:         DataFile forwardsFile = journal.reserveDataFile();
0:         LOG.trace("Reserved now file for forwarded acks: {}", forwardsFile);
1: 
0:         Map<Integer, Set<Integer>> updatedAckLocations = new HashMap<Integer, Set<Integer>>();
1: 
1:         try (TargetedDataFileAppender appender = new TargetedDataFileAppender(journal, forwardsFile);) {
1:             KahaRewrittenDataFileCommand compactionMarker = new KahaRewrittenDataFileCommand();
1:             compactionMarker.setSourceDataFileId(journalToRead);
0:             compactionMarker.setRewriteType(COMPACTED_JOURNAL_FILE);
1: 
1:             ByteSequence payload = toByteSequence(compactionMarker);
0:             appender.storeItem(payload, Journal.USER_RECORD_TYPE, isEnableJournalDiskSyncs());
1:             LOG.trace("Marked ack rewrites file as replacing file: {}", journalToRead);
1: 
0:             Location nextLocation = journal.getNextLocation(new Location(journalToRead, 0));
0:             while (nextLocation != null && nextLocation.getDataFileId() == journalToRead) {
1:                 JournalCommand<?> command = null;
1:                 try {
1:                     command = load(nextLocation);
1:                 } catch (IOException ex) {
1:                     LOG.trace("Error loading command during ack forward: {}", nextLocation);
1:                 }
1: 
1:                 if (command != null && command instanceof KahaRemoveMessageCommand) {
1:                     payload = toByteSequence(command);
0:                     Location location = appender.storeItem(payload, Journal.USER_RECORD_TYPE, isEnableJournalDiskSyncs());
1:                     updatedAckLocations.put(location.getDataFileId(), journalLogsReferenced);
1:                 }
1: 
0:                 nextLocation = journal.getNextLocation(nextLocation);
1:             }
1:         }
1: 
1:         LOG.trace("ACKS forwarded, updates for ack locations: {}", updatedAckLocations);
1: 
1:         // Lock index while we update the ackMessageFileMap.
0:         indexLock.writeLock().lock();
1: 
1:         // Update the ack map with the new locations of the acks
1:         for (Entry<Integer, Set<Integer>> entry : updatedAckLocations.entrySet()) {
1:             Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(entry.getKey());
1:             if (referenceFileIds == null) {
0:                 referenceFileIds = new HashSet<Integer>();
1:                 referenceFileIds.addAll(entry.getValue());
1:                 metadata.ackMessageFileMap.put(entry.getKey(), referenceFileIds);
1:             } else {
1:                 referenceFileIds.addAll(entry.getValue());
1:             }
1:         }
1: 
1:         // remove the old location data from the ack map so that the old journal log file can
1:         // be removed on next GC.
1:         metadata.ackMessageFileMap.remove(journalToRead);
1: 
0:         indexLock.writeLock().unlock();
1: 
1:         LOG.trace("ACK File Map following updates: {}", metadata.ackMessageFileMap);
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         if (indexDirectory == null) {
/////////////////////////////////////////////////////////////////////////
1: 
1:     public int getCompactAcksAfterNoGC() {
1:         return compactAcksAfterNoGC;
1:     }
1: 
1:     /**
1:      * Sets the number of GC cycles where no journal logs were removed before an attempt to
1:      * move forward all the acks in the last log that contains them and is otherwise unreferenced.
1:      * <p>
1:      * A value of -1 will disable this feature.
1:      *
1:      * @param compactAcksAfterNoGC
1:      *      Number of empty GC cycles before we rewrite old ACKS.
1:      */
1:     public void setCompactAcksAfterNoGC(int compactAcksAfterNoGC) {
1:         this.compactAcksAfterNoGC = compactAcksAfterNoGC;
1:     }
1: 
1:     /**
1:      * Returns whether Ack compaction will ignore that the store is still growing
1:      * and run more often.
1:      *
1:      * @return the compactAcksIgnoresStoreGrowth current value.
1:      */
1:     public boolean isCompactAcksIgnoresStoreGrowth() {
1:         return compactAcksIgnoresStoreGrowth;
1:     }
1: 
1:     /**
1:      * Configure if Ack compaction will occur regardless of continued growth of the
1:      * journal logs meaning that the store has not run out of space yet.  Because the
1:      * compaction operation can be costly this value is defaulted to off and the Ack
1:      * compaction is only done when it seems that the store cannot grow and larger.
1:      *
1:      * @param compactAcksIgnoresStoreGrowth the compactAcksIgnoresStoreGrowth to set
1:      */
1:     public void setCompactAcksIgnoresStoreGrowth(boolean compactAcksIgnoresStoreGrowth) {
1:         this.compactAcksIgnoresStoreGrowth = compactAcksIgnoresStoreGrowth;
1:     }
commit:193f6be
/////////////////////////////////////////////////////////////////////////
1:                     BTreeVisitor.BetweenVisitor<Location, Long> visitor =
0:                         new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1));
/////////////////////////////////////////////////////////////////////////
1:                             if (pendingAcks == null || pendingAcks.isEmpty() ||
1:                                 (pendingAcks.size() == 1 && pendingAcks.getTail().range() == 1)) {
1: 
commit:13044de
/////////////////////////////////////////////////////////////////////////
1:         protected int openwireVersion = OpenWireFormat.DEFAULT_STORE_VERSION;
/////////////////////////////////////////////////////////////////////////
1:                 openwireVersion = OpenWireFormat.DEFAULT_LEGACY_VERSION;
commit:455f1ca
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                     for (Long sequenceId : pendingAcks) {
/////////////////////////////////////////////////////////////////////////
1:                         } else {
1:                             current = Long.valueOf(0L);
/////////////////////////////////////////////////////////////////////////
1: 
1:             // There might not be a reference if the ackLocation was the last
1:             // one which is a placeholder for the next incoming message and
1:             // no value was added to the message references table.
1:             if (count != null) {
1:                 count = count.longValue() + 1;
1:                 sd.messageReferences.put(ackPosition, count);
1:             }
/////////////////////////////////////////////////////////////////////////
1:             sd.messageReferences.put(messageSequence + 1, Long.valueOf(0L));
/////////////////////////////////////////////////////////////////////////
1:                 if (count != null) {
1:                     long references = count.longValue() - 1;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:bfb1778
/////////////////////////////////////////////////////////////////////////
1:             Metadata rc = createMetadata();
/////////////////////////////////////////////////////////////////////////
1:                 metadata = createMetadata();
/////////////////////////////////////////////////////////////////////////
1:                 metadata = createMetadata();
/////////////////////////////////////////////////////////////////////////
1:                 int maxNumProducers = getMaxFailoverProducersToTrack();
1:                 int maxAuditDepth = getFailoverProducersAuditDepth();
1:                 metadata.producerSequenceIdTracker.setAuditDepth(maxAuditDepth);
1:                 metadata.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(maxNumProducers);
/////////////////////////////////////////////////////////////////////////
1:     private Metadata createMetadata() {
1:         Metadata md = new Metadata();
1:         md.producerSequenceIdTracker.setAuditDepth(getFailoverProducersAuditDepth());
1:         md.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(getMaxFailoverProducersToTrack());
1:         return md;
1:     }
1: 
author:Dejan Bosanac
-------------------------------------------------------------------------------
commit:f4a2543
/////////////////////////////////////////////////////////////////////////
1:             if (sd.subscriptions != null && !sd.subscriptions.isEmpty(tx)) {
0:                 Iterator<Entry<String, SequenceSet>> it = sd.ackPositions.iterator(tx);
0:                 while (it.hasNext()) {
0:                     Entry<String, SequenceSet> entry = it.next();
0:                     entry.getValue().remove(id);
1:                 }
commit:4ab55f1
/////////////////////////////////////////////////////////////////////////
0:             // remove ack positions
0:             Iterator<Entry<String, SequenceSet>> it = sd.ackPositions.iterator(tx);
0:             while (it.hasNext()) {
0:                 Entry<String, SequenceSet> entry = it.next();
0:                 entry.getValue().remove(id);
1:             }
1: 
author:Christopher L. Shannon
-------------------------------------------------------------------------------
commit:c6542a9
/////////////////////////////////////////////////////////////////////////
0:             //clear the cache on shutdown of the store
1:             storeCache.clear();
author:Christian Posta
-------------------------------------------------------------------------------
commit:023b2ac
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:45e59e6
/////////////////////////////////////////////////////////////////////////
0:     int preallocationBatchSize = Journal.DEFAULT_PREALLOCATION_BATCH_SIZE;
0:     private String preallocationScope = Journal.PreallocationScope.ENTIRE_JOURNAL.name();
1:     private String preallocationStrategy = Journal.PreallocationStrategy.SPARSE_FILE.name();
/////////////////////////////////////////////////////////////////////////
1:         manager.setPreallocationScope(Journal.PreallocationScope.valueOf(preallocationScope.trim().toUpperCase()));
1:         manager.setPreallocationStrategy(
1:                 Journal.PreallocationStrategy.valueOf(preallocationStrategy.trim().toUpperCase()));
0:         manager.setPreallocationBatchSize(preallocationBatchSize);
/////////////////////////////////////////////////////////////////////////
1: 
1:     public String getPreallocationScope() {
1:         return preallocationScope;
1:     }
1: 
1:     public void setPreallocationScope(String preallocationScope) {
1:         this.preallocationScope = preallocationScope;
1:     }
1: 
1:     public String getPreallocationStrategy() {
1:         return preallocationStrategy;
1:     }
1: 
1:     public void setPreallocationStrategy(String preallocationStrategy) {
1:         this.preallocationStrategy = preallocationStrategy;
1:     }
1: 
0:     public int getPreallocationBatchSize() {
0:         return preallocationBatchSize;
1:     }
1: 
0:     public void setPreallocationBatchSize(int preallocationBatchSize) {
0:         this.preallocationBatchSize = preallocationBatchSize;
1:     }
author:Hiram Chirino
-------------------------------------------------------------------------------
commit:232b8c5
/////////////////////////////////////////////////////////////////////////
1:     protected File indexDirectory = null;
/////////////////////////////////////////////////////////////////////////
1:     private PageFile createPageFile() throws IOException {
0:         if( indexDirectory == null ) {
1:             indexDirectory = directory;
1:         }
1:         IOHelper.mkdirs(indexDirectory);
1:         PageFile index = new PageFile(indexDirectory, "db");
/////////////////////////////////////////////////////////////////////////
1:     public PageFile getPageFile() throws IOException {
/////////////////////////////////////////////////////////////////////////
1: 
1:     public File getIndexDirectory() {
1:         return indexDirectory;
1:     }
1: 
1:     public void setIndexDirectory(File indexDirectory) {
1:         this.indexDirectory = indexDirectory;
1:     }
author:Gary Tully
-------------------------------------------------------------------------------
commit:90d6c20
/////////////////////////////////////////////////////////////////////////
1:                             if (metadata.version >= 3) {
1:                                 // migrate
1:                                 BTreeIndex<Long, HashSet<String>> oldAckPositions =
0:                                         new BTreeIndex<Long, HashSet<String>>(pageFile, dataIn.readLong());
1:                                 oldAckPositions.setKeyMarshaller(LongMarshaller.INSTANCE);
1:                                 oldAckPositions.setValueMarshaller(HashSetStringMarshaller.INSTANCE);
1:                                 oldAckPositions.load(tx);
1: 
1:                                 // Do the initial build of the data in memory before writing into the store
1:                                 // based Ack Positions List to avoid a lot of disk thrashing.
1:                                 Iterator<Entry<Long, HashSet<String>>> iterator = oldAckPositions.iterator(tx);
1:                                 while (iterator.hasNext()) {
1:                                     Entry<Long, HashSet<String>> entry = iterator.next();
1: 
1:                                     for(String subKey : entry.getValue()) {
1:                                         SequenceSet pendingAcks = temp.get(subKey);
1:                                         if (pendingAcks == null) {
1:                                             pendingAcks = new SequenceSet();
1:                                             temp.put(subKey, pendingAcks);
1:                                         }
1: 
1:                                         pendingAcks.add(entry.getKey());
commit:0061f6f
/////////////////////////////////////////////////////////////////////////
0:             if (data instanceof KahaSubscriptionCommand) {
0:                 KahaSubscriptionCommand kahaSubscriptionCommand = (KahaSubscriptionCommand)data;
0:                 if (kahaSubscriptionCommand.hasSubscriptionInfo()) {
0:                     // needs to be processed via activate and will be replayed on reconnect
0:                     LOG.debug("ignoring add sub command during recovery replay:" + data);
1:                     return;
1:                 }
1:             }
commit:5cadb04
/////////////////////////////////////////////////////////////////////////
1:     private boolean checksumJournalFiles = true;
commit:66e8011
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 process(message, lastRecoveryPosition, (Runnable)null, (Runnable)null);
/////////////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand<?> data, boolean sync, Runnable before, Runnable after, Runnable onJournalStoreComplete) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:                 process(data, location, before, after);
/////////////////////////////////////////////////////////////////////////
1:                 after.run();
/////////////////////////////////////////////////////////////////////////
0:             process(data, location, (Runnable) null, (Runnable) null);
/////////////////////////////////////////////////////////////////////////
0:     void process(JournalCommand<?> data, final Location location, final Runnable before, final Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:                 process(command, location, before, after);
/////////////////////////////////////////////////////////////////////////
0:     protected void process(KahaCommitCommand command, Location location, final Runnable before, final Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:             // only non persistent messages in this tx
1:             if (before != null) {
0:                 before.run();
/////////////////////////////////////////////////////////////////////////
0:             // run before with the index lock so that queue can order cursor updates with index updates
0:             if (before != null) {
0:                 before.run();
1:             }
/////////////////////////////////////////////////////////////////////////
commit:65bc9f3
/////////////////////////////////////////////////////////////////////////
1:                 int dataFileId = metadata.producerSequenceIdTrackerLocation.getDataFileId();
1:                 if (gcCandidateSet.contains(dataFileId) && gcCandidateSet.first() == dataFileId) {
1:                     // rewrite so we don't prevent gc
1:                     metadata.producerSequenceIdTracker.setModified(true);
1:                     if (LOG.isTraceEnabled()) {
1:                         LOG.trace("rewriting producerSequenceIdTracker:" + metadata.producerSequenceIdTrackerLocation);
1:                     }
1:                 }
1:                 gcCandidateSet.remove(dataFileId);
1:                 if (LOG.isTraceEnabled()) {
0:                     LOG.trace("gc candidates after producerSequenceIdTrackerLocation:" + dataFileId + ", " + gcCandidateSet);
1:                 }
commit:0dcdab7
/////////////////////////////////////////////////////////////////////////
1: import java.util.Arrays;
/////////////////////////////////////////////////////////////////////////
1:                 metadata.firstInProgressTransactionLocation = getInProgressTxLocationRange()[0];
/////////////////////////////////////////////////////////////////////////
1:     public Location[] getInProgressTxLocationRange() {
1:         Location[] range = new Location[]{null, null};
1:                         trackMaxAndMin(range, ops);
1:                         trackMaxAndMin(range, ops);
1:         return range;
1:     }
1: 
1:     private void trackMaxAndMin(Location[] range, List<Operation> ops) {
1:         Location t = ops.get(0).getLocation();
0:         if (range[0]==null || t.compareTo(range[0]) <= 0) {
1:             range[0] = t;
1:         }
1:         t = ops.get(ops.size() -1).getLocation();
0:         if (range[1]==null || t.compareTo(range[1]) >= 0) {
1:             range[1] = t;
1:         }
/////////////////////////////////////////////////////////////////////////
1:         Location lastUpdate = metadata.lastUpdate;
1:         Location[] inProgressTxRange = getInProgressTxLocationRange();
1:         metadata.firstInProgressTransactionLocation = inProgressTxRange[0];
/////////////////////////////////////////////////////////////////////////
1:                 LOG.trace("Last update: " + lastUpdate + ", full gc candidates set: " + gcCandidateSet);
1:             }
1: 
1:             if (lastUpdate != null) {
0:                 gcCandidateSet.remove(lastUpdate.getDataFileId());
/////////////////////////////////////////////////////////////////////////
1:             // Don't GC files referenced by in-progress tx
1:             if (inProgressTxRange[0] != null) {
1:                 for (int pendingTx=inProgressTxRange[0].getDataFileId(); pendingTx <= inProgressTxRange[1].getDataFileId(); pendingTx++) {
1:                     gcCandidateSet.remove(pendingTx);
1:             if (LOG.isTraceEnabled()) {
0:                 LOG.trace("gc candidates after tx range:" + Arrays.asList(inProgressTxRange) + ", " + gcCandidateSet);
commit:3bffaf7
/////////////////////////////////////////////////////////////////////////
1:     class TranInfo {
1:         TransactionId id;
1:         Location location;
1: 
1:         class opCount {
1:             int add;
1:             int remove;
1:         }
0:         HashMap<KahaDestination, opCount> destinationOpCount = new HashMap<KahaDestination, opCount>();
1: 
1:         public void track(Operation operation) {
1:             if (location == null ) {
1:                 location = operation.getLocation();
1:             }
1:             KahaDestination destination;
1:             boolean isAdd = false;
0:             if (operation instanceof AddOpperation) {
0:                 AddOpperation add = (AddOpperation) operation;
1:                 destination = add.getCommand().getDestination();
1:                 isAdd = true;
1:             } else {
0:                 RemoveOpperation removeOpperation = (RemoveOpperation) operation;
1:                 destination = removeOpperation.getCommand().getDestination();
1:             }
1:             opCount opCount = destinationOpCount.get(destination);
1:             if (opCount == null) {
1:                 opCount = new opCount();
1:                 destinationOpCount.put(destination, opCount);
1:             }
1:             if (isAdd) {
1:                 opCount.add++;
1:             } else {
1:                 opCount.remove++;
1:             }
1:         }
1: 
1:         @Override
1:         public String toString() {
1:            StringBuffer buffer = new StringBuffer();
1:            buffer.append(location).append(";").append(id).append(";\n");
1:            for (Entry<KahaDestination, opCount> op : destinationOpCount.entrySet()) {
1:                buffer.append(op.getKey()).append('+').append(op.getValue().add).append(',').append('-').append(op.getValue().remove).append(';');
1:            }
1:            return buffer.toString();
1:         }
1:     }
1: 
1:     @SuppressWarnings("rawtypes")
1:     public String getTransactions() {
1: 
0:         ArrayList<TranInfo> infos = new ArrayList<TranInfo>();
1:         synchronized (inflightTransactions) {
1:             if (!inflightTransactions.isEmpty()) {
1:                 for (Entry<TransactionId, List<Operation>> entry : inflightTransactions.entrySet()) {
1:                     TranInfo info = new TranInfo();
1:                     info.id = entry.getKey();
1:                     for (Operation operation : entry.getValue()) {
1:                         info.track(operation);
1:                     }
1:                     infos.add(info);
1:                 }
1:             }
1:         }
1:         return infos.toString();
1:     }
1: 
commit:eaac0d2
/////////////////////////////////////////////////////////////////////////
1:                 addAckLocationForRetroactiveSub(tx, sd, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1:     private void addAckLocationForRetroactiveSub(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:         SequenceSet allOutstanding = new SequenceSet();
1:         Iterator<Map.Entry<String, SequenceSet>> iterator = sd.ackPositions.iterator(tx);
0:         while (iterator.hasNext()) {
1:             SequenceSet set = iterator.next().getValue();
1:             for (Long entry : set) {
1:                 allOutstanding.add(entry);
1:             }
1:         sd.ackPositions.put(tx, subscriptionKey, allOutstanding);
1:         for (Long ackPosition : allOutstanding) {
1:             Long count = sd.messageReferences.get(ackPosition);
1:             count = count.longValue() + 1;
0:             sd.messageReferences.put(ackPosition, count);
commit:fb0b63e
/////////////////////////////////////////////////////////////////////////
0:                 rollbackStatsOnDuplicate(command.getDestination());
/////////////////////////////////////////////////////////////////////////
0:     abstract void rollbackStatsOnDuplicate(KahaDestination commandDestination);
1: 
commit:d1357b4
/////////////////////////////////////////////////////////////////////////
1:         public StoredDestination readPayload(final DataInput dataIn) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:                 if (metadata.version >= 4) {
0:                                 new BTreeIndex<Long, HashSet<String>>(pageFile, dataIn.readLong());
commit:dcf1f5e
/////////////////////////////////////////////////////////////////////////
1:             } catch (Throwable t) {
1:                 LOG.warn("Index corrupted. Recovering the index through journal replay. Cause:" + t);
1:                 if (LOG.isDebugEnabled()) {
1:                     LOG.debug("Index load failure", t);
1:                 }
/////////////////////////////////////////////////////////////////////////
0:                 metadata = new Metadata();
1:                 pageFile = null;
/////////////////////////////////////////////////////////////////////////
1:                     if (metadata.page != null) {
1:                         pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                             public void execute(Transaction tx) throws IOException {
0:                                 checkpointUpdate(tx, true);
1:                             }
1:                         });
1:                     }
/////////////////////////////////////////////////////////////////////////
1:                 if (metadata.page != null) {
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         public void execute(Transaction tx) throws IOException {
1:                             tx.store(metadata.page, metadataMarshaller, true);
1:                         }
1:                     });
1:                 }
commit:89f22da
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         if (checkpointInterval == 0 &&  cleanupInterval == 0) {
1:             LOG.info("periodic checkpoint/cleanup disabled, will ocurr on clean shutdown/restart");
0:             return;
1:         }
/////////////////////////////////////////////////////////////////////////
0:                             long sleepTime = Math.min(checkpointInterval > 0 ? checkpointInterval : cleanupInterval, 500);
0:                                 if( cleanupInterval > 0 && (now - lastCleanup >= cleanupInterval) ) {
0:                                 } else if( checkpointInterval > 0 && (now - lastCheckpoint >= checkpointInterval )) {
/////////////////////////////////////////////////////////////////////////
0:                     if (checkpointThread != null) {
0:                         checkpointThread.join();
1:                     }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     // /////////////////////////////////////////////////////////////////
1:     // Methods call by the broker to update and query the store.
1:     // /////////////////////////////////////////////////////////////////
1:     public Location store(JournalCommand<?> data) throws IOException {
1:         return store(data, false, null,null);
1:     }
1: 
1:     public Location store(JournalCommand<?> data, Runnable onJournalStoreComplete) throws IOException {
0:         return store(data, false, null,null, onJournalStoreComplete);
1:     }
1: 
0:     public Location store(JournalCommand<?> data, boolean sync, Runnable before,Runnable after) throws IOException {
0:         return store(data, sync, before, after, null);
1:     }
1: 
0:     public Location store(JournalCommand<?> data, boolean sync, Runnable before,Runnable after, Runnable onJournalStoreComplete) throws IOException {
0:             Location location = onJournalStoreComplete == null ? journal.write(sequence, sync) :  journal.write(sequence, onJournalStoreComplete) ;
/////////////////////////////////////////////////////////////////////////
1:     final Runnable nullCompletionCallback = new Runnable() {
1:         @Override
1:         public void run() {
1:         }
1:     };
1:         // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false
1:         Location location = store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), nullCompletionCallback);
1:         try {
1:             location.getLatch().await();
1:         } catch (InterruptedException e) {
1:             throw new InterruptedIOException(e.toString());
1:         }
1:         return location;
/////////////////////////////////////////////////////////////////////////
1:         manager.setEnableAsyncDiskSync(isEnableJournalDiskSyncs());
commit:bb4a2f7
/////////////////////////////////////////////////////////////////////////
1:     private boolean enableIndexDiskSyncs = true;
1:     private boolean enableIndexRecoveryFile = true;
1:     private boolean enableIndexPageCaching = true;
/////////////////////////////////////////////////////////////////////////
1:         index.setEnableDiskSyncs(isEnableIndexDiskSyncs());
1:         index.setEnableRecoveryFile(isEnableIndexRecoveryFile());
1:         index.setEnablePageCaching(isEnableIndexPageCaching());
/////////////////////////////////////////////////////////////////////////
1:     public void setEnableIndexDiskSyncs(boolean enableIndexDiskSyncs) {
1:         this.enableIndexDiskSyncs = enableIndexDiskSyncs;
1:     }
1: 
1:     public void setEnableIndexRecoveryFile(boolean enableIndexRecoveryFile) {
1:         this.enableIndexRecoveryFile = enableIndexRecoveryFile;
1:     }
1: 
1:     public void setEnableIndexPageCaching(boolean enableIndexPageCaching) {
1:         this.enableIndexPageCaching = enableIndexPageCaching;
1:     }
1: 
1:     public boolean isEnableIndexDiskSyncs() {
1:         return enableIndexDiskSyncs;
1:     }
1: 
1:     public boolean isEnableIndexRecoveryFile() {
1:         return enableIndexRecoveryFile;
1:     }
1: 
1:     public boolean isEnableIndexPageCaching() {
1:         return enableIndexPageCaching;
1:     }
1: 
commit:41cdadb
/////////////////////////////////////////////////////////////////////////
0:                      if (LOG.isInfoEnabled() && redoCounter % 100000 == 0) {
0:                          LOG.info("@" + recoveryPosition +  ", "  + redoCounter + " entries recovered ..");
1:                      }
commit:395bf82
/////////////////////////////////////////////////////////////////////////
1:             if (after != null) {
0:                 // since we don't push this after and we may find another, lets run it now
0:                 after.run();
1:             }
commit:85edfb3
/////////////////////////////////////////////////////////////////////////
1:     public static final File DEFAULT_DIRECTORY = new File("KahaDB");
/////////////////////////////////////////////////////////////////////////
1:     protected File directory = DEFAULT_DIRECTORY;
commit:9c9b856
/////////////////////////////////////////////////////////////////////////
1:             } else if (LOG.isDebugEnabled()) {
0:                 LOG.debug("no message sequence exists for id: " + command.getMessageId() + " and sub: " + command.getSubscriptionKey());
/////////////////////////////////////////////////////////////////////////
1:      * @param messageSequence
commit:2398a3a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                 }  else if (LOG.isDebugEnabled()) {
1:                     LOG.debug("message not found in order index: " + sequenceId  + " for: " + command.getMessageId());
1:             } else if (LOG.isDebugEnabled()) {
1:                 LOG.debug("message not found in sequence id index: " + command.getMessageId());
commit:2030097
/////////////////////////////////////////////////////////////////////////
1: public abstract class MessageDatabase extends ServiceSupport implements BrokerServiceAware {
/////////////////////////////////////////////////////////////////////////
0:     private boolean rewriteOnRedelivery = false;
/////////////////////////////////////////////////////////////////////////
1:                 this.indexLock.writeLock().lock();
1:                 try {
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         public void execute(Transaction tx) throws IOException {
0:                             checkpointUpdate(tx, true);
1:                         }
1:                     });
1:                     pageFile.unload();
0:                     metadata = new Metadata();
1:                 } finally {
1:                     this.indexLock.writeLock().unlock();
1:                 }
1:                 journal.close();
0:                 synchronized (checkpointThreadLock) {
0:                     checkpointThread.join();
1:                 }
0:                 lockFile.unlock();
0:                 lockFile=null;
/////////////////////////////////////////////////////////////////////////
1:     public ByteSequence toByteSequence(JournalCommand<?> data) throws IOException {
1:         int size = data.serializedSizeFramed();
1:         DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
1:         os.writeByte(data.type().getNumber());
1:         data.writeFramed(os);
1:         return os.toByteSequence();
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:             ByteSequence sequence = toByteSequence(data);
0:             Location location = journal.write(sequence, sync);
/////////////////////////////////////////////////////////////////////////
1:     protected void process(KahaRollbackCommand command, Location location)  throws IOException {
1:         List<Operation> updates = null;
1:             updates = inflightTransactions.remove(key);
1:             if (updates == null) {
1:                 updates = preparedTransactions.remove(key);
1:             }
1:         }
0:         if (isRewriteOnRedelivery()) {
0:             persistRedeliveryCount(updates);
1:         }
1:     }
1: 
0:     private void persistRedeliveryCount(List<Operation> updates)  throws IOException {
0:         if (updates != null) {
0:             for (Operation operation : updates) {
0:                 operation.getCommand().visit(new Visitor() {
1:                     @Override
1:                     public void visit(KahaRemoveMessageCommand command) throws IOException {
0:                         incrementRedeliveryAndReWrite(command.getMessageId(), command.getDestination());
1:                     }
1:                 });
0:    abstract void incrementRedeliveryAndReWrite(String key, KahaDestination destination) throws IOException;
1: 
/////////////////////////////////////////////////////////////////////////
1:     abstract class Operation <T extends JournalCommand<T>> {
1:         final T command;
1:         public Operation(T command, Location location) {
1:             this.command = command;
/////////////////////////////////////////////////////////////////////////
1:         public T getCommand() {
1:             return command;
1:         }
1: 
0:     class AddOpperation extends Operation<KahaAddMessageCommand> {
1:             super(command, location);
/////////////////////////////////////////////////////////////////////////
0:     class RemoveOpperation extends Operation<KahaRemoveMessageCommand> {
1:             super(command, location);
/////////////////////////////////////////////////////////////////////////
0:     public boolean isRewriteOnRedelivery() {
0:         return rewriteOnRedelivery;
1:     }
1: 
0:     public void setRewriteOnRedelivery(boolean rewriteOnRedelivery) {
0:         this.rewriteOnRedelivery = rewriteOnRedelivery;
1:     }
1: 
commit:1595378
/////////////////////////////////////////////////////////////////////////
1: import java.io.DataInput;
1: import java.io.DataOutput;
1: import java.io.EOFException;
1: import java.io.File;
1: import java.io.IOException;
1: import java.io.InputStream;
1: import java.io.ObjectInputStream;
1: import java.io.ObjectOutputStream;
1: import java.io.OutputStream;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.data.KahaAddMessageCommand;
1: import org.apache.activemq.store.kahadb.data.KahaCommitCommand;
1: import org.apache.activemq.store.kahadb.data.KahaDestination;
1: import org.apache.activemq.store.kahadb.data.KahaEntryType;
1: import org.apache.activemq.store.kahadb.data.KahaPrepareCommand;
1: import org.apache.activemq.store.kahadb.data.KahaProducerAuditCommand;
1: import org.apache.activemq.store.kahadb.data.KahaRemoveDestinationCommand;
1: import org.apache.activemq.store.kahadb.data.KahaRemoveMessageCommand;
1: import org.apache.activemq.store.kahadb.data.KahaRollbackCommand;
1: import org.apache.activemq.store.kahadb.data.KahaSubscriptionCommand;
1: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
1: import org.apache.activemq.store.kahadb.data.KahaTransactionInfo;
0: import org.apache.kahadb.util.LocationMarshaller;
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.ByteSequence;
0: import org.apache.kahadb.util.DataByteArrayInputStream;
0: import org.apache.kahadb.util.DataByteArrayOutputStream;
0: import org.apache.kahadb.util.LockFile;
0: import org.apache.kahadb.util.LongMarshaller;
0: import org.apache.kahadb.util.Marshaller;
0: import org.apache.kahadb.util.Sequence;
0: import org.apache.kahadb.util.SequenceSet;
0: import org.apache.kahadb.util.StringMarshaller;
0: import org.apache.kahadb.util.VariableMarshaller;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                version = is.readInt();
0:             }catch (EOFException expectedOnUpgrade) {
0:                 version=1;
/////////////////////////////////////////////////////////////////////////
1:     protected Journal journal;
/////////////////////////////////////////////////////////////////////////
0:     protected boolean enableJournalDiskSyncs=true;
1:     long checkpointInterval = 5*1000;
1:     long cleanupInterval = 30*1000;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                     for (Iterator<Entry<String, StoredDestination>> iterator = metadata.destinations.iterator(tx); iterator.hasNext();) {
1:                         StoredDestination sd = loadStoredDestination(tx, entry.getKey(), entry.getValue().subscriptions!=null);
0:         }finally {
/////////////////////////////////////////////////////////////////////////
0:                                 if( now - lastCleanup >= cleanupInterval ) {
0:                                 } else if( now - lastCheckpoint >= checkpointInterval ) {
/////////////////////////////////////////////////////////////////////////
1:         if( opened.compareAndSet(false, true) ) {
1:             getJournal().start();
/////////////////////////////////////////////////////////////////////////
1:                 getJournal().start();
1:                 getJournal().delete();
1:                 getJournal().close();
1:                 journal = null;
1:             store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
0:         }finally {
/////////////////////////////////////////////////////////////////////////
0:         if( opened.compareAndSet(true, false)) {
0:                         checkpointUpdate(tx, true);
0:             }finally {
0:             journal.close();
0:             lockFile=null;
1:             if( pageFile != null && pageFile.isLoaded() ) {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
/////////////////////////////////////////////////////////////////////////
1:                 for (List<Operation> ops : inflightTransactions.values()) {
1:                     if (!ops.isEmpty()) {
0:                         l = ops.get(0).getLocation();
0:                         break;
1:                     }
1:                 }
1:                 for (List<Operation> ops : preparedTransactions.values()) {
1:                     if (!ops.isEmpty()) {
0:                         Location t = ops.get(0).getLocation();
0:                         if (l==null || t.compareTo(l) <= 0) {
0:                             l = t;
1:                         }
0:                         break;
1:                     }
/////////////////////////////////////////////////////////////////////////
1:      *
1:      * @throws IOException
1:      * @throws IOException
1:      * @throws IllegalStateException
1: 
1:             long start = System.currentTimeMillis();
0:             Location producerAuditPosition = recoverProducerAudit();
1:             Location lastIndoubtPosition = getRecoveryPosition();
1: 
0:             Location recoveryPosition = minimum(producerAuditPosition, lastIndoubtPosition);
1: 
1:             if (recoveryPosition != null) {
1:                 int redoCounter = 0;
0:                 LOG.info("Recovering from the journal ...");
1:                 while (recoveryPosition != null) {
0:                     JournalCommand<?> message = load(recoveryPosition);
0:                     metadata.lastUpdate = recoveryPosition;
0:                     process(message, recoveryPosition, lastIndoubtPosition);
0:                     redoCounter++;
1:                     recoveryPosition = journal.getNextLocation(recoveryPosition);
1:                 }
1:                 long end = System.currentTimeMillis();
1:                 LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1: 
1:             // We may have to undo some index updates.
1:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                 public void execute(Transaction tx) throws IOException {
1:                     recoverIndex(tx);
1:                 }
1:             });
1: 
0:             // rollback any recovered inflight local transactions
0:             Set<TransactionId> toRollback = new HashSet<TransactionId>();
1:             synchronized (inflightTransactions) {
1:                 for (Iterator<TransactionId> it = inflightTransactions.keySet().iterator(); it.hasNext(); ) {
1:                     TransactionId id = it.next();
1:                     if (id.isLocalTransaction()) {
1:                         toRollback.add(id);
1:                     }
1:                 }
1:                 for (TransactionId tx: toRollback) {
1:                     LOG.debug("rolling back recovered indoubt local transaction " + tx);
1:                     store(new KahaRollbackCommand().setTransactionInfo(TransactionIdConversion.convertToLocal(tx)), false, null, null);
1:                 }
1:             }
0:         }finally {
1:     private KahaTransactionInfo createLocalTransactionInfo(TransactionId tx) {
1:         return TransactionIdConversion.convertToLocal(tx);
0:             Location lastIndoubtPosition) {
/////////////////////////////////////////////////////////////////////////
0:     private Location recoverProducerAudit() throws IOException {
0:             KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
1:     protected void recoverIndex(Transaction tx) throws IOException {
1:         long undoCounter=0;
/////////////////////////////////////////////////////////////////////////
0:         if( undoCounter > 0 ) {
/////////////////////////////////////////////////////////////////////////
1:                 int last=-1;
1:                     if( first==null ) {
1:                     } else if( second==null ) {
/////////////////////////////////////////////////////////////////////////
1:                         if( last != fileId ) {
/////////////////////////////////////////////////////////////////////////
0:         while( !ss.isEmpty() ) {
0:             missingJournalFiles.add( (int)ss.removeFirst() );
0:         missingJournalFiles.removeAll( journal.getFileMap().keySet() );
0:         if( !missingJournalFiles.isEmpty() ) {
0:             LOG.info("Some journal files are missing: "+missingJournalFiles);
0:             missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing,0), new Location(missing+1,0)));
0:         if ( checkForCorruptJournalFiles ) {
0:                 missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id,dataFile.getLength()), new Location(id+1,0)));
0:                 while( seq!=null ) {
0:                     missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast()+1)));
0:         if( !missingPredicates.isEmpty() ) {
/////////////////////////////////////////////////////////////////////////
0:                 if( !matches.isEmpty() ) {
1:                     if( ignoreMissingJournalfiles ) {
/////////////////////////////////////////////////////////////////////////
0:                         throw new IOException("Detected missing/corrupt journal files. "+matches.size()+" messages affected.");
0:         if( undoCounter > 0 ) {
/////////////////////////////////////////////////////////////////////////
1:     public void incrementalRecover() throws IOException {
1:             if( nextRecoveryPosition == null ) {
1:                 if( lastRecoveryPosition==null ) {
1:                     nextRecoveryPosition = getRecoveryPosition();
/////////////////////////////////////////////////////////////////////////
1:                 JournalCommand<?> message = load(lastRecoveryPosition);
0:         }finally {
/////////////////////////////////////////////////////////////////////////
1:     private Location getRecoveryPosition() throws IOException {
/////////////////////////////////////////////////////////////////////////
1:             if( metadata.lastUpdate!=null) {
/////////////////////////////////////////////////////////////////////////
1:             if( !opened.get() ) {
0:                     checkpointUpdate(tx, cleanup);
0:         }finally {
1:         if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:             LOG.info("Slow KahaDB access: cleanup took "+(end-start));
0:     public void checkpoint(Callback closure) throws Exception {
0:                     checkpointUpdate(tx, false);
0:         }finally {
/////////////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand<?> data) throws IOException {
0:         return store(data, false, null,null);
0:     public Location store(JournalCommand<?> data, boolean sync, Runnable before,Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:             if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
1:                 LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
/////////////////////////////////////////////////////////////////////////
1:      *
1:      * @param location
0:      * @return
1:      * @throws IOException
1:     public JournalCommand<?> load(Location location) throws IOException {
0:         if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
1:             LOG.info("Slow KahaDB access: Journal read took: "+(end-start)+" ms");
1:         if( type == null ) {
0:             throw new IOException("Could not load journal record. Invalid location: "+location);
1:         JournalCommand<?> message = (JournalCommand<?>)type.createMessage();
1:      * @param data
1:      * @param location
1:      * @param inDoubtlocation
1:      * @throws IOException
/////////////////////////////////////////////////////////////////////////
0:             }finally {
/////////////////////////////////////////////////////////////////////////
0:            List<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:            inflightTx.add(new RemoveOpperation(command, location));
/////////////////////////////////////////////////////////////////////////
0:             }finally {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
/////////////////////////////////////////////////////////////////////////
1:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
/////////////////////////////////////////////////////////////////////////
1:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
/////////////////////////////////////////////////////////////////////////
1:         TransactionId key = TransactionIdConversion.convert(command.getTransactionInfo());
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             long ackLocation=NOT_ACKED;
1:                 ackLocation = sd.orderIndex.nextMessageId-1;
/////////////////////////////////////////////////////////////////////////
0:     void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
1:         metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
0:         if( cleanup ) {
/////////////////////////////////////////////////////////////////////////
1:             if( journalFilesBeingReplicated!=null ) {
/////////////////////////////////////////////////////////////////////////
0:             if( metadata.firstInProgressTransactionLocation!=null ) {
0:             if( firstTxLocation!=null ) {
0:                 while( !gcCandidateSet.isEmpty() ) {
0:                     if( last >= firstTxLocation.getDataFileId() ) {
/////////////////////////////////////////////////////////////////////////
1:                 if( gcCandidateSet.isEmpty() ) {
1:                     int last=-1;
1:                         if( first==null ) {
1:                             SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
1:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
1:                         } else if( second==null ) {
1:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:                             SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
1:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
/////////////////////////////////////////////////////////////////////////
1:                             if( last != fileId ) {
/////////////////////////////////////////////////////////////////////////
0:             if( !gcCandidateSet.isEmpty() ) {
0:                 LOG.debug("Cleanup removing the data files: "+gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:     private Location checkpointProducerAudit() throws IOException {
0:         return store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), true, null, null);
/////////////////////////////////////////////////////////////////////////
1:             this.messageId=messageId;
1:             this.location=location;
1:             return "["+messageId+","+location+"]";
/////////////////////////////////////////////////////////////////////////
1:                     // upgrade
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         public void execute(Transaction tx) throws IOException {
0:                             value.orderIndex.lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
1:                             value.orderIndex.lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             value.orderIndex.lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:                             value.orderIndex.lowPriorityIndex.load(tx);
0:                             value.orderIndex.highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
1:                             value.orderIndex.highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             value.orderIndex.highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:                             value.orderIndex.highPriorityIndex.load(tx);
1:                         }
1:                     });
/////////////////////////////////////////////////////////////////////////
1:             rc.mergeFramed((InputStream)dataIn);
1:             object.writeFramed((OutputStream)dataOut);
/////////////////////////////////////////////////////////////////////////
1:                             rc.orderIndex.iterator(tx, new MessageOrderCursor(entry.getValue().lastAckedSequence)); orderIterator.hasNext(); ) {
/////////////////////////////////////////////////////////////////////////
1:                     for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext();) {
1:                                 Math.max(rc.orderIndex.nextMessageId, entry.getValue().lastAckedSequence +1);
0:                     Entry<Long,HashSet<String>> last = rc.ackPositions.getLast(tx);
0:                         Math.max(rc.orderIndex.nextMessageId, last.getKey());
/////////////////////////////////////////////////////////////////////////
0:         for (Iterator<Entry<String, LastAck>> iterator = sd.subscriptionAcks.iterator(tx); iterator.hasNext();) {
0:         sd.ackPositions.put(tx, messageSequence+1, nextMessageIdMarker);
/////////////////////////////////////////////////////////////////////////
0:     private final LinkedHashMap<TransactionId, List<Operation>> inflightTransactions = new LinkedHashMap<TransactionId, List<Operation>>();
0:     // messages that have prepared (pending) acks cannot be re-dispatched unless the outcome is rollback,
/////////////////////////////////////////////////////////////////////////
1:         TransactionId key = TransactionIdConversion.convert(info);
/////////////////////////////////////////////////////////////////////////
1:         return TransactionIdConversion.convert(transactionInfo);
/////////////////////////////////////////////////////////////////////////
0:     private Journal createJournal() throws IOException {
1:         Journal manager = new Journal();
0:         manager.setSizeAccumulator(storeSize);
/////////////////////////////////////////////////////////////////////////
1:     public Journal getJournal() throws IOException {
1:         if (journal == null) {
1:             journal = createJournal();
1:         return journal;
/////////////////////////////////////////////////////////////////////////
1:     class MessageOrderCursor{
1:         MessageOrderCursor(){
1:         MessageOrderCursor(long position){
1:             this.defaultCursorPosition=position;
1:             this.lowPriorityCursorPosition=position;
1:             this.highPriorityCursorPosition=position;
1:         MessageOrderCursor(MessageOrderCursor other){
1:             this.defaultCursorPosition=other.defaultCursorPosition;
1:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
1:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
/////////////////////////////////////////////////////////////////////////
1:             this.defaultCursorPosition=0;
1:             this.highPriorityCursorPosition=0;
1:             this.lowPriorityCursorPosition=0;
1:             if (defaultCursorPosition!=0) {
1:             if (highPriorityCursorPosition!=0) {
1:             if (lowPriorityCursorPosition!=0) {
1:            return "MessageOrderCursor:[def:" + defaultCursorPosition
1:                    + ", low:" + lowPriorityCursorPosition
1:                    + ", high:" +  highPriorityCursorPosition + "]";
1:             this.defaultCursorPosition=other.defaultCursorPosition;
1:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
1:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
/////////////////////////////////////////////////////////////////////////
1:             if (result == null && highPriorityIndex!=null) {
1:                 if (result ==null && lowPriorityIndex!=null) {
/////////////////////////////////////////////////////////////////////////
1:             if (lastDefaultKey!=null) {
1:                 cursor.defaultCursorPosition=lastDefaultKey.longValue()+1;
1:             if (lastHighKey!=null) {
1:                 cursor.highPriorityCursorPosition=lastHighKey.longValue()+1;
1:             if (lastLowKey!=null) {
1:                 cursor.lowPriorityCursorPosition=lastLowKey.longValue()+1;
/////////////////////////////////////////////////////////////////////////
1:                 BTreeIndex<Long, MessageKeys> index, Long sequenceId) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx) throws IOException{
0:             return new MessageOrderIterator(tx,cursor);
1:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx, MessageOrderCursor m) throws IOException{
0:             return new MessageOrderIterator(tx,m);
1:         class MessageOrderIterator implements Iterator<Entry<Long, MessageKeys>>{
1:             Iterator<Entry<Long, MessageKeys>>currentIterator;
1:             final Iterator<Entry<Long, MessageKeys>>highIterator;
1:             final Iterator<Entry<Long, MessageKeys>>defaultIterator;
1:             final Iterator<Entry<Long, MessageKeys>>lowIterator;
1: 
commit:c6ed5ff
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:                 process(message, lastRecoveryPosition, (Runnable)null);
/////////////////////////////////////////////////////////////////////////
0:             process(data, location, after);
0:             if (after != null) {
0:                 Runnable afterCompletion = null;
0:                 synchronized (orderedTransactionAfters) {
0:                     if (!orderedTransactionAfters.empty()) {
0:                         afterCompletion = orderedTransactionAfters.pop();
1:                     }
1:                 }
0:                 if (afterCompletion != null) {
0:                     afterCompletion.run();
1:                 } else {
0:                     // non persistent message case
0:                     after.run();
1:                 }
1: 
/////////////////////////////////////////////////////////////////////////
0:             process(data, location, (Runnable) null);
/////////////////////////////////////////////////////////////////////////
0:     void process(JournalCommand<?> data, final Location location, final Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:                 process(command, location, after);
/////////////////////////////////////////////////////////////////////////
1: 
1:             @Override
1:             public void visit(KahaProducerAuditCommand command) throws IOException {
1:                 processLocation(location);
1:             }
1: 
1:             @Override
1:             public void visit(KahaTraceCommand command) {
1:                 processLocation(location);
1:             }
/////////////////////////////////////////////////////////////////////////
1:     protected void processLocation(final Location location) {
1:         this.indexLock.writeLock().lock();
1:         try {
0:             metadata.lastUpdate = location;
1:         } finally {
1:             this.indexLock.writeLock().unlock();
1:         }
1:     }
1: 
0:     private final Stack<Runnable> orderedTransactionAfters = new Stack<Runnable>();
0:     private void push(Runnable after) {
0:         if (after != null) {
0:             synchronized (orderedTransactionAfters) {
0:                 orderedTransactionAfters.push(after);
1:             }
1:         }
1:     }
1: 
0:     protected void process(KahaCommitCommand command, Location location, final Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:             metadata.lastUpdate = location;
0:             push(after);
/////////////////////////////////////////////////////////////////////////
0:         metadata.lastUpdate = location;
/////////////////////////////////////////////////////////////////////////
0:         metadata.lastUpdate = ackLocation;
/////////////////////////////////////////////////////////////////////////
0:                     LOG.warn("setBatch: sequence " + sequence + " not found in orderindex:" + this);
commit:2b10259
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.LocationMarshaller;
/////////////////////////////////////////////////////////////////////////
1:         long start = System.currentTimeMillis();
1:         long end = System.currentTimeMillis();
0:         if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:             LOG.info("Slow KahaDB access: Journal read took: "+(end-start)+" ms");
1:         }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         rc.locationIndex.setKeyMarshaller(org.apache.kahadb.util.LocationMarshaller.INSTANCE);
commit:101e711
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.command.ActiveMQDestination;
1: import org.apache.activemq.command.MessageAck;
/////////////////////////////////////////////////////////////////////////
0:     protected final Set<String> ackedAndPrepared = new HashSet<String>();
1: 
0:     // messages that have prepared (pending) acks cannot be redispatched unless the outcome is rollback,
0:     // till then they are skipped by the store.
0:     // 'at most once' XA guarantee
0:     public void trackRecoveredAcks(ArrayList<MessageAck> acks) {
1:         this.indexLock.writeLock().lock();
1:         try {
0:             for (MessageAck ack : acks) {
0:                 ackedAndPrepared.add(ack.getLastMessageId().toString());
1:             }
1:         } finally {
1:             this.indexLock.writeLock().unlock();
1:         }
1:     }
1: 
0:     public void forgetRecoveredAcks(ArrayList<MessageAck> acks) throws IOException {
0:         if (acks != null) {
1:             this.indexLock.writeLock().lock();
1:             try {
0:                 for (MessageAck ack : acks) {
0:                     ackedAndPrepared.remove(ack.getLastMessageId().toString());
1:                 }
1:             } finally {
1:                 this.indexLock.writeLock().unlock();
1:             }
1:         }
1:     }
1: 
commit:1c1aa17
/////////////////////////////////////////////////////////////////////////
1:         final String subscriptionKey = command.getSubscriptionKey();
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:                         }
/////////////////////////////////////////////////////////////////////////
1:         if (!sd.ackPositions.isEmpty(tx)) {
/////////////////////////////////////////////////////////////////////////
1:                 } else {
0:                     // update
0:                     sd.ackPositions.put(tx, sequenceId, hs);
commit:2d121f4
/////////////////////////////////////////////////////////////////////////
1:             } else {
1:                 // update based on ackPositions for unmatched, last entry is always the next
0:                 if (!rc.ackPositions.isEmpty(tx)) {
0:                     Entry<Long,HashSet<String>> last = rc.ackPositions.getLast(tx);
1:                     rc.orderIndex.nextMessageId =
0:                         Math.max(rc.orderIndex.nextMessageId, last.getKey());
1:                 }
/////////////////////////////////////////////////////////////////////////
0:     final HashSet nextMessageIdMarker = new HashSet<String>();
/////////////////////////////////////////////////////////////////////////
0:         // add empty next to keep track of nextMessage
0:         sd.ackPositions.put(tx, messageSequence+1, nextMessageIdMarker);
commit:a6c51a4
/////////////////////////////////////////////////////////////////////////
0:     // for testing
0:     public LockFile getLockFile() {
0:         return lockFile;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     // public for testing
0:     public Location getFirstInProgressTxLocation() {
/////////////////////////////////////////////////////////////////////////
1: 
0:             // rollback any recovered inflight local transactions
0:             Set<TransactionId> toRollback = new HashSet<TransactionId>();
1:             synchronized (inflightTransactions) {
0:                 for (Iterator<TransactionId> it = inflightTransactions.keySet().iterator(); it.hasNext(); ) {
0:                     TransactionId id = it.next();
0:                     if (id.isLocalTransaction()) {
0:                         toRollback.add(id);
1:                     }
1:                 }
0:                 for (TransactionId tx: toRollback) {
0:                     LOG.debug("rolling back recovered indoubt local transaction " + tx);
0:                     store(new KahaRollbackCommand().setTransactionInfo(createTransactionInfo(tx)), false, null, null);
1:                 }
1:             }
/////////////////////////////////////////////////////////////////////////
1: 
1:     // /////////////////////////////////////////////////////////////////
1:     // Internal conversion methods.
1:     // /////////////////////////////////////////////////////////////////
1: 
0:     KahaTransactionInfo createTransactionInfo(TransactionId txid) {
0:         if (txid == null) {
0:             return null;
1:         }
0:         KahaTransactionInfo rc = new KahaTransactionInfo();
1: 
0:         if (txid.isLocalTransaction()) {
0:             LocalTransactionId t = (LocalTransactionId) txid;
0:             KahaLocalTransactionId kahaTxId = new KahaLocalTransactionId();
0:             kahaTxId.setConnectionId(t.getConnectionId().getValue());
0:             kahaTxId.setTransacitonId(t.getValue());
0:             rc.setLocalTransacitonId(kahaTxId);
1:         } else {
0:             XATransactionId t = (XATransactionId) txid;
0:             KahaXATransactionId kahaTxId = new KahaXATransactionId();
0:             kahaTxId.setBranchQualifier(new Buffer(t.getBranchQualifier()));
0:             kahaTxId.setGlobalTransactionId(new Buffer(t.getGlobalTransactionId()));
0:             kahaTxId.setFormatId(t.getFormatId());
0:             rc.setXaTransacitonId(kahaTxId);
1:         }
1:         return rc;
1:     }
commit:6b643dc
/////////////////////////////////////////////////////////////////////////
1: 
1:         // reflect last update exclusive of current checkpoint
0:         Location firstTxLocation = metadata.lastUpdate;
1: 
/////////////////////////////////////////////////////////////////////////
1: 
0:             LOG.trace("Last update: " + firstTxLocation + ", full gc candidates set: " + gcCandidateSet);
1: 
1: 
0:             // Don't GC files after the first in progress tx
0:                 if (metadata.firstInProgressTransactionLocation.getDataFileId() < firstTxLocation.getDataFileId()) {
0:                    firstTxLocation = metadata.firstInProgressTransactionLocation;
0:                 };
commit:acc3d4f
/////////////////////////////////////////////////////////////////////////
0:                     lastDefaultKey = sequence;
0:                         lastHighKey = sequence;
0:                         lastLowKey = sequence;
0:                     lastDefaultKey = sequence;
commit:aadd682
/////////////////////////////////////////////////////////////////////////
0:                 LOG.trace("gc candidates after first tx:" + firstTxLocation + ", " + gcCandidateSet);
commit:62c6c8f
/////////////////////////////////////////////////////////////////////////
0:     private final Object checkpointThreadLock = new Object();
/////////////////////////////////////////////////////////////////////////
0:         synchronized (checkpointThreadLock) {
0:             boolean start = false;
0:             if (checkpointThread == null) {
0:                 start = true;
0:             } else if (!checkpointThread.isAlive()) {
0:                 start = true;
0:                 LOG.info("KahaDB: Recovering checkpoint thread after death");
1:             }
0:             if (start) {
0:                 checkpointThread = new Thread("ActiveMQ Journal Checkpoint Worker") {
1:                     @Override
0:                     public void run() {
1:                         try {
0:                             long lastCleanup = System.currentTimeMillis();
0:                             long lastCheckpoint = System.currentTimeMillis();
0:                             // Sleep for a short time so we can periodically check
0:                             // to see if we need to exit this thread.
0:                             long sleepTime = Math.min(checkpointInterval, 500);
0:                             while (opened.get()) {
0:                                 Thread.sleep(sleepTime);
0:                                 long now = System.currentTimeMillis();
0:                                 if( now - lastCleanup >= cleanupInterval ) {
0:                                     checkpointCleanup(true);
0:                                     lastCleanup = now;
0:                                     lastCheckpoint = now;
0:                                 } else if( now - lastCheckpoint >= checkpointInterval ) {
0:                                     checkpointCleanup(false);
0:                                     lastCheckpoint = now;
1:                                 }
1:                             }
1:                         } catch (InterruptedException e) {
0:                             // Looks like someone really wants us to exit this thread...
0:                         } catch (IOException ioe) {
0:                             LOG.error("Checkpoint failed", ioe);
0:                             brokerService.handleIOException(ioe);
0:                 };
1: 
0:                 checkpointThread.setDaemon(true);
0:                 checkpointThread.start();
1:         }
/////////////////////////////////////////////////////////////////////////
0:             synchronized (checkpointThreadLock) {
0: 	            checkpointThread.join();
1:             }
/////////////////////////////////////////////////////////////////////////
commit:62609f0
/////////////////////////////////////////////////////////////////////////
1: 
0:             final TreeSet<Integer> completeFileSet = new TreeSet<Integer>(journal.getFileMap().keySet());
0:             final TreeSet<Integer> gcCandidateSet = new TreeSet<Integer>(completeFileSet);
/////////////////////////////////////////////////////////////////////////
0:                         if (completeFileSet.contains(referencedFileId) && !gcCandidates.contains(referencedFileId)) {
commit:9e40b91
/////////////////////////////////////////////////////////////////////////
0:         return store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), true, null, null);
commit:aec047d
/////////////////////////////////////////////////////////////////////////
1:             this.priority = MessageOrderIndex.LO;
/////////////////////////////////////////////////////////////////////////
1:                     lastGetPriority = HI;
commit:8871c67
/////////////////////////////////////////////////////////////////////////
1:         if (sd.subscriptions != null && sd.subscriptions.isEmpty(tx)) {
/////////////////////////////////////////////////////////////////////////
0:                 if (sd.subscriptions != null && !sd.subscriptions.isEmpty(tx)) {
0:                     addAckLocationForNewMessage(tx, sd, id);
1:                 }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:                 if (command.getAck() != UNMATCHED) {
1:                     sd.orderIndex.get(tx, sequence);
1:                     byte priority = sd.orderIndex.lastGetPriority();
1:                     sd.subscriptionAcks.put(tx, subscriptionKey, new LastAck(sequence, priority));
1:                 // The following method handles deleting un-referenced messages.
0:                 removeAckLocation(tx, sd, subscriptionKey, sequence);
/////////////////////////////////////////////////////////////////////////
1:             } else {
0:                 addAckLocationForRetroactiveSub(tx, sd, ackLocation, subscriptionKey);
1:             sd.subscriptionAcks.put(tx, subscriptionKey, new LastAck(ackLocation));
1:             sd.subscriptionAcks.remove(tx, subscriptionKey);
0:             removeAckLocationsForSub(tx, sd, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1: 
1:     class LastAck {
1:         long lastAckedSequence;
1:         byte priority;
1: 
1:         public LastAck(LastAck source) {
1:             this.lastAckedSequence = source.lastAckedSequence;
1:             this.priority = source.priority;
1:         }
1: 
1:         public LastAck() {
1:             this.priority = MessageOrderIndex.HI;
1:         }
1: 
1:         public LastAck(long ackLocation) {
1:             this.lastAckedSequence = ackLocation;
1:             this.priority = MessageOrderIndex.HI;
1:         }
1: 
1:         public LastAck(long ackLocation, byte priority) {
1:             this.lastAckedSequence = ackLocation;
1:             this.priority = priority;
1:         }
1: 
1:         public String toString() {
1:             return "[" + lastAckedSequence + ":" + priority + "]";
1:         }
1:     }
1: 
1:     protected class LastAckMarshaller implements Marshaller<LastAck> {
1:         
1:         public void writePayload(LastAck object, DataOutput dataOut) throws IOException {
1:             dataOut.writeLong(object.lastAckedSequence);
1:             dataOut.writeByte(object.priority);
1:         }
1: 
1:         public LastAck readPayload(DataInput dataIn) throws IOException {
1:             LastAck lastAcked = new LastAck();
1:             lastAcked.lastAckedSequence = dataIn.readLong();
1:             if (metadata.version >= 3) {
1:                 lastAcked.priority = dataIn.readByte();
1:             }
1:             return lastAcked;
1:         }
1: 
1:         public int getFixedSize() {
1:             return 9;
1:         }
1: 
1:         public LastAck deepCopy(LastAck source) {
1:             return new LastAck(source);
1:         }
1: 
1:         public boolean isDeepCopySupported() {
1:             return true;
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:         BTreeIndex<String, LastAck> subscriptionAcks;
/////////////////////////////////////////////////////////////////////////
0:                 value.subscriptionAcks = new BTreeIndex<String, LastAck>(pageFile, dataIn.readLong());
/////////////////////////////////////////////////////////////////////////
0:                 rc.subscriptionAcks = new BTreeIndex<String, LastAck>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:             rc.subscriptionAcks.setValueMarshaller(new LastAckMarshaller());
/////////////////////////////////////////////////////////////////////////
1: 
1:                 // on upgrade need to fill ackLocation with available messages past last ack
1:                 for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
1:                     Entry<String, LastAck> entry = iterator.next();
1:                     for (Iterator<Entry<Long, MessageKeys>> orderIterator =
0:                             rc.orderIndex.iterator(tx, new MessageOrderCursor(entry.getValue().lastAckedSequence)); orderIterator.hasNext(); ) {
1:                         Long sequence = orderIterator.next().getKey();
1:                         addAckLocation(tx, rc, sequence, entry.getKey());
1:                     }
1:                     // modify so it is upgraded                   
1:                     rc.subscriptionAcks.put(tx, entry.getKey(), entry.getValue());
1:                 if (!rc.subscriptionAcks.isEmpty(tx)) {
0:                     for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext();) {
1:                         Entry<String, LastAck> entry = iterator.next();
1:                         rc.orderIndex.nextMessageId =
0:                                 Math.max(rc.orderIndex.nextMessageId, entry.getValue().lastAckedSequence +1);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     // new sub is interested in potentially all existing messages
0:     private void addAckLocationForRetroactiveSub(Transaction tx, StoredDestination sd, Long messageSequence, String subscriptionKey) throws IOException {
0:         for (Iterator<Entry<Long, HashSet<String>>> iterator = sd.ackPositions.iterator(tx, messageSequence); iterator.hasNext(); ) {
0:             Entry<Long, HashSet<String>> entry = iterator.next();
0:             entry.getValue().add(subscriptionKey);
0:             sd.ackPositions.put(tx, entry.getKey(), entry.getValue());
1:         }
1:     }
1: 
1:     // on a new message add, all existing subs are interested in this message
0:     private void addAckLocationForNewMessage(Transaction tx, StoredDestination sd, Long messageSequence) throws IOException {
0:         HashSet hs = new HashSet<String>();
0:         for (Iterator<Entry<String, LastAck>> iterator = sd.subscriptionAcks.iterator(tx); iterator.hasNext();) {
1:             Entry<String, LastAck> entry = iterator.next();
0:             hs.add(entry.getKey());
1:         }
0:         sd.ackPositions.put(tx, messageSequence, hs);
1:     }
1: 
0:     private void removeAckLocationsForSub(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
0:         if (!sd.ackPositions.isEmpty(tx)) {        
0:             Long end = sd.ackPositions.getLast(tx).getKey();
0:             for (Long sequence = sd.ackPositions.getFirst(tx).getKey(); sequence <= end; sequence++) {
0:                 removeAckLocation(tx, sd, subscriptionKey, sequence);
1:             }
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:                     // Find all the entries that need to get deleted.
0:                     ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
1:                     sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
1:                     // Do the actual deletes.
1:                     for (Entry<Long, MessageKeys> entry : deletes) {
1:                         sd.locationIndex.remove(tx, entry.getValue().location);
1:                         sd.messageIdIndex.remove(tx, entry.getValue().messageId);
1:                         sd.orderIndex.remove(tx, entry.getKey());
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     class MessageOrderIndex {
1:         static final byte HI = 9;
1:         static final byte LO = 0;
1:         static final byte DEF = 4;
1: 
/////////////////////////////////////////////////////////////////////////
1:         byte lastGetPriority;
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:         void setBatch(Transaction tx, LastAck last) throws IOException {
1:             setBatch(tx, last.lastAckedSequence);
1:             if (cursor.defaultCursorPosition == 0
1:                     && cursor.highPriorityCursorPosition == 0
1:                     && cursor.lowPriorityCursorPosition == 0) {
1:                 long next = last.lastAckedSequence + 1;
1:                 switch (last.priority) {
1:                     case DEF:
1:                         cursor.defaultCursorPosition = next;
1:                         cursor.highPriorityCursorPosition = next;
0:                         break;
1:                     case HI:
1:                         cursor.highPriorityCursorPosition = next;
0:                         break;
1:                     case LO:
1:                         cursor.lowPriorityCursorPosition = next;
1:                         cursor.defaultCursorPosition = next;
1:                         cursor.highPriorityCursorPosition = next;
0:                         break;
1:                 }
1:             }
1:         }
/////////////////////////////////////////////////////////////////////////
1:                     lastGetPriority = LO;
1:                 } else {
0:                   lastGetPriority = HI;
1:             } else {
1:                 lastGetPriority = DEF;
/////////////////////////////////////////////////////////////////////////
1: 
1:         public byte lastGetPriority() {
1:             return lastGetPriority;
1:         }
1: 
commit:3f0cf98
/////////////////////////////////////////////////////////////////////////
1: import java.io.ByteArrayInputStream;
/////////////////////////////////////////////////////////////////////////
0:     static final int VERSION = 3;
/////////////////////////////////////////////////////////////////////////
1:             os.writeInt(VERSION);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             pageFile.flush();            
/////////////////////////////////////////////////////////////////////////
0:         if (sd.subscriptions != null && sd.ackPositions.isEmpty(tx)) {
/////////////////////////////////////////////////////////////////////////
0:                 if (prev != null) {
0:                     if (ackSequenceToStore != sequence) {
0:                         // unmatched, need to add ack locations for the intermediate sequences
0:                         for (long matchedGapSequence = extractSequenceId(prev) + 1; matchedGapSequence < sequence; matchedGapSequence++) {
0:                             addAckLocation(tx, sd, matchedGapSequence, subscriptionKey);
1:                         }
0:                     // The following method handles deleting un-referenced messages.
0:                     removeAckLocation(tx, sd, subscriptionKey, extractSequenceId(prev));
0:                 addAckLocation(tx, sd, sequence, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1: 
1:             sd.ackPositions.clear(tx);
1:             sd.ackPositions.unload(tx);
0:             tx.free(sd.ackPositions.getPageId());
/////////////////////////////////////////////////////////////////////////
0:             addAckLocation(tx, sd, ackLocation, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
0:         BTreeIndex<Long, HashSet<String>> ackPositions;
1:             final StoredDestination value = new StoredDestination();
/////////////////////////////////////////////////////////////////////////
0:                 if (metadata.version >= 3) {
0:                     value.ackPositions = new BTreeIndex<Long, HashSet<String>>(pageFile, dataIn.readLong());
1:                 } else {
1:                     // upgrade
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         public void execute(Transaction tx) throws IOException {
0:                             value.ackPositions = new BTreeIndex<Long, HashSet<String>>(pageFile, tx.allocate());
0:                             value.ackPositions.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             value.ackPositions.setValueMarshaller(HashSetStringMarshaller.INSTANCE);
1:                             value.ackPositions.load(tx);
1:                         }
1:                     });
1:                 }
1:             } else {
1:                     // upgrade
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         public void execute(Transaction tx) throws IOException {
0:                             value.orderIndex.lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                             value.orderIndex.lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             value.orderIndex.lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                             value.orderIndex.lowPriorityIndex.load(tx);
1: 
0:                             value.orderIndex.highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                             value.orderIndex.highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             value.orderIndex.highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                             value.orderIndex.highPriorityIndex.load(tx);
1:                         }
1:                     });
1: 
/////////////////////////////////////////////////////////////////////////
0:                 dataOut.writeLong(value.ackPositions.getPageId());
1:             dataOut.writeLong(value.orderIndex.lowPriorityIndex.getPageId());
1:             dataOut.writeLong(value.orderIndex.highPriorityIndex.getPageId());
/////////////////////////////////////////////////////////////////////////
0:                 rc.ackPositions = new BTreeIndex<Long, HashSet<String>>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
0:             rc.ackPositions.setKeyMarshaller(LongMarshaller.INSTANCE);
0:             rc.ackPositions.setValueMarshaller(HashSetStringMarshaller.INSTANCE);
1:             rc.ackPositions.load(tx);
1: 
1:             if (metadata.version < 3) {
0:                 // on upgrade need to fill ackLocation
0:                 for (Iterator<Entry<String, Long>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext();) {
0:                     Entry<String, Long> entry = iterator.next();
0:                     addAckLocation(tx, rc, extractSequenceId(entry.getValue()), entry.getKey());
1:                 }
0:                 if (!rc.ackPositions.isEmpty(tx)) {
0:                     Long lastAckedMessageId = rc.ackPositions.getLast(tx).getKey();
/////////////////////////////////////////////////////////////////////////
1: 
0:         if (metadata.version < 3) {
1:             // store again after upgrade
1:             metadata.destinations.put(tx, key, rc);
1:         }        
/////////////////////////////////////////////////////////////////////////
1:     private void addAckLocation(Transaction tx, StoredDestination sd, Long messageSequence, String subscriptionKey) throws IOException {
0:         HashSet<String> hs = sd.ackPositions.get(tx, messageSequence);
0:         // every ack location addition needs to be a btree modification to get it stored
0:         sd.ackPositions.put(tx, messageSequence, hs);
/////////////////////////////////////////////////////////////////////////
0:             HashSet<String> hs = sd.ackPositions.get(tx, sequenceId);
0:                     HashSet<String> firstSet = sd.ackPositions.getFirst(tx).getValue();
0:                     sd.ackPositions.remove(tx, sequenceId);
/////////////////////////////////////////////////////////////////////////
1:             lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:             lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:             lowPriorityIndex.load(tx);
1:             highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:             highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:             highPriorityIndex.load(tx);
/////////////////////////////////////////////////////////////////////////
1:     private static class HashSetStringMarshaller extends VariableMarshaller<HashSet<String>> {
1:         final static HashSetStringMarshaller INSTANCE = new HashSetStringMarshaller();
1: 
1:         public void writePayload(HashSet<String> object, DataOutput dataOut) throws IOException {
1:             ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:             ObjectOutputStream oout = new ObjectOutputStream(baos);
1:             oout.writeObject(object);
1:             oout.flush();
1:             oout.close();
1:             byte[] data = baos.toByteArray();
1:             dataOut.writeInt(data.length);
1:             dataOut.write(data);
1:         }
1: 
1:         public HashSet<String> readPayload(DataInput dataIn) throws IOException {
1:             int dataLen = dataIn.readInt();
1:             byte[] data = new byte[dataLen];
1:             dataIn.readFully(data);
1:             ByteArrayInputStream bais = new ByteArrayInputStream(data);
1:             ObjectInputStream oin = new ObjectInputStream(bais);
1:             try {
1:                 return (HashSet<String>) oin.readObject();
1:             } catch (ClassNotFoundException cfe) {
1: 	            IOException ioe = new IOException("Failed to read HashSet<String>: " + cfe);
1: 	            ioe.initCause(cfe);
1: 	            throw ioe;
1: 	        }
1:         }
1:     }
commit:6dea944
/////////////////////////////////////////////////////////////////////////
0:                 if (ackSequenceToStore != sequence) {
0:                     // unmatched, need to add ack locations for the intermediate sequences
0:                     for (long matchedGapSequence = extractSequenceId(prev) + 1; matchedGapSequence < sequence; matchedGapSequence++) {
0:                         addAckLocation(sd, matchedGapSequence, subscriptionKey);
1:                     }
1:                 }
commit:6fd292d
/////////////////////////////////////////////////////////////////////////
0:     static final long UNMATCHED_SEQ = -2;
1: 
/////////////////////////////////////////////////////////////////////////
0:     protected Long extractSequenceId(Long prev) {
0:         if (prev < NOT_ACKED) {
0:             prev = Math.abs(prev) + UNMATCHED_SEQ;
1:         }
0:         return prev;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
0:                 Long ackSequenceToStore = sequence;
0:                     // store negative sequence to indicate that it was unmatched
0:                     ackSequenceToStore = new Long(UNMATCHED_SEQ - sequence);
1: 
0:                 Long prev = sd.subscriptionAcks.put(tx, subscriptionKey, ackSequenceToStore);
1: 
0:                 removeAckLocation(tx, sd, subscriptionKey, extractSequenceId(prev));
/////////////////////////////////////////////////////////////////////////
0:                 removeAckLocation(tx, sd, subscriptionKey, extractSequenceId(prev));
/////////////////////////////////////////////////////////////////////////
0:                 addAckLocation(rc, extractSequenceId(entry.getValue()), entry.getKey());
commit:5477bc0
/////////////////////////////////////////////////////////////////////////
1:     protected static final Buffer UNMATCHED;
1:     static {
1:         UNMATCHED = new Buffer(new byte[]{});
1:     }
/////////////////////////////////////////////////////////////////////////
0:                     sd.subscriptionAcks.put(tx, subscriptionKey, prev);
commit:6ddbba4
/////////////////////////////////////////////////////////////////////////
0:     protected static final Buffer UNMATCHED = new Buffer(new byte[]{});
/////////////////////////////////////////////////////////////////////////
0:                 if (command.getAck() == UNMATCHED) {
0:                     sd.subscriptionAcks.put(tx, subscriptionKey, prev);    
1:                 }
0:                 // The following method handles deleting un-referenced messages.
0:                 removeAckLocation(tx, sd, subscriptionKey, prev);
1: 
/////////////////////////////////////////////////////////////////////////
0:                     HashSet<String> firstSet = sd.ackPositions.values().iterator().next();
0:                     // Did we just empty out the first set in the
0:                     // ordered list of ack locations? Then it's time to
0:                     // delete some messages.
0:                     if (hs == firstSet) {
1:                         // Find all the entries that need to get deleted.
0:                         ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
0:                         sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
1: 
1:                         // Do the actual deletes.
1:                         for (Entry<Long, MessageKeys> entry : deletes) {
1:                             sd.locationIndex.remove(tx, entry.getValue().location);
0:                             sd.messageIdIndex.remove(tx,entry.getValue().messageId);
0:                             sd.orderIndex.remove(tx,entry.getKey());
1:                         }
commit:514ef7d
/////////////////////////////////////////////////////////////////////////
1: 
0:                 // The following method handles deleting un-referenced messages.
0:                 removeAckLocation(tx, sd, subscriptionKey, sequence);
/////////////////////////////////////////////////////////////////////////
0:                 LOG.trace("gc candidates after first tx:" + firstTxLocation.getDataFileId() + ", " + gcCandidateSet);
1:             for (Entry<String, StoredDestination> entry : storedDestinations.entrySet()) {
1:                 entry.getValue().locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
/////////////////////////////////////////////////////////////////////////
1:                 LOG.trace("gc candidates after dest:" + entry.getKey() + ", " + gcCandidateSet);
1:             LOG.trace("gc candidates: " + gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
1:                         LOG.trace("not removing data file: " + candidate
/////////////////////////////////////////////////////////////////////////
0:                     ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
0:                     sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
0:                     // Do the actual delete.
0:                     for (Entry<Long, MessageKeys> entry : deletes) {
0:                         sd.locationIndex.remove(tx, entry.getValue().location);
1:                         sd.messageIdIndex.remove(tx, entry.getValue().messageId);
1:                         sd.orderIndex.remove(tx, entry.getKey());
/////////////////////////////////////////////////////////////////////////
1: 
0:             Iterator<Entry<Long, MessageKeys>> iterator = index.iterator(tx, sequenceId);
1:             deletes.add(iterator.next());
1:         }
commit:5cbb4db
/////////////////////////////////////////////////////////////////////////
0:                 if (entry.getKey().compareTo(sequenceId) == 0) {
commit:9705671
/////////////////////////////////////////////////////////////////////////
1: 
1:         public String toString() {
0:            return "MessageOrderCursor:[def:" + defaultCursorPosition
0:                    + ", low:" + lowPriorityCursorPosition
0:                    + ", high:" +  highPriorityCursorPosition + "]";
1:         }
1: 
1:         public void sync(MessageOrderCursor other) {
0:             this.defaultCursorPosition=other.defaultCursorPosition;
0:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
0:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
1:         }
/////////////////////////////////////////////////////////////////////////
1:             if (defaultPriorityIndex.containsKey(tx, sequenceId)) {
1:                 getDeleteList(tx, deletes, defaultPriorityIndex, sequenceId);
1:             } else if (highPriorityIndex != null && highPriorityIndex.containsKey(tx, sequenceId)) {
1:             } else if (lowPriorityIndex != null && lowPriorityIndex.containsKey(tx, sequenceId)) {
/////////////////////////////////////////////////////////////////////////
commit:1e900b3
/////////////////////////////////////////////////////////////////////////
0:             LOG.debug("gc candidates: " + gcCandidateSet);
commit:a5135f1
/////////////////////////////////////////////////////////////////////////
0:     public static final int LOG_SLOW_ACCESS_TIME = Integer.parseInt(System.getProperty(PROPERTY_LOG_SLOW_ACCESS_TIME, "0"));
commit:dd68c61
/////////////////////////////////////////////////////////////////////////
0:             final TreeSet<Integer> gcCandidates = new TreeSet<Integer>(gcCandidateSet);
0:                         if (journal.getFileMap().containsKey(referencedFileId) && !gcCandidates.contains(referencedFileId)) {
commit:c458bd1
/////////////////////////////////////////////////////////////////////////
0:                 LOG.warn("Duplicate message add attempt rejected. Destination: " + command.getDestination().getName() + ", Message id: " + command.getMessageId());
commit:815c2f3
/////////////////////////////////////////////////////////////////////////
1:                 sd.locationIndex.remove(tx, location);
commit:6f7e3fc
/////////////////////////////////////////////////////////////////////////
1: 
1:     protected StoredDestination getExistingStoredDestination(KahaDestination destination, Transaction tx) throws IOException {
1:         String key = key(destination);
1:         StoredDestination rc = storedDestinations.get(key);
1:         if (rc == null && metadata.destinations.containsKey(tx, key)) {
1:             rc = getStoredDestination(destination, tx);
1:         }
1:         return rc;
1:     }
1: 
commit:f2517c0
/////////////////////////////////////////////////////////////////////////
1:     protected boolean forceRecoverIndex = false;
/////////////////////////////////////////////////////////////////////////
0: 	            LOG.info("Recovering from the journal ...");
/////////////////////////////////////////////////////////////////////////
1: 
1:         if (!this.forceRecoverIndex) {
1: 
1:             // If we need to recover the transactions..
1:             if (metadata.firstInProgressTransactionLocation != null) {
1:                 return metadata.firstInProgressTransactionLocation;
1:             }
1:             // Perhaps there were no transactions...
0:             if( metadata.lastUpdate!=null) {
1:                 // Start replay at the record after the last one recorded in the index file.
0:                 return journal.getNextLocation(metadata.lastUpdate);
1:             }
/////////////////////////////////////////////////////////////////////////
1:                 recordAckMessageReferenceLocation(ackLocation, keys.location);
/////////////////////////////////////////////////////////////////////////
0:     Map<Integer, Set<Integer>> ackMessageFileMap = new HashMap<Integer, Set<Integer>>();
1:     private void recordAckMessageReferenceLocation(Location ackLocation, Location messageLocation) {
0:         Set<Integer> referenceFileIds = ackMessageFileMap.get(Integer.valueOf(ackLocation.getDataFileId()));
1:         if (referenceFileIds == null) {
0:             referenceFileIds = new HashSet<Integer>();
1:             referenceFileIds.add(messageLocation.getDataFileId());
0:             ackMessageFileMap.put(ackLocation.getDataFileId(), referenceFileIds);
1:         } else {
1:             Integer id = Integer.valueOf(messageLocation.getDataFileId());
1:             if (!referenceFileIds.contains(id)) {
1:                 referenceFileIds.add(id);
1:             }
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:             // check we are not deleting file with ack for in-use journal files
1:             Iterator<Integer> candidates = gcCandidateSet.iterator();
1:             while (candidates.hasNext()) {
1:                 Integer candidate = candidates.next();
0:                 Set<Integer> referencedFileIds = ackMessageFileMap.get(candidate);
1:                 if (referencedFileIds != null) {
1:                     for (Integer referencedFileId : referencedFileIds) {
0:                         if (journal.getFileMap().containsKey(referencedFileId) && !gcCandidateSet.contains(referencedFileId)) {
1:                             // active file that is not targeted for deletion is referenced so don't delete
1:                             candidates.remove();
0:                             break;
1:                         }
1:                     }
1:                     if (gcCandidateSet.contains(candidate)) {
0:                         ackMessageFileMap.remove(candidate);
1:                     } else {
0:                         LOG.debug("not removing data file: " + candidate
1:                                 + " as contained ack(s) refer to referenced file: " + referencedFileIds);
1:                     }
1:                 }
1:             }
1: 
commit:b1d7a78
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:             List<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:             inflightTx.add(new AddOpperation(command, location));
/////////////////////////////////////////////////////////////////////////
0:            List<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:            inflightTx.add(new RemoveOpperation(command, location));
/////////////////////////////////////////////////////////////////////////
1:         List<Operation> inflightTx;
/////////////////////////////////////////////////////////////////////////
1:         final List<Operation> messagingTx = inflightTx;
/////////////////////////////////////////////////////////////////////////
0:         TransactionId key = key(command.getTransactionInfo());
1:             List<Operation> tx = inflightTransactions.remove(key);
/////////////////////////////////////////////////////////////////////////
0:         TransactionId key = key(command.getTransactionInfo());
0:             List<Operation> tx = inflightTransactions.remove(key);
/////////////////////////////////////////////////////////////////////////
0:     protected final LinkedHashMap<TransactionId, List<Operation>> inflightTransactions = new LinkedHashMap<TransactionId, List<Operation>>();
0:     protected final LinkedHashMap<TransactionId, List<Operation>> preparedTransactions = new LinkedHashMap<TransactionId, List<Operation>>();
0:     private List<Operation> getInflightTx(KahaTransactionInfo info, Location location) {
1:         List<Operation> tx;
1:         synchronized (inflightTransactions) {
1:             tx = inflightTransactions.get(key);
1:             if (tx == null) {
1:                 tx = Collections.synchronizedList(new ArrayList<Operation>());
1:                 inflightTransactions.put(key, tx);
1:             }
commit:5763561
/////////////////////////////////////////////////////////////////////////
1: import java.util.concurrent.atomic.AtomicLong;
/////////////////////////////////////////////////////////////////////////
0:     protected AtomicLong storeSize = new AtomicLong(0);
/////////////////////////////////////////////////////////////////////////
0:         manager.setSizeAccumulator(storeSize);
commit:a6a6a70
/////////////////////////////////////////////////////////////////////////
1: import java.io.ByteArrayOutputStream;
0: import java.io.EOFException;
0: import java.io.ObjectInputStream;
0: import java.io.ObjectOutputStream;
/////////////////////////////////////////////////////////////////////////
1: 
1: import org.apache.activemq.ActiveMQMessageAuditNoSync;
0: import org.apache.activemq.command.MessageId;
1: import org.apache.activemq.protobuf.Buffer;
0: import org.apache.activemq.store.kahadb.data.KahaProducerAuditCommand;
/////////////////////////////////////////////////////////////////////////
1:     static final int CLOSED_STATE = 1;
1:     static final int OPEN_STATE = 2;
1:     static final long NOT_ACKED = -1;
/////////////////////////////////////////////////////////////////////////
1:         protected Location producerSequenceIdTrackerLocation = null;
1:         protected transient ActiveMQMessageAuditNoSync producerSequenceIdTracker = new ActiveMQMessageAuditNoSync();
/////////////////////////////////////////////////////////////////////////
1:             try {
1:                 if (is.readBoolean()) {
1:                     producerSequenceIdTrackerLocation = LocationMarshaller.INSTANCE.readPayload(is);
1:                 } else {
1:                     producerSequenceIdTrackerLocation = null;
1:                 }
1:             } catch (EOFException expectedOnUpgrade) {
1:             }
/////////////////////////////////////////////////////////////////////////
1:             
1:             if (producerSequenceIdTrackerLocation != null) {
1:                 os.writeBoolean(true);
1:                 LocationMarshaller.INSTANCE.writePayload(producerSequenceIdTrackerLocation, os);
1:             } else {
1:                 os.writeBoolean(false);
1:             }
/////////////////////////////////////////////////////////////////////////
1: 	protected Metadata metadata = new Metadata();
/////////////////////////////////////////////////////////////////////////
1:     int setIndexWriteBatchSize = PageFile.DEFAULT_WRITE_BATCH_SIZE;
1:     
/////////////////////////////////////////////////////////////////////////
1:             if (!inflightTransactions.isEmpty()) {
0:                 l = inflightTransactions.values().iterator().next().get(0).getLocation();
1:             if (!preparedTransactions.isEmpty()) {
0:                 Location t = preparedTransactions.values().iterator().next().get(0).getLocation();
0:                 if (l==null || t.compareTo(l) <= 0) {
0:                     l = t;
1:                 }
1:             }
/////////////////////////////////////////////////////////////////////////
0: 	        Location producerAuditPosition = recoverProducerAudit();
0: 	        Location lastIndoubtPosition = getRecoveryPosition();
1: 	        
0: 	        Location recoveryPosition = minimum(producerAuditPosition, lastIndoubtPosition);
1: 	            
0: 	        if (recoveryPosition != null) {  
0: 	            int redoCounter = 0;
0: 	            LOG.info("Recoverying from the journal ...");
0: 	            while (recoveryPosition != null) {
0: 	                JournalCommand<?> message = load(recoveryPosition);
0: 	                metadata.lastUpdate = recoveryPosition;
0: 	                process(message, recoveryPosition, lastIndoubtPosition);
0: 	                redoCounter++;
0: 	                recoveryPosition = journal.getNextLocation(recoveryPosition);
1: 	            }
1: 	            long end = System.currentTimeMillis();
0: 	            LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1: 	        
/////////////////////////////////////////////////////////////////////////
0: 	private Location minimum(Location producerAuditPosition,
0:             Location lastIndoubtPosition) {
1: 	    Location min = null;
0: 	    if (producerAuditPosition != null) {
0: 	        min = producerAuditPosition;
0: 	        if (lastIndoubtPosition != null && lastIndoubtPosition.compareTo(producerAuditPosition) < 0) {
0: 	            min = lastIndoubtPosition;
1: 	        }
1: 	    } else {
0: 	        min = lastIndoubtPosition;
1: 	    }
1: 	    return min;
1:     }
1: 	
0: 	private Location recoverProducerAudit() throws IOException {
1: 	    if (metadata.producerSequenceIdTrackerLocation != null) {
0: 	        KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(metadata.producerSequenceIdTrackerLocation);
1: 	        try {
1: 	            ObjectInputStream objectIn = new ObjectInputStream(audit.getAudit().newInput());
1: 	            metadata.producerSequenceIdTracker = (ActiveMQMessageAuditNoSync) objectIn.readObject();
0: 	        } catch (ClassNotFoundException cfe) {
0: 	            IOException ioe = new IOException("Failed to read producerAudit: " + cfe);
0: 	            ioe.initCause(cfe);
1: 	            throw ioe;
1: 	        }
0: 	        return journal.getNextLocation(metadata.producerSequenceIdTrackerLocation);
1: 	    } else {
0: 	        // got no audit stored so got to recreate via replay from start of the journal
1: 	        return journal.getNextLocation(null);
1: 	    }
1:     }
1: 
0:     protected void recoverIndex(Transaction tx) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:                 metadata.producerSequenceIdTracker.rollback(new MessageId(keys.messageId));
/////////////////////////////////////////////////////////////////////////
0: 	            JournalCommand<?> message = load(lastRecoveryPosition);
/////////////////////////////////////////////////////////////////////////
0:     private Location getRecoveryPosition() throws IOException {
1:         
/////////////////////////////////////////////////////////////////////////
1: 	    
/////////////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand<?> data) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand<?> data, boolean sync, Runnable before,Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:     public JournalCommand<?> load(Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:         JournalCommand<?> message = (JournalCommand<?>)type.createMessage();
1:     
1:     /**
1:      * do minimal recovery till we reach the last inDoubtLocation
0:      * @param data
0:      * @param location
0:      * @param inDoubtlocation
1:      * @throws IOException
1:      */
1:     void process(JournalCommand<?> data, final Location location, final Location inDoubtlocation) throws IOException {
1:         if (inDoubtlocation != null && location.compareTo(inDoubtlocation) >= 0) {
0:             process(data, location);
1:         } else {
1:             // just recover producer audit
1:             data.visit(new Visitor() {
1:                 public void visit(KahaAddMessageCommand command) throws IOException {
1:                     metadata.producerSequenceIdTracker.isDuplicate(command.getMessageId());
1:                 }
1:             });
1:         }
1:     }
/////////////////////////////////////////////////////////////////////////
0:     void process(JournalCommand<?> data, final Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:                 sd.orderIndex.put(tx, id, new MessageKeys(command.getMessageId(), location));            
/////////////////////////////////////////////////////////////////////////
1:         // record this id in any event, initial send or recovery
1:         metadata.producerSequenceIdTracker.isDuplicate(command.getMessageId());
/////////////////////////////////////////////////////////////////////////
0:         metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit();
/////////////////////////////////////////////////////////////////////////
0:     private Location checkpointProducerAudit() throws IOException {
1:         ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:         ObjectOutputStream oout = new ObjectOutputStream(baos);
1:         oout.writeObject(metadata.producerSequenceIdTracker);
1:         oout.flush();
1:         oout.close();
0:         return store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())));
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     public void setMaxFailoverProducersToTrack(int maxFailoverProducersToTrack) {
1:         this.metadata.producerSequenceIdTracker.setMaximumNumberOfProducersToTrack(maxFailoverProducersToTrack);
1:     }
1:     
1:     public int getMaxFailoverProducersToTrack() {
1:         return this.metadata.producerSequenceIdTracker.getMaximumNumberOfProducersToTrack();
1:     }
1:     
1:     public void setFailoverProducersAuditDepth(int failoverProducersAuditDepth) {
1:         this.metadata.producerSequenceIdTracker.setAuditDepth(failoverProducersAuditDepth);
1:     }
1:     
1:     public int getFailoverProducersAuditDepth() {
1:         return this.metadata.producerSequenceIdTracker.getAuditDepth();
1:     }
1:     
commit:76f842d
/////////////////////////////////////////////////////////////////////////
1:         synchronized (inflightTransactions) {
/////////////////////////////////////////////////////////////////////////
1:         }
/////////////////////////////////////////////////////////////////////////
1:             synchronized (inflightTransactions) {
/////////////////////////////////////////////////////////////////////////
1:             synchronized (inflightTransactions) {
/////////////////////////////////////////////////////////////////////////
0:         ArrayList<Operation> inflightTx = null;
0:         synchronized (inflightTransactions) {
1:             inflightTx = inflightTransactions.remove(key);
1:         }
1:         if (inflightTx == null) {
0:             return;
1:         }
0:         final ArrayList<Operation> messagingTx = inflightTx;
0:         synchronized (indexMutex) {
/////////////////////////////////////////////////////////////////////////
0:         synchronized (inflightTransactions) {
/////////////////////////////////////////////////////////////////////////
0:         synchronized (inflightTransactions) {
commit:3271401
/////////////////////////////////////////////////////////////////////////
0:     private static final long NOT_ACKED = -1;
/////////////////////////////////////////////////////////////////////////
0:             long ackLocation=NOT_ACKED;
/////////////////////////////////////////////////////////////////////////
1:             
0:             if (rc.nextMessageId == 0) {
1:                 // check for existing durable sub all acked out - pull next seq from acks as messages are gone
0:                 if (!rc.ackPositions.isEmpty()) {
0:                     Long lastAckedMessageId = rc.ackPositions.lastKey();
0:                     if (lastAckedMessageId != NOT_ACKED) {
0:                         rc.nextMessageId = lastAckedMessageId+1;
1:                     }
1:                 }
1:             }
commit:33f4190
/////////////////////////////////////////////////////////////////////////
commit:e1389a6
/////////////////////////////////////////////////////////////////////////
0:         return store(data, false, null);
/////////////////////////////////////////////////////////////////////////
0:      * @param done 
0:     public Location store(JournalCommand data, boolean sync, Runnable done) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:             if (done != null) {
0:                 done.run();
1:             }
commit:722258e
/////////////////////////////////////////////////////////////////////////
1:                 if (keys != null) {
1:                     sd.locationIndex.remove(tx, keys.location);
1:                 }
commit:8f8f9ac
/////////////////////////////////////////////////////////////////////////
1:     	long start;
1:             start = System.currentTimeMillis();
commit:039a15f
/////////////////////////////////////////////////////////////////////////
0: 	        checkpointThread.setDaemon(true);
commit:356c39d
/////////////////////////////////////////////////////////////////////////
1:     int journalMaxWriteBatchSize = Journal.DEFAULT_MAX_WRITE_BATCH_SIZE;
/////////////////////////////////////////////////////////////////////////
1:         manager.setWriteBatchSize(getJournalMaxWriteBatchSize());
1:     public int getJournalMaxWriteBatchSize() {
1:         return journalMaxWriteBatchSize;
1:     }
1:     
1:     public void setJournalMaxWriteBatchSize(int journalMaxWriteBatchSize) {
1:         this.journalMaxWriteBatchSize = journalMaxWriteBatchSize;
1:     }
1: 
commit:c42d980
/////////////////////////////////////////////////////////////////////////
1:     int journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
/////////////////////////////////////////////////////////////////////////
1:     public void setJournalMaxFileLength(int journalMaxFileLength) {
1:     public int getJournalMaxFileLength() {
commit:880f3d6
/////////////////////////////////////////////////////////////////////////
0:     long journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
/////////////////////////////////////////////////////////////////////////
0:     public void setJournalMaxFileLength(long journalMaxFileLength) {
0:     public long getJournalMaxFileLength() {
commit:38b840a
/////////////////////////////////////////////////////////////////////////
0: 		File lockFileName = new File(directory, "lock");
0: 		lockFile = new LockFile(lockFileName, true);
0: 		if (failIfDatabaseIsLocked) {
0: 		    lockFile.lock();
1: 		} else {
0: 		    while (true) {
1: 		        try {
0: 		            lockFile.lock();
0: 		            break;
0: 		        } catch (IOException e) {
0: 		            LOG.info("Database "+lockFileName+" is locked... waiting " + (DATABASE_LOCKED_WAIT_DELAY / 1000) + " seconds for the database to be unlocked. Reason: " + e);
1: 		            try {
0: 		                Thread.sleep(DATABASE_LOCKED_WAIT_DELAY);
0: 		            } catch (InterruptedException e1) {
1: 		            }
1: 		        }
1: 		    }
1: 		}
/////////////////////////////////////////////////////////////////////////
0:             if( pageFile != null && pageFile.isLoaded() ) {
commit:a88a513
/////////////////////////////////////////////////////////////////////////
0: 	                    LOG.info("Database "+lockFileName+" is locked... waiting " + (DATABASE_LOCKED_WAIT_DELAY / 1000) + " seconds for the database to be unlocked. Reason: " + e);
commit:bb153ae
/////////////////////////////////////////////////////////////////////////
0:         		LOG.info("KahaDB Cleanup took "+(end-start));
/////////////////////////////////////////////////////////////////////////
0:     		LOG.info("KahaDB long enqueue time: Journal Add Took: "+(start2-start)+" ms, Index Update took "+(end-start2)+" ms");
commit:a91f59a
/////////////////////////////////////////////////////////////////////////
1:         close();
commit:deea2d1
/////////////////////////////////////////////////////////////////////////
0:     int journalMaxFileLength = Journal.DEFAULT_MAX_FILE_LENGTH;
1:     boolean enableIndexWriteAsync = false;
0:     int setIndexWriteBatchSize = PageFile.DEFAULT_WRITE_BATCH_SIZE; 
/////////////////////////////////////////////////////////////////////////
1:  
/////////////////////////////////////////////////////////////////////////
0:         PageFile index = new PageFile(directory, "db");
1:         index.setEnableWriteThread(isEnableIndexWriteAsync());
1:         index.setWriteBatchSize(getIndexWriteBatchSize());
1:         return index;
1:         manager.setMaxFileLength(getJournalMaxFileLength());
/////////////////////////////////////////////////////////////////////////
1:     
1:     public void setIndexWriteBatchSize(int setIndexWriteBatchSize) {
1:         this.setIndexWriteBatchSize = setIndexWriteBatchSize;
1:     }
1:     public int getIndexWriteBatchSize() {
1:         return setIndexWriteBatchSize;
1:     }
1:     
1:     public void setEnableIndexWriteAsync(boolean enableIndexWriteAsync) {
1:         this.enableIndexWriteAsync = enableIndexWriteAsync;
1:     }
1:     
1:     boolean isEnableIndexWriteAsync() {
1:         return enableIndexWriteAsync;
1:     }
1:     
/////////////////////////////////////////////////////////////////////////
0:     public void setJournalMaxFileLength(int journalMaxFileLength) {
1:         this.journalMaxFileLength = journalMaxFileLength;
1:     }
1:     
0:     public int getJournalMaxFileLength() {
1:         return journalMaxFileLength;
1:     }
1:     
commit:3c543a0
/////////////////////////////////////////////////////////////////////////
0:         pf.setEnableAsyncWrites(!isSyncWrites());
author:Timothy A. Bish
-------------------------------------------------------------------------------
commit:bc4392b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.openwire.OpenWireFormat;
/////////////////////////////////////////////////////////////////////////
0:         protected int openwireVersion = OpenWireFormat.DEFAULT_VERSION;
1: 
/////////////////////////////////////////////////////////////////////////
0:                 version = is.readInt();
1:                 version = 1;
1:             try {
1:                 openwireVersion = is.readInt();
1:             } catch (EOFException expectedOnUpgrade) {
0:                 openwireVersion = OpenWireFormat.DEFAULT_VERSION;
1:             }
/////////////////////////////////////////////////////////////////////////
1:             os.writeInt(this.openwireVersion);
commit:d9b54d6
/////////////////////////////////////////////////////////////////////////
1:             // rollback any recovered inflight local transactions, and discard any inflight XA transactions.
0:             Set<TransactionId> toDiscard = new HashSet<TransactionId>();
1:                     } else {
1:                         toDiscard.add(id);
/////////////////////////////////////////////////////////////////////////
1:                 for (TransactionId tx: toDiscard) {
1:                     if (LOG.isDebugEnabled()) {
1:                         LOG.debug("discarding recovered in-flight XA transaction " + tx);
1:                     }
1:                     inflightTransactions.remove(tx);
1:                 }
commit:7057e81
/////////////////////////////////////////////////////////////////////////
1: 
1:             synchronized (preparedTransactions) {
0:                 for (TransactionId txId : preparedTransactions.keySet()) {
0:                     LOG.warn("Recovered prepared XA TX: [{}]", txId);
1:                 }
1:             }
1: 
commit:3bf9d0c
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.data.KahaAckMessageFileMapCommand;
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.util.ByteSequence;
1: import org.apache.activemq.util.DataByteArrayInputStream;
1: import org.apache.activemq.util.DataByteArrayOutputStream;
1: import org.apache.activemq.util.IOHelper;
1: import org.apache.activemq.util.ServiceStopper;
1: import org.apache.activemq.util.ServiceSupport;
/////////////////////////////////////////////////////////////////////////
0:     static final int VERSION = 5;
/////////////////////////////////////////////////////////////////////////
1:         protected Location ackMessageFileMapLocation = null;
0:         protected transient Map<Integer, Set<Integer>> ackMessageFileMap = new HashMap<Integer, Set<Integer>>();
/////////////////////////////////////////////////////////////////////////
1:             if (version >= 5 && is.readBoolean()) {
1:                 ackMessageFileMapLocation = LocationMarshaller.INSTANCE.readPayload(is);
1:             } else {
1:                 ackMessageFileMapLocation = null;
1:             }
/////////////////////////////////////////////////////////////////////////
1:             if (ackMessageFileMapLocation != null) {
1:                 os.writeBoolean(true);
1:                 LocationMarshaller.INSTANCE.writePayload(ackMessageFileMapLocation, os);
1:             } else {
1:                 os.writeBoolean(false);
1:             }
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:         @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
0:             Location ackMessageFileLocation = recoverAckMessageFileMap();
0:             Location recoveryPosition = minimum(producerAuditPosition, ackMessageFileLocation);
0:             recoveryPosition = minimum(recoveryPosition, lastIndoubtPosition);
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("unchecked")
0:     private Location recoverAckMessageFileMap() throws IOException {
1:         if (metadata.ackMessageFileMapLocation != null) {
0:             KahaAckMessageFileMapCommand audit = (KahaAckMessageFileMapCommand) load(metadata.ackMessageFileMapLocation);
1:             try {
1:                 ObjectInputStream objectIn = new ObjectInputStream(audit.getAckMessageFileMap().newInput());
1:                 metadata.ackMessageFileMap = (Map<Integer, Set<Integer>>) objectIn.readObject();
0:                 return journal.getNextLocation(metadata.ackMessageFileMapLocation);
0:             } catch (Exception e) {
1:                 LOG.warn("Cannot recover ackMessageFileMap", e);
0:                 return journal.getNextLocation(null);
1:             }
1:         } else {
0:             // got no ackMessageFileMap stored so got to recreate via replay from start of the journal
0:             return journal.getNextLocation(null);
1:         }
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             try {
1:                 is.close();
1:             } catch (IOException e) {}
/////////////////////////////////////////////////////////////////////////
1:             public void visit(KahaAckMessageFileMapCommand command) throws IOException {
1:                 processLocation(location);
1:             }
1: 
1:             @Override
/////////////////////////////////////////////////////////////////////////
0:                 // store a DUP message. Bad BOY! Don't do it, and log a warning.
1:             // restore the previous value.. Looks like this was a redo of a previously
1:             // added message. We don't want to assign it a new id as the other indexes would
/////////////////////////////////////////////////////////////////////////
1: 
1:                 MessageKeys keys = sd.orderIndex.get(tx, sequence);
1:                 if (keys != null) {
1:                     recordAckMessageReferenceLocation(ackLocation, keys.location);
1:                 }
/////////////////////////////////////////////////////////////////////////
1:         Set<Integer> referenceFileIds = metadata.ackMessageFileMap.get(Integer.valueOf(ackLocation.getDataFileId()));
1:             metadata.ackMessageFileMap.put(ackLocation.getDataFileId(), referenceFileIds);
/////////////////////////////////////////////////////////////////////////
1: 
1:             sd.subLocations.clear(tx);
1:             sd.subLocations.unload(tx);
1:             tx.free(sd.subLocations.getHeadPageId());
/////////////////////////////////////////////////////////////////////////
1:             sd.subLocations.put(tx, subscriptionKey, location);
/////////////////////////////////////////////////////////////////////////
1:             sd.subLocations.remove(tx, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1:         metadata.ackMessageFileMapLocation = checkpointAckMessageFileMap();
/////////////////////////////////////////////////////////////////////////
1:             if (metadata.ackMessageFileMapLocation != null) {
1:                 int dataFileId = metadata.ackMessageFileMapLocation.getDataFileId();
1:                 gcCandidateSet.remove(dataFileId);
1:                 if (LOG.isTraceEnabled()) {
0:                     LOG.trace("gc candidates after ackMessageFileMapLocation:" + dataFileId + ", " + gcCandidateSet);
1:                 }
1:             }
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1:                 // Durable Subscription
1:                 if (entry.getValue().subLocations != null) {
1:                     Iterator<Entry<String, Location>> iter = entry.getValue().subLocations.iterator(tx);
1:                     while (iter.hasNext()) {
1:                         Entry<String, Location> subscription = iter.next();
1:                         int dataFileId = subscription.getValue().getDataFileId();
1: 
1:                         // Move subscription along if it has no outstanding messages that need ack'd
1:                         // and its in the last log file in the journal.
1:                         if (!gcCandidateSet.isEmpty() && gcCandidateSet.first() == dataFileId) {
1:                             final StoredDestination destination = entry.getValue();
1:                             final String subscriptionKey = subscription.getKey();
1:                             SequenceSet pendingAcks = destination.ackPositions.get(tx, subscriptionKey);
1: 
1:                             // When pending is size one that is the next message Id meaning there
1:                             // are no pending messages currently.
0:                             if (pendingAcks == null || pendingAcks.size() <= 1) {
1:                                 if (LOG.isTraceEnabled()) {
1:                                     LOG.trace("Found candidate for rewrite: {} from file {}", entry.getKey(), dataFileId);
1:                                 }
1: 
1:                                 final KahaSubscriptionCommand kahaSub =
1:                                     destination.subscriptions.get(tx, subscriptionKey);
1:                                 destination.subLocations.put(
1:                                     tx, subscriptionKey, checkpointSubscriptionCommand(kahaSub));
1: 
1:                                 // Skips the remove from candidates if we rewrote the subscription
1:                                 // in order to prevent duplicate subscription commands on recover.
1:                                 // If another subscription is on the same file and isn't rewritten
1:                                 // than it will remove the file from the set.
1:                                 continue;
1:                             }
1:                         }
1: 
1:                         gcCandidateSet.remove(dataFileId);
1:                     }
1:                 }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 Set<Integer> referencedFileIds = metadata.ackMessageFileMap.get(candidate);
/////////////////////////////////////////////////////////////////////////
0:                         metadata.ackMessageFileMap.remove(candidate);
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     private Location checkpointAckMessageFileMap() throws IOException {
1:         ByteArrayOutputStream baos = new ByteArrayOutputStream();
1:         ObjectOutputStream oout = new ObjectOutputStream(baos);
1:         oout.writeObject(metadata.ackMessageFileMap);
1:         oout.flush();
1:         oout.close();
1:         // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false
1:         Location location = store(new KahaAckMessageFileMapCommand().setAckMessageFileMap(new Buffer(baos.toByteArray())), nullCompletionCallback);
1:         try {
1:             location.getLatch().await();
1:         } catch (InterruptedException e) {
1:             throw new InterruptedIOException(e.toString());
1:         }
1:         return location;
1:     }
1: 
1:     private Location checkpointSubscriptionCommand(KahaSubscriptionCommand subscription) throws IOException {
1: 
1:         ByteSequence sequence = toByteSequence(subscription);
1:         Location location = journal.write(sequence, nullCompletionCallback) ;
1: 
1:         try {
1:             location.getLatch().await();
1:         } catch (InterruptedException e) {
1:             throw new InterruptedIOException(e.toString());
1:         }
1:         return location;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         ListIndex<String, Location> subLocations;
/////////////////////////////////////////////////////////////////////////
1:                             value.ackPositions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:                             value.ackPositions.setValueMarshaller(SequenceSet.Marshaller.INSTANCE);
0:                             value.ackPositions.load(tx);
/////////////////////////////////////////////////////////////////////////
1: 
1:                 if (metadata.version >= 5) {
0:                     value.subLocations = new ListIndex<String, Location>(pageFile, dataIn.readLong());
1:                 } else {
0:                     // upgrade
1:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                         @Override
1:                         public void execute(Transaction tx) throws IOException {
0:                             value.subLocations = new ListIndex<String, Location>(pageFile, tx.allocate());
1:                             value.subLocations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:                             value.subLocations.setValueMarshaller(LocationMarshaller.INSTANCE);
1:                             value.subLocations.load(tx);
1:                         }
1:                     });
1:                 }
0:                 // upgrade
1:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                     @Override
1:                     public void execute(Transaction tx) throws IOException {
0:                         value.orderIndex.lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                         value.orderIndex.lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                         value.orderIndex.lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                         value.orderIndex.lowPriorityIndex.load(tx);
0:                         value.orderIndex.highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                         value.orderIndex.highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                         value.orderIndex.highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                         value.orderIndex.highPriorityIndex.load(tx);
1:                     }
1:                 });
/////////////////////////////////////////////////////////////////////////
1:                 dataOut.writeLong(value.subLocations.getHeadPageId());
/////////////////////////////////////////////////////////////////////////
0:                 rc.subLocations = new ListIndex<String, Location>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:             rc.subLocations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:             rc.subLocations.setValueMarshaller(LocationMarshaller.INSTANCE);
1:             rc.subLocations.load(tx);
1: 
commit:f21992e
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:54d56df
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.util.ByteSequence;
0: import org.apache.activemq.util.Callback;
0: import org.apache.activemq.util.DataByteArrayInputStream;
0: import org.apache.activemq.util.DataByteArrayOutputStream;
0: import org.apache.activemq.util.IOHelper;
0: import org.apache.activemq.util.LockFile;
0: import org.apache.activemq.util.ServiceStopper;
0: import org.apache.activemq.util.ServiceSupport;
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                         @Override
/////////////////////////////////////////////////////////////////////////
1:                         @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                     @Override
/////////////////////////////////////////////////////////////////////////
1:                     @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                 @Override
/////////////////////////////////////////////////////////////////////////
1:                     @Override
/////////////////////////////////////////////////////////////////////////
1:                     @Override
/////////////////////////////////////////////////////////////////////////
1:         if (metadata.producerSequenceIdTracker == null || metadata.producerSequenceIdTracker.modified()) {
0:             ByteArrayOutputStream baos = new ByteArrayOutputStream();
0:             ObjectOutputStream oout = new ObjectOutputStream(baos);
0:             oout.writeObject(metadata.producerSequenceIdTracker);
0:             oout.flush();
0:             oout.close();
0:             // using completion callback allows a disk sync to be avoided when enableJournalDiskSyncs = false
0:             Location location = store(new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), nullCompletionCallback);
1:             try {
0:                 location.getLatch().await();
0:             } catch (InterruptedException e) {
0:                 throw new InterruptedIOException(e.toString());
1:             }
1:             return location;
1:         return metadata.producerSequenceIdTrackerLocation;
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:                         @Override
/////////////////////////////////////////////////////////////////////////
1:                         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:     @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:             @Override
/////////////////////////////////////////////////////////////////////////
1:             @Override
/////////////////////////////////////////////////////////////////////////
1:             @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
/////////////////////////////////////////////////////////////////////////
1:         @Override
commit:ff5e7e7
/////////////////////////////////////////////////////////////////////////
commit:34af42f
/////////////////////////////////////////////////////////////////////////
1:             } else {
1: 
0:                 if (sd.subscriptionCache.size() == 1) {
1: 
0:                     int messageIdCount = 0;
0:                     TreeSet<Long> msgIdContents = new TreeSet<Long>();
0:                     Iterator<Entry<String, Long>> iterator1 = sd.messageIdIndex.iterator(tx);
0:                     while (iterator1.hasNext()) {
0:                         Entry<String, Long> entry = iterator1.next();
0:                         messageIdCount++;
0:                         msgIdContents.add(entry.getValue());
1:                     }
1: 
0:                     int locationCount = 0;
0:                     TreeSet<Long> locationContents = new TreeSet<Long>();
0:                     Iterator<Entry<Location, Long>> iterator2 = sd.locationIndex.iterator(tx);
0:                     while (iterator2.hasNext()) {
0:                         Entry<Location, Long> entry = iterator2.next();
0:                         locationCount++;
0:                         locationContents.add(entry.getValue());
1:                     }
1: 
0:                     LOG.info("Size of sd.messageIdIndex = " + messageIdCount);
0:                     LOG.info("Size of sd.locationIndex = " + locationCount);
0:                     LOG.info("Size of sd.ackPositions = " + sd.ackPositions.size());
0:                     LOG.info("Size of sd.messageReferences = " + sd.messageReferences.size());
1: 
0:                     Iterator<Entry<String, SequenceSet>> iterator3 = sd.ackPositions.iterator(tx);
0:                     while (iterator3.hasNext()) {
0:                         Entry<String, SequenceSet> entry = iterator3.next();
0:                         StringBuilder logEntry = new StringBuilder();
0:                         logEntry.append("Subscription["+entry.getKey()+"] references: ");
0:                         for (Long sequenceId : entry.getValue()) {
0:                             logEntry.append(sequenceId + " ");
1:                         }
0:                         LOG.info(logEntry.toString());
1:                     }
1: 
0:                     StringBuilder msgIdLog = new StringBuilder();
0:                     msgIdLog.append("sd.messageIdIndex contains [");
0:                     for(Long sequenceId : msgIdContents) {
0:                         msgIdLog.append(sequenceId + " ");
1:                     }
0:                     msgIdLog.append("]");
0:                     LOG.info(msgIdLog.toString());
0:                     StringBuilder locationLog = new StringBuilder();
0:                     locationLog.append("sd.locationIndex contains [");
0:                     for(Long sequenceId : locationContents) {
0:                         locationLog.append(sequenceId + " ");
1:                     }
0:                     locationLog.append("]");
0:                     LOG.info(locationLog.toString());
1: 
0:                     LOG.info("Order index last default key: " + sd.orderIndex.lastDefaultKey);
0:                     LOG.info("Order index last high key: " + sd.orderIndex.lastHighKey);
0:                     LOG.info("Order index last low key: " + sd.orderIndex.lastLowKey);
1:                 }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 SequenceSet pendingAcks = subscription.getValue();
1:                 if (pendingAcks != null && !pendingAcks.isEmpty()) {
1:                     Long lastPendingAck = pendingAcks.getTail().getLast();
0:                     for(Long sequenceId : pendingAcks) {
1: 
1:                         // We always add a trailing empty entry for the next position to start from
1:                         // so we need to ensure we don't count that as a message reference on reload.
1:                         if (!sequenceId.equals(lastPendingAck)) {
1:                             current = current.longValue() + 1;
1:                         }
1: 
1:                         rc.messageReferences.put(sequenceId, current);
commit:c6ec76e
/////////////////////////////////////////////////////////////////////////
1:             SequenceSet sequences = sd.ackPositions.get(tx, subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1:                 Long references = sd.messageReferences.get(sequenceId);
1:                 if (references != null) {
1:                     references = references.longValue() - 1;
1:                     if (references.longValue() > 0) {
1:                         sd.messageReferences.put(sequenceId, references);
1:                     } else {
1:                         sd.messageReferences.remove(sequenceId);
1:                         unreferenced.add(sequenceId);
1:                     }
commit:3cea40d
/////////////////////////////////////////////////////////////////////////
0:                 sd.orderIndex.clear(tx);
/////////////////////////////////////////////////////////////////////////
1:         void clear(Transaction tx) throws IOException {
1:             this.remove(tx);
1:             this.resetCursorPosition();
1:             this.allocate(tx);
1:             this.load(tx);
1:             this.configureLast(tx);
1:         }
1: 
commit:0af0021
/////////////////////////////////////////////////////////////////////////
0: import java.io.DataInput;
0: import java.io.DataOutput;
0: import java.io.EOFException;
0: import java.io.File;
0: import java.io.IOException;
0: import java.io.InputStream;
1: import java.io.InterruptedIOException;
0: import java.io.ObjectInputStream;
0: import java.io.ObjectOutputStream;
0: import java.io.OutputStream;
1: import java.util.ArrayList;
1: import java.util.Collection;
1: import java.util.Collections;
1: import java.util.Date;
1: import java.util.HashMap;
1: import java.util.HashSet;
1: import java.util.Iterator;
1: import java.util.LinkedHashMap;
1: import java.util.LinkedHashSet;
1: import java.util.List;
1: import java.util.Map;
1: import java.util.Set;
1: import java.util.SortedSet;
0: import java.util.Stack;
1: import java.util.TreeMap;
1: import java.util.TreeSet;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.store.kahadb.data.KahaAddMessageCommand;
0: import org.apache.activemq.store.kahadb.data.KahaCommitCommand;
0: import org.apache.activemq.store.kahadb.data.KahaDestination;
0: import org.apache.activemq.store.kahadb.data.KahaEntryType;
0: import org.apache.activemq.store.kahadb.data.KahaPrepareCommand;
0: import org.apache.activemq.store.kahadb.data.KahaProducerAuditCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRemoveDestinationCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRemoveMessageCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRollbackCommand;
0: import org.apache.activemq.store.kahadb.data.KahaSubscriptionCommand;
0: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
0: import org.apache.activemq.store.kahadb.data.KahaTransactionInfo;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.ByteSequence;
0: import org.apache.kahadb.util.DataByteArrayInputStream;
0: import org.apache.kahadb.util.DataByteArrayOutputStream;
0: import org.apache.kahadb.util.LocationMarshaller;
0: import org.apache.kahadb.util.LockFile;
0: import org.apache.kahadb.util.LongMarshaller;
0: import org.apache.kahadb.util.Marshaller;
0: import org.apache.kahadb.util.Sequence;
0: import org.apache.kahadb.util.SequenceSet;
0: import org.apache.kahadb.util.StringMarshaller;
0: import org.apache.kahadb.util.VariableMarshaller;
/////////////////////////////////////////////////////////////////////////
1: 
1:             if (sd.subscriptions.isEmpty(tx)) {
1:                 sd.messageIdIndex.clear(tx);
1:                 sd.locationIndex.clear(tx);
1:             }
commit:cdba931
/////////////////////////////////////////////////////////////////////////
1:     public static final int LOG_SLOW_ACCESS_TIME = Integer.getInteger(PROPERTY_LOG_SLOW_ACCESS_TIME, 0);
commit:534a44f
/////////////////////////////////////////////////////////////////////////
0:             if (checkpointThread != null && !checkpointThread.isAlive()) {
commit:c273cab
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
0:             if (checkpointThread == null || !checkpointThread.isAlive()) {
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
0:                 if (metadata.version >= VERSION) {
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("rawtypes")
1:     @SuppressWarnings("rawtypes")
/////////////////////////////////////////////////////////////////////////
0:     @SuppressWarnings("rawtypes")
commit:e23afb3
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             sd.ackPositions.add(tx, subscriptionKey, sequences);
1:             sd.ackPositions.put(tx, subscriptionKey, sequences);
/////////////////////////////////////////////////////////////////////////
1:             sd.ackPositions.add(tx, subscriptionKey, sequences);
1:             sd.ackPositions.put(tx, subscriptionKey, sequences);
/////////////////////////////////////////////////////////////////////////
0:                 sd.ackPositions.add(tx, subscriptionKey, sequences);
0:                 sd.ackPositions.put(tx, subscriptionKey, sequences);
/////////////////////////////////////////////////////////////////////////
0:     private void removeAckLocation(Transaction tx, StoredDestination sd, String subscriptionKey, Long messageSequence) throws IOException {
1:         if (messageSequence != null) {
1:                 range.remove(messageSequence);
/////////////////////////////////////////////////////////////////////////
1:                 Long count = sd.messageReferences.get(messageSequence);
1:                     sd.messageReferences.put(messageSequence, Long.valueOf(references));
1:                     sd.messageReferences.remove(messageSequence);
1:                 sd.orderIndex.getDeleteList(tx, deletes, messageSequence);
commit:5325cdb
/////////////////////////////////////////////////////////////////////////
1:             } catch (EOFException expectedOnUpgrade) {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         } finally {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         } finally {
/////////////////////////////////////////////////////////////////////////
1:             } finally {
/////////////////////////////////////////////////////////////////////////
1:         } finally {
/////////////////////////////////////////////////////////////////////////
1:                 if (LOG.isInfoEnabled()) {
1:                     long end = System.currentTimeMillis();
0:                     LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1:                 }
/////////////////////////////////////////////////////////////////////////
1:                     if (LOG.isDebugEnabled()) {
0:                         LOG.debug("rolling back recovered indoubt local transaction " + tx);
1:                     }
1:         } finally {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             // The rolledback operations are basically in flight journal writes.  To avoid getting
1:             // these the end user should do sync writes to the journal.
1:             if (LOG.isInfoEnabled()) {
1:                 long end = System.currentTimeMillis();
1:                 LOG.info("Rolled back " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:             }
/////////////////////////////////////////////////////////////////////////
1:         while (!ss.isEmpty()) {
1:             missingJournalFiles.add((int) ss.removeFirst());
0:         missingJournalFiles.removeAll(journal.getFileMap().keySet());
0:         if (!missingJournalFiles.isEmpty()) {
1:             if (LOG.isInfoEnabled()) {
0:                 LOG.info("Some journal files are missing: " + missingJournalFiles);
1:             }
1:             missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing, 0), new Location(missing + 1, 0)));
1:         if (checkForCorruptJournalFiles) {
1:                 missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, dataFile.getLength()), new Location(id + 1, 0)));
1:                 while (seq != null) {
0:                     missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1)));
1:         if (!missingPredicates.isEmpty()) {
/////////////////////////////////////////////////////////////////////////
1:                 if (!matches.isEmpty()) {
/////////////////////////////////////////////////////////////////////////
1:             if (LOG.isInfoEnabled()) {
1:                 long end = System.currentTimeMillis();
1:                 LOG.info("Detected missing/corrupt journal files.  Dropped " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:             }
/////////////////////////////////////////////////////////////////////////
1:         } finally {
/////////////////////////////////////////////////////////////////////////
1:         } finally {
1: 
1:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
1:             if (LOG.isInfoEnabled()) {
1:                 LOG.info("Slow KahaDB access: cleanup took " + (end - start));
1:             }
/////////////////////////////////////////////////////////////////////////
1:         } finally {
/////////////////////////////////////////////////////////////////////////
1:                 if (LOG.isInfoEnabled()) {
0:                     LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
1:                 }
/////////////////////////////////////////////////////////////////////////
0:             if (LOG.isInfoEnabled()) {
0:                 LOG.info("Slow KahaDB access: Journal read took: "+(end-start)+" ms");
1:             }
/////////////////////////////////////////////////////////////////////////
0:             } finally {
/////////////////////////////////////////////////////////////////////////
0:             } finally {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
1:             if (LOG.isTraceEnabled()) {
0:                 LOG.trace("Last update: " + firstTxLocation + ", full gc candidates set: " + gcCandidateSet);
1:             }
/////////////////////////////////////////////////////////////////////////
1:                 if (LOG.isTraceEnabled()) {
0:                     LOG.trace("gc candidates after first tx:" + firstTxLocation + ", " + gcCandidateSet);
1:                 }
/////////////////////////////////////////////////////////////////////////
1:                 if (LOG.isTraceEnabled()) {
0:                     LOG.trace("gc candidates after dest:" + entry.getKey() + ", " + gcCandidateSet);
1:                 }
1:             if (LOG.isTraceEnabled()) {
0:                 LOG.trace("gc candidates: " + gcCandidateSet);
1:             }
/////////////////////////////////////////////////////////////////////////
0:                         if (LOG.isTraceEnabled()) {
0:                             LOG.trace("not removing data file: " + candidate
0:                                     + " as contained ack(s) refer to referenced file: " + referencedFileIds);
1:                         }
1:             if (!gcCandidateSet.isEmpty()) {
0:                 if (LOG.isDebugEnabled()) {
0:                     LOG.debug("Cleanup removing the data files: " + gcCandidateSet);
1:                 }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
commit:943db3c
/////////////////////////////////////////////////////////////////////////
0: import java.util.ArrayList;
0: import java.util.Collection;
0: import java.util.Collections;
0: import java.util.Date;
0: import java.util.HashMap;
0: import java.util.HashSet;
0: import java.util.Iterator;
0: import java.util.LinkedHashMap;
0: import java.util.LinkedHashSet;
0: import java.util.List;
0: import java.util.Map;
0: import java.util.Set;
0: import java.util.SortedSet;
0: import java.util.Stack;
0: import java.util.TreeMap;
0: import java.util.TreeSet;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.index.ListIndex;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.LocationMarshaller;
/////////////////////////////////////////////////////////////////////////
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
/////////////////////////////////////////////////////////////////////////
0:     static final int VERSION = 4;
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("unused")
/////////////////////////////////////////////////////////////////////////
1:             tx.free(sd.ackPositions.getHeadPageId());
/////////////////////////////////////////////////////////////////////////
1:             sd.subscriptionCache.add(subscriptionKey);
1:             sd.subscriptionCache.remove(subscriptionKey);
/////////////////////////////////////////////////////////////////////////
1:         ListIndex<String, SequenceSet> ackPositions;
1: 
1:         // Transient data used to track which Messages are no longer needed.
0:         final TreeMap<Long, Long> messageReferences = new TreeMap<Long, Long>();
0:         final HashSet<String> subscriptionCache = new LinkedHashSet<String>();
/////////////////////////////////////////////////////////////////////////
0:                     value.ackPositions = new ListIndex<String, SequenceSet>(pageFile, dataIn.readLong());
0:                             BTreeIndex<Long, HashSet<String>> oldAckPositions =
0:                                 new BTreeIndex<Long, HashSet<String>>(pageFile, tx.allocate());
0:                             oldAckPositions.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                             oldAckPositions.setValueMarshaller(HashSetStringMarshaller.INSTANCE);
0:                             oldAckPositions.load(tx);
1: 
0:                             LinkedHashMap<String, SequenceSet> temp = new LinkedHashMap<String, SequenceSet>();
1: 
0:                             // Do the initial build of the data in memory before writing into the store
0:                             // based Ack Positions List to avoid a lot of disk thrashing.
0:                             Iterator<Entry<Long, HashSet<String>>> iterator = oldAckPositions.iterator(tx);
0:                             while (iterator.hasNext()) {
0:                                 Entry<Long, HashSet<String>> entry = iterator.next();
1: 
0:                                 for(String subKey : entry.getValue()) {
0:                                     SequenceSet pendingAcks = temp.get(subKey);
0:                                     if (pendingAcks == null) {
0:                                         pendingAcks = new SequenceSet();
0:                                         temp.put(subKey, pendingAcks);
1:                                     }
1: 
0:                                     pendingAcks.add(entry.getKey());
1:                                 }
1:                             }
1: 
1:                             // Now move the pending messages to ack data into the store backed
1:                             // structure.
0:                             value.ackPositions = new ListIndex<String, SequenceSet>(pageFile, tx.allocate());
1:                             for(String subscriptionKey : temp.keySet()) {
1:                                 value.ackPositions.put(tx, subscriptionKey, temp.get(subscriptionKey));
1:                             }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 dataOut.writeLong(value.ackPositions.getHeadPageId());
/////////////////////////////////////////////////////////////////////////
0:                 rc.ackPositions = new ListIndex<String, SequenceSet>(pageFile, tx.allocate());
/////////////////////////////////////////////////////////////////////////
1:             rc.ackPositions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:             rc.ackPositions.setValueMarshaller(SequenceSet.Marshaller.INSTANCE);
/////////////////////////////////////////////////////////////////////////
1:             // Configure the message references index
1:             Iterator<Entry<String, SequenceSet>> subscriptions = rc.ackPositions.iterator(tx);
1:             while (subscriptions.hasNext()) {
1:                 Entry<String, SequenceSet> subscription = subscriptions.next();
0:                 if (subscription.getValue() != null) {
0:                     for(Long sequenceId : subscription.getValue()) {
1:                         Long current = rc.messageReferences.get(sequenceId);
1:                         if (current == null) {
1:                             current = new Long(0);
1:                         }
0:                         rc.messageReferences.put(sequenceId, Long.valueOf(current.longValue() + 1));
1:                     }
1:                 }
1:             }
1: 
1:             // Configure the subscription cache
1:             for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
0:                 Entry<String, LastAck> entry = iterator.next();
1:                 rc.subscriptionCache.add(entry.getKey());
1:             }
1: 
/////////////////////////////////////////////////////////////////////////
1:                 if (!rc.messageReferences.isEmpty()) {
1:                     Long nextMessageId = (Long) rc.messageReferences.keySet().toArray()[rc.messageReferences.size() - 1];
1:                             Math.max(rc.orderIndex.nextMessageId, nextMessageId);
1:         if (metadata.version < VERSION) {
/////////////////////////////////////////////////////////////////////////
1:         SequenceSet sequences = sd.ackPositions.get(tx, subscriptionKey);
1:         if (sequences == null) {
1:             sequences = new SequenceSet();
1:             sequences.add(messageSequence);
0:             sd.ackPositions.put(tx, subscriptionKey, sequences);
1:         } else {
1:             sequences.add(messageSequence);
0:             sd.ackPositions.add(tx, subscriptionKey, sequences);
1: 
1:         Long count = sd.messageReferences.get(messageSequence);
1:         if (count == null) {
1:             count = Long.valueOf(0L);
1:         }
1:         count = count.longValue() + 1;
1:         sd.messageReferences.put(messageSequence, count);
1:         SequenceSet sequences = sd.ackPositions.get(tx, subscriptionKey);
1:         if (sequences == null) {
1:             sequences = new SequenceSet();
1:             sequences.add(messageSequence);
0:             sd.ackPositions.put(tx, subscriptionKey, sequences);
1:         } else {
1:             sequences.add(messageSequence);
0:             sd.ackPositions.add(tx, subscriptionKey, sequences);
1: 
1:         Long count = sd.messageReferences.get(messageSequence);
1:         if (count == null) {
1:             count = Long.valueOf(0L);
1:         }
1:         count = count.longValue() + 1;
1:         sd.messageReferences.put(messageSequence, count);
1:         for(String subscriptionKey : sd.subscriptionCache) {
0:             SequenceSet sequences = null;
0:             sequences = sd.ackPositions.get(tx, subscriptionKey);
1:             if (sequences == null) {
1:                 sequences = new SequenceSet();
1:                 sequences.add(new Sequence(messageSequence, messageSequence + 1));
0:                 sd.ackPositions.put(tx, subscriptionKey, sequences);
1:             } else {
1:                 sequences.add(new Sequence(messageSequence, messageSequence + 1));
0:                 sd.ackPositions.add(tx, subscriptionKey, sequences);
1:             }
1: 
1:             Long count = sd.messageReferences.get(messageSequence);
1:             if (count == null) {
1:                 count = Long.valueOf(0L);
1:             }
1:             count = count.longValue() + 1;
1:             sd.messageReferences.put(messageSequence, count);
0:             sd.messageReferences.put(messageSequence+1, Long.valueOf(0L));
1:             SequenceSet sequences = sd.ackPositions.remove(tx, subscriptionKey);
1:             if (sequences == null || sequences.isEmpty()) {
0:                 return;
1:             }
1: 
0:             ArrayList<Long> unreferenced = new ArrayList<Long>();
1: 
1:             for(Long sequenceId : sequences) {
0:                 long references = 0;
0:                 Long count = sd.messageReferences.get(sequenceId);
0:                 if (count != null) {
0:                     references = count.longValue() - 1;
1:                 } else {
0:                     continue;
1:                 }
1: 
1:                 if (references > 0) {
0:                     sd.messageReferences.put(sequenceId, Long.valueOf(references));
1:                 } else {
0:                     sd.messageReferences.remove(sequenceId);
0:                     unreferenced.add(sequenceId);
1:                 }
1:             }
1: 
1:             for(Long sequenceId : unreferenced) {
0:                 // Find all the entries that need to get deleted.
0:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
0:                 sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
1: 
0:                 // Do the actual deletes.
0:                 for (Entry<Long, MessageKeys> entry : deletes) {
0:                     sd.locationIndex.remove(tx, entry.getValue().location);
0:                     sd.messageIdIndex.remove(tx, entry.getValue().messageId);
0:                     sd.orderIndex.remove(tx, entry.getKey());
1:                 }
/////////////////////////////////////////////////////////////////////////
1:             SequenceSet range = sd.ackPositions.get(tx, subscriptionKey);
1:             if (range != null && !range.isEmpty()) {
0:                 range.remove(sequenceId);
1:                 if (!range.isEmpty()) {
1:                     sd.ackPositions.put(tx, subscriptionKey, range);
1:                     sd.ackPositions.remove(tx, subscriptionKey);
1:                 }
1: 
1:                 // Check if the message is reference by any other subscription.
0:                 Long count = sd.messageReferences.get(sequenceId);
0:                 long references = count.longValue() - 1;
0:                 if (references > 0) {
0:                     sd.messageReferences.put(sequenceId, Long.valueOf(references));
0:                     return;
1:                 } else {
0:                     sd.messageReferences.remove(sequenceId);
1:                 }
1: 
0:                 // Find all the entries that need to get deleted.
0:                 ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
0:                 sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
1: 
0:                 // Do the actual deletes.
0:                 for (Entry<Long, MessageKeys> entry : deletes) {
0:                     sd.locationIndex.remove(tx, entry.getValue().location);
0:                     sd.messageIdIndex.remove(tx, entry.getValue().messageId);
0:                     sd.orderIndex.remove(tx, entry.getKey());
1:     public LastAck getLastAck(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
1:         return sd.subscriptionAcks.get(tx, subscriptionKey);
1:     }
1: 
0:     public long getStoredMessageCount(Transaction tx, StoredDestination sd, String subscriptionKey) throws IOException {
0:         SequenceSet messageSequences = sd.ackPositions.get(tx, subscriptionKey);
0:         if (messageSequences != null) {
0:             long result = messageSequences.rangeSize();
0:             // if there's anything in the range the last value is always the nextMessage marker, so remove 1.
0:             return result > 0 ? result - 1 : 0;
1:         }
1: 
1:         return 0;
1:     }
1: 
/////////////////////////////////////////////////////////////////////////
1:     @SuppressWarnings("unused")
/////////////////////////////////////////////////////////////////////////
1:         @SuppressWarnings("unchecked")
commit:40f9146
/////////////////////////////////////////////////////////////////////////
1: 
1:     protected BrokerService brokerService;
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:     protected Journal journal;
0:     protected Metadata metadata = new Metadata();
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1:     private void loadPageFile() throws IOException {
1:         this.indexLock.writeLock().lock();
1:         try {
1:             final PageFile pageFile = getPageFile();
/////////////////////////////////////////////////////////////////////////
0:             pageFile.flush();
1:     }
1: 
1:     private void startCheckpoint() {
/////////////////////////////////////////////////////////////////////////
1:     }
1:     public void open() throws IOException {
0:         if( opened.compareAndSet(false, true) ) {
1:             loadPageFile();
1:             startCheckpoint();
1:         }
1:     }
1: 
0:         if (lockFile == null) {
0:                 boolean locked = false;
0:                 while ((!isStopped()) && (!isStopping())) {
0:                         locked = true;
0:                         LOG.info("Database "
0:                                 + lockFileName
0:                                 + " is locked... waiting "
0:                                 + (getDatabaseLockedWaitDelay() / 1000)
0:                                 + " seconds for the database to be unlocked. Reason: "
0:                                 + e);
0:                 if (!locked) {
0:                     throw new IOException("attempt to obtain lock aborted due to shutdown");
1:                 }
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:             open();
0:             store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
1: 
1:     public void close() throws IOException, InterruptedException {
0:         if( opened.compareAndSet(true, false)) {
1:             this.indexLock.writeLock().lock();
1:             try {
1:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                     public void execute(Transaction tx) throws IOException {
0:                         checkpointUpdate(tx, true);
1:                     }
1:                 });
1:                 pageFile.unload();
0:                 metadata = new Metadata();
0:             }finally {
1:                 this.indexLock.writeLock().unlock();
0:             journal.close();
0:             synchronized (checkpointThreadLock) {
0:                 checkpointThread.join();
1:             }
0:             lockFile.unlock();
0:             lockFile=null;
1:         }
1:     }
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1:      *
/////////////////////////////////////////////////////////////////////////
1: 
1:             long start = System.currentTimeMillis();
0:             Location producerAuditPosition = recoverProducerAudit();
0:             Location lastIndoubtPosition = getRecoveryPosition();
1: 
0:             Location recoveryPosition = minimum(producerAuditPosition, lastIndoubtPosition);
1: 
0:             if (recoveryPosition != null) {
0:                 int redoCounter = 0;
0:                 LOG.info("Recovering from the journal ...");
0:                 while (recoveryPosition != null) {
0:                     JournalCommand<?> message = load(recoveryPosition);
0:                     metadata.lastUpdate = recoveryPosition;
0:                     process(message, recoveryPosition, lastIndoubtPosition);
0:                     redoCounter++;
0:                     recoveryPosition = journal.getNextLocation(recoveryPosition);
1:                 }
0:                 long end = System.currentTimeMillis();
0:                 LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1:             }
1: 
0:             // We may have to undo some index updates.
/////////////////////////////////////////////////////////////////////////
1: 
0:     private Location minimum(Location producerAuditPosition,
0:         Location min = null;
0:         if (producerAuditPosition != null) {
0:             min = producerAuditPosition;
0:             if (lastIndoubtPosition != null && lastIndoubtPosition.compareTo(producerAuditPosition) < 0) {
0:                 min = lastIndoubtPosition;
1:             }
1:         } else {
0:             min = lastIndoubtPosition;
1:         }
0:         return min;
1: 
0:     private Location recoverProducerAudit() throws IOException {
1:         if (metadata.producerSequenceIdTrackerLocation != null) {
0:             KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(metadata.producerSequenceIdTrackerLocation);
1:             try {
0:                 ObjectInputStream objectIn = new ObjectInputStream(audit.getAudit().newInput());
0:                 metadata.producerSequenceIdTracker = (ActiveMQMessageAuditNoSync) objectIn.readObject();
0:             } catch (ClassNotFoundException cfe) {
0:                 IOException ioe = new IOException("Failed to read producerAudit: " + cfe);
0:                 ioe.initCause(cfe);
0:                 throw ioe;
1:             }
0:             return journal.getNextLocation(metadata.producerSequenceIdTrackerLocation);
1:         } else {
0:             // got no audit stored so got to recreate via replay from start of the journal
0:             return journal.getNextLocation(null);
1:         }
1:         // It is possible index updates got applied before the journal updates..
1: 
1: 
1:                 @Override
1:                 protected void matched(Location key, Long value) {
1:                     matches.add(value);
1:                 }
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1:             }
1:             // The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
1:             // should do sync writes to the journal.
0:             LOG.info("Rolled back " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
/////////////////////////////////////////////////////////////////////////
1: 
0:             // The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
0:             // should do sync writes to the journal.
0:             LOG.info("Detected missing/corrupt journal files.  Dropped " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:     }
1:     private Location nextRecoveryPosition;
1:     private Location lastRecoveryPosition;
0:     public void incrementalRecover() throws IOException {
1:         this.indexLock.writeLock().lock();
0:             if( nextRecoveryPosition == null ) {
0:                 if( lastRecoveryPosition==null ) {
0:                     nextRecoveryPosition = getRecoveryPosition();
1:                 } else {
1:                     nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:                 }
1:             }
1:             while (nextRecoveryPosition != null) {
1:                 lastRecoveryPosition = nextRecoveryPosition;
1:                 metadata.lastUpdate = lastRecoveryPosition;
0:                 JournalCommand<?> message = load(lastRecoveryPosition);
0:                 process(message, lastRecoveryPosition);
1:                 nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:             }
1:     }
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     }
0:         long start;
1:         this.indexLock.writeLock().lock();
0:             if( !opened.get() ) {
0:                 return;
1:             }
/////////////////////////////////////////////////////////////////////////
0:         long end = System.currentTimeMillis();
0:         if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:             LOG.info("Slow KahaDB access: cleanup took "+(end-start));
1:         }
1: 
0:     public void checkpoint(Callback closure) throws Exception {
1:         this.indexLock.writeLock().lock();
/////////////////////////////////////////////////////////////////////////
1:     }
/////////////////////////////////////////////////////////////////////////
0:         if (before != null) {
0:             before.run();
1:         }
1: 
0:             long end = System.currentTimeMillis();
0:             if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:                 LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
1:             }
1: 
1:             this.indexLock.writeLock().lock();
0:                 metadata.lastUpdate = location;
/////////////////////////////////////////////////////////////////////////
0:         } catch (IOException ioe) {
0:             throw ioe;
1:         }
1:      *
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:     private final HashSet<Integer> journalFilesBeingReplicated = new HashSet<Integer>();
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:                 }
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:             // Don't GC files under replication
0:             if( journalFilesBeingReplicated!=null ) {
1:                 gcCandidateSet.removeAll(journalFilesBeingReplicated);
1:             }
/////////////////////////////////////////////////////////////////////////
1: 
0:                 while( !gcCandidateSet.isEmpty() ) {
0:                     Integer last = gcCandidateSet.last();
0:                     if( last >= firstTxLocation.getDataFileId() ) {
0:                         gcCandidateSet.remove(last);
1:                     } else {
0:                         break;
1:                     }
1:                 }
0:                 if( gcCandidateSet.isEmpty() ) {
0:                     break;
0:                         if( first==null ) {
0:                             SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
0:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
1:                                 subset.remove(second.getDataFileId());
1:                             }
1:                             return !subset.isEmpty();
0:                         } else if( second==null ) {
1:                             SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
0:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:                                 subset.remove(first.getDataFileId());
1:                             }
1:                             return !subset.isEmpty();
1:                         } else {
0:                             SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
0:                             if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
1:                                 subset.remove(first.getDataFileId());
1:                             }
0:                             if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
1:                                 subset.remove(second.getDataFileId());
1:                             }
1:                             return !subset.isEmpty();
1:                         }
1:                         for (Location l : keys) {
0:                             if( last != fileId ) {
1:                                 gcCandidateSet.remove(fileId);
/////////////////////////////////////////////////////////////////////////
0:                 LOG.debug("Cleanup removing the data files: "+gcCandidateSet);
0:                 journal.removeDataFiles(gcCandidateSet);
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1:         return journalFilesBeingReplicated;
1:     }
0:     private final HashMap<String, StoredDestination> storedDestinations = new HashMap<String, StoredDestination>();
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
0:                     // modify so it is upgraded
1: 
/////////////////////////////////////////////////////////////////////////
1:         }
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
1: 
1:         return pageFile;
1:     }
0:     public Journal getJournal() throws IOException {
0:         return journal;
1:     }
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1:     public void setBrokerService(BrokerService brokerService) {
1:         this.brokerService = brokerService;
1:     }
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
1: 
/////////////////////////////////////////////////////////////////////////
1: 
1: 
/////////////////////////////////////////////////////////////////////////
0:                 IOException ioe = new IOException("Failed to read HashSet<String>: " + cfe);
0:                 ioe.initCause(cfe);
0:                 throw ioe;
1:             }
author:Hiram R. Chirino
-------------------------------------------------------------------------------
commit:b2b4fc8
/////////////////////////////////////////////////////////////////////////
0:                 ackedAndPrepared.add(ack.getLastMessageId().toProducerKey());
/////////////////////////////////////////////////////////////////////////
0:                     ackedAndPrepared.remove(ack.getLastMessageId().toProducerKey());
commit:4c51977
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.util.*;
/////////////////////////////////////////////////////////////////////////
1:     ReentrantReadWriteLock checkpointLock = new ReentrantReadWriteLock();
/////////////////////////////////////////////////////////////////////////
1:             checkpointLock.writeLock().lock();
1:                     checkpointUpdate(true);
1:                 checkpointLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
1:         checkpointUpdate(cleanup);
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:             Location location;
1:             checkpointLock.readLock().lock();
1:             try {
1: 
1:                 long start = System.currentTimeMillis();
0:                 location = onJournalStoreComplete == null ? journal.write(sequence, sync) :  journal.write(sequence, onJournalStoreComplete) ;
1:                 long start2 = System.currentTimeMillis();
0:                 process(data, location, after);
1: 
0:                 long end = System.currentTimeMillis();
0:                 if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:                     if (LOG.isInfoEnabled()) {
0:                         LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
1:                     }
1:                 }
1: 
0:             } finally{
1:                 checkpointLock.readLock().unlock();
1:             }
/////////////////////////////////////////////////////////////////////////
1:     private void checkpointUpdate(final boolean cleanup) throws IOException {
0:         checkpointLock.writeLock().lock();
1:         try {
1:             this.indexLock.writeLock().lock();
1:             try {
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                     @Override
1:                     public void execute(Transaction tx) throws IOException {
0:                         checkpointUpdate(tx, cleanup);
1:                     }
1:                 });
0:             } finally {
1:                 this.indexLock.writeLock().unlock();
1:             }
1: 
0:         } finally {
0:             checkpointLock.writeLock().unlock();
1:         }
1:     }
1: 
commit:c5cf038
commit:1aab71b
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.disk.index.BTreeIndex;
1: import org.apache.activemq.store.kahadb.disk.index.BTreeVisitor;
1: import org.apache.activemq.store.kahadb.disk.index.ListIndex;
1: import org.apache.activemq.store.kahadb.disk.journal.DataFile;
1: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1: import org.apache.activemq.store.kahadb.disk.journal.Location;
1: import org.apache.activemq.store.kahadb.disk.page.Page;
1: import org.apache.activemq.store.kahadb.disk.page.PageFile;
1: import org.apache.activemq.store.kahadb.disk.page.Transaction;
0: import org.apache.activemq.util.ByteSequence;
0: import org.apache.activemq.util.DataByteArrayInputStream;
0: import org.apache.activemq.util.DataByteArrayOutputStream;
1: import org.apache.activemq.store.kahadb.disk.util.LocationMarshaller;
0: import org.apache.activemq.util.LockFile;
1: import org.apache.activemq.store.kahadb.disk.util.LongMarshaller;
1: import org.apache.activemq.store.kahadb.disk.util.Marshaller;
1: import org.apache.activemq.store.kahadb.disk.util.Sequence;
1: import org.apache.activemq.store.kahadb.disk.util.SequenceSet;
1: import org.apache.activemq.store.kahadb.disk.util.StringMarshaller;
1: import org.apache.activemq.store.kahadb.disk.util.VariableMarshaller;
/////////////////////////////////////////////////////////////////////////
0:         rc.locationIndex.setKeyMarshaller(org.apache.activemq.store.kahadb.disk.util.LocationMarshaller.INSTANCE);
commit:bfed2c0
/////////////////////////////////////////////////////////////////////////
0:                 LOG.warn("Duplicate message add attempt rejected. Message id: "+command.getMessageId());
commit:bdd9e2a
/////////////////////////////////////////////////////////////////////////
0: import java.util.ArrayList;
0: import java.util.Collection;
0: import java.util.Date;
0: import java.util.HashMap;
0: import java.util.HashSet;
0: import java.util.Iterator;
0: import java.util.LinkedHashMap;
0: import java.util.List;
0: import java.util.SortedSet;
0: import java.util.TreeMap;
0: import java.util.TreeSet;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.journal.DataFile;
0: import org.apache.kahadb.util.ByteSequence;
0: import org.apache.kahadb.util.DataByteArrayInputStream;
0: import org.apache.kahadb.util.DataByteArrayOutputStream;
0: import org.apache.kahadb.util.LockFile;
0: import org.apache.kahadb.util.LongMarshaller;
0: import org.apache.kahadb.util.Marshaller;
0: import org.apache.kahadb.util.Sequence;
0: import org.apache.kahadb.util.SequenceSet;
0: import org.apache.kahadb.util.StringMarshaller;
0: import org.apache.kahadb.util.VariableMarshaller;
/////////////////////////////////////////////////////////////////////////
1:             previous = sd.messageIdIndex.put(tx, command.getMessageId(), id);
0:             if( previous == null ) {
0:                 sd.orderIndex.put(tx, id, new MessageKeys(command.getMessageId(), location));
1:             } else {
0:                 // If the message ID as indexed, then the broker asked us to store a DUP
0:                 // message.  Bad BOY!  Don't do it, and log a warning.
1: 
0:                 LOG.warn("Duplicate message add attempt rejected. Message id: "+command.getMessageId()+", on: "+command.getDestination());
1:                 
0:                 // TODO: consider just rolling back the tx.
1:                 sd.messageIdIndex.put(tx, command.getMessageId(), previous);
1:             }
0:             // added message.  We don't want to assign it a new id as the other indexes would 
0:             //
0:             // TODO: consider just rolling back the tx.
commit:35658c7
/////////////////////////////////////////////////////////////////////////
1:     public static final String PROPERTY_LOG_SLOW_ACCESS_TIME = "org.apache.activemq.store.kahadb.LOG_SLOW_ACCESS_TIME";
0:     public static final int LOG_SLOW_ACCESS_TIME = Integer.parseInt(System.getProperty(PROPERTY_LOG_SLOW_ACCESS_TIME, "500"));
1: 
1: 
/////////////////////////////////////////////////////////////////////////
0:         	if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:         		LOG.info("Slow KahaDB access: cleanup took "+(end-start));
/////////////////////////////////////////////////////////////////////////
0:     	if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:     		LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
commit:c9500f4
/////////////////////////////////////////////////////////////////////////
0: import java.util.*;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.journal.DataFile;
/////////////////////////////////////////////////////////////////////////
1:     private boolean checkForCorruptJournalFiles = false;
0:     private boolean checksumJournalFiles = false;
/////////////////////////////////////////////////////////////////////////
0:         long end = System.currentTimeMillis();
0:         if( undoCounter > 0 ) {
0:         	// The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
0:         	// should do sync writes to the journal.
0: 	        LOG.info("Rolled back " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:         }
1: 
1:         undoCounter = 0;
1:         start = System.currentTimeMillis();
/////////////////////////////////////////////////////////////////////////
0:             LOG.info("Some journal files are missing: "+missingJournalFiles);
1:         }
0:         ArrayList<BTreeVisitor.Predicate<Location>> missingPredicates = new ArrayList<BTreeVisitor.Predicate<Location>>();
1:         for (Integer missing : missingJournalFiles) {
0:             missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing,0), new Location(missing+1,0)));
1:         }
0:         if ( checkForCorruptJournalFiles ) {
1:             Collection<DataFile> dataFiles = journal.getFileMap().values();
1:             for (DataFile dataFile : dataFiles) {
1:                 int id = dataFile.getDataFileId();
0:                 missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id,dataFile.getLength()), new Location(id+1,0)));
1:                 Sequence seq = dataFile.getCorruptedBlocks().getHead();
0:                 while( seq!=null ) {
0:                     missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast()+1)));
1:                     seq = seq.getNext();
0:         if( !missingPredicates.isEmpty() ) {
1:             for (StoredDestination sd : storedDestinations.values()) {
1: 
0:                 final ArrayList<Long> matches = new ArrayList<Long>();
1:                 sd.locationIndex.visit(tx, new BTreeVisitor.OrVisitor<Location, Long>(missingPredicates) {
1:                     protected void matched(Location key, Long value) {
0:                         matches.add(value);
1:                     }
1:                 });
1: 
0:                 // If somes message references are affected by the missing data files...
0:                 if( !matches.isEmpty() ) {
1: 
1:                     // We either 'gracefully' recover dropping the missing messages or
1:                     // we error out.
0:                     if( ignoreMissingJournalfiles ) {
1:                         // Update the index to remove the references to the missing data
1:                         for (Long sequenceId : matches) {
1:                             MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
1:                             sd.locationIndex.remove(tx, keys.location);
1:                             sd.messageIdIndex.remove(tx, keys.messageId);
1:                             undoCounter++;
1:                             // TODO: do we need to modify the ack positions for the pub sub case?
1:                         }
1: 
1:                     } else {
0:                         throw new IOException("Detected missing/corrupt journal files. "+matches.size()+" messages affected.");
1:                     }
1:                 }
1:             }
1:         }
1:         
0:         end = System.currentTimeMillis();
0: 	        LOG.info("Detected missing/corrupt journal files.  Dropped " + undoCounter + " messages from the index in " + ((end - start) / 1000.0f) + " seconds.");
/////////////////////////////////////////////////////////////////////////
1:         manager.setCheckForCorruptionOnStartup(checkForCorruptJournalFiles);
1:         manager.setChecksum(checksumJournalFiles || checkForCorruptJournalFiles);
/////////////////////////////////////////////////////////////////////////
1: 
1:     public boolean isCheckForCorruptJournalFiles() {
1:         return checkForCorruptJournalFiles;
1:     }
1: 
1:     public void setCheckForCorruptJournalFiles(boolean checkForCorruptJournalFiles) {
1:         this.checkForCorruptJournalFiles = checkForCorruptJournalFiles;
1:     }
1: 
1:     public boolean isChecksumJournalFiles() {
1:         return checksumJournalFiles;
1:     }
1: 
1:     public void setChecksumJournalFiles(boolean checksumJournalFiles) {
1:         this.checksumJournalFiles = checksumJournalFiles;
1:     }
commit:fbc5eb5
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.*;
/////////////////////////////////////////////////////////////////////////
1:     private boolean ignoreMissingJournalfiles = false;
0:     private int indexCacheSize = 100;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
0:     private void lock() throws IOException {
0:         if( lockFile == null ) {
0:             File lockFileName = new File(directory, "lock");
0:             lockFile = new LockFile(lockFileName, true);
0:             if (failIfDatabaseIsLocked) {
0:                 lockFile.lock();
1:             } else {
0:                 while (true) {
1:                     try {
0:                         lockFile.lock();
0:                         break;
0:                     } catch (IOException e) {
0:                         LOG.info("Database "+lockFileName+" is locked... waiting " + (DATABASE_LOCKED_WAIT_DELAY / 1000) + " seconds for the database to be unlocked. Reason: " + e);
1:                         try {
0:                             Thread.sleep(DATABASE_LOCKED_WAIT_DELAY);
0:                         } catch (InterruptedException e1) {
1:                         }
1:                     }
1:                 }
1:             }
1:         }
1:     }
1: 
0:             lock();
1:             if (deleteAllMessages) {
0:                 getJournal().start();
0:                 getJournal().delete();
0:                 getJournal().close();
0:                 journal = null;
1:                 getPageFile().delete();
1:                 LOG.info("Persistence store purged.");
1:                 deleteAllMessages = false;
1:             }
1: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
1: 
1:         // Lets be extra paranoid here and verify that all the datafiles being referenced
1:         // by the indexes still exists.
1: 
1:         final SequenceSet ss = new SequenceSet();
0:         for (StoredDestination sd : storedDestinations.values()) {
1:             // Use a visitor to cut down the number of pages that we load
1:             sd.locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
0:                 int last=-1;
1: 
1:                 public boolean isInterestedInKeysBetween(Location first, Location second) {
0:                     if( first==null ) {
1:                         return !ss.contains(0, second.getDataFileId());
0:                     } else if( second==null ) {
1:                         return true;
1:                     } else {
1:                         return !ss.contains(first.getDataFileId(), second.getDataFileId());
1:                     }
1:                 }
1: 
1:                 public void visit(List<Location> keys, List<Long> values) {
1:                     for (Location l : keys) {
1:                         int fileId = l.getDataFileId();
0:                         if( last != fileId ) {
1:                             ss.add(fileId);
1:                             last = fileId;
1:                         }
1:                     }
1:                 }
1: 
1:             });
1:         }
0:         HashSet<Integer> missingJournalFiles = new HashSet<Integer>();
0:         while( !ss.isEmpty() ) {
0:             missingJournalFiles.add( (int)ss.removeFirst() );
1:         }
0:         missingJournalFiles.removeAll( journal.getFileMap().keySet() );
1: 
0:         if( !missingJournalFiles.isEmpty() ) {
0:             if( ignoreMissingJournalfiles ) {
1: 
0:                 for (StoredDestination sd : storedDestinations.values()) {
1: 
0:                     final ArrayList<Long> matches = new ArrayList<Long>();
0:                     for (Integer missing : missingJournalFiles) {
0:                         sd.locationIndex.visit(tx, new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing,0), new Location(missing+1,0)) {
1:                             @Override
0:                             protected void matched(Location key, Long value) {
0:                                 matches.add(value);
1:                             }
1:                         });
1:                     }
1: 
1: 
0:                     for (Long sequenceId : matches) {
1:                         MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
0:                         sd.locationIndex.remove(tx, keys.location);
0:                         sd.messageIdIndex.remove(tx, keys.messageId);
0:                         undoCounter++;
0:                         // TODO: do we need to modify the ack positions for the pub sub case?
1:                     }
1:                 }
1:                 
1:             } else {
0:                 throw new IOException("Detected missing journal files: "+missingJournalFiles);
1:             }
1:         }
1: 
/////////////////////////////////////////////////////////////////////////
1:         index.setPageCacheSize(indexCacheSize);
/////////////////////////////////////////////////////////////////////////
1: 
1:     public boolean isIgnoreMissingJournalfiles() {
1:         return ignoreMissingJournalfiles;
1:     }
1:     
1:     public void setIgnoreMissingJournalfiles(boolean ignoreMissingJournalfiles) {
1:         this.ignoreMissingJournalfiles = ignoreMissingJournalfiles;
1:     }
1: 
1:     public int getIndexCacheSize() {
1:         return indexCacheSize;
1:     }
1: 
1:     public void setIndexCacheSize(int indexCacheSize) {
1:         this.indexCacheSize = indexCacheSize;
1:     }
commit:e22a37a
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.VariableMarshaller;
/////////////////////////////////////////////////////////////////////////
1:     class MetadataMarshaller extends VariableMarshaller<Metadata> {
/////////////////////////////////////////////////////////////////////////
0:     static protected class MessageKeysMarshaller extends VariableMarshaller<MessageKeys> {
/////////////////////////////////////////////////////////////////////////
1:     protected class StoredDestinationMarshaller extends VariableMarshaller<StoredDestination> {
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1: 
0:         public int getFixedSize() {
0:             return 8;
1:         }
1: 
0:         public Location deepCopy(Location source) {
0:             return new Location(source);
1:         }
1: 
0:         public boolean isDeepCopySupported() {
1:             return true;
1:         }
1:     static class KahaSubscriptionCommandMarshaller extends VariableMarshaller<KahaSubscriptionCommand> {
commit:f73b622
/////////////////////////////////////////////////////////////////////////
commit:d761e80
/////////////////////////////////////////////////////////////////////////
0: 	        if( recoveryPosition!=null ) {
0: 		        int redoCounter = 0;
0: 		        while (recoveryPosition != null) {
0: 		            JournalCommand message = load(recoveryPosition);
0: 		            metadata.lastUpdate = recoveryPosition;
0: 		            process(message, recoveryPosition);
0: 		            redoCounter++;
0: 		            recoveryPosition = journal.getNextLocation(recoveryPosition);
1: 		        }
0: 		        long end = System.currentTimeMillis();
0: 	        	LOG.info("Replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
1: 	     
0: 	        // We may have to undo some index updates.
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
1:                 public void execute(Transaction tx) throws IOException {
0:                     recoverIndex(tx);
1:                 }
0:             });
0: 	protected void recoverIndex(Transaction tx) throws IOException {
0:         long start = System.currentTimeMillis();
0:         // It is possible index updates got applied before the journal updates.. 
1:         // in that case we need to removed references to messages that are not in the journal
1:         final Location lastAppendLocation = journal.getLastAppendLocation();
0:         long undoCounter=0;
1:         
1:         // Go through all the destinations to see if they have messages past the lastAppendLocation
0:         for (StoredDestination sd : storedDestinations.values()) {
1:         	
0:             final ArrayList<Long> matches = new ArrayList<Long>();
1:             // Find all the Locations that are >= than the last Append Location.
1:             sd.locationIndex.visit(tx, new BTreeVisitor.GTEVisitor<Location, Long>(lastAppendLocation) {
1: 				@Override
0: 				protected void matched(Location key, Long value) {
0: 					matches.add(value);
1: 				}
0:             });
1:             
1:             
0:             for (Long sequenceId : matches) {
1:                 MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
0:                 sd.locationIndex.remove(tx, keys.location);
0:                 sd.messageIdIndex.remove(tx, keys.messageId);
0:                 undoCounter++;
0:                 // TODO: do we need to modify the ack positions for the pub sub case?
1: 			}
1:         }
0:         long end = System.currentTimeMillis();
0:         if( undoCounter > 0 ) {
0:         	// The rolledback operations are basically in flight journal writes.  To avoid getting these the end user
0:         	// should do sync writes to the journal.
0: 	        LOG.info("Rolled back " + undoCounter + " operations from the index in " + ((end - start) / 1000.0f) + " seconds.");
1:         }
1: 	}
1: 
commit:51e82d5
/////////////////////////////////////////////////////////////////////////
0:         synchronized (indexMutex) {
0: 	        long start = System.currentTimeMillis();
1: 	        
0: 	        Location recoveryPosition = getRecoveryPosition();
0: 	        if( recoveryPosition ==null ) {
0: 	        	return;
1: 	        }
1: 	        
0: 	        int redoCounter = 0;
0: 	        LOG.info("Journal Recovery Started from: " + journal + " at " + recoveryPosition.getDataFileId() + ":" + recoveryPosition.getOffset());
1: 	
0: 	        while (recoveryPosition != null) {
0: 	            JournalCommand message = load(recoveryPosition);
0: 	            metadata.lastUpdate = recoveryPosition;
0: 	            process(message, recoveryPosition);
0: 	            redoCounter++;
0: 	            recoveryPosition = journal.getNextLocation(recoveryPosition);
1: 	        }
0: 	        long end = System.currentTimeMillis();
0: 	        LOG.info("Replayed " + redoCounter + " operations from redo log in " + ((end - start) / 1000.0f) + " seconds.");
0:         synchronized (indexMutex) {
0: 	        if( nextRecoveryPosition == null ) {
0: 	        	if( lastRecoveryPosition==null ) {
0: 	        		nextRecoveryPosition = getRecoveryPosition();
1: 	        	} else {
0: 	                nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1: 	        	}        	
1: 	        }
0: 	        while (nextRecoveryPosition != null) {
0: 	        	lastRecoveryPosition = nextRecoveryPosition;
0: 	            metadata.lastUpdate = lastRecoveryPosition;
0: 	            JournalCommand message = load(lastRecoveryPosition);
0: 	            process(message, lastRecoveryPosition);            
0: 	            nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1: 	        }
/////////////////////////////////////////////////////////////////////////
0:         synchronized (indexMutex) {
0:         	metadata.lastUpdate = location;
1:         }
commit:8262ef7
/////////////////////////////////////////////////////////////////////////
0: import java.util.SortedSet;
0: import java.util.TreeSet;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:         	
0:         	final TreeSet<Integer> gcCandidateSet = new TreeSet<Integer>(journal.getFileMap().keySet());
1:         	
0:         	// Don't GC files under replication
0:         	if( journalFilesBeingReplicated!=null ) {
0:         		gcCandidateSet.removeAll(journalFilesBeingReplicated);
1:         	}
1:         	
0:         	// Don't GC files after the first in progress tx
0:         	Location firstTxLocation = metadata.lastUpdate;
0:             if( metadata.firstInProgressTransactionLocation!=null ) {
0:                 firstTxLocation = metadata.firstInProgressTransactionLocation;
1:             }
1:             
0:             if( firstTxLocation!=null ) {
0:             	while( !gcCandidateSet.isEmpty() ) {
0:             		Integer last = gcCandidateSet.last();
0:             		if( last >= firstTxLocation.getDataFileId() ) {
0:             			gcCandidateSet.remove(last);
1:             		} else {
0:             			break;
1:             		}
1:             	}
1:             }
1: 
1:             // Go through all the destinations to see if any of them can remove GC candidates.
0:             	if( gcCandidateSet.isEmpty() ) {
0:                 	break;
1:                 }
0:                     	if( first==null ) {
0:                     		SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId()+1);
0:                     		if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
0:                     			subset.remove(second.getDataFileId());
1:                     		}
0: 							return !subset.isEmpty();
0:                     	} else if( second==null ) {
0:                     		SortedSet<Integer> subset = gcCandidateSet.tailSet(first.getDataFileId());
0:                     		if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
0:                     			subset.remove(first.getDataFileId());
1:                     		}
0: 							return !subset.isEmpty();
1:                     	} else {
0:                     		SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId()+1);
0:                     		if( !subset.isEmpty() && subset.first() == first.getDataFileId() ) {
0:                     			subset.remove(first.getDataFileId());
1:                     		}
0:                     		if( !subset.isEmpty() && subset.last() == second.getDataFileId() ) {
0:                     			subset.remove(second.getDataFileId());
1:                     		}
0: 							return !subset.isEmpty();
1:                     	}
0:                     	for (Location l : keys) {
1:                             int fileId = l.getDataFileId();
0: 							if( last != fileId ) {
0:                         		gcCandidateSet.remove(fileId);
1:                                 last = fileId;
1: 						}                        
1: 
0:             if( !gcCandidateSet.isEmpty() ) {
0: 	            LOG.debug("Cleanup removing the data files: "+gcCandidateSet);
0: 	            journal.removeDataFiles(gcCandidateSet);
commit:c059425
/////////////////////////////////////////////////////////////////////////
0:     protected boolean enableJournalDiskSyncs=true;
0:     long checkpointInterval = 5*1000;
0:     long cleanupInterval = 30*1000;
/////////////////////////////////////////////////////////////////////////
0:         return new PageFile(directory, "db");
/////////////////////////////////////////////////////////////////////////
1:     public boolean isEnableJournalDiskSyncs() {
0:         return enableJournalDiskSyncs;
1:     public void setEnableJournalDiskSyncs(boolean syncWrites) {
0:         this.enableJournalDiskSyncs = syncWrites;
1:     public long getCheckpointInterval() {
1:     public void setCheckpointInterval(long checkpointInterval) {
1:     public long getCleanupInterval() {
1:     public void setCleanupInterval(long cleanupInterval) {
commit:19c4316
/////////////////////////////////////////////////////////////////////////
0:         	long start = System.currentTimeMillis();
/////////////////////////////////////////////////////////////////////////
0:         	long end = System.currentTimeMillis();
0:         	if( end-start > 100 ) { 
0:         		LOG.warn("KahaDB Cleanup took "+(end-start));
1:         	}
/////////////////////////////////////////////////////////////////////////
0: 
0:     	
0: 
0:         long start = System.currentTimeMillis();
0:         long start2 = System.currentTimeMillis();
0:     	long end = System.currentTimeMillis();
0:     	if( end-start > 100 ) { 
0:     		LOG.warn("KahaDB long enqueue time: Journal Add Took: "+(start2-start)+" ms, Index Update took "+(end-start2)+" ms");
1:     	}
0: 
commit:f62737b
/////////////////////////////////////////////////////////////////////////
1: package org.apache.activemq.store.kahadb;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.store.kahadb.data.KahaAddMessageCommand;
0: import org.apache.activemq.store.kahadb.data.KahaCommitCommand;
0: import org.apache.activemq.store.kahadb.data.KahaDestination;
0: import org.apache.activemq.store.kahadb.data.KahaEntryType;
0: import org.apache.activemq.store.kahadb.data.KahaLocalTransactionId;
0: import org.apache.activemq.store.kahadb.data.KahaPrepareCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRemoveDestinationCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRemoveMessageCommand;
0: import org.apache.activemq.store.kahadb.data.KahaRollbackCommand;
0: import org.apache.activemq.store.kahadb.data.KahaSubscriptionCommand;
0: import org.apache.activemq.store.kahadb.data.KahaTraceCommand;
0: import org.apache.activemq.store.kahadb.data.KahaTransactionInfo;
0: import org.apache.activemq.store.kahadb.data.KahaXATransactionId;
/////////////////////////////////////////////////////////////////////////
commit:456a2ba
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
0:  *
1:  *      http://www.apache.org/licenses/LICENSE-2.0
0:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
0: package org.apache.kahadb.store;
0: 
0: import java.io.DataInput;
0: import java.io.DataOutput;
0: import java.io.File;
0: import java.io.IOException;
0: import java.io.InputStream;
0: import java.io.OutputStream;
0: import java.util.ArrayList;
0: import java.util.Date;
0: import java.util.HashMap;
0: import java.util.HashSet;
0: import java.util.Iterator;
0: import java.util.LinkedHashMap;
0: import java.util.List;
0: import java.util.TreeMap;
1: import java.util.Map.Entry;
1: import java.util.concurrent.atomic.AtomicBoolean;
0: 
0: import org.apache.activemq.command.ConnectionId;
0: import org.apache.activemq.command.LocalTransactionId;
0: import org.apache.activemq.command.SubscriptionInfo;
1: import org.apache.activemq.command.TransactionId;
0: import org.apache.activemq.command.XATransactionId;
0: import org.apache.activemq.util.Callback;
0: import org.apache.commons.logging.Log;
0: import org.apache.commons.logging.LogFactory;
0: import org.apache.kahadb.index.BTreeIndex;
0: import org.apache.kahadb.index.BTreeVisitor;
0: import org.apache.kahadb.journal.Journal;
0: import org.apache.kahadb.journal.Location;
0: import org.apache.kahadb.page.Page;
0: import org.apache.kahadb.page.PageFile;
0: import org.apache.kahadb.page.Transaction;
0: import org.apache.kahadb.store.data.KahaAddMessageCommand;
0: import org.apache.kahadb.store.data.KahaCommitCommand;
0: import org.apache.kahadb.store.data.KahaDestination;
0: import org.apache.kahadb.store.data.KahaEntryType;
0: import org.apache.kahadb.store.data.KahaLocalTransactionId;
0: import org.apache.kahadb.store.data.KahaPrepareCommand;
0: import org.apache.kahadb.store.data.KahaRemoveDestinationCommand;
0: import org.apache.kahadb.store.data.KahaRemoveMessageCommand;
0: import org.apache.kahadb.store.data.KahaRollbackCommand;
0: import org.apache.kahadb.store.data.KahaSubscriptionCommand;
0: import org.apache.kahadb.store.data.KahaTraceCommand;
0: import org.apache.kahadb.store.data.KahaTransactionInfo;
0: import org.apache.kahadb.store.data.KahaXATransactionId;
0: import org.apache.kahadb.util.ByteSequence;
0: import org.apache.kahadb.util.DataByteArrayInputStream;
0: import org.apache.kahadb.util.DataByteArrayOutputStream;
0: import org.apache.kahadb.util.LockFile;
0: import org.apache.kahadb.util.LongMarshaller;
0: import org.apache.kahadb.util.Marshaller;
0: import org.apache.kahadb.util.StringMarshaller;
0: 
0: public class MessageDatabase {
0: 
0:     private static final Log LOG = LogFactory.getLog(MessageDatabase.class);
0:     private static final int DATABASE_LOCKED_WAIT_DELAY = 10 * 1000;
0: 
0:     public static final int CLOSED_STATE = 1;
0:     public static final int OPEN_STATE = 2;
0: 
1:     protected class Metadata {
1:         protected Page<Metadata> page;
1:         protected int state;
1:         protected BTreeIndex<String, StoredDestination> destinations;
1:         protected Location lastUpdate;
1:         protected Location firstInProgressTransactionLocation;
0: 
1:         public void read(DataInput is) throws IOException {
1:             state = is.readInt();
0:             destinations = new BTreeIndex<String, StoredDestination>(pageFile, is.readLong());
1:             if (is.readBoolean()) {
1:                 lastUpdate = LocationMarshaller.INSTANCE.readPayload(is);
0:             } else {
1:                 lastUpdate = null;
1:             }
1:             if (is.readBoolean()) {
1:                 firstInProgressTransactionLocation = LocationMarshaller.INSTANCE.readPayload(is);
0:             } else {
1:                 firstInProgressTransactionLocation = null;
1:             }
1:         }
0: 
1:         public void write(DataOutput os) throws IOException {
1:             os.writeInt(state);
1:             os.writeLong(destinations.getPageId());
0: 
1:             if (lastUpdate != null) {
1:                 os.writeBoolean(true);
1:                 LocationMarshaller.INSTANCE.writePayload(lastUpdate, os);
0:             } else {
1:                 os.writeBoolean(false);
1:             }
0: 
1:             if (firstInProgressTransactionLocation != null) {
1:                 os.writeBoolean(true);
1:                 LocationMarshaller.INSTANCE.writePayload(firstInProgressTransactionLocation, os);
0:             } else {
1:                 os.writeBoolean(false);
1:             }
1:         }
1:     }
0: 
0:     class MetadataMarshaller implements Marshaller<Metadata> {
0:         public Class<Metadata> getType() {
0:             return Metadata.class;
1:         }
0: 
1:         public Metadata readPayload(DataInput dataIn) throws IOException {
0:             Metadata rc = new Metadata();
1:             rc.read(dataIn);
1:             return rc;
1:         }
0: 
1:         public void writePayload(Metadata object, DataOutput dataOut) throws IOException {
1:             object.write(dataOut);
1:         }
1:     }
0: 
1:     protected PageFile pageFile;
0: 	protected Journal journal;
0:     protected Metadata metadata = new Metadata();
0: 
1:     protected MetadataMarshaller metadataMarshaller = new MetadataMarshaller();
0: 
1:     protected boolean failIfDatabaseIsLocked;
0: 
1:     protected boolean deleteAllMessages;
0:     protected File directory;
0:     protected Thread checkpointThread;
0:     protected boolean syncWrites=true;
0:     int checkpointInterval = 5*1000;
0:     int cleanupInterval = 30*1000;
0:     
0:     protected AtomicBoolean started = new AtomicBoolean();
1:     protected AtomicBoolean opened = new AtomicBoolean();
0:     private LockFile lockFile;
0: 
0:     public MessageDatabase() {
1:     }
0: 
0:     public void start() throws Exception {
0:         if (started.compareAndSet(false, true)) {
1:         	load();
1:         }
1:     }
0: 
0:     public void stop() throws Exception {
0:         if (started.compareAndSet(true, false)) {
1:             unload();
1:         }
1:     }
0: 
0: 	private void loadPageFile() throws IOException {
0: 		synchronized (indexMutex) {
0: 		    final PageFile pageFile = getPageFile();
1:             pageFile.load();
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
1:                     if (pageFile.getPageCount() == 0) {
1:                         // First time this is created.. Initialize the metadata
1:                         Page<Metadata> page = tx.allocate();
1:                         assert page.getPageId() == 0;
1:                         page.set(metadata);
1:                         metadata.page = page;
1:                         metadata.state = CLOSED_STATE;
0:                         metadata.destinations = new BTreeIndex<String, StoredDestination>(pageFile, tx.allocate().getPageId());
0: 
1:                         tx.store(metadata.page, metadataMarshaller, true);
0:                     } else {
1:                         Page<Metadata> page = tx.load(0, metadataMarshaller);
1:                         metadata = page.get();
1:                         metadata.page = page;
1:                     }
1:                     metadata.destinations.setKeyMarshaller(StringMarshaller.INSTANCE);
1:                     metadata.destinations.setValueMarshaller(new StoredDestinationMarshaller());
1:                     metadata.destinations.load(tx);
1:                 }
0:             });
0:             pageFile.flush();
0:             
1:             // Load up all the destinations since we need to scan all the indexes to figure out which journal files can be deleted.
1:             // Perhaps we should just keep an index of file
1:             storedDestinations.clear();
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
0:                     for (Iterator<Entry<String, StoredDestination>> iterator = metadata.destinations.iterator(tx); iterator.hasNext();) {
1:                         Entry<String, StoredDestination> entry = iterator.next();
0:                         StoredDestination sd = loadStoredDestination(tx, entry.getKey(), entry.getValue().subscriptions!=null);
1:                         storedDestinations.put(entry.getKey(), sd);
1:                     }
1:                 }
0:             });
1:         }
1: 	}
0: 	
1: 	/**
1: 	 * @throws IOException
1: 	 */
0: 	public void open() throws IOException {
0: 		if( opened.compareAndSet(false, true) ) {
0:             File lockFileName = new File(directory, "lock");
0:             lockFile = new LockFile(lockFileName, true);
0: 	        if (failIfDatabaseIsLocked) {
0: 	            lockFile.lock();
0: 	        } else {
0: 	            while (true) {
0: 	                try {
0: 	                    lockFile.lock();
0: 	                    break;
0: 	                } catch (IOException e) {
0: 	                    LOG.info("Database "+lockFileName+" is locked... waiting " + (DATABASE_LOCKED_WAIT_DELAY / 1000) + " seconds for the database to be unlocked.");
0: 	                    try {
0: 	                        Thread.sleep(DATABASE_LOCKED_WAIT_DELAY);
0: 	                    } catch (InterruptedException e1) {
1: 	                    }
1: 	                }
1: 	            }
1: 	        }
0: 	        
0:             getJournal().start();
0:             
1: 	        loadPageFile();
0: 	        
0: 	        checkpointThread = new Thread("ActiveMQ Journal Checkpoint Worker") {
0: 	            public void run() {
0: 	                try {
0: 	                    long lastCleanup = System.currentTimeMillis();
0: 	                    long lastCheckpoint = System.currentTimeMillis();
0: 	                    
0: 	                    // Sleep for a short time so we can periodically check 
0: 	                    // to see if we need to exit this thread.
0: 	                    long sleepTime = Math.min(checkpointInterval, 500);
0: 	                    while (opened.get()) {
0: 	                        Thread.sleep(sleepTime);
0: 	                        long now = System.currentTimeMillis();
0: 	                        if( now - lastCleanup >= cleanupInterval ) {
0: 	                            checkpointCleanup(true);
0: 	                            lastCleanup = now;
0: 	                            lastCheckpoint = now;
0: 	                        } else if( now - lastCheckpoint >= checkpointInterval ) {
0: 	                            checkpointCleanup(false);
0: 	                            lastCheckpoint = now;
1: 	                        }
1: 	                    }
0: 	                } catch (InterruptedException e) {
0: 	                    // Looks like someone really wants us to exit this thread...
1: 	                }
1: 	            }
0: 	        };
0: 	        checkpointThread.start();
1:             recover();
1: 		}
1: 	}
0: 	
1:     public void load() throws IOException {
0:     	
0:         synchronized (indexMutex) {
0: 	    	open();
0: 	    	
0: 	        if (deleteAllMessages) {
0: 	            journal.delete();
0: 	
0: 	            pageFile.unload();
1: 	            pageFile.delete();
0: 	            metadata = new Metadata();
0: 	            
0: 	            LOG.info("Persistence store purged.");
0: 	            deleteAllMessages = false;
0: 	            
1: 	            loadPageFile();
1: 	        }
0: 	        store(new KahaTraceCommand().setMessage("LOADED " + new Date()));
0: 
1:         }
0: 
1:     }
0: 
0:     
0: 	public void close() throws IOException, InterruptedException {
0: 		if( opened.compareAndSet(true, false)) {
0: 	        synchronized (indexMutex) {
0: 	            pageFile.unload();
0: 	            metadata = new Metadata();
1: 	        }
0: 	        journal.close();
0: 	        checkpointThread.join();
0: 	        lockFile.unlock();
0: 	        lockFile=null;
1: 		}
1: 	}
0: 	
1:     public void unload() throws IOException, InterruptedException {
0:         synchronized (indexMutex) {
0:             if( pageFile.isLoaded() ) {
1:                 metadata.state = CLOSED_STATE;
0:                 metadata.firstInProgressTransactionLocation = getFirstInProgressTxLocation();
0:     
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                     public void execute(Transaction tx) throws IOException {
1:                         tx.store(metadata.page, metadataMarshaller, true);
1:                     }
0:                 });
0:                 close();
1:             }
1:         }
1:     }
0: 
1:     /**
0:      * @return
1:      */
0:     private Location getFirstInProgressTxLocation() {
0:         Location l = null;
0:         if (!inflightTransactions.isEmpty()) {
0:             l = inflightTransactions.values().iterator().next().get(0).getLocation();
1:         }
0:         if (!preparedTransactions.isEmpty()) {
0:             Location t = preparedTransactions.values().iterator().next().get(0).getLocation();
0:             if (l==null || t.compareTo(l) <= 0) {
0:                 l = t;
1:             }
1:         }
0:         return l;
1:     }
0: 
1:     /**
1:      * Move all the messages that were in the journal into long term storage. We
1:      * just replay and do a checkpoint.
0:      * 
1:      * @throws IOException
1:      * @throws IOException
0:      * @throws InvalidLocationException
0:      * @throws IllegalStateException
1:      */
1:     private void recover() throws IllegalStateException, IOException {
0:         long start = System.currentTimeMillis();
0:         
0:         Location recoveryPosition = getRecoveryPosition();
0:         if( recoveryPosition ==null ) {
0:         	return;
1:         }
0:         
0:         int redoCounter = 0;
0:         LOG.info("Journal Recovery Started from: " + journal + " at " + recoveryPosition.getDataFileId() + ":" + recoveryPosition.getOffset());
0: 
0:         while (recoveryPosition != null) {
0:             JournalCommand message = load(recoveryPosition);
0:             metadata.lastUpdate = recoveryPosition;
0:             process(message, recoveryPosition);
0:             redoCounter++;
0:             recoveryPosition = journal.getNextLocation(recoveryPosition);
1:         }
0:         long end = System.currentTimeMillis();
0:         LOG.info("Replayed " + redoCounter + " operations from redo log in " + ((end - start) / 1000.0f) + " seconds.");
1:     }
0:     
0: 	private Location nextRecoveryPosition;
0: 	private Location lastRecoveryPosition;
0: 
0: 	public void incrementalRecover() throws IOException {
0:         if( nextRecoveryPosition == null ) {
0:         	if( lastRecoveryPosition==null ) {
0:         		nextRecoveryPosition = getRecoveryPosition();
0:         	} else {
0:                 nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:         	}        	
1:         }
0:         while (nextRecoveryPosition != null) {
0:         	lastRecoveryPosition = nextRecoveryPosition;
0:             metadata.lastUpdate = lastRecoveryPosition;
0:             JournalCommand message = load(lastRecoveryPosition);
0:             process(message, lastRecoveryPosition);            
0:             nextRecoveryPosition = journal.getNextLocation(lastRecoveryPosition);
1:         }
1: 	}
0: 	
1:     public Location getLastUpdatePosition() throws IOException {
1:         return metadata.lastUpdate;
1:     }
0:     
0: 	private Location getRecoveryPosition() throws IOException {
0: 		
0:         // If we need to recover the transactions..
0:         if (metadata.firstInProgressTransactionLocation != null) {
0:             return metadata.firstInProgressTransactionLocation;
1:         }
0:         
0:         // Perhaps there were no transactions...
0:         if( metadata.lastUpdate!=null) {
0:             // Start replay at the record after the last one recorded in the index file.
0:             return journal.getNextLocation(metadata.lastUpdate);
1:         }
0:         
1:         // This loads the first position.
0:         return journal.getNextLocation(null);
1: 	}
0: 
0:     protected void checkpointCleanup(final boolean cleanup) {
0:         try {
0:             synchronized (indexMutex) {
0:             	if( !opened.get() ) {
0:             		return;
1:             	}
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                     public void execute(Transaction tx) throws IOException {
0:                         checkpointUpdate(tx, cleanup);
1:                     }
0:                 });
1:             }
0:         } catch (IOException e) {
0:         	e.printStackTrace();
1:         }
1:     }
0: 
0:     
0: 	public void checkpoint(Callback closure) throws Exception {
0:         synchronized (indexMutex) {
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
0:                     checkpointUpdate(tx, false);
1:                 }
0:             });
0:             pageFile.flush();
0:             closure.execute();
1:         }
1: 	}
0: 
1:     // /////////////////////////////////////////////////////////////////
0:     // Methods call by the broker to update and query the store.
1:     // /////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand data) throws IOException {
0:         return store(data, false);
1:     }
0: 
1:     /**
0:      * All updated are are funneled through this method. The updates a converted
1:      * to a JournalMessage which is logged to the journal and then the data from
1:      * the JournalMessage is used to update the index just like it would be done
0:      * durring a recovery process.
1:      */
0:     public Location store(JournalCommand data, boolean sync) throws IOException {
0:         int size = data.serializedSizeFramed();
0:         DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
0:         os.writeByte(data.type().getNumber());
0:         data.writeFramed(os);
0:         Location location = journal.write(os.toByteSequence(), sync);
0:         process(data, location);
0:         metadata.lastUpdate = location;
1:         return location;
1:     }
0: 
1:     /**
1:      * Loads a previously stored JournalMessage
0:      * 
0:      * @param location
0:      * @return
1:      * @throws IOException
1:      */
0:     public JournalCommand load(Location location) throws IOException {
1:         ByteSequence data = journal.read(location);
1:         DataByteArrayInputStream is = new DataByteArrayInputStream(data);
1:         byte readByte = is.readByte();
1:         KahaEntryType type = KahaEntryType.valueOf(readByte);
0:         if( type == null ) {
0:             throw new IOException("Could not load journal record. Invalid location: "+location);
1:         }
0:         JournalCommand message = (JournalCommand)type.createMessage();
1:         message.mergeFramed(is);
1:         return message;
1:     }
0: 
1:     // /////////////////////////////////////////////////////////////////
1:     // Journaled record processing methods. Once the record is journaled,
1:     // these methods handle applying the index updates. These may be called
1:     // from the recovery method too so they need to be idempotent
1:     // /////////////////////////////////////////////////////////////////
0: 
0:     private void process(JournalCommand data, final Location location) throws IOException {
1:         data.visit(new Visitor() {
1:             @Override
1:             public void visit(KahaAddMessageCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
0:             public void visit(KahaRemoveMessageCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
1:             public void visit(KahaPrepareCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
1:             public void visit(KahaCommitCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
1:             public void visit(KahaRollbackCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
1:             public void visit(KahaRemoveDestinationCommand command) throws IOException {
1:                 process(command, location);
1:             }
0: 
1:             @Override
1:             public void visit(KahaSubscriptionCommand command) throws IOException {
1:                 process(command, location);
1:             }
0:         });
1:     }
0: 
0:     private void process(final KahaAddMessageCommand command, final Location location) throws IOException {
1:         if (command.hasTransactionInfo()) {
0:             synchronized (indexMutex) {
0:                 ArrayList<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:                 inflightTx.add(new AddOpperation(command, location));
1:             }
0:         } else {
0:             synchronized (indexMutex) {
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                     public void execute(Transaction tx) throws IOException {
0:                         upadateIndex(tx, command, location);
1:                     }
0:                 });
1:             }
1:         }
1:     }
0: 
1:     protected void process(final KahaRemoveMessageCommand command, final Location location) throws IOException {
1:         if (command.hasTransactionInfo()) {
0:             synchronized (indexMutex) {
0:                 ArrayList<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:                 inflightTx.add(new RemoveOpperation(command, location));
1:             }
0:         } else {
0:             synchronized (indexMutex) {
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                     public void execute(Transaction tx) throws IOException {
1:                         updateIndex(tx, command, location);
1:                     }
0:                 });
1:             }
1:         }
0: 
1:     }
0: 
1:     protected void process(final KahaRemoveDestinationCommand command, final Location location) throws IOException {
0:         synchronized (indexMutex) {
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
1:                     updateIndex(tx, command, location);
1:                 }
0:             });
1:         }
1:     }
0: 
1:     protected void process(final KahaSubscriptionCommand command, final Location location) throws IOException {
0:         synchronized (indexMutex) {
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
1:                     updateIndex(tx, command, location);
1:                 }
0:             });
1:         }
1:     }
0: 
0:     protected void process(KahaCommitCommand command, Location location) throws IOException {
0:         TransactionId key = key(command.getTransactionInfo());
0:         synchronized (indexMutex) {
0:             ArrayList<Operation> inflightTx = inflightTransactions.remove(key);
1:             if (inflightTx == null) {
1:                 inflightTx = preparedTransactions.remove(key);
1:             }
1:             if (inflightTx == null) {
0:                 return;
1:             }
0: 
0:             final ArrayList<Operation> messagingTx = inflightTx;
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
0:                     for (Operation op : messagingTx) {
0:                         op.execute(tx);
1:                     }
1:                 }
0:             });
1:         }
1:     }
0: 
1:     protected void process(KahaPrepareCommand command, Location location) {
0:         synchronized (indexMutex) {
0:             TransactionId key = key(command.getTransactionInfo());
0:             ArrayList<Operation> tx = inflightTransactions.remove(key);
1:             if (tx != null) {
1:                 preparedTransactions.put(key, tx);
1:             }
1:         }
1:     }
0: 
0:     protected void process(KahaRollbackCommand command, Location location) {
0:         synchronized (indexMutex) {
0:             TransactionId key = key(command.getTransactionInfo());
0:             ArrayList<Operation> tx = inflightTransactions.remove(key);
0:             if (tx == null) {
0:                 preparedTransactions.remove(key);
1:             }
1:         }
1:     }
0: 
1:     // /////////////////////////////////////////////////////////////////
1:     // These methods do the actual index updates.
1:     // /////////////////////////////////////////////////////////////////
0: 
0:     protected final Object indexMutex = new Object();
0: 	private final HashSet<Integer> journalFilesBeingReplicated = new HashSet<Integer>();
0: 
0:     private void upadateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
1:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
0: 
1:         // Skip adding the message to the index if this is a topic and there are
1:         // no subscriptions.
0:         if (sd.subscriptions != null && sd.ackPositions.isEmpty()) {
0:             return;
1:         }
0: 
1:         // Add the message.
0:         long id = sd.nextMessageId++;
1:         Long previous = sd.locationIndex.put(tx, location, id);
0:         if( previous == null ) {
0:             sd.messageIdIndex.put(tx, command.getMessageId(), id);
0:             sd.orderIndex.put(tx, id, new MessageKeys(command.getMessageId(), location));
0:         } else {
0:             // restore the previous value.. Looks like this was a redo of a previously
0:             // added message.  We don't want to assing it a new id as the other indexes would 
1:             // be wrong..
1:             sd.locationIndex.put(tx, location, previous);
1:         }
0:         
1:     }
0: 
0:     private void updateIndex(Transaction tx, KahaRemoveMessageCommand command, Location ackLocation) throws IOException {
1:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
1:         if (!command.hasSubscriptionKey()) {
0:             
1:             // In the queue case we just remove the message from the index..
1:             Long sequenceId = sd.messageIdIndex.remove(tx, command.getMessageId());
1:             if (sequenceId != null) {
0:                 MessageKeys keys = sd.orderIndex.remove(tx, sequenceId);
0:                 sd.locationIndex.remove(tx, keys.location);
1:             }
0:         } else {
1:             // In the topic case we need remove the message once it's been acked
1:             // by all the subs
1:             Long sequence = sd.messageIdIndex.get(tx, command.getMessageId());
0: 
1:             // Make sure it's a valid message id...
1:             if (sequence != null) {
1:                 String subscriptionKey = command.getSubscriptionKey();
0:                 Long prev = sd.subscriptionAcks.put(tx, subscriptionKey, sequence);
0: 
0:                 // The following method handles deleting un-referenced messages.
0:                 removeAckLocation(tx, sd, subscriptionKey, prev);
0: 
0:                 // Add it to the new location set.
0:                 addAckLocation(sd, sequence, subscriptionKey);
1:             }
0: 
1:         }
1:     }
0: 
0:     private void updateIndex(Transaction tx, KahaRemoveDestinationCommand command, Location location) throws IOException {
1:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
0:         sd.orderIndex.clear(tx);
0:         sd.orderIndex.unload(tx);
0:         tx.free(sd.orderIndex.getPageId());
0:         
0:         sd.locationIndex.clear(tx);
1:         sd.locationIndex.unload(tx);
1:         tx.free(sd.locationIndex.getPageId());
0: 
0:         sd.messageIdIndex.clear(tx);
1:         sd.messageIdIndex.unload(tx);
1:         tx.free(sd.messageIdIndex.getPageId());
0: 
1:         if (sd.subscriptions != null) {
1:             sd.subscriptions.clear(tx);
1:             sd.subscriptions.unload(tx);
1:             tx.free(sd.subscriptions.getPageId());
0: 
1:             sd.subscriptionAcks.clear(tx);
1:             sd.subscriptionAcks.unload(tx);
1:             tx.free(sd.subscriptionAcks.getPageId());
1:         }
0: 
1:         String key = key(command.getDestination());
1:         storedDestinations.remove(key);
1:         metadata.destinations.remove(tx, key);
1:     }
0: 
0:     private void updateIndex(Transaction tx, KahaSubscriptionCommand command, Location location) throws IOException {
1:         StoredDestination sd = getStoredDestination(command.getDestination(), tx);
0: 
1:         // If set then we are creating it.. otherwise we are destroying the sub
1:         if (command.hasSubscriptionInfo()) {
1:             String subscriptionKey = command.getSubscriptionKey();
1:             sd.subscriptions.put(tx, subscriptionKey, command);
0:             long ackLocation=-1;
1:             if (!command.getRetroactive()) {
0:                 ackLocation = sd.nextMessageId-1;
1:             }
0: 
0:             sd.subscriptionAcks.put(tx, subscriptionKey, ackLocation);
0:             addAckLocation(sd, ackLocation, subscriptionKey);
0:         } else {
1:             // delete the sub...
1:             String subscriptionKey = command.getSubscriptionKey();
1:             sd.subscriptions.remove(tx, subscriptionKey);
0:             Long prev = sd.subscriptionAcks.remove(tx, subscriptionKey);
0:             if( prev!=null ) {
0:                 removeAckLocation(tx, sd, subscriptionKey, prev);
1:             }
1:         }
0: 
1:     }
0:     
1:     /**
1:      * @param tx
1:      * @throws IOException
1:      */
0:     private void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
0: 
1:         LOG.debug("Checkpoint started.");
0:         
1:         metadata.state = OPEN_STATE;
0:         metadata.firstInProgressTransactionLocation = getFirstInProgressTxLocation();
1:         tx.store(metadata.page, metadataMarshaller, true);
0:         pageFile.flush();
0: 
0:         if( cleanup ) {
0:             // Find empty journal files to remove.
0:             final HashSet<Integer> inUseFiles = new HashSet<Integer>();
0:             for (StoredDestination sd : storedDestinations.values()) {
0:                 
1:                 // Use a visitor to cut down the number of pages that we load
0:                 sd.locationIndex.visit(tx, new BTreeVisitor<Location, Long>() {
0:                     int last=-1;
1:                     public boolean isInterestedInKeysBetween(Location first, Location second) {
0:                         if( second!=null ) {
0:                             if( last+1 == second.getDataFileId() ) {
0:                                 last++;
0:                                 inUseFiles.add(last);
1:                             }
0:                             if( last == second.getDataFileId() ) {
1:                                 return false;
1:                             }
1:                         }
0:                         return true;
1:                     }
0:     
1:                     public void visit(List<Location> keys, List<Long> values) {
0:                         for (int i = 0; i < keys.size(); i++) {
0:                             if( last != keys.get(i).getDataFileId() ) {
0:                                 inUseFiles.add(keys.get(i).getDataFileId());
0:                                 last = keys.get(i).getDataFileId();
1:                             }
1:                         }
0:                         
1:                     }
0:     
0:                 });
1:             }
0:             inUseFiles.addAll(journalFilesBeingReplicated);
0:             Location l = metadata.lastUpdate;
0:             if( metadata.firstInProgressTransactionLocation!=null ) {
0:                 l = metadata.firstInProgressTransactionLocation;
1:             }
0:             
0:             LOG.debug("In use files: "+inUseFiles+", lastUpdate: "+l);
0:             journal.consolidateDataFilesNotIn(inUseFiles, l==null?null:l.getDataFileId());
1:         }
0:         
1:         LOG.debug("Checkpoint done.");
1:     }
0:     
1:     public HashSet<Integer> getJournalFilesBeingReplicated() {
0: 		return journalFilesBeingReplicated;
1: 	}
0: 
1:     // /////////////////////////////////////////////////////////////////
1:     // StoredDestination related implementation methods.
1:     // /////////////////////////////////////////////////////////////////
0: 
0: 
0: 	private final HashMap<String, StoredDestination> storedDestinations = new HashMap<String, StoredDestination>();
0: 
0:     class StoredSubscription {
0:         SubscriptionInfo subscriptionInfo;
0:         String lastAckId;
0:         Location lastAckLocation;
0:         Location cursor;
1:     }
0:     
1:     static class MessageKeys {
1:         final String messageId;
1:         final Location location;
0:         
1:         public MessageKeys(String messageId, Location location) {
0:             this.messageId=messageId;
0:             this.location=location;
1:         }
0:         
1:         @Override
1:         public String toString() {
0:             return "["+messageId+","+location+"]";
1:         }
1:     }
0:     
0:     static protected class MessageKeysMarshaller implements Marshaller<MessageKeys> {
0:         static final MessageKeysMarshaller INSTANCE = new MessageKeysMarshaller();
0:         
0:         public Class<MessageKeys> getType() {
0:             return MessageKeys.class;
1:         }
0: 
1:         public MessageKeys readPayload(DataInput dataIn) throws IOException {
0:             return new MessageKeys(dataIn.readUTF(), LocationMarshaller.INSTANCE.readPayload(dataIn));
1:         }
0: 
1:         public void writePayload(MessageKeys object, DataOutput dataOut) throws IOException {
1:             dataOut.writeUTF(object.messageId);
0:             LocationMarshaller.INSTANCE.writePayload(object.location, dataOut);
1:         }
1:     }
0:     
0:     static class StoredDestination {
1:         long nextMessageId;
0:         BTreeIndex<Long, MessageKeys> orderIndex;
1:         BTreeIndex<Location, Long> locationIndex;
1:         BTreeIndex<String, Long> messageIdIndex;
0: 
1:         // These bits are only set for Topics
1:         BTreeIndex<String, KahaSubscriptionCommand> subscriptions;
0:         BTreeIndex<String, Long> subscriptionAcks;
0:         HashMap<String, Long> subscriptionCursors;
0:         TreeMap<Long, HashSet<String>> ackPositions;
1:     }
0: 
0:     protected class StoredDestinationMarshaller implements Marshaller<StoredDestination> {
0:         public Class<StoredDestination> getType() {
0:             return StoredDestination.class;
1:         }
0: 
0:         public StoredDestination readPayload(DataInput dataIn) throws IOException {
0:             StoredDestination value = new StoredDestination();
0:             value.orderIndex = new BTreeIndex<Long, MessageKeys>(pageFile, dataIn.readLong());
0:             value.locationIndex = new BTreeIndex<Location, Long>(pageFile, dataIn.readLong());
0:             value.messageIdIndex = new BTreeIndex<String, Long>(pageFile, dataIn.readLong());
0: 
1:             if (dataIn.readBoolean()) {
0:                 value.subscriptions = new BTreeIndex<String, KahaSubscriptionCommand>(pageFile, dataIn.readLong());
0:                 value.subscriptionAcks = new BTreeIndex<String, Long>(pageFile, dataIn.readLong());
1:             }
1:             return value;
1:         }
0: 
1:         public void writePayload(StoredDestination value, DataOutput dataOut) throws IOException {
0:             dataOut.writeLong(value.orderIndex.getPageId());
1:             dataOut.writeLong(value.locationIndex.getPageId());
1:             dataOut.writeLong(value.messageIdIndex.getPageId());
1:             if (value.subscriptions != null) {
1:                 dataOut.writeBoolean(true);
1:                 dataOut.writeLong(value.subscriptions.getPageId());
1:                 dataOut.writeLong(value.subscriptionAcks.getPageId());
0:             } else {
1:                 dataOut.writeBoolean(false);
1:             }
1:         }
1:     }
0: 
0:     static class LocationMarshaller implements Marshaller<Location> {
0:         final static LocationMarshaller INSTANCE = new LocationMarshaller();
0: 
0:         public Class<Location> getType() {
0:             return Location.class;
1:         }
0: 
0:         public Location readPayload(DataInput dataIn) throws IOException {
0:             Location rc = new Location();
0:             rc.setDataFileId(dataIn.readInt());
0:             rc.setOffset(dataIn.readInt());
1:             return rc;
1:         }
0: 
0:         public void writePayload(Location object, DataOutput dataOut) throws IOException {
0:             dataOut.writeInt(object.getDataFileId());
0:             dataOut.writeInt(object.getOffset());
1:         }
1:     }
0: 
0:     static class KahaSubscriptionCommandMarshaller implements Marshaller<KahaSubscriptionCommand> {
1:         final static KahaSubscriptionCommandMarshaller INSTANCE = new KahaSubscriptionCommandMarshaller();
0: 
0:         public Class<KahaSubscriptionCommand> getType() {
0:             return KahaSubscriptionCommand.class;
1:         }
0: 
1:         public KahaSubscriptionCommand readPayload(DataInput dataIn) throws IOException {
1:             KahaSubscriptionCommand rc = new KahaSubscriptionCommand();
0:             rc.mergeFramed((InputStream)dataIn);
1:             return rc;
1:         }
0: 
1:         public void writePayload(KahaSubscriptionCommand object, DataOutput dataOut) throws IOException {
0:             object.writeFramed((OutputStream)dataOut);
1:         }
1:     }
0: 
1:     protected StoredDestination getStoredDestination(KahaDestination destination, Transaction tx) throws IOException {
1:         String key = key(destination);
1:         StoredDestination rc = storedDestinations.get(key);
1:         if (rc == null) {
1:             boolean topic = destination.getType() == KahaDestination.DestinationType.TOPIC || destination.getType() == KahaDestination.DestinationType.TEMP_TOPIC;
1:             rc = loadStoredDestination(tx, key, topic);
1:             // Cache it. We may want to remove/unload destinations from the
1:             // cache that are not used for a while
1:             // to reduce memory usage.
1:             storedDestinations.put(key, rc);
1:         }
1:         return rc;
1:     }
0: 
1:     /**
1:      * @param tx
1:      * @param key
1:      * @param topic
0:      * @return
1:      * @throws IOException
1:      */
1:     private StoredDestination loadStoredDestination(Transaction tx, String key, boolean topic) throws IOException {
1:         // Try to load the existing indexes..
1:         StoredDestination rc = metadata.destinations.get(tx, key);
1:         if (rc == null) {
1:             // Brand new destination.. allocate indexes for it.
1:             rc = new StoredDestination();
0:             rc.orderIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:             rc.locationIndex = new BTreeIndex<Location, Long>(pageFile, tx.allocate());
0:             rc.messageIdIndex = new BTreeIndex<String, Long>(pageFile, tx.allocate());
0: 
1:             if (topic) {
0:                 rc.subscriptions = new BTreeIndex<String, KahaSubscriptionCommand>(pageFile, tx.allocate());
0:                 rc.subscriptionAcks = new BTreeIndex<String, Long>(pageFile, tx.allocate());
1:             }
1:             metadata.destinations.put(tx, key, rc);
1:         }
0: 
1:         // Configure the marshalers and load.
0:         rc.orderIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:         rc.orderIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:         rc.orderIndex.load(tx);
0: 
1:         // Figure out the next key using the last entry in the destination.
0:         Entry<Long, MessageKeys> lastEntry = rc.orderIndex.getLast(tx);
0:         if( lastEntry!=null ) {
0:             rc.nextMessageId = lastEntry.getKey()+1;
1:         }
0: 
0:         rc.locationIndex.setKeyMarshaller(LocationMarshaller.INSTANCE);
1:         rc.locationIndex.setValueMarshaller(LongMarshaller.INSTANCE);
1:         rc.locationIndex.load(tx);
0: 
1:         rc.messageIdIndex.setKeyMarshaller(StringMarshaller.INSTANCE);
1:         rc.messageIdIndex.setValueMarshaller(LongMarshaller.INSTANCE);
1:         rc.messageIdIndex.load(tx);
0:         
1:         // If it was a topic...
1:         if (topic) {
0: 
1:             rc.subscriptions.setKeyMarshaller(StringMarshaller.INSTANCE);
1:             rc.subscriptions.setValueMarshaller(KahaSubscriptionCommandMarshaller.INSTANCE);
1:             rc.subscriptions.load(tx);
0: 
1:             rc.subscriptionAcks.setKeyMarshaller(StringMarshaller.INSTANCE);
0:             rc.subscriptionAcks.setValueMarshaller(LongMarshaller.INSTANCE);
1:             rc.subscriptionAcks.load(tx);
0: 
0:             rc.ackPositions = new TreeMap<Long, HashSet<String>>();
0:             rc.subscriptionCursors = new HashMap<String, Long>();
0: 
0:             for (Iterator<Entry<String, Long>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext();) {
0:                 Entry<String, Long> entry = iterator.next();
0:                 addAckLocation(rc, entry.getValue(), entry.getKey());
1:             }
0: 
1:         }
1:         return rc;
1:     }
0: 
1:     /**
1:      * @param sd
0:      * @param messageSequence
1:      * @param subscriptionKey
1:      */
0:     private void addAckLocation(StoredDestination sd, Long messageSequence, String subscriptionKey) {
0:         HashSet<String> hs = sd.ackPositions.get(messageSequence);
0:         if (hs == null) {
0:             hs = new HashSet<String>();
0:             sd.ackPositions.put(messageSequence, hs);
1:         }
0:         hs.add(subscriptionKey);
1:     }
0: 
1:     /**
1:      * @param tx
1:      * @param sd
1:      * @param subscriptionKey
0:      * @param sequenceId
1:      * @throws IOException
1:      */
0:     private void removeAckLocation(Transaction tx, StoredDestination sd, String subscriptionKey, Long sequenceId) throws IOException {
1:         // Remove the sub from the previous location set..
1:         if (sequenceId != null) {
0:             HashSet<String> hs = sd.ackPositions.get(sequenceId);
0:             if (hs != null) {
0:                 hs.remove(subscriptionKey);
0:                 if (hs.isEmpty()) {
0:                     HashSet<String> firstSet = sd.ackPositions.values().iterator().next();
0:                     sd.ackPositions.remove(sequenceId);
0: 
0:                     // Did we just empty out the first set in the
0:                     // ordered list of ack locations? Then it's time to
0:                     // delete some messages.
0:                     if (hs == firstSet) {
0: 
0:                         // Find all the entries that need to get deleted.
0:                         ArrayList<Entry<Long, MessageKeys>> deletes = new ArrayList<Entry<Long, MessageKeys>>();
0:                         for (Iterator<Entry<Long, MessageKeys>> iterator = sd.orderIndex.iterator(tx); iterator.hasNext();) {
0:                             Entry<Long, MessageKeys> entry = iterator.next();
0:                             if (entry.getKey().compareTo(sequenceId) <= 0) {
0:                                 // We don't do the actually delete while we are
0:                                 // iterating the BTree since
0:                                 // iterating would fail.
0:                                 deletes.add(entry);
1:                             }
1:                         }
0: 
0:                         // Do the actual deletes.
0:                         for (Entry<Long, MessageKeys> entry : deletes) {
0:                             sd.locationIndex.remove(tx, entry.getValue().location);
0:                             sd.messageIdIndex.remove(tx,entry.getValue().messageId);
0:                             sd.orderIndex.remove(tx,entry.getKey());
1:                         }
1:                     }
1:                 }
1:             }
1:         }
1:     }
0: 
0:     private String key(KahaDestination destination) {
1:         return destination.getType().getNumber() + ":" + destination.getName();
1:     }
0: 
1:     // /////////////////////////////////////////////////////////////////
1:     // Transaction related implementation methods.
1:     // /////////////////////////////////////////////////////////////////
0:     protected final LinkedHashMap<TransactionId, ArrayList<Operation>> inflightTransactions = new LinkedHashMap<TransactionId, ArrayList<Operation>>();
0:     protected final LinkedHashMap<TransactionId, ArrayList<Operation>> preparedTransactions = new LinkedHashMap<TransactionId, ArrayList<Operation>>();
0: 
0:     private ArrayList<Operation> getInflightTx(KahaTransactionInfo info, Location location) {
0:         TransactionId key = key(info);
0:         ArrayList<Operation> tx = inflightTransactions.get(key);
0:         if (tx == null) {
0:             tx = new ArrayList<Operation>();
0:             inflightTransactions.put(key, tx);
1:         }
1:         return tx;
1:     }
0: 
1:     private TransactionId key(KahaTransactionInfo transactionInfo) {
0:         if (transactionInfo.hasLocalTransacitonId()) {
0:             KahaLocalTransactionId tx = transactionInfo.getLocalTransacitonId();
0:             LocalTransactionId rc = new LocalTransactionId();
0:             rc.setConnectionId(new ConnectionId(tx.getConnectionId()));
0:             rc.setValue(tx.getTransacitonId());
1:             return rc;
0:         } else {
0:             KahaXATransactionId tx = transactionInfo.getXaTransacitonId();
0:             XATransactionId rc = new XATransactionId();
0:             rc.setBranchQualifier(tx.getBranchQualifier().toByteArray());
0:             rc.setGlobalTransactionId(tx.getGlobalTransactionId().toByteArray());
0:             rc.setFormatId(tx.getFormatId());
1:             return rc;
1:         }
1:     }
0: 
0:     abstract class Operation {
1:         final Location location;
0: 
0:         public Operation(Location location) {
1:             this.location = location;
1:         }
0: 
1:         public Location getLocation() {
1:             return location;
1:         }
0: 
1:         abstract public void execute(Transaction tx) throws IOException;
1:     }
0: 
0:     class AddOpperation extends Operation {
0:         final KahaAddMessageCommand command;
0: 
0:         public AddOpperation(KahaAddMessageCommand command, Location location) {
0:             super(location);
0:             this.command = command;
1:         }
0: 
0:         public void execute(Transaction tx) throws IOException {
0:             upadateIndex(tx, command, location);
1:         }
0: 
0:         public KahaAddMessageCommand getCommand() {
0:             return command;
1:         }
1:     }
0: 
0:     class RemoveOpperation extends Operation {
0:         final KahaRemoveMessageCommand command;
0: 
0:         public RemoveOpperation(KahaRemoveMessageCommand command, Location location) {
0:             super(location);
0:             this.command = command;
1:         }
0: 
0:         public void execute(Transaction tx) throws IOException {
1:             updateIndex(tx, command, location);
1:         }
0: 
0:         public KahaRemoveMessageCommand getCommand() {
0:             return command;
1:         }
1:     }
0: 
1:     // /////////////////////////////////////////////////////////////////
1:     // Initialization related implementation methods.
1:     // /////////////////////////////////////////////////////////////////
0: 
0:     private PageFile createPageFile() {
0:         PageFile pf = new PageFile(directory, "db");
0:         return pf;
1:     }
0: 
0:     private Journal createJournal() {
0:         Journal manager = new Journal();
1:         manager.setDirectory(directory);
0:         manager.setMaxFileLength(1024 * 1024 * 20);
0:         manager.setUseNio(false);
1:         return manager;
1:     }
0: 
1:     public File getDirectory() {
1:         return directory;
1:     }
0: 
1:     public void setDirectory(File directory) {
1:         this.directory = directory;
1:     }
0: 
1:     public boolean isDeleteAllMessages() {
1:         return deleteAllMessages;
1:     }
0: 
1:     public void setDeleteAllMessages(boolean deleteAllMessages) {
1:         this.deleteAllMessages = deleteAllMessages;
1:     }
0: 
0:     public boolean isSyncWrites() {
0:         return syncWrites;
1:     }
0: 
0:     public void setSyncWrites(boolean syncWrites) {
0:         this.syncWrites = syncWrites;
1:     }
0: 
0:     public int getCheckpointInterval() {
1:         return checkpointInterval;
1:     }
0: 
0:     public void setCheckpointInterval(int checkpointInterval) {
1:         this.checkpointInterval = checkpointInterval;
1:     }
0: 
0:     public int getCleanupInterval() {
1:         return cleanupInterval;
1:     }
0: 
0:     public void setCleanupInterval(int cleanupInterval) {
1:         this.cleanupInterval = cleanupInterval;
1:     }
0: 
0:     public PageFile getPageFile() {
1:         if (pageFile == null) {
1:             pageFile = createPageFile();
1:         }
0: 		return pageFile;
1: 	}
0: 
0: 	public Journal getJournal() {
0:         if (journal == null) {
0:             journal = createJournal();
1:         }
0: 		return journal;
1: 	}
0: 
1:     public boolean isFailIfDatabaseIsLocked() {
1:         return failIfDatabaseIsLocked;
1:     }
0: 
1:     public void setFailIfDatabaseIsLocked(boolean failIfDatabaseIsLocked) {
1:         this.failIfDatabaseIsLocked = failIfDatabaseIsLocked;
1:     }
1: }
author:Bosanac Dejan
-------------------------------------------------------------------------------
commit:170b86a
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
commit:6ce702d
/////////////////////////////////////////////////////////////////////////
0:         IOHelper.mkdirs(directory);
/////////////////////////////////////////////////////////////////////////
1:             this.indexLock.writeLock().lock();
0:                 if (metadata.page != null) {
0:                     pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                         public void execute(Transaction tx) throws IOException {
0:                             checkpointUpdate(tx, true);
0:                         }
0:                     });
0:                 pageFile.unload();
0:                 metadata = new Metadata();
1:                 this.indexLock.writeLock().unlock();
0:             }
0:             journal.close();
0:             synchronized (checkpointThreadLock) {
0:                 if (checkpointThread != null) {
0:                     checkpointThread.join();
0:                 }
commit:a604424
/////////////////////////////////////////////////////////////////////////
1:     protected AtomicLong journalSize = new AtomicLong(0);
/////////////////////////////////////////////////////////////////////////
1:         manager.setSizeAccumulator(journalSize);
commit:5f7fc14
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.store.kahadb.data.*;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.*;
0: import java.io.ByteArrayInputStream;
0: import java.io.ByteArrayOutputStream;
0: import java.io.*;
0: import java.util.*;
0: import java.util.Map.Entry;
0: import java.util.concurrent.atomic.AtomicBoolean;
0: import java.util.concurrent.atomic.AtomicLong;
1: import java.util.concurrent.locks.ReentrantReadWriteLock;
0: 
/////////////////////////////////////////////////////////////////////////
1:     private boolean archiveCorruptedIndex = false;
/////////////////////////////////////////////////////////////////////////
0:             try {
0:                 loadPageFile();
0:             } catch (IOException ioe) {
0:                 LOG.warn("Index corrupted, trying to recover ...", ioe);
1:                 // try to recover index
0:                 try {
0:                     pageFile.unload();
1:                 } catch (Exception ignore) {}
1:                 if (archiveCorruptedIndex) {
1:                     pageFile.archive();
0:                 } else {
0:                     pageFile.delete();
0:                 }
0:                 loadPageFile();
0:             }
/////////////////////////////////////////////////////////////////////////
1:     public boolean isArchiveCorruptedIndex() {
1:         return archiveCorruptedIndex;
0:     }
0: 
1:     public void setArchiveCorruptedIndex(boolean archiveCorruptedIndex) {
1:         this.archiveCorruptedIndex = archiveCorruptedIndex;
0:     }
0: 
commit:01ae0ea
/////////////////////////////////////////////////////////////////////////
0:             if (metadata.producerSequenceIdTrackerLocation != null) {
0:                 gcCandidateSet.remove(metadata.producerSequenceIdTrackerLocation.getDataFileId());
0:             }
0: 
commit:14755a1
/////////////////////////////////////////////////////////////////////////
0:                 return journal.getNextLocation(metadata.producerSequenceIdTrackerLocation);
0:             } catch (Exception e) {
1:                 LOG.warn("Cannot recover message audit", e);
0:                 return journal.getNextLocation(null);
/////////////////////////////////////////////////////////////////////////
0:                 metadata.producerSequenceIdTracker.rollback(keys.messageId);
commit:8bf987b
/////////////////////////////////////////////////////////////////////////
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
/////////////////////////////////////////////////////////////////////////
1:     private static final Logger LOG = LoggerFactory.getLogger(MessageDatabase.class);
commit:2aa2278
/////////////////////////////////////////////////////////////////////////
0:     protected File directory = new File("KahaDB");
commit:a19e27a
/////////////////////////////////////////////////////////////////////////
0: 	private void startCheckpoint() {
0:         checkpointThread = new Thread("ActiveMQ Journal Checkpoint Worker") {
0:             public void run() {
0:                 try {
0:                     long lastCleanup = System.currentTimeMillis();
0:                     long lastCheckpoint = System.currentTimeMillis();
0:                     // Sleep for a short time so we can periodically check 
0:                     // to see if we need to exit this thread.
0:                     long sleepTime = Math.min(checkpointInterval, 500);
0:                     while (opened.get()) {
0:                         
0:                         Thread.sleep(sleepTime);
0:                         long now = System.currentTimeMillis();
0:                         if( now - lastCleanup >= cleanupInterval ) {
0:                             checkpointCleanup(true);
0:                             lastCleanup = now;
0:                             lastCheckpoint = now;
0:                         } else if( now - lastCheckpoint >= checkpointInterval ) {
0:                             checkpointCleanup(false);
0:                             lastCheckpoint = now;
0:                         }
0:                     }
0:                 } catch (InterruptedException e) {
0:                     // Looks like someone really wants us to exit this thread...
0:                 } catch (IOException ioe) {
0:                     LOG.error("Checkpoint failed", ioe);
0:                     brokerService.handleIOException(ioe);
0:                 }
0:             }
0:                     
0:         };
0:         checkpointThread.setDaemon(true);
0:         checkpointThread.start();
0: 	}
0: 	
/////////////////////////////////////////////////////////////////////////
0: 	        startCheckpoint();
/////////////////////////////////////////////////////////////////////////
1:      * All updated are are funneled through this method. The updates are converted
1:      * during a recovery process.
0:     	try {
0:             int size = data.serializedSizeFramed();
0:             DataByteArrayOutputStream os = new DataByteArrayOutputStream(size + 1);
0:             os.writeByte(data.type().getNumber());
0:             data.writeFramed(os);
0:     
0:             long start = System.currentTimeMillis();
0:             Location location = journal.write(os.toByteSequence(), sync);
0:             long start2 = System.currentTimeMillis();
0:             process(data, location);
0:         	long end = System.currentTimeMillis();
0:         	if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:         		LOG.info("Slow KahaDB access: Journal append took: "+(start2-start)+" ms, Index update took "+(end-start2)+" ms");
0:         	}
0:     
0:             synchronized (indexMutex) {
0:             	metadata.lastUpdate = location;
0:             }
0:             if (!checkpointThread.isAlive()) {
0:                 LOG.info("KahaDB: Recovering checkpoint thread after exception");
0:                 startCheckpoint();
0:             }
0:             return location;
0:     	} catch (IOException ioe) {
0:             LOG.error("KahaDB failed to store to Journal", ioe);
0:             brokerService.handleIOException(ioe);
0:     	    throw ioe;
commit:e8a641c
/////////////////////////////////////////////////////////////////////////
0: 	                    LOG.error("Checkpoint failed", ioe);
0: 	                    brokerService.handleIOException(ioe);
/////////////////////////////////////////////////////////////////////////
commit:b1a9130
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.broker.BrokerService;
1: import org.apache.activemq.broker.BrokerServiceAware;
/////////////////////////////////////////////////////////////////////////
0: import org.springframework.core.enums.LetterCodedLabeledEnum;
0: public class MessageDatabase implements BrokerServiceAware {
0: 	
0: 	private BrokerService brokerService;
/////////////////////////////////////////////////////////////////////////
0: 	                } catch (IOException ioe) {
0: 	                	LOG.error("Checkpoint failed", ioe);
0: 	                	stopBroker();
/////////////////////////////////////////////////////////////////////////
1:     protected void checkpointCleanup(final boolean cleanup) throws IOException {
0:     	long start = System.currentTimeMillis();
0:         synchronized (indexMutex) {
0:         	if( !opened.get() ) {
0:         		return;
0:             pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                 public void execute(Transaction tx) throws IOException {
0:                     checkpointUpdate(tx, cleanup);
0:                 }
0:             });
0:     	long end = System.currentTimeMillis();
0:     	if( LOG_SLOW_ACCESS_TIME>0 && end-start > LOG_SLOW_ACCESS_TIME) {
0:     		LOG.info("Slow KahaDB access: cleanup took "+(end-start));
0:     	}
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 
0: 	public void setBrokerService(BrokerService brokerService) {
0: 		this.brokerService = brokerService;
0: 	}
0: 	
0:     protected void stopBroker() {
0:         new Thread() {
0:            public void run() {
0:         	   try {
0:     	            brokerService.stop();
0:     	        } catch (Exception e) {
0:     	            LOG.warn("Failure occured while stopping broker", e);
0:     	        }    			
0:     		}
0:     	}.start();
0:     }
commit:df8ae38
/////////////////////////////////////////////////////////////////////////
0:     protected boolean enableJournalDiskSyncs=true;
commit:f89bf47
/////////////////////////////////////////////////////////////////////////
0:     protected boolean enableJournalDiskSyncs=false;
author:Robert Davies
-------------------------------------------------------------------------------
commit:fb915c3
/////////////////////////////////////////////////////////////////////////
0:                 if (count != null){
0:                     if (references > 0) {
0:                         sd.messageReferences.put(messageSequence, Long.valueOf(references));
0:                         return;
0:                     } else {
0:                         sd.messageReferences.remove(messageSequence);
0:                     }
commit:7da61d9
/////////////////////////////////////////////////////////////////////////
0: import java.io.ByteArrayInputStream;
0: import java.io.ByteArrayOutputStream;
0: import java.io.*;
0: import java.util.*;
0: import java.util.Map.Entry;
0: import java.util.concurrent.atomic.AtomicBoolean;
0: import java.util.concurrent.atomic.AtomicLong;
0: import java.util.concurrent.locks.ReentrantReadWriteLock;
0: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     private boolean useIndexLFRUEviction = false;
1:     private float indexLFUEvictionFactor = 0.2f;
/////////////////////////////////////////////////////////////////////////
1:         index.setUseLFRUEviction(isUseIndexLFRUEviction());
1:         index.setLFUEvictionFactor(getIndexLFUEvictionFactor());
/////////////////////////////////////////////////////////////////////////
1:     public float getIndexLFUEvictionFactor() {
1:         return indexLFUEvictionFactor;
0:     }
0: 
1:     public void setIndexLFUEvictionFactor(float indexLFUEvictionFactor) {
1:         this.indexLFUEvictionFactor = indexLFUEvictionFactor;
0:     }
0: 
1:     public boolean isUseIndexLFRUEviction() {
1:         return useIndexLFRUEviction;
0:     }
0: 
1:     public void setUseIndexLFRUEviction(boolean useIndexLFRUEviction) {
1:         this.useIndexLFRUEviction = useIndexLFRUEviction;
0:     }
0: 
commit:8e61f51
/////////////////////////////////////////////////////////////////////////
0: import java.io.*;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.command.ActiveMQDestination;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.store.kahadb.data.*;
/////////////////////////////////////////////////////////////////////////
0: import org.apache.kahadb.util.*;
0: import org.slf4j.Logger;
0: import org.slf4j.LoggerFactory;
/////////////////////////////////////////////////////////////////////////
0: 
0: 
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:                 version = is.readInt();
0:             } catch (EOFException expectedOnUpgrade) {
0:                 version = 1;
/////////////////////////////////////////////////////////////////////////
0:     protected JournalManager journalManager;
/////////////////////////////////////////////////////////////////////////
0:     protected boolean enableJournalDiskSyncs = true;
0:     long checkpointInterval = 5 * 1000;
0:     long cleanupInterval = 30 * 1000;
/////////////////////////////////////////////////////////////////////////
0:     private boolean journalPerDestination = false;
0: 
/////////////////////////////////////////////////////////////////////////
0:                     for (Iterator<Entry<String, StoredDestination>> iterator = metadata.destinations.iterator(tx); iterator.hasNext(); ) {
0:                         StoredDestination sd = loadStoredDestination(tx, entry.getKey(), entry.getValue().subscriptions != null);
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:                                 if (now - lastCleanup >= cleanupInterval) {
0:                                 } else if (now - lastCheckpoint >= checkpointInterval) {
/////////////////////////////////////////////////////////////////////////
0:         if (opened.compareAndSet(false, true)) {
0:             getJournalManager().start();
/////////////////////////////////////////////////////////////////////////
0:                 getJournalManager().start();
0:                 getJournalManager().delete();
0:                 getJournalManager().close();
0:                 journalManager = null;
0:             for (Journal journal : getJournalManager().getJournals()) {
0:                 store(journal, new KahaTraceCommand().setMessage("LOADED " + new Date()));
0:             }
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:         if (opened.compareAndSet(true, false)) {
0:                         for (Journal journal : getJournalManager().getJournals()) {
0:                             checkpointUpdate(tx, journal, true);
0:                         }
0:             } finally {
0:             journalManager.close();
0:             lockFile = null;
0:             if (pageFile != null && pageFile.isLoaded()) {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:                 if (l == null || t.compareTo(l) <= 0) {
/////////////////////////////////////////////////////////////////////////
0:             for (Journal journal : getJournalManager().getJournals()) {
0:                 recover(journal);
0:         } finally {
0:     private void recover(final Journal journal) throws IllegalStateException, IOException {
0: 
0:         long start = System.currentTimeMillis();
0:         Location producerAuditPosition = recoverProducerAudit(journal);
0:         Location lastIndoubtPosition = getRecoveryPosition(journal);
0: 
0:         Location recoveryPosition = minimum(producerAuditPosition, lastIndoubtPosition);
0: 
0:         if (recoveryPosition != null) {
0:             int redoCounter = 0;
0:             LOG.info("Recovering from the journal ...");
0:             while (recoveryPosition != null) {
0:                 JournalCommand<?> message = load(journal, recoveryPosition);
0:                 metadata.lastUpdate = recoveryPosition;
0:                 process(message, recoveryPosition, lastIndoubtPosition);
0:                 redoCounter++;
0:                 recoveryPosition = journal.getNextLocation(recoveryPosition);
0:             }
0:             long end = System.currentTimeMillis();
0:             LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
0:         }
0: 
0:         // We may have to undo some index updates.
0:         pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:             public void execute(Transaction tx) throws IOException {
0:                 recoverIndex(tx, journal);
0:             }
0:         });
0: 
0:         // rollback any recovered inflight local transactions
0:         Set<TransactionId> toRollback = new HashSet<TransactionId>();
0:         synchronized (inflightTransactions) {
0:             for (Iterator<TransactionId> it = inflightTransactions.keySet().iterator(); it.hasNext(); ) {
0:                 TransactionId id = it.next();
0:                 if (id.isLocalTransaction()) {
0:                     toRollback.add(id);
0:                 }
0:             }
0:             for (TransactionId tx : toRollback) {
0:                 LOG.debug("rolling back recovered indoubt local transaction " + tx);
0:                 store(journal, new KahaRollbackCommand().setTransactionInfo(createTransactionInfo(tx)), false, null, null);
0:             }
0:         }
0:     }
0: 
0:                              Location lastIndoubtPosition) {
/////////////////////////////////////////////////////////////////////////
0:     private Location recoverProducerAudit(Journal journal) throws IOException {
0:             KahaProducerAuditCommand audit = (KahaProducerAuditCommand) load(journal, metadata.producerSequenceIdTrackerLocation);
/////////////////////////////////////////////////////////////////////////
0:     protected void recoverIndex(Transaction tx, Journal journal) throws IOException {
0:         long undoCounter = 0;
/////////////////////////////////////////////////////////////////////////
0:         if (undoCounter > 0) {
/////////////////////////////////////////////////////////////////////////
0:                 int last = -1;
0:                     if (first == null) {
0:                     } else if (second == null) {
/////////////////////////////////////////////////////////////////////////
0:                         if (last != fileId) {
/////////////////////////////////////////////////////////////////////////
0:         while (!ss.isEmpty()) {
0:             missingJournalFiles.add((int) ss.removeFirst());
0:         missingJournalFiles.removeAll(journal.getFileMap().keySet());
0:         if (!missingJournalFiles.isEmpty()) {
0:             LOG.info("Some journal files are missing: " + missingJournalFiles);
0:             missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(missing, 0), new Location(missing + 1, 0)));
0:         if (checkForCorruptJournalFiles) {
0:                 missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, dataFile.getLength()), new Location(id + 1, 0)));
0:                 while (seq != null) {
0:                     missingPredicates.add(new BTreeVisitor.BetweenVisitor<Location, Long>(new Location(id, (int) seq.getFirst()), new Location(id, (int) seq.getLast() + 1)));
0:         if (!missingPredicates.isEmpty()) {
/////////////////////////////////////////////////////////////////////////
0:                 if (!matches.isEmpty()) {
0:                     if (ignoreMissingJournalfiles) {
/////////////////////////////////////////////////////////////////////////
0:                         throw new IOException("Detected missing/corrupt journal files. " + matches.size() + " messages affected.");
0:         if (undoCounter > 0) {
/////////////////////////////////////////////////////////////////////////
0:     public void incrementalRecover(Journal journal) throws IOException {
0:             if (nextRecoveryPosition == null) {
0:                 if (lastRecoveryPosition == null) {
0:                     nextRecoveryPosition = getRecoveryPosition(journal);
/////////////////////////////////////////////////////////////////////////
0:                 JournalCommand<?> message = load(journal, lastRecoveryPosition);
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:     private Location getRecoveryPosition(Journal journal) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:             if (metadata.lastUpdate != null) {
/////////////////////////////////////////////////////////////////////////
0:         for (Journal journal : getJournalManager().getJournals()) {
0:             checkpointCleanup(journal, cleanup);
0:         }
0:     }
0: 
0:     protected void checkpointCleanup(final Journal journal, final boolean cleanup) throws IOException {
0:             if (!opened.get()) {
0:                     checkpointUpdate(tx, journal, cleanup);
0:         } finally {
0:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
0:             LOG.info("Slow KahaDB access: cleanup took " + (end - start));
0:     public void checkpoint(final Journal journal, Callback closure) throws Exception {
0:                     checkpointUpdate(tx, journal, false);
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:     public Location store(Journal journal, JournalCommand<?> data) throws IOException {
0:         return store(journal, data, false, null, null);
0: 
0:     public Location store(final Journal journal, JournalCommand<?> data, boolean sync, Runnable before, Runnable after) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:             if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
0:                 LOG.info("Slow KahaDB access: Journal append took: " + (start2 - start) + " ms, Index update took " + (end - start2) + " ms");
0:             } finally {
/////////////////////////////////////////////////////////////////////////
0:     public JournalCommand<?> load(Journal journal, Location location) throws IOException {
0:         if (LOG_SLOW_ACCESS_TIME > 0 && end - start > LOG_SLOW_ACCESS_TIME) {
0:             LOG.info("Slow KahaDB access: Journal read took: " + (end - start) + " ms");
0:         if (type == null) {
0:             throw new IOException("Could not load journal record. Invalid location: " + location);
0:         JournalCommand<?> message = (JournalCommand<?>) type.createMessage();
/////////////////////////////////////////////////////////////////////////
0:             } finally {
/////////////////////////////////////////////////////////////////////////
0:             List<Operation> inflightTx = getInflightTx(command.getTransactionInfo(), location);
0:             inflightTx.add(new RemoveOpperation(command, location));
/////////////////////////////////////////////////////////////////////////
0:             } finally {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0:         } finally {
/////////////////////////////////////////////////////////////////////////
0: 
/////////////////////////////////////////////////////////////////////////
0:             long ackLocation = NOT_ACKED;
0:                 ackLocation = sd.orderIndex.nextMessageId - 1;
/////////////////////////////////////////////////////////////////////////
0:     void checkpointUpdate(Transaction tx, Journal journal, boolean cleanup) throws IOException {
0:         metadata.producerSequenceIdTrackerLocation = checkpointProducerAudit(journal);
0:         if (cleanup) {
/////////////////////////////////////////////////////////////////////////
0:             if (journalFilesBeingReplicated != null) {
0:             if (metadata.firstInProgressTransactionLocation != null) {
0:                     firstTxLocation = metadata.firstInProgressTransactionLocation;
0:                 }
0:                 ;
0:             if (firstTxLocation != null) {
0:                 while (!gcCandidateSet.isEmpty()) {
0:                     if (last >= firstTxLocation.getDataFileId()) {
/////////////////////////////////////////////////////////////////////////
0:                 if (gcCandidateSet.isEmpty()) {
0:                     int last = -1;
0: 
0:                         if (first == null) {
0:                             SortedSet<Integer> subset = gcCandidateSet.headSet(second.getDataFileId() + 1);
0:                             if (!subset.isEmpty() && subset.last() == second.getDataFileId()) {
0:                         } else if (second == null) {
0:                             if (!subset.isEmpty() && subset.first() == first.getDataFileId()) {
0:                             SortedSet<Integer> subset = gcCandidateSet.subSet(first.getDataFileId(), second.getDataFileId() + 1);
0:                             if (!subset.isEmpty() && subset.first() == first.getDataFileId()) {
0:                             if (!subset.isEmpty() && subset.last() == second.getDataFileId()) {
/////////////////////////////////////////////////////////////////////////
0:                             if (last != fileId) {
/////////////////////////////////////////////////////////////////////////
0:             if (!gcCandidateSet.isEmpty()) {
0:                 LOG.debug("Cleanup removing the data files: " + gcCandidateSet);
/////////////////////////////////////////////////////////////////////////
0:     private Location checkpointProducerAudit(Journal journal) throws IOException {
0:         return store(journal, new KahaProducerAuditCommand().setAudit(new Buffer(baos.toByteArray())), true, null, null);
/////////////////////////////////////////////////////////////////////////
0:             this.messageId = messageId;
0:             this.location = location;
0:             return "[" + messageId + "," + location + "]";
/////////////////////////////////////////////////////////////////////////
0:                 // upgrade
0:                 pageFile.tx().execute(new Transaction.Closure<IOException>() {
0:                     public void execute(Transaction tx) throws IOException {
0:                         value.orderIndex.lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                         value.orderIndex.lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                         value.orderIndex.lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                         value.orderIndex.lowPriorityIndex.load(tx);
0:                         value.orderIndex.highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                         value.orderIndex.highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                         value.orderIndex.highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                         value.orderIndex.highPriorityIndex.load(tx);
0:                     }
0:                 });
/////////////////////////////////////////////////////////////////////////
0:             rc.mergeFramed((InputStream) dataIn);
0:             object.writeFramed((OutputStream) dataOut);
/////////////////////////////////////////////////////////////////////////
0:                                  rc.orderIndex.iterator(tx, new MessageOrderCursor(entry.getValue().lastAckedSequence)); orderIterator.hasNext(); ) {
/////////////////////////////////////////////////////////////////////////
0:                     for (Iterator<Entry<String, LastAck>> iterator = rc.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
0:                                 Math.max(rc.orderIndex.nextMessageId, entry.getValue().lastAckedSequence + 1);
0:                     Entry<Long, HashSet<String>> last = rc.ackPositions.getLast(tx);
0:                             Math.max(rc.orderIndex.nextMessageId, last.getKey());
/////////////////////////////////////////////////////////////////////////
0: 
0:         for (Iterator<Entry<String, LastAck>> iterator = sd.subscriptionAcks.iterator(tx); iterator.hasNext(); ) {
0:         sd.ackPositions.put(tx, messageSequence + 1, nextMessageIdMarker);
/////////////////////////////////////////////////////////////////////////
0:     private JournalManager createJournalManager() throws IOException {
0:         JournalManager manager = isJournalPerDestination() ? new DestinationJournalManager() : new DefaultJournalManager();
0:         manager.setStoreSize(storeSize);
/////////////////////////////////////////////////////////////////////////
0:     public JournalManager getJournalManager() throws IOException {
0:         if (journalManager == null) {
0:             journalManager = createJournalManager();
0:         return journalManager;
0:     }
0: 
0:     public Journal getJournal(ActiveMQDestination destination) throws IOException {
0:         return getJournalManager().getJournal(destination);
/////////////////////////////////////////////////////////////////////////
0:     public boolean isJournalPerDestination() {
0:         return journalPerDestination;
0:     }
0: 
0:     public void setJournalPerDestination(boolean journalPerDestination) {
0:         this.journalPerDestination = journalPerDestination;
0:     }
0: 
/////////////////////////////////////////////////////////////////////////
0:     class MessageOrderCursor {
0: 
0:         MessageOrderCursor() {
0:         MessageOrderCursor(long position) {
0:             this.defaultCursorPosition = position;
0:             this.lowPriorityCursorPosition = position;
0:             this.highPriorityCursorPosition = position;
0:         MessageOrderCursor(MessageOrderCursor other) {
0:             this.defaultCursorPosition = other.defaultCursorPosition;
0:             this.lowPriorityCursorPosition = other.lowPriorityCursorPosition;
0:             this.highPriorityCursorPosition = other.highPriorityCursorPosition;
/////////////////////////////////////////////////////////////////////////
0:             this.defaultCursorPosition = 0;
0:             this.highPriorityCursorPosition = 0;
0:             this.lowPriorityCursorPosition = 0;
0:             if (defaultCursorPosition != 0) {
0:             if (highPriorityCursorPosition != 0) {
0:             if (lowPriorityCursorPosition != 0) {
0:             return "MessageOrderCursor:[def:" + defaultCursorPosition
0:                     + ", low:" + lowPriorityCursorPosition
0:                     + ", high:" + highPriorityCursorPosition + "]";
0:             this.defaultCursorPosition = other.defaultCursorPosition;
0:             this.lowPriorityCursorPosition = other.lowPriorityCursorPosition;
0:             this.highPriorityCursorPosition = other.highPriorityCursorPosition;
/////////////////////////////////////////////////////////////////////////
0:             if (result == null && highPriorityIndex != null) {
0:                 if (result == null && lowPriorityIndex != null) {
/////////////////////////////////////////////////////////////////////////
0:             if (lastDefaultKey != null) {
0:                 cursor.defaultCursorPosition = lastDefaultKey.longValue() + 1;
0:             if (lastHighKey != null) {
0:                 cursor.highPriorityCursorPosition = lastHighKey.longValue() + 1;
0:             if (lastLowKey != null) {
0:                 cursor.lowPriorityCursorPosition = lastLowKey.longValue() + 1;
/////////////////////////////////////////////////////////////////////////
0:                            BTreeIndex<Long, MessageKeys> index, Long sequenceId) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx) throws IOException {
0:             return new MessageOrderIterator(tx, cursor);
0:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx, MessageOrderCursor m) throws IOException {
0:             return new MessageOrderIterator(tx, m);
0:         class MessageOrderIterator implements Iterator<Entry<Long, MessageKeys>> {
0:             Iterator<Entry<Long, MessageKeys>> currentIterator;
0:             final Iterator<Entry<Long, MessageKeys>> highIterator;
0:             final Iterator<Entry<Long, MessageKeys>> defaultIterator;
0:             final Iterator<Entry<Long, MessageKeys>> lowIterator;
commit:cba0468
/////////////////////////////////////////////////////////////////////////
0:     static final int VERSION = 2;
/////////////////////////////////////////////////////////////////////////
1:         protected int version = VERSION;
/////////////////////////////////////////////////////////////////////////
0:             try {
0:                version = is.readInt();
0:             }catch (EOFException expectedOnUpgrade) {
0:                 version=1;
0:             }
1:             LOG.info("KahaDB is version " + version);
/////////////////////////////////////////////////////////////////////////
0:             if (version > 1) {
0:                os.writeInt(version);
0:             }
/////////////////////////////////////////////////////////////////////////
1:         int priority = command.getPrioritySupported() ? command.getPriority() : javax.jms.Message.DEFAULT_PRIORITY;
0:         long id = sd.orderIndex.getNextMessageId(priority);
1:         if (previous == null) {
1:             if (previous == null) {
1:                 sd.orderIndex.put(tx, priority, id, new MessageKeys(command.getMessageId(), location));
0:                 // If the message ID as indexed, then the broker asked us to
0:                 // store a DUP
0:                 // message. Bad BOY! Don't do it, and log a warning.
0:                 LOG.warn("Duplicate message add attempt rejected. Message id: " + command.getMessageId());
0:             // restore the previous value.. Looks like this was a redo of a
0:             // previously
0:             // added message. We don't want to assign it a new id as the other
0:             // indexes would
/////////////////////////////////////////////////////////////////////////
1:         sd.orderIndex.remove(tx);
/////////////////////////////////////////////////////////////////////////
0:                 ackLocation = sd.orderIndex.nextMessageId-1;
/////////////////////////////////////////////////////////////////////////
0:  
1:     class StoredDestination {
0:         
1:         MessageOrderIndex orderIndex = new MessageOrderIndex();
1:         HashMap<String, MessageOrderCursor> subscriptionCursors;
/////////////////////////////////////////////////////////////////////////
0:             value.orderIndex.defaultPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, dataIn.readLong());
/////////////////////////////////////////////////////////////////////////
1:             if (metadata.version >= 2) {
0:                 value.orderIndex.lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, dataIn.readLong());
0:                 value.orderIndex.highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, dataIn.readLong());
0:             }
1:             dataOut.writeLong(value.orderIndex.defaultPriorityIndex.getPageId());
/////////////////////////////////////////////////////////////////////////
1:             if (metadata.version >= 2) {
0:                 dataOut.writeLong(value.orderIndex.lowPriorityIndex.getPageId());
0:                 dataOut.writeLong(value.orderIndex.highPriorityIndex.getPageId());
0:             }
/////////////////////////////////////////////////////////////////////////
1:             rc.orderIndex.allocate(tx);
/////////////////////////////////////////////////////////////////////////
1:         rc.orderIndex.configureLast(tx);
/////////////////////////////////////////////////////////////////////////
0:             rc.subscriptionCursors = new HashMap<String, MessageOrderCursor>();
1:             if (rc.orderIndex.nextMessageId == 0) {
0:                         rc.orderIndex.nextMessageId = lastAckedMessageId+1;
/////////////////////////////////////////////////////////////////////////
0:                         sd.orderIndex.getDeleteList(tx, deletes, sequenceId);
/////////////////////////////////////////////////////////////////////////
0:     
0:     
0:     class MessageOrderCursor{
1:         long defaultCursorPosition;
1:         long lowPriorityCursorPosition;
1:         long highPriorityCursorPosition;
0:         MessageOrderCursor(){
0:         }
0:         
0:         MessageOrderCursor(long position){
0:             this.defaultCursorPosition=position;
0:             this.lowPriorityCursorPosition=position;
0:             this.highPriorityCursorPosition=position;
0:         }
0:         
0:         MessageOrderCursor(MessageOrderCursor other){
0:             this.defaultCursorPosition=other.defaultCursorPosition;
0:             this.lowPriorityCursorPosition=other.lowPriorityCursorPosition;
0:             this.highPriorityCursorPosition=other.highPriorityCursorPosition;
0:         }
0:         
1:         MessageOrderCursor copy() {
1:             return new MessageOrderCursor(this);
0:         }
0:         
1:         void reset() {
0:             this.defaultCursorPosition=0;
0:             this.highPriorityCursorPosition=0;
0:             this.lowPriorityCursorPosition=0;
0:         }
0:         
1:         void increment() {
0:             if (defaultCursorPosition!=0) {
1:                 defaultCursorPosition++;
0:             }
0:             if (highPriorityCursorPosition!=0) {
1:                 highPriorityCursorPosition++;
0:             }
0:             if (lowPriorityCursorPosition!=0) {
1:                 lowPriorityCursorPosition++;
0:             }
0:         }
0:     }
0:     
0:     class MessageOrderIndex{
0:         long nextMessageId;
1:         BTreeIndex<Long, MessageKeys> defaultPriorityIndex;
1:         BTreeIndex<Long, MessageKeys> lowPriorityIndex;
1:         BTreeIndex<Long, MessageKeys> highPriorityIndex;
0:         MessageOrderCursor cursor = new MessageOrderCursor();
1:         Long lastDefaultKey;
1:         Long lastHighKey;
1:         Long lastLowKey;
0:         
0:         
1:         MessageKeys remove(Transaction tx, Long key) throws IOException {
1:             MessageKeys result = defaultPriorityIndex.remove(tx, key);
0:             if (result == null && highPriorityIndex!=null) {
1:                 result = highPriorityIndex.remove(tx, key);
0:                 if (result ==null && lowPriorityIndex!=null) {
1:                     result = lowPriorityIndex.remove(tx, key);
0:                 }
0:             }
1:             return result;
0:         }
0:         
1:         void load(Transaction tx) throws IOException {
1:             defaultPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:             defaultPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
1:             defaultPriorityIndex.load(tx);
0:             if (metadata.version >= 2) {
0:                 lowPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                 lowPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                 lowPriorityIndex.load(tx);
0: 
0:                 highPriorityIndex.setKeyMarshaller(LongMarshaller.INSTANCE);
0:                 highPriorityIndex.setValueMarshaller(MessageKeysMarshaller.INSTANCE);
0:                 highPriorityIndex.load(tx);
0:             }
0:         }
0:         
1:         void allocate(Transaction tx) throws IOException {
0:             defaultPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:             if (metadata.version >= 2) {
0:                 lowPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:                 highPriorityIndex = new BTreeIndex<Long, MessageKeys>(pageFile, tx.allocate());
0:             }
0:         }
0:         
1:         void configureLast(Transaction tx) throws IOException {
1:             // Figure out the next key using the last entry in the destination.
1:             if (highPriorityIndex != null) {
0:                 Entry<Long, MessageKeys> lastEntry = highPriorityIndex.getLast(tx);
1:                 if (lastEntry != null) {
0:                     nextMessageId = lastEntry.getKey() + 1;
0:                 } else {
0:                     lastEntry = defaultPriorityIndex.getLast(tx);
1:                     if (lastEntry != null) {
0:                         nextMessageId = lastEntry.getKey() + 1;
0:                     } else {
0:                         lastEntry = lowPriorityIndex.getLast(tx);
1:                         if (lastEntry != null) {
0:                             nextMessageId = lastEntry.getKey() + 1;
0:                         }
0:                     }
0:                 }
0:             } else {
0:                 Entry<Long, MessageKeys> lastEntry = defaultPriorityIndex.getLast(tx);
1:                 if (lastEntry != null) {
0:                     nextMessageId = lastEntry.getKey() + 1;
0:                 }
0:             }
0:         }
0:         
0:                
1:         void remove(Transaction tx) throws IOException {
1:             defaultPriorityIndex.clear(tx);
1:             defaultPriorityIndex.unload(tx);
1:             tx.free(defaultPriorityIndex.getPageId());
1:             if (lowPriorityIndex != null) {
1:                 lowPriorityIndex.clear(tx);
1:                 lowPriorityIndex.unload(tx);
0: 
1:                 tx.free(lowPriorityIndex.getPageId());
0:             }
1:             if (highPriorityIndex != null) {
1:                 highPriorityIndex.clear(tx);
1:                 highPriorityIndex.unload(tx);
1:                 tx.free(highPriorityIndex.getPageId());
0:             }
0:         }
0:         
1:         void resetCursorPosition() {
1:             this.cursor.reset();
1:             lastDefaultKey = null;
1:             lastHighKey = null;
1:             lastLowKey = null;
0:         }
0:         
1:         void setBatch(Transaction tx, Long sequence) throws IOException {
1:             if (sequence != null) {
1:                 Long nextPosition = new Long(sequence.longValue() + 1);
0:                 if (defaultPriorityIndex.containsKey(tx, sequence)) {
0:                     lastDefaultKey = nextPosition;
0:                     cursor.defaultCursorPosition = nextPosition.longValue();
0:                 } else if (highPriorityIndex != null) {
0:                     if (highPriorityIndex.containsKey(tx, sequence)) {
0:                         lastHighKey = nextPosition;
0:                         cursor.highPriorityCursorPosition = nextPosition.longValue();
0:                     } else if (lowPriorityIndex.containsKey(tx, sequence)) {
0:                         lastLowKey = nextPosition;
0:                         cursor.lowPriorityCursorPosition = nextPosition.longValue();
0:                     }
0:                 } else {
0:                     lastDefaultKey = nextPosition;
0:                     cursor.defaultCursorPosition = nextPosition.longValue();
0:                 }
0:             }
0:         }
0:         
1:         void stoppedIterating() {
0:             if (lastDefaultKey!=null) {
0:                 cursor.defaultCursorPosition=lastDefaultKey.longValue()+1;
0:             }
0:             if (lastHighKey!=null) {
0:                 cursor.highPriorityCursorPosition=lastHighKey.longValue()+1;
0:             }
0:             if (lastLowKey!=null) {
0:                 cursor.lowPriorityCursorPosition=lastLowKey.longValue()+1;
0:             }
1:             lastDefaultKey = null;
1:             lastHighKey = null;
1:             lastLowKey = null;
0:         }
0:         
1:         void getDeleteList(Transaction tx, ArrayList<Entry<Long, MessageKeys>> deletes, Long sequenceId)
1:                 throws IOException {
0:             getDeleteList(tx, deletes, defaultPriorityIndex, sequenceId);
1:             if (highPriorityIndex != null) {
1:                 getDeleteList(tx, deletes, highPriorityIndex, sequenceId);
0:             }
1:             if (lowPriorityIndex != null) {
1:                 getDeleteList(tx, deletes, lowPriorityIndex, sequenceId);
0:             }
0:         }
0:         
1:         void getDeleteList(Transaction tx, ArrayList<Entry<Long, MessageKeys>> deletes,
0:                 BTreeIndex<Long, MessageKeys> index, Long sequenceId) throws IOException {
0:             for (Iterator<Entry<Long, MessageKeys>> iterator = index.iterator(tx); iterator.hasNext();) {
0:                 Entry<Long, MessageKeys> entry = iterator.next();
0:                 if (entry.getKey().compareTo(sequenceId) <= 0) {
0:                     // We don't do the actually delete while we are
0:                     // iterating the BTree since
0:                     // iterating would fail.
0:                     deletes.add(entry);
0:                 } else {
0:                     // no point in iterating the in-order sequences anymore
0:                     break;
0:                 }
0:             }
0:         } 
0:         
0:         long getNextMessageId(int priority) {
1:             return nextMessageId++;
0:         }
0:         
1:         MessageKeys get(Transaction tx, Long key) throws IOException {
1:             MessageKeys result = defaultPriorityIndex.get(tx, key);
1:             if (result == null) {
1:                 result = highPriorityIndex.get(tx, key);
1:                 if (result == null) {
1:                     result = lowPriorityIndex.get(tx, key);
0:                 }
0:             }
1:             return result;
0:         }
0:         
1:         MessageKeys put(Transaction tx, int priority, Long key, MessageKeys value) throws IOException {
1:             if (priority == javax.jms.Message.DEFAULT_PRIORITY) {
1:                 return defaultPriorityIndex.put(tx, key, value);
1:             } else if (priority > javax.jms.Message.DEFAULT_PRIORITY) {
1:                 return highPriorityIndex.put(tx, key, value);
0:             } else {
1:                 return lowPriorityIndex.put(tx, key, value);
0:             }
0:         }
0:         
0:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx) throws IOException{
0:             return new MessageOrderIterator(tx,cursor);
0:         }
0:         
0:         Iterator<Entry<Long, MessageKeys>> iterator(Transaction tx, MessageOrderCursor m) throws IOException{
0:             return new MessageOrderIterator(tx,m);
0:         }
0:         
0:         class MessageOrderIterator implements Iterator<Entry<Long, MessageKeys>>{
0:             Iterator<Entry<Long, MessageKeys>>currentIterator;
0:             final Iterator<Entry<Long, MessageKeys>>highIterator;
0:             final Iterator<Entry<Long, MessageKeys>>defaultIterator;
0:             final Iterator<Entry<Long, MessageKeys>>lowIterator;
0:             Long lastKey;
0:             
0:             
0: 
0:             MessageOrderIterator(Transaction tx, MessageOrderCursor m) throws IOException {
0:                 this.defaultIterator = defaultPriorityIndex.iterator(tx, m.defaultCursorPosition);
1:                 if (highPriorityIndex != null) {
0:                     this.highIterator = highPriorityIndex.iterator(tx, m.highPriorityCursorPosition);
0:                 } else {
1:                     this.highIterator = null;
0:                 }
1:                 if (lowPriorityIndex != null) {
0:                     this.lowIterator = lowPriorityIndex.iterator(tx, m.lowPriorityCursorPosition);
0:                 } else {
1:                     this.lowIterator = null;
0:                 }
0:             }
0:             
1:             public boolean hasNext() {
1:                 if (currentIterator == null) {
1:                     if (highIterator != null) {
1:                         if (highIterator.hasNext()) {
1:                             currentIterator = highIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         if (defaultIterator.hasNext()) {
1:                             currentIterator = defaultIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         if (lowIterator.hasNext()) {
1:                             currentIterator = lowIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         return false;
0:                     } else {
1:                         currentIterator = defaultIterator;
1:                         return currentIterator.hasNext();
0:                     }
0:                 }
1:                 if (highIterator != null) {
1:                     if (currentIterator.hasNext()) {
0:                         return true;
0:                     }
1:                     if (currentIterator == highIterator) {
1:                         if (defaultIterator.hasNext()) {
1:                             currentIterator = defaultIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         if (lowIterator.hasNext()) {
1:                             currentIterator = lowIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         return false;
0:                     }
1:                     if (currentIterator == defaultIterator) {
1:                         if (lowIterator.hasNext()) {
1:                             currentIterator = lowIterator;
1:                             return currentIterator.hasNext();
0:                         }
1:                         return false;
0:                     }
0:                 }
1:                 return currentIterator.hasNext();
0:             }
0: 
1:             public Entry<Long, MessageKeys> next() {
1:                 Entry<Long, MessageKeys> result = currentIterator.next();
1:                 if (result != null) {
1:                     Long key = result.getKey();
1:                     if (highIterator != null) {
1:                         if (currentIterator == defaultIterator) {
1:                             lastDefaultKey = key;
1:                         } else if (currentIterator == highIterator) {
1:                             lastHighKey = key;
0:                         } else {
1:                             lastLowKey = key;
0:                         }
0:                     } else {
1:                         lastDefaultKey = key;
0:                     }
0:                 }
1:                 return result;
0:             }
0: 
1:             public void remove() {
1:                 throw new UnsupportedOperationException();
0:             }
0:            
0:         }
0:     }
0:     
0:     
0:     
commit:5f400b3
/////////////////////////////////////////////////////////////////////////
0:                     recordAckMessageReferenceLocation(ackLocation, keys.location);
0:                 }                
commit:b47da80
/////////////////////////////////////////////////////////////////////////
0: import java.util.concurrent.locks.Lock;
0: import java.util.concurrent.locks.ReentrantLock;
0: import java.util.concurrent.locks.ReentrantReadWriteLock;
/////////////////////////////////////////////////////////////////////////
0: 	    this.indexLock.writeLock().lock();
0: 	    try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
1:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:         this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
1:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0: 		    this.indexLock.writeLock().lock();
0: 	        try {
/////////////////////////////////////////////////////////////////////////
0: 	        }finally {
1: 	            this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:         this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
1:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:         this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
1:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0: 	    this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
0:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:     	this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
0:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0: 	    this.indexLock.writeLock().lock();
0:         try {
0:         }finally {
0:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:         	this.indexLock.writeLock().lock();
0:             try {
0:             }finally {
0:                 this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:             this.indexLock.writeLock().lock();
0:             try {
0:             }finally {
0:                 this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:             this.indexLock.writeLock().lock();
0:             try {
0:             }finally {
0:                 this.indexLock.writeLock().unlock();
0:         this.indexLock.writeLock().lock();
0:         try {
0:         }finally {
0:             this.indexLock.writeLock().unlock();
0:         this.indexLock.writeLock().lock();
0:         try {
0:         }finally {
0:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
0:         this.indexLock.writeLock().lock();
0:         try {
/////////////////////////////////////////////////////////////////////////
0:         }finally {
0:             this.indexLock.writeLock().unlock();
/////////////////////////////////////////////////////////////////////////
1:     protected final ReentrantReadWriteLock indexLock = new ReentrantReadWriteLock();
commit:caea2f2
/////////////////////////////////////////////////////////////////////////
0:      static final int CLOSED_STATE = 1;
0:      static final int OPEN_STATE = 2;
0:      static final long NOT_ACKED = -1;
/////////////////////////////////////////////////////////////////////////
commit:47181b7
/////////////////////////////////////////////////////////////////////////
0:     private static final int DEFAULT_DATABASE_LOCKED_WAIT_DELAY = 10 * 1000;
/////////////////////////////////////////////////////////////////////////
0:     private int databaseLockedWaitDelay = DEFAULT_DATABASE_LOCKED_WAIT_DELAY;
/////////////////////////////////////////////////////////////////////////
0:                         LOG.info("Database "+lockFileName+" is locked... waiting " + (getDatabaseLockedWaitDelay() / 1000) + " seconds for the database to be unlocked. Reason: " + e);
0:                             Thread.sleep(getDatabaseLockedWaitDelay());
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
0:      * @return the databaseLockedWaitDelay
0:      */
0:     public int getDatabaseLockedWaitDelay() {
0:         return this.databaseLockedWaitDelay;
0:     }
0: 
0:     /**
0:      * @param databaseLockedWaitDelay the databaseLockedWaitDelay to set
0:      */
0:     public void setDatabaseLockedWaitDelay(int databaseLockedWaitDelay) {
0:         this.databaseLockedWaitDelay = databaseLockedWaitDelay;
0:     }
commit:27262c8
/////////////////////////////////////////////////////////////////////////
0:         return store(data, false, null,null);
/////////////////////////////////////////////////////////////////////////
0:     public Location store(JournalCommand data, boolean sync, Runnable before,Runnable after) throws IOException {
0:     	if (before != null) {
0:     	    before.run();
0:     	}
0:         try {
/////////////////////////////////////////////////////////////////////////
0:             if (after != null) {
0:                 after.run();
commit:1a5ad28
/////////////////////////////////////////////////////////////////////////
0: 	protected BrokerService brokerService;
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0: 	        loadPageFile();        
/////////////////////////////////////////////////////////////////////////
0: 	            pageFile.tx().execute(new Transaction.Closure<IOException>() {
0: 	                public void execute(Transaction tx) throws IOException {
0: 	                    checkpointUpdate(tx, true);
0: 	                }
0: 	            });
/////////////////////////////////////////////////////////////////////////
0:             
0: 	        long start = System.currentTimeMillis();        
0: 		        LOG.info("Recoverying from the journal ...");
/////////////////////////////////////////////////////////////////////////
0: 	        	LOG.info("Recovery replayed " + redoCounter + " operations from the journal in " + ((end - start) / 1000.0f) + " seconds.");
/////////////////////////////////////////////////////////////////////////
0:     void process(JournalCommand data, final Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:     protected void process(final KahaAddMessageCommand command, final Location location) throws IOException {
0:                 TransactionId key = key(command.getTransactionInfo());
/////////////////////////////////////////////////////////////////////////
0:     void upadateIndex(Transaction tx, KahaAddMessageCommand command, Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     void updateIndex(Transaction tx, KahaRemoveMessageCommand command, Location ackLocation) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     void updateIndex(Transaction tx, KahaRemoveDestinationCommand command, Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
1:     void updateIndex(Transaction tx, KahaSubscriptionCommand command, Location location) throws IOException {
/////////////////////////////////////////////////////////////////////////
0:     void checkpointUpdate(Transaction tx, boolean cleanup) throws IOException {
commit:ea84378
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.util.ServiceStopper;
0: import org.apache.activemq.util.ServiceSupport;
/////////////////////////////////////////////////////////////////////////
0: public class MessageDatabase extends ServiceSupport implements BrokerServiceAware {
/////////////////////////////////////////////////////////////////////////
1:     private int indexCacheSize = 10000;
/////////////////////////////////////////////////////////////////////////
0:     @Override
1:     public void doStart() throws Exception {
0:         load();
0:     @Override
1:     public void doStop(ServiceStopper stopper) throws Exception {
0:         unload();
commit:baf9301
/////////////////////////////////////////////////////////////////////////
0:                             }else {
0:                                 //no point in iterating the in-order sequences anymore
0:                                 break;
commit:98bb7bf
/////////////////////////////////////////////////////////////////////////
0: import org.apache.activemq.util.IOHelper;
/////////////////////////////////////////////////////////////////////////
1:     protected File directoryArchive;
/////////////////////////////////////////////////////////////////////////
0:     private Journal createJournal() throws IOException {
/////////////////////////////////////////////////////////////////////////
1:         if (getDirectoryArchive() != null) {
1:             IOHelper.mkdirs(getDirectoryArchive());
1:             manager.setDirectoryArchive(getDirectoryArchive());
0:         }
/////////////////////////////////////////////////////////////////////////
0: 	public Journal getJournal() throws IOException {
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
1:      * @return the directoryArchive
0:      */
1:     public File getDirectoryArchive() {
1:         return this.directoryArchive;
0:     }
0: 
0:     /**
1:      * @param directoryArchive the directoryArchive to set
0:      */
1:     public void setDirectoryArchive(File directoryArchive) {
1:         this.directoryArchive = directoryArchive;
0:     }
commit:f8cb847
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
1:     protected boolean archiveDataLogs;
/////////////////////////////////////////////////////////////////////////
0:     
/////////////////////////////////////////////////////////////////////////
0:             @Override
/////////////////////////////////////////////////////////////////////////
0:                     @Override
/////////////////////////////////////////////////////////////////////////
0:         @Override
/////////////////////////////////////////////////////////////////////////
0:         @Override
/////////////////////////////////////////////////////////////////////////
1:         manager.setArchiveDataLogs(isArchiveDataLogs());
/////////////////////////////////////////////////////////////////////////
0: 
0:     /**
1:      * @return the archiveDataLogs
0:      */
1:     public boolean isArchiveDataLogs() {
1:         return this.archiveDataLogs;
0:     }
0: 
0:     /**
1:      * @param archiveDataLogs the archiveDataLogs to set
0:      */
1:     public void setArchiveDataLogs(boolean archiveDataLogs) {
1:         this.archiveDataLogs = archiveDataLogs;
0:     }
============================================================================
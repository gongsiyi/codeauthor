1:c290a17: /**
1:c290a17:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:c290a17:  * contributor license agreements.  See the NOTICE file distributed with
1:c290a17:  * this work for additional information regarding copyright ownership.
1:c290a17:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:c290a17:  * (the "License"); you may not use this file except in compliance with
1:c290a17:  * the License.  You may obtain a copy of the License at
1:c290a17:  *
1:c290a17:  *      http://www.apache.org/licenses/LICENSE-2.0
1:c290a17:  *
1:c290a17:  * Unless required by applicable law or agreed to in writing, software
1:c290a17:  * distributed under the License is distributed on an "AS IS" BASIS,
1:c290a17:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:c290a17:  * See the License for the specific language governing permissions and
1:c290a17:  * limitations under the License.
1:c290a17:  */
1:c290a17: package org.apache.activemq.bugs;
13:c290a17: 
1:4d265fd: import java.io.File;
1:4d265fd: import java.io.FilenameFilter;
1:4d265fd: import java.util.Arrays;
1:c290a17: import java.util.Properties;
1:4d265fd: import java.util.Vector;
1:c290a17: import java.util.concurrent.CountDownLatch;
1:c290a17: import java.util.concurrent.TimeUnit;
1:4d265fd: import java.util.concurrent.atomic.AtomicLong;
1:c290a17: import javax.jms.JMSException;
1:c290a17: import javax.jms.Message;
1:c290a17: import javax.jms.MessageConsumer;
1:c290a17: import javax.jms.MessageListener;
1:c290a17: import javax.jms.MessageProducer;
1:c290a17: import javax.jms.Session;
1:4d265fd: import javax.jms.TopicSubscriber;
1:c290a17: import org.apache.activemq.ActiveMQConnection;
1:c290a17: import org.apache.activemq.ActiveMQConnectionFactory;
1:c290a17: import org.apache.activemq.broker.BrokerService;
1:c290a17: import org.apache.activemq.broker.jmx.BrokerView;
1:c290a17: import org.apache.activemq.broker.region.policy.PolicyEntry;
1:c290a17: import org.apache.activemq.broker.region.policy.PolicyMap;
1:c290a17: import org.apache.activemq.command.ActiveMQQueue;
1:c290a17: import org.apache.activemq.command.ActiveMQTopic;
1:c290a17: import org.apache.activemq.store.PersistenceAdapter;
1:c290a17: import org.apache.activemq.store.kahadb.KahaDBPersistenceAdapter;
1:62bdbb0: import org.apache.activemq.store.kahadb.disk.journal.Journal;
1:c290a17: import org.apache.activemq.util.IntrospectionSupport;
1:8bf987b: import org.slf4j.Logger;
1:8bf987b: import org.slf4j.LoggerFactory;
1:c290a17: 
1:c290a17: // variation on AMQ2584 where the DLQ consumer works in parallel to producer so
1:c290a17: // that some dups are not suppressed as they are already acked by the consumer
1:c290a17: // the audit needs to be disabled to allow these dupes to be consumed
1:c290a17: public class AMQ2584ConcurrentDlqTest extends org.apache.activemq.TestSupport {
1:c290a17: 
1:8bf987b:     static final Logger LOG = LoggerFactory.getLogger(AMQ2584ConcurrentDlqTest.class);
1:c290a17:     BrokerService broker = null;
1:c290a17:     ActiveMQTopic topic;
1:c290a17: 
1:c290a17:     ActiveMQConnection consumerConnection = null, producerConnection = null, dlqConnection = null;
1:4d265fd:     Session consumerSession;
1:c290a17:     Session producerSession;
1:c290a17:     MessageProducer producer;
1:4d265fd:     Vector<TopicSubscriber> duralbeSubs = new Vector<TopicSubscriber>();
1:c290a17:     final int numMessages = 1000;
1:4d265fd:     final int numDurableSubs = 2;
1:c290a17: 
1:c290a17:     String data;
1:4d265fd:     private long dlqConsumerLastReceivedTimeStamp;
1:4d265fd:     private AtomicLong dlqReceivedCount = new AtomicLong(0);
1:4d265fd: 
1:4d265fd:     // 2 deliveries of each message, 3 producers
1:4d265fd:     CountDownLatch redeliveryConsumerLatch = new CountDownLatch(((2 * numMessages) * numDurableSubs) - 1);
1:4d265fd:     // should get at least numMessages, possibly more
1:4d265fd:     CountDownLatch dlqConsumerLatch = new CountDownLatch((numMessages - 1));
1:c290a17: 
1:c290a17:     public void testSize() throws Exception {
1:c290a17:         openConsumer(redeliveryConsumerLatch);
1:c290a17:         openDlqConsumer(dlqConsumerLatch);
1:4d265fd: 
1:c290a17: 
1:c290a17:         assertEquals(0, broker.getAdminView().getStorePercentUsage());
1:c290a17: 
1:c290a17:         for (int i = 0; i < numMessages; i++) {
1:c290a17:             sendMessage(false);
5:c290a17:         }
1:4d265fd: 
1:c290a17:         final BrokerView brokerView = broker.getAdminView();
1:c290a17: 
1:c290a17:         broker.getSystemUsage().getStoreUsage().isFull();
1:4d265fd:         LOG.info("store percent usage: " + brokerView.getStorePercentUsage());
1:4d265fd:         assertTrue("redelivery consumer got all it needs, remaining: "
1:4d265fd:                 + redeliveryConsumerLatch.getCount(), redeliveryConsumerLatch.await(60, TimeUnit.SECONDS));
1:c290a17:         assertTrue("dql  consumer got all it needs", dlqConsumerLatch.await(60, TimeUnit.SECONDS));
1:c290a17:         closeConsumer();
1:c290a17: 
1:c290a17:         LOG.info("Giving dlq a chance to clear down once topic consumer is closed");
1:4d265fd: 
1:4d265fd:         // consumer all of the duplicates that arrived after the first ack
1:4d265fd:         closeDlqConsumer();
1:4d265fd: 
1:c290a17:         //get broker a chance to clean obsolete messages, wait 2*cleanupInterval
1:c290a17:         Thread.sleep(5000);
1:c290a17: 
1:4d265fd:         FilenameFilter justLogFiles = new FilenameFilter() {
1:4d265fd:             public boolean accept(File file, String s) {
1:4d265fd:                 return s.endsWith(".log");
1:4d265fd:             }
1:4d265fd:         };
1:4d265fd:         int numFiles = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getDirectory().list(justLogFiles).length;
1:4d265fd:         if (numFiles > 2) {
1:4d265fd:             LOG.info(Arrays.toString(((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getDirectory().list(justLogFiles)));
1:4d265fd:         }
1:c290a17:         LOG.info("num files: " + numFiles);
1:4d265fd:         assertEquals("kahaDB dir should contain 1 db file,is: " + numFiles, 1, numFiles);
1:4d265fd:     }
1:c290a17: 
1:c290a17:     private void openConsumer(final CountDownLatch latch) throws Exception {
1:c290a17:         consumerConnection = (ActiveMQConnection) createConnection();
1:c290a17:         consumerConnection.setClientID("cliID");
1:c290a17:         consumerConnection.start();
1:4d265fd:         consumerSession = consumerConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:c290a17: 
1:c290a17:         MessageListener listener = new MessageListener() {
2:c290a17:             public void onMessage(Message message) {
1:c290a17:                 latch.countDown();
1:c290a17:                 try {
1:4d265fd:                     consumerSession.recover();
1:c290a17:                 } catch (Exception ignored) {
1:c290a17:                     ignored.printStackTrace();
1:c290a17:                 }
1:c290a17:             }
1:c290a17:         };
1:c290a17: 
1:4d265fd:         for (int i = 1; i <= numDurableSubs; i++) {
1:4d265fd:             TopicSubscriber sub = consumerSession.createDurableSubscriber(topic, "subName" + i);
1:4d265fd:             sub.setMessageListener(listener);
1:4d265fd:             duralbeSubs.add(sub);
1:4d265fd:         }
1:c290a17:     }
1:4d265fd: 
1:4d265fd:     private void openDlqConsumer(final CountDownLatch received) throws Exception {
1:4d265fd: 
1:4d265fd:         dlqConnection = (ActiveMQConnection) createConnection();
1:4d265fd:         Session dlqSession = dlqConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:4d265fd:         MessageConsumer dlqConsumer = dlqSession.createConsumer(new ActiveMQQueue("ActiveMQ.DLQ"));
1:4d265fd:         dlqConsumer.setMessageListener(new MessageListener() {
1:4d265fd:             public void onMessage(Message message) {
1:4d265fd:                 if (received.getCount() > 0 && received.getCount() % 200 == 0) {
1:4d265fd:                     LOG.info("remaining on DLQ: " + received.getCount());
1:4d265fd:                 }
1:4d265fd:                 received.countDown();
1:4d265fd:                 dlqConsumerLastReceivedTimeStamp = System.currentTimeMillis();
1:4d265fd:                 dlqReceivedCount.incrementAndGet();
1:4d265fd:             }
1:4d265fd:         });
1:4d265fd:         dlqConnection.start();
1:4d265fd:     }
1:4d265fd: 
1:4d265fd: 
1:c290a17:     private void closeConsumer() throws JMSException {
1:4d265fd:         for (TopicSubscriber sub : duralbeSubs) {
1:4d265fd:             sub.close();
1:4d265fd:         }
1:4d265fd:         if (consumerSession != null) {
1:4d265fd:             for (int i = 1; i <= numDurableSubs; i++) {
1:4d265fd:                 consumerSession.unsubscribe("subName" + i);
1:4d265fd:             }
1:4d265fd:         }
1:4d265fd:         if (consumerConnection != null) {
1:c290a17:             consumerConnection.close();
1:4d265fd:             consumerConnection = null;
1:4d265fd:         }
1:c290a17:     }
1:4d265fd: 
1:4d265fd:     private void closeDlqConsumer() throws JMSException, InterruptedException {
1:4d265fd:         final long limit = System.currentTimeMillis() + 30 * 1000;
1:4d265fd:         if (dlqConsumerLastReceivedTimeStamp > 0) {
1:4d265fd:             while (System.currentTimeMillis() < dlqConsumerLastReceivedTimeStamp + 5000
1:4d265fd:                     && System.currentTimeMillis() < limit) {
1:4d265fd:                 LOG.info("waiting for DLQ do drain, receivedCount: " + dlqReceivedCount);
1:4d265fd:                 TimeUnit.SECONDS.sleep(1);
1:4d265fd:             }
1:4d265fd:         }
1:4d265fd:         if (dlqConnection != null) {
1:4d265fd:             dlqConnection.close();
1:4d265fd:             dlqConnection = null;
1:4d265fd:         }
1:c290a17:     }
1:c290a17: 
1:c290a17:     private void sendMessage(boolean filter) throws Exception {
1:c290a17:         if (producerConnection == null) {
1:c290a17:             producerConnection = (ActiveMQConnection) createConnection();
1:c290a17:             producerConnection.start();
1:c290a17:             producerSession = producerConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:c290a17:             producer = producerSession.createProducer(topic);
1:c290a17:         }
1:c290a17: 
1:c290a17:         Message message = producerSession.createMessage();
1:c290a17:         message.setStringProperty("data", data);
1:c290a17:         producer.send(message);
1:c290a17:     }
1:c290a17: 
1:c290a17:     private void startBroker(boolean deleteMessages) throws Exception {
1:c290a17:         broker = new BrokerService();
1:c290a17:         broker.setAdvisorySupport(false);
1:c290a17:         broker.setBrokerName("testStoreSize");
1:c290a17: 
1:c290a17:         PolicyMap map = new PolicyMap();
1:c290a17:         PolicyEntry entry = new PolicyEntry();
1:c290a17:         entry.setEnableAudit(false);
1:c290a17:         map.setDefaultEntry(entry);
1:c290a17:         broker.setDestinationPolicy(map);
1:c290a17: 
1:c290a17:         if (deleteMessages) {
1:c290a17:             broker.setDeleteAllMessagesOnStartup(true);
1:c290a17:         }
1:c290a17:         configurePersistenceAdapter(broker.getPersistenceAdapter());
1:c290a17:         broker.getSystemUsage().getStoreUsage().setLimit(200 * 1000 * 1000);
1:c290a17:         broker.start();
1:c290a17:     }
1:c290a17: 
1:c290a17:     private void configurePersistenceAdapter(PersistenceAdapter persistenceAdapter) {
1:c290a17:         Properties properties = new Properties();
1:c290a17:         String maxFileLengthVal = String.valueOf(2 * 1024 * 1024);
1:c290a17:         properties.put("journalMaxFileLength", maxFileLengthVal);
1:c290a17:         properties.put("maxFileLength", maxFileLengthVal);
1:c290a17:         properties.put("cleanupInterval", "2000");
1:c290a17:         properties.put("checkpointInterval", "2000");
1:62bdbb0:         properties.put("preallocationScope", Journal.PreallocationScope.ENTIRE_JOURNAL.name());
1:66a945a:         // there are problems with duplicate dispatch in the cursor, which maintain
1:66a945a:         // a map of messages. A dup dispatch can be dropped.
1:66a945a:         // see: org.apache.activemq.broker.region.cursors.OrderedPendingList
1:66a945a:         // Adding duplicate detection to the default DLQ strategy removes the problem
1:66a945a:         // which means we can leave the default for concurrent store and dispatch q
1:66a945a:         //properties.put("concurrentStoreAndDispatchQueues", "false");
1:4d265fd: 
1:c290a17:         IntrospectionSupport.setProperties(persistenceAdapter, properties);
1:c290a17:     }
1:c290a17: 
1:c290a17:     private void stopBroker() throws Exception {
1:c290a17:         if (broker != null)
1:c290a17:             broker.stop();
1:c290a17:         broker = null;
1:c290a17:     }
1:c290a17: 
1:c290a17:     protected ActiveMQConnectionFactory createConnectionFactory() throws Exception {
1:c290a17:         return new ActiveMQConnectionFactory("vm://testStoreSize?jms.watchTopicAdvisories=false&jms.redeliveryPolicy.maximumRedeliveries=1&jms.redeliveryPolicy.initialRedeliveryDelay=0&waitForStart=5000&create=false");
1:c290a17:     }
1:c290a17: 
1:c290a17:     @Override
1:c290a17:     protected void setUp() throws Exception {
1:c290a17:         super.setUp();
1:c290a17: 
1:c290a17:         StringBuilder sb = new StringBuilder(5000);
1:c290a17:         for (int i = 0; i < 5000; i++) {
1:c290a17:             sb.append('a');
1:c290a17:         }
1:c290a17:         data = sb.toString();
1:c290a17: 
1:c290a17:         startBroker(true);
1:c290a17:         topic = (ActiveMQTopic) createDestination();
1:c290a17:     }
1:c290a17: 
1:c290a17:     @Override
1:c290a17:     protected void tearDown() throws Exception {
1:c290a17:         stopBroker();
1:c290a17:         super.tearDown();
1:c290a17:     }
1:c290a17: }
============================================================================
author:gtully
-------------------------------------------------------------------------------
commit:62bdbb0
/////////////////////////////////////////////////////////////////////////
1: import org.apache.activemq.store.kahadb.disk.journal.Journal;
/////////////////////////////////////////////////////////////////////////
1:         properties.put("preallocationScope", Journal.PreallocationScope.ENTIRE_JOURNAL.name());
author:Timothy A. Bish
-------------------------------------------------------------------------------
commit:ef24cc9
author:Bosanac Dejan
-------------------------------------------------------------------------------
commit:8bf987b
/////////////////////////////////////////////////////////////////////////
1: import org.slf4j.Logger;
1: import org.slf4j.LoggerFactory;
1:     static final Logger LOG = LoggerFactory.getLogger(AMQ2584ConcurrentDlqTest.class);
author:Gary Tully
-------------------------------------------------------------------------------
commit:66a945a
/////////////////////////////////////////////////////////////////////////
1:         // there are problems with duplicate dispatch in the cursor, which maintain
1:         // a map of messages. A dup dispatch can be dropped.
1:         // see: org.apache.activemq.broker.region.cursors.OrderedPendingList
1:         // Adding duplicate detection to the default DLQ strategy removes the problem
1:         // which means we can leave the default for concurrent store and dispatch q
1:         //properties.put("concurrentStoreAndDispatchQueues", "false");
commit:4d265fd
/////////////////////////////////////////////////////////////////////////
1: import java.io.File;
1: import java.io.FilenameFilter;
1: import java.util.Arrays;
1: import java.util.Vector;
1: import java.util.concurrent.atomic.AtomicLong;
1: import javax.jms.TopicSubscriber;
/////////////////////////////////////////////////////////////////////////
1:     Session consumerSession;
1:     Vector<TopicSubscriber> duralbeSubs = new Vector<TopicSubscriber>();
1:     final int numDurableSubs = 2;
1:     private long dlqConsumerLastReceivedTimeStamp;
1:     private AtomicLong dlqReceivedCount = new AtomicLong(0);
1: 
1:     // 2 deliveries of each message, 3 producers
1:     CountDownLatch redeliveryConsumerLatch = new CountDownLatch(((2 * numMessages) * numDurableSubs) - 1);
1:     // should get at least numMessages, possibly more
1:     CountDownLatch dlqConsumerLatch = new CountDownLatch((numMessages - 1));
1: 
1: 
1:         LOG.info("store percent usage: " + brokerView.getStorePercentUsage());
1:         assertTrue("redelivery consumer got all it needs, remaining: "
1:                 + redeliveryConsumerLatch.getCount(), redeliveryConsumerLatch.await(60, TimeUnit.SECONDS));
1: 
1:         // consumer all of the duplicates that arrived after the first ack
1:         closeDlqConsumer();
1: 
1:         FilenameFilter justLogFiles = new FilenameFilter() {
1:             public boolean accept(File file, String s) {
1:                 return s.endsWith(".log");
1:             }
1:         };
1:         int numFiles = ((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getDirectory().list(justLogFiles).length;
1:         if (numFiles > 2) {
1:             LOG.info(Arrays.toString(((KahaDBPersistenceAdapter) broker.getPersistenceAdapter()).getDirectory().list(justLogFiles)));
1:         }
1:         assertEquals("kahaDB dir should contain 1 db file,is: " + numFiles, 1, numFiles);
1:     }
1:         consumerSession = consumerConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:                     consumerSession.recover();
1:         for (int i = 1; i <= numDurableSubs; i++) {
1:             TopicSubscriber sub = consumerSession.createDurableSubscriber(topic, "subName" + i);
1:             sub.setMessageListener(listener);
1:             duralbeSubs.add(sub);
1:         }
1: 
1:     private void openDlqConsumer(final CountDownLatch received) throws Exception {
1: 
1:         dlqConnection = (ActiveMQConnection) createConnection();
1:         Session dlqSession = dlqConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:         MessageConsumer dlqConsumer = dlqSession.createConsumer(new ActiveMQQueue("ActiveMQ.DLQ"));
1:         dlqConsumer.setMessageListener(new MessageListener() {
1:             public void onMessage(Message message) {
1:                 if (received.getCount() > 0 && received.getCount() % 200 == 0) {
1:                     LOG.info("remaining on DLQ: " + received.getCount());
1:                 }
1:                 received.countDown();
1:                 dlqConsumerLastReceivedTimeStamp = System.currentTimeMillis();
1:                 dlqReceivedCount.incrementAndGet();
1:             }
1:         });
1:         dlqConnection.start();
1:     }
1: 
1: 
1:         for (TopicSubscriber sub : duralbeSubs) {
1:             sub.close();
1:         }
1:         if (consumerSession != null) {
1:             for (int i = 1; i <= numDurableSubs; i++) {
1:                 consumerSession.unsubscribe("subName" + i);
1:             }
1:         }
1:         if (consumerConnection != null) {
1:             consumerConnection = null;
1:         }
1: 
1:     private void closeDlqConsumer() throws JMSException, InterruptedException {
1:         final long limit = System.currentTimeMillis() + 30 * 1000;
1:         if (dlqConsumerLastReceivedTimeStamp > 0) {
1:             while (System.currentTimeMillis() < dlqConsumerLastReceivedTimeStamp + 5000
1:                     && System.currentTimeMillis() < limit) {
1:                 LOG.info("waiting for DLQ do drain, receivedCount: " + dlqReceivedCount);
1:                 TimeUnit.SECONDS.sleep(1);
1:             }
1:         }
1:         if (dlqConnection != null) {
1:             dlqConnection.close();
1:             dlqConnection = null;
1:         }
/////////////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////
0:         properties.put("concurrentStoreAndDispatchQueues", "false");
1: 
commit:c290a17
/////////////////////////////////////////////////////////////////////////
1: /**
1:  * Licensed to the Apache Software Foundation (ASF) under one or more
1:  * contributor license agreements.  See the NOTICE file distributed with
1:  * this work for additional information regarding copyright ownership.
1:  * The ASF licenses this file to You under the Apache License, Version 2.0
1:  * (the "License"); you may not use this file except in compliance with
1:  * the License.  You may obtain a copy of the License at
1:  *
1:  *      http://www.apache.org/licenses/LICENSE-2.0
1:  *
1:  * Unless required by applicable law or agreed to in writing, software
1:  * distributed under the License is distributed on an "AS IS" BASIS,
1:  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
1:  * See the License for the specific language governing permissions and
1:  * limitations under the License.
1:  */
1: package org.apache.activemq.bugs;
1: 
1: import java.util.Properties;
1: import java.util.concurrent.CountDownLatch;
1: import java.util.concurrent.TimeUnit;
1: 
1: import javax.jms.JMSException;
1: import javax.jms.Message;
1: import javax.jms.MessageConsumer;
1: import javax.jms.MessageListener;
1: import javax.jms.MessageProducer;
1: import javax.jms.Session;
1: 
0: import junit.framework.Test;
1: 
1: import org.apache.activemq.ActiveMQConnection;
1: import org.apache.activemq.ActiveMQConnectionFactory;
1: import org.apache.activemq.broker.BrokerService;
1: import org.apache.activemq.broker.jmx.BrokerView;
1: import org.apache.activemq.broker.region.policy.PolicyEntry;
1: import org.apache.activemq.broker.region.policy.PolicyMap;
1: import org.apache.activemq.command.ActiveMQQueue;
1: import org.apache.activemq.command.ActiveMQTopic;
1: import org.apache.activemq.store.PersistenceAdapter;
1: import org.apache.activemq.store.kahadb.KahaDBPersistenceAdapter;
1: import org.apache.activemq.util.IntrospectionSupport;
0: import org.apache.commons.logging.Log;
0: import org.apache.commons.logging.LogFactory;
1: 
1: // variation on AMQ2584 where the DLQ consumer works in parallel to producer so
1: // that some dups are not suppressed as they are already acked by the consumer
1: // the audit needs to be disabled to allow these dupes to be consumed
1: public class AMQ2584ConcurrentDlqTest extends org.apache.activemq.TestSupport {
1: 
0:     static final Log LOG = LogFactory.getLog(AMQ2584ConcurrentDlqTest.class);
1:     BrokerService broker = null;
1:     ActiveMQTopic topic;
1: 
1:     ActiveMQConnection consumerConnection = null, producerConnection = null, dlqConnection = null;
1:     Session producerSession;
1:     MessageProducer producer;
0:     final int minPercentUsageForStore = 10;
1:     final int numMessages = 1000;
1: 
1:     String data;
1: 
1:     public void testSize() throws Exception {
0:         CountDownLatch redeliveryConsumerLatch = new CountDownLatch(((2*numMessages) *3) -1);
0:         CountDownLatch dlqConsumerLatch = new CountDownLatch((numMessages) -1);
1:         openConsumer(redeliveryConsumerLatch);
1:         openDlqConsumer(dlqConsumerLatch);
1:                
1: 
1:         assertEquals(0, broker.getAdminView().getStorePercentUsage());
1: 
1:         for (int i = 0; i < numMessages; i++) {
1:             sendMessage(false);
1:         }
1:         
1:         final BrokerView brokerView = broker.getAdminView();
1: 
1:         broker.getSystemUsage().getStoreUsage().isFull();
0:         LOG.info("store percent usage: "+brokerView.getStorePercentUsage());
0:         //assertTrue("some store in use", broker.getAdminView().getStorePercentUsage() > minPercentUsageForStore);
0:         assertTrue("redelivery consumer got all it needs", redeliveryConsumerLatch.await(60, TimeUnit.SECONDS));
1:         assertTrue("dql  consumer got all it needs", dlqConsumerLatch.await(60, TimeUnit.SECONDS));
1:         closeConsumer();
1: 
1:         LOG.info("Giving dlq a chance to clear down once topic consumer is closed");
1:         //get broker a chance to clean obsolete messages, wait 2*cleanupInterval
1:         Thread.sleep(5000);
1: 
0:         // consumer some of the duplicates that arrived after the first ack
0:         closeDlqConsumer();
0:         int numFiles = ((KahaDBPersistenceAdapter)broker.getPersistenceAdapter()).getDirectory().list().length;
1:         LOG.info("num files: " + numFiles);
0:         assertTrue("kahaDB dir should contain few db files,but definitely less than 10, is: " + numFiles,10>numFiles);
1: 		}
1:        
1: 
1:     private void openConsumer(final CountDownLatch latch) throws Exception {
1:         consumerConnection = (ActiveMQConnection) createConnection();
1:         consumerConnection.setClientID("cliID");
1:         consumerConnection.start();
0:         final Session session = consumerConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1: 
1:         MessageListener listener = new MessageListener() {
1:             public void onMessage(Message message) {
1:                 latch.countDown();
1:                 try {
0:                     session.recover();
1:                 } catch (Exception ignored) {
1:                     ignored.printStackTrace();
1:                 }
1: 
1:             }
1:         };
1: 
0:         session.createDurableSubscriber(topic, "subName1").setMessageListener(listener);
0:         session.createDurableSubscriber(topic, "subName2").setMessageListener(listener);
0:         session.createDurableSubscriber(topic, "subName3").setMessageListener(listener);
1:     }
0:     private void openDlqConsumer(final CountDownLatch received)throws Exception{
1:     	
0:     	dlqConnection  = (ActiveMQConnection) createConnection();
0:     	Session dlqSession = dlqConnection .createSession(false, Session.AUTO_ACKNOWLEDGE);
0:     	MessageConsumer dlqConsumer = dlqSession.createConsumer(new ActiveMQQueue("ActiveMQ.DLQ"));
0:     	dlqConsumer.setMessageListener(new MessageListener() {
1:           public void onMessage(Message message) {
0:               if (received.getCount() % 200 == 0) {
0:                   LOG.info("remaining on DLQ: " + received.getCount());
1:               }
0:               received.countDown();
1:           }
0:     	});
0:     	dlqConnection.start();
1:     } 
1:     
1:     
1:     private void closeConsumer() throws JMSException {
0:         if (consumerConnection != null)
1:             consumerConnection.close();
0:         consumerConnection = null;
1:     }
0:     private void closeDlqConsumer() throws JMSException {
0:         if (dlqConnection != null)
0:         	dlqConnection.close();
0:         dlqConnection = null;
1:     }
1: 
1:     private void sendMessage(boolean filter) throws Exception {
1:         if (producerConnection == null) {
1:             producerConnection = (ActiveMQConnection) createConnection();
1:             producerConnection.start();
1:             producerSession = producerConnection.createSession(false, Session.AUTO_ACKNOWLEDGE);
1:             producer = producerSession.createProducer(topic);
1:         }
1: 
1:         Message message = producerSession.createMessage();
1:         message.setStringProperty("data", data);
1:         producer.send(message);
1:     }
1: 
1:     private void startBroker(boolean deleteMessages) throws Exception {
1:         broker = new BrokerService();
1:         broker.setAdvisorySupport(false);
1:         broker.setBrokerName("testStoreSize");
1: 
1:         PolicyMap map = new PolicyMap();
1:         PolicyEntry entry = new PolicyEntry();
1:         entry.setEnableAudit(false);
1:         map.setDefaultEntry(entry);
1:         broker.setDestinationPolicy(map);
1: 
1:         if (deleteMessages) {
1:             broker.setDeleteAllMessagesOnStartup(true);
1:         }
0:         KahaDBPersistenceAdapter persistenceAdapter=new KahaDBPersistenceAdapter();
0:         persistenceAdapter.setEnableJournalDiskSyncs(false);
1:         
0:         broker.setPersistenceAdapter(persistenceAdapter);
1:         configurePersistenceAdapter(broker.getPersistenceAdapter());
1:         broker.getSystemUsage().getStoreUsage().setLimit(200 * 1000 * 1000);
1:         broker.start();
1:     }
1: 
1:     private void configurePersistenceAdapter(PersistenceAdapter persistenceAdapter) {
1:         Properties properties = new Properties();
1:         String maxFileLengthVal = String.valueOf(2 * 1024 * 1024);
1:         properties.put("journalMaxFileLength", maxFileLengthVal);
1:         properties.put("maxFileLength", maxFileLengthVal);
1:         properties.put("cleanupInterval", "2000");
1:         properties.put("checkpointInterval", "2000");
1:        
1:         IntrospectionSupport.setProperties(persistenceAdapter, properties);
1:     }
1: 
1:     private void stopBroker() throws Exception {
1:         if (broker != null)
1:             broker.stop();
1:         broker = null;
1:     }
1: 
1:     protected ActiveMQConnectionFactory createConnectionFactory() throws Exception {
1:         return new ActiveMQConnectionFactory("vm://testStoreSize?jms.watchTopicAdvisories=false&jms.redeliveryPolicy.maximumRedeliveries=1&jms.redeliveryPolicy.initialRedeliveryDelay=0&waitForStart=5000&create=false");
1:     }
1: 
1:     @Override
1:     protected void setUp() throws Exception {
1:         super.setUp();
1: 
1:         StringBuilder sb = new StringBuilder(5000);
1:         for (int i = 0; i < 5000; i++) {
1:             sb.append('a');
1:         }
1:         data = sb.toString();
1: 
1:         startBroker(true);
1:         topic = (ActiveMQTopic) createDestination();
1:     }
1: 
1:     @Override
1:     protected void tearDown() throws Exception {
1:         stopBroker();
1:         super.tearDown();
1:     }
1: }
============================================================================